diff --git a/.ci-farms/igalia b/.ci-farms-disabled/igalia
similarity index 100%
rename from .ci-farms/igalia
rename to .ci-farms-disabled/igalia
diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
index d73c9e47434..558144d765d 100644
--- a/.gitlab-ci.yml
+++ b/.gitlab-ci.yml
@@ -47,6 +47,10 @@ workflow:
         DEQP_RUNNER_MAX_FAILS: 40
     # post-merge pipeline
     - if: &is-post-merge $GITLAB_USER_LOGIN == "marge-bot" && $CI_PIPELINE_SOURCE == "push"
+      variables:
+        FDO_RUNNER_JOB_PRIORITY_TAG_X86_64: priority:high
+        FDO_RUNNER_JOB_PRIORITY_TAG_X86_64_KVM: priority:high-kvm
+        FDO_RUNNER_JOB_PRIORITY_TAG_AARCH64: priority:high-aarch64
     # Pre-merge pipeline
     - if: &is-pre-merge $CI_PIPELINE_SOURCE == "merge_request_event"
     # Push to a branch on a fork
@@ -74,12 +78,11 @@ workflow:
 
 variables:
   FDO_UPSTREAM_REPO: mesa/mesa
-  MESA_TEMPLATES_COMMIT: &ci-templates-commit 48e4b6c9a2015f969fbe648999d16d5fb3eef6c4
+  MESA_TEMPLATES_COMMIT: &ci-templates-commit c6aeb16f86e32525fa630fb99c66c4f3e62fc3cb
   CI_PRE_CLONE_SCRIPT: |-
           set -o xtrace
-          wget -q -O download-git-cache.sh ${CI_PROJECT_URL}/-/raw/${CI_COMMIT_SHA}/.gitlab-ci/download-git-cache.sh
-          bash download-git-cache.sh
-          rm download-git-cache.sh
+          curl --silent --location --fail --retry-connrefused --retry 3 --retry-delay 10 \
+            ${CI_PROJECT_URL}/-/raw/${CI_COMMIT_SHA}/.gitlab-ci/download-git-cache.sh | bash
           set +o xtrace
   S3_JWT_FILE: /s3_jwt
   S3_JWT_FILE_SCRIPT: |-
@@ -166,37 +169,34 @@ stages:
   - build-only
   - code-validation
   - amd
-  - amd-postmerge
+  - amd-nightly
   - intel
-  - intel-postmerge
+  - intel-nightly
   - nouveau
-  - nouveau-postmerge
+  - nouveau-nightly
   - arm
-  - arm-postmerge
+  - arm-nightly
   - broadcom
-  - broadcom-postmerge
+  - broadcom-nightly
   - freedreno
-  - freedreno-postmerge
+  - freedreno-nightly
   - etnaviv
-  - etnaviv-postmerge
+  - etnaviv-nightly
   - software-renderer
-  - software-renderer-postmerge
+  - software-renderer-nightly
   - layered-backends
-  - layered-backends-postmerge
+  - layered-backends-nightly
   - performance
   - deploy
 
 include:
-  - project: 'freedesktop/ci-templates'
-    ref: 16bc29078de5e0a067ff84a1a199a3760d3b3811
-    file:
-      - '/templates/ci-fairy.yml'
   - project: 'freedesktop/ci-templates'
     ref: *ci-templates-commit
     file:
       - '/templates/alpine.yml'
       - '/templates/debian.yml'
       - '/templates/fedora.yml'
+      - '/templates/ci-fairy.yml'
   - local: '.gitlab-ci/image-tags.yml'
   - local: '.gitlab-ci/lava/lava-gitlab-ci.yml'
   - local: '.gitlab-ci/container/gitlab-ci.yml'
@@ -337,7 +337,7 @@ include:
 
 # Git archive
 
-make git archive:
+make-git-archive:
   extends:
     - .fdo.ci-fairy
   stage: git-archive
@@ -351,7 +351,7 @@ make git archive:
     # compress the current folder
     - tar -cvzf ../$CI_PROJECT_NAME.tar.gz .
 
-    - s3_upload ../$CI_PROJECT_NAME.tar.gz "https://$S3_HOST/git-cache/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME/"
+    - ci-fairy s3cp --token-file "${S3_JWT_FILE}" ../$CI_PROJECT_NAME.tar.gz https://$S3_HOST/git-cache/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME/$CI_PROJECT_NAME.tar.gz
 
 # Sanity checks of MR settings and commit logs
 sanity:
@@ -381,7 +381,6 @@ sanity:
         DEBIAN_TEST_GL_TAG
         DEBIAN_TEST_VK_TAG
         FEDORA_X86_64_BUILD_TAG
-        KERNEL_ROOTFS_TAG
         KERNEL_TAG
         PKG_REPO_REV
         WINDOWS_X64_BUILD_TAG
diff --git a/.gitlab-ci/android-cts-runner.sh b/.gitlab-ci/android-cts-runner.sh
index b4fb77fe2f9..72bfd87040a 100755
--- a/.gitlab-ci/android-cts-runner.sh
+++ b/.gitlab-ci/android-cts-runner.sh
@@ -4,8 +4,8 @@
 
 . "${SCRIPTS_DIR}/setup-test-env.sh"
 
-export PATH=/android-tools/android-cts/jdk/bin/:/android-tools/build-tools:$PATH
-export JAVA_HOME=/android-tools/android-cts/jdk
+export PATH=/android-cts/jdk/bin/:$PATH
+export JAVA_HOME=/android-cts/jdk
 
 # Wait for the appops service to show up
 while [ "$($ADB shell dumpsys -l | grep appops)" = "" ] ; do sleep 1; done
@@ -14,23 +14,23 @@ SKIP_FILE="$INSTALL/${GPU_VERSION}-android-cts-skips.txt"
 
 EXCLUDE_FILTERS=""
 if [ -e "$SKIP_FILE" ]; then
-  EXCLUDE_FILTERS="$(grep -v -E "(^#|^[[:space:]]*$)" "$SKIP_FILE" | sed -s 's/.*/--exclude-filter "\0" /g')"
+  EXCLUDE_FILTERS="$(grep -v -E "(^#|^[[:space:]]*$)" "$SKIP_FILE" | sed -e 's/\s*$//g' -e 's/.*/--exclude-filter "\0" /g')"
 fi
 
 INCLUDE_FILE="$INSTALL/${GPU_VERSION}-android-cts-include.txt"
 
 if [ -e "$INCLUDE_FILE" ]; then
-  INCLUDE_FILTERS="$(grep -v -E "(^#|^[[:space:]]*$)" "$INCLUDE_FILE" | sed -s 's/.*/--include-filter "\0" /g')"
+  INCLUDE_FILTERS="$(grep -v -E "(^#|^[[:space:]]*$)" "$INCLUDE_FILE" | sed -e 's/\s*$//g' -e 's/.*/--include-filter "\0" /g')"
 else
   INCLUDE_FILTERS=$(printf -- "--include-filter %s " $ANDROID_CTS_MODULES | sed -e 's/ $//g')
 fi
 
 set +e
-eval "/android-tools/android-cts/tools/cts-tradefed" run commandAndExit cts-dev \
-  $EXCLUDE_FILTERS \
-  $INCLUDE_FILTERS
+eval "/android-cts/tools/cts-tradefed" run commandAndExit cts-dev \
+  $INCLUDE_FILTERS \
+  $EXCLUDE_FILTERS
 
-[ "$(grep "^FAILED" /android-tools/android-cts/results/latest/invocation_summary.txt | tr -d ' ' | cut -d ':' -f 2)" = "0" ]
+[ "$(grep "^FAILED" /android-cts/results/latest/invocation_summary.txt | tr -d ' ' | cut -d ':' -f 2)" = "0" ]
 
 # shellcheck disable=SC2034 # EXIT_CODE is used by the script that sources this one
 EXIT_CODE=$?
@@ -38,7 +38,7 @@ set -e
 
 section_switch cuttlefish_results "cuttlefish: gathering the results"
 
-cp -r "/android-tools/android-cts/results/latest"/* $RESULTS_DIR
-cp -r "/android-tools/android-cts/logs/latest"/* $RESULTS_DIR
+cp -r "/android-cts/results/latest"/* $RESULTS_DIR
+cp -r "/android-cts/logs/latest"/* $RESULTS_DIR
 
 section_end cuttlefish_results
diff --git a/.gitlab-ci/bare-metal/cisco-2960-poe-off.sh b/.gitlab-ci/bare-metal/cisco-2960-poe-off.sh
deleted file mode 100755
index fdc52d3c43a..00000000000
--- a/.gitlab-ci/bare-metal/cisco-2960-poe-off.sh
+++ /dev/null
@@ -1,17 +0,0 @@
-#!/bin/bash
-# shellcheck disable=SC2086 # we want word splitting
-
-if [ -z "$BM_POE_INTERFACE" ]; then
-    echo "Must supply the PoE Interface to power down"
-    exit 1
-fi
-
-if [ -z "$BM_POE_ADDRESS" ]; then
-    echo "Must supply the PoE Switch host"
-    exit 1
-fi
-
-SNMP_KEY="1.3.6.1.4.1.9.9.402.1.2.1.1.1.$BM_POE_INTERFACE"
-SNMP_OFF="i 4"
-
-snmpset -v2c -r 3 -t 30 -cmesaci "$BM_POE_ADDRESS" "$SNMP_KEY" $SNMP_OFF
diff --git a/.gitlab-ci/bare-metal/cisco-2960-poe-on.sh b/.gitlab-ci/bare-metal/cisco-2960-poe-on.sh
deleted file mode 100755
index 1f80ab37889..00000000000
--- a/.gitlab-ci/bare-metal/cisco-2960-poe-on.sh
+++ /dev/null
@@ -1,22 +0,0 @@
-#!/bin/bash
-# shellcheck disable=SC2086 # we want word splitting
-
-if [ -z "$BM_POE_INTERFACE" ]; then
-    echo "Must supply the PoE Interface to power up"
-    exit 1
-fi
-
-if [ -z "$BM_POE_ADDRESS" ]; then
-    echo "Must supply the PoE Switch host"
-    exit 1
-fi
-
-set -ex
-
-SNMP_KEY="1.3.6.1.4.1.9.9.402.1.2.1.1.1.$BM_POE_INTERFACE"
-SNMP_ON="i 1"
-SNMP_OFF="i 4"
-
-snmpset -v2c -r 3 -t 10 -cmesaci "$BM_POE_ADDRESS" "$SNMP_KEY" $SNMP_OFF
-sleep 3s
-snmpset -v2c -r 3 -t 10 -cmesaci "$BM_POE_ADDRESS" "$SNMP_KEY" $SNMP_ON
diff --git a/.gitlab-ci/bare-metal/poe-powered.sh b/.gitlab-ci/bare-metal/poe-powered.sh
index 3be933ef855..26f716c74eb 100755
--- a/.gitlab-ci/bare-metal/poe-powered.sh
+++ b/.gitlab-ci/bare-metal/poe-powered.sh
@@ -144,33 +144,6 @@ fi
 
 date +'%F %T'
 
-# Set up the pxelinux config for Jetson Nano
-mkdir -p /tftp/pxelinux.cfg
-cat <<EOF >/tftp/pxelinux.cfg/default-arm-tegra210-p3450-0000
-PROMPT 0
-TIMEOUT 30
-DEFAULT primary
-MENU TITLE jetson nano boot options
-LABEL primary
-      MENU LABEL CI kernel on TFTP
-      LINUX Image
-      FDT tegra210-p3450-0000.dtb
-      APPEND \${cbootargs} $BM_CMDLINE
-EOF
-
-# Set up the pxelinux config for Jetson TK1
-cat <<EOF >/tftp/pxelinux.cfg/default-arm-tegra124-jetson-tk1
-PROMPT 0
-TIMEOUT 30
-DEFAULT primary
-MENU TITLE jetson TK1 boot options
-LABEL primary
-      MENU LABEL CI kernel on TFTP
-      LINUX zImage
-      FDT tegra124-jetson-tk1.dtb
-      APPEND \${cbootargs} $BM_CMDLINE
-EOF
-
 # Create the rootfs in the NFS directory
 . $BM/rootfs-setup.sh /nfs
 
diff --git a/.gitlab-ci/bare-metal/telnet-buffer.py b/.gitlab-ci/bare-metal/telnet-buffer.py
deleted file mode 100755
index 408243a0109..00000000000
--- a/.gitlab-ci/bare-metal/telnet-buffer.py
+++ /dev/null
@@ -1,41 +0,0 @@
-#!/usr/bin/python3
-
-# Copyright Â© 2020 Christian Gmeiner
-#
-# Permission is hereby granted, free of charge, to any person obtaining a
-# copy of this software and associated documentation files (the "Software"),
-# to deal in the Software without restriction, including without limitation
-# the rights to use, copy, modify, merge, publish, distribute, sublicense,
-# and/or sell copies of the Software, and to permit persons to whom the
-# Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice (including the next
-# paragraph) shall be included in all copies or substantial portions of the
-# Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
-# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
-# IN THE SOFTWARE.
-#
-# Tiny script to read bytes from telnet, and write the output to stdout, with a
-# buffer in between so we don't lose serial output from its buffer.
-#
-
-import sys
-import telnetlib
-
-host = sys.argv[1]
-port = sys.argv[2]
-
-tn = telnetlib.Telnet(host, port, 1000000)
-
-while True:
-    bytes = tn.read_some()
-    sys.stdout.buffer.write(bytes)
-    sys.stdout.flush()
-
-tn.close()
diff --git a/.gitlab-ci/build/gitlab-ci.yml b/.gitlab-ci/build/gitlab-ci.yml
index aec36a761b3..e1588fb27b2 100644
--- a/.gitlab-ci/build/gitlab-ci.yml
+++ b/.gitlab-ci/build/gitlab-ci.yml
@@ -130,7 +130,7 @@ debian-testing-asan:
       -D mesa-clc=system
       -D tools=dlclose-skip
       -D valgrind=disabled
-    S3_ARTIFACT_NAME: ""
+    S3_ARTIFACT_NAME: mesa-x86_64-asan-${BUILDTYPE}
     ARTIFACTS_DEBUG_SYMBOLS: 1
     RUN_MESON_TESTS: "false" # just too slow
     # Do a host build for mesa-clc (asan complains not being loaded as
@@ -138,7 +138,6 @@ debian-testing-asan:
     HOST_BUILD_OPTIONS: >
       -D build-tests=false
       -D enable-glcpp-tests=false
-      -D gallium-opencl=disabled
       -D gallium-rusticl=false
       -D gallium-nine=false
       -D gallium-drivers=
@@ -177,8 +176,7 @@ debian-testing-msan:
     HOST_BUILD_OPTIONS: >
       -D build-tests=false
       -D enable-glcpp-tests=false
-      -D gallium-opencl=disabled
-      -D gallium-drivers=
+      -D gallium-drivers=panfrost
       -D vulkan-drivers=
       -D video-codecs=
       -D glx=disabled
@@ -187,7 +185,6 @@ debian-testing-msan:
       -D install-mesa-clc=true
       -D precomp-compiler=enabled
       -D install-precomp-compiler=true
-      -D tools=panfrost
 
 debian-testing-ubsan:
   extends:
@@ -214,7 +211,6 @@ debian-testing-ubsan:
     HOST_BUILD_OPTIONS: >
       -D build-tests=false
       -D enable-glcpp-tests=false
-      -D gallium-opencl=disabled
       -D gallium-rusticl=false
       -D gallium-drivers=
       -D vulkan-drivers=
@@ -302,7 +298,6 @@ alpine-build-testing:
       -Wno-error=array-bounds
       -Wno-error=stringop-overflow
       -Wno-error=stringop-overread
-      -Wno-error=misleading-indentation
     DRI_LOADERS: >
       -D glx=disabled
       -D gbm=enabled
@@ -421,8 +416,7 @@ debian-android:
     HOST_BUILD_OPTIONS: >
       -D build-tests=false
       -D enable-glcpp-tests=false
-      -D gallium-opencl=disabled
-      -D gallium-drivers=
+      -D gallium-drivers=panfrost
       -D vulkan-drivers=
       -D video-codecs=
       -D glx=disabled
@@ -431,7 +425,6 @@ debian-android:
       -D install-mesa-clc=true
       -D precomp-compiler=enabled
       -D install-precomp-compiler=true
-      -D tools=panfrost
     S3_ARTIFACT_NAME: mesa-x86_64-android-${BUILDTYPE}
   script:
     # x86_64 build:
@@ -501,8 +494,7 @@ debian-arm32:
     HOST_BUILD_OPTIONS: >
       -D build-tests=false
       -D enable-glcpp-tests=false
-      -D gallium-opencl=disabled
-      -D gallium-drivers=
+      -D gallium-drivers=panfrost
       -D vulkan-drivers=
       -D video-codecs=
       -D glx=disabled
@@ -511,7 +503,6 @@ debian-arm32:
       -D install-mesa-clc=true
       -D precomp-compiler=enabled
       -D install-precomp-compiler=true
-      -D tools=panfrost
     S3_ARTIFACT_NAME: mesa-arm32-default-${BUILDTYPE}
     # The strip command segfaults, failing to strip the binary and leaving
     # tempfiles in our artifacts.
@@ -795,7 +786,6 @@ debian-x86_32:
     HOST_BUILD_OPTIONS: >
       -D build-tests=false
       -D enable-glcpp-tests=false
-      -D gallium-opencl=disabled
       -D gallium-drivers=
       -D vulkan-drivers=
       -D video-codecs=
diff --git a/.gitlab-ci/common/export-gitlab-job-env-for-dut.sh b/.gitlab-ci/common/export-gitlab-job-env-for-dut.sh
index 0f21b3b704b..de6ddede4b0 100755
--- a/.gitlab-ci/common/export-gitlab-job-env-for-dut.sh
+++ b/.gitlab-ci/common/export-gitlab-job-env-for-dut.sh
@@ -49,7 +49,6 @@ VARS=(
     FLAKES_CHANNEL
     FLUSTER_CODECS
     FLUSTER_FRACTION
-    FLUSTER_VECTORS_VERSION
     FREEDRENO_HANGCHECK_MS
     GALLIUM_DRIVER
     GALLIVM_PERF
@@ -108,6 +107,7 @@ VARS=(
     PIGLIT_REPLAY_SUBCOMMAND
     PIGLIT_RESULTS
     PIGLIT_RUNNER_OPTIONS
+    PIGLIT_TAG
     PIGLIT_TESTS
     PIGLIT_TRACES_FILE
     PIPELINE_ARTIFACTS_BASE
@@ -120,8 +120,6 @@ VARS=(
     S3_RESULTS_UPLOAD
     SKQP_ASSETS_DIR
     SKQP_BACKENDS
-    STORAGE_FORK_HOST_PATH
-    STORAGE_MAINLINE_HOST_PATH
     TU_DEBUG
     VIRGL_HOST_API
     VIRGL_RENDER_SERVER
diff --git a/.gitlab-ci/common/init-stage2.sh b/.gitlab-ci/common/init-stage2.sh
index f411722e4f2..0ce96019594 100755
--- a/.gitlab-ci/common/init-stage2.sh
+++ b/.gitlab-ci/common/init-stage2.sh
@@ -109,6 +109,9 @@ export LIBGL_DRIVERS_PATH=/install/lib/dri
 # telling it to look in /usr/local/lib.
 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib
 
+# The Broadcom devices need /usr/local/bin unconditionally added to the path
+export PATH=/usr/local/bin:$PATH
+
 # Store Mesa's disk cache under /tmp, rather than sending it out over NFS.
 export XDG_CACHE_HOME=/tmp
 
@@ -230,7 +233,7 @@ cleanup
 # upload artifacts (lava jobs)
 if [ -n "$S3_RESULTS_UPLOAD" ]; then
   tar --zstd -cf results.tar.zst results/;
-  s3_upload results.tar.zst "https://${S3_RESULTS_UPLOAD}/"
+  ci-fairy s3cp --token-file "${S3_JWT_FILE}" results.tar.zst https://"$S3_RESULTS_UPLOAD"/results.tar.zst
 fi
 
 # We still need to echo the hwci: mesa message, as some scripts rely on it, such
diff --git a/.gitlab-ci/conditional-build-image-tags.yml b/.gitlab-ci/conditional-build-image-tags.yml
index cff5183edca..2c962ed0f61 100644
--- a/.gitlab-ci/conditional-build-image-tags.yml
+++ b/.gitlab-ci/conditional-build-image-tags.yml
@@ -1,2 +1,3 @@
 variables:
-  CONDITIONAL_BUILD_ANGLE_TAG: ab19bccfd3858c539ba8cb8d9b52a003
+  CONDITIONAL_BUILD_ANGLE_TAG: be4f59328ef607bcbf5048a3f6f27410
+  CONDITIONAL_BUILD_PIGLIT_TAG: a19e424b8a3f020dbf1b9dd29f220a4f
diff --git a/.gitlab-ci/container/baremetal_build.sh b/.gitlab-ci/container/baremetal_build.sh
index 9fed2539ce0..9abf8912ca8 100644
--- a/.gitlab-ci/container/baremetal_build.sh
+++ b/.gitlab-ci/container/baremetal_build.sh
@@ -1,4 +1,5 @@
 #!/usr/bin/env bash
+# shellcheck disable=SC2154 # arch is assigned in previous scripts
 
 set -e
 set -o xtrace
@@ -6,11 +7,12 @@ set -o xtrace
 # Fetch the arm-built rootfs image and unpack it in our x86_64 container (saves
 # network transfer, disk usage, and runtime on test jobs)
 
-# shellcheck disable=SC2154 # arch is assigned in previous scripts
-if curl --fail -L -s "${ARTIFACTS_PREFIX}/${FDO_UPSTREAM_REPO}/${ARTIFACTS_SUFFIX}/${arch}/done"; then
-  ARTIFACTS_URL="${ARTIFACTS_PREFIX}/${FDO_UPSTREAM_REPO}/${ARTIFACTS_SUFFIX}/${arch}"
+S3_PATH="https://${S3_HOST}/${S3_KERNEL_BUCKET}"
+
+if curl -L --retry 3 -f --retry-delay 10 -s --head "${S3_PATH}/${FDO_UPSTREAM_REPO}/${LAVA_DISTRIBUTION_TAG}"; then
+  ARTIFACTS_URL="${S3_PATH}/${FDO_UPSTREAM_REPO}/${LAVA_DISTRIBUTION_TAG}"
 else
-  ARTIFACTS_URL="${ARTIFACTS_PREFIX}/${CI_PROJECT_PATH}/${ARTIFACTS_SUFFIX}/${arch}"
+  ARTIFACTS_URL="${S3_PATH}/${CI_PROJECT_PATH}/${LAVA_DISTRIBUTION_TAG}"
 fi
 
 curl -L --retry 4 -f --retry-all-errors --retry-delay 60 \
@@ -33,30 +35,11 @@ if [[ $arch == "arm64" ]]; then
     DEVICE_TREES=""
     DEVICE_TREES="$DEVICE_TREES apq8016-sbc-usb-host.dtb"
     DEVICE_TREES="$DEVICE_TREES apq8096-db820c.dtb"
-    DEVICE_TREES="$DEVICE_TREES tegra210-p3450-0000.dtb"
-    DEVICE_TREES="$DEVICE_TREES imx8mq-nitrogen.dtb"
 
     for DTB in $DEVICE_TREES; do
 	curl -L --retry 4 -f --retry-all-errors --retry-delay 60 \
             -O "${KERNEL_IMAGE_BASE}/arm64/$DTB"
     done
 
-    popd
-elif [[ $arch == "armhf" ]]; then
-    mkdir -p /baremetal-files
-    pushd /baremetal-files
-
-    curl -L --retry 4 -f --retry-all-errors --retry-delay 60 \
-        -O "${KERNEL_IMAGE_BASE}"/armhf/zImage
-
-    DEVICE_TREES=""
-    DEVICE_TREES="$DEVICE_TREES imx6q-cubox-i.dtb"
-    DEVICE_TREES="$DEVICE_TREES tegra124-jetson-tk1.dtb"
-
-    for DTB in $DEVICE_TREES; do
-	curl -L --retry 4 -f --retry-all-errors --retry-delay 60 \
-            -O "${KERNEL_IMAGE_BASE}/armhf/$DTB"
-    done
-
     popd
 fi
diff --git a/.gitlab-ci/container/build-android-x86_64-llvm.sh b/.gitlab-ci/container/build-android-x86_64-llvm.sh
index 78fbb98fcfb..aaacc8bec40 100755
--- a/.gitlab-ci/container/build-android-x86_64-llvm.sh
+++ b/.gitlab-ci/container/build-android-x86_64-llvm.sh
@@ -114,7 +114,7 @@ tar --zstd -cf "${ANDROID_LLVM_ARTIFACT_NAME}.tar.zst" "$LLVM_INSTALL_PREFIX"
 # version does not change, and delete it.
 # The file is not deleted for non-CI because it can be useful in local runs.
 if [ -n "$CI" ]; then
-  s3_upload "${ANDROID_LLVM_ARTIFACT_NAME}.tar.zst" "https://${S3_HOST}/${S3_ANDROID_BUCKET}/${CI_PROJECT_PATH}/"
+  ci-fairy s3cp --token-file "${S3_JWT_FILE}" "${ANDROID_LLVM_ARTIFACT_NAME}.tar.zst" "https://${S3_HOST}/${S3_ANDROID_BUCKET}/${CI_PROJECT_PATH}/${ANDROID_LLVM_ARTIFACT_NAME}.tar.zst"
   rm "${ANDROID_LLVM_ARTIFACT_NAME}.tar.zst"
 fi
 
diff --git a/.gitlab-ci/container/build-angle.sh b/.gitlab-ci/container/build-angle.sh
index 9ebf3646ae8..1e03e8390cf 100755
--- a/.gitlab-ci/container/build-angle.sh
+++ b/.gitlab-ci/container/build-angle.sh
@@ -3,17 +3,17 @@
 # When changing this file, you need to bump the following
 # .gitlab-ci/image-tags.yml tags:
 # DEBIAN_TEST_ANDROID_TAG
-# KERNEL_ROOTFS_TAG
+# DEBIAN_TEST_GL_TAG
 
 set -uex
 
-uncollapsed_section_start angle "Building ANGLE"
+section_start angle "Building ANGLE"
 
 # Do a very early check to make sure the tag is correct without the need of
 # setting up the environment variables locally
 ci_tag_build_time_check "ANGLE_TAG"
 
-ANGLE_REV="a3f2545f6bb3e8d27827dceb2b4e901673995ad1"
+ANGLE_REV="f355e2b37ed43939e2753fc7dacccf75abb4c1a3"
 
 # Set ANGLE_ARCH based on DEBIAN_ARCH if it hasn't been explicitly defined
 if [[ -z "${ANGLE_ARCH:-}" ]]; then
diff --git a/.gitlab-ci/container/build-apitrace.sh b/.gitlab-ci/container/build-apitrace.sh
index 915d9948710..a0ef4497136 100644
--- a/.gitlab-ci/container/build-apitrace.sh
+++ b/.gitlab-ci/container/build-apitrace.sh
@@ -3,15 +3,13 @@
 
 # When changing this file, you need to bump the following
 # .gitlab-ci/image-tags.yml tags:
-# DEBIAN_TEST_GL_TAG
-# DEBIAN_TEST_VK_TAG
-# KERNEL_ROOTFS_TAG
+# DEBIAN_BASE_TAG
 
 set -uex
 
 uncollapsed_section_start apitrace "Building apitrace"
 
-APITRACE_VERSION="952bad1469ea747012bdc48c48993bd5f13eec04"
+APITRACE_VERSION="b6102d10960c9f43b1b473903fc67937dd19fb98"
 
 git clone https://github.com/apitrace/apitrace.git --single-branch --no-checkout /apitrace
 pushd /apitrace
diff --git a/.gitlab-ci/container/build-crosvm.sh b/.gitlab-ci/container/build-crosvm.sh
index c1d8c3bafa3..fa469e1677f 100644
--- a/.gitlab-ci/container/build-crosvm.sh
+++ b/.gitlab-ci/container/build-crosvm.sh
@@ -6,7 +6,6 @@
 # DEBIAN_BASE_TAG
 # DEBIAN_TEST_GL_TAG
 # DEBIAN_TEST_VK_TAG
-# KERNEL_ROOTFS_TAG
 
 set -uex
 
diff --git a/.gitlab-ci/container/build-deqp-runner.sh b/.gitlab-ci/container/build-deqp-runner.sh
index 9209aeed91b..6ccb31e667d 100644
--- a/.gitlab-ci/container/build-deqp-runner.sh
+++ b/.gitlab-ci/container/build-deqp-runner.sh
@@ -5,11 +5,10 @@
 # .gitlab-ci/image-tags.yml tags:
 # DEBIAN_TEST_ANDROID_TAG
 # DEBIAN_BASE_TAG
-# KERNEL_ROOTFS_TAG
 
 set -uex
 
-uncollapsed_section_start deqp-runner "Building deqp-runner"
+section_start deqp-runner "Building deqp-runner"
 
 DEQP_RUNNER_VERSION=0.20.3
 
diff --git a/.gitlab-ci/container/build-deqp.sh b/.gitlab-ci/container/build-deqp.sh
index 9a16f7655f7..3ee0d6e0e8f 100755
--- a/.gitlab-ci/container/build-deqp.sh
+++ b/.gitlab-ci/container/build-deqp.sh
@@ -6,14 +6,13 @@
 # DEBIAN_TEST_ANDROID_TAG
 # DEBIAN_TEST_GL_TAG
 # DEBIAN_TEST_VK_TAG
-# KERNEL_ROOTFS_TAG
 
 set -ue -o pipefail
 
 # shellcheck disable=SC2153
 deqp_api=${DEQP_API,,}
 
-uncollapsed_section_start deqp-$deqp_api "Building dEQP $DEQP_API"
+section_start deqp-$deqp_api "Building dEQP $DEQP_API"
 
 set -x
 
@@ -289,7 +288,7 @@ if [ "$DEQP_API" != tools ]; then
 
     # Compress the caselists, since Vulkan's in particular are gigantic; higher
     # compression levels provide no real measurable benefit.
-    zstd -1 --rm mustpass/*.txt
+    zstd -f -1 --rm mustpass/*.txt
 fi
 
 if [ "$DEQP_API" = tools ]; then
diff --git a/.gitlab-ci/container/build-fluster.sh b/.gitlab-ci/container/build-fluster.sh
index 8816e5b7574..91bd9ff57fb 100644
--- a/.gitlab-ci/container/build-fluster.sh
+++ b/.gitlab-ci/container/build-fluster.sh
@@ -4,36 +4,61 @@
 # shellcheck disable=SC2034 # Variables are used in scripts called from here
 # shellcheck disable=SC2086 # we want word splitting
 
+# When changing this file, you need to bump the following
+# .gitlab-ci/image-tags.yml tags:
+# DEBIAN_TEST_VIDEO_TAG
+
 # Install fluster in /usr/local.
 
+set -uex
+
+section_start fluster "Install fluster"
+
 FLUSTER_REVISION="e997402978f62428fffc8e5a4a709690d9ca9bc5"
 
 git clone https://github.com/fluendo/fluster.git --single-branch --no-checkout
 
+export SKIP_UPDATE_FLUSTER_VECTORS=false
+
+check_fluster()
+{
+    S3_PATH_FLUSTER="${S3_HOST}/${S3_KERNEL_BUCKET}/$1/${DATA_STORAGE_PATH}/fluster/${FLUSTER_VECTORS_VERSION}/vectors.tar.zst"
+    if curl -L --retry 4 -f --retry-connrefused --retry-delay 30 -s --head \
+      "https://${S3_PATH_FLUSTER}"; then
+        echo "Fluster vectors are up-to-date, skip rebuilding them."
+        export SKIP_UPDATE_FLUSTER_VECTORS=true
+    fi
+}
+
+check_fluster "${FDO_UPSTREAM_REPO}"
+if ! $SKIP_UPDATE_FLUSTER_VECTORS; then
+    check_fluster "${CI_PROJECT_PATH}"
+fi
+
 pushd fluster || exit
-git checkout ${FLUSTER_REVISION}
+git checkout "${FLUSTER_REVISION}"
 popd || exit
 
-if [ "${SKIP_UPDATE_FLUSTER_VECTORS}" != 1 ]; then
+if ! $SKIP_UPDATE_FLUSTER_VECTORS; then
     # Download the necessary vectors: H264, H265 and VP9
     # When updating FLUSTER_REVISION, make sure to update the vectors if necessary or
     # fluster-runner will report Missing results.
-    fluster/fluster.py download \
+    fluster/fluster.py download -j ${FDO_CI_CONCURRENT:-4} \
 	JVT-AVC_V1 JVT-FR-EXT JVT-MVC JVT-SVC_V1 \
 	JCT-VC-3D-HEVC JCT-VC-HEVC_V1 JCT-VC-MV-HEVC JCT-VC-RExt JCT-VC-SCC JCT-VC-SHVC \
 	VP9-TEST-VECTORS-HIGH VP9-TEST-VECTORS
 
     # Build fluster vectors archive and upload it
     tar --zstd -cf "vectors.tar.zst" fluster/resources/
-    s3_upload vectors.tar.zst "https://${S3_PATH_FLUSTER}/"
+    ci-fairy s3cp --token-file "${S3_JWT_FILE}" "vectors.tar.zst" \
+      "https://${S3_PATH_FLUSTER}/vectors.tar.zst"
+fi
 
-    touch /lava-files/done
-    s3_upload /lava-files/done "https://${S3_PATH_FLUSTER}/"
+mv fluster/ /usr/local/
 
-    # Don't include the vectors in the rootfs
-    rm -fr fluster/resources/*
+if $SKIP_UPDATE_FLUSTER_VECTORS; then
+    curl -L --retry 4 -f --retry-connrefused --retry-delay 30 \
+      "${FDO_HTTP_CACHE_URI:-}https://${S3_PATH_FLUSTER}" | tar --zstd -x -C /usr/local/
 fi
 
-mkdir -p "${ROOTFS}/usr/local/"
-mv fluster "${ROOTFS}/usr/local/"
-
+section_end fluster
diff --git a/.gitlab-ci/container/build-fossilize.sh b/.gitlab-ci/container/build-fossilize.sh
index b726fe92a4d..8ce3ee8d608 100644
--- a/.gitlab-ci/container/build-fossilize.sh
+++ b/.gitlab-ci/container/build-fossilize.sh
@@ -3,7 +3,6 @@
 # When changing this file, you need to bump the following
 # .gitlab-ci/image-tags.yml tags:
 # DEBIAN_TEST_VK_TAG
-# KERNEL_ROOTFS_TAG
 
 set -ex
 
diff --git a/.gitlab-ci/container/build-mold.sh b/.gitlab-ci/container/build-mold.sh
index 6ca90eb831f..ff7f1d3af4e 100644
--- a/.gitlab-ci/container/build-mold.sh
+++ b/.gitlab-ci/container/build-mold.sh
@@ -8,7 +8,6 @@ set -ex
 # DEBIAN_BASE_TAG
 # DEBIAN_BUILD_TAG
 # FEDORA_X86_64_BUILD_TAG
-# KERNEL_ROOTFS_TAG
 
 uncollapsed_section_start mold "Building mold"
 
diff --git a/.gitlab-ci/container/build-piglit.sh b/.gitlab-ci/container/build-piglit.sh
index de7c20c0db6..fe926639968 100644
--- a/.gitlab-ci/container/build-piglit.sh
+++ b/.gitlab-ci/container/build-piglit.sh
@@ -8,9 +8,12 @@ uncollapsed_section_start piglit "Building piglit"
 # .gitlab-ci/image-tags.yml tags:
 # DEBIAN_TEST_GL_TAG
 # DEBIAN_TEST_VK_TAG
-# KERNEL_ROOTFS_TAG
 
-REV="0ecdebb0f5927728ddeeb851639a559b0f7d6590"
+# Do a very early check to make sure the tag is correct without the need of
+# setting up the environment variables locally
+ci_tag_build_time_check "PIGLIT_TAG"
+
+REV="c50d9aa54f85e0af9d72fab86c73f89356d96399"
 
 git clone https://gitlab.freedesktop.org/mesa/piglit.git --single-branch --no-checkout /piglit
 pushd /piglit
diff --git a/.gitlab-ci/container/build-rust.sh b/.gitlab-ci/container/build-rust.sh
index 3d4f2c67f3f..23fede2564b 100644
--- a/.gitlab-ci/container/build-rust.sh
+++ b/.gitlab-ci/container/build-rust.sh
@@ -5,7 +5,7 @@
 
 set -ex
 
-uncollapsed_section_start rust "Building Rust toolchain"
+section_start rust "Building Rust toolchain"
 
 # Pick a specific snapshot from rustup so the compiler doesn't drift on us.
 RUST_VERSION=1.78.0-2024-05-02
diff --git a/.gitlab-ci/container/build-skqp.sh b/.gitlab-ci/container/build-skqp.sh
index c0c7107a722..4a55cf706df 100755
--- a/.gitlab-ci/container/build-skqp.sh
+++ b/.gitlab-ci/container/build-skqp.sh
@@ -6,11 +6,11 @@
 #
 # When changing this file, you need to bump the following
 # .gitlab-ci/image-tags.yml tags:
-# KERNEL_ROOTFS_TAG
+# DEBIAN_TEST_GL_TAG
 
 set -uex
 
-uncollapsed_section_start skqp "Building skqp"
+uncollapsed_section_start skqp "Building SkQP"
 
 SKQP_BRANCH=android-cts-12.1_r5
 
@@ -75,7 +75,7 @@ popd
 # Fetch some needed build tools needed to build skia/skqp.
 # Basically, it clones repositories with commits SHAs from ${SKIA_DIR}/DEPS
 # directory.
-python tools/git-sync-deps
+python3 tools/git-sync-deps
 
 mkdir -p "${SKQP_OUT_DIR}"
 mkdir -p "${SKQP_INSTALL_DIR}"
diff --git a/.gitlab-ci/container/build-va-tools.sh b/.gitlab-ci/container/build-va-tools.sh
index 859701c1d92..5db6bab7dd7 100644
--- a/.gitlab-ci/container/build-va-tools.sh
+++ b/.gitlab-ci/container/build-va-tools.sh
@@ -1,12 +1,13 @@
 #!/usr/bin/env bash
 # shellcheck disable=SC2086 # we want word splitting
+
 # When changing this file, you need to bump the following
 # .gitlab-ci/image-tags.yml tags:
-# KERNEL_ROOTFS_TAG
+# DEBIAN_TEST_VIDEO_TAG
 
 set -uex
 
-uncollapsed_section_start va-tools "Building va-tools"
+section_start va-tools "Building va-tools"
 
 git config --global user.email "mesa@example.com"
 git config --global user.name "Mesa CI"
diff --git a/.gitlab-ci/container/build-vkd3d-proton.sh b/.gitlab-ci/container/build-vkd3d-proton.sh
index d7eab97c286..ce722e2c525 100644
--- a/.gitlab-ci/container/build-vkd3d-proton.sh
+++ b/.gitlab-ci/container/build-vkd3d-proton.sh
@@ -7,36 +7,30 @@ set -ex
 
 uncollapsed_section_start vkd3d-proton "Building vkd3d-proton"
 
-VKD3D_PROTON_COMMIT="078f07f588c849c52fa21c8cfdd1c201465b1932"
+VKD3D_PROTON_COMMIT="7eef0a64e3fc107a6cb10e3abd1b56d21b575de8"
 
 VKD3D_PROTON_DST_DIR="/vkd3d-proton-tests"
 VKD3D_PROTON_SRC_DIR="/vkd3d-proton-src"
 VKD3D_PROTON_BUILD_DIR="/vkd3d-proton-build"
 
-function build_arch {
-  local arch="$1"
-
-  meson setup                              \
-        -Denable_tests=true                \
-        --buildtype release                \
-        --prefix "$VKD3D_PROTON_DST_DIR"   \
-        --strip                            \
-        --bindir "x${arch}"                \
-        --libdir "x${arch}"                \
-        "$VKD3D_PROTON_BUILD_DIR/build.${arch}"
-
-  ninja -C "$VKD3D_PROTON_BUILD_DIR/build.${arch}" install
-
-  install -D -m755 -t "${VKD3D_PROTON_DST_DIR}/x${arch}/bin" "$VKD3D_PROTON_BUILD_DIR/build.${arch}/tests/d3d12"
-}
-
 git clone https://github.com/HansKristian-Work/vkd3d-proton.git --single-branch -b master --no-checkout "$VKD3D_PROTON_SRC_DIR"
 pushd "$VKD3D_PROTON_SRC_DIR"
 git checkout "$VKD3D_PROTON_COMMIT"
 git submodule update --init --recursive
 git submodule update --recursive
-build_arch 64
-build_arch 86
+
+meson setup                              \
+      -D enable_tests=true               \
+      --buildtype release                \
+      --prefix "$VKD3D_PROTON_DST_DIR"   \
+      --strip                            \
+      --libdir "lib"                     \
+      "$VKD3D_PROTON_BUILD_DIR/build"
+
+ninja -C "$VKD3D_PROTON_BUILD_DIR/build" install
+
+install -m755 -t "${VKD3D_PROTON_DST_DIR}/" "$VKD3D_PROTON_BUILD_DIR/build/tests/d3d12"
+
 mkdir "$VKD3D_PROTON_DST_DIR/tests"
 cp \
   "tests/test-runner.sh" \
diff --git a/.gitlab-ci/container/build-vulkan-validation.sh b/.gitlab-ci/container/build-vulkan-validation.sh
index 55ac4804b17..3ab11e141c5 100644
--- a/.gitlab-ci/container/build-vulkan-validation.sh
+++ b/.gitlab-ci/container/build-vulkan-validation.sh
@@ -3,7 +3,6 @@
 # When changing this file, you need to bump the following
 # .gitlab-ci/image-tags.yml tags:
 # DEBIAN_TEST_GL_TAG
-# KERNEL_ROOTFS_TAG
 
 set -uex
 
diff --git a/.gitlab-ci/container/build-wayland.sh b/.gitlab-ci/container/build-wayland.sh
index 551edcfe7db..c691116e311 100644
--- a/.gitlab-ci/container/build-wayland.sh
+++ b/.gitlab-ci/container/build-wayland.sh
@@ -14,7 +14,6 @@ uncollapsed_section_start wayland "Building Wayland"
 # DEBIAN_TEST_GL_TAG
 # DEBIAN_TEST_VK_TAG
 # FEDORA_X86_64_BUILD_TAG
-# KERNEL_ROOTFS_TAG
 
 export LIBWAYLAND_VERSION="1.21.0"
 export WAYLAND_PROTOCOLS_VERSION="1.41"
diff --git a/.gitlab-ci/container/container_pre_build.sh b/.gitlab-ci/container/container_pre_build.sh
index b4b36a93acd..7c5ac6a36c7 100755
--- a/.gitlab-ci/container/container_pre_build.sh
+++ b/.gitlab-ci/container/container_pre_build.sh
@@ -38,14 +38,6 @@ chmod +x /usr/local/bin/ninja
 # flags (doesn't apply to non-container builds, but we don't run make there)
 export MAKEFLAGS="-j${FDO_CI_CONCURRENT:-4}"
 
-# make wget to try more than once, when download fails or timeout
-echo -e "retry_connrefused = on\n" \
-        "read_timeout = 300\n" \
-        "tries = 4\n" \
-	"retry_on_host_error = on\n" \
-	"retry_on_http_error = 429,500,502,503,504\n" \
-        "wait_retry = 32" >> /etc/wgetrc
-
 # Ensure that rust tools are in PATH if they exist
 CARGO_ENV_FILE="$HOME/.cargo/env"
 if [ -f "$CARGO_ENV_FILE" ]; then
diff --git a/.gitlab-ci/container/debian/arm64_build.sh b/.gitlab-ci/container/debian/arm64_build.sh
index e3cf5351ca6..9450fd0683e 100644
--- a/.gitlab-ci/container/debian/arm64_build.sh
+++ b/.gitlab-ci/container/debian/arm64_build.sh
@@ -86,7 +86,8 @@ apt-get update
 
 apt-get -y install "${DEPS[@]}" "${EPHEMERAL[@]}"
 
-pip3 install --break-system-packages git+http://gitlab.freedesktop.org/freedesktop/ci-templates@ffe4d1b10aab7534489f0c4bbc4c5899df17d3f2
+# Needed for ci-fairy s3cp
+pip3 install --break-system-packages "ci-fairy[s3] @ git+https://gitlab.freedesktop.org/freedesktop/ci-templates@$MESA_TEMPLATES_COMMIT"
 
 arch=armhf
 . .gitlab-ci/container/cross_build.sh
diff --git a/.gitlab-ci/container/debian/baremetal_arm32_test.sh b/.gitlab-ci/container/debian/baremetal_arm32_test-gl.sh
similarity index 100%
rename from .gitlab-ci/container/debian/baremetal_arm32_test.sh
rename to .gitlab-ci/container/debian/baremetal_arm32_test-gl.sh
diff --git a/.gitlab-ci/container/debian/baremetal_arm64_test.sh b/.gitlab-ci/container/debian/baremetal_arm64_test-gl.sh
similarity index 100%
rename from .gitlab-ci/container/debian/baremetal_arm64_test.sh
rename to .gitlab-ci/container/debian/baremetal_arm64_test-gl.sh
diff --git a/.gitlab-ci/container/debian/baremetal_arm64_test-vk.sh b/.gitlab-ci/container/debian/baremetal_arm64_test-vk.sh
new file mode 100644
index 00000000000..7ae813999ee
--- /dev/null
+++ b/.gitlab-ci/container/debian/baremetal_arm64_test-vk.sh
@@ -0,0 +1,5 @@
+#!/usr/bin/env bash
+
+set -e
+
+arch=arm64 . .gitlab-ci/container/debian/baremetal_arm_test.sh
diff --git a/.gitlab-ci/container/debian/baremetal_arm_test.sh b/.gitlab-ci/container/debian/baremetal_arm_test.sh
index 3849dd52404..70d9fd8aea7 100644
--- a/.gitlab-ci/container/debian/baremetal_arm_test.sh
+++ b/.gitlab-ci/container/debian/baremetal_arm_test.sh
@@ -3,7 +3,6 @@
 # When changing this file, you need to bump the following
 # .gitlab-ci/image-tags.yml tags:
 # DEBIAN_BASE_TAG
-# KERNEL_ROOTFS_TAG
 
 set -e
 
@@ -42,15 +41,3 @@ curl -L --retry 4 -f --retry-all-errors --retry-delay 60 \
     -o /usr/share/snmp/mibs/SNMPv2-SMI.txt
 
 . .gitlab-ci/container/baremetal_build.sh
-
-mkdir -p /baremetal-files/jetson-nano/boot/
-ln -s \
-    /baremetal-files/Image \
-    /baremetal-files/tegra210-p3450-0000.dtb \
-    /baremetal-files/jetson-nano/boot/
-
-mkdir -p /baremetal-files/jetson-tk1/boot/
-ln -s \
-    /baremetal-files/zImage \
-    /baremetal-files/tegra124-jetson-tk1.dtb \
-    /baremetal-files/jetson-tk1/boot/
diff --git a/.gitlab-ci/container/debian/test-base.sh b/.gitlab-ci/container/debian/test-base.sh
index 52b54546322..4998eb4d735 100644
--- a/.gitlab-ci/container/debian/test-base.sh
+++ b/.gitlab-ci/container/debian/test-base.sh
@@ -21,6 +21,8 @@ sed -i -e 's/http:\/\/deb/https:\/\/deb/g' /etc/apt/sources.list.d/*
 
 echo "deb [trusted=yes] https://gitlab.freedesktop.org/gfx-ci/ci-deb-repo/-/raw/${PKG_REPO_REV}/ ${FDO_DISTRIBUTION_VERSION%-*} main" | tee /etc/apt/sources.list.d/gfx-ci_.list
 
+echo "deb [signed-by=/usr/share/keyrings/debian-archive-keyring.gpg] https://deb.debian.org/debian ${FDO_DISTRIBUTION_VERSION%-*} non-free-firmware" | tee /etc/apt/sources.list.d/non-free-firmware.list
+
 : "${LLVM_VERSION:?llvm version not set!}"
 
 . .gitlab-ci/container/debian/maybe-add-llvm-repo.sh
@@ -71,13 +73,13 @@ EPHEMERAL=(
     "llvm-${LLVM_VERSION}-dev"
     make
     meson
-    openssh-server
     patch
     pkgconf
     protobuf-compiler
     python3-dev
     python3-pip
     python3-setuptools
+    python3-venv
     python3-wheel
     wayland-protocols
     xz-utils
@@ -87,6 +89,7 @@ DEPS=(
     apt-utils
     clinfo
     curl
+    dropbear
     git
     git-lfs
     inetutils-syslogd
@@ -129,6 +132,7 @@ DEPS=(
     python3-simplejson
     python3-six
     python3-yaml
+    sntp
     socat
     spirv-tools
     sysvinit-core
@@ -142,34 +146,58 @@ DEPS=(
     xauth
     xvfb
     zlib1g
+)
+
+HW_DEPS=(
+    firmware-realtek
+    netcat-openbsd
+    mount
+    python3-distutils
+    python3-serial
+    tzdata
     zstd
 )
 
+[ "$DEBIAN_ARCH" = "arm64" ] && ARCH_DEPS=(
+    firmware-linux-nonfree
+    firmware-qcom-media
+)
+[ "$DEBIAN_ARCH" = "armhf" ] && ARCH_DEPS=(
+    firmware-misc-nonfree
+)
+[ "$DEBIAN_ARCH" = "amd64" ] && ARCH_DEPS=(
+    firmware-amd-graphics
+    firmware-misc-nonfree
+)
+
 apt-get update
 apt-get dist-upgrade -y
 
 apt-get install --purge -y \
       sysvinit-core libelogind0
 
-apt-get install -y --no-remove "${DEPS[@]}"
+apt-get install -y --no-remove "${DEPS[@]}" "${HW_DEPS[@]}" "${ARCH_DEPS[@]}"
 
 apt-get install -y --no-install-recommends "${EPHEMERAL[@]}"
 
 . .gitlab-ci/container/container_pre_build.sh
 
-# Needed for ci-fairy, this revision is able to upload files to MinIO
-# and doesn't depend on git
-pip3 install --break-system-packages git+http://gitlab.freedesktop.org/freedesktop/ci-templates@ffe4d1b10aab7534489f0c4bbc4c5899df17d3f2
+# Needed for ci-fairy s3cp
+pip3 install --break-system-packages "ci-fairy[s3] @ git+https://gitlab.freedesktop.org/freedesktop/ci-templates@$MESA_TEMPLATES_COMMIT"
 
 # Needed for manipulation with traces yaml files.
 pip3 install --break-system-packages yq
 
 section_end debian_setup
 
-############### Download prebuilt kernel
+############### Build ci-kdl
+
+. .gitlab-ci/container/build-kdl.sh
+
+############### Download prebuilt kernel and firmware
 
 if [ "$DEBIAN_ARCH" = amd64 ]; then
-  uncollapsed_section_start kernel "Downloading kernel for crosvm"
+  uncollapsed_section_start kernel "Downloading kernel and firmware"
   export KERNEL_IMAGE_NAME=bzImage
   mkdir -p /kernel
   # shellcheck disable=SC2153 # KERNEL_IMAGE_BASE is set in the root .gitlab-ci.yml file
@@ -177,6 +205,7 @@ if [ "$DEBIAN_ARCH" = amd64 ]; then
       -o "/kernel/${KERNEL_IMAGE_NAME}" "${KERNEL_IMAGE_BASE}/${DEBIAN_ARCH}/${KERNEL_IMAGE_NAME}"
   section_end kernel
 fi
+. .gitlab-ci/container/get-firmware-from-source.sh / "$FIRMWARE_FILES"
 
 ############### Build mold
 
diff --git a/.gitlab-ci/container/debian/test-gl.sh b/.gitlab-ci/container/debian/test-gl.sh
index d1cbef720be..8bda2279c66 100644
--- a/.gitlab-ci/container/debian/test-gl.sh
+++ b/.gitlab-ci/container/debian/test-gl.sh
@@ -27,12 +27,15 @@ EPHEMERAL=(
     libcap-dev
     "libclang-cpp${LLVM_VERSION}-dev"
     libdrm-dev
+    libfontconfig-dev
+    libgl-dev
     libgles2-mesa-dev
+    libglu1-mesa-dev
     libgtest-dev
+    libglx-dev
     libpciaccess-dev
     libpng-dev
     libudev-dev
-    libvulkan-dev
     libwaffle-dev
     libwayland-dev
     libx11-xcb-dev
@@ -50,11 +53,15 @@ EPHEMERAL=(
     ocl-icd-opencl-dev
     patch
     pkgconf
+    python-is-python3
     python3-distutils
     xz-utils
 )
 
 DEPS=(
+    libfontconfig1
+    libglu1-mesa
+    libvulkan-dev
 )
 
 apt-get update
@@ -69,7 +76,7 @@ section_end debian_setup
 
 ############### Build ANGLE
 
-if [ "$DEBIAN_ARCH" == "arm64" ]; then
+if [ "$DEBIAN_ARCH" != "armhf" ]; then
   ANGLE_TARGET=linux \
   . .gitlab-ci/container/build-angle.sh
 fi
@@ -112,6 +119,13 @@ rm -rf /VK-GL-CTS
 
 . .gitlab-ci/container/build-vulkan-validation.sh
 
+
+############### Build SKQP
+
+if [ "$DEBIAN_ARCH" != "armhf" ]; then
+  . .gitlab-ci/container/build-skqp.sh
+fi
+
 ############### Build nine tests
 
 . .gitlab-ci/container/build-ninetests.sh
diff --git a/.gitlab-ci/container/debian/x86_64_build-base.sh b/.gitlab-ci/container/debian/x86_64_build-base.sh
index a7fcc8184f7..b54d5f4c23c 100644
--- a/.gitlab-ci/container/debian/x86_64_build-base.sh
+++ b/.gitlab-ci/container/debian/x86_64_build-base.sh
@@ -99,8 +99,8 @@ apt-get install -y --no-remove "${DEPS[@]}" "${EPHEMERAL[@]}" \
 
 . .gitlab-ci/container/build-libclc.sh
 
-# Needed for ci-fairy, this revision is able to upload files to S3
-pip3 install --break-system-packages git+http://gitlab.freedesktop.org/freedesktop/ci-templates@ffe4d1b10aab7534489f0c4bbc4c5899df17d3f2
+# Needed for ci-fairy s3cp
+pip3 install --break-system-packages "ci-fairy[s3] @ git+https://gitlab.freedesktop.org/freedesktop/ci-templates@$MESA_TEMPLATES_COMMIT"
 
 . .gitlab-ci/container/install-meson.sh
 
diff --git a/.gitlab-ci/container/debian/x86_64_pyutils.sh b/.gitlab-ci/container/debian/x86_64_pyutils.sh
index b940e4e2e28..ca35251fc08 100644
--- a/.gitlab-ci/container/debian/x86_64_pyutils.sh
+++ b/.gitlab-ci/container/debian/x86_64_pyutils.sh
@@ -54,8 +54,8 @@ apt-get update
 apt-get install -y --no-remove --no-install-recommends "${DEPS[@]}" "${EPHEMERAL[@]}" \
         "${EXTRA_LOCAL_PACKAGES:-}"
 
-# Needed for ci-fairy, this revision is able to upload files to S3
-pip3 install --break-system-packages git+http://gitlab.freedesktop.org/freedesktop/ci-templates@ffe4d1b10aab7534489f0c4bbc4c5899df17d3f2
+# Needed for ci-fairy s3cp
+pip3 install --break-system-packages "ci-fairy[s3] @ git+https://gitlab.freedesktop.org/freedesktop/ci-templates@$MESA_TEMPLATES_COMMIT"
 
 pip3 install --break-system-packages -r bin/ci/test/requirements.txt
 
diff --git a/.gitlab-ci/container/debian/x86_64_test-android.sh b/.gitlab-ci/container/debian/x86_64_test-android.sh
index 78752f35013..d474d32fabe 100755
--- a/.gitlab-ci/container/debian/x86_64_test-android.sh
+++ b/.gitlab-ci/container/debian/x86_64_test-android.sh
@@ -12,22 +12,25 @@ set -e
 
 set -o xtrace
 
+section_start debian_setup "Base Debian system setup"
+
 export DEBIAN_FRONTEND=noninteractive
 
 # Ephemeral packages (installed for this script and removed again at the end)
 EPHEMERAL=(
-   build-essential:native
-   ccache
-   cmake
-   config-package-dev
-   debhelper-compat
-   dpkg-dev
-   ninja-build
-   sudo
-   unzip
+    build-essential:native
+    ccache
+    cmake
+    config-package-dev
+    debhelper-compat
+    dpkg-dev
+    ninja-build
+    sudo
+    unzip
 )
 
 DEPS=(
+    aapt
     iproute2
 )
 apt-get install -y --no-remove --no-install-recommends \
@@ -37,15 +40,21 @@ apt-get install -y --no-remove --no-install-recommends \
 
 . .gitlab-ci/container/container_pre_build.sh
 
+section_end debian_setup
+
 ############### Downloading NDK for native builds for the guest ...
 
+section_start android-ndk "Downloading Android NDK"
+
 # Fetch the NDK and extract just the toolchain we want.
 ndk="android-ndk-${ANDROID_NDK_VERSION}"
 curl -L --retry 4 -f --retry-all-errors --retry-delay 60 \
   -o "$ndk.zip" "https://dl.google.com/android/repository/$ndk-linux.zip"
-unzip -d / "$ndk.zip"
+unzip -q -d / "$ndk.zip"
 rm "$ndk.zip"
 
+section_end android-ndk
+
 ############### Build ANGLE
 
 ANGLE_TARGET=android \
@@ -83,7 +92,7 @@ rm -rf /VK-GL-CTS
 
 ############### Downloading Cuttlefish resources ...
 
-uncollapsed_section_start cuttlefish "Downloading, building and installing Cuttlefish"
+section_start cuttlefish "Downloading, building and installing Cuttlefish"
 
 CUTTLEFISH_PROJECT_PATH=ao2/aosp-manifest
 CUTTLEFISH_BUILD_VERSION_TAGS=mesa-venus
@@ -138,40 +147,29 @@ usermod -a -G kvm,cvdnetwork root
 
 section_end cuttlefish
 
-############### Downloading Android CTS tools
+############### Downloading Android CTS
 
-uncollapsed_section_start android-cts "Downloading Android CTS tools"
+section_start android-cts "Downloading Android CTS"
 
 ANDROID_CTS_VERSION="${ANDROID_VERSION}_r1"
 ANDROID_CTS_DEVICE_ARCH="x86"
 
-mkdir /android-tools
-pushd /android-tools
-
 curl -L --retry 4 -f --retry-all-errors --retry-delay 60 \
   -o "android-cts-${ANDROID_CTS_VERSION}-linux_x86-${ANDROID_CTS_DEVICE_ARCH}.zip" \
   "https://dl.google.com/dl/android/cts/android-cts-${ANDROID_CTS_VERSION}-linux_x86-${ANDROID_CTS_DEVICE_ARCH}.zip"
-unzip "android-cts-${ANDROID_CTS_VERSION}-linux_x86-${ANDROID_CTS_DEVICE_ARCH}.zip"
+unzip -q -d / "android-cts-${ANDROID_CTS_VERSION}-linux_x86-${ANDROID_CTS_DEVICE_ARCH}.zip"
 rm "android-cts-${ANDROID_CTS_VERSION}-linux_x86-${ANDROID_CTS_DEVICE_ARCH}.zip"
 
 # Keep only the interesting tests to save space
 # shellcheck disable=SC2086 # we want word splitting
 ANDROID_CTS_MODULES_KEEP_EXPRESSION=$(printf "%s|" $ANDROID_CTS_MODULES | sed -e 's/|$//g')
-find android-cts/testcases/ -mindepth 1 -type d | grep -v -E "$ANDROID_CTS_MODULES_KEEP_EXPRESSION" | xargs rm -rf
-
-curl -L --retry 4 -f --retry-all-errors --retry-delay 60 \
-  -o "build-tools_r${ANDROID_SDK_VERSION}-linux.zip" "https://dl.google.com/android/repository/build-tools_r${ANDROID_SDK_VERSION}-linux.zip"
-unzip "build-tools_r${ANDROID_SDK_VERSION}-linux.zip"
-rm "build-tools_r${ANDROID_SDK_VERSION}-linux.zip"
-mv "android-$ANDROID_VERSION" build-tools
-
-popd
+find /android-cts/testcases/ -mindepth 1 -type d | grep -v -E "$ANDROID_CTS_MODULES_KEEP_EXPRESSION" | xargs rm -rf
 
 section_end android-cts
 
 ############### Uninstall the build software
 
-uncollapsed_section_switch debian_cleanup "Cleaning up base Debian system"
+section_switch debian_cleanup "Cleaning up base Debian system"
 
 rm -rf "/${ndk:?}"
 
diff --git a/.gitlab-ci/container/debian/x86_64_test-video.sh b/.gitlab-ci/container/debian/x86_64_test-video.sh
new file mode 100755
index 00000000000..5877ec1aa74
--- /dev/null
+++ b/.gitlab-ci/container/debian/x86_64_test-video.sh
@@ -0,0 +1,71 @@
+#!/usr/bin/env bash
+# The relative paths in this file only become valid at runtime.
+# shellcheck disable=SC1091
+#
+# When changing this file, you need to bump the following
+# .gitlab-ci/image-tags.yml tags:
+# DEBIAN_TEST_VIDEO_TAG
+
+set -e
+
+. .gitlab-ci/setup-test-env.sh
+
+set -o xtrace
+
+section_start debian_setup "Base Debian system setup"
+
+export DEBIAN_FRONTEND=noninteractive
+
+apt-get install -y gstreamer1.0-vaapi  # This interferes with systemd deps, install separately
+
+# Ephemeral packages (installed for this script and removed again at the end)
+EPHEMERAL=(
+    g++
+    libdrm-dev
+    libva-dev
+    meson
+    pkgconf
+)
+
+DEPS=(
+    gstreamer1.0-plugins-bad
+    gstreamer1.0-plugins-base
+    gstreamer1.0-plugins-good
+    gstreamer1.0-plugins-ugly
+    gstreamer1.0-tools
+    libgstreamer1.0-0
+    libva-drm2
+    libva-wayland2
+    libva2
+)
+
+apt-get update
+
+apt-get install -y --no-remove --no-install-recommends \
+      "${DEPS[@]}" "${EPHEMERAL[@]}" "${EXTRA_LOCAL_PACKAGES:-}"
+
+. .gitlab-ci/container/container_pre_build.sh
+
+section_end debian_setup
+
+############### Build libva tests
+
+. .gitlab-ci/container/build-va-tools.sh
+
+############### Install Fluster
+
+. .gitlab-ci/container/build-fluster.sh
+
+############### Uninstall the build software
+
+section_switch debian_cleanup "Cleaning up base Debian system"
+
+apt-get purge -y "${EPHEMERAL[@]}"
+
+. .gitlab-ci/container/container_post_build.sh
+
+section_end debian_cleanup
+
+############### Remove unused packages
+
+. .gitlab-ci/container/strip-rootfs.sh
diff --git a/.gitlab-ci/container/fdo_cntr_export.sh b/.gitlab-ci/container/fdo_cntr_export.sh
new file mode 100644
index 00000000000..7cb3ff4fec9
--- /dev/null
+++ b/.gitlab-ci/container/fdo_cntr_export.sh
@@ -0,0 +1,73 @@
+#!/usr/bin/env bash
+
+# This script exports the container image to a rootfs tarball and uploads it to
+# S3.
+#
+# Usage:
+#
+#   ./fdo_cntr_export.sh <container-image-url>
+#
+# The container image URL is the URL of the container image to export. It can be
+# a local path or a remote URL.
+
+# Example:
+# ./fdo_cntr_export.sh registry.freedesktop.org/mesa/mesa/debian/x86_64_test-android:tag
+
+# When changing this file, you need to bump the following
+# .gitlab-ci/image-tags.yml tags:
+# DEBIAN_TEST_GL_TAG
+# DEBIAN_TEST_VIDEO_TAG
+# DEBIAN_TEST_VK_TAG
+
+set -eux -o pipefail
+
+: "${CONTAINER:=$1}"
+IMAGE_URL="${CONTAINER}"
+readonly IMAGE_URL
+
+container=$(buildah from "$IMAGE_URL")
+readonly container
+readonly ROOTFSTAR=lava-rootfs.tar.zst
+touch "$ROOTFSTAR"
+
+buildah copy "$container" ".gitlab-ci/container/setup-rootfs.sh" /root/setup-rootfs.sh
+
+# Using --isolation chroot to ensure proper execution in CI/CD environments
+buildah run --isolation chroot "$container" -- /root/setup-rootfs.sh
+
+buildah_export() {
+    # Mount the volume
+    mountpoint=$(buildah mount "$1")
+
+    if [ ! -d "$mountpoint" ]; then
+        echo "Mount point not found: $mountpoint" >/dev/stderr
+        exit 1
+    fi
+
+    # Compress to zstd
+    ZSTD_CLEVEL=10 tar -C "$mountpoint" -I zstd -cf "$2" .
+}
+
+# When hacking on it locally, the script might not be executed as root.
+# In CI it's always root.
+if (($(id -u) != 0)); then
+    # Run unshare for rootless envs
+    buildah unshare -- bash -c "$(declare -f buildah_export); buildah_export '$container' '$ROOTFSTAR'"
+else
+    # Run directly
+    buildah_export "$container" "$ROOTFSTAR"
+fi
+
+# Unmount the container
+buildah umount "$container"
+
+# Remove the container
+buildah rm "$container"
+
+# Upload the rootfs tarball to S3.
+# The URL format matches the registry format, and LAVA_DISTRIBUTION_TAG is
+# used later to match this URL.
+curl --fail --retry-connrefused --retry 4 --retry-delay 30 \
+  --header "Authorization: Bearer $(cat "${S3_JWT_FILE}")" \
+  -X PUT --form file=@"$ROOTFSTAR" \
+  "https://${S3_HOST}/${S3_KERNEL_BUCKET}/${CI_PROJECT_PATH}/${CI_JOB_NAME}:${FDO_DISTRIBUTION_TAG}"
diff --git a/.gitlab-ci/container/gitlab-ci.yml b/.gitlab-ci/container/gitlab-ci.yml
index e8f4fdb30b2..92b5482b954 100644
--- a/.gitlab-ci/container/gitlab-ci.yml
+++ b/.gitlab-ci/container/gitlab-ci.yml
@@ -78,17 +78,35 @@
     # should make CI_BUILD_COMPONENTS="angle piglit"
     CI_BUILD_COMPONENTS: "angle"
 
+.container-builds-piglit:
+  variables:
+    PIGLIT_TAG: "${CONDITIONAL_BUILD_PIGLIT_TAG}"
+
 .container-builds-x86_64:
   extends:
     - .container-builds-angle
+    - .container-builds-piglit
   variables:
-    CI_BUILD_COMPONENTS: "angle"
+    CI_BUILD_COMPONENTS: "angle piglit"
+
+.container-builds-arm32:
+  extends:
+    - .container-builds-piglit
+  variables:
+    CI_BUILD_COMPONENTS: "piglit"
 
 .container-builds-arm64:
   extends:
     - .container-builds-angle
+    - .container-builds-piglit
   variables:
-    CI_BUILD_COMPONENTS: "angle"
+    CI_BUILD_COMPONENTS: "angle piglit"
+
+# Export the container rootfs and upload it to S3
+.export-container:
+  variables:
+    FDO_DISTRIBUTION_PACKAGES: zstd
+    FDO_DISTRIBUTION_POST_EXEC: 'bash .gitlab-ci/container/fdo_cntr_export.sh'
 
 .use-base-image:
   extends:
@@ -113,7 +131,6 @@ debian/x86_64_build-base:
   variables:
     MESA_BASE_IMAGE: "debian/x86_64_build-base"
     MESA_BASE_TAG: *debian-x86_64_build-base
-    MESA_ARTIFACTS_BASE_TAG: *debian-x86_64_build-base
     LLVM_VERSION: *debian-x86_64-llvm
   needs:
     - debian/x86_64_build-base
@@ -203,14 +220,15 @@ debian/s390x_build:
 
 # Android NDK cross-build image
 .android-variables:
-  extends:
-    - .container-builds-android
   variables:
     ANDROID_VERSION: 14
     ANDROID_NDK_VERSION: "r27c"
     ANDROID_SDK_VERSION: 34
     # Space-separated list of interesting CTS modules
-    ANDROID_CTS_MODULES: CtsGraphicsTestCases
+    ANDROID_CTS_MODULES: >-
+      CtsGraphicsTestCases
+      CtsNativeHardwareTestCases
+      CtsSkQPTestCases
     ANDROID_LLVM_VERSION: llvmorg-19.1.7
     ANDROID_LLVM_ARTIFACT_NAME: android-x86_64-llvm-20250324
     # This can be confusing: LLVM_VERSION refers to the host LLVM toolchain
@@ -221,7 +239,6 @@ debian/s390x_build:
 debian/android_build:
   extends:
     - .android-variables
-    - .container-builds-android
     - .use-debian/x86_64_build-base
   variables:
     MESA_IMAGE_TAG: &debian-android_build ${DEBIAN_BUILD_TAG}
@@ -314,9 +331,9 @@ fedora/x86_64_build:
     - .fdo.container-build@fedora
     - .container
   variables:
-    FDO_DISTRIBUTION_VERSION: 41
+    FDO_DISTRIBUTION_VERSION: 42
     MESA_IMAGE_TAG: &fedora-x86_64_build ${FEDORA_X86_64_BUILD_TAG}
-    LLVM_VERSION: &fedora-x86_64-llvm 19
+    LLVM_VERSION: &fedora-x86_64-llvm 20
 
 .use-fedora/x86_64_build:
   tags:
@@ -334,6 +351,7 @@ fedora/x86_64_build:
 debian/x86_64_test-base:
   extends:
     - .debian-container
+    - .firmware_x86_64
   variables:
     MESA_IMAGE_TAG: &debian-x86_64_test-base "${DEBIAN_BASE_TAG}--${PKG_REPO_REV}--${KERNEL_TAG}"
     LLVM_VERSION: *debian-x86_64-llvm
@@ -385,6 +403,7 @@ debian/arm64_test-base:
     - $FDO_RUNNER_JOB_PRIORITY_TAG_AARCH64
   extends:
     - .debian-container
+    - .firmware_arm64
   variables:
     MESA_IMAGE_TAG: &debian-arm64_test-base "${DEBIAN_BASE_TAG}--${PKG_REPO_REV}"
     LLVM_VERSION: *debian-arm64-llvm
@@ -405,9 +424,13 @@ debian/arm64_test-base:
 
 # Debian based x86_64 test image for GL
 debian/x86_64_test-gl:
-  extends: .use-debian/x86_64_test-base
+  extends:
+    - .use-debian/x86_64_test-base
+    - .container-builds-x86_64
+    - .export-container
   variables:
     MESA_IMAGE_TAG: &debian-x86_64_test-gl ${DEBIAN_TEST_GL_TAG}
+    LAVA_DISTRIBUTION_TAG: "debian/x86_64_test-gl:${DEBIAN_TEST_GL_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
 
 .use-debian/x86_64_test-gl:
   tags:
@@ -423,9 +446,13 @@ debian/x86_64_test-gl:
 
 # Debian based x86_64 test image for VK
 debian/x86_64_test-vk:
-  extends: .use-debian/x86_64_test-base
+  extends:
+    - .use-debian/x86_64_test-base
+    - .container-builds-x86_64
+    - .export-container
   variables:
     MESA_IMAGE_TAG: &debian-x86_64_test-vk ${DEBIAN_TEST_VK_TAG}
+    LAVA_DISTRIBUTION_TAG: "debian/x86_64_test-vk:${DEBIAN_TEST_VK_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
 
 .use-debian/x86_64_test-vk:
   tags:
@@ -444,6 +471,7 @@ debian/x86_64_test-android:
   extends:
     - .android-variables
     - .use-debian/x86_64_test-base
+    - .container-builds-android
   variables:
     MESA_IMAGE_TAG: &debian-x86_64_test-android ${DEBIAN_TEST_ANDROID_TAG}
 
@@ -460,6 +488,27 @@ debian/x86_64_test-android:
   needs:
     - debian/x86_64_test-android
 
+# Debian based x86_64 test image for video
+debian/x86_64_test-video:
+  extends:
+    - .use-debian/x86_64_test-base
+    - .export-container
+  variables:
+    MESA_IMAGE_TAG: &debian-x86_64_test-video ${DEBIAN_TEST_VIDEO_TAG}
+    LAVA_DISTRIBUTION_TAG: "debian/x86_64_test-video:${DEBIAN_TEST_VIDEO_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
+
+.use-debian/x86_64_test-video:
+  tags:
+    - $FDO_RUNNER_JOB_PRIORITY_TAG_X86_64
+  extends:
+    - .set-image-base-tag
+  variables:
+    MESA_BASE_TAG: *debian-x86_64_test-base
+    MESA_IMAGE_PATH: "debian/x86_64_test-video"
+    MESA_IMAGE_TAG: *debian-x86_64_test-video
+  needs:
+    - debian/x86_64_test-video
+
 # Debian-based x86_64 image to run Python utilities
 debian/x86_64_pyutils:
   extends:
@@ -484,9 +533,13 @@ debian/x86_64_pyutils:
 debian/arm32_test-gl:
   tags:
     - $FDO_RUNNER_JOB_PRIORITY_TAG_AARCH64
-  extends: .use-debian/arm32_test-base
+  extends:
+    - .use-debian/arm32_test-base
+    - .container-builds-arm32
+    - .export-container
   variables:
     MESA_IMAGE_TAG: &debian-arm32_test-gl ${DEBIAN_TEST_GL_TAG}
+    LAVA_DISTRIBUTION_TAG: "debian/arm32_test-gl:${DEBIAN_TEST_GL_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}--${MESA_TEMPLATES_COMMIT}"
 
 .use-debian/arm32_test-gl:
   tags:
@@ -506,7 +559,9 @@ debian/arm32_test-vk:
     - when: never # There are currently no arm32 VK jobs
   tags:
     - $FDO_RUNNER_JOB_PRIORITY_TAG_AARCH64
-  extends: .use-debian/arm32_test-base
+  extends:
+    - .use-debian/arm32_test-base
+    - .container-builds-arm32
   variables:
     MESA_IMAGE_TAG: &debian-arm32_test-vk ${DEBIAN_TEST_VK_TAG}
 
@@ -529,8 +584,10 @@ debian/arm64_test-gl:
   extends:
     - .use-debian/arm64_test-base
     - .container-builds-arm64
+    - .export-container
   variables:
     MESA_IMAGE_TAG: &debian-arm64_test-gl ${DEBIAN_TEST_GL_TAG}
+    LAVA_DISTRIBUTION_TAG: "debian/arm64_test-gl:${DEBIAN_TEST_GL_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}--${MESA_TEMPLATES_COMMIT}"
 
 .use-debian/arm64_test-gl:
   tags:
@@ -548,9 +605,13 @@ debian/arm64_test-gl:
 debian/arm64_test-vk:
   tags:
     - $FDO_RUNNER_JOB_PRIORITY_TAG_AARCH64
-  extends: .use-debian/arm64_test-base
+  extends:
+    - .use-debian/arm64_test-base
+    - .container-builds-arm64
+    - .export-container
   variables:
     MESA_IMAGE_TAG: &debian-arm64_test-vk ${DEBIAN_TEST_VK_TAG}
+    LAVA_DISTRIBUTION_TAG: "debian/arm64_test-vk:${DEBIAN_TEST_VK_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}--${MESA_TEMPLATES_COMMIT}"
 
 .use-debian/arm64_test-vk:
   tags:
@@ -565,7 +626,7 @@ debian/arm64_test-vk:
     - debian/arm64_test-vk
 
 # Get firmware directly rather than using package versions.
-# Change KERNEL_ROOTFS_TAG to add firmware changes.
+# Change DEBIAN_BASE_TAG to add firmware changes.
 # FIRMWARE_FILES is a list of json files arranged by vendor in .gitlab-ci/firmware/*
 .firmware_x86_64:
   variables:
@@ -582,60 +643,6 @@ debian/arm64_test-vk:
   variables:
     FIRMWARE_FILES: |
 
-.kernel+rootfs:
-  extends:
-    - .container+build-rules
-    - .debian-container-version
-  stage: container
-  timeout: 120m
-  variables:
-    GIT_STRATEGY: fetch
-    MESA_ROOTFS_TAG: &kernel-rootfs ${KERNEL_ROOTFS_TAG}
-    DISTRIBUTION_TAG: &distribution-tag-arm "${MESA_ROOTFS_TAG}--${KERNEL_TAG}--${MESA_ARTIFACTS_TAG}--${MESA_TEMPLATES_COMMIT}"
-  script:
-    - .gitlab-ci/container/lava_build.sh
-
-kernel+rootfs_x86_64:
-  extends:
-    - .use-debian/x86_64_build-base
-    - .kernel+rootfs
-    - .firmware_x86_64
-    - .container-builds-x86_64
-  image: "$FDO_BASE_IMAGE"
-  variables:
-    DEBIAN_ARCH: "amd64"
-    DISTRIBUTION_TAG: &distribution-tag-x86_64 "${MESA_ROOTFS_TAG}--${KERNEL_TAG}--${MESA_ARTIFACTS_BASE_TAG}--${MESA_TEMPLATES_COMMIT}"
-    LLVM_VERSION: *debian-x86_64-llvm
-
-kernel+rootfs_arm64:
-  extends:
-    - .use-debian/arm64_build
-    - .kernel+rootfs
-    - .firmware_arm64
-    - .container-builds-arm64
-  variables:
-    DEBIAN_ARCH: "arm64"
-    LLVM_VERSION: *debian-arm64-llvm
-
-kernel+rootfs_arm32:
-  extends:
-    - kernel+rootfs_arm64
-    - .firmware_arm32
-  variables:
-    DEBIAN_ARCH: "armhf"
-    LLVM_VERSION: &debian-arm32-llvm 15 # no armhf builds for LLVM
-
-# Cannot use anchors defined here from included files, so use extends: instead
-.use-kernel+rootfs-arm:
-  variables:
-    DISTRIBUTION_TAG: *distribution-tag-arm
-    MESA_ROOTFS_TAG: *kernel-rootfs
-
-.use-kernel+rootfs-x86_64:
-  variables:
-    DISTRIBUTION_TAG: *distribution-tag-x86_64
-    MESA_ROOTFS_TAG: *kernel-rootfs
-
 # x86_64 image with ARM64 & ARM32 kernel & rootfs for baremetal testing
 .debian/baremetal_arm_test:
   extends:
@@ -645,49 +652,57 @@ kernel+rootfs_arm32:
     # Don't want the .container rules
     - .container+build-rules
   variables:
-    FDO_DISTRIBUTION_TAG: "${MESA_IMAGE_TAG}--${MESA_ROOTFS_TAG}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
-    ARTIFACTS_PREFIX: "https://${S3_HOST}/${S3_KERNEL_BUCKET}"
-    ARTIFACTS_SUFFIX: "${MESA_ROOTFS_TAG}--${KERNEL_TAG}--${MESA_ARTIFACTS_TAG}--${MESA_TEMPLATES_COMMIT}"
+    FDO_DISTRIBUTION_TAG: "${MESA_IMAGE_TAG}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
     MESA_ARTIFACTS_TAG: *debian-arm64_build
-    MESA_ROOTFS_TAG: *kernel-rootfs
 
-debian/baremetal_arm32_test:
+debian/baremetal_arm32_test-gl:
   extends:
     - .debian/baremetal_arm_test
   needs:
-    - kernel+rootfs_arm32
+    - debian/arm32_test-gl
   variables:
-    MESA_IMAGE_TAG: &debian-arm32_test "${DEBIAN_BASE_TAG}--${PKG_REPO_REV}"
+    MESA_IMAGE_TAG: &baremetal-arm32_test-gl "${DEBIAN_TEST_GL_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}"
+    LAVA_DISTRIBUTION_TAG: !reference [debian/arm32_test-gl, variables, LAVA_DISTRIBUTION_TAG]
 
-debian/baremetal_arm64_test:
+debian/baremetal_arm64_test-gl:
   extends:
     - .debian/baremetal_arm_test
   needs:
-    - kernel+rootfs_arm64
+    - debian/arm64_test-gl
   variables:
-    MESA_IMAGE_TAG: &debian-arm64_test "${DEBIAN_BASE_TAG}--${PKG_REPO_REV}"
+    MESA_IMAGE_TAG: &baremetal-arm64_test-gl "${DEBIAN_TEST_GL_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}"
+    LAVA_DISTRIBUTION_TAG: !reference [debian/arm64_test-gl, variables, LAVA_DISTRIBUTION_TAG]
 
-.use-debian/baremetal_arm_test:
+debian/baremetal_arm64_test-vk:
+  extends:
+    - .debian/baremetal_arm_test
+  needs:
+    - debian/arm64_test-vk
   variables:
-    MESA_ROOTFS_TAG: *kernel-rootfs
+    MESA_IMAGE_TAG: &baremetal-arm64_test-vk "${DEBIAN_TEST_VK_TAG}--${DEBIAN_BASE_TAG}--${PKG_REPO_REV}"
+    LAVA_DISTRIBUTION_TAG: !reference [debian/arm64_test-vk, variables, LAVA_DISTRIBUTION_TAG]
 
-.use-debian/baremetal_arm32_test:
-  image: "$CI_REGISTRY_IMAGE/${MESA_IMAGE_PATH}:${MESA_IMAGE_TAG}--${MESA_ROOTFS_TAG}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
-  extends:
-    - .use-debian/baremetal_arm_test
+.use-debian/baremetal_arm32_test-gl:
+  image: "$CI_REGISTRY_IMAGE/${MESA_IMAGE_PATH}:${MESA_IMAGE_TAG}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
   variables:
-    MESA_IMAGE_PATH: "debian/baremetal_arm32_test"
-    MESA_IMAGE_TAG: *debian-arm32_test
+    MESA_IMAGE_PATH: "debian/baremetal_arm32_test-gl"
+    MESA_IMAGE_TAG: *baremetal-arm32_test-gl
   needs:
     - debian/baremetal_arm_test
 
-.use-debian/baremetal_arm64_test:
-  image: "$CI_REGISTRY_IMAGE/${MESA_IMAGE_PATH}:${MESA_IMAGE_TAG}--${MESA_ROOTFS_TAG}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
-  extends:
-    - .use-debian/baremetal_arm_test
+.use-debian/baremetal_arm64_test-gl:
+  image: "$CI_REGISTRY_IMAGE/${MESA_IMAGE_PATH}:${MESA_IMAGE_TAG}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
+  variables:
+    MESA_IMAGE_PATH: "debian/baremetal_arm64_test-gl"
+    MESA_IMAGE_TAG: *baremetal-arm64_test-gl
+  needs:
+    - debian/baremetal_arm_test
+
+.use-debian/baremetal_arm64_test-vk:
+  image: "$CI_REGISTRY_IMAGE/${MESA_IMAGE_PATH}:${MESA_IMAGE_TAG}--${KERNEL_TAG}--${MESA_TEMPLATES_COMMIT}"
   variables:
-    MESA_IMAGE_PATH: "debian/baremetal_arm64_test"
-    MESA_IMAGE_TAG: *debian-arm64_test
+    MESA_IMAGE_PATH: "debian/baremetal_arm64_test-vk"
+    MESA_IMAGE_TAG: *baremetal-arm64_test-vk
   needs:
     - debian/baremetal_arm_test
 
diff --git a/.gitlab-ci/container/lava_build.sh b/.gitlab-ci/container/lava_build.sh
deleted file mode 100755
index d18c06a3536..00000000000
--- a/.gitlab-ci/container/lava_build.sh
+++ /dev/null
@@ -1,428 +0,0 @@
-#!/usr/bin/env bash
-# shellcheck disable=SC1091 # The relative paths in this file only become valid at runtime.
-# shellcheck disable=SC2034 # Variables are used in scripts called from here
-# shellcheck disable=SC2086 # we want word splitting
-# shellcheck disable=SC2016 # non-expanded variables are intentional
-# When changing this file, you need to bump the following
-# .gitlab-ci/image-tags.yml tags:
-# KERNEL_ROOTFS_TAG
-# If you need to update the fluster vectors cache without updating the fluster revision,
-# you can update the FLUSTER_VECTORS_VERSION tag in .gitlab-ci/image-tags.yml.
-# When changing FLUSTER_REVISION, KERNEL_ROOTFS_TAG needs to be updated as well to rebuild
-# the rootfs.
-
-set -e
-
-. .gitlab-ci/setup-test-env.sh
-
-set -o xtrace
-
-export DEBIAN_FRONTEND=noninteractive
-: "${LLVM_VERSION:?llvm version not set!}"
-export FIRMWARE_FILES="${FIRMWARE_FILES}"
-export SKIP_UPDATE_FLUSTER_VECTORS=0
-
-check_minio()
-{
-    S3_PATH="${S3_HOST}/${S3_KERNEL_BUCKET}/$1/${DISTRIBUTION_TAG}/${DEBIAN_ARCH}"
-    if curl -L --retry 4 -f --retry-delay 60 -s \
-      "https://${S3_PATH}/done"; then
-        echo "Remote files are up-to-date, skip rebuilding them."
-        exit
-    fi
-}
-
-check_fluster()
-{
-    S3_PATH_FLUSTER="${S3_HOST}/${S3_KERNEL_BUCKET}/$1/${DATA_STORAGE_PATH}/fluster/${FLUSTER_VECTORS_VERSION}"
-    if curl -L --retry 4 -f --retry-delay 60 -s \
-      "https://${S3_PATH_FLUSTER}/done"; then
-        echo "Fluster vectors are up-to-date, skip downloading them."
-        export SKIP_UPDATE_FLUSTER_VECTORS=1
-    fi
-}
-
-check_minio "${FDO_UPSTREAM_REPO}"
-check_minio "${CI_PROJECT_PATH}"
-
-check_fluster "${FDO_UPSTREAM_REPO}"
-check_fluster "${CI_PROJECT_PATH}"
-
-. .gitlab-ci/container/container_pre_build.sh
-
-# Install rust, which we'll be using for deqp-runner.  It will be cleaned up at the end.
-. .gitlab-ci/container/build-rust.sh
-
-if [[ "$DEBIAN_ARCH" = "arm64" ]]; then
-    BUILD_CL="ON"
-    BUILD_VK="ON"
-    GCC_ARCH="aarch64-linux-gnu"
-    KERNEL_ARCH="arm64"
-
-elif [[ "$DEBIAN_ARCH" = "armhf" ]]; then
-    BUILD_CL="OFF"
-    BUILD_VK="OFF"
-    GCC_ARCH="arm-linux-gnueabihf"
-    KERNEL_ARCH="arm"
-    . .gitlab-ci/container/create-cross-file.sh armhf
-    CONTAINER_ARCH_PACKAGES=(
-      libegl1-mesa-dev:armhf
-      libelf-dev:armhf
-      libgbm-dev:armhf
-      libgles2-mesa-dev:armhf
-      libpng-dev:armhf
-      libudev-dev:armhf
-      libvulkan-dev:armhf
-      libwaffle-dev:armhf
-      libwayland-dev:armhf
-      libx11-xcb-dev:armhf
-      libxkbcommon-dev:armhf
-    )
-else
-    BUILD_CL="ON"
-    BUILD_VK="ON"
-    GCC_ARCH="x86_64-linux-gnu"
-    KERNEL_ARCH="x86_64"
-    CONTAINER_ARCH_PACKAGES=(
-      libasound2-dev libcap-dev libfdt-dev libva-dev p7zip wine
-    )
-fi
-
-# Determine if we're in a cross build.
-if [[ -e /cross_file-$DEBIAN_ARCH.txt ]]; then
-    EXTRA_MESON_ARGS="--cross-file /cross_file-$DEBIAN_ARCH.txt"
-    EXTRA_CMAKE_ARGS="-DCMAKE_TOOLCHAIN_FILE=/toolchain-$DEBIAN_ARCH.cmake"
-
-    if [ $DEBIAN_ARCH = arm64 ]; then
-        RUST_TARGET="aarch64-unknown-linux-gnu"
-    elif [ $DEBIAN_ARCH = armhf ]; then
-        RUST_TARGET="armv7-unknown-linux-gnueabihf"
-    fi
-    rustup target add $RUST_TARGET
-    export EXTRA_CARGO_ARGS="--target $RUST_TARGET"
-
-    export ARCH=${KERNEL_ARCH}
-    export CROSS_COMPILE="${GCC_ARCH}-"
-fi
-
-# no need to remove these at end, image isn't saved at the end
-CONTAINER_EPHEMERAL=(
-    arch-test
-    automake
-    bc
-    "clang-${LLVM_VERSION}"
-    cmake
-    curl
-    mmdebstrap
-    git
-    glslang-tools
-    jq
-    libdrm-dev
-    libegl1-mesa-dev
-    libxext-dev
-    libfontconfig-dev
-    libgbm-dev
-    libgl-dev
-    libgles2-mesa-dev
-    libglu1-mesa-dev
-    libglx-dev
-    libpng-dev
-    libssl-dev
-    libudev-dev
-    libvulkan-dev
-    libwaffle-dev
-    libwayland-dev
-    libx11-xcb-dev
-    libxcb-dri2-0-dev
-    libxkbcommon-dev
-    libwayland-dev
-    "lld-${LLVM_VERSION}"
-    ninja-build
-    openssh-server
-    patch
-    protobuf-compiler
-    python-is-python3
-    python3-distutils
-    python3-mako
-    python3-numpy
-    python3-serial
-    python3-venv
-    unzip
-    wayland-protocols
-    zstd
-)
-
-[ "$BUILD_CL" == "ON" ] && CONTAINER_EPHEMERAL+=(
-	ocl-icd-opencl-dev
-)
-
-
-echo "deb [trusted=yes] https://gitlab.freedesktop.org/gfx-ci/ci-deb-repo/-/raw/${PKG_REPO_REV}/ ${FDO_DISTRIBUTION_VERSION%-*} main" | tee /etc/apt/sources.list.d/gfx-ci_.list
-
-. .gitlab-ci/container/debian/maybe-add-llvm-repo.sh
-
-apt-get update
-apt-get install -y --no-remove \
-		   -o Dpkg::Options::='--force-confdef' -o Dpkg::Options::='--force-confold' \
-		   "${CONTAINER_EPHEMERAL[@]}" \
-                   "${CONTAINER_ARCH_PACKAGES[@]}" \
-                   ${EXTRA_LOCAL_PACKAGES}
-
-export ROOTFS=/lava-files/rootfs-${DEBIAN_ARCH}
-mkdir -p "$ROOTFS"
-
-# rootfs packages
-PKG_BASE=(
-  tzdata mount
-)
-PKG_CI=(
-  firmware-realtek
-  bash ca-certificates curl
-  initramfs-tools jq netcat-openbsd dropbear openssh-server
-  libasan8
-  libubsan1
-  git
-  python3-dev python3-pip python3-setuptools python3-wheel
-  weston # Wayland
-  xinit xserver-xorg-core xwayland # X11
-)
-PKG_MESA_DEP=(
-  libdrm2 libsensors5 libexpat1 # common
-  libvulkan1 # vulkan
-  libx11-6 libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0 libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxdamage1 libxext6 libxfixes3 libxkbcommon0 libxrender1 libxshmfence1 libxxf86vm1 # X11
-)
-PKG_DEP=(
-  libpng16-16
-  libva-wayland2
-  libwaffle-1-0
-  libpython3.11 python3 python3-lxml python3-mako python3-numpy python3-packaging python3-pil python3-renderdoc python3-requests python3-simplejson python3-yaml # Python
-  sntp
-  strace
-  waffle-utils
-  zstd
-)
-# arch dependent rootfs packages
-[ "$DEBIAN_ARCH" = "arm64" ] && PKG_ARCH=(
-  libgl1 libglu1-mesa
-  firmware-linux-nonfree firmware-qcom-media
-  libfontconfig1
-)
-[ "$DEBIAN_ARCH" = "amd64" ] && PKG_ARCH=(
-  firmware-amd-graphics
-  firmware-misc-nonfree
-  gstreamer1.0-plugins-bad gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-ugly gstreamer1.0-tools gstreamer1.0-vaapi libgstreamer1.0-0 # Fluster
-  libgl1 libglu1-mesa
-  inetutils-syslogd iptables libcap2
-  libfontconfig1
-  spirv-tools
-  libelf1 libfdt1 "libllvm${LLVM_VERSION}"
-  libva2 libva-drm2
-  socat
-  sysvinit-core
-  wine
-)
-[ "$DEBIAN_ARCH" = "armhf" ] && PKG_ARCH=(
-  firmware-misc-nonfree
-)
-
-[ "$BUILD_CL" == "ON" ] && PKG_ARCH+=(
-	clinfo
-	"libclang-cpp${LLVM_VERSION}"
-	"libclang-common-${LLVM_VERSION}-dev"
-	ocl-icd-libopencl1
-)
-[ "$BUILD_VK" == "ON" ] && PKG_ARCH+=(
-	libvulkan-dev
-)
-
-mmdebstrap \
-    --variant=apt \
-    --arch="${DEBIAN_ARCH}" \
-    --components main,contrib,non-free-firmware \
-    --customize-hook='.gitlab-ci/container/get-firmware-from-source.sh "$ROOTFS" "$FIRMWARE_FILES"' \
-    --include "${PKG_BASE[*]} ${PKG_CI[*]} ${PKG_DEP[*]} ${PKG_MESA_DEP[*]} ${PKG_ARCH[*]}" \
-    bookworm \
-    "$ROOTFS/" \
-    "http://deb.debian.org/debian" \
-    "deb [trusted=yes] https://gitlab.freedesktop.org/gfx-ci/ci-deb-repo/-/raw/${PKG_REPO_REV}/ ${FDO_DISTRIBUTION_VERSION%-*} main" \
-    "${LLVM_APT_REPO:-}"
-
-############### Install mold
-. .gitlab-ci/container/build-mold.sh
-
-############### Building
-STRIP_CMD="${GCC_ARCH}-strip"
-mkdir -p $ROOTFS/usr/lib/$GCC_ARCH
-
-############### Build libclc
-
-if [ "$BUILD_CL" = "ON" ]; then
-  rm -rf /usr/lib/clc/*
-  . .gitlab-ci/container/build-libclc.sh
-  mkdir -p $ROOTFS/usr/{share,lib}/clc
-  mv /usr/share/clc/spirv*-mesa3d-.spv $ROOTFS/usr/share/clc/
-  ln -s /usr/share/clc/spirv64-mesa3d-.spv $ROOTFS/usr/lib/clc/
-  ln -s /usr/share/clc/spirv-mesa3d-.spv $ROOTFS/usr/lib/clc/
-fi
-
-############### Build Vulkan validation layer (for zink)
-if [ "$DEBIAN_ARCH" = "amd64" ]; then
-  . .gitlab-ci/container/build-vulkan-validation.sh
-  mv /usr/lib/x86_64-linux-gnu/libVkLayer_khronos_validation.so $ROOTFS/usr/lib/x86_64-linux-gnu/
-  mkdir -p $ROOTFS/usr/share/vulkan/explicit_layer.d
-  mv /usr/share/vulkan/explicit_layer.d/* $ROOTFS/usr/share/vulkan/explicit_layer.d/
-fi
-
-############### Build apitrace
-. .gitlab-ci/container/build-apitrace.sh
-mkdir -p $ROOTFS/apitrace
-mv /apitrace/build $ROOTFS/apitrace
-rm -rf /apitrace
-
-############### Build ANGLE
-if [ "$DEBIAN_ARCH" != "armhf" ]; then
-  ANGLE_TARGET=linux \
-  . .gitlab-ci/container/build-angle.sh
-  mv /angle $ROOTFS/.
-  rm -rf /angle
-fi
-
-############### Build dEQP runner
-. .gitlab-ci/container/build-deqp-runner.sh
-mkdir -p $ROOTFS/usr/bin
-mv /usr/local/bin/*-runner $ROOTFS/usr/bin/.
-
-
-############### Build dEQP
-
-DEQP_API=tools \
-DEQP_TARGET=default \
-. .gitlab-ci/container/build-deqp.sh
-
-DEQP_API=GL \
-DEQP_TARGET=surfaceless \
-. .gitlab-ci/container/build-deqp.sh
-
-DEQP_API=GLES \
-DEQP_TARGET=surfaceless \
-. .gitlab-ci/container/build-deqp.sh
-
-if [ "$BUILD_VK" == "ON" ]; then
-  DEQP_API=VK \
-  DEQP_TARGET=default \
-  . .gitlab-ci/container/build-deqp.sh
-
-  if [ "$DEBIAN_ARCH" == "amd64" ]; then
-    DEQP_API=VK-main \
-    DEQP_TARGET=default \
-    . .gitlab-ci/container/build-deqp.sh
-  fi
-fi
-
-rm -rf /VK-GL-CTS
-
-mv /deqp-* $ROOTFS/.
-
-
-############### Build SKQP
-if [[ "$DEBIAN_ARCH" = "arm64" ]] \
-  || [[ "$DEBIAN_ARCH" = "amd64" ]]; then
-    . .gitlab-ci/container/build-skqp.sh
-    mv /skqp $ROOTFS/.
-fi
-
-############### Build piglit
-PIGLIT_OPTS="-DPIGLIT_USE_WAFFLE=ON
-	     -DPIGLIT_USE_GBM=ON
-	     -DPIGLIT_USE_WAYLAND=ON
-	     -DPIGLIT_USE_X11=ON
-	     -DPIGLIT_BUILD_GLX_TESTS=ON
-	     -DPIGLIT_BUILD_EGL_TESTS=ON
-	     -DPIGLIT_BUILD_WGL_TESTS=OFF
-	     -DPIGLIT_BUILD_GL_TESTS=ON
-	     -DPIGLIT_BUILD_GLES1_TESTS=ON
-	     -DPIGLIT_BUILD_GLES2_TESTS=ON
-	     -DPIGLIT_BUILD_GLES3_TESTS=ON
-	     -DPIGLIT_BUILD_CL_TESTS=$BUILD_CL
-	     -DPIGLIT_BUILD_VK_TESTS=$BUILD_VK
-	     -DPIGLIT_BUILD_DMA_BUF_TESTS=ON" \
-  . .gitlab-ci/container/build-piglit.sh
-mv /piglit $ROOTFS/.
-
-############### Build libva tests
-if [[ "$DEBIAN_ARCH" = "amd64" ]]; then
-    . .gitlab-ci/container/build-va-tools.sh
-    mv /va/bin/* $ROOTFS/usr/bin/
-fi
-
-############### Build Crosvm
-if [[ ${DEBIAN_ARCH} = "amd64" ]]; then
-    . .gitlab-ci/container/build-crosvm.sh
-    mv /usr/local/bin/crosvm $ROOTFS/usr/bin/
-    mv /usr/local/lib/libvirglrenderer.* $ROOTFS/usr/lib/$GCC_ARCH/
-    mkdir -p $ROOTFS/usr/local/libexec/
-    mv /usr/local/libexec/virgl* $ROOTFS/usr/local/libexec/
-fi
-
-############### Build ci-kdl
-. .gitlab-ci/container/build-kdl.sh
-mv /ci-kdl $ROOTFS/
-
-############### Install fluster
-if [[ ${DEBIAN_ARCH} = "amd64" ]]; then
-    section_start fluster "Install fluster"
-    . .gitlab-ci/container/build-fluster.sh
-    section_end fluster
-fi
-
-############### Build local stuff for use by igt and kernel testing, which
-############### will reuse most of our container build process from a specific
-############### hash of the Mesa tree.
-if [[ -e ".gitlab-ci/local/build-rootfs.sh" ]]; then
-    . .gitlab-ci/local/build-rootfs.sh
-fi
-
-############### Delete rust, since the tests won't be compiling anything.
-rm -rf /root/.cargo
-rm -rf /root/.rustup
-
-############### Delete firmware files we don't need
-if [ "$DEBIAN_ARCH" = "amd64" ]; then
-   dpkg -L firmware-misc-nonfree | grep -v "i915" | xargs rm || true
-fi
-
-############### Fill rootfs
-cp .gitlab-ci/setup-test-env.sh $ROOTFS/.
-cp .gitlab-ci/container/setup-rootfs.sh $ROOTFS/.
-cp .gitlab-ci/container/strip-rootfs.sh $ROOTFS/.
-cp .gitlab-ci/container/debian/llvm-snapshot.gpg.key $ROOTFS/.
-cp .gitlab-ci/container/debian/winehq.gpg.key $ROOTFS/.
-chroot $ROOTFS bash /setup-rootfs.sh
-rm $ROOTFS/{llvm-snapshot,winehq}.gpg.key
-rm "$ROOTFS/setup-test-env.sh"
-rm "$ROOTFS/setup-rootfs.sh"
-rm "$ROOTFS/strip-rootfs.sh"
-cp /etc/wgetrc $ROOTFS/etc/.
-
-# Copy all tags to the rootfs, so test jobs can check if they are using the intended version
-TAG_FILE_DIR="$(get_tag_file)"
-if [ -d "${TAG_FILE_DIR}" ]; then
-    cp --parents -r "${TAG_FILE_DIR}" $ROOTFS/.
-fi
-
-if [ "${DEBIAN_ARCH}" = "arm64" ]; then
-    mkdir -p /lava-files/rootfs-arm64/lib/firmware/qcom/sm8350/  # for firmware imported later
-fi
-
-ROOTFSTAR="lava-rootfs.tar.zst"
-du -ah "$ROOTFS" | sort -h | tail -100
-pushd $ROOTFS
-  tar --zstd -cf /lava-files/${ROOTFSTAR} .
-popd
-
-. .gitlab-ci/container/container_post_build.sh
-
-s3_upload /lava-files/"${ROOTFSTAR}" "https://${S3_PATH}/"
-
-touch /lava-files/done
-s3_upload /lava-files/done "https://${S3_PATH}/"
diff --git a/.gitlab-ci/container/setup-rootfs.sh b/.gitlab-ci/container/setup-rootfs.sh
old mode 100644
new mode 100755
index 9dedee05f76..0ba816bd629
--- a/.gitlab-ci/container/setup-rootfs.sh
+++ b/.gitlab-ci/container/setup-rootfs.sh
@@ -2,19 +2,11 @@
 # shellcheck disable=SC1091 # The relative paths in this file only become valid at runtime.
 # When changing this file, you need to bump the following
 # .gitlab-ci/image-tags.yml tags:
-# KERNEL_ROOTFS_TAG
-set -ex
+# DEBIAN_TEST_GL_TAG
+# DEBIAN_TEST_VIDEO_TAG
+# DEBIAN_TEST_VK_TAG
 
-. setup-test-env.sh
-
-export DEBIAN_FRONTEND=noninteractive
-
-# Needed for ci-fairy, this revision is able to upload files to
-# MinIO and doesn't depend on git
-pip3 install --break-system-packages git+http://gitlab.freedesktop.org/freedesktop/ci-templates@ffe4d1b10aab7534489f0c4bbc4c5899df17d3f2
-
-# Needed for manipulation with traces yaml files.
-pip3 install --break-system-packages yq
+set -eux -o pipefail
 
 passwd root -d
 chsh -s /bin/sh
@@ -29,5 +21,3 @@ chmod +x  /init
 # Copy timezone file and remove tzdata package
 rm -rf /etc/localtime
 cp /usr/share/zoneinfo/Etc/UTC /etc/localtime
-
-. strip-rootfs.sh
diff --git a/.gitlab-ci/container/strip-rootfs.sh b/.gitlab-ci/container/strip-rootfs.sh
index 227ba9be254..53f72680464 100644
--- a/.gitlab-ci/container/strip-rootfs.sh
+++ b/.gitlab-ci/container/strip-rootfs.sh
@@ -4,8 +4,8 @@
 # .gitlab-ci/image-tags.yml tags:
 # DEBIAN_TEST_ANDROID_TAG
 # DEBIAN_TEST_GL_TAG
+# DEBIAN_TEST_VIDEO_TAG
 # DEBIAN_TEST_VK_TAG
-# KERNEL_ROOTFS_TAG
 set -ex
 
 section_start strip-rootfs "Stripping rootfs"
@@ -38,7 +38,6 @@ UNNEEDED_PACKAGES=(
   udev
   init-system-helpers
   cpio
-  passwd
   libsemanage1 libsemanage-common
   libsepol1
   gpgv
diff --git a/.gitlab-ci/cuttlefish-runner.sh b/.gitlab-ci/cuttlefish-runner.sh
index b4c21dfa7c6..e86a8ceb3fc 100755
--- a/.gitlab-ci/cuttlefish-runner.sh
+++ b/.gitlab-ci/cuttlefish-runner.sh
@@ -49,6 +49,14 @@ ulimit -S -n 32768
 VSOCK_BASE=10000 # greater than all the default vsock ports
 VSOCK_CID=$((VSOCK_BASE + (CI_JOB_ID & 0xfff)))
 
+# Venus requires a custom kernel for now
+if [ "$ANDROID_GPU_MODE" = "venus" ] || [ "$ANDROID_GPU_MODE" = "venus_guest_angle" ]; then
+  CUSTOM_KERNEL_ARGS="
+  -kernel_path=/cuttlefish/bzImage
+  -initramfs_path=/cuttlefish/initramfs.img
+  "
+fi
+
 HOME=/cuttlefish launch_cvd \
   -daemon \
   -verbosity=VERBOSE \
@@ -64,8 +72,7 @@ HOME=/cuttlefish launch_cvd \
   -gpu_mode="$ANDROID_GPU_MODE" \
   -cpus=${FDO_CI_CONCURRENT:-4} \
   -memory_mb 8192 \
-  -kernel_path="/cuttlefish/bzImage" \
-  -initramfs_path="/cuttlefish/initramfs.img"
+  $CUSTOM_KERNEL_ARGS
 
 sleep 1
 
diff --git a/.gitlab-ci/deqp-runner.sh b/.gitlab-ci/deqp-runner.sh
index abe727d28d2..113807a7dab 100755
--- a/.gitlab-ci/deqp-runner.sh
+++ b/.gitlab-ci/deqp-runner.sh
@@ -31,6 +31,16 @@ if [ -n "$ANGLE_TAG" ]; then
   export LD_LIBRARY_PATH=/angle:$LD_LIBRARY_PATH
 fi
 
+if [ -n "$PIGLIT_TAG" ]; then
+  # Are we using the right Piglit version?
+  ci_tag_test_time_check "PIGLIT_TAG"
+elif [ -d "/piglit" ]; then
+  # The job does not inherit from .test-piglit, so we move it out of the way.
+  # This makes sure that we can both do the right version checks when needed,
+  # and also optimise our dependencies so we don't pull unneeded stuff.
+  mv /piglit /piglit.unused
+fi
+
 # Ensure Mesa Shader Cache resides on tmpfs.
 SHADER_CACHE_HOME=${XDG_CACHE_HOME:-${HOME}/.cache}
 SHADER_CACHE_DIR=${MESA_SHADER_CACHE_DIR:-${SHADER_CACHE_HOME}/mesa_shader_cache}
diff --git a/.gitlab-ci/download-git-cache.sh b/.gitlab-ci/download-git-cache.sh
index 27fb7a930c8..a414f764aeb 100644
--- a/.gitlab-ci/download-git-cache.sh
+++ b/.gitlab-ci/download-git-cache.sh
@@ -16,8 +16,8 @@ fi
 TMP_DIR=$(mktemp -d)
 
 echo "$(date +"%F %T") Downloading archived master..."
-if ! /usr/bin/wget \
-	      -O "$TMP_DIR/$CI_PROJECT_NAME.tar.gz" \
+if ! curl --location --fail --retry-connrefused --retry 3 --retry-delay 10 \
+              --output "$TMP_DIR/$CI_PROJECT_NAME.tar.gz" \
               "https://${S3_HOST}/${S3_GITCACHE_BUCKET}/${FDO_UPSTREAM_REPO}/$CI_PROJECT_NAME.tar.gz";
 then
     echo "Repository cache not available"
diff --git a/.gitlab-ci/fluster/fluster-runner.sh b/.gitlab-ci/fluster/fluster-runner.sh
index 65a8e7fa7c9..e7ccaaa7d1a 100755
--- a/.gitlab-ci/fluster/fluster-runner.sh
+++ b/.gitlab-ci/fluster/fluster-runner.sh
@@ -13,19 +13,6 @@ if [ -z "$FLUSTER_CODECS" ]; then
    exit 1
 fi
 
-# Check which fluster vectors to get
-FLUSTER_VECTORS_HOST_PATH="${STORAGE_MAINLINE_HOST_PATH}/fluster/${FLUSTER_VECTORS_VERSION}"
-if [ "$CI_PROJECT_PATH" != "$FDO_UPSTREAM_REPO" ]; then
-  if ! curl -s -L --retry 4 -f --retry-delay 60 "${FDO_HTTP_CACHE_URI:-}https://${FLUSTER_VECTORS_HOST_PATH}/done"; then
-    echo "Using Fluster vectors from the fork, cached from mainline is unavailable."
-    FLUSTER_VECTORS_HOST_PATH="${STORAGE_FORK_HOST_PATH}/fluster/${FLUSTER_VECTORS_VERSION}"
-  else
-    echo "Using the cached Fluster vectors."
-  fi
-fi
-
-curl -L --retry 4 -f --retry-all-errors --retry-delay 60 "${FDO_HTTP_CACHE_URI:-}https://${FLUSTER_VECTORS_HOST_PATH}/vectors.tar.zst" | tar --zstd -x -C /usr/local/
-
 INSTALL="$PWD/install"
 
 # Set up the driver environment.
diff --git a/.gitlab-ci/gtest-runner.sh b/.gitlab-ci/gtest-runner.sh
index b55e581a341..0a55446c96f 100755
--- a/.gitlab-ci/gtest-runner.sh
+++ b/.gitlab-ci/gtest-runner.sh
@@ -8,6 +8,8 @@ set -ex
 
 INSTALL=$PWD/install
 
+export PATH=/va/bin:$PATH
+
 # Set up the driver environment.
 export LD_LIBRARY_PATH=$INSTALL/lib/
 
diff --git a/.gitlab-ci/image-tags.yml b/.gitlab-ci/image-tags.yml
index a9cb3b91e66..3e94e428c39 100644
--- a/.gitlab-ci/image-tags.yml
+++ b/.gitlab-ci/image-tags.yml
@@ -19,22 +19,22 @@ include:
   - .gitlab-ci/conditional-build-image-tags.yml
 
 variables:
-  DEBIAN_BASE_TAG: "20250408-virgl"
+  DEBIAN_BASE_TAG: "20250424-rootfs"
 
-  DEBIAN_BUILD_TAG: "20250324-android"
+  DEBIAN_BUILD_TAG: "20250422-ci-fairy"
 
-  DEBIAN_TEST_ANDROID_TAG: "20250415-anglit"
-  DEBIAN_TEST_GL_TAG: "20250415-anglit"
-  DEBIAN_TEST_VK_TAG: "20250416-vkvideo"
-  KERNEL_ROOTFS_TAG: "20250415-anglit"
+  DEBIAN_TEST_ANDROID_TAG: "20250423-rootfs"
+  DEBIAN_TEST_GL_TAG: "20250423-rootfs"
+  DEBIAN_TEST_VIDEO_TAG: "20250423-rootfs"
+  DEBIAN_TEST_VK_TAG: "20250423-rootfs"
 
-  DEBIAN_PYUTILS_TAG: "20250321-s3cp-fix5"
+  DEBIAN_PYUTILS_TAG: "20250422-ci-fairy"
 
-  ALPINE_X86_64_BUILD_TAG: "20250324-sphinx"
-  ALPINE_X86_64_LAVA_SSH_TAG: "20250321-s3cp-fix5"
-  FEDORA_X86_64_BUILD_TAG: "20250321-s3cp-fix5"
+  ALPINE_X86_64_BUILD_TAG: "20250423-rootfs"
+  ALPINE_X86_64_LAVA_SSH_TAG: "20250423-rootfs"
+  FEDORA_X86_64_BUILD_TAG: "20250423-rootfs"
 
-  KERNEL_TAG: "v6.14-mesa-0bdd"
+  KERNEL_TAG: "v6.14-mesa-dea4"
   KERNEL_REPO: "gfx-ci/linux"
   PKG_REPO_REV: "95bf62c"
 
diff --git a/.gitlab-ci/lava/lava-gitlab-ci.yml b/.gitlab-ci/lava/lava-gitlab-ci.yml
index e5b392be4d7..590c1f6b4b5 100644
--- a/.gitlab-ci/lava/lava-gitlab-ci.yml
+++ b/.gitlab-ci/lava/lava-gitlab-ci.yml
@@ -20,13 +20,14 @@ variables:
   timeout: 1h
   variables:
     GIT_STRATEGY: none # testing doesn't build anything from source
+    HWCI_TEST_SCRIPT: ./install/deqp-runner.sh
     FDO_CI_CONCURRENT: 6 # should be replaced by per-machine definitions
     # the dispatchers use this to cache data locally
     LAVA_HTTP_CACHE_URI: "http://caching-proxy/cache/?uri="
     # base system generated by the container build job, shared between many pipelines
     BASE_SYSTEM_HOST_PREFIX: "${S3_HOST}/${S3_KERNEL_BUCKET}"
-    BASE_SYSTEM_MAINLINE_HOST_PATH: "${BASE_SYSTEM_HOST_PREFIX}/${FDO_UPSTREAM_REPO}/${DISTRIBUTION_TAG}/${DEBIAN_ARCH}"
-    BASE_SYSTEM_FORK_HOST_PATH: "${BASE_SYSTEM_HOST_PREFIX}/${CI_PROJECT_PATH}/${DISTRIBUTION_TAG}/${DEBIAN_ARCH}"
+    BASE_SYSTEM_MAINLINE_HOST_PATH: "${BASE_SYSTEM_HOST_PREFIX}/${FDO_UPSTREAM_REPO}/${LAVA_DISTRIBUTION_TAG}"
+    BASE_SYSTEM_FORK_HOST_PATH: "${BASE_SYSTEM_HOST_PREFIX}/${CI_PROJECT_PATH}/${LAVA_DISTRIBUTION_TAG}"
     # per-job build artifacts
     JOB_ROOTFS_OVERLAY_PATH: "${JOB_ARTIFACTS_BASE}/job-rootfs-overlay.tar.gz"
     JOB_RESULTS_PATH: "${JOB_ARTIFACTS_BASE}/results.tar.zst"
@@ -35,8 +36,6 @@ variables:
     S3_RESULTS_UPLOAD: "${JOB_ARTIFACTS_BASE}"
     PIGLIT_NO_WINDOW: 1
     VISIBILITY_GROUP: "Collabora+fdo"
-    STORAGE_MAINLINE_HOST_PATH: "${BASE_SYSTEM_HOST_PREFIX}/${FDO_UPSTREAM_REPO}/${DATA_STORAGE_PATH}"
-    STORAGE_FORK_HOST_PATH: "${BASE_SYSTEM_HOST_PREFIX}/${CI_PROJECT_PATH}/${DATA_STORAGE_PATH}"
   before_script:
     - !reference [.download_s3, before_script]
   script:
@@ -64,82 +63,114 @@ variables:
     - job: python-artifacts
       artifacts: false
 
-.lava-test:arm32:
+.lava-x86_64-test:
   variables:
-    ARCH: arm32
-    DEBIAN_ARCH: armhf
-    KERNEL_IMAGE_NAME: zImage
+    ARCH: x86_64
+    DEBIAN_ARCH: amd64
+    KERNEL_IMAGE_NAME: bzImage
     KERNEL_IMAGE_TYPE: "zimage"
     BOOT_METHOD: u-boot
   extends:
-    - .use-debian/arm64_build # for same $MESA_ARTIFACTS_TAG as in kernel+rootfs_arm32
     - .use-debian/x86_64_pyutils
     - .lava-test
-    - .use-kernel+rootfs-arm
   needs:
     - !reference [.lava-test, needs]
-    - job: kernel+rootfs_arm32
+    - job: debian-testing
       artifacts: false
-    - job: debian-arm32
+
+.lava-x86_64-test-gl:
+  variables:
+    LAVA_DISTRIBUTION_TAG: !reference [debian/x86_64_test-gl, variables, LAVA_DISTRIBUTION_TAG]
+  extends:
+    - .lava-x86_64-test
+  needs:
+    - !reference [.lava-x86_64-test, needs]
+    - job: debian/x86_64_test-gl
       artifacts: false
 
-.lava-test-deqp:arm32:
+.lava-x86_64-test-video:
+  variables:
+    LAVA_DISTRIBUTION_TAG: !reference [debian/x86_64_test-video, variables, LAVA_DISTRIBUTION_TAG]
   extends:
-    - .lava-test:arm32
+    - .lava-x86_64-test
+  needs:
+    - !reference [.lava-x86_64-test, needs]
+    - job: debian/x86_64_test-video
+      artifacts: false
+
+.lava-x86_64-test-vk:
   variables:
-    HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
+    LAVA_DISTRIBUTION_TAG: !reference [debian/x86_64_test-vk, variables, LAVA_DISTRIBUTION_TAG]
+  extends:
+    - .lava-x86_64-test
+  needs:
+    - !reference [.lava-x86_64-test, needs]
+    - job: debian/x86_64_test-vk
+      artifacts: false
 
-.lava-test:arm64:
+.lava-arm32-test:
   variables:
-    ARCH: arm64
-    DEBIAN_ARCH: arm64
-    KERNEL_IMAGE_NAME: Image
-    KERNEL_IMAGE_TYPE: "image"
+    ARCH: arm32
+    DEBIAN_ARCH: armhf
+    KERNEL_IMAGE_NAME: zImage
+    KERNEL_IMAGE_TYPE: "zimage"
     BOOT_METHOD: u-boot
   extends:
-    - .use-debian/arm64_build # for same $MESA_ARTIFACTS_TAG as in kernel+rootfs_arm64
     - .use-debian/x86_64_pyutils
     - .lava-test
-    - .use-kernel+rootfs-arm
   needs:
     - !reference [.lava-test, needs]
-    - job: kernel+rootfs_arm64
-      artifacts: false
-    - job: debian-arm64
+    - job: debian-arm32
       artifacts: false
 
-.lava-test-deqp:arm64:
+.lava-arm32-test-gl:
   variables:
-    HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
+    LAVA_DISTRIBUTION_TAG: !reference [debian/arm32_test-gl, variables, LAVA_DISTRIBUTION_TAG]
   extends:
-    - .lava-test:arm64
+    - .lava-arm32-test
+  needs:
+    - !reference [.lava-arm32-test, needs]
+    - job: debian/arm32_test-gl
+      artifacts: false
 
-.lava-test:x86_64:
+.lava-arm64-test:
   variables:
-    ARCH: x86_64
-    DEBIAN_ARCH: amd64
-    KERNEL_IMAGE_NAME: bzImage
-    KERNEL_IMAGE_TYPE: "zimage"
+    ARCH: arm64
+    DEBIAN_ARCH: arm64
+    KERNEL_IMAGE_NAME: Image
+    KERNEL_IMAGE_TYPE: "image"
     BOOT_METHOD: u-boot
   extends:
-    - .use-debian/x86_64_build-base # for same $MESA_ARTIFACTS_BASE_TAG as in kernel+rootfs_x86_64
     - .use-debian/x86_64_pyutils
     - .lava-test
-    - .use-kernel+rootfs-x86_64
   needs:
     - !reference [.lava-test, needs]
-    - job: kernel+rootfs_x86_64
+    - job: debian-arm64
       artifacts: false
-    - job: debian-testing
+
+.lava-arm64-test-gl:
+  variables:
+    LAVA_DISTRIBUTION_TAG: !reference [debian/arm64_test-gl, variables, LAVA_DISTRIBUTION_TAG]
+  extends:
+    - .lava-arm64-test
+  needs:
+    - !reference [.lava-arm64-test, needs]
+    - job: debian/arm64_test-gl
       artifacts: false
 
-.lava-test-deqp:x86_64:
+.lava-arm64-test-vk:
   variables:
-    HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
+    LAVA_DISTRIBUTION_TAG: !reference [debian/arm64_test-vk, variables, LAVA_DISTRIBUTION_TAG]
   extends:
-    - .lava-test:x86_64
+    - .lava-arm64-test
+  needs:
+    - !reference [.lava-arm64-test, needs]
+    - job: debian/arm64_test-vk
+      artifacts: false
 
 .lava-piglit-traces:
+  extends:
+    - .test-piglit
   variables:
     HWCI_TEST_SCRIPT: "/install/piglit/piglit-traces.sh"
     # until we overcome Infrastructure issues, give traces extra 5 min before timeout
@@ -150,19 +181,19 @@ variables:
     reports:
       junit: results/junit.xml
 
-.lava-piglit-traces:x86_64:
+.lava-x86_64-piglit-traces:
   extends:
-    - .lava-test:x86_64
+    - .lava-x86_64-test-gl
     - .lava-piglit-traces
 
-.lava-piglit-traces:arm32:
+.lava-arm32-piglit-traces:
   extends:
-    - .lava-test:arm32
+    - .lava-arm32-test-gl
     - .lava-piglit-traces
 
-.lava-piglit-traces:arm64:
+.lava-arm64-piglit-traces:
   extends:
-    - .lava-test:arm64
+    - .lava-arm64-test-gl
     - .lava-piglit-traces
 
 .lava-fluster:
diff --git a/.gitlab-ci/lava/lava-submit.sh b/.gitlab-ci/lava/lava-submit.sh
index fbcae2a979c..14837347b7d 100755
--- a/.gitlab-ci/lava/lava-submit.sh
+++ b/.gitlab-ci/lava/lava-submit.sh
@@ -40,7 +40,6 @@ section_start prepare_rootfs "Preparing root filesystem"
 
 set -ex
 
-section_switch rootfs "Assembling root filesystem"
 ROOTFS_URL="$(get_path_to_artifact lava-rootfs.tar.zst)"
 [ $? != 1 ] || exit 1
 
@@ -52,7 +51,7 @@ cp artifacts/ci-common/init-*.sh results/job-rootfs-overlay/
 cp "$SCRIPTS_DIR"/setup-test-env.sh results/job-rootfs-overlay/
 
 tar zcf job-rootfs-overlay.tar.gz -C results/job-rootfs-overlay/ .
-s3_upload job-rootfs-overlay.tar.gz "https://${JOB_ARTIFACTS_BASE}/"
+ci-fairy s3cp --token-file "${S3_JWT_FILE}" job-rootfs-overlay.tar.gz "https://${JOB_ROOTFS_OVERLAY_PATH}"
 
 # Prepare env vars for upload.
 section_switch variables "Environment variables passed through to device:"
diff --git a/.gitlab-ci/lava/lava_job_submitter.py b/.gitlab-ci/lava/lava_job_submitter.py
index cda92d44f72..c62ee5afd57 100755
--- a/.gitlab-ci/lava/lava_job_submitter.py
+++ b/.gitlab-ci/lava/lava_job_submitter.py
@@ -225,10 +225,9 @@ def wait_for_job_get_started(job, attempt_no):
 
 
 def bootstrap_log_follower(main_test_case, timestamp_relative_to) -> LogFollower:
-    deploy_timeout = GL_SECTION_TIMEOUTS[LogSectionType.LAVA_DEPLOY]
     start_section = GitlabSection(
         id="dut_deploy",
-        header=f"Running LAVA deploy action - Timeout: {deploy_timeout}",
+        header="Running LAVA deploy action",
         type=LogSectionType.LAVA_DEPLOY,
         start_collapsed=True,
         timestamp_relative_to=timestamp_relative_to,
diff --git a/.gitlab-ci/lava/utils/lava_job_definition.py b/.gitlab-ci/lava/utils/lava_job_definition.py
index d67b59d0ed3..721c36d0a40 100644
--- a/.gitlab-ci/lava/utils/lava_job_definition.py
+++ b/.gitlab-ci/lava/utils/lava_job_definition.py
@@ -257,7 +257,8 @@ class LAVAJobDefinition:
         # since the license isn't bundled inside the repository
         if self.job_submitter.device_type == "sm8350-hdk":
             run_steps.append(
-                "curl -L --retry 4 -f --retry-all-errors --retry-delay 60 "
+                "mkdir -p /lib/firmware/qcom/sm8350 && "
+                + "curl -L --retry 4 -f --retry-all-errors --retry-delay 60 "
                 + "https://github.com/allahjasif1990/hdk888-firmware/raw/main/a660_zap.mbn "
                 + '-o "/lib/firmware/qcom/sm8350/a660_zap.mbn"'
             )
diff --git a/.gitlab-ci/lava/utils/log_section.py b/.gitlab-ci/lava/utils/log_section.py
index 06157d4eb9a..641ed937f8c 100644
--- a/.gitlab-ci/lava/utils/log_section.py
+++ b/.gitlab-ci/lava/utils/log_section.py
@@ -14,7 +14,6 @@ class LogSectionType(Enum):
     LAVA_QUEUE = auto()
     LAVA_DEPLOY = auto()
     LAVA_BOOT = auto()
-    TEST_DUT_SUITE = auto()
     TEST_SUITE = auto()
     TEST_CASE = auto()
     LAVA_POST_PROCESSING = auto()
@@ -44,12 +43,9 @@ LAVA_BOOT_TIMEOUT = int(getenv("LAVA_BOOT_TIMEOUT", 5))
 # including LAVA scheduling and boot duration
 LAVA_TEST_OVERHEAD_MIN = 5
 
-# Test DUT suite phase is where the initialization happens in DUT, not on docker.
-# The device will be listening to SSH session until the end of the job.
-LAVA_TEST_DUT_SUITE_TIMEOUT = int(getenv("CI_JOB_TIMEOUT")) // 60 - LAVA_TEST_OVERHEAD_MIN
-
-# Test suite phase is where the initialization happens on docker.
-LAVA_TEST_SUITE_TIMEOUT = int(getenv("LAVA_TEST_SUITE_TIMEOUT", 5))
+# Test suite phase is where initialization occurs on both the DUT and the Docker container.
+# The device will be listening to the SSH session until the end of the job.
+LAVA_TEST_SUITE_TIMEOUT = int(getenv("CI_JOB_TIMEOUT")) // 60 - LAVA_TEST_OVERHEAD_MIN
 
 # Test cases may take a long time, this script has no right to interrupt
 # them. But if the test case takes almost 1h, it will never succeed due to
@@ -66,7 +62,6 @@ DEFAULT_GITLAB_SECTION_TIMEOUTS = {
     LogSectionType.LAVA_QUEUE: timedelta(minutes=LAVA_QUEUE_TIMEOUT),
     LogSectionType.LAVA_DEPLOY: timedelta(minutes=LAVA_DEPLOY_TIMEOUT),
     LogSectionType.LAVA_BOOT: timedelta(minutes=LAVA_BOOT_TIMEOUT),
-    LogSectionType.TEST_DUT_SUITE: timedelta(minutes=LAVA_TEST_DUT_SUITE_TIMEOUT),
     LogSectionType.TEST_SUITE: timedelta(minutes=LAVA_TEST_SUITE_TIMEOUT),
     LogSectionType.TEST_CASE: timedelta(minutes=LAVA_TEST_CASE_TIMEOUT),
     LogSectionType.LAVA_POST_PROCESSING: timedelta(
@@ -95,10 +90,9 @@ class LogSection:
             section_id = self.section_id.format(*match.groups())
             section_header = self.section_header.format(*match.groups())
             is_main_test_case = section_id == main_test_case
-            timeout = DEFAULT_GITLAB_SECTION_TIMEOUTS[self.section_type]
             return GitlabSection(
                 id=section_id,
-                header=f"{section_header} - Timeout: {timeout}",
+                header=section_header,
                 type=self.section_type,
                 start_collapsed=self.collapsed,
                 suppress_start=is_main_test_case,
@@ -122,27 +116,22 @@ LOG_SECTIONS = (
         section_id="{}",
         section_header="test_case {}",
         section_type=LogSectionType.TEST_CASE,
+        collapsed=True,
     ),
     LogSection(
         regex=re.compile(r"<?STARTRUN>? ([^>]*ssh.*server.*)"),
         levels=("debug"),
         section_id="{}",
-        section_header="[dut] test_suite {}",
-        section_type=LogSectionType.TEST_DUT_SUITE,
-    ),
-    LogSection(
-        regex=re.compile(r"<?STARTRUN>? ([^>]*)"),
-        levels=("debug"),
-        section_id="{}",
-        section_header="[docker] test_suite {}",
+        section_header="Setting up hardware device for remote control",
         section_type=LogSectionType.TEST_SUITE,
+        collapsed=True,
     ),
     LogSection(
         regex=re.compile(r"ENDTC>? ([^>]+)"),
         levels=("target", "debug"),
         section_id="post-{}",
         section_header="Post test_case {}",
-        collapsed=True,
         section_type=LogSectionType.LAVA_POST_PROCESSING,
+        collapsed=True,
     ),
 )
diff --git a/.gitlab-ci/meson/build.sh b/.gitlab-ci/meson/build.sh
index f1d1037e73a..b0e02a7f8a2 100755
--- a/.gitlab-ci/meson/build.sh
+++ b/.gitlab-ci/meson/build.sh
@@ -177,7 +177,6 @@ meson setup _build \
       -D libunwind=${UNWIND} \
       ${DRI_LOADERS} \
       ${GALLIUM_ST} \
-      -D gallium-opencl=disabled \
       -D gallium-drivers=${GALLIUM_DRIVERS:-[]} \
       -D vulkan-drivers=${VULKAN_DRIVERS:-[]} \
       -D video-codecs=all \
diff --git a/.gitlab-ci/piglit/piglit-traces.sh b/.gitlab-ci/piglit/piglit-traces.sh
index a04cad9c091..dba58e2468b 100755
--- a/.gitlab-ci/piglit/piglit-traces.sh
+++ b/.gitlab-ci/piglit/piglit-traces.sh
@@ -12,6 +12,9 @@ set -ex
 # Our rootfs may not have "less", which apitrace uses during apitrace dump
 export PAGER=cat  # FIXME: export everywhere
 
+# Check we're using the version of Piglit we think we are
+ci_tag_test_time_check "PIGLIT_TAG"
+
 INSTALL=$(realpath -s "$PWD"/install)
 
 export PIGLIT_REPLAY_DESCRIPTION_FILE="$INSTALL/$PIGLIT_TRACES_FILE"
@@ -127,7 +130,8 @@ replay_s3_upload_images() {
             __DESTINATION_FILE_PATH="$__S3_TRACES_PREFIX/${line##*-}"
         fi
 
-        s3_upload "$RESULTS_DIR/$__PREFIX/$line" "https://${__S3_PATH}/${__DESTINATION_FILE_PATH%/*}/"
+        ci-fairy s3cp --token-file "${S3_JWT_FILE}" "$RESULTS_DIR/$__PREFIX/$line" \
+            "https://${__S3_PATH}/${__DESTINATION_FILE_PATH}"
     done
 }
 
diff --git a/.gitlab-ci/prepare-artifacts-python.sh b/.gitlab-ci/prepare-artifacts-python.sh
index 8c6e34dacb5..8b0e6d6a718 100755
--- a/.gitlab-ci/prepare-artifacts-python.sh
+++ b/.gitlab-ci/prepare-artifacts-python.sh
@@ -1,6 +1,4 @@
 #!/usr/bin/env bash
-# shellcheck disable=SC2038 # TODO: rewrite the find
-# shellcheck disable=SC2086 # we want word splitting
 # shellcheck disable=SC1091 # relative paths only become valid at runtime
 
 . "${SCRIPTS_DIR}/setup-test-env.sh"
@@ -14,7 +12,6 @@ mkdir -p artifacts/
 
 # Test runs don't pull down the git tree, so put the dEQP helper
 # script and associated bits there.
-echo "$(cat VERSION) (git-$(git rev-parse HEAD | cut -b -10))" > artifacts/VERSION
 cp -Rp .gitlab-ci/report-flakes.py artifacts/
 cp -Rp .gitlab-ci/setup-test-env.sh artifacts/
 cp -Rp .gitlab-ci/common artifacts/ci-common
@@ -23,37 +20,11 @@ cp -Rp .gitlab-ci/bare-metal artifacts/
 cp -Rp .gitlab-ci/lava artifacts/
 cp -Rp .gitlab-ci/bin/*_logger.py artifacts/
 
-mapfile -t duplicate_files < <(
-  find src/ -path '*/ci/*' \
-    \( \
-      -name '*.txt' \
-      -o -name '*.toml' \
-      -o -name '*traces*.yml' \
-    \) \
-    -exec basename -a {} + | sort | uniq -d
-)
-if [ ${#duplicate_files[@]} -gt 0 ]; then
-  echo 'Several files with the same name in various ci/ folders:'
-  printf -- '  %s\n' "${duplicate_files[@]}"
-  exit 1
-fi
-
-if [ -d "src/" ]; then
-  find src/ -path '*/ci/*' \
-    \( \
-      -name '*.txt' \
-      -o -name '*.toml' \
-      -o -name '*traces*.yml' \
-    \) \
-    -exec cp -p {} artifacts/ \;
-fi
-cp -Rp .gitlab-ci/*.txt artifacts/
-
 if [ -n "$S3_ARTIFACT_NAME" ]; then
     # Pass needed files to the test stage
     S3_ARTIFACT_TAR="$S3_ARTIFACT_NAME.tar.zst"
     tar c artifacts/ | zstd -o "${S3_ARTIFACT_TAR}"
-    s3_upload "${S3_ARTIFACT_TAR}" "https://${PIPELINE_ARTIFACTS_BASE}/"
+    ci-fairy s3cp --token-file "${S3_JWT_FILE}" "${S3_ARTIFACT_TAR}" "https://${PIPELINE_ARTIFACTS_BASE}/${S3_ARTIFACT_TAR}"
     rm "${S3_ARTIFACT_TAR}"
 fi
 
diff --git a/.gitlab-ci/prepare-artifacts.sh b/.gitlab-ci/prepare-artifacts.sh
index aa46e6897b0..7ce5e874877 100755
--- a/.gitlab-ci/prepare-artifacts.sh
+++ b/.gitlab-ci/prepare-artifacts.sh
@@ -1,5 +1,4 @@
 #!/usr/bin/env bash
-# shellcheck disable=SC2038 # TODO: rewrite the find
 # shellcheck disable=SC2086 # we want word splitting
 # shellcheck disable=SC1091 # paths only become valid at runtime
 
@@ -32,7 +31,8 @@ fi
 
 # Test runs don't pull down the git tree, so put the dEQP helper
 # script and associated bits there.
-echo "$(cat VERSION) (git-$(git rev-parse HEAD | cut -b -10))" > install/VERSION
+git_sha=$(git rev-parse --short=10 HEAD)
+echo "$(cat VERSION) (git-$git_sha)" > install/VERSION
 cp -Rp .gitlab-ci/bare-metal install/
 cp -Rp .gitlab-ci/common install/
 cp -Rp .gitlab-ci/piglit install/
@@ -71,20 +71,11 @@ find src/ -path '*/ci/*' \
   \) \
   -exec cp -p {} install/ \;
 
-# Tar up the install dir so that symlinks and hardlinks aren't each
-# packed separately in the zip file.
-mkdir -p artifacts/
-tar -cf artifacts/install.tar install
-cp -Rp .gitlab-ci/common artifacts/ci-common
-cp -Rp .gitlab-ci/lava artifacts/
-cp -Rp .gitlab-ci/b2c artifacts/
-cp bin/ci/structured_logger.py artifacts/
-
 if [ -n "$S3_ARTIFACT_NAME" ]; then
     # Pass needed files to the test stage
-    S3_ARTIFACT_NAME="$S3_ARTIFACT_NAME.tar.zst"
-    zstd --quiet --threads ${FDO_CI_CONCURRENT:-0} artifacts/install.tar -o ${S3_ARTIFACT_NAME}
-    s3_upload "${S3_ARTIFACT_NAME}" "https://${PIPELINE_ARTIFACTS_BASE}/"
+    S3_ARTIFACT_TAR="$S3_ARTIFACT_NAME.tar.zst"
+    tar -c install | zstd --quiet --threads ${FDO_CI_CONCURRENT:-0} -o ${S3_ARTIFACT_TAR}
+    ci-fairy s3cp --token-file "${S3_JWT_FILE}" ${S3_ARTIFACT_TAR} https://${PIPELINE_ARTIFACTS_BASE}/${S3_ARTIFACT_TAR}
 fi
 
 section_end prepare-artifacts
diff --git a/.gitlab-ci/setup-test-env.sh b/.gitlab-ci/setup-test-env.sh
index f141730d159..8df29f9f938 100644
--- a/.gitlab-ci/setup-test-env.sh
+++ b/.gitlab-ci/setup-test-env.sh
@@ -285,25 +285,6 @@ export -f get_tag_file
 
 # Structured tagging ------
 
-s3_upload() {
-    x_off
-    local file=$1 s3_folder_url=$2
-    if [ ! -f "$file" ] || [[ "$s3_folder_url" != https://*/ ]]
-    then
-      echo "Error: s3_upload incorrect usage."
-      echo "Usage: s3_upload <file> <s3_folder_url>"
-      echo "  - <file> must exist."
-      echo "  - <s3_folder_url> must start with 'https://' and end with '/'."
-      exit 1
-    fi
-    curl --fail --retry-all-errors --retry 4 --retry-delay 60 \
-      --header "Authorization: Bearer $(cat "${S3_JWT_FILE}")" \
-      -X PUT --form file=@"$file" \
-      "$s3_folder_url"
-    x_restore
-}
-export -f s3_upload
-
 export -f error
 export -f trap_err
 
diff --git a/.gitlab-ci/test-source-dep.yml b/.gitlab-ci/test-source-dep.yml
index b19a2d388b6..502334b869f 100644
--- a/.gitlab-ci/test-source-dep.yml
+++ b/.gitlab-ci/test-source-dep.yml
@@ -133,16 +133,9 @@
   extends:
     - .piglit-performance-base
   needs:
-    - debian/baremetal_arm64_test
+    - debian/baremetal_arm64_test-gl
     - debian-arm64-release
 
-.piglit-performance:x86_64:
-  extends:
-    - .piglit-performance-base
-  needs:
-    - kernel+rootfs_x86_64
-    - debian-release
-
 # Mesa source file dependencies that may impact any GL driver test job.
 .gallium-core-rules:
   rules:
@@ -155,6 +148,7 @@
         - src/gallium/frontends/dri/*
         - src/gallium/frontends/glx/**/*
         - src/gallium/targets/**/*
+        - src/gallium/tests/**/*
         - src/gallium/winsys/*
       when: on_success
 
diff --git a/.gitlab-ci/test/gitlab-ci.yml b/.gitlab-ci/test/gitlab-ci.yml
index a55c2bfd7de..3df0ef9752d 100644
--- a/.gitlab-ci/test/gitlab-ci.yml
+++ b/.gitlab-ci/test/gitlab-ci.yml
@@ -2,12 +2,11 @@
   # Cancel job if a newer commit is pushed to the same branch
   interruptible: true
   variables:
-    GIT_STRATEGY: none # testing doesn't build anything from source
+    GIT_STRATEGY: none  # testing doesn't build anything from source
+  # `before_script:` is only used by test jobs on generic fdo runners
+  # it's overwritten by hardware test jobs
   before_script:
-    - !reference [default, before_script]
-    # Note: Build dir (and thus install) may be dirty due to GIT_STRATEGY
-    - rm -rf install
-    - tar -xf artifacts/install.tar
+    - !reference [.download_s3, before_script]
     - section_start ldd_section "Checking ldd on driver build"
     - LD_LIBRARY_PATH=install/lib find install/lib -name "*.so" -print -exec ldd {} \;
     - section_end ldd_section
@@ -86,11 +85,9 @@ yaml-toml-shell-py-test:
     - uncollapsed_section_start tomllint "tomllint"
     - echo "If your change looks right but this script rejects it, contact @eric (GitLab) / eric_engestrom (IRC)."
     - python3 bin/toml_lint.py
-    - section_end tomllint
-    - section_start yamllint "yamllint"
+    - uncollapsed_section_switch yamllint "yamllint"
     - .gitlab-ci/run-yamllint.sh
-    - section_end yamllint
-    - section_start shellcheck "shellcheck"
+    - uncollapsed_section_switch shellcheck "shellcheck"
     - .gitlab-ci/run-shellcheck.sh
     - section_end shellcheck
     - .gitlab-ci/run-pytest.sh
@@ -130,6 +127,7 @@ yaml-toml-shell-py-test:
     - !reference [.required-for-hardware-jobs, needs]
   variables:
     DEBIAN_ARCH: amd64
+    S3_ARTIFACT_NAME: mesa-x86_64-default-debugoptimized
 
 .test-vk:
   extends:
@@ -141,6 +139,7 @@ yaml-toml-shell-py-test:
     - !reference [.required-for-hardware-jobs, needs]
   variables:
     DEBIAN_ARCH: amd64
+    S3_ARTIFACT_NAME: mesa-x86_64-default-debugoptimized
 
 .test-cl:
   extends:
@@ -149,6 +148,8 @@ yaml-toml-shell-py-test:
   needs:
     - debian/x86_64_test-gl
     - !reference [.required-for-hardware-jobs, needs]
+  variables:
+    S3_ARTIFACT_NAME: mesa-x86_64-default-debugoptimized
 
 .test-android:
   extends:
@@ -158,6 +159,7 @@ yaml-toml-shell-py-test:
     # This is for the guest artifacts from debian-android which will be
     # downloaded explicitly by cuttlefish-runner.sh
     S3_ANDROID_ARTIFACT_NAME: mesa-x86_64-android-debug
+    S3_ARTIFACT_NAME: mesa-x86_64-default-debugoptimized
     # Set the default Vulkan driver to lavapipe for some preliminary checks
     # that Cuttlefish always performs before starting the VM. This can be
     # overwritten depending on the physical machine running the job.
@@ -181,7 +183,11 @@ yaml-toml-shell-py-test:
   variables:
     ANGLE_TAG: ${CONDITIONAL_BUILD_ANGLE_TAG}
 
-.b2c-vkd3d-proton-test:
+.test-piglit:
+  variables:
+    PIGLIT_TAG: ${CONDITIONAL_BUILD_PIGLIT_TAG}
+
+.test-vkd3d-proton:
   variables:
     HWCI_TEST_SCRIPT: install/vkd3d-runner.sh
 
@@ -195,6 +201,8 @@ yaml-toml-shell-py-test:
       - results/
     exclude:
       - results/*.shader_cache
+  extends:
+    - .test-piglit
   variables:
     # until we overcome Infrastructure issues, give traces extra 5 min before timeout
     DEVICE_HANGING_TIMEOUT_SEC: 600
@@ -209,7 +217,7 @@ yaml-toml-shell-py-test:
 
 .deqp-test:
   script:
-    - rm -rf results # Clear out old results if the docker container was cached
+    - rm -rf results  # Clear out old results if the docker container was cached
     - ./install/deqp-runner.sh
   artifacts:
     exclude:
@@ -260,62 +268,98 @@ yaml-toml-shell-py-test:
       junit: results/junit.xml
 
 # ARM testing of bare-metal boards attached to an x86 gitlab-runner system
-.baremetal-test-arm32:
+.baremetal-test-arm32-gl:
   extends:
     - .baremetal-test
-    - .use-debian/baremetal_arm32_test
+    - .use-debian/baremetal_arm32_test-gl
   variables:
     DEBIAN_ARCH: armhf
     S3_ARTIFACT_NAME: mesa-arm32-default-debugoptimized
   needs:
-    - debian/baremetal_arm32_test
+    - debian/baremetal_arm32_test-gl
     - job: debian-arm32
       artifacts: false
     - !reference [.required-for-hardware-jobs, needs]
 
 # ARM64 testing of bare-metal boards attached to an x86 gitlab-runner system
-.baremetal-test-arm64:
+.baremetal-test-arm64-gl:
+  extends:
+    - .baremetal-test
+    - .use-debian/baremetal_arm64_test-gl
+  variables:
+    DEBIAN_ARCH: arm64
+    S3_ARTIFACT_NAME: mesa-arm64-default-debugoptimized
+  needs:
+    - debian/baremetal_arm64_test-gl
+    - job: debian-arm64
+      artifacts: false
+    - !reference [.required-for-hardware-jobs, needs]
+
+# ARM64 testing of bare-metal boards attached to an x86 gitlab-runner system
+.baremetal-test-arm64-vk:
   extends:
     - .baremetal-test
-    - .use-debian/baremetal_arm64_test
+    - .use-debian/baremetal_arm64_test-vk
   variables:
     DEBIAN_ARCH: arm64
     S3_ARTIFACT_NAME: mesa-arm64-default-debugoptimized
   needs:
-    - debian/baremetal_arm64_test
+    - debian/baremetal_arm64_test-vk
     - job: debian-arm64
       artifacts: false
     - !reference [.required-for-hardware-jobs, needs]
 
 # ARM32/64 testing of bare-metal boards attached to an x86 gitlab-runner system, using an asan mesa build
-.baremetal-arm32-asan-test:
+.baremetal-arm32-asan-test-gl:
   variables:
     S3_ARTIFACT_NAME: mesa-arm32-asan-debugoptimized
     DEQP_FORCE_ASAN: 1
   needs:
-    - debian/baremetal_arm32_test
+    - debian/baremetal_arm32_test-gl
     - job: debian-arm32-asan
       artifacts: false
     - !reference [.required-for-hardware-jobs, needs]
 
-.baremetal-arm64-asan-test:
+.baremetal-arm64-asan-test-gl:
   variables:
     S3_ARTIFACT_NAME: mesa-arm64-asan-debugoptimized
     DEQP_FORCE_ASAN: 1
   needs:
-    - debian/baremetal_arm64_test
+    - debian/baremetal_arm64_test-gl
     - job: debian-arm64-asan
       artifacts: false
     - !reference [.required-for-hardware-jobs, needs]
 
-.baremetal-arm64-ubsan-test:
+.baremetal-arm64-asan-test-vk:
+  variables:
+    S3_ARTIFACT_NAME: mesa-arm64-asan-debugoptimized
+    DEQP_FORCE_ASAN: 1
+  needs:
+    - debian/baremetal_arm64_test-vk
+    - job: debian-arm64-asan
+      artifacts: false
+    - !reference [.required-for-hardware-jobs, needs]
+
+.baremetal-arm64-ubsan-test-gl:
+  extends:
+    - .baremetal-test
+    - .use-debian/baremetal_arm64_test-vk
+  variables:
+    S3_ARTIFACT_NAME: mesa-arm64-ubsan-debugoptimized
+  needs:
+    - debian/baremetal_arm64_test-vk
+    - job: debian-arm64-ubsan
+      artifacts: false
+    - !reference [.required-for-hardware-jobs, needs]
+
+.baremetal-arm64-ubsan-test-vk:
   extends:
     - .baremetal-test
-    - .use-debian/baremetal_arm64_test
+    - .use-debian/baremetal_arm64_test-vk
   variables:
     S3_ARTIFACT_NAME: mesa-arm64-ubsan-debugoptimized
   needs:
-    - debian/baremetal_arm64_test
+    - debian/baremetal_arm64_test-vk
     - job: debian-arm64-ubsan
       artifacts: false
     - !reference [.required-for-hardware-jobs, needs]
@@ -323,7 +367,7 @@ yaml-toml-shell-py-test:
 .baremetal-deqp-test:
   variables:
     HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
-    FDO_CI_CONCURRENT: 0 # Default to number of CPUs
+    FDO_CI_CONCURRENT: 0  # Default to number of CPUs
 
 # For Valve's bare-metal testing farm jobs.
 .b2c-test:
@@ -376,6 +420,9 @@ yaml-toml-shell-py-test:
     B2C_JOB_TEMPLATE: "${CI_B2C_ARTIFACTS}/b2c.yml.jinja2.jinja2"
     JOB_FOLDER: "job_folder"
 
+    # Assume by default this is running deqp, as that's almost always true
+    HWCI_TEST_SCRIPT: install/deqp-runner.sh
+
   needs:
     - job: python-artifacts
       artifacts: true
diff --git a/.gitlab-ci/tests/utils/test_lava_log.py b/.gitlab-ci/tests/utils/test_lava_log.py
index 9d9f6d9713d..7fa9423e0bd 100644
--- a/.gitlab-ci/tests/utils/test_lava_log.py
+++ b/.gitlab-ci/tests/utils/test_lava_log.py
@@ -118,19 +118,15 @@ def test_gl_sections():
     section_types = [s.type for s in lf.section_history]
 
     assert "section_start" in parsed_lines[0]
-    assert "collapsed=true" not in parsed_lines[0]
+    assert "collapsed=true" in parsed_lines[0]
     assert "section_end" in parsed_lines[1]
     assert "section_start" in parsed_lines[2]
-    assert "collapsed=true" not in parsed_lines[2]
+    assert "collapsed=true" in parsed_lines[2]
     assert "section_end" in parsed_lines[3]
     assert "section_start" in parsed_lines[4]
-    assert "collapsed=true" not in parsed_lines[4]
-    assert "section_end" in parsed_lines[5]
-    assert "section_start" in parsed_lines[6]
-    assert "collapsed=true" in parsed_lines[6]
+    assert "collapsed=true" in parsed_lines[4]
     assert section_types == [
         # LogSectionType.LAVA_BOOT,  True, if LogFollower started with Boot section
-        LogSectionType.TEST_DUT_SUITE,
         LogSectionType.TEST_SUITE,
         LogSectionType.TEST_CASE,
         LogSectionType.LAVA_POST_PROCESSING,
diff --git a/.gitlab-ci/vkd3d-runner.sh b/.gitlab-ci/vkd3d-runner.sh
index 36737e18f6f..401baa50f89 100755
--- a/.gitlab-ci/vkd3d-runner.sh
+++ b/.gitlab-ci/vkd3d-runner.sh
@@ -3,7 +3,7 @@
 
 . "${SCRIPTS_DIR}/setup-test-env.sh"
 
-set -e
+set -eu -o pipefail
 
 comma_separated() {
   local IFS=,
@@ -21,7 +21,7 @@ INSTALL=$(realpath -s "$PWD"/install)
 # Modifiying here directly LD_LIBRARY_PATH may cause problems when
 # using a command wrapper. Hence, we will just set it when running the
 # command.
-export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:$INSTALL/lib/:/vkd3d-proton-tests/x64/"
+export LD_LIBRARY_PATH="${LD_LIBRARY_PATH:-}:$INSTALL/lib/:/vkd3d-proton-tests/lib/"
 
 
 # Set the Vulkan driver to use.
@@ -43,7 +43,7 @@ fi
 # Sanity check to ensure that our environment is sufficient to make our tests
 # run against the Mesa built by CI, rather than any installed distro version.
 MESA_VERSION=$(cat "$INSTALL/VERSION")
-if ! vulkaninfo | grep driverInfo | tee /tmp/version.txt | grep -F "Mesa $MESA_VERSION"; then
+if ! vulkaninfo 2>/dev/null | grep driverInfo | tee /tmp/version.txt | grep -qF "Mesa $MESA_VERSION"; then
     printf "%s\n" "Found $(cat /tmp/version.txt), expected $MESA_VERSION"
     exit 1
 fi
@@ -51,7 +51,10 @@ fi
 # Gather the list expected failures
 EXPECTATIONFILE="$RESULTS_DIR/$GPU_VERSION-vkd3d-fails.txt"
 if [ -f "$INSTALL/$GPU_VERSION-vkd3d-fails.txt" ]; then
-    grep -vE '^(#|$)' "$INSTALL/$GPU_VERSION-vkd3d-fails.txt" | sort > "$EXPECTATIONFILE"
+    # Ignore the grep "failure" if the file exists but contains only comments
+    # or empty lines; the expectation file used will be empty in this case,
+    # which is not a problem.
+    grep -vE '^(#|$)' "$INSTALL/$GPU_VERSION-vkd3d-fails.txt" | sort > "$EXPECTATIONFILE" || true
 else
     printf "%s\n" "$GPU_VERSION-vkd3d-fails.txt not found, assuming a \"no failures\" baseline."
     touch "$EXPECTATIONFILE"
@@ -89,17 +92,13 @@ fi
 printf "%s\n" "Running vkd3d-proton testsuite..."
 
 LOGFILE="$RESULTS_DIR/vkd3d-proton-log.txt"
-TEST_LOGS="$RESULTS_DIR/test-logs"
-(cd /vkd3d-proton-tests && tests/test-runner.sh x64/bin/d3d12 --jobs "${FDO_CI_CONCURRENT:-4}" --output-dir "$TEST_LOGS" | tee "$LOGFILE")
+TEST_LOGS="/test-logs"
+pushd /vkd3d-proton-tests
+tests/test-runner.sh ./d3d12 --jobs "${FDO_CI_CONCURRENT:-4}" --output-dir "$TEST_LOGS" | tee "$LOGFILE" || true
+popd
 
 printf '\n\n'
 
-# Check if the executable finished (ie. no segfault).
-if ! grep -E "^Finished" "$LOGFILE" > /dev/null; then
-    error "Failed, see ${ARTIFACTS_BASE_URL}/results/vkd3d-proton-log.txt"
-    exit 1
-fi
-
 # Print list of flakes seen this time
 flakes_seen=()
 for flake in "${flakes[@]}"; do
@@ -114,12 +113,17 @@ if [ ${#flakes_seen[@]} -gt 0 ]; then
   printf >&2 '  %s\n' "${flakes_seen[@]}"
 fi
 
-# Collect all the failures
-mapfile -t fails < <(grep -oE "^FAILED .+$" "$LOGFILE" | cut -d' ' -f2 | sort)
+# Collect all the failures; ignore grep "failure" if there are none
+fails_lines=$(grep -oE "^FAILED .+$" "$LOGFILE" | cut -d' ' -f2 | sort) || true
+if [ -n "$fails_lines" ]; then
+  mapfile -t fails < <(echo "$fails_lines")
+else
+  fails=()
+fi
 
 # Save test output for failed tests (before excluding flakes)
 for failed_test in "${fails[@]}"; do
-  cp "$TEST_LOGS/$failed_test.log" "$RESULTS/$failed_test.log"
+  cp "$TEST_LOGS/$failed_test.log" "$RESULTS_DIR/$failed_test.log"
 done
 
 # Ignore flakes when comparing
@@ -129,11 +133,11 @@ for flake in "${flakes[@]}"; do
   done
 done
 
-RESULTSFILE="$RESULTS/$GPU_VERSION.txt"
+RESULTSFILE="$RESULTS_DIR/$GPU_VERSION.txt"
 for failed_test in "${fails[@]}"; do
-  if ! grep -qE "$failed_test end" "$RESULTS/$failed_test.log"; then
+  if ! grep -qE "$failed_test end" "$RESULTS_DIR/$failed_test.log"; then
     test_status=Crash
-  elif grep -qE "Test failed:" "$RESULTS/$failed_test.log"; then
+  elif grep -qE "Test failed:" "$RESULTS_DIR/$failed_test.log"; then
     test_status=Fail
   else
     test_status=Unknown
@@ -147,7 +151,7 @@ for expected_fail_line in "${expected_fail_lines[@]}"; do
   test_name=$(cut -d, -f1 <<< "$expected_fail_line")
   if [ ! -f "$TEST_LOGS/$test_name.log" ]; then
     test_status='UnexpectedImprovement(Skip)'
-  elif [ ! -f "$RESULTS/$test_name.log" ]; then
+  elif [ ! -f "$RESULTS_DIR/$test_name.log" ]; then
     test_status='UnexpectedImprovement(Pass)'
   else
     continue
diff --git a/.gitlab-ci/windows/mesa_build.ps1 b/.gitlab-ci/windows/mesa_build.ps1
index 5c17c9dabf1..ef27ac0e5ff 100644
--- a/.gitlab-ci/windows/mesa_build.ps1
+++ b/.gitlab-ci/windows/mesa_build.ps1
@@ -53,7 +53,6 @@ meson setup `
 -Dvideo-codecs="all" `
 -Dgles1=enabled `
 -Dgles2=enabled `
--Dgallium-opencl=icd `
 -Dgallium-rusticl=false `
 -Dmicrosoft-clc=enabled `
 -Dstatic-libclc=all `
diff --git a/.pick_status.json b/.pick_status.json
deleted file mode 100644
index 81921c977e0..00000000000
--- a/.pick_status.json
+++ /dev/null
@@ -1,7402 +0,0 @@
-[
-    {
-        "sha": "84b9c281fe82dd66f2552687cecb61a8e22809d0",
-        "description": "radv: Return VK_ERROR_INCOMPATIBLE_DRIVER for unsupported devices",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5d72ebf3e7bb392126ce68dcecbdaaa5d05db343",
-        "description": "nvk: Stop printing errors for invalid dma-buf image queries",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "63557a03dfd4e9b41c4bef55dac6899d41350872",
-        "description": "mailmap: update my name and email",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e3e7dad82db882859fc5044d92f9fad6bdba86b4",
-        "description": "nak: Stop relying on nir_lower_pack",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "efd1cddbe90f4af26716adfb6a6cc12eca1d71b3",
-        "description": "nak: Set lower_pack_64_4x16",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "140cd7c4f4f0bcd27b627d1122cd76b033728381",
-        "description": "v3dv/ci: document flakes seen over the last 7 days",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6a18569aa51cdb802c64fd08373df40555c0579c",
-        "description": "v3d/ci: document flakes seen over the last 7 days",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bf643bbcf68ac950cf0101d4ce90d728db7dabca",
-        "description": "vc4/ci: document flakes seen over the last 7 days",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "df3618edc214e6ff6b873f939dcc590a6edab003",
-        "description": "v3dv/ci: fix malformatted flakes line",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "daad392d5c3c4f8887b6792c45ad183164e501b5",
-        "description": "virtio/vpipe: Correct vdrm_vpipe_connect() definition",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "bf0e3d6274bac0190a6d4d90afbd2a9a6bec249d",
-        "notes": null
-    },
-    {
-        "sha": "9ca71b52aa5bc2eda1f08149f7780e59858ee27b",
-        "description": "aco: swap the correct v_mov_b32 if there are two of them",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "408fa33c092810155baac342de90fd712231aa89",
-        "notes": null
-    },
-    {
-        "sha": "2f4f9f0b98b488a621051f9a68da33ce25782e66",
-        "description": "hk: Implement VK_EXT_map_memory_placed",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0acb34b065b7db4df20c2a38bd2a0dfdfc2c48bd",
-        "description": "hk: use nir_lower_default_point_size",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a49403f4aca7a0537fe8bc036e730ad1dee789e4",
-        "description": "agx/nir_lower_tess: use nir_lower_default_point_size",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d53a3a081b598461794d0eab7a11e5c03f193360",
-        "description": "agx/nir_lower_gs: use nir_lower_default_point_size",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5788770d91cbd7328afd521ba0e4b284264c5d36",
-        "description": "nir: add nir_lower_default_point_size pass",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9ce14a5787fb52809afeb5d5fd1b918b20e71aec",
-        "description": "nak: Remove #![allow(unstable_name_collisions)]",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7edb08668590e5040faf669e1c700a2b51475a8a",
-        "description": "nak: Call nir_opt_phi_to_bool",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c0dfdc907ba3acefe2a7a1382123e788ad508b16",
-        "description": "tu: allow bigger block sizes when copying between buffers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ae51c59663db80bd39e2e84c3ac8c3aee4512ab6",
-        "description": "broadcom/ci: update expected results",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c434050a0088ec3f07d63fd1019aea541632faed",
-        "description": "brw: add pre ray trace intrinsic moves",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "37608c075f279cfe57c66d907e92e0cd4b9ef67c",
-        "description": "anv: promote VK_EXT_robustness2 to VK_KHR_robustness2",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f03be478a9cb81a800c719fc116c2b1b769170f5",
-        "description": "tu/lrz: Add tu_ignore_frag_depth_direction driconf",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "847ad80e03e3cf90d005c8393829588005716917",
-        "description": "tu/lrz: Consider FS depth layout when gl_FragDepth is written",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d05b92d72003e6f2331dc05fc5e97afad3472e02",
-        "description": "tu: Add \"check_cmd_buffer_status\" debug option",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "86d21fd2cfec075797acac05552e3bd10b2ee59e",
-        "description": "anv: Set tc/beta offset according to the flag from PPS.",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "79981063552ce879ca64ce58eb70754b28d6d1ae",
-        "description": "vulkan/video: Fix wrong parsing for H265 decoding",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "20543981b56f4032daf0f3543eae53e6771e1c8e",
-        "description": "nak: Print the % for SSA predicates",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "56bdf9043b5e223eeaca007d0cd0f3f0d789b257",
-        "description": "nak: Move SSAValue and friends to a new ssa_value.rs file",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9d1c38ddf11202805ac8e281ddd34940f8ad68a6",
-        "description": "nak: Check that swizzles are none",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "bad23ddb4849908a648d503a615a5a9b15e9768a",
-        "notes": null
-    },
-    {
-        "sha": "6e72f0f81b05a02341fb68c9d6de96c33ec5ca96",
-        "description": "nak: Add Src::is_unmodified() helper",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "bad23ddb4849908a648d503a615a5a9b15e9768a",
-        "notes": null
-    },
-    {
-        "sha": "d91ba8f36d04137d33d0c621ec77efcef5420c11",
-        "description": "nak: Mark Large SSARef paths as cold",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2f44970b683530ae0e172b2aea984d08df991453",
-        "description": "nak: Support large SSARef",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "dee3a0aa58f288bbd0069be8e1c83dab9c2e2391",
-        "description": "nak: CBuf and SSARef are no longer Copy",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "68069fb8105e52c8bcef9616a0826e7a7c0ae653",
-        "description": "nak: SrcRef is no longer Copy",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a9d27892372f9ed67ba86bc16018733249abd813",
-        "description": "nak: Src is no longer Copy",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "30f6ca6391411d39a65665d8e43dcb9f977691bc",
-        "description": "nak: Replace Src::new_zero() with a ZERO constant",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f21557154be06f76b9f92d79eb84e8c6ebe2d216",
-        "description": "nak/from_nir: Turn srcs into a closure",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "854b2d5882c0f95a509c5e9ef41eda4f2e1452b2",
-        "description": "nak: Dst is no longer Copy",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0ac3296f28f5c4402eec438e4e708cfbd4e6c20e",
-        "description": "nak/from_nir: Make fault an Option<SSAValue>",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ddcf0029cdabda7b8879a1da9aa010995fdab7c7",
-        "description": "nak: Use references to src/dst more places",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ffe438c77d173fc639d84081a1b3e64e134de337",
-        "description": "nak: Return SSAValue from builder where possible",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b9e9a811b84c6033af60792656647183f4c7b501",
-        "description": "nak: Split scalar/vec in SSABuilder::alloc_ssa",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1ff9848d25bd68eeb927ff92add2703cc2aa5f6e",
-        "description": "nak: Use NonZeroU32 for SSAValue and remove NONE",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "121b2b889bc09cd035b954d2312bad0584d57c8f",
-        "description": "nak: Add an SSARef::from_iter() helper",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4f07092bdba3d6eaedd572050d98571a632d02e3",
-        "description": "venus: fix to passively enable wsi required extensions",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "06f5d1a1052a1f7fb2c530ea22b1fc6e261d1821",
-        "notes": null
-    },
-    {
-        "sha": "149bad63ea3eb6376bfd737b06a21182f930655c",
-        "description": "Uprev Piglit to 1498c397ea35119692b579dd6f523de4651c663f",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2f8b27713d1f0b54ae2d5fe7cce9218b17c0ffd6",
-        "description": "nak: Fold Src::fold_imm() into the legalization pass",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c3417c3c8248b6f2b021cf8f1a3aa1bf5a6cd358",
-        "description": "nak: Use as_u32() directly in Src::is_fneg_zero()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "274be4291e0d1b6000eec4c3c6d80d6e03366ec3",
-        "description": "nak: Handle SrcType::F64 in Src::is_fneg_zero()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8a4ffe3c7ef477f21e9fb0f77ba15a48293cdbb2",
-        "description": "nak: Fold source modifiers in Src::as_u32()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4648a1547674bbfe37bf2b9a2ec19c3d1dc22967",
-        "description": "nak: Take a SrcType in Src::as_u32()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4b5eec6c2a80d18994724046cf365b43b08cb520",
-        "description": "nak/sm20: Use SrcRef::as_u32()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cb156a468ec05ec0f082b98b7692f01ea13ec479",
-        "description": "nak: Match on the SrcRef directly in Src::is_nonzero()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a82b5696498e333a2e9ab957bceb6d1d269e9cdc",
-        "description": "anv: Reduce memory pool usage in MTL and ARL",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "ea18572ff287f9a024e4dbcffc7d833e777e4c7b",
-        "notes": null
-    },
-    {
-        "sha": "7c78c76181db01790163a1b720fbf1137b2b3499",
-        "description": "iris/xe: take the grids variable_shared_mem into account",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fee9230bb518e9a688e65e6125d9cbe4f8ad8cff",
-        "description": "iris/xe: fix compute shader start address",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "57ccfd0502953124df1d245d1a4e529c0fe8661c",
-        "description": "iris: parse global bindings for every gen",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8447f7aaae41ce88587aedb77acafb571a6763b8",
-        "description": "pan/genxml: Fix inverted logic on nr_regs",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "811525b543b5a0581af9bb4b17bb92edbde6fe0a",
-        "notes": null
-    },
-    {
-        "sha": "1aa5fd5da2b17706290e76bb377c2f6a4d93d299",
-        "description": "radv: promote VK_EXT_robustness2 to VK_KHR_robustness2",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4e09a5c9927ff63525cbc5204af324a4c389b809",
-        "description": "vulkan: Update XML and headers to 1.4.314",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "02d7c8f9d3787209d7227c440e5663745eb27f8c",
-        "description": "spirv: Update the JSON and headers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7e0f157b8a335eb04d05471fc4280fd11fb573c5",
-        "description": "ci: pass vk_require_etc2 from radv jobs through to the duts",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0684dc5fa89287504cb086450a55df3ca946dba5",
-        "description": "radv: fix GPU hangs with image copies for ASTC/ETC2 formats on transfer queue",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b8c47c55357cb4b6f933249efa41406733a2c39b",
-        "description": "turnip/ci: Update expectations",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8b835a4abb0240d412c3190210800bdc38dac155",
-        "description": "freedreno/ci: Document regressions",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0f5ab7af3d0b38111f72fbf7db13b6a404f1d36a",
-        "description": "anv/ci: Update expectations",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9ac2b73cf42168b9658761e14fa5dc62bbb79a77",
-        "description": "iris/ci: Update trace checksums",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "31c2fae476f1eb6d048737369942c021b6cdb500",
-        "description": "llvmpipe/ci: document regression in a02b6e6b...676e26ae",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "51c5b7e3f93f3a894eabba69d62520d8f5ca6727",
-        "description": "etnaviv/ci: document two fixed tests",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7b14b1d350d1703043d314052e4c9d4cd3500a0d",
-        "description": "lavapipe/ci: document flakes (including a flaky timeout) seen recently",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5cf33e67043721db8c961b6fd3332cbb42907d37",
-        "description": "zink+nvk/ci: document flakes seen recently",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5b958bd18f70ae831e2fa0309440029c2f00b77f",
-        "description": "zink+radv/ci: document flakes seen recently",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "32fe00280a45f0fe2ffc78579f17eda268736a79",
-        "description": "turnip/ci: document flakes seen recently",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c145f7f2dc26ac36c86752772fd03b49923b83a1",
-        "description": "radeonsi/ci: document flakes seen recently",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a601d688988a91339a0b78bb3a88f985c1025b68",
-        "description": "radv/ci: document flakes seen recently",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "75880655f836e173a09c75955fe7a85f84037b06",
-        "description": "nir/lower_gs_intrinsics: silence warning",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bc49045294a3dd899cd2ebbbc1adebef22021d09",
-        "description": "nir/opt_shrink_vectors: add assume to silence warning",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5629332dcf9e3a7219af384b2b469289b3e4a325",
-        "description": "util: silence -Wstringop-overread in SHA1",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2797f42451ced49cdca1836350bf058c121e97ef",
-        "description": "tu: Fix disable_fs state update condition",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "be481e66159316b7147d82be3d87b0b63c9e624d",
-        "notes": null
-    },
-    {
-        "sha": "969820e7fe95a2465d14ebd719f16abbf8729e76",
-        "description": "tu/lrz: Disable LRZ if RP writes depth but doesn't set on GPU dir",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f903397874cfaa364b4a9a2d0f8f7d2597925915",
-        "description": "tu/lrz: Call tu_lrz_write_disable_reason once per RP",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6d84dac8276246ba267772358d24c5a8bb3df565",
-        "description": "tu/lrz: Fix NOLRZ dbg option",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9d20241a03108e60f0ddc6a331a8032b2bff22bb",
-        "description": "tu/lrz: Fix DONT_CARE not resulting in disabled LRZ",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "06f5d1a1052a1f7fb2c530ea22b1fc6e261d1821",
-        "description": "venus: expose WSI on renderer without dma-buf support",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f177b787b83ce80221a2070740b0544078e8693f",
-        "description": "ci: Drop obsolete -Wno-error= stanzas",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1356d2004287354fdd959f495097ad6be4a34dcb",
-        "description": "radv: disable SINGLE clear codes to workaround a hw bug with DCC on GFX11",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "55ad0fd35c600538150f4c94ca2f03024cb0076b",
-        "description": "radv: do not clear unwritten color attachments with dual-source blending",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "e1483d022b28218bd53aea1c4917739cf0398b3e",
-        "notes": null
-    },
-    {
-        "sha": "32d9afdf734ee776012c1565d9683ab1a4142877",
-        "description": "nir/printf: add new helper to printf at a specific pixel.",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "43f22110e7a99b5f5b67f05a273741feb595cc8e",
-        "description": "nir/printf: break out va_list handling",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e0a111540f0f54c7ff0f0d0b046f184f033008f7",
-        "description": "util/driconf: add force_gl_depth_component_type_int workaround",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e7ce35f3c503e547b48499c3a5b2391382c579a7",
-        "description": "ci/fluster: Fix and rename S3_PATH_FLUSTER to S3_FLUSTER_TAR",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "a3fb667b1d4bda3ca10d4fa20924f61d6c28af4d",
-        "notes": null
-    },
-    {
-        "sha": "4a614cfbfb245f239b9173ab7303a95f99f9945c",
-        "description": "amd/ci: Remove increased timeout for radeonsi-raven-vaapi-fluster job",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f6f7f9e7a2f4561eba8f4ac7a89a87d92f6cbe6b",
-        "description": "ci/fluster: Use the structured tag as the Fluster vector version",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b01a091856e19c6cea3b183b5ce60516111a4247",
-        "description": "ci/fluster: Use structured tagging for Fluster",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3ca7897ba90740485c7420b844769ba79232fd6f",
-        "description": "ci/fluster: Move Fluster to its own subfolder in the test-video container",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1bc853f2a00cb8bf4cdf111c74a5733f5bb88e59",
-        "description": "ci/fluster: Add sections to job logs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "46abb7bd2eb543380c64cca7f9ca97263c86f553",
-        "description": "ci/fluster: Move the fluster-runner.sh script",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9cf5c01d0c37f6c9ace05e1ded96eaf5cbbb8fd7",
-        "description": "amd/ci: Rename .radeonsi-raven-vaapi-fluster to .radeonsi-vaapi-fluster-rules",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c90e1ba5cc3c06b32d85795871302f99c9ca963a",
-        "description": "ci/test: Move and rename .lava-fluster to .test-fluster",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7f0de1a51212881c9a7614327bf3e1fbc9784ddb",
-        "description": "ac: remove gfx11_emulate_clear_state",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5e487dbc49e5be57a1da255ae31fe642bd42f815",
-        "description": "amd: stop using CLEAR_STATE on gfx11",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cf9b0dd5896676b831f9e842555dcdd534f109ba",
-        "description": "anv, hasvk: ignore QFOT if both src and dst queue families are equal",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c1dbfa0e0ff56467d3581690f6db4b78e817729a",
-        "description": "freedreno/a6xx: Implement fast border colors in sampler",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3691694933c3d3c6a9f6b7f6dda4452ac141af9a",
-        "description": "tu: Remove builtin border color logic",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a1cf7054d9ca3854724df0a3a9c31cae79b5cf98",
-        "description": "tu: Implement fast border colors in sampler",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4690637acd5d62170006cc33946f57672144708c",
-        "description": "freedreno/regs: Document fast border color in sampler",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "02337aec715c25dae7ff2479d986f831c77fe536",
-        "description": "virgl/ci: update flakes",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8949e4a7ec7a3503386271697cc45d1c68a7fe54",
-        "description": "ci: add libproc2-0",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "27020be893518492a621fb7283f6947da7bedf63",
-        "description": "ci: angle: fix depot-tools dependency release",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6427e57e3393f0a4ba3df25f4ee965078c7fa6a1",
-        "description": "freedreno/percntr: Expose LRZ derived counters",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4cb358f1c2707494b09ae590cf11e3165fb0166d",
-        "description": "radv: Remove offset parameter from radv_make_texel_buffer_descriptor.",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "96765935e83d6014e2d5f49b4b859afdfd5cb236",
-        "description": "radv/amdgpu: Fix hash key in radv_amdgpu_winsys_destroy().",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ec3011ed0470d90987a35cb3be751cd20c64f0ca",
-        "description": "gallium: remove pipe_grid_info::input",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6730b8b228ac47f1bb7803189fd14444422bd135",
-        "description": "gallium: remove pipe_grid_info::pc and PIPE_SHADER_IR_NATIVE",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a990ada276d4cbecaa462135e72d94549316f166",
-        "description": "gallium: remove pipe_context::set_compute_resources and PIPE_BIND_COMPUTE_RESOURCE",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "502b821ea3898d5bd8c5cfb25664a2982cfa2f6a",
-        "description": "gallium: remove pipe_compute_state::req_input_mem",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "97b17e7b42932808324f1ceee51ce71ac964d0c6",
-        "description": "gallium: remove pipe_compute_caps::max_input_size",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "76d82f9b2a3e0fac90fe7b2a6f961742507065dd",
-        "description": "gallium: remove pipe_compute_caps::max_private_size",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "44051e6fbdfebcce6607012f7001cf6b52a6804f",
-        "description": "gallium: remove pipe_compute_caps::images_supported",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9d73da915593ea4ee06553008a92b99d1f399eaf",
-        "description": "gallium: remove pipe_compute_caps::ir_target",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e5775ac0e084273d8ed8205879d85d3cc6cc95ff",
-        "description": "gallium: remove pipe_compute_caps::max_threads_per_block_clover",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2deea42ebaac9cd43007d2a881e9f5ac5512799d",
-        "description": "gallium: remove pipe_compute_caps::max_block_size_clover",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2443ce2db61599e58808d846fff098e6b2229588",
-        "description": "gallium: remove pipe_binary_program_header",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c93d80ba9816e36cc35b851ef8be97dba1da1de9",
-        "description": "nvc0: remove support for pipe_grid_info::input",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d7b3ab3bc2fa6adff32e0e130b4d6266673ce4b1",
-        "description": "nv50: move pipe_grid_info::input into the driver",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6416c49247af7586104a86931b175a7b1cc553e9",
-        "description": "radeonsi: remove more clover related code",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "67b9be91be1d83e8c5be135b7caeff5342606738",
-        "description": "r600: remove all clover related code",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f6e3c967d9a1f1c680613d53306a415afb977247",
-        "description": "r600: fix r600_buffer_from_user_memory for rusticl",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7addf551f38b1e8cafae2bb3c4563481971a9947",
-        "description": "ci: drop tracking of removed folder",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "185a3f9105669502b509f06179795a3b45d656f6",
-        "notes": null
-    },
-    {
-        "sha": "3e5a735d01700163d25b1c00ee05b97644da9cf2",
-        "description": "intel/tools: Fix batch buffer decoder",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "ec2d20a70d018736c6ef7cb5bbbe48d82e8c6b4c",
-        "notes": null
-    },
-    {
-        "sha": "63f633557ff53726b7bc8e2292f330ace8624be0",
-        "description": "intel: fix null render target setup logic",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "98cdb9349a7fa181c3895655d217589f909a7beb",
-        "notes": null
-    },
-    {
-        "sha": "1d7a988ec2442feab1f2e3b3bc88ddf72456d311",
-        "description": "vtn: use nir_const_value_for_raw_uint for bfloat SpecConstantOp/FConvert",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "90e1b128903cabfe4fcfb5ae52cf46d5ddbf1189",
-        "notes": null
-    },
-    {
-        "sha": "752f5f317ef72275a4616f1da51a75d7a8405642",
-        "description": "aco: replace max_const_offset_plus_one with max_const_offset",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a85ebe16b37fef0eeeff396bab03df735e2b6620",
-        "description": "aco: fix max_const_offset_plus_one overflow",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "c26851b80b9d8daea4a98da05910e530cd6d80a7",
-        "notes": null
-    },
-    {
-        "sha": "615d0c9669595adf114a705f5b8ee88277aa99f2",
-        "description": "anv: Remove ANV_BO_ALLOC_HOST_CACHED from ANV_BO_ALLOC_MAPPED assert() on anv_device_alloc_bo()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "57bf6466852894a753c5a36a858c0ae5712dbc9b",
-        "description": "anv: Fix assert failure in discrete GPUs when allocating a LMEM+SMEM slab parent",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "dabb012423dc27e2b03f13f7144406edacc89069",
-        "notes": null
-    },
-    {
-        "sha": "8a339cdebccdea0610bdd7a1ecc9a5ec63951940",
-        "description": "egl: fix sw fallback rejection in non-sw EGL_PLATFORM=device",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4d8146befb3502b6f77df7d6e152d25d01201e9e",
-        "description": "egl: rename dri2_load_driver -> dri2_detect_swrast",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "453ecaddb56028e784f0923fca8308fecd10f655",
-        "description": "freedreno: Remove compute_constlen_quirk",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ea9d694a7b363d66dd9e57bc0f55c5fd903632b2",
-        "description": "ir3: Take LB restriction on constlen into account on a7xx",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "5879eaac185ed1c167fd01aff9b91c7cbe43ab0a",
-        "notes": null
-    },
-    {
-        "sha": "80bcbc0e924f7e021bcca155fa12501a2d6fb467",
-        "description": "freedreno/a6xx, turnip: Set CONSTANTRAMMODE correctly",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "5879eaac185ed1c167fd01aff9b91c7cbe43ab0a",
-        "notes": null
-    },
-    {
-        "sha": "57986ae5ec57820e4e06d7674f1496de58f4fd0e",
-        "description": "freedreno/a6xx: Define CONSTANTRAMMODE",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "5879eaac185ed1c167fd01aff9b91c7cbe43ab0a",
-        "notes": null
-    },
-    {
-        "sha": "156ab5839d045ea291a47789014ce61ddbad0804",
-        "description": "freedreno: Add compute_lb_size device info",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "5879eaac185ed1c167fd01aff9b91c7cbe43ab0a",
-        "notes": null
-    },
-    {
-        "sha": "6445fd47d8a2a7b2ea1d8a0a306f64e1d25392e5",
-        "description": "docs: add sha sum for 25.0.5",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "36a98e226c547c92f4ecfbdc9a424a93a3eb6000",
-        "description": "docs: add release notes for 25.0.5",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4e9c89e7873724ba3426c44a09b089924b6698c1",
-        "description": "docs: update calendar for 25.0.5",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f17d350001a195c89633f083866c5afb7563f78c",
-        "description": "lima: Move fdot lowering from NIR to lima",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0f747d09900c1507e683a6ff3918691d3d880008",
-        "description": "docs: update calendar for 25.1.0-rc3",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9a97a5d57750906a881144b13ab6e089c203d163",
-        "description": "nak: fix handling of delays > 15",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "2b569ecdb6531228a1c2eac38da310b8cd0f3cfc",
-        "notes": null
-    },
-    {
-        "sha": "c8b57594e0faa5851af44d85cebf4a8036df1106",
-        "description": "ci/baremetal: fix ubsan gl target",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "e16d422da52c2e1990c43ee858a4e06c8dd01346",
-        "notes": null
-    },
-    {
-        "sha": "9d01b318a337507e0b8f2646208d7f21a8038416",
-        "description": "anv,tu: Bypass RMV pcie_family_id check",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2781df4d10a97c08fdc2650233e7842a8655156c",
-        "description": "Revert \"ci: disable Igalia's farm\"",
-        "nominated": false,
-        "nomination_type": 3,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "1eb3a40615e64cd145d1e66c301075b6b8478c5b",
-        "notes": null
-    },
-    {
-        "sha": "9082715ab014270fb8bdf555526d7e55a4890538",
-        "description": "vk/cmd_queue: generate copies for string struct members",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "26cdd7ebd6254376b0250962db1fe6a679391a93",
-        "description": "vk/cmd_queue: generate copies for struct-ptr members",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a7edaaacce7607cb26c86ba1f5bd2347a27ee797",
-        "description": "vk/cmd_queue: stop generating weird casts for free functions",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c3b6122cdf65b73c4c235bd178b8e20e507b47a0",
-        "description": "vk/cmd_queue: try to fix some indentation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f6c5f0c19dae04e27d34f7387c0df1f492af8c01",
-        "description": "ci: Switch cross-builds to '-D tools=panfrost'",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "674c96ad0a4a9b57342c90135fbceb696d7aae46",
-        "description": "panfrost: build panfrost_compile for -Dtools=panfrost",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a228d715b6b3fad7a98dab8807ba5b8d9411c5b3",
-        "description": "asahi: Drop unnecessary idep_mesaclc dependency",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "007d7418f8fb41c1ea789f5049be023312802048",
-        "description": "asahi: build asahi_clc for -Dtools=asahi",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7c4cce5bfd4bb940c4a2cb994b074d3b77b92a56",
-        "description": "etnaviv: compiler: Enable more pack/unpack lowerings",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2193ae0253e5ce72dd1b353ab4e9b5e574a8dd9c",
-        "description": "etnaviv: compiler: Call nir_lower_alu_width(..)",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "68a89bb08563113b99367714b5c9a9dfd6cc9fdf",
-        "description": "etnaviv: compiler: Handle f2f16 and f2f32",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f7bc22e0d726d60a911270ea08fad36d8a52605c",
-        "description": "anv: force fragment shader execution when occlusion queries are active",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5a2ee9b5347da67001b64a835e99fd881f748124",
-        "description": "iris: Remove iris_slab_free cast",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4f0aa96d2625f0fe10deed2cada215eba860d651",
-        "description": "anv: Do conservative oversubscription of pages to 2MB",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2c05488be169a4bb0f8c73744ed7d07237d085e5",
-        "description": "anv: Align size of bos larger than 1MB to 64k to enable 64k pages",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "dde91cf9cbd5c346f2add8662801c4ef1f0b45a1",
-        "description": "anv: Always grow fixed address pools by 2MB in platforms that there is a performance gain",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7361b3287fb2c776d09110d522f91611063b611d",
-        "description": "anv: Remove useless if block",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6f7a32ec928a47a13c408f34b931bb8c634636e9",
-        "description": "anv: Add support for batch buffers in anv_slab_bo in i915",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "39bb51ab274a37e3647641e48073b85f0f92577c",
-        "description": "anv: Add support for batch buffers in anv_slab_bo in Xe KMD",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a0a600ca5fab4dee6df3f36910b138f7656467e4",
-        "description": "anv: Skip anv_bo_pool if memory pool is enabled",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0b561f691bd29f2c6eeb87498ba7fe6d8d2e576e",
-        "description": "anv: Add support for ANV_BO_ALLOC_DYNAMIC_VISIBLE_POOL in anv_slab_bo",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8fd4423d99fa6f46428510733ed5e4ac401ed353",
-        "description": "anv: Add support for ANV_BO_ALLOC_DESCRIPTOR_POOL in anv_slab_bo",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ea18572ff287f9a024e4dbcffc7d833e777e4c7b",
-        "description": "anv: Add support for ANV_BO_ALLOC_AUX_CCS in anv_slab_bo",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "dabb012423dc27e2b03f13f7144406edacc89069",
-        "description": "anv: Implement anv_slab_bo and enable memory pool",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3bf6d42fda02f54e6235d2c0fc6a855b2bd75a66",
-        "description": "anv: Add the base infrastructure to support memory pool",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5d8ec0ce5c6564935d1565d105fa7bd646333e90",
-        "description": "anv: Move VMA alignment requirements to its own function",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4e7ba17413b0869cb5874ecf979ac8ed6adda0c8",
-        "description": "anv: Export anv_bo_is_small_heap()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ce4d48107c0dd727e1cf05ba70cb4a053937cfba",
-        "description": "util: Move pb_slab from gallium to util",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0642708fe8c14a81827a92a4f05b669f3c1f0726",
-        "description": "gallium: Remove pb_buffer.h include from pb_slab.h",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e0a9ec34e7d6f0d4a5b77078f373e0e17d5c0b28",
-        "description": "intel: Add has_partial_mmap_offset to intel_device_info",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "374ef9228bd4bd711463b790611cba16326f3a79",
-        "description": "anv: add ability to mmap at offset",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1d46a663aecd061d50c26a4950fabbb9ed7970f2",
-        "description": "anv: update Wa_22019225126 check",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "eeffb4e674d10db9aefebeca91c2d87c1676b81e",
-        "description": "intel/dev: update mesa_defs.json from internal database",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "97dc196d427fc67cb1878df62913b82413b924ea",
-        "description": "tu: Add total renderpasses,dispatches to cmdbuf tracepoint",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "99b23235a66e33051140472c2eabd46de1e2af64",
-        "description": "tu: Don't enable secondary command buffer tracepoint by default",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9dfd4a091c83d7a393f3ceac0607cc71e5df0ae8",
-        "description": "tu: Fix segfault in fail_submit KGSL path",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "ec268fa5b666a49adafc431dbc05b73bfd74526e",
-        "notes": null
-    },
-    {
-        "sha": "103a16e4fa36d52bb0dc6325848fbdd7b5c1372f",
-        "description": "frontend/dri: don't call set_damage_region with a null resource",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "29d7b90cfcb67ecc2ff3e422dd7b38898abb1bbe",
-        "description": "brw: make HALT instruction act as barrier in new CSE pass",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "9690bd369d5a6739142eeb23f92d34429b75855d",
-        "notes": null
-    },
-    {
-        "sha": "b9275b54a1c906d2180aee0a12895bd617597b50",
-        "description": "nak/sm70_encode: Remove unused has_mod parameter",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "28d077838f5ba7ae706d7d967163b84b8ca1e41b",
-        "description": "nak/sm70_encode: Encode fneg/fabs for hfma2 src 2",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1ff7135691d9fd3e0135ef5a13f6c95ad259094c",
-        "description": "nak: Remove hfma2 src 1 modifiers",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "567cae69c3efd0070e3b9b8444dc8a24f0f83838",
-        "notes": null
-    },
-    {
-        "sha": "d48b3a232c4989c4dcf4cbc2644fc5fd985af083",
-        "description": "docs: Remove the docs for setting up bare-metal devices",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a587a0a38903e02fbdcb9b23caeed1ce9e8e4320",
-        "description": "docs: Move the docs about caching downloads to LAVA from bare-metal",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6338ed44c519c67b7eb9b6731af1cede52da9438",
-        "description": "aco/gfx12: increase maximum vbuffer offset",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d987d5e341a43dd1704cd04a6b90a1317b9fa074",
-        "description": "aco/gfx12: increase maximum global/scratch offset",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "02d193f05826e5f93b3b1d335eef4f74e577b0d4",
-        "description": "aco/gfx12: increase maximum smem offset",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c26851b80b9d8daea4a98da05910e530cd6d80a7",
-        "description": "aco: increase max_const_offset_plus_one for SMEM load_global",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f390893a64e57c34ee959b17a7b301909627236b",
-        "description": "aco/gfx12: use s_sub_u64",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5b4813c4f0c931952f49eb0909c20f119c39c107",
-        "description": "aco/gfx12: use s_add_u64",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "821c1bfa7e1776177b0323b1d8d4b44f32361f91",
-        "description": "intel/compiler: Fix stackIDs on Xe2+",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b9fe5aad37d20dd767b44528da251e0ed322d3de",
-        "description": "anv: enable VK_KHR_shader_bfloat16",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "07fa3b37855bff1ddd3d157a5a5ffd0f148d9530",
-        "description": "intel: Add support for BFloat16 as cooperative matrix source",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2bbe042e879175703ae63479f9754f4f087a3fd2",
-        "description": "spirv: Enable bfloat16 capabilities",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e0b195cadbb85b33e4d3055f6e1beb8d45722843",
-        "description": "spirv: Use bfdot for SpvOpDot with BFloat16",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "28070976904a087ce304e32deed7bb08619df626",
-        "description": "spirv: Implement Conversions to/from bfloat16",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "90e1b128903cabfe4fcfb5ae52cf46d5ddbf1189",
-        "description": "spirv: Add bfloat16 support to SpecConstantOp",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "dc8074683d78db7cd71120e9ef5fa1c61fb5c72d",
-        "description": "spirv: construct a bfloat16 from the given SPIR-V bitsize and encoding",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fb6ae2eac1fd883d69cca3cdb26c50a7272496dc",
-        "description": "spirv: Refactor to use glsl_type to pick ALU ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bba607ac2b6fd14ce33bbff44fc1684e41541a7a",
-        "description": "spirv: Move Convert opcodes handling to its own function",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d4381c0908a3c2be93ef32300c35b904d4a92ee5",
-        "description": "brw/cmat: Implement conversion from/to BFloat16",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "de88184ab650a140b0c459b386a2755377b8d785",
-        "description": "brw/cmat: Support different src/dst packing factors in emit_packed_alu1",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7fa7be970d5a230a445d3211752b2131d5892989",
-        "description": "brw/cmat: Extract emit_packed_alu1() function",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4b4500ad35dc01d834d235b12c9c3d9514d7ea31",
-        "description": "brw/cmat: Store more information about cmat slices",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a7ff177a88efca7aa3ec8b4a4d0cc724d43d516b",
-        "description": "brw: Consider bfloat16 in lower simd width pass",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2c31516b3ea7067a39b836be17615bb8f28bdabd",
-        "description": "brw: Consider bfloat16 in lower regioning pass",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5936768ce0b862b39322a6917da2f59477e3bdbe",
-        "description": "brw: Consider bfloat16 in copy propagation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "129c0748112fbe7b43a214f293c82e5db2f0bf69",
-        "description": "brw: Implement support for BFloat16 ALU opcodes",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a38960e8f37e667442255aba73cf7dd4cff2e215",
-        "description": "brw, nir: Use glsl_base_type instead of nir_alu_type for @dpas_intel",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cf4021f93c3774f690ec5327c000b2742f8a7428",
-        "description": "nir: Add opcodes for BFloat16",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9e5d7eb88d7046fc6dd5c6ef85f9ae7e898702cd",
-        "description": "compiler/types: add a bfloat16 type",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ecd2d2cf46dfc3305a6dc1497815b7b54eef513e",
-        "description": "util: Add functions to convert float to/from bfloat16",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3e0418ba02d40eb209519bc8d847481f516fc6d6",
-        "description": "intel/executor: Fix bfloat example for converting F to packed BF",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "fafdd242850657d58ae66836ee5d154f1187fe8b",
-        "notes": null
-    },
-    {
-        "sha": "6ab4ae1a19f5bd8227376449655a48036b7d13c9",
-        "description": "pan/bi: Properly lower add/sub with saturation on v11+",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "d79a31bf81a3527897f7c6f5178abd47d80fbaee",
-        "notes": null
-    },
-    {
-        "sha": "20279c28c827a1d5f3ba8ef35a3f21bcbf0fb96c",
-        "description": "aco/tests: add pseudo-scalar transcendental and fallback path RA tests",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "96e49b7904322282e91fd239e2e8d5da61b279b6",
-        "description": "aco/ra: add ra_test_policy::use_compact_relocate",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3c1dbc1d9bcd00ba1e928965eb2b73067850a5c8",
-        "description": "aco/ra: cleanup compact_relocate_vars fallback path",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a780345e014196231e6d9e15c328c0aadeaa02f3",
-        "description": "aco: fix compact_relocate_vars fallback with scc/exec/m0 precolored regs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f6581b41c4cb5b284f5550c7494d67ca37b391e6",
-        "description": "aco/ra: don't require alignment for NPOT SGPR temporaries",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "623230a6efa25677173d59e648b84b7fc47bffe5",
-        "description": "aco/ra: change sorting in compact_relocate_vars",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3f9b8edb1ce9ed00319c0efa3af3f2533921668c",
-        "description": "ci: Re enable fd-farm",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "87e143b05359c4a66c2d0ce3875b0ebfa81bb8b2",
-        "description": "docs/features: mark off missing panvk extensions",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "5ed79c2d2ba7fa2589d19a382e59ae22c6c14f40",
-        "notes": null
-    },
-    {
-        "sha": "f23f8c2826ff116eb5a31d68e04a99351742a5a9",
-        "description": "panvk: Advertise VK_EXT_depth_bias_control",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "970bdecb509bb8bbc9c9ddafb4bb0a6ab8821b22",
-        "description": "panvk: Advertise VK_EXT_shader_replicated_composites",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d4998f7ff3f500598abb47223f2118c6b43a802a",
-        "description": "panvk: Advertise VK_EXT_shader_demote_to_helper_invocation support",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "83cbac00d330efd1486d57ce25dce9751031e4d5",
-        "description": "pan/{bi,va}: Lower terminate to demote",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cd4400e27b097fb52d0f634a9673c28c143f662f",
-        "description": "pan/bi: Lower is_helper_invocation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "59c307a3f33c5d3883658dfe2a1ab6d4e950a699",
-        "description": "pan/bi: Fix and improve the !abs && !coarse case in bi_emit_derivative()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5ed79c2d2ba7fa2589d19a382e59ae22c6c14f40",
-        "description": "panvk: Advertise support for VK_KHR_shader_terminate_invocation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5a55133ce7d5bb2419f2aa99c5296037afb7ba6a",
-        "description": "hk: advertise VK_KHR_shader_quad_control",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ef1792bea86b63bf04db413f6e81299366f4919a",
-        "description": "amd/ci: document regression in e612e840...e210b79c",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "80b1aea7059fc5bdb282526725848d948df94dca",
-        "description": "amd/ci: disable retry on nightly radeonsi-vangogh-glcts-full job",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bc44d029df8be4f076b621b65762953ebc9cabcc",
-        "description": "radv: Ignore image barrier queue families if equal",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1fccc09abe472704982fd01c01c0b35b42096130",
-        "description": "radv: fix re-emitting VRS state when rendering begins",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "42279823269ea8391a336475f1070f2cb7e998e8",
-        "description": "ci: rename misleading *-postmerge stages to *-nightly",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "26bc35c8f9e9fb474dc6ee6ad5b2eff0d74da5df",
-        "description": "ci: Delete the kernel+rootfs jobs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "13db56320bbe2312b0f902bf677d9ab19e5893c0",
-        "description": "ci/baremetal: Use container rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e16d422da52c2e1990c43ee858a4e06c8dd01346",
-        "description": "ci/baremetal: Split baremetal_arm64_test to -gl and -vk",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a2150a0f567893facda4ec844ed2acd08c7886e3",
-        "description": "ci/baremetal: Remove legacy support for unused devices",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8296c19817182d84dac2baf4243155cd9a838c5c",
-        "description": "ci: Add a workaround for finding deqp-runner on Broadcom",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "55e78ef6789eaaab48734c72e92fca4cd2ed0670",
-        "description": "ci/lava: Remove job definitions using kernel+rootfs jobs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "10ea0002a6f725c4c66e665c82620dda1ba1d681",
-        "description": "ci/intel: Convert to using the new container based rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "961498a098917969e2ce6ddf379ed05f7cc1b435",
-        "description": "ci/svga: Convert to using the new container based rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "be79a2d2d3bdff2dea6b9fa16dff39fc698d7fff",
-        "description": "ci/lima: Convert to using the new container based rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "da27eea9e09500637fed75920f256ad50cc5c182",
-        "description": "ci/etnaviv: Convert to using the new container based rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4f7c40d5d457d988f8cf33f4ed44443fb5e54eb8",
-        "description": "ci/panfrost: Convert to using the new container based rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4d2e5f577a34db900654b4a77048093b2034d3e3",
-        "description": "ci/freedreno: Convert to using the new container based rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f8e87fbf50a437a4178ec47d23c2a4352633d91e",
-        "description": "ci/amd: Convert to using the new container based rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9870512787b9ee9c82ddb2237f6426fa74a4c4c4",
-        "description": "ci/lava: Use the new test-video-based rootfs for VA-API jobs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a3fb667b1d4bda3ca10d4fa20924f61d6c28af4d",
-        "description": "ci: Include Fluster vectors in the rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "414e1a22c83b18d8e36c9ffd6b708628c2c2ff60",
-        "description": "ci/container: Add new container for libva and fluster testing",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "751ff1a41e4d38450d01b17f199ec6f72ec1f1f7",
-        "description": "ci/va: Add /va/bin to PATH for test-video container",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "82a25daf9d8c2dac5c6adc9123655e56e1cad11d",
-        "description": "ci/va: Collapse build section for va-tools",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8448fbae8c0e49454c5436b37023ca3ce2bc892b",
-        "description": "ci/lava: Move rootfs handling for Fluster out of build script",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e80045d23e0388058179da36105971f06730c98c",
-        "description": "ci/lava: Use the new container based rootfs for piglit traces",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2e8adb9e98c621493173f9d35e93766aa64e0361",
-        "description": "ci/lava: Use rootfs exported from test-* containers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1009613aec104723825ffb27a1c443fb4057985b",
-        "description": "ci/lava: Add job definitions using the test-* containers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "225ac7f2b2cf7aaf746daf8a9bce7e2d543f00f6",
-        "description": "ci/container: Include SkQP in the test-gl containers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "33d5204ec1998bd509c9f9e2b05865395e330efe",
-        "description": "ci/container: Include ANGLE in the x86_64 test-gl container",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "16db8b22ccbecbdeab35947cb137e1bfbf67d12a",
-        "description": "ci: Export the rootfs from the test-* containers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "53c7a04d12152f28da44f8ebd1c809a2794a7349",
-        "description": "ci/lava: Ensure firmware directory exists before downloading a660_zap.mbn",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e9b98b0cc918ad1ccb697f52de1326e9db91bfa2",
-        "description": "ci: Add rootfs export script",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d4bf1fecb79318d60af6444ea3a4e37794ca8b76",
-        "description": "ci: Keep important packages for rootfs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "816b0212a82c378aa765a1f0e47ea4f4000ee9fc",
-        "description": "ci: Update setup-rootfs.sh for test-* containers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3609dbc06147311f77b45e47ebb705a1534a1113",
-        "description": "ci: Add ci-kdl to test-base container",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a5159ff108f0769cee3075ff77592bc155ed1f8c",
-        "description": "ci: Add packages for hardware CI testing",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "73993c2e74a745d111b482b82de6ae657cbc2b7d",
-        "description": "ci: Add firmware to test-base container",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "580a151642d29039acf75754a58ba06f8052c794",
-        "description": "ci: use https:// to install ci-fairy",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7d5f0eebc64ae90c29a4309ed5b20862e96ffde1",
-        "description": "ci: Uprev ci-templates to get FDO_DISTRIBUTION_POST_EXEC and S3 fixes",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "118a4c58725bf3b462bc8190df97620029156e10",
-        "description": "ci/android: Remove redundant android-tools folder",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3eb61729e3162b3ab9505652a55ecae7705a2118",
-        "description": "ci/deqp-runner: Collapse build section",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c1242c15af30085006c3103821dfef4a8baf977b",
-        "description": "ci/rust: Collapse build section",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bfe6f50ab43f9433d858be7fc5973221d526d6d1",
-        "description": "ci/deqp: Collapse build section",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7686edcb73e57fe94b8b40c4a87aceffd5719b38",
-        "description": "ci/angle: Collapse build section",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7d1e34204f20509e9fbe1a59f542f4ddf9226cca",
-        "description": "ci/android: Collapse more build sections",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b3c07fe722d6dcf399d4101f9f39fe298fe3e292",
-        "description": "ci/android: Use aapt from Debian packages",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c2ac7fa77bf9d045840890fe6cbf06fad37f4242",
-        "description": "brw/cmod: Allow integer CMP to ADD propagation only for Z and NZ",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e26270249b1c093c8b2443492dc940d3e41418b9",
-        "description": "brw/cmod: Don't propagate from CMP to possible Inf + (-Inf)",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "020b0055e7a085a6a8c961ad12ce94e58606a1ae",
-        "notes": null
-    },
-    {
-        "sha": "0dab520a19e323237e415210a70cb21b30512386",
-        "description": "brw/cmod: Fix some errors when propagating from CMP to ADD.SAT",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "020b0055e7a085a6a8c961ad12ce94e58606a1ae",
-        "notes": null
-    },
-    {
-        "sha": "8f0fd0e66e65c897ea85101171f4e35ee2a34ae4",
-        "description": "brw/cmod: Remove special handling of NOT",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "08fe7988d7fcc4182bc04cdbe6a01a72bbd8a04c",
-        "description": "brw/algebraic: Convert some NOT to MOV",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9ce869aef571f30bb5dab0e35c57900bcf6fab56",
-        "description": "brw/cmod: Delete some stale comment text",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "12a022cf45fcd502606a478d3fd09578f9e61f40",
-        "description": "brw/algebraic: Greatly simplify brw_opt_constant_fold_instruction",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9a946f8125e25dbf8d2c28d8c280809e92533b17",
-        "description": "lavapipe: Fix ray tracing position fetch with multiple geometries",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "dea4bb3757a5dea0d5117453b9a3990ae933857e",
-        "description": "ir3: VARYING_SLOT_LAYER output is used for binning",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "9775b33d0f14f91622f5a26a3c499a84da227c3d",
-        "notes": null
-    },
-    {
-        "sha": "42aae5c3fad672f13be0a7ff99414ea6a7e321cb",
-        "description": "etnaviv: nir: Legalize txd derivatives src's",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5841d44f91bb6d8387e36d6497100e0aea98735e",
-        "description": "radv: set radv_disable_dcc=true for WWE 2k23",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1eb3a40615e64cd145d1e66c301075b6b8478c5b",
-        "description": "ci: disable Igalia's farm",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7112c606ef1b24cde2b743c3fad2adf97405b20d",
-        "description": "panvk: Advertise support for VK_KHR_shader_integer_dot_product",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2a16422fab77cf447206e01507f4865cd88abfb6",
-        "description": "panvk: Advertise KHR_draw_indirect_count for v10+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cebd908bf36c080d9a8c96eb45f064ef6addbc8d",
-        "description": "panvk: Implement CmdDraw[Indexed]IndirectCount for v10+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "de896234d86d8e36c19e0687f4c94b3298dcb290",
-        "description": "aco: improve spilling of clobbered operands",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7fe84024cb0985c2ab676d3e83520e5213db05df",
-        "description": "aco: fix get_temp_reg_changes with clobbered operands",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "d6cb45dbb03941edd65c948a243e73774184eeee",
-        "notes": null
-    },
-    {
-        "sha": "656d7a0f881486634f83cdb7e03af94706f13119",
-        "description": "ir3: don't use VS input regs for binning variant",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a5a0dd3ccc08a0df318663d0c0912b1c99f17d5b",
-        "description": "panvk: Implement multiDrawIndirect for v10+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2bbfcaf01f1d7b2962e37dd522fe72ba972e8bff",
-        "description": "panvk: Prepare cmd_prepare_shader_res_table() for multiDrawIndirect",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "690675748bf1e2532cd041199fc0d00fd8eaf2b9",
-        "description": "panvk: Prepare cmd_prepare_push_uniforms() for multiDrawIndirect",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ed9f1359368be185f632e2a5b1f6edf16ef89b62",
-        "description": "anv: put parenthesis to the set_sampler_size equation",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "76096d04bbafddb523ffc360f6d738d16d94816b",
-        "notes": null
-    },
-    {
-        "sha": "3493500abb78a4dc22aba14840bba5c777fde745",
-        "description": "ci: Update build-apitrace.sh header with the right tag",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b92dd9c5732facb2f0dfd7e87937e9425d5338eb",
-        "description": "ci: bump apitrace version",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "47db31b55643d46709f842fdc5e696f6997afeb0",
-        "description": "ci: take google-freedreno farm offline",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d39e2869a8dffc42085033d2e4a2e25a7d57911c",
-        "description": "panvk: re-enable KHR_shader_quad_control on v10+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b3fd8ddf6a421efebb94b40972eeeffa4f6b9f65",
-        "description": "panvk: support vulkan 1.2 on v10+",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7f358797382329243e121c5b307a042ce202f013",
-        "description": "driconf: Jusant needs force_vk_vendor=-1 on Intel devices",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3c021b79b483af9fc8d5f8f9ef3befca851db699",
-        "description": "aco/ra: use a correct stride for subdword get_reg_impl",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ae6d4f11953b122d3ae4a12628ac3082e2de6256",
-        "description": "aco/ra: update_renames() before add_subdword_definition()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9d0cd43a684aa5b15750e2293c70ed80d879899c",
-        "description": "ci/build: drop install.tar from gitlab artifacts",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "630aef6653672a2e9aca46445ed521ccba1dccdd",
-        "description": "ci/test: make generic fdo runner test jobs use the S3 artifacts too",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1d7cce270079c58f0ff8993a8781cd84cb955bfe",
-        "description": "ci/ci-tron: default HWCI_TEST_SCRIPT to deqp-runner, as it's almost always what's run",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "20631a07cab18df726605a5d3fd38bfa98bd3d80",
-        "description": "ci/test: rename .b2c-vkd3d-proton-test to .test-vkd3d-proton",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ce79b8a7994e1c530c8aea77ebb1bc513437a596",
-        "description": "radv/ci: move radv-kabini-vkd3d out of gitlab-ci-inc.yml",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "aecdf762cefd4d11d7b862551afc85559262a5a2",
-        "description": "amd/ci: ci yaml indentation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "35816d642255287102cb1f387b93a3245370ba2b",
-        "description": "ci/test: fix annoying yamllint warning about 2 spaces before comments",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "aca1a332c247d8e195efcb57e68453c6cda58c59",
-        "description": "ci/build: drop unnecessary shellcheck disables",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ab0e505d7f97743d353f9b34430887b9c15d168f",
-        "description": "ci/build: rename variable to avoid changing the meaning of existing variable",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8c28f77bd116e9adfb5f352dc3edd9677eda3a47",
-        "description": "ci/build: split git commit sha command out of echo",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "621aebe0467937ead0df9790c926d4516b195a6a",
-        "description": "ci/build: drop unused VERSION from python-artifacts",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5be47997343aec64e386b649452003c8ec5ecc82",
-        "description": "ci/build: drop lava scripts from builds artifacts",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1f08d75272a11dbb8ad94b75fdfe56dd4a9b5563",
-        "description": "ci/build: drop expectation files from python-artifacts",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d35c630483816186f28a5eeb1f6a861466f20d99",
-        "description": "ci/build: drop b2c files from the builds artifacts",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cd8d8ca79542d14cfe1dbbdc32bbf8cdc4346c77",
-        "description": "ci: Update kernel to fix GPU recovery issues on sm8350",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b03e07158331b2d37dab8a1183931ac55cb39758",
-        "description": "aco/gfx11: create waitcnt for workgroup vmem barriers",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d432fd9e327bb16eefd2f28ab7da4ebd2775dc25",
-        "description": "panvk: Advertise support for VK_EXT_extended_dynamic_state[2]",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e3cbb2c131be7623f9f2bdcf2b8fe48c0c06269c",
-        "description": "panvk: Implement CmdBindVertexBuffers2()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1d1187282841366828ca813ab8d9300346e3be10",
-        "description": "etnaviv: nir: Use nir_shader_tex_pass(..)",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3eb75756795ef29fd7a983ebeb0b095358aadc38",
-        "description": "asahi: do not use \"Null\" layout",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "614b66529de2832575cdb0c97581d0d5f791ed72",
-        "description": "etnaviv: nir: Add support for txf texture operation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "eefe486533eb58d3d1e81daa5abd16e63ee4c7a9",
-        "description": "etnaviv: nir: Legalize txf lod src",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "da90fca6093dd58cc351b0ac624ea8c0d83a81f9",
-        "description": "etnaviv: isa: Add txf instruction",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6325868bbea44d7be5bc7bafb73089a00ecaef10",
-        "description": "svga: handle null target pointers in svga_set_stream_output_targets()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "65411350aca2b123c78c70d6a4200e3a6c12e675",
-        "description": "aco/insert_exec: disable empty quads when leaving divergent control, even if not top level",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3ad385b9cc39e3cd44df03ab4f6285f073984e40",
-        "description": "radv: Clear dirty flag for clip rects state after emitting it.",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "0ba3a8b3cce74e40c9545dbbb047f11159ac3c7e",
-        "notes": null
-    },
-    {
-        "sha": "3a05477ac6be615c6342fcb6575d8fffa6cb5aa7",
-        "description": "radv: Clear dirty flag for MSAA state after emitting it.",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "08918f08805f87ba82e3dcf611e186d51ae4db41",
-        "notes": null
-    },
-    {
-        "sha": "e60416b4e427b120d1b77cbd15f659dc36daf97f",
-        "description": "anv: use companion batch for operations with HIZ/STC_CCS destination",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "31eeb72e45be6ef943df0b60f3cd7a646fa7b349",
-        "notes": null
-    },
-    {
-        "sha": "3aec638a8beda9f82927f13ba24618469219c9e1",
-        "description": "rusticl: remove unnecessary check for device in kernel list",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4be2a49e02fa55d2630d1b57bf3407bbf3740852",
-        "description": "rusticl: improve use of Rust idioms",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2c202eb7870524072863823e1a9413222021317f",
-        "description": "rusticl: verify validity of property names and values",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "62d8541f39cbbc42aed504d46a1aaee9f0bf014b",
-        "description": "rusticl: improve internal typing",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ec314aa358c6505c5dc62ced831636450406fef3",
-        "description": "rusticl: align memory utilities with std",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "26867670b2c9b2b16c4daf2dde6d072ba736ad4a",
-        "description": "rusticl/device: set maximum work dimension to match implicit bounds",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "845611bb43b7c74f3a6cfb03ea3525bc6cac1620",
-        "description": "panvk: Take resource index in valhall_lower_get_ssbo_size",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "e4613f8b2388e583b15bbbe9595458b2595f1cc2",
-        "notes": null
-    },
-    {
-        "sha": "7ec937b81ec1b95414ae192e6c677808c3d91d83",
-        "description": "v3d/vc4/ci: Add -gl suffix to the GL suite names",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9ab13e1ed08d3ae03107bd9f7a85effbc12f7318",
-        "description": "v3d/vc4/ci: update fraction and parallel values",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8dd578e2a4ea02ae9c8b9c0a0b7b7de8a105cd50",
-        "description": "panvk: Enable VK_EXT_direct_mode_display",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "8c2bfa279d33cf54eda230650fde4e358354d703",
-        "notes": null
-    },
-    {
-        "sha": "419a9e9d4277cf187f8a2da3ec151beadb00b311",
-        "description": "mesa-clc: add an option to force inclusion of OpenCL headers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "680752d97feec680e04e24e69069f457efdc591a",
-        "description": "ci: Use hyphens in make-git-archive job name",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b758e4908504396ddd24e99ba549686c00569605",
-        "description": "ci: Update ci-fairy to use shared ref from ci-templates",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bf4fa82af94615eddb8cad508f0972802b2cea3b",
-        "description": "ci: use curl instead of wget in download-git-cache.sh",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "74809ce0e3f062a5f054a2938de7e37029239583",
-        "description": "ci: drop dead wgetrc as there are no uses of wget in our CI images",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "006f5c20bdeda6f0907d1034e0d24889911ccbac",
-        "description": "panfrost: Allow max effective tile size of 64x64 on v12+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "943a59c8f95b07ccd6f2c42be1ae716745eb0f10",
-        "description": "panvk: Emit sample count and tile size when emitting framebuffer/tiler descriptors",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c7f2bc6bedb5dbb0d9f713db64d11291204f1cf9",
-        "description": "panvk: Take rasterization sample into account in indirect draw on v10+",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "1f3b8bb9188e0520dea18c0b20fa7f857a2532a2",
-        "notes": null
-    },
-    {
-        "sha": "765801fd9e820172f15bbf7374f462172d752113",
-        "description": "intel/dev: add note about PAT entries and Wa_18038669374",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a0407a6ecfdb983e9feeacb4dc50a6000863a5d2",
-        "description": "ci/vkd3d: fail shell pipeline when part of it fails",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "104f21c27b0c8b2dce1ba5e6a3b3c05e77067e1f",
-        "description": "ci/vkd3d: treat reading undefined variables as an error",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "89d4ddce0e9e53425148d2b4a36d879084440443",
-        "description": "ci/vkd3d: fix RESULTS_DIR variable name",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3c0d414cbf12704305ff54aa2a5232edb52584d4",
-        "description": "ci/vkd3d: only keep logs of failed tests",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7f0fe3475860ae8cf9c7b1f2cceb2aa497fa2c5e",
-        "description": "ci/vkd3d: quieten the mesa version check",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0f8fd5da7a20f9fcf1655373ca68b889589d1e38",
-        "description": "ci/vkd3d: fix test failure list when no test failed",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d21e300f33c82f1f871f068c2e6d6a7b8f311d9d",
-        "description": "ci/vkd3d: drop misguided \"something failed\" error message",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e93261f579263fcf3900ce3767da087f412c1515",
-        "description": "panfrost: allow promoting sysval UBO to push constants",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "59a3e12039cde5df1451193557512b38cea0039e",
-        "notes": null
-    },
-    {
-        "sha": "6d2190300aa0147919ca08b02ace568d539c11eb",
-        "description": "radv/nir/lower_cmat: tightly pack 8bit gfx11 acc matrix",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bbc9bc9d245ce2394cc8b74f2dec1fdfbbaa67f5",
-        "description": "radv/nir/lower_cmat: use cmat_mul instead of duplicating hw details for type conversion",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "31a34305701e06df5e88d75bc80f588cdb447de6",
-        "description": "radv/nir/lower_cmat: use radv_nir_cmat_bits consistently",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "300b6f73714fd7e82491eb49db283d78495c4421",
-        "description": "util/disk_cache: Re-enable multi-file cache by default",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9822fa3ef311a98b3ce79c111201a84782a91b3e",
-        "description": "Get rid of 5 remaining references to glapitable.h",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "0cebfb15b568c79bfc7c3298954dff7302407722",
-        "notes": null
-    },
-    {
-        "sha": "6a58bc357b9da03fe467e44dd4cdaaa8b8be47b1",
-        "description": "docs: update calendar for 25.1.0-rc2",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "60452e016ecd9f84ca9336d81a8f549b7a27f27a",
-        "description": "wsi/headless: Override finish_create",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "579578f10acda284c39cab2b12ccb8de2d2f793c",
-        "notes": null
-    },
-    {
-        "sha": "1f6cca0800e3d8f91dba1b7f616922613b90b5c6",
-        "description": "intel: fixup a few debugging option checks",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "ad328bc58d0bbbfddf9a5d4b0ae4c0aa27f21f9d",
-        "notes": null
-    },
-    {
-        "sha": "62e50de5d0bfe9ba90795cbb9422273cf2636848",
-        "description": "aco: use v_perm_b32 for byte swaps within a VGPR on gfx10",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a43783fd7642356cf0e35fa2a7b42d718eb87196",
-        "description": "aco: use v_perm_b32 for do_pack_2x16 on gfx10+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "78a3b48db0212674605676b33f4dadaf649b7a7e",
-        "description": "radeonsi: enable nir_io_compaction_groups_tes_inputs_into_pos_and_var_groups",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0836e9758bbd6c93c964b64a8864976bcdbfe881",
-        "description": "radeonsi: initialize use_ngg* sooner",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "55db7fc18cdf1e446d305b935ddbd4787d780144",
-        "description": "nir/opt_varyings: group TES inputs based on whether they are used by POS or VAR",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f15399af0fef2e2adebccbddbf1f85f63fdccc34",
-        "description": "nir: add gathering passes that gather which inputs affect specific outputs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "33965bb21bac40840cf07958f509dcada4ead979",
-        "description": "nir_lower_mem_access_bit_sizes: fix negative chunk offsets",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4685d8e2d9e333d6e338cf703d2da4f574cba796",
-        "description": "libagx: use common heap alloc for tessellator",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d339bf7a98eae1e238d9a9e37d479c17675d074f",
-        "description": "libagx: rename agx_geometry_state to agx_heap",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "29cc2b6d4274fe820044c78cc6a0d2d27d6d97be",
-        "description": "libagx: do not include heap in geometry params",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cb52aa58d6ba15ef1ddb1522c0316a526c98b296",
-        "description": "agx/nir_lower_gs: bound static topologies",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9b1d771747c14b2aef5f54af7898f51c3504c9c1",
-        "description": "agx/nir_lower_gs: compact static topologies",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5640266eb38f1b930be1160b712a7ac47347cddd",
-        "description": "agx/nir_lower_gs: rework gs rast shape handling",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2a0314250beb62d069bae84c4c1aaf09288e1ae8",
-        "description": "agx/nir_lower_gs: don't use nir_def_rewrite_uses",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3670f95e12020beb155cd8484916c294149299d6",
-        "description": "agx/nir_lower_gs: avoid redundant sr read's",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8b0dca384f9398a38b5470895c935c1cdcda6fd1",
-        "description": "agx/nir_lower_gs: fix type confusion",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "b9b6828fdaebb037a3b842b4a33e9d622db4d21a",
-        "notes": null
-    },
-    {
-        "sha": "d548259b2f4280df6cfb7930b37a350c4e2a10f3",
-        "description": "agx: plumb vertex_id_zero_base",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fbb85a8d096d958dddf9f165728e3d484ccc8ca2",
-        "description": "agx: use abi.h defines",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6f265ab83fb4b08ecab69906cac20901f091f58b",
-        "description": "asahi: clang-format",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d31ad329c2505b9cedb39bec61a8f2b9c58b6289",
-        "description": "util: optimize bitcount on OpenCL",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "bfc18b6fb1642625925e54ce9fa570e6b3e3f0f1",
-        "notes": null
-    },
-    {
-        "sha": "eecfb02463e7dacbb2f3f949b46bd5c0d9ebbe3e",
-        "description": "frontends/va: Handle properly when decoding more slices than limit",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1a373edfc576f81885fa2685d95edc27d50e7022",
-        "description": "nak/sm20: Fix legalization of IAdd and IMul",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "078ffb860b436c7b10a9180a9620749528c284b5",
-        "notes": null
-    },
-    {
-        "sha": "ca296bf0a94987b681230388d148d77145714557",
-        "description": "nak/sm20: Call copy_alu_src_if_fabs() first",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c26273109f786117108d19c98a7a4eb43ac8d744",
-        "description": "panfrost/ci: Update spec@ext_transform_feedback@max-varyings result",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a36402afc89d3510ce9d9f33423bb5c9d953d02c",
-        "description": "panfrost: Use LD_VAR_BUF if possible on v9+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "49a9c915400104dbe7963a63c48dea5318ac2b8f",
-        "description": "panfrost: Remove fixed_varying_mask from uncompiled_shader",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cd2ca0ac222f50fad989229906170e4d1acdc1fc",
-        "description": "panfrost: Enable more than 16 varyings on v9+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "85b6bd989ec501975259e42af2927caa16d8707b",
-        "description": "panvk: Advertise support for VK_KHR_maintenance5",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9d1262e108dcd962cff4d564e9f0f62799414305",
-        "description": "pan/format: Disable image storage on A8_UNORM",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "d95423686fda6c8a96702b1535a967132f8887f8",
-        "notes": null
-    },
-    {
-        "sha": "8d1e55a3b508428174479bfd3a78a988b8d3560d",
-        "description": "panvk: Implement GetImageSubresourceLayout2 and GetDeviceImageSubresourceLayoutKHR()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7abe32a1302a00cdc6341c6976e96168f453a3a6",
-        "description": "panvk: Call vk_image_finish() in GetDeviceImageMemoryRequirements()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1e3acb062acf46d944c18519568b17c00b6fbeee",
-        "description": "panvk: Don't pass a dev to panvk_image_init()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1b22f6d6795b053fd210a5a400abb766d19b03a3",
-        "description": "panvk: Pass a const image to is_disjoint()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "51e46ed57fb19158fd4d3bf31f343694b912c319",
-        "description": "panvk: Implement CmdBindIndexBuffer2()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b632ac7e3b764845659df1b5fc04c0d86df6a0c0",
-        "description": "panvk: Advertise support for VK_KHR_maintenance4",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "dd3e1190a2bdbc6b996152510407adb9a8cb5618",
-        "description": "aco/insert_exec: reset temporary when recreating wqm mask from exact mask",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "b872ff6ef28bc44ac0f7aa5f963a273e40c79a61",
-        "notes": null
-    },
-    {
-        "sha": "13f6be262a47439389b0d290839109c47d1d3271",
-        "description": "aco/insert_exec: only restore wqm mask after control flow if necessary",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "b872ff6ef28bc44ac0f7aa5f963a273e40c79a61",
-        "notes": null
-    },
-    {
-        "sha": "6802d66b501d672566a95d391177202bae6a722a",
-        "description": "v3d/ci: move depthstencil-default_fb-drawpixels-24_8 samples=4 to flakes",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "08c323951b78b00e0d59237498fdbf501aad9751",
-        "description": "v3dv: Implement dual source blending",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a72be0f7208630c6518244ef248ee219ee9b3bf1",
-        "description": "v3d: Implement dual source blending",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "42154029fcd18ac6dcf677b0467711e03687064d",
-        "description": "v3d/compiler: Implement software blend lowering",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b38c4e898272f40b994e6b4092a37cd64c9f4f62",
-        "description": "nir/alpha_to_coverage: Add an intrinsic for better dithering",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a6f67d5b69bcd2335e614c9782d415a45da08ff9",
-        "description": "v3d/compiler: Only lower logic ops for color buffers that exist",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1ec0cdb73377767c9665a1e376af329db8458af6",
-        "description": "v3d/compiler: Fixup output types for all 8 outputs",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d3aedbfe9d08c7a867352fc52ff9c8c7ec34431d",
-        "description": "asahi/lib: Move alpha_to_one and alpha_to_coverage lowering to common code.",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "091d52965f805d61dd3a8e091ac20869a794e632",
-        "description": "radeonsi: init use_aco properly when llvm is disabled",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2ab7ff51b9d86a6bdaf6f8ed398ca2b1b51aa4ff",
-        "description": "radeonsi: skip blit incompatible scenarios",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "992a340eab07797bf161262a189f7eca2fdf80e0",
-        "description": "ac/nir: init blake3 for cs blit shader",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2a381bbc3cec1a54095cf4a51df8516d25207fe4",
-        "description": "radeonsi: fix potential use after free in si_set_debug_callback",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "59a3f38ff6fdc7bd47309dd58ce5070c903a0c28",
-        "notes": null
-    },
-    {
-        "sha": "48bccb7d55633d8d53e15397bbec2bc7a64c6135",
-        "description": "bin/ci: crnm: bug stress mode retry formula",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e6843c170518c55001b20543004eb5d3e8d7ce11",
-        "description": "bin/ci: crnm: bug while stressing a single job",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ce200e6a4a086f20ba64b07d02e3cf67ca877599",
-        "description": "bin/ci: crnm: Fix job duration calculation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b3a9125014105e072eae3720547c5823e35a1eb9",
-        "description": "bin/ci: crnm: Improve timer display formatting",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "769c9bf27cc24408a4b569009216431a9d93892c",
-        "description": "bin/ci: crnm: Improve job enabling robustness",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6464083a6b056ba87d8b613fd0a6dd465863994b",
-        "description": "ci: Extract target job handling in CI monitor script",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "098ee11c1c3df22d033553227b7a343c47291f5f",
-        "description": "panvk: Set supportsNonZeroFirstInstance=true",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0a3f1da321cd5c41bbdd37c817c440f5d6f44a08",
-        "description": "panvk: Advertise support for VK_EXT_vertex_attribute_divisor",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b2a8e3838d6f70d94d785622ea89fd65acb0d322",
-        "description": "panvk/csf: Fix instance attribute offseting",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "1570f0172e02aa660bb0b2619d67c1cff52b3914",
-        "notes": null
-    },
-    {
-        "sha": "b093855caaeb0f8c45e7cbe3a7ce2d31f1e1d6a5",
-        "description": "panvk/csf: Pass less arguments to emit_vs_attrib()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "93484bf38ab08052f1240839720fcd7246328254",
-        "description": "rusticl: allow packagers to enable radeonsi by default",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6f080ac5324b7cf1d394ea1a08a8002be74326f6",
-        "description": "rusticl/device: fix panic when disabling 3D image write support",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e3edc6029b253090c04c34b6bea59eedd14524f4",
-        "description": "ac/llvm: use mul24 intrinsics",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3c267535ae46b09152bb2d9146efb69269efff3a",
-        "description": "anv: Add new debug flag to show shader stage",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ad328bc58d0bbbfddf9a5d4b0ae4c0aa27f21f9d",
-        "description": "intel: Switch uint64_t intel_debug to a bitset",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2a1aa129ed6535a63b39f7b1a86515c379b0751b",
-        "description": "intel: Switch debug flags to enums to prep for bitset conversion",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ff95e506d9d6d3f60f9257f31f367c8df8b88541",
-        "description": "docs/nvk: Update conformance and hardware support information",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8514452cf78609f86e36a79910b57c6398e51a9b",
-        "description": "Uprev Piglit to c50d9aa54f85e0af9d72fab86c73f89356d96399",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3f49272944b39fa424aac6d5c33ff9eabdabc3b8",
-        "description": "Uprev ANGLE to f355e2b37ed43939e2753fc7dacccf75abb4c1a3",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fcb6dfb29c76454a7e24c177609e6b5dfda79c94",
-        "description": "intel: Fix the MOCS values in XY_BLOCK_COPY_BLT for Xe2+",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "161c412a8296961f21f06761f89d58ad124ecc0d",
-        "description": "intel: Fix the MOCS values in XY_FAST_COLOR_BLT for Xe2+",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "36f22cc951c3249ebe36ab722739317d49e17f84",
-        "description": "tu,freedreno: Don't fallback to LINEAR with DRM_FORMAT_MOD_QCOM_COMPRESSED",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "fc50fb35b0526a10da5e5fe72d4291c5175a9759",
-        "notes": null
-    },
-    {
-        "sha": "ee10938beed3840b9583ad4d67ff96052a9daaf1",
-        "description": "tu: Fix flushing when using a staging buffer for copies",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0a41200f821c4993e1eb6651ddab02f51a8986b1",
-        "description": "pick-ui: add missing dependency",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "c37a468a8a109cbaece70760fd748fc838185b88",
-        "notes": null
-    },
-    {
-        "sha": "501ed5be497f74e436f1ab89b47d07aeab814582",
-        "description": "lp: fix gnu-empty-initializer warning",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8d2e16cc110b081c4fd8910aac93715cdf6d005c",
-        "description": "panvk: reset dyn_bufs map count to 0 in create_copy_table",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "e350c334b6b2c7b420f326501533984c43d7c900",
-        "notes": null
-    },
-    {
-        "sha": "6901f74fbf112fa129197b7b0101578ba992d24a",
-        "description": "intel/executor: Reorganize -h and --help",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d383d78e8c0544e6ebf9b23f57969bc6f5288fe7",
-        "description": "nvk: Maxwell+ is now conformant",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8f3489f351fc352e116e575884af5bc11423b4a2",
-        "description": "aco/isel: create WMMA with constant C matrix if possible",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4fa3fb87c78628105559cc934bd3d5add852523f",
-        "description": "aco/insert_NOPs: allow WMMA with constant C matrix",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c3964e87f805af48ae6f3b86aa58c97a110a8c25",
-        "description": "radv: apply fneg/fabs modifiers to wmma",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6d7e67d98632e0fff202cd196af05179e7c6eefe",
-        "description": "nir,amd: add neg_lo/hi modifiers to cmat_matmul_amd",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b0c8f316001c3050f268d9eca9dd22a1a8a822f6",
-        "description": "aco: set opsel_hi to 1 for WMMA",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5f3a3740dcc6d243f2ef14138fb1c09bcbb9b5fd",
-        "description": "zink: use util_dynarray_resize_zero() for descriptor pool",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7b17dbd0c05bceef8a620b73bfdf4fc68e02dc69",
-        "description": "util/dynarray: add util_dynarray_resize_zero()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a99e5be44642cb6e56f567f41854aac93dff66dc",
-        "description": "teflon: Release the arrays of tensors in operations",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "63251d43ae433e1cdaceb8ca4d1bc897987d3df0",
-        "description": "etnaviv: Release screen->dummy_desc_reloc.bo",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "bca5ef70a436380d1b6cb0f5bd84f1872cabc5e5",
-        "notes": null
-    },
-    {
-        "sha": "113143a47034ea5e110ca06d222028a5051c8c80",
-        "description": "teflon/tests: Read model data with mmap, for speed",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "baafa9172a0461cab6e6efc4d75fb957c41cac89",
-        "description": "etnaviv/ml: Rework tensor addition on V8",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "104309ede383b8ca328b7405d28e707998fa6dae",
-        "description": "etnaviv/ml: Support padding the channels dimension",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4a951a73e7a7b5af82776500649135cc76a20fb6",
-        "description": "teflon: Support more Pad configurations",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c31ce2d71f8ee30664f8db7c1ee1f43b09f0388b",
-        "description": "etnaviv/ml: Fix depthwise convolutions",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3e26fc4498948e3a320469ff12be80b9ba5005a7",
-        "description": "nir/opt_algebraic: disable fsat(a + 1.0) opt if a can be NaN",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "a4a3487aae98cc83990b1c79785983b65124145f",
-        "notes": null
-    },
-    {
-        "sha": "a60d61cce855cf053cbd290e399cc5991ddd1369",
-        "description": "nir: improve fadd is_a_number analysis by using the range",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a6fd9f488ac401c9236b2cc3f319f8713517242d",
-        "description": "nir: add is_a_number analysis for ffma",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cb6d03592527d687438bbce215be906fc9fc5192",
-        "description": "nir: add range analysis for ffmaz",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8ad695195eec69488fd7770a2d6884aebc4fad91",
-        "description": "nir/opt_algebraic: turn exact fmin(1.0, a) into fsat if a is not NaN and not negative",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "18a0de18344e1bae7afb62b38ff20b74dd130552",
-        "description": "nir/opt_algebraic: optimize fmax(ffma(a, b, c), 0.0) to fsat",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f71fc26393e5dab0d49c2cd9a6be55b00bb87790",
-        "description": "nir/opt_algebraic: generalize fmax(fadd(a, b), 0.0) to fsat by not requiring fneg",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1050c6983375dca3575872e221e8f572ec2c7143",
-        "description": "libagx: drop libagx_sub_sat",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bfc18b6fb1642625925e54ce9fa570e6b3e3f0f1",
-        "description": "libagx: drop libagx_popcount",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9c4660d1a6de3253b501a19627b1d0a17b82ae7e",
-        "description": "libagx: use #pragma once in geometry.h",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "63a28319670a7352d942a91d206a1f5970c5d9f5",
-        "description": "agx/nir_lower_tess: drop dead todo",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "41960652e1700a669de5bef3f6e0ad5cee5fa3b4",
-        "description": "agx/nir_lower_tess: drop pointless helpers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2a065fc446ef8f458cf5f4e7151db5bb23b4dbbf",
-        "description": "agx/nir_lower_gs: use common nir_verts_in_output_prim",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ea209c98fcb387a8732a5152e7e3c829b1bcda09",
-        "description": "agx/nir_lower_gs: drop silly fwd decl",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ba9f86df518cf2c5e65d6d60edde2bfa4578e82b",
-        "description": "agx/nir_lower_gs: privatize lower_output_to_var_state",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d42a92fd93df14325f4cad72954f64ab28fa2c05",
-        "description": "agx/nir_lower_gs: clean up more state->info",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "470f226ed846469eeadadeb9b3318b40045fb029",
-        "description": "agx/nir_lower_gs: remove silly comment",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1017095c5af8ae76bf5cc2bd331ae318a1bfe641",
-        "description": "agx/nir_lower_gs: clean up state/info duplication",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "753e3ba55bc4f5e25ff922190294667e6ede7b34",
-        "description": "asahi,hk: use indirect-local dispatches for GS",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "70c805d8631bd3e5eb78f7da7066a300392c86c4",
-        "description": "hk: bump wg sizes for geometry shader",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "164fc8a1582254960cff5d9c1bff75fd025dfa87",
-        "description": "agx/nir_lower_gs: clean comment",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b9b6828fdaebb037a3b842b4a33e9d622db4d21a",
-        "description": "agx/nir_lower_gs: optimize static topologies",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3da89391978aeb4f92327d5d7309d3597aa19e30",
-        "description": "libagx: factor out _libagx_end_primitive",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d2cc7f38d3530b4e232e8137b8b039a03c4a12ca",
-        "description": "asahi: optimize out empty dispatches",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b916c38c76465429cfaa69201c94dab9c173f98f",
-        "description": "hk: optimize out empty dispatches",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f6ee36a43731a074b643c6685142484a02a4ab67",
-        "description": "agx: add agx_is_shader_empty helper",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f1aeb46a34a58fce4d87009e7f4f203ae64fcb37",
-        "description": "nir: factor out nir_verts_in_output_prim helper",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6c33b1e8c16cf6a6a3042fc562a4fdf46a4d733a",
-        "description": "ci: replace s3_upload wrapper with ci-fairy s3cp",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4b3b3d4c703ab3153092ddf0bb7da6e2c013311f",
-        "description": "ci: use MESA_TEMPLATES_COMMIT for ci-fairy install",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c4aeef02e28c90460a0b71126cd9fdac1b735234",
-        "description": "ci: bump ci-templates",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ba64e92641be464167420aca68b53321a6185b1d",
-        "description": "Add libzstd static library.",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "de78a75f13d5d5c7c332920ce620fb2428d53ad6",
-        "description": "panvk: Set .pushDescriptor=true",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5b7e5db14909e1a56cd7225f5640a0a10c7f780c",
-        "description": "panvk: Advertise support for VK_EXT_vertex_input_dynamic_state",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2b5ca87927ea357c93254b3a064c34b633f0be39",
-        "description": "gallium/pipe: Increase hevc max slice to 600",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0f65c858ea20681a2fc9f7525c89ce48b96422dc",
-        "description": "nak: Add test for lea disasm.",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5f5cb088a9f5218de3e11ace26f90be7cd397284",
-        "description": "nak: Disable cbuf textures on blackwell",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fd90b072f166aad4c6a9933fc4b36e4237f79b3b",
-        "description": "nak: sm100+ texture encodings",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f70b7d10c2e6435702641db4dd98e34841bf64e0",
-        "description": "nak: Fix sm90+ atomg/redg encoding",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "869452aaf08083ff37b3806961cecbfed0226133",
-        "description": "nak: Remove range parameter from set_atom_type",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2b8218425090ef6bfbd7061efe2a531150227f74",
-        "description": "nak: Add nvdisasm_tests",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d31172d092f93eb8e67de666c7adb9221a4d2e38",
-        "description": "nvk: Remove dead function nvk_meta_init_render",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2fc4c98aaff49d54187724f0452fce6df23c60bf",
-        "description": "nvk: Override render enable for blits and resolves",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "32f2317223c4e5dfc085bd1c0f506bd0831e7fb2",
-        "notes": null
-    },
-    {
-        "sha": "52085f2a0e1cdb218a2d3c241c9c6d25309b901b",
-        "description": "nvk: SET_STATISTICS_COUNTER at start of meta_begin",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "6f85e6b06bef9f315511bf38c833df41d8c1952a",
-        "notes": null
-    },
-    {
-        "sha": "1bf8542490679fa2a244e27fb2b04bbc3d122f74",
-        "description": "anv: Enable VK_EXT_external_memory_acquire_unmodified",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3613b9c4f7ba8994efbc9142f1c9b76d38d0dcd6",
-        "description": "anv: Fix comment about external queue transitions",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e87a04c6c132da10a5a50ee783e04b99f1b41685",
-        "description": "anv: Assert that only external images have private bindings",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0463e14b9423be0ce354fafde0f01c5c89280315",
-        "description": "anv: Enable 64bit memory structure mode for RT",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "703f29874bb9ee414e1ee12487cd38c4dd31488f",
-        "description": "intel/bvh/debug: Adapt instance leaf dumping to support 64-bit RT",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cbc8af4555db8d64bb0b5e0bb86e11596b16375e",
-        "description": "intel/bvh: Compile and adapt bvh shaders separately into Xe1/2 and Xe3+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "36433e932b67034fa2283ec730a19f1c05ceada7",
-        "description": "intel/rt: Update BVH instance leaf load for Xe3+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5cd0f4ba2fdcd1371731de586523b295d73ea289",
-        "description": "intel/compiler: Update MemRay data structure to 64-bit",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7b526de18ffcfd61fa63aecc9980a2d4b157bcf5",
-        "description": "intel/compiler/rt: Calculate barycentrics on demand",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "afc23dffa45e21a1475ae784c08ce3125355d5a6",
-        "description": "intel/compiler: Update MemHit data structure to 64-bit version",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "40fb95d51a8af5d8f1ff2b70b385703632837e53",
-        "description": "intel/compiler: Use 24bits for hit_kind on Xe3+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "64fd66407bc02f75ac1afd878b48339df202977c",
-        "description": "intel/compiler: Pass around intel_device_info parameter in helper",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6deb1950a4b632b9c1b0af88ad949a4dcf6d4257",
-        "description": "anv: Update RT dispatch globals to use 64bit data structure",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fcd5fe4a759aa1e1c57ad863b780bb9cc6e2d8af",
-        "description": "intel/genxml/xe3: Update 3STATE_BTD field",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "92afeb37bf0ab61846323aa2969b703899dbcb8f",
-        "description": "panfrost: Take tiler memory budget into account in pan_select_tiler_hierarchy_mask",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c643f6263315912659ccf9a2da1cef468cb93feb",
-        "description": "ci: bump to fedora 42",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2bcb55f3f66652873b11e24e3012dc19c3bff4ae",
-        "description": "aco: help clang 20 do some additions and subtractions",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b59b53e82430bf8c983ba2f9d8b14dd2d48e5ca3",
-        "description": "ci: uprev vkd3d-proton",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "55199d988abe8faeffdc8096efb8423ebb9c28f8",
-        "description": "turnip/ci: drop skip of test_vrs_depth_write_dxbc as it no longer hangs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fec01a11d4b0e4f262d763565f23db8e4e597004",
-        "description": "ci/vkd3d: drop unused 32-bit build",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5ccf28ce1bb24894fdf6cda50562d4f301099cea",
-        "description": "radeonsi/uvd_enc: Move all code to radeon_uvd_enc.c",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d9f214001b16778001772598310585de096fa0e6",
-        "description": "radeonsi/vce: Move all code to radeon_vce.c",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b0b52d4922c5d1cd818461801506a0bd6593643d",
-        "description": "radeonsi/vcn: Fix decode target index for H264 interlaced streams",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "0e68a2655f46b2a1d2ce969cf18fbababa09a099",
-        "notes": null
-    },
-    {
-        "sha": "bde3ab4cd38a1a99bfc4330a4f83295faec5701d",
-        "description": "ir3/isa: add nop encoding for bary.f/flat.b",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cd953a7dfa3fca2e95af858e9506eda2a570e6bb",
-        "description": "nak/sm20: Use the immediates instead of rZ in OpShfl",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "608eef01d6f0fd57720e3d273290c817db8add4f",
-        "notes": null
-    },
-    {
-        "sha": "0b8359e159db0c016e5d3e704de2bc6c274784af",
-        "description": "nak/sm20: Fix legalization of float source types",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "142fb563c49e7f9717ecb6a474dc1a3b613ebc8c",
-        "notes": null
-    },
-    {
-        "sha": "a2caf95c5023dae405a44649dc4a5c556c775368",
-        "description": "nak: Handle OpFRnd in is_fp64()",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "b27fc463da2fbb11f1cd9c83b0de09247db6ca3c",
-        "notes": null
-    },
-    {
-        "sha": "4a51089f30b1d9fc7081d629f69eb89baa2a2f01",
-        "description": "radv: fix incorrect patch_outputs_read for TCS with dynamic state",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "8c2f9f0665d03b0fd0042354eb79cc069a77736b",
-        "notes": null
-    },
-    {
-        "sha": "2948f7ce962dc6384f2e2f0e186db3af6559e337",
-        "description": "ac/gpu_info: rename tess ring variables, fold double_offchip_wg",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d2e016c37dd52e8a509b274435718548b121d28f",
-        "description": "ac/nir: don't store tess levels for TES in TCS if no_varying is set",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "be8977811b9885dbac7aad9c75a00da85a620972",
-        "description": "ac/nir: remove shader_info parameter from ac_nir_compute_tess_wg_info",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6d9e7086425553d83364099826e3e35385e555a2",
-        "description": "ac/gpu_info: reduce the tess offchip ring size and compute it proportionately",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9333c0a1ed28372f119620db63aaf5e763f0d2ba",
-        "description": "ac/gpu_info: compute the tess factor ring size proportionately to the CU count",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5fb2de9454158c6e6c55abc8c486e112fbdc0c03",
-        "description": "ac/nir: don't include TCS offchip size in LDS_SIZE",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b8f2fb81f602f3d94c5a074f917b91f97d8555c6",
-        "description": "ac/gpu_info: print tessellation ring info",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b8d15fee3df2c81abe1b2ab954a3a0f6b61c0019",
-        "description": "ac: minor cleanup of ac_compute_num_tess_patches",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a905a17f3996e41ec45977d526a45590b79d704f",
-        "description": "ac: use HS offchip wg size from radeon_info in ac_compute_num_tess_patches",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d82eda72a1fe3932615b3fb16391e84de0431e6c",
-        "description": "ac/gpu_info: move HS info into radeon_info",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ea294349bd49d57f85808de8c8d1d48e5b9e29d1",
-        "description": "radv: move the tess factor ring after the tess offchip ring",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c057d9105fc142ec043edb9eaee9acc05457db6d",
-        "description": "ac/gpu_info: add total_tess_ring_size",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "97119d980c49eeeda46540736d9f3c5af6ef2b00",
-        "description": "ac/gpu_info: clean up ac_get_hs_info, use standard terms like workgroup",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ac6351fd23ed322609536f94c8264f4660cacf40",
-        "description": "radeonsi/tests: use proper skip file",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3d3ca9b65e2dc09a765aba3c0e4b3878bd0a83bc",
-        "description": "venus: virtgpu: Require stable wire format",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2a4675ee9fa2742da9826d1b5fb064b6a0066713",
-        "description": "venus: fix missing renderer destructions",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "25b8f4f7143f2e022df245ba2e1a2ab3ed4a2f90",
-        "notes": null
-    },
-    {
-        "sha": "39e4fd98ce55a06c813a75f9db8c4e5a06aa25b1",
-        "description": "venus: Do not use instance pointer before NULL check",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "a753f50668e9b97351f30ac985202bcfcd10fb7f",
-        "notes": null
-    },
-    {
-        "sha": "7d3a99a46cc9f0527cfe9da0a0b5b75731cd614d",
-        "description": "nak/sm20: Use the correct index field for OpS2R",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "078ffb860b436c7b10a9180a9620749528c284b5",
-        "notes": null
-    },
-    {
-        "sha": "4d8d6a28c8ea533cc8959694805fa845500399e6",
-        "description": "nak: Use s2r for SV_CLOCK on Kepler",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "142fb563c49e7f9717ecb6a474dc1a3b613ebc8c",
-        "description": "nak/sm20: Improve folding of ffma and dfma",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9855467ed0c11305ad785676217de27b0ec96bac",
-        "description": "docs: Rename distro to distribution",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5251c824043939b0d9ec6ba3b7998cf46ad938a3",
-        "description": "docs: Drop distro unmaintained and deprecated file.",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "40845278766bd3009dbca21ddbcd5b104b122a48",
-        "description": "intel/compiler: Always run opt_algebraic after descriptor_lowering",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c0f56fc64cad946d5c4fda509ef3056994c183d9",
-        "description": "nvk: Return an error for Kepler storage images instead of asserting",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f6b9d13a150a27682f170bee96dce8448ffafe71",
-        "description": "nak/sm20: Implement OpBar",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8401a6084098a1be9899d42aeaf404448f4e6941",
-        "description": "nak/sm20: Add double ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "608eef01d6f0fd57720e3d273290c817db8add4f",
-        "description": "nak/sm20: Add subgroup ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5a140e7c3e6351f52f0087be8a9f414cd4e3f747",
-        "description": "nak/sm20: Add more memory ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "84f18f31ad7b38c8a6ef71a4a96689595217efb3",
-        "description": "amdgpu: Add queue id support to the user queue wait IOCTL",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "949d2e507d9678815d0e8413fb891ff4059a85e2",
-        "description": "anv: expose promoted KHR_depth_clamp_zero_one",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ddbf2ec8839b1ffa1ebd665a9b9bc8db3b810357",
-        "description": "nak: Add a new OpFSwz and use it for derivatives on Kepler",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "309c48cbb782573abfbad3f21da81f0fba016552",
-        "description": "nak/sm20: Add texture ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8d41221158550b47fb24c0486ae47ada0e47c2e1",
-        "description": "nak/nir: Use Kepler texture source ordering on SM30",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b8c7d937fedf51440084ac682d2be32a139cea44",
-        "description": "nak: Add OpTexDepBar",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "043995220ac91620902867ad7bf4c1402c3a7616",
-        "description": "nak/sm20: Add control-flow ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9a62a76c4660ea5a8c81deb76f5911c069833186",
-        "description": "nak/sm20: Add shader I/O ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bdbe6447edccba317c6a4705f17086c8cad2f07e",
-        "description": "nak/nir: Use Maxwell input interpolation for SM20+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0105a75c53cec3ac814339e9b0486e419c87def4",
-        "description": "nak/sm20: Add conversion ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b27fc463da2fbb11f1cd9c83b0de09247db6ca3c",
-        "description": "nak: Record and set DOES_FP64 in the SPH",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d249e7ddacfd741afb3e6fa3e9179390375c2b11",
-        "description": "nak: Lower 64-bit shifts in NIR on Kepler A and earlier",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9fbf63b5844bf18f0b079ed6ed7663a73820d0ad",
-        "description": "nak/sm20: Add integer ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a3330f1d466d746f23d72c498f2dcfb2ab479d50",
-        "description": "nak/sm20: Add float ops",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "078ffb860b436c7b10a9180a9620749528c284b5",
-        "description": "nak/sm20: Add initial SM20 encoding",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "84505c5d99cf95d57e1d7032b13f08420a8f4c0a",
-        "description": "asahi: fix possible null deref",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b756e7da65366d78b22f568fc4b1ba7afc7d6050",
-        "description": "agx: delete more inots",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e541ffcbe862956f16d2fe38716c97c0a14c06a5",
-        "description": "hk: fix patch count = 0 handling",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "21b12b540f7ecd443714a10e5e6cd8848733810a",
-        "description": "etnaviv: hwdb: update gc_feature_database from NXP",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d7c957c47490992b2a40a0a60611f0a6b3de9125",
-        "description": "etnaviv: hwdb: update gc_feature_database from ST",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e7c6037d12211c94c24839291d73bbddc19ca184",
-        "description": "ir3: use opt_shrink_vectors",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f269c7b3b51dde18ce836cbbcf554629a909863d",
-        "description": "nir/opt_shrink_vectors: enable for load_ubo_vec4",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "792c30dd323cfd68eca630a65d919eb673d427f0",
-        "description": "radv/meta: remove redundant parameter to blit_surf_for_image_level_layer()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a3f2c5f05ebb7e654739ea83e55affb40bc71892",
-        "description": "radv/meta: remove unnecessary radv_meta_blit2d_buffer::bs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "78c2feed00529c478c568d205ed64263f1d1cdce",
-        "description": "radv/meta: rename more buffer->memory for fill/copy/update operations",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "43c8cb1ae20c2e0ce4733d14c3ce18a567bfb78d",
-        "description": "radv/meta: remove unused functions/prototypes",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "78f03dcf70ed0c893fe31a241387e0204b767399",
-        "description": "radv/meta: simplify dealing with image layouts for blits/resolves",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0140b7ba577a37654e3f000db45b16e247ae96af",
-        "description": "agx: remove silly cls argument",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b1e86b3eaeb7efea6b6b38280c3367b0579a7d0a",
-        "description": "agx: early-kill sources only if it won't shuffle",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b88fe9b0c56d99db7a1c9581e1371a59df583a85",
-        "description": "agx: late-kill sources",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7fad96d1940e1546f43a54662d81ae270a77a1b8",
-        "description": "agx: model sources as late-kill in demand calcs",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "cc7aa31b304c01243a66da43a7dd870ba6a2846d",
-        "description": "ir3,tu,freedreno: Allow more tex coord interpolations for prefetch",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c4c7482a90b2cbcaf7cbf9a3612b7f6b8bf4a56f",
-        "description": "ir3: Move nir_intrinsic_barycentric_sysval to common ir3",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "33caee7dfe7aea752be130bca03670c1097abd91",
-        "description": "glx: drop dead GL_LIB_NAME define",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "5b89be3545aada5340c360101d1fb4d9ebdc2d56",
-        "notes": null
-    },
-    {
-        "sha": "a5033c54e7be8cc6ad90f8070b92b0395a4ee68b",
-        "description": "anv: use the common function for detecting a mesh shader stage",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9b477eea195b197869c931711a3fa8b2c9d72cfd",
-        "description": "intel/compiler: use a immediate when doing the shift",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e63b24bee8b4f153563f5e198c1f2ebb2e388b80",
-        "description": "ac,radeonsi: clear_state is not supported in user queue",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "61fd80a42eddbdd2cd900d0c49d89d2f95c66d97",
-        "description": "ac,winsys/amdgpu: get userq_ip_mask supported from kernel info ioctl",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b9054115d4eda1a784294d74958f7e09438ed34a",
-        "description": "amd: update amdgpu_drm.h for userq info",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5b89be3545aada5340c360101d1fb4d9ebdc2d56",
-        "description": "glx: Don't try to dlopen ourselves",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9a610c5ab9c1cefc097e533720d4134c6bc62652",
-        "description": "loader: Use RTLD_LOCAL not RTLD_GLOBAL",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bc811a602e853888c087f6b302fcff15a5964d0b",
-        "description": "radeonsi: fix configuring compute scratch",
-        "nominated": false,
-        "nomination_type": 2,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": "e433a57650c1a95e17e05ed58e3069cfb8664db6",
-        "notes": null
-    },
-    {
-        "sha": "6b1f30f3594c659435bb14c8ff1e70c69fdfb633",
-        "description": "ci: Fix Android container structured tagging checks",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b2490e58169028ff6f981ab4fcc208833af26ade",
-        "description": "ci: Uncollapse yaml-toml-shell-py-test log sections",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "519e329cd603daa088506ddb8b70a437aa88961f",
-        "description": "ci: bump apitrace",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "762b749f9f0144ef71ecf66af5a1b38c893394aa",
-        "description": "driconf: enable custom_border_colors_without_format for ANGLE-on-anv",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "995dc61bf55db37e2c2bd10897829ff98d2ac63d",
-        "description": "EGL: legacy-x11=dri2 should support hardware driver",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "323bad6b18717fcc395f67ef508e5a3d0aed7d02",
-        "notes": null
-    },
-    {
-        "sha": "76031ba53dd96ebec73e8dd4e90ea322ece991e0",
-        "description": "radv: Optimize the gfx12 encode shader",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "97f6287827371c9c208cd6e26419d65685111f46",
-        "description": "radv: Use the BVH8 format on GFX12",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "95e7343a7deed7a3bde37ec116f5380f249c6df5",
-        "description": "radv/bvh: Add helpers for encoding",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3af19f336c31b657b4f5f1eababe60936b0d77d8",
-        "description": "radv/bvh: Document GFX12 BVH encoding",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2942e3affb0200b4b0981676d8d5cecb29e5c5a7",
-        "description": "radv/rra: Set rra_accel_struct_header::rtip_level",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fa99eeb2b4058e3ead116e62accaccf4c5ee838c",
-        "description": "radv/rra: Move gfx10_3 specific code to a new file",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9d157173b2453742f28de333c53b1475b444ef5b",
-        "description": "radv: Refactor create_bvh_descriptor",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "978e9b670eaef3d6b3984f135af7d1d240938a7d",
-        "description": "aco,nir: Add support for new GFX12 ray tracing instructions",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ee0f7848581c813eb16d31a0da552c7797bfac13",
-        "description": "aco/ra: Don't consider precolored ops/defs in get_reg_impl",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b9e506afd48d9065a636bf6effb2438dd242b2fd",
-        "description": "aco: Add support for multiple definitions in emit_mimg",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f309d76aab3ec56d5b84fb54ffb1fc9d6472da97",
-        "description": "aco: Add support for multiple ops fixed to defs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fe739a2da267c40a07e04282a0ce08bd9e37186e",
-        "description": "ac: Add rt_version",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c33e598f39f34e6f63c1eae28feed60caad1a1d7",
-        "description": "vulkan: Add vk_ir_header::dst_leaf_node_offset",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2dee1117b75a859d7b055dec4f3e886e549590c1",
-        "description": "vulkan: Add a vk_device parameter to get_encode_key",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0cc9443e9b5419f927a3f81d4ed9b7e9c1829907",
-        "description": "util: Add BITSET_EXTRACT",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c37a468a8a109cbaece70760fd748fc838185b88",
-        "description": "pick-ui: make `Backport-to: 25.0` backport to 25.0 *and more recent release branches*",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "37e6a8b57ff38649121e77f7a548999fb9fcdbd5",
-        "description": "d3d12: Minor fixes to residency algorithm when eviction is needed",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "565980f3c0f360eb946fe9fa75b507290b2bd7d0",
-        "description": "d3d12: Add tc memory throttles",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "43e521f7a58b9e83eebcff696c426c59711a6b52",
-        "description": "hk: Don't expect garbage on shared_size",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "33295b2249b46c5c0c3c5dae143c9a5572662902",
-        "description": "spirv, nir: Allow non-Aliased workgroup memory blocks",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fd0a7efb5af5840f29e29e66dcef4c114ba7c94e",
-        "description": "spirv, nir: Delay calculation of shared_size when using explicit layout",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "adfe29cb46ca7e8c5b8ea30dc31f3244e5fe2e91",
-        "description": "ci: give high priority to post-merge jobs as well",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a96e280dfe52e57a5f7174e864029b7510e70f40",
-        "description": "intel: Program XY_FAST_COLOR_BLT::Destination Mocs for gfx12",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8b068ef6c1420d8795a24215f0f4f9b820a9b9ff",
-        "description": "hk: handle HIC with twiddled",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "88bdc27342a81258af0828a30e9e7770353542f8",
-        "description": "asahi: let booleans be your guide",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "551355d4e5239b079b4782e09cb9573ae600efa7",
-        "description": "asahi,hk: factor out zls_control pack helper",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3a560dd32b8882cc0829c8dca316078e971fee87",
-        "description": "asahi: identify ZLS compress load/store bits",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9757185153c59b16b1146c0005db1c295311f404",
-        "description": "hk: plumb ZLS tiling",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "454a90eaa87a00f020dc152667d56a9184da024d",
-        "description": "asahi: plumb ZLS tiling bits",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "715f6b3b331aa3e95739deba8068e0e437cb9339",
-        "description": "asahi: identify ZLS tiling bits",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0dca602aff269b3bfcddc2e825ec4fdee4bbfdc0",
-        "description": "asahi: generalize compression check",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "72f3dcc8da10acf329e1972ef5df7d6fcc431d2d",
-        "description": "asahi: generalize tiling checks",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c4130af883448e82e93418998adcb5e8e5057732",
-        "description": "asahi: extend tile width/height in texture desc",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f21dc4d0cf982683603b90ee33f0280dd7ce076d",
-        "description": "asahi: pack sample count in s/w texture descriptor",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8f57b5187f3258463c9ca1c15e02e4cdc2359ad1",
-        "description": "ail: support twiddled",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6fdad684daa46e4191df8d4d4886513917df5f2a",
-        "description": "ail: generalize ail_space_bits",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e5006dc6ae984def3dbdaa0848a906b2ee398e0b",
-        "description": "hk: fill sparse.write with nonzero values",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ffac153bcff393fc6341ab525b92c0e7efa30d6f",
-        "description": "hk: reindent/unscope",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "86d3489c35db5cafef87831b2f48e9e2d6ab3efe",
-        "description": "hk: drop FS null checks",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3ab8ce8579c967e1d8fb024de298a958511d9ffd",
-        "description": "hk: fix null FS corner cases",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d959557669f9deb5647e2481afbe1f3d55aa79f9",
-        "description": "hk: fix tessellation + clipper queries",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "427479c0404f1b2b77cd651da8e942196e1e2ddd",
-        "description": "aco: remove va_vdst/vm_vsrc/sa_sdst variables",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3d6fa6996c2544a3cb4dd792d795fb17f298a4f9",
-        "description": "aco: init vm_vsrc/sa_sdst from depctr_wait",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ce2be5ab8eff11673bf46436ea1cde48915eadf6",
-        "description": "aco: combine VALU lanemask hazard into VALUMaskWriteHazard",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "eee3c8eab8e57669bfa1397297c62a52215088a5",
-        "description": "nak: Handle idp4 ureg latencies",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "6b8a4e6bb73117e1141fe80e6d8fdfe5d2a39d33",
-        "notes": null
-    },
-    {
-        "sha": "de1ed48325ce70565ee2c159a1911eef43d663c4",
-        "description": "nak/spill_values: Spill constants across edges if needed",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "7b82e26e3c289b2937df65f610d6ffc734e3bbde",
-        "notes": null
-    },
-    {
-        "sha": "8744c98fa9c977c962ed3dc511619b0d08496400",
-        "description": "meson: remove duplicate `deprecated` for `power8` option",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "c4b305079d70790ee9d34a25a2f70759ece96f0d",
-        "notes": null
-    },
-    {
-        "sha": "b9472db4963d3d434dc02a2adc7f6ce1e99ddaa1",
-        "description": "meson: remove duplicate `deprecated` for `gallium-xa` option",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "cf40099730c4af304227c30c891834cec220abff",
-        "notes": null
-    },
-    {
-        "sha": "cbc1ec4f73483df36968dd54274f5f03a1b95851",
-        "description": "anv: re enable compression for CPS surfaces on platforms other than Xe",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "80f9b61f0225e23705cf0d2b243f9eb27a9cfa9e",
-        "notes": null
-    },
-    {
-        "sha": "4fcf2eb1d76823b8bab4d665f706a766f5bea2ed",
-        "description": "aco/gfx12: VOPD src0/1 are src bank compatible if they are the same vgpr",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3446f2059d551a4cf1c1ac6d8594000ff483935e",
-        "description": "aco/gfx12: assume VOPD with two v_mov_b32 are src bank compatible",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "1bd5ae7b14cdb9c1ae95eb8e6afe0aabf4474f68",
-        "description": "aco: refactor can_use_vopd so that it returns flags",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d4b418bbb9c91cff8c8e4a2ceb9f0e694cc8ef20",
-        "description": "aco: add are_src_banks_compatible helper for VOPD creation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4b0da5b51ff9ef3e2362aa43e5564d43bdb045f5",
-        "description": "aco: rename is_opy_only to can_be_opx",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "408fa33c092810155baac342de90fd712231aa89",
-        "description": "aco/gfx12: don't use second VALU for VOPD's OPX if there is a WaR",
-        "nominated": true,
-        "nomination_type": 4,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a9fde960e64f777c134449e57a160591e6e9547d",
-        "description": "etnaviv/ml: Support FullyConnected with signed weights",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9615d44d6e4ad6b3de63459fb4377f5515c9f8c6",
-        "description": "teflon: Skip unsupported FullyConvolution operations",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9409595c325dae8ec19861ed6081931cf3e6bb81",
-        "description": "etnaviv/ml: All tensors are now 4D, adapt to it",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c728e73d650c431b38302583b2b72fc4592d87ba",
-        "description": "etnaviv/ml: Track memory layout of tensors",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c4a5f8d66575d7f2b559243633614d952b8dd16e",
-        "description": "teflon: Set unused dimensions to 1",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "23ae1c3bff55b6f945cd96aca51e3bcc68606085",
-        "description": "teflon: Actually accept concatenations with different number of channels",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "bde0e69bcdfae20f91552ec01f2c08a7529d7718",
-        "description": "etnaviv/ml: Consolidate transpose/detranspose",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e06265ed3a7bc41be38593957292adc7b2b32caa",
-        "description": "teflon: Only mark integers as signed",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "209a0ede9813e1d2feb8b254f06c891703bcf0d4",
-        "description": "radv: add a function to emit meshlet registers on GFX11+",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "836757bec3b0acc22d25d086af3ed98c2a8d9f20",
-        "description": "radv: tidy up radv_emit_ps_epilog_state()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "dca35b7226c9d853efeb7bf197909059638b440f",
-        "description": "radv: tidy up radv_emit_geometry_shader()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d999afeb7acfaca11ae579cf50ad3858c34f0b5f",
-        "description": "radv: tidy up radv_emit_vertex_shader()",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "85fdf69027d528888b801dc46567046377be130e",
-        "description": "radv: simplify combining TES/VS+GS config registers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0dd9833348022a668704914191487a2a7688e134",
-        "description": "radv: remove redundant assertion when emitting PS epilog state",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "a230d2daa3c42fca270c35d1810b8243d3ad63d3",
-        "description": "radv: use radeon_set_sh_reg() for only 1 DWORD",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "4dabc7776fd6d194d664f27e53ad0ad16300972a",
-        "description": "ci/android: show how to add more Android CTS test cases",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "fbc715200e6acc96de1ec0d091abadbd5bfb6546",
-        "description": "ci/android: strip tailing spaces in Android CTS expectation files",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8f41667b37c3d22d5fad6798abb5d95f6e6a7cff",
-        "description": "ci/android: specify EXCLUDE_FILTERS after INCLUDE_FILTERS when launching Android CTS",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "af96ed09f074b4a39d0eea2080327f202995ae3e",
-        "description": "ci/deqp: force overwriting exiting files when compressing with zstd",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "3e2f43bb131a53c341333a2873192cafe6f0a8a1",
-        "description": "ci/android: only use custom kernel for venus GPU_MODEs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "725acc0b74d4abb7a341454ddcf4203801c11e72",
-        "description": "meson: bump default value of platform-sdk-version to Android 14",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "11e8a9649566b9a032a86da6fe617d350fd4e549",
-        "description": "radv: use common scratch tmpring size programming",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "710d7ea8b8b72f9e2292d22dca6d22810e27f376",
-        "description": "radv: compute the optimal scratch wavesize",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e433a57650c1a95e17e05ed58e3069cfb8664db6",
-        "description": "ac,radeonsi: rework computing scratch wavesize and tmpring register",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d94f8b4460369cc3de105ec4b4120dfc24fe1669",
-        "description": "ac/gpu_info,radv: add scratch_wavesize_granularity info",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "82dda2180624dea25887af405840297b593af71f",
-        "description": "zink: Do not use demote on IMG blobs",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8d08cde667954e71592cee70933a38afe04deb7b",
-        "description": "ci/piglit: Use structured tagging for Piglit",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "e616761fb2d845c4f1764920d0168e556d184473",
-        "description": "radv: re-introduce the compute vs CP DMA heuristic for copy/fill operations",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5e2508e7c44840b3a662cf0e666e72c1deeec557",
-        "description": "radv: simplify radv_fill_xxx() helpers",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "8ba94d8263f1f9b3c5baf1514de2878fd7505019",
-        "description": "radv: add radv_fill_image() helper",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0fa43b5bfb08489a68645a33c43520cff97005ca",
-        "description": "radv: use radv_fill_memory() in the accel struct path",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "6d70ec449ff3c6a3216a56c7e88fbbee3bda2291",
-        "description": "iris: make sure to not mix compressed vs non-compressed",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "c2a46578626402c2ceebfe5a4a8e6640101678a6",
-        "description": "iris: force reallocate on eglCreateImage with GFX >= 20",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "aa73767f5e34c92e29e75fe8a6649b15168ed7a6",
-        "description": "etnaviv/ml: Support per-channel quantized weights",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ce9030740a9ee615970b24417b5851ca0589297b",
-        "description": "teflon: Allow per-axis quantization",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7dfcca9007a97109eabb2958904bcc35ad633960",
-        "description": "etnaviv/ml: Fix zero point values for signedness",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d88f0b8f3c11fa23d58ae3892c1f8f2f37150c59",
-        "description": "etnaviv/ml: Reorder dimensions in convolutions",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d55a69e76939b312fd56d15cbe706cda3e1ad6b4",
-        "description": "nak: make is_fneg_zero detect -rZ",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "47fc46894414be0e98c2f0c5bc76cc0c9d866fbe",
-        "description": "nak/sm70: Fix the bit74_75_ar_mod assert",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "40422927dcb1249cdb1444557aca671387140428",
-        "notes": null
-    },
-    {
-        "sha": "328112c6bc7ffe129b6b83619f3c130858e21417",
-        "description": "nak/legalize: Take a RegFile in copy_alu_src_and_lower_ineg()",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "af6093a71267f6be5392c74491ab68f83ff750d0",
-        "notes": null
-    },
-    {
-        "sha": "22a30bfa4f9424c221d641bc79468f4928b39440",
-        "description": "nak/legalize: Take a RegFile in copy_alu_src_and_lower_fmod",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "269b09c44987b1c6a21bd0bd8b1643bc71db00de",
-        "description": "docs: add sha sum for 25.0.4",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "71c1acfaf2c1c99051521a4227c77ae9ab48bf04",
-        "description": "docs: add release notes for 25.0.4",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f74a585dbb14d029c59b3c79f9c95c18026e0222",
-        "description": "docs: update calendar for 25.0.4",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "d5ad7981401c2393cac38fc3215e8bbb97de06b9",
-        "description": "spirv, radv, intel: Add NIR intrinsic for cmat conversion",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "2f02fa5db4baae40711a11e743ea0c156d9dae7b",
-        "description": "intel/ci: Start using the new 6.14 kernel on JSL",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "da71656dd95793b1d5e3f8a139fe44b751255766",
-        "description": "ci/lava: Merge and deduplicate log sections",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "70b033d2adf961b2793f6e4ac5aaa5df11ce1106",
-        "description": "ci/lava: Don't include the timeout in the log sections",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "f7224dd159c2c74ccd5cab1637b4552ecee6442b",
-        "description": "ci/lava: Collapse more log sections",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "60a31156b09e7ed16d0f4434cdc3dd93cb1488a6",
-        "description": "mesa_interface: fix legacy dri2 compatibility",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "3b603d164662d0f5c70a9c8dcbfc6a987ed8b94e",
-        "notes": null
-    },
-    {
-        "sha": "de6efc01c123d63508a8c32936c1ff2cfd4c1081",
-        "description": "zink: verify that surface exists when adding implicit feedback loop",
-        "nominated": true,
-        "nomination_type": 1,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "251d1e2551c556b561c5a4278dc6b13f940ec056",
-        "description": "etnaviv/ml: Use etna_buffer_resource instead of etna_resource",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "d738b3ea2b78df138758dfd166262c1890e94c22",
-        "notes": null
-    },
-    {
-        "sha": "1f5bc6ddbf995863c66228b1f81bcc124ddc17c8",
-        "description": "etnaviv/tests: Add comment on why the SSDLite MobileDet test fails",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "0213eef3b358c9e190e6d6286fe49796cd4e6146",
-        "description": "teflon/tests: Dump output buffers to disk",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "80e09e9b1ff23c05723633c17cbc3786d4a8e516",
-        "description": "teflon/tests: Divide the tolerance level by a constant",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "15a8c49ad5a3bd9b46f91afee84aef169105264b",
-        "description": "teflon/tests: Print shorter negative INT8s",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "554fb8af11a17653ea0e65c1003643ae6acc7c59",
-        "description": "teflon/tests: Take into account signedness when checking the output tensors",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b3746305eae8d7412672fb5ee2b65e065f1f1dc3",
-        "description": "teflon/tests: Test all models in /models",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "68200ac9619be79954979b323b683820d80c630f",
-        "description": "teflon/tests: Use a single tolerance value",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "7ca4e4d34bab4c8536e5e28829931c43534411fe",
-        "description": "microsoft/compiler: Force load_output => undef in tess_ctrl main func",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "ab591dc642aafd6c33a9a9ba7b3a4f59d56e1f3d",
-        "description": "iris: Fix IRIS_HEAP_SYSTEM_MEMORY_CACHED_COHERENT slab parent allocation",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "9b55451ea7baf3a6f487765fa6d1c0fb5be5ddb6",
-        "description": "hk: fix underbinding scratch",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "678134add50eb4c4e388ea9233e0f457de68fe75",
-        "notes": null
-    },
-    {
-        "sha": "dbe6c3927020eb75d07fdc1323a5ad30628b9659",
-        "description": "docs: update calendar for 25.1.0-rc1",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "5844dea31620f36c41ac738e17fefd57084b2dbb",
-        "description": "delete clover",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "555821ff93118d4a6ea441127cd0427a95743d47",
-        "description": "winsys/amdgpu: disable VM_ALWAYS_VALID",
-        "nominated": true,
-        "nomination_type": 2,
-        "resolution": 1,
-        "main_sha": null,
-        "because_sha": "8c91624614c1f939974fe0d2d1a3baf83335cecb",
-        "notes": null
-    },
-    {
-        "sha": "3f7345a0ce04ce28073a1f8d557fe45c24cc8a9c",
-        "description": "docs: reset new_features.txt",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    },
-    {
-        "sha": "b8968276e6d5d54483bd5baf74d73b43f111ddaa",
-        "description": "VERSION: bump to 25.2",
-        "nominated": false,
-        "nomination_type": 0,
-        "resolution": 4,
-        "main_sha": null,
-        "because_sha": null,
-        "notes": null
-    }
-]
\ No newline at end of file
diff --git a/VERSION b/VERSION
index a20b126a277..11ee655b7b8 100644
--- a/VERSION
+++ b/VERSION
@@ -1 +1 @@
-25.1.0
+25.2.0-devel
diff --git a/android/Android.mk b/android/Android.mk
index 1df8da523af..4befeb6a345 100644
--- a/android/Android.mk
+++ b/android/Android.mk
@@ -104,6 +104,7 @@ LOCAL_SHARED_LIBRARIES += \
     libutils
 ifeq ($(shell test $(PLATFORM_SDK_VERSION) -ge 35; echo $$?), 0)
 LOCAL_SHARED_LIBRARIES += libui
+LOCAL_STATIC_LIBRARIES += libzstd
 MESON_GEN_PKGCONFIGS += ui
 endif
 MESON_GEN_PKGCONFIGS += android.hardware.graphics.mapper:4.0
diff --git a/bin/ci/ci_run_n_monitor.py b/bin/ci/ci_run_n_monitor.py
index 5cd732be4fe..a131b383089 100755
--- a/bin/ci/ci_run_n_monitor.py
+++ b/bin/ci/ci_run_n_monitor.py
@@ -16,12 +16,12 @@ import argparse
 import re
 import sys
 import time
-from collections import defaultdict
+from collections import defaultdict, Counter
 from concurrent.futures import ThreadPoolExecutor
 from functools import partial
 from itertools import chain
 from subprocess import check_output, CalledProcessError
-from typing import Dict, TYPE_CHECKING, Iterable, Literal, Optional, Tuple
+from typing import Callable, Dict, TYPE_CHECKING, Iterable, Literal, Optional, Tuple, cast
 
 import gitlab
 import gitlab.v4.objects
@@ -44,6 +44,7 @@ if TYPE_CHECKING:
 
 REFRESH_WAIT_LOG = 10
 REFRESH_WAIT_JOBS = 6
+MAX_ENABLE_JOB_ATTEMPTS = 3
 
 URL_START = "\033]8;;"
 URL_END = "\033]8;;\a"
@@ -99,17 +100,44 @@ def job_duration(job: gitlab.v4.objects.ProjectPipelineJob) -> float:
     if job.duration:
         return job.duration
     elif job.started_at:
-        return time.perf_counter() - time.mktime(job.started_at.timetuple())
+        # Convert both times to UTC timestamps for consistent comparison
+        current_time = time.time()
+        start_time = job.started_at.timestamp()
+        return current_time - start_time
     return 0.0
 
 
 def pretty_wait(sec: int) -> None:
     """shows progressbar in dots"""
     for val in range(sec, 0, -1):
-        print(f"â²  {val} seconds", end="\r")  # U+23F2 Timer clock
+        print(f"â²  {val:2d} seconds", end="\r")  # U+23F2 Timer clock
         time.sleep(1)
 
 
+def run_target_job(
+    job: gitlab.v4.objects.ProjectPipelineJob,
+    enable_job_fn: Callable,
+    stress: int,
+    execution_times: dict,
+    target_statuses: dict,
+    name_field_pad: int,
+) -> None:
+    execution_times[job.name][job.id] = (job_duration(job), job.status, job.web_url)
+    if stress and job.status in COMPLETED_STATUSES:
+        if (
+            stress < 0
+            or len(execution_times[job.name]) < stress
+        ):
+            enable_job_fn(job=job, action_type="retry")
+            # Wait for the next loop to get the updated job object
+            return
+    else:
+        enable_job_fn(job=job, action_type="target")
+
+    print_job_status(job, job.status not in target_statuses[job.name], name_field_pad)
+    target_statuses[job.name] = job.status
+
+
 def monitor_pipeline(
     project: gitlab.v4.objects.Project,
     pipeline: gitlab.v4.objects.ProjectPipeline,
@@ -122,8 +150,7 @@ def monitor_pipeline(
     """Monitors pipeline and delegate canceling jobs"""
     statuses: dict[str, str] = defaultdict(str)
     target_statuses: dict[str, str] = defaultdict(str)
-    stress_status_counter: dict[str, dict[str, int]] = defaultdict(lambda: defaultdict(int))
-    execution_times = defaultdict(lambda: defaultdict(tuple))
+    execution_times: dict[str, dict[str, tuple[float, str, str]]] = defaultdict(lambda: defaultdict(tuple))
     target_id: int = -1
     name_field_pad: int = len(max(dependencies, key=len))+2
     # In a running pipeline, we can skip following job traces that are in these statuses.
@@ -137,17 +164,18 @@ def monitor_pipeline(
                include_stage_regex.fullmatch(job.stage) and \
                not exclude_stage_regex.fullmatch(job.stage) and \
                job.status in COMPLETED_STATUSES:
-                stress_status_counter[job.name][job.status] += 1
                 execution_times[job.name][job.id] = (job_duration(job), job.status, job.web_url)
 
     # jobs_waiting is a list of job names that are waiting for status update.
     # It occurs when a job that we want to run depends on another job that is not yet finished.
     jobs_waiting = []
+    # Dictionary to track the number of attempts made for each job
+    enable_attempts: dict[int, int] = {}
     # FIXME: This function has too many parameters, consider refactoring.
     enable_job_fn = partial(
         enable_job,
         project=project,
-        pipeline=pipeline,
+        enable_attempts=enable_attempts,
         job_name_field_pad=name_field_pad,
         jobs_waiting=jobs_waiting,
     )
@@ -156,28 +184,20 @@ def monitor_pipeline(
         to_cancel = []
         jobs_waiting.clear()
         for job in sorted(pipeline.jobs.list(all=True), key=lambda j: j.name):
+            job = cast(gitlab.v4.objects.ProjectPipelineJob, job)
             if target_jobs_regex.fullmatch(job.name) and \
                include_stage_regex.fullmatch(job.stage) and \
                not exclude_stage_regex.fullmatch(job.stage):
+                run_target_job(
+                    job,
+                    enable_job_fn,
+                    stress,
+                    execution_times,
+                    target_statuses,
+                    name_field_pad,
+                )
                 target_id = job.id
-                target_status = job.status
-
-                if stress and target_status in COMPLETED_STATUSES:
-                    if (
-                        stress < 0
-                        or sum(stress_status_counter[job.name].values()) < stress
-                    ):
-                        stress_status_counter[job.name][target_status] += 1
-                        execution_times[job.name][job.id] = (job_duration(job), target_status, job.web_url)
-                        job = enable_job_fn(job=job, action_type="retry")
-                else:
-                    execution_times[job.name][job.id] = (job_duration(job), target_status, job.web_url)
-                    job = enable_job_fn(job=job, action_type="target")
-
-                print_job_status(job, target_status not in target_statuses[job.name], name_field_pad)
-                target_statuses[job.name] = target_status
                 continue
-
             # all other non-target jobs
             if job.status != statuses[job.name]:
                 print_job_status(job, True, name_field_pad)
@@ -185,7 +205,9 @@ def monitor_pipeline(
 
             # run dependencies and cancel the rest
             if job.name in dependencies:
-                job = enable_job_fn(job=job, action_type="dep")
+                if not enable_job_fn(job=job, action_type="dep"):
+                    # Wait for the next loop to get the updated job object
+                    continue
                 if job.status == "failed":
                     deps_failed.append(job.name)
             else:
@@ -195,14 +217,22 @@ def monitor_pipeline(
 
         if stress:
             enough = True
-            for job_name, status in sorted(stress_status_counter.items()):
+            status_counters = {
+                name: Counter(info[1] for info in runs.values())
+                for name, runs in execution_times.items()
+            }
+            for job_name, counter in sorted(status_counters.items()):
+                n_succeed = counter.get("success", 0)
+                n_failed = counter.get("failed", 0)
+                n_total_completed = n_succeed + n_failed
+                n_total_seen = len(execution_times[job_name])
                 print(
-                    f"* {job_name:{name_field_pad}}succ: {status['success']}; "
-                    f"fail: {status['failed']}; "
-                    f"total: {sum(status.values())} of {stress}",
+                    f"* {job_name:{name_field_pad}}succ: {n_succeed}; "
+                    f"fail: {n_failed}; "
+                    f"total: {n_total_seen} of {stress}",
                     flush=False,
                 )
-                if stress < 0 or sum(status.values()) < stress:
+                if stress < 0 or n_total_completed < stress:
                     enough = False
 
             if not enough:
@@ -218,8 +248,10 @@ def monitor_pipeline(
             pretty_wait(REFRESH_WAIT_JOBS)
             continue
 
-        if len(target_statuses) == 1 and RUNNING_STATUSES.intersection(
-            target_statuses.values()
+        if (
+            stress in [0, 1]
+            and len(target_statuses) == 1
+            and RUNNING_STATUSES.intersection(target_statuses.values())
         ):
             return target_id, None, execution_times
 
@@ -247,42 +279,58 @@ def monitor_pipeline(
         pretty_wait(REFRESH_WAIT_JOBS)
 
 
-def get_pipeline_job(
-    pipeline: gitlab.v4.objects.ProjectPipeline,
-    job_id: int,
-) -> gitlab.v4.objects.ProjectPipelineJob:
-    pipeline_jobs = pipeline.jobs.list(all=True)
-    return [j for j in pipeline_jobs if j.id == job_id][0]
-
-
 def enable_job(
     project: gitlab.v4.objects.Project,
-    pipeline: gitlab.v4.objects.ProjectPipeline,
     job: gitlab.v4.objects.ProjectPipelineJob,
+    enable_attempts: dict[int, int],
     action_type: Literal["target", "dep", "retry"],
     job_name_field_pad: int = 0,
     jobs_waiting: list[str] = [],
-) -> gitlab.v4.objects.ProjectPipelineJob:
+) -> bool:
+    """
+    Enable a job to run.
+    :param project: The GitLab project.
+    :param job: The job to enable.
+    :param enable_attempts: A dictionary to track the number of attempts made for each job.
+    :param action_type: The type of action to perform.
+    :return: True if the job was enabled, False otherwise.
+    """
     # We want to run this job, but it is not ready to run yet, so let's try again in the next
     # iteration.
     if job.status == "created":
         jobs_waiting.append(job.name)
-        return job
+        return False
 
     if (
         (job.status in COMPLETED_STATUSES and action_type != "retry")
         or job.status in {"skipped"} | RUNNING_STATUSES
     ):
-        return job
+        return False
+
+    # Get current attempt number
+    attempt_count = enable_attempts.get(job.id, 0)
+    # Check if we've exceeded max attempts to avoid infinite loop
+    if attempt_count >= MAX_ENABLE_JOB_ATTEMPTS:
+        raise RuntimeError(
+            f"Maximum enabling attempts ({MAX_ENABLE_JOB_ATTEMPTS}) reached for job {job.name} "
+            f"({link2print(job.web_url, job.id)}). Giving up."
+        )
+    enable_attempts[job.id] = attempt_count + 1
 
     pjob = project.jobs.get(job.id, lazy=True)
 
     if job.status in {"success", "failed", "canceled", "canceling"}:
-        new_job = pjob.retry()
-        job = get_pipeline_job(pipeline, new_job["id"])
+        try:
+            pjob.retry()
+        except Exception as e:
+            print(f"Error retrying job {job.name}: {e}")
+            return False
     else:
-        pjob.play()
-        job = get_pipeline_job(pipeline, pjob.id)
+        try:
+            pjob.play()
+        except Exception as e:
+            print(f"Error playing job {job.name}: {e}")
+            return False
 
     if action_type == "target":
         jtype = "ð target"  # U+1F78B Round target
@@ -294,7 +342,7 @@ def enable_job(
     job_name_field_pad = len(job.name) if job_name_field_pad < 1 else job_name_field_pad
     print(Fore.MAGENTA + f"{jtype} job {job.name:{job_name_field_pad}}manually enabled" + Style.RESET_ALL)
 
-    return job
+    return True
 
 
 def cancel_job(
@@ -378,9 +426,9 @@ def parse_args() -> argparse.Namespace:
         help="Job stages to exclude when searching for target jobs. "
              "For multiple targets, pass multiple values, eg. "
              "`--exclude-stage foo bar`. By default, performance and "
-             "post-merge jobs are excluded; pass --exclude-stage '' to "
+             "nightly jobs are excluded; pass --exclude-stage '' to "
              "include them for consideration.",
-        default=["performance", ".*-postmerge"],
+        default=["performance", ".*-postmerge", ".*-nightly"],
         nargs=argparse.ONE_OR_MORE,
     )
     parser.add_argument(
diff --git a/docs/ci/LAVA.rst b/docs/ci/LAVA.rst
index c8911c71d08..43b2bcef85b 100644
--- a/docs/ci/LAVA.rst
+++ b/docs/ci/LAVA.rst
@@ -85,3 +85,46 @@ relevant as we have many stable branches all using CI).
 
 Now it's time to define your test jobs in the driver-specific
 gitlab-ci.yml file, using the device-specific tags.
+
+Caching downloads
+-----------------
+
+To improve the runtime for downloading traces during traces job runs, you will
+want a pass-through HTTP cache.  On your runner box, install nginx:
+
+.. code-block:: sh
+
+   sudo apt install nginx libnginx-mod-http-lua
+
+Add the server setup files:
+
+.. literalinclude:: fdo-cache
+   :name: /etc/nginx/sites-available/fdo-cache
+   :caption: /etc/nginx/sites-available/fdo-cache
+
+.. literalinclude:: uri-caching.conf
+   :name: /etc/nginx/snippets/uri-caching.conf
+   :caption: /etc/nginx/snippets/uri-caching.conf
+
+Edit the listener addresses in fdo-cache to suit the ethernet interface that
+your devices are on.
+
+Enable the site and restart nginx:
+
+.. code-block:: sh
+
+   sudo rm /etc/nginx/sites-enabled/default
+   sudo ln -s /etc/nginx/sites-available/fdo-cache /etc/nginx/sites-enabled/fdo-cache
+   sudo systemctl restart nginx
+
+   # First download will hit the internet
+   wget http://localhost/cache/?uri=https://s3.freedesktop.org/mesa-tracie-public/itoral-gl-terrain-demo/demo-v2.trace
+   # Second download should be cached.
+   wget http://localhost/cache/?uri=https://s3.freedesktop.org/mesa-tracie-public/itoral-gl-terrain-demo/demo-v2.trace
+
+Now, set ``download-url`` in your ``traces-*.yml`` entry to something like
+``http://caching-proxy/cache/?uri=https://s3.freedesktop.org/mesa-tracie-public``
+and you should have cached downloads for traces.  Add it to
+``FDO_HTTP_CACHE_URI=`` in your ``config.toml`` runner environment lines and you
+can use it for cached artifact downloads instead of going all the way to
+freedesktop.org on each job.
diff --git a/docs/ci/bare-metal.rst b/docs/ci/bare-metal.rst
index 772f5f4c984..16dbd4e8a2e 100644
--- a/docs/ci/bare-metal.rst
+++ b/docs/ci/bare-metal.rst
@@ -1,232 +1,10 @@
 Bare-metal CI
 =============
 
-The bare-metal scripts run on a system with gitlab-runner and Docker,
-connected to potentially multiple bare-metal boards that run tests of
-Mesa.  Currently "fastboot", "ChromeOS Servo", and POE-powered devices are
-supported.
+Bare-metal support is being removed from Mesa, and adding new devices is
+no longer supported.
 
-In comparison with LAVA, this doesn't involve maintaining a separate
-web service with its own job scheduler and replicating jobs between the
-two.  It also places more of the board support in Git, instead of
-web service configuration.  On the other hand, the serial interactions
-and bootloader support are more primitive.
+Please consider using one of the following alternatives:
 
-Requirements (fastboot)
------------------------
-
-This testing requires power control of the DUTs by the gitlab-runner
-machine, since this is what we use to reset the system and get back to
-a pristine state at the start of testing.
-
-We require access to the console output from the gitlab-runner system,
-since that is how we get the final results back from the tests.  You
-should probably have the console on a serial connection, so that you
-can see bootloader progress.
-
-The boards need to be able to have a kernel/initramfs supplied by the
-gitlab-runner system, since Mesa often needs to update the kernel either for new
-DRM functionality, or to fix kernel bugs.
-
-The boards must have networking, so that we can extract the dEQP XML results to
-artifacts on GitLab, and so that we can download traces (too large for an
-initramfs) for trace replay testing.  Given that we need networking already, and
-our dEQP/Piglit/etc. payload is large, we use NFS from the x86 runner system
-rather than initramfs.
-
-See ``src/freedreno/ci/gitlab-ci.yml`` for an example of fastboot on DB410c and
-DB820c (freedreno-a306 and freedreno-a530).
-
-Requirements (Servo)
---------------------
-
-For Servo-connected boards, we can use the EC connection for power
-control to reboot the board.  However, loading a kernel is not as easy
-as fastboot, so we assume your bootloader can do TFTP, and that your
-gitlab-runner mounts the runner's tftp directory specific to the board
-at /tftp in the container.
-
-Since we're going the TFTP route, we also use NFS root.  This avoids
-packing the rootfs and sending it to the board as a ramdisk, which
-means we can support larger rootfses (for Piglit testing), at the cost
-of needing more storage on the runner.
-
-Telling the board about where its TFTP and NFS should come from is
-done using dnsmasq on the runner host.  For example, this snippet in
-the dnsmasq.conf.d in the Google farm, with the gitlab-runner host we
-call "servo"::
-
-   dhcp-host=1c:69:7a:0d:a3:d3,10.42.0.10,set:servo
-
-   # Fixed dhcp addresses for my sanity, and setting a tag for
-   # specializing other DHCP options
-   dhcp-host=a0:ce:c8:c8:d9:5d,10.42.0.11,set:cheza1
-   dhcp-host=a0:ce:c8:c8:d8:81,10.42.0.12,set:cheza2
-
-   # Specify the next server, watch out for the double ',,'.  The
-   # filename didn't seem to get picked up by the bootloader, so we use
-   # tftp-unique-root and mount directories like
-   # /srv/tftp/10.42.0.11/jwerner/cheza as /tftp in the job containers.
-   tftp-unique-root
-   dhcp-boot=tag:cheza1,cheza1/vmlinuz,,10.42.0.10
-   dhcp-boot=tag:cheza2,cheza2/vmlinuz,,10.42.0.10
-
-   dhcp-option=tag:cheza1,option:root-path,/srv/nfs/cheza1
-   dhcp-option=tag:cheza2,option:root-path,/srv/nfs/cheza2
-
-See ``src/freedreno/ci/gitlab-ci.yml`` for an example of Servo on cheza.  Note
-that other Servo boards in CI are managed using LAVA.
-
-Requirements (POE)
-------------------
-
-For boards with 30W or less power consumption, POE can be used for the power
-control.  The parts list ends up looking something like (for example):
-
-- x86-64 gitlab-runner machine with a mid-range CPU, and 3+ GB of SSD storage
-  per board.  This can host at least 15 boards in our experience.
-- Cisco 2960S gigabit ethernet switch with POE. (Cisco 3750G, 3560G, or 2960G
-  were also recommended as reasonable-priced HW, but make sure the name ends in
-  G, X, or S)
-- POE splitters to power the boards (you can find ones that go to micro USB,
-  USBC, and 5V barrel jacks at least)
-- USB serial cables (Adafruit sells pretty reliable ones)
-- A large powered USB hub for all the serial cables
-- A pile of ethernet cables
-
-You'll talk to the Cisco for configuration using its USB port, which provides a
-serial terminal at 9600 baud.  You need to enable SNMP control, which we'll do
-using a "mesaci" community name that the gitlab runner can access as its
-authentication (no password) to configure.  To talk to the SNMP on the router,
-you need to put an IP address on the default VLAN (VLAN 1).
-
-Setting that up looks something like:
-
-.. code-block: console
-
-   Switch>
-   Password:
-   Switch#configure terminal
-   Switch(config)#interface Vlan 1
-   Switch(config-if)#ip address 10.42.0.2 255.255.0.0
-   Switch(config-if)#end
-   Switch(config)#snmp-server community mesaci RW
-   Switch(config)#end
-   Switch#copy running-config startup-config
-
-With that set up, you should be able to power on/off a port with something like:
-
-.. code-block: console
-
-   % snmpset -v2c -r 3 -t 30 -cmesaci 10.42.0.2 1.3.6.1.4.1.9.9.402.1.2.1.1.1.1 i 1
-   % snmpset -v2c -r 3 -t 30 -cmesaci 10.42.0.2 1.3.6.1.4.1.9.9.402.1.2.1.1.1.1 i 4
-
-Note that the "1.3.6..." SNMP OID changes between switches.  The last digit
-above is the interface id (port number).  You can probably find the right OID by
-Google, that was easier than figuring it out from finding the switch's MIB
-database.  You can query the POE status from the switch serial using the ``show
-power inline`` command.
-
-Other than that, find the dnsmasq/tftp/NFS setup for your boards "servo" above.
-
-See ``src/broadcom/ci/gitlab-ci.yml`` and ``src/nouveau/ci/gitlab-ci.yml`` for an
-examples of POE for Raspberry Pi 3/4, and Jetson Nano.
-
-Setup
------
-
-Each board will be registered in freedesktop.org GitLab.  You'll want
-something like this to register a fastboot board:
-
-.. code-block:: sh
-
-   sudo gitlab-runner register \
-        --url https://gitlab.freedesktop.org \
-        --registration-token $1 \
-        --name MY_BOARD_NAME \
-        --tag-list MY_BOARD_TAG \
-        --executor docker \
-        --docker-image "alpine:latest" \
-        --docker-volumes "/dev:/dev" \
-        --docker-network-mode "host" \
-        --docker-privileged \
-        --non-interactive
-
-For a Servo board, you'll need to also volume mount the board's NFS
-root dir at /nfs and TFTP kernel directory at /tftp.
-
-The registration token has to come from a freedesktop.org GitLab admin
-going to https://gitlab.freedesktop.org/admin/runners
-
-The name scheme for Google's lab is google-freedreno-boardname-n, and
-our tag is something like google-freedreno-db410c.  The tag is what
-identifies a board type so that board-specific jobs can be dispatched
-into that pool.
-
-We need privileged mode and the /dev bind mount in order to get at the
-serial console and fastboot USB devices (--device arguments don't
-apply to devices that show up after container start, which is the case
-with fastboot, and the Servo serial devices are actually links to
-/dev/pts).  We use host network mode so that we can spin up a nginx
-server to collect XML results for fastboot.
-
-Once you've added your boards, you're going to need to add a little
-more customization in ``/etc/gitlab-runner/config.toml``.  First, add
-``concurrent = <number of boards>`` at the top ("we should have up to
-this many jobs running managed by this gitlab-runner").  Then for each
-board's runner, set ``limit = 1`` ("only 1 job served by this board at a
-time").  Finally, add the board-specific environment variables
-required by your bare-metal script, something like::
-
-   [[runners]]
-     name = "google-freedreno-db410c-1"
-     environment = ["BM_SERIAL=/dev/ttyDB410c8", "BM_POWERUP=google-power-up.sh 8", "BM_FASTBOOT_SERIAL=15e9e390", "FDO_CI_CONCURRENT=4"]
-
-The ``FDO_CI_CONCURRENT`` variable should be set to the number of CPU threads on
-the board, which is used for auto-tuning of job parallelism.
-
-Once you've updated your runners' configs, restart with ``sudo service
-gitlab-runner restart``
-
-Caching downloads
------------------
-
-To improve the runtime for downloading traces during traces job runs, you will
-want a pass-through HTTP cache.  On your runner box, install nginx:
-
-.. code-block:: sh
-
-   sudo apt install nginx libnginx-mod-http-lua
-
-Add the server setup files:
-
-.. literalinclude:: fdo-cache
-   :name: /etc/nginx/sites-available/fdo-cache
-   :caption: /etc/nginx/sites-available/fdo-cache
-
-.. literalinclude:: uri-caching.conf
-   :name: /etc/nginx/snippets/uri-caching.conf
-   :caption: /etc/nginx/snippets/uri-caching.conf
-
-Edit the listener addresses in fdo-cache to suit the ethernet interface that
-your devices are on.
-
-Enable the site and restart nginx:
-
-.. code-block:: sh
-
-   sudo rm /etc/nginx/sites-enabled/default
-   sudo ln -s /etc/nginx/sites-available/fdo-cache /etc/nginx/sites-enabled/fdo-cache
-   sudo systemctl restart nginx
-
-   # First download will hit the internet
-   wget http://localhost/cache/?uri=https://s3.freedesktop.org/mesa-tracie-public/itoral-gl-terrain-demo/demo-v2.trace
-   # Second download should be cached.
-   wget http://localhost/cache/?uri=https://s3.freedesktop.org/mesa-tracie-public/itoral-gl-terrain-demo/demo-v2.trace
-
-Now, set ``download-url`` in your ``traces-*.yml`` entry to something like
-``http://caching-proxy/cache/?uri=https://s3.freedesktop.org/mesa-tracie-public``
-and you should have cached downloads for traces.  Add it to
-``FDO_HTTP_CACHE_URI=`` in your ``config.toml`` runner environment lines and you
-can use it for cached artifact downloads instead of going all the way to
-freedesktop.org on each job.
+- `CI-tron <https://gfx-ci.pages.freedesktop.org/ci-tron/>`__
+- :doc:`LAVA`
diff --git a/docs/ci/kernel.rst b/docs/ci/kernel.rst
index 48cb856cb48..346af59df64 100644
--- a/docs/ci/kernel.rst
+++ b/docs/ci/kernel.rst
@@ -53,16 +53,11 @@ Kconfigs location
 Updating image tags
 -------------------
 
-Every kernel uprev should update 3 image tags, located at two files.
+Every kernel uprev should update the following tag:
 
-:code:`.gitlab-ci/container/gitlab-ci.yml` tag
-^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-- **KERNEL_URL** for the location of the new kernel
-
-:code:`.gitlab-ci/image-tags.yml` tags
+:code:`.gitlab-ci/image-tags.yml` tag
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-- **KERNEL_ROOTFS_TAG** to rebuild rootfs with the new kernel
-- **DEBIAN_X86_TEST_GL_TAG** to ensure that the new rootfs is being used by the GitLab x86 jobs
+- **KERNEL_TAG** to use the new kernel
 
 Development routine
 -------------------
diff --git a/docs/ci/structured-tagging.rst b/docs/ci/structured-tagging.rst
index ecb3151f742..59197c98dd4 100644
--- a/docs/ci/structured-tagging.rst
+++ b/docs/ci/structured-tagging.rst
@@ -249,11 +249,11 @@ To integrate structured tagging for a new component (for example, ``my_component
             variables:
                MY_COMPONENT_TAG: "${CONDITIONAL_BUILD_MY_COMPONENT_TAG}"
 
-   - It is time to modify the job that builds the component image to include the new component tag. Let's suppose that only the ``kernel+rootfs_x86_64`` job builds the component image. We need to add the new component tag to the job as an extension:
+   - It is time to modify the job that builds the component image to include the new component tag. Let's suppose that only the ``debian/arm64_test-gl`` job builds the component image. We need to add the new component tag to the job as an extension:
 
       .. code-block:: yaml
 
-         kernel+rootfs_x86_64:
+         debian/arm64_test-gl:
             extends:
                - .container-builds-my-component
                - .container-builds-my-component2
diff --git a/docs/codingstyle.rst b/docs/codingstyle.rst
index 9fc5c6c2ea2..8a467400a2c 100644
--- a/docs/codingstyle.rst
+++ b/docs/codingstyle.rst
@@ -51,7 +51,7 @@ Add this to your ``.vimrc`` to automatically format any C & C++ file
 
 If ``/usr/share/clang/clang-format.py`` doesn't exist, try
 ``/usr/share/clang/clang-format-$CLANG_VERSION/clang-format.py``
-(replacing ``$CLANG_VERSION`` with your clang version). If your distro
+(replacing ``$CLANG_VERSION`` with your clang version). If your distribution
 has put the file somewhere else, look through the files in the package
 providing ``clang-format``.
 
@@ -82,8 +82,8 @@ Add this to your ``.emacs`` to automatically format any C & C++ file
    (add-hook 'c++-mode-hook (lambda () (clang-format-save-hook-for-this-buffer)))
 
 If ``/usr/share/clang/clang-format.el`` doesn't exist, look through the
-files in the package providing ``clang-format`` in your distro. If you
-can't find anything (e.g. on Debian/Ubuntu), refer to `this StackOverflow
+files in the package providing ``clang-format`` in your distribution.
+If you can't find anything (e.g. on Debian/Ubuntu), refer to `this StackOverflow
 answer <https://stackoverflow.com/questions/59690583/how-do-you-use-clang-format-on-emacs-ubuntu/59850773#59850773>`__
 to install clang-format through Emacs instead.
 
diff --git a/docs/drivers/nvk.rst b/docs/drivers/nvk.rst
index 41040c26f4a..a06f6097547 100644
--- a/docs/drivers/nvk.rst
+++ b/docs/drivers/nvk.rst
@@ -6,9 +6,12 @@ NVK is a Vulkan driver for NVIDIA GPUs.
 Hardware support
 ----------------
 
-NVK currently supports Turing (RTX 20XX and GTX 16XX) and later GPUs.
-Eventually, we plan to support as far back as Kepler (GeForce 600 and 700
-series) GPUs but anything pre-Turing is currently disabled by default.
+NVK currently supports Maxwell (some GTX 700 and 800 series, most 900
+series) and later GPUs.  Kepler (GeForce 600 and 700 series) work is
+currently in-progress but incomplete.  Support for new GPU generations may
+take up to a year after the launch of the hardware because it takes time
+for Nouveau developers to get access to hardware and documentation from
+NVIDIA.
 
 Kernel requirements
 -------------------
@@ -18,8 +21,8 @@ NVK requires at least a Linux 6.6 kernel
 Conformance status:
 -------------------
 
-NVK is a conformant Vulkan 1.3 implementation for all Turing (RTX 20XX and
-GTX 16XX) and later GPUs.
+NVK is a conformant Vulkan 1.4 implementation for all Maxwell (some GTX 700
+and 800 series, most 900 series) and later GPUs.
 
 Debugging
 ---------
diff --git a/docs/drivers/panfrost.rst b/docs/drivers/panfrost.rst
index 854bb804a17..a3fa495aba9 100644
--- a/docs/drivers/panfrost.rst
+++ b/docs/drivers/panfrost.rst
@@ -60,8 +60,8 @@ LLVM is required by Panfrost's compilers at build time.
 
 In case of cross compilation without LLVM,
 you can build and install the required tools on the host (with LLVM installed) with
-``meson . build-host/ -Dtools=panfrost -Dmesa-clc=enabled -Dinstall-mesa-clc=true
--Dprecomp-compiler=enabled -Dinstall-precomp-compiler=true``
+``meson . build-host/ -Dvulkan-drivers=panfrost -Dgallium-drivers=panfrost
+-Dmesa-clc=enabled -Dinstall-mesa-clc=true -Dprecomp-compiler=enabled -Dinstall-precomp-compiler=true``
 and then use ``-Dmesa-clc=system -Dprecomp-compiler=system`` on the cross compile side.
 
 For general information on building Mesa, read :doc:`the install documentation
diff --git a/docs/envvars.rst b/docs/envvars.rst
index f8118f53837..bf3effa66dc 100644
--- a/docs/envvars.rst
+++ b/docs/envvars.rst
@@ -201,10 +201,10 @@ Core Mesa environment variables
 
    if set, determines the directory to be used for the on-disk cache of
    compiled shader programs. If set then the cache will be stored in
-   ``$MESA_SHADER_CACHE_DIR/mesa_shader_cache_db``. If this variable is not
+   ``$MESA_SHADER_CACHE_DIR/mesa_shader_cache``. If this variable is not
    set, then the cache will be stored in
-   ``$XDG_CACHE_HOME/mesa_shader_cache_db`` (if that variable is set), or else
-   within ``.cache/mesa_shader_cache_db`` within the user's home directory.
+   ``$XDG_CACHE_HOME/mesa_shader_cache`` (if that variable is set), or else
+   within ``.cache/mesa_shader_cache`` within the user's home directory.
 
 .. envvar:: MESA_SHADER_CACHE_SHOW_STATS
 
@@ -228,9 +228,9 @@ Core Mesa environment variables
 
 .. envvar:: MESA_DISK_CACHE_MULTI_FILE
 
-   if set to 1, enables the multi file on-disk shader cache implementation
-   instead of the default Mesa-DB cache implementation.
-   This implementation increases the overall disk usage.
+   if set to 1 (set by default), enables the multi file on-disk
+   shader cache implementation. This implementation increases the overall
+   disk usage.
    If :envvar:`MESA_SHADER_CACHE_DIR` is set, the cache will be stored in
    ``$MESA_SHADER_CACHE_DIR/mesa_shader_cache``, or else within
    ``$XDG_CACHE_HOME/mesa_shader_cache`` (if that variable is set)
@@ -248,6 +248,18 @@ Core Mesa environment variables
    and ``filename1_idx.foz``. A limit of 8 DBs can be loaded and this limit
    is shared with :envvar:`MESA_DISK_CACHE_READ_ONLY_FOZ_DBS_DYNAMIC_LIST`.
 
+.. envvar:: MESA_DISK_CACHE_DATABASE
+
+   if set to 1, enables the Mesa-DB single file on-disk shader cache
+   implementation instead of the default multi-file cache implementation.
+   Like :envvar:`MESA_DISK_CACHE_SINGLE_FILE`, Mesa-DB reduces overall
+   disk usage but Mesa-DB supports cache size limits via
+   :envvar:`MESA_SHADER_CACHE_MAX_SIZE`. If
+   :envvar:`MESA_SHADER_CACHE_DIR` is not set, the cache will be stored
+   in ``$XDG_CACHE_HOME/mesa_shader_cache_db`` (if that variable is set)
+   or else within ``.cache/mesa_shader_cache_db`` within the user's home
+   directory.
+
 .. envvar:: MESA_DISK_CACHE_DATABASE_NUM_PARTS
 
    specifies number of mesa-db cache parts, default is 50.
@@ -1077,20 +1089,20 @@ Gallium environment variables
 
 .. envvar:: GALLIUM_TRACE
 
-   If set, this variable will cause the :ref:`trace` output to be written to the
+   If set, this variable will cause the trace output to be written to the
    specified file. Paths may be relative or absolute; relative paths are relative
    to the working directory.  For example, setting it to "trace.xml" will cause
    the trace to be written to a file of the same name in the working directory.
 
 .. envvar:: GALLIUM_TRACE_TC
 
-   If enabled while :ref:`trace` is active, this variable specifies that the threaded context
+   If enabled while trace is active, this variable specifies that the threaded context
    should be traced for drivers which implement it. By default, the driver thread is traced,
    which will include any reordering of the command stream from threaded context.
 
 .. envvar:: GALLIUM_TRACE_TRIGGER
 
-   If set while :ref:`trace` is active, this variable specifies a filename to monitor.
+   If set while trace is active, this variable specifies a filename to monitor.
    Once the file exists (e.g., from the user running 'touch /path/to/file'), a single
    frame will be recorded into the trace output.
    Paths may be relative or absolute; relative paths are relative to the working directory.
@@ -1135,54 +1147,6 @@ Gallium environment variables
    ``sse4.1``
    ``avx``
 
-Clover environment variables
-----------------------------
-
-.. envvar:: CLOVER_DEVICE_TYPE
-
-   allows to overwrite the device type of devices. Possible values are
-   ``accelerator``, ``cpu``, ``custom`` and ``gpu``
-
-.. envvar:: CLOVER_DEVICE_VERSION_OVERRIDE
-
-   overwrites the auto detected OpenCL version of a device. Possible values:
-   ``1.0``
-   ``1.1``
-   ``1.2``
-   ``2.0``
-   ``2.1``
-   ``2.2``
-   ``3.0``
-
-.. envvar:: CLOVER_DEVICE_CLC_VERSION_OVERRIDE
-
-   overwrites the auto detected CLC version. Possible values:
-   ``1.0``
-   ``1.1``
-   ``1.2``
-   ``2.0``
-   ``2.1``
-   ``2.2``
-   ``3.0``
-
-.. envvar:: CLOVER_EXTRA_BUILD_OPTIONS
-
-   allows specifying additional compiler and linker options. Specified
-   options are appended after the options set by the OpenCL program in
-   ``clBuildProgram``.
-
-.. envvar:: CLOVER_EXTRA_COMPILE_OPTIONS
-
-   allows specifying additional compiler options. Specified options are
-   appended after the options set by the OpenCL program in
-   ``clCompileProgram``.
-
-.. envvar:: CLOVER_EXTRA_LINK_OPTIONS
-
-   allows specifying additional linker options. Specified options are
-   appended after the options set by the OpenCL program in
-   ``clLinkProgram``.
-
 .. _rusticl-env-var:
 
 Rusticl environment variables
@@ -1509,6 +1473,8 @@ RADV driver environment variables
       Dump backend IR (ACO or LLVM) for selected shader stages.
    ``asm``
       Dump shader disassembly for selected shader stages.
+   ``bvh4``
+      Use bvh4 encoding on GPUs that support bvh8 encoding.
 
 .. envvar:: RADV_FORCE_FAMILY
 
diff --git a/docs/faq.rst b/docs/faq.rst
index 20780ccbe4d..e9fec60c98b 100644
--- a/docs/faq.rst
+++ b/docs/faq.rst
@@ -125,8 +125,8 @@ popular and feature-complete.
 2.1 What's the easiest way to install Mesa?
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-If you're using a Linux-based system, your distro CD most likely already
-has Mesa packages (like RPM or DEB) which you can easily install.
+If you're using a Linux-based system, your distribution
+most likely already includes Mesa packages.
 
 2.2 I get undefined symbols such as bgnpolygon, v3f, etc...
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
diff --git a/docs/features.txt b/docs/features.txt
index 8a4c79e07b4..29e368ef5b9 100644
--- a/docs/features.txt
+++ b/docs/features.txt
@@ -99,7 +99,7 @@ GL 3.2, GLSL 1.50 --- all DONE: freedreno, nv50, nvc0, r600, radeonsi, llvmpipe,
 
 GL 3.3, GLSL 3.30 --- all DONE: freedreno, nv50, nvc0, r600, radeonsi, llvmpipe, softpipe, virgl, zink, d3d12, iris, crocus/gen6+, asahi
 
-  GL_ARB_blend_func_extended                            DONE (freedreno/a3xx, freedreno/a6xx, panfrost, lima)
+  GL_ARB_blend_func_extended                            DONE (freedreno/a3xx, freedreno/a6xx, v3d, panfrost, lima)
   GL_ARB_explicit_attrib_location                       DONE (all drivers that support GLSL)
   GL_ARB_occlusion_query2                               DONE (v3d, panfrost)
   GL_ARB_sampler_objects                                DONE (all drivers)
@@ -461,7 +461,7 @@ Vulkan 1.2 -- all DONE: anv, nvk, panvk, tu, vn
   VK_KHR_buffer_device_address                          DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_create_renderpass2                             DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_depth_stencil_resolve                          DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
-  VK_KHR_draw_indirect_count                            DONE (anv, dzn, hasvk, lvp, nvk, radv, tu, vn)
+  VK_KHR_draw_indirect_count                            DONE (anv, dzn, hasvk, lvp, nvk, panvk/v10+, radv, tu, vn)
   VK_KHR_driver_properties                              DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_image_format_list                              DONE (anv, dzn, hasvk, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
   VK_KHR_imageless_framebuffer                          DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
@@ -487,21 +487,21 @@ Vulkan 1.3 -- all DONE: anv, lvp, nvk, radv, tu, vn, v3dv
   VK_KHR_copy_commands2                                 DONE (anv, hasvk, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
   VK_KHR_dynamic_rendering                              DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_format_feature_flags2                          DONE (anv, hasvk, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
-  VK_KHR_maintenance4                                   DONE (anv, hasvk, lvp, nvk, radv, tu, v3dv, vn)
-  VK_KHR_shader_integer_dot_product                     DONE (anv, dzn, hasvk, lvp, nvk, radv, tu, v3dv, vn)
+  VK_KHR_maintenance4                                   DONE (anv, hasvk, lvp, nvk, panvk/v10+, radv, tu, v3dv, vn)
+  VK_KHR_shader_integer_dot_product                     DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_shader_non_semantic_info                       DONE (anv, hasvk, nvk, panvk, radv, tu, v3dv, vn)
-  VK_KHR_shader_terminate_invocation                    DONE (anv, hasvk, lvp, nvk, radv, tu, v3dv, vn)
+  VK_KHR_shader_terminate_invocation                    DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_synchronization2                               DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_zero_initialize_workgroup_memory               DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_EXT_4444_formats                                   DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
-  VK_EXT_extended_dynamic_state                         DONE (anv, hasvk, lvp, nvk, radv, tu, v3dv, vn)
-  VK_EXT_extended_dynamic_state2                        DONE (anv, hasvk, lvp, nvk, radv, tu, v3dv, vn)
+  VK_EXT_extended_dynamic_state                         DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
+  VK_EXT_extended_dynamic_state2                        DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_EXT_inline_uniform_block                           DONE (anv, hasvk, lvp, nvk, radv, tu, v3dv, vn)
   VK_EXT_pipeline_creation_cache_control                DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_EXT_pipeline_creation_feedback                     DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_EXT_private_data                                   DONE (anv, hasvk, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
   VK_EXT_image_robustness                               DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
-  VK_EXT_shader_demote_to_helper_invocation             DONE (anv, hasvk, lvp, nvk, radv, tu, v3dv, vn)
+  VK_EXT_shader_demote_to_helper_invocation             DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_EXT_subgroup_size_control                          DONE (anv, hasvk, lvp, nvk, panvk/v10+, radv, tu, v3dv, vn)
   VK_EXT_texel_buffer_alignment                         DONE (anv, hasvk, lvp, nvk, pvr, radv, tu, v3dv, vn)
   VK_EXT_texture_compression_astc_hdr                   DONE (vn)
@@ -515,7 +515,7 @@ Vulkan 1.4 -- all DONE: anv, lvp, nvk, radv/gfx8+, tu/a7xx+, vn
   VK_KHR_index_type_uint8                               DONE (anv, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
   VK_KHR_line_rasterization                             DONE (anv, lvp, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_load_store_op_none                             DONE (anv, lvp, nvk, radv, tu, v3dv, vn)
-  VK_KHR_maintenance5                                   DONE (anv, lvp, nvk, radv, tu, v3dv, vn)
+  VK_KHR_maintenance5                                   DONE (anv, lvp, nvk, panvk/v10+, radv, tu, v3dv, vn)
   VK_KHR_maintenance6                                   DONE (anv, lvp, nvk, radv, tu, vn)
   VK_KHR_map_memory2                                    DONE (anv, lvp, nvk, panvk, radv, tu, vn)
   VK_KHR_push_descriptor                                DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, vn)
@@ -559,11 +559,12 @@ Khronos extensions that are not part of any Vulkan version:
   VK_KHR_ray_tracing_maintenance1                       DONE (anv/gfx12.5+, radv/gfx10.3+, tu/a740+, vn)
   VK_KHR_ray_tracing_pipeline                           DONE (anv/gfx12.5+, lvp, radv/gfx10.3+, vn)
   VK_KHR_ray_tracing_position_fetch                     DONE (anv, radv/gfx10.3+, vn)
+  VK_KHR_shader_bfloat16                                DONE (anv/gfx12.5+, radv/gfx11+)
   VK_KHR_shader_clock                                   DONE (anv, hasvk, lvp, nvk, radv, tu, vn)
   VK_KHR_shader_maximal_reconvergence                   DONE (anv, lvp, nvk, panvk/v10+, radv, vn)
   VK_KHR_shader_relaxed_extended_instruction            DONE (anv, hasvk, nvk, panvk, radv, tu, v3dv, vn)
   VK_KHR_shader_subgroup_uniform_control_flow           DONE (anv, hasvk, nvk, panvk/v10+, radv, tu, vn)
-  VK_KHR_shader_quad_control                            DONE (anv, nvk, radv, vn)
+  VK_KHR_shader_quad_control                            DONE (anv, nvk, panvk/v10+, radv, vn)
   VK_KHR_shared_presentable_image                       not started
   VK_KHR_surface                                        DONE (anv, dzn, hasvk, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
   VK_KHR_surface_protected_capabilities                 DONE (anv, lvp, nvk, radv, tu, v3dv, vn)
@@ -589,7 +590,7 @@ Khronos extensions that are not part of any Vulkan version:
   VK_EXT_debug_marker                                   DONE (radv)
   VK_EXT_debug_report                                   DONE (anv, dzn, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
   VK_EXT_debug_utils                                    DONE (anv, dzn, hasvk, lvp, nvk, panvk, pvr, radv, tu, v3dv, vn)
-  VK_EXT_depth_bias_control                             DONE (anv, nvk, radv, vn)
+  VK_EXT_depth_bias_control                             DONE (anv, nvk, panvk, radv, vn)
   VK_EXT_depth_clamp_control                            DONE (anv, hasvk, nvk, radv, vn)
   VK_EXT_depth_clip_control                             DONE (anv, hasvk, lvp, nvk, radv, tu, v3dv, vn)
   VK_EXT_depth_clip_enable                              DONE (anv, hasvk, lvp, nvk, panvk, radv, tu, v3dv/vc7+, vn)
@@ -648,7 +649,7 @@ Khronos extensions that are not part of any Vulkan version:
   VK_EXT_shader_atomic_float2                           DONE (anv, lvp, radv, vn)
   VK_EXT_shader_image_atomic_int64                      DONE (nvk, radv, vn)
   VK_EXT_shader_object                                  DONE (lvp, nvk, radv)
-  VK_EXT_shader_replicated_composites                   DONE (anv, dzn, hasvk, lvp, nvk, radv, tu, vn)
+  VK_EXT_shader_replicated_composites                   DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, vn)
   VK_EXT_shader_stencil_export                          DONE (anv, lvp, radv, tu, vn)
   VK_EXT_shader_subgroup_ballot                         DONE (anv, dzn, hasvk, lvp, nvk, radv, vn)
   VK_EXT_shader_subgroup_vote                           DONE (anv, dzn, hasvk, lvp, nvk, radv, vn)
@@ -656,8 +657,8 @@ Khronos extensions that are not part of any Vulkan version:
   VK_EXT_surface_maintenance1                           DONE (anv, lvp, nvk, radv, tu, v3dv, vn)
   VK_EXT_swapchain_maintenance1                         DONE (anv, lvp, nvk, radv, tu, v3dv, vn)
   VK_EXT_transform_feedback                             DONE (anv, hasvk, lvp, nvk, radv, tu, vn)
-  VK_EXT_vertex_attribute_divisor                       DONE (anv, dzn, hasvk, lvp, nvk, radv, tu, v3dv, vn)
-  VK_EXT_vertex_input_dynamic_state                     DONE (anv, lvp, nvk, radv, tu, vn)
+  VK_EXT_vertex_attribute_divisor                       DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, v3dv, vn)
+  VK_EXT_vertex_input_dynamic_state                     DONE (anv, lvp, nvk, panvk, radv, tu, vn)
   VK_EXT_ycbcr_image_arrays                             DONE (anv, hasvk, lvp, nvk, panvk/v10+, radv, vn)
   VK_ANDROID_external_memory_android_hardware_buffer    DONE (anv, radv, tu, vn)
   VK_ANDROID_native_buffer                              DONE (anv, radv, tu, v3dv, vn)
@@ -697,160 +698,6 @@ Khronos extensions that are not part of any Vulkan version:
   VK_QCOM_fragment_density_map_offset                   DONE (tu)
 
 
-Clover OpenCL 1.0 -- all DONE:
-
-  Image support                                         in progress
-  - Optional image formats                              in progress
-
-
-Clover OpenCL 1.1 -- all DONE:
-
-  Additional queries for clGetDeviceInfo                DONE (nvc0, r600, radeonsi)
-  CL_CONTEXT_NUM_DEVICES for clGetContextInfo           DONE
-  New optional image formats                            not started
-  - CL_Rx                                               not started
-  - CL_RGx                                              not started
-  - CL_RGBx                                             not started
-  clCreateSubBuffer                                     DONE
-  Read from, write to, copy rectangular regions         DONE
-  clSetMemObjectDestructorCallback                      DONE
-  Control OpenCL C version when building                DONE
-  Query for preferred work-group size multiple          DONE (nvc0, r600, radeonsi)
-  Support user events                                   DONE
-  clSetEventCallback                                    DONE
-  Minimum requirement changes for clGetDeviceInfo       DONE (nvc0, r600, radeonsi)
-  Arg prerequisite change for clEnqueueNDRangeKernel    DONE ()
-  OpenCL C 1.1                                          DONE (nvc0, r600, radeonsi)
-  - 3-component vector data types                       DONE (nvc0, r600, radeonsi)
-  - cl_khr_byte_addressable_store                       DONE (nvc0, r600, radeonsi)
-  - cl_khr_global_int32_base_atomics                    DONE (nvc0, r600, radeonsi)
-  - cl_khr_global_int32_extended_atomics                DONE (nvc0, r600, radeonsi)
-  - cl_khr_local_int32_base_atomics                     DONE (nvc0, r600, radeonsi)
-  - cl_khr_local_int32_extended_atomics                 DONE (nvc0, r600, radeonsi)
-
-
-Clover OpenCL 1.2 -- all DONE:
-
-  Custom devices                                        DONE
-  Built-in kernels                                      in progress
-  Device partitioning                                   not started
-  Separate compilation and linking of programs          DONE
-  Extend cl_mem_flags                                   DONE
-  clEnqueueFillBuffer, clEnqueueFillImage               DONE
-  Add CL_MAP_WRITE_INVALIDATE_REGION to cl_map_flags    DONE
-  New image types                                       not started
-  clCreateImage                                         DONE
-  clEnqueueMigrateMemObjects                            DONE
-  Retrieve kernels information from a program           DONE
-  clGetKernelArgInfo                                    DONE
-  clEnqueueMarkerWithWaitList                           DONE
-  clEnqueueBarrierWithWaitList                          DONE
-  clUnloadPlatformCompiler                              DONE
-  cl_khr_fp64                                           DONE (nvc0, r600, radeonsi)
-  printf                                                DONE (nvc0)
-  CL_KERNEL_ATTRIBUTES for clGetKernelInfo              DONE
-  OpenCL C 1.2                                          DONE
-
-
-Clover OpenCL 2.0 -- all DONE:
-
-  Shared virtual memory                                 DONE (nvc0, llvmpipe)
-  Device queues                                         not started
-  - cl_khr_create_command_queue                         not started
-  - Additional queries for clGetDeviceInfo              not started
-  Pipes                                                 not started
-  Extended 2D images creation                           in progress
-  - CL_ABGR                                             DONE
-  - cl_khr_image2d_from_buffer                          not started
-  - cl_khr_depth_images                                 not started
-  - from sRGB images                                    not started
-  clCreateSamplerWithProperties                         not started
-  Non-uniform work-group sizes                          not started
-  cl_khr_3d_image_writes                                not started
-  OpenCL C 2.0                                          in progress
-  - Work-group Collective Functions                     not started
-  - Generic address space                               in progress
-
-
-Clover OpenCL 2.1 -- all DONE:
-
-  Sub groups                                            not started
-  - cl_khr_subgroups                                    not started
-  cl_khr_il_program                                     DONE (nvc0)
-  Device and host timer synchronization                 not started
-  clEnqueueSVMMigrateMem                                not started
-  clCloneKernel                                         not started
-  Default device command queue                          not started
-  CL_UNORM_INT_101010_2                                 DONE
-
-
-Clover OpenCL 2.2 -- all DONE:
-
-  clSetProgramSpecializationConstant                    not started
-  clSetProgramReleaseCallback                           not started
-  Initialization and clean-up kernels                   not started
-  CL_MAX_SIZE_RESTRICTION_EXCEEDED for clSetKernelArg   not started
-  Support SPIR-V 1.1 and 1.2                            not started
-
-
-Clover OpenCL 3.0 -- all DONE:
-
-  Optional device capabilities queries                  in progress
-  cl_khr_extended_versioning                            DONE
-  clSetContextDestructorCallback                        DONE
-  clCreateBufferWithProperties                          DONE
-  clCreateImageWithProperties                           DONE
-  Query properties arrays                               in progress
-  Supported OpenCLÂ C versions and features queries      DONE
-  CL_COMMAND_SVM_MIGRATE_MEM for clGetEventInfo         not started
-  OpenCL C 3.0                                          DONE
-  Latest conformance version passed for devices         not started
-
-
-Clover extensions that are not part of any OpenCL version:
-  cl_khr_async_copy_fence                               not started
-  cl_khr_async_work_group_copy_fence                    not started
-  cl_khr_device_enqueue_local_arg_types                 not started
-  cl_khr_device_uuid                                    not started
-  cl_khr_egl_event                                      not started
-  cl_khr_egl_image                                      not started
-  cl_khr_expect_assume                                  not started
-  cl_khr_extended_async_copies                          not started
-  cl_khr_extended_bit_ops                               not started
-  cl_khr_fp16                                           DONE ()
-  cl_khr_gl_depth_images                                not started
-  cl_khr_gl_msaa_sharing                                not started
-  cl_khr_gl_sharing                                     not started
-  cl_khr_icd                                            DONE
-  cl_khr_initialize_memory                              not started
-  cl_khr_int64_base_atomics                             DONE ()
-  cl_khr_int64_extended_atomics                         DONE ()
-  cl_khr_integer_dot_product                            not started
-  cl_khr_mipmap_image                                   not started
-  cl_khr_pci_bus_info                                   not started
-  cl_khr_priority_hints                                 not started
-  cl_khr_spirv_extended_debug_info                      not started
-  cl_khr_spirv_linkonce_odr                             not started
-  cl_khr_spirv_no_integer_wrap_decoration               not started
-  cl_khr_srgb_image_writes                              not started
-  cl_khr_subgroup_ballot                                not started
-  cl_khr_subgroup_clustered_reduce                      not started
-  cl_khr_subgroup_extended_types                        not started
-  cl_khr_subgroup_named_barrier                         not started
-  cl_khr_subgroup_non_uniform_arithmetic                not started
-  cl_khr_subgroup_non_uniform_vote                      not started
-  cl_khr_subgroup_rotate                                not started
-  cl_khr_subgroup_shuffle                               not started
-  cl_khr_subgroup_shuffle_relative                      not started
-  cl_khr_suggested_local_work_size                      not started
-  cl_khr_terminate_context                              not started
-  cl_khr_throttle_hints                                 not started
-  cl_khr_work_group_uniform_arithmetic                  not started
-  cl_arm_non_uniform_work_group_size                    not started
-  cl_arm_shared_virtual_memory                          DONE (nvc0)
-  cl_intel_unified_shared_memory                        not started
-
-
 Rusticl OpenCL 1.0 -- all DONE:
 
   Image support                                         DONE
diff --git a/docs/gallium/cso/rasterizer.rst b/docs/gallium/cso/rasterizer.rst
index 62e5a843bb1..11d886436aa 100644
--- a/docs/gallium/cso/rasterizer.rst
+++ b/docs/gallium/cso/rasterizer.rst
@@ -56,7 +56,7 @@ flatshade
       CONSTANT, LINEAR and PERSPECTIVE. The flatshade state is needed at
       clipping time to determine how to set the color of new vertices.
 
-      :ref:`Draw` can implement flat shading by copying the provoking vertex
+      Draw can implement flat shading by copying the provoking vertex
       color to all the other vertices in the primitive.
 
 flatshade_first
@@ -80,7 +80,7 @@ Polygons
 
 light_twoside
    If set, there are per-vertex back-facing colors.  The hardware
-   (perhaps assisted by :ref:`Draw`) should be set up to use this state
+   (perhaps assisted by Draw) should be set up to use this state
    along with the front/back information to set the final vertex colors
    prior to rasterization.
 
@@ -178,7 +178,7 @@ sprite_coord_enable
    always rasterized as quads).  Any mismatch between these states should
    be considered a bug in the gallium frontend.
 
-   This feature is implemented in the :ref:`Draw` module but may also be
+   This feature is implemented in the Draw module but may also be
    implemented natively by GPUs or implemented with a geometry shader.
 
 
@@ -187,7 +187,7 @@ sprite_coord_mode
    point sprites. For PIPE_SPRITE_COORD_LOWER_LEFT, the lower-left vertex will
    have coordinates (0,0,0,1). For PIPE_SPRITE_COORD_UPPER_LEFT, the upper-left
    vertex will have coordinates (0,0,0,1).
-   This state is used by :ref:`Draw` to generate texcoords.
+   This state is used by Draw to generate texcoords.
 
 
 point_quad_rasterization
diff --git a/docs/gallium/distro.rst b/docs/gallium/distro.rst
deleted file mode 100644
index 0a9a93f63c0..00000000000
--- a/docs/gallium/distro.rst
+++ /dev/null
@@ -1,187 +0,0 @@
-Distribution
-============
-
-Along with the interface definitions, the following drivers, Gallium frontends,
-and auxiliary modules are shipped in the standard Gallium distribution.
-
-Drivers
--------
-
-Intel i915
-^^^^^^^^^^
-
-Driver for Intel i915 and i945 chipsets.
-
-LLVM Softpipe
-^^^^^^^^^^^^^
-
-A version of :ref:`softpipe` that uses the Low-Level Virtual Machine to
-dynamically generate optimized rasterizing pipelines.
-
-NVIDIA NV30
-^^^^^^^^^^^
-
-Driver for the NVIDIA NV30 and NV40 families of GPUs.
-
-NVIDIA NV50
-^^^^^^^^^^^
-
-Driver for the NVIDIA NV50 family of GPUs.
-
-NVIDIA NVC0
-^^^^^^^^^^^
-
-Driver for the NVIDIA NVC0 / Fermi family of GPUs.
-
-VMware SVGA
-^^^^^^^^^^^
-
-Driver for VMware virtualized guest operating system graphics processing.
-
-ATI R300
-^^^^^^^^
-
-Driver for the ATI/AMD R300, R400, and R500 families of GPUs.
-
-ATI/AMD R600
-^^^^^^^^^^^^
-
-Driver for the ATI/AMD R600, R700, Evergreen and Northern Islands families of GPUs.
-
-AMD RadeonSI
-^^^^^^^^^^^^
-
-Driver for the AMD Southern Islands family of GPUs.
-
-Freedreno
-^^^^^^^^^
-
-Driver for Qualcomm Adreno 2xx, 3xx, and 4xx series of GPUs.
-
-.. _softpipe:
-
-Softpipe
-^^^^^^^^
-
-Reference software rasterizer. Slow but accurate.
-
-.. _trace:
-
-Trace
-^^^^^
-
-Wrapper driver. Trace dumps an XML record of the calls made to the
-:ref:`Context` and :ref:`Screen` objects that it wraps.
-
-Gallium frontends
------------------
-
-Clover
-^^^^^^
-
-Tracker that implements the Khronos OpenCL standard.
-
-.. _dri:
-
-Direct Rendering Infrastructure
-^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-
-Tracker that implements the client-side DRI protocol, for providing direct
-acceleration services to X11 servers with the DRI extension. Supports DRI1
-and DRI2. Only GL is supported.
-
-GLX
-^^^
-
-MesaGL
-^^^^^^
-
-The Gallium frontend implementing a GL state machine. Not usable as
-a standalone frontend; Mesa should be built with another Gallium frontend,
-such as :ref:`DRI` or EGL.
-
-Nine
-^^^^
-
-The Gallium frontend implements the Direct3D 9 API.
-
-VDPAU
-^^^^^
-
-Tracker for Video Decode and Presentation API for Unix.
-
-WGL
-^^^
-
-Xorg DDX
-^^^^^^^^
-
-Tracker for Xorg X11 servers. Provides device-dependent
-modesetting and acceleration as a DDX driver.
-
-Auxiliary
----------
-
-OS
-^^
-
-The OS module contains the abstractions for basic operating system services:
-
-* memory allocation
-* simple message logging
-* obtaining run-time configuration option
-* threading primitives
-
-This is the bare minimum required to port Gallium to a new platform.
-
-The OS module already provides the implementations of these abstractions for
-the most common platforms.  When targeting an embedded platform no
-implementation will be provided -- these must be provided separately.
-
-CSO Cache
-^^^^^^^^^
-
-The CSO cache is used to accelerate preparation of state by saving
-driver-specific state structures for later use.
-
-.. _draw:
-
-Draw
-^^^^
-
-Draw is a software :term:`TCL` pipeline for hardware that lacks vertex shaders
-or other essential parts of pre-rasterization vertex preparation.
-
-Gallivm
-^^^^^^^
-
-Indices
-^^^^^^^
-
-Indices provides tools for translating or generating element indices for
-use with element-based rendering.
-
-Pipe Buffer Managers
-^^^^^^^^^^^^^^^^^^^^
-
-Each of these managers provides various services to drivers that are not
-fully utilizing a memory manager.
-
-Remote Debugger
-^^^^^^^^^^^^^^^
-
-Runtime Assembly Emission
-^^^^^^^^^^^^^^^^^^^^^^^^^
-
-TGSI
-^^^^
-
-The TGSI auxiliary module provides basic utilities for manipulating TGSI
-streams.
-
-Translate
-^^^^^^^^^
-
-Util
-^^^^
-
diff --git a/docs/gallium/index.rst b/docs/gallium/index.rst
index 20cf1594679..207bd3aae8f 100644
--- a/docs/gallium/index.rst
+++ b/docs/gallium/index.rst
@@ -15,7 +15,6 @@ Contents:
    context
    cso
    buffermapping
-   distro
    postprocess
    glossary
 
diff --git a/docs/install.rst b/docs/install.rst
index 29673a3dfdd..08684cc15dc 100644
--- a/docs/install.rst
+++ b/docs/install.rst
@@ -66,7 +66,7 @@ Check/install the respective development package as prompted by the
 configure error message.
 
 Here are some common ways to retrieve most/all of the dependencies based
-on the packaging tool used by your distro.
+on the packaging tool used by your distribution.
 
 .. code-block:: sh
 
diff --git a/docs/meson.rst b/docs/meson.rst
index 219d9892bac..65d1b80de54 100644
--- a/docs/meson.rst
+++ b/docs/meson.rst
@@ -51,7 +51,7 @@ most of these with just one command. On Fedora and similar, ``sudo dnf
 builddep mesa`` does the same.
 
 .. note::
-   All these dependencies are for latest linux distros and is tested on ubuntu-24 only for now.
+   All these dependencies are for latest Linux distributions and is tested on Ubuntu 24.xx only for now.
 
    Also note, some packages below might not be available in your OS with the exact name, in such case you can search for it and install the distribution specific one.
 
diff --git a/docs/release-calendar.csv b/docs/release-calendar.csv
index 4ae4b677d41..908fa2056c3 100644
--- a/docs/release-calendar.csv
+++ b/docs/release-calendar.csv
@@ -1,8 +1,5 @@
-25.0,2025-04-16,25.0.4,Eric Engestrom,
-,2025-04-30,25.0.5,Eric Engestrom,
+25.0,2025-04-30,25.0.5,Eric Engestrom,
 ,2025-05-14,25.0.6,Eric Engestrom,
 ,2025-05-28,25.0.7,Eric Engestrom,Last planned 25.0.x release.
-25.1,2025-04-16,25.1.0-rc1,Eric Engestrom,25.1 branchpoint
-,2025-04-23,25.1.0-rc2,Eric Engestrom,
-,2025-04-30,25.1.0-rc3,Eric Engestrom,
+25.1,2025-04-30,25.1.0-rc3,Eric Engestrom,
 ,2025-05-07,25.1.0-rc4,Eric Engestrom,or 25.1.0 final
diff --git a/docs/relnotes.rst b/docs/relnotes.rst
index 137fa488558..c6c36285b22 100644
--- a/docs/relnotes.rst
+++ b/docs/relnotes.rst
@@ -3,7 +3,7 @@ Release Notes
 
 The release notes summarize what's new or changed in each Mesa release.
 
--  :doc:`25.1.0 release notes <relnotes/25.1.0>`
+-  :doc:`25.0.4 release notes <relnotes/25.0.4>`
 -  :doc:`25.0.3 release notes <relnotes/25.0.3>`
 -  :doc:`25.0.2 release notes <relnotes/25.0.2>`
 -  :doc:`25.0.1 release notes <relnotes/25.0.1>`
@@ -447,7 +447,7 @@ The release notes summarize what's new or changed in each Mesa release.
    :maxdepth: 1
    :hidden:
 
-   25.1.0 <relnotes/25.1.0>
+   25.0.4 <relnotes/25.0.4>
    25.0.3 <relnotes/25.0.3>
    25.0.2 <relnotes/25.0.2>
    25.0.1 <relnotes/25.0.1>
diff --git a/docs/relnotes/25.0.4.rst b/docs/relnotes/25.0.4.rst
new file mode 100644
index 00000000000..80d292e0a24
--- /dev/null
+++ b/docs/relnotes/25.0.4.rst
@@ -0,0 +1,256 @@
+Mesa 25.0.4 Release Notes / 2025-04-17
+======================================
+
+Mesa 25.0.4 is a bug fix release which fixes bugs found since the 25.0.3 release.
+
+Mesa 25.0.4 implements the OpenGL 4.6 API, but the version reported by
+glGetString(GL_VERSION) or glGetIntegerv(GL_MAJOR_VERSION) /
+glGetIntegerv(GL_MINOR_VERSION) depends on the particular driver being used.
+Some drivers don't support all the features required in OpenGL 4.6. OpenGL
+4.6 is **only** available if requested at context creation.
+Compatibility contexts may report a lower version depending on each driver.
+
+Mesa 25.0.4 implements the Vulkan 1.4 API, but the version reported by
+the apiVersion property of the VkPhysicalDeviceProperties struct
+depends on the particular driver being used.
+
+SHA checksums
+-------------
+
+::
+
+    SHA256: 76293cf4372ca4e4e73fd6c36c567b917b608a4db9d11bd2e33068199a7df04d  mesa-25.0.4.tar.xz
+    SHA512: 562a97bd0374ff2a76f71c848df4fe542f1fc66c420a9101eb4bb1947d00eee4417d9c6f2d1be19638663753785c19384f8a6dc078c3187448ab79413d906152  mesa-25.0.4.tar.xz
+
+
+New features
+------------
+
+- None
+
+
+Bug fixes
+---------
+
+- RADV: Performance regression in Elden Ring on GFX8/Polaris
+- RADV: Performance regression in Elden Ring on GFX8/Polaris
+- Confidential issue #12324
+- Confidential issue #12946
+- The Last of Us Part I GPU hang on gfx1201
+- brw: new Xe2 CTS failures
+- [NVK] NAK assert in The Last of Us Part 2 shader
+- [ANV][LNL] - Lost Records: Bloom & Rage (1902960) - Title hangs on launch and subsequently crashes to desktop.
+- [BMG] Intel b580 battlemage: Fort Solis (Unreal Engine game) boots to menu, hangs while loading after hitting continue from the main menu
+- [ANV][LNL] -  NINJA GAIDEN 2 Black (3287520) - Environment assets are incorrectly rendered or missing.
+- [ANV][LNL] - The Headliners (3059070) - Title hangs a few minutes after launch.
+- anv, regression: Invisibly blinking cliffs & rocks in Satisfactory DX12 on BMG
+- vk/overlay: output_file option failing
+- [bisected, LNL] brw: 341e5117ecbc ("brw/nir: Treat load_const as convergent") regresses arb_gpu_shader5-interpolateAtOffset on LNL
+- vulkan regression mesa 24.3.4 to 25.0.0.rc3 with broadcom
+- radv: nir_opt_varyings.c:2766: deduplicate_outputs: Assertion \`list_index == 0' failed.
+- vulkan/wsi: memory leak from wsi_CreateSwapchainKHR
+
+
+Changes
+-------
+
+Aaron Ruby (2):
+
+- gfxstream: Make the virtgpu device discovery for LinuxVirtGpu more robust
+- gfxstream: Add common interfaces in the VirtGpuDevice to query DrmInfo and PciBusInfo
+
+Alyssa Rosenzweig (4):
+
+- nir/lower_blend: refactor logicop variables
+- nir/lower_blend: disable logic ops for unsupported formats
+- panfrost: invert and rename no_ubo_to_push flag
+- panfrost: do not push "true" UBOs
+
+Benjamin Lee (2):
+
+- panvk/csf: fix uninitialized read in utrace_clone_init_builder
+- panfrost/pps: fix omitting several counters
+
+Benjamin Otte (1):
+
+- lavapipe: Don't advertise support for multiplane drm formats
+
+Boris Brezillon (2):
+
+- vulkan/state: Fix input attachment map state initialization/copy
+- vk/pass: Add input attachment location info
+
+Caio Oliveira (1):
+
+- nir/load_store_vectorize: Skip new bit-sizes that are unaligned with high_offset
+
+Caterina Shablia (2):
+
+- panfrost: don't overwrite push uniforms and sysvals UBO with user's UBO
+- panfrost: update nr_uniform_buffers before dispatching XFB
+
+Connor Abbott (1):
+
+- tu: Fix layer_count with dynamic rendering + multiview
+
+David Rosca (4):
+
+- radeonsi/vcn: Disable AV1 unidir compound with rate control
+- radv/video: Fix msg header total size
+- radv/video: Fix encode session info for VCN3+
+- radeonsi/vpe: Use float division to get scaling ratio
+
+Eric Engestrom (7):
+
+- docs: add sha sum for 25.0.3
+- [25.0 only] update more ci expectations
+- .pick_status.json: Update to 7c5389695bdf106acaab6ccc69535f25c1d7a8e6
+- ci: rename ci-tron priority tag to avoid conflict with the generic fdo runners
+- .pick_status.json: Update to 2f00daf67a7990da68dfc4a8e5f2019daecb7a59
+- .pick_status.json: Update to 58321cf2e57279079bf742be1063ac2900ea2436
+- .pick_status.json: Update to 555821ff93118d4a6ea441127cd0427a95743d47
+
+Eric R. Smith (2):
+
+- panfrost,lima: use index size in panfrost minmax_cache
+- panfrost: fix transaction elimination crc valid calculation
+
+Erik Faye-Lund (4):
+
+- panfrost: fixup typo in 16x sample-pattern
+- nir/lower_tex: use texture_mask instead of shifting on use
+- panvk: set shared_addr_format
+- panvk: claim official conformance on v10
+
+Faith Ekstrand (3):
+
+- nak: Allow predicates in nir_intrinsic_as_uniform
+- nvk/nvkmd: Check the correct flag for the Kepler GART workaround
+- nil: Multiply by array_stride_B instead of adding
+
+Felix DeGrood (1):
+
+- vk/overlay-layer: fix regression in non-control pathway
+
+Georg Lehmann (2):
+
+- spirv: clamp/sign-extend non 32bit ldexp exponents
+- spirv: fix cooperative matrix by value function params
+
+Gurchetan Singh (3):
+
+- gfxstream: check device exists before using it
+- gfxstream: refactor device initialization
+- gfxstream: follow the semantics desired by distro VK loader
+
+Ian Romanick (4):
+
+- brw/algebraic: Constant folding for BROADCAST and SHUFFLE
+- brw/nir: Fix source handling of nir_intrinsic_load_barycentric_at_offset
+- brw/algebraic: Optimize derivative of convergent value
+- brw/nir: Use offset() for all uses of offs in emit_pixel_interpolater_alu_at_offset
+
+Jan Alexander Steffens (heftig) (1):
+
+- gfxstream: Use proper log format for 32-bit Vulkan
+
+Job Noorman (1):
+
+- ir3/ra: assign interval offsets to new defs after shared RA
+
+Jose Maria Casanova Crespo (1):
+
+- v3dv: avoid TFU reading unmapped pages beyond the end of the buffers
+
+Juan A. Suarez Romero (1):
+
+- v3dv: don't check if DRM device is master
+
+Kenneth Graunke (4):
+
+- brw: Track the largest VGRF size in liveness analysis
+- brw: Use live->max_vgrf_size in register coalescing
+- brw: Use live->max_vgrf_size in pre-RA scheduling
+- brw: Don't assert about MAX_VGRF_SIZE in brw_opt_split_virtual_grfs()
+
+Lars-Ivar Hesselberg Simonsen (2):
+
+- panvk: Add barrier for interleaved ZS copy cmds
+- vk/sync: Fix execution only barriers
+
+Lionel Landwerlin (3):
+
+- brw: fix shuffle with scalar/uniform index
+- anv: fix self dependency computation
+- brw: fix Wa_22013689345 emission
+
+Marek OlÅ¡Ã¡k (5):
+
+- radeonsi: work around a primitive restart bug on gfx10-10.3
+- radeonsi: make si_shader_selector::main_shader_part_* an iterable union
+- radeonsi: add ACO-specific main shader parts
+- ac/surface: make gfx12_estimate_size reusable by gfx6
+- ac/surface: select 3D tile mode without overallocating too much for gfx6-8
+
+Mike Blumenkrantz (4):
+
+- gallium/util: check nr_samples in pipe_surface_equal()
+- tu: check for valid descriptor set when binding descriptors
+- zink: don't set shared block stride without KHR_workgroup_memory_explicit_layout
+- zink: stop setting ArrayStride on image arrays
+
+Natalie Vock (1):
+
+- aco: Make private_segment_buffer/scratch_offset per-resume
+
+Patrick Lerda (9):
+
+- r600: move stores to the end of shader when required
+- r600: fix textures with swizzles limited to zero and one
+- r600: fallback to util_blitter_draw_rectangle when required
+- r600: fix pa_su_vtx_cntl rounding mode
+- r600: fix points clipping
+- i915: fix i915_set_vertex_buffers() related refcnt imbalance and remove redundancies
+- i915: fix slab_create() related memory leaks
+- i915: fix nir_to_tgsi() related memory leak
+- i915: fix draw_create_fragment_shader() related memory leak
+
+Pierre-Eric Pelloux-Prayer (1):
+
+- winsys/amdgpu: disable VM_ALWAYS_VALID
+
+Rob Clark (1):
+
+- tu/vdrm: Fix userspace fence cmds
+
+Ryan Mckeever (1):
+
+- pan/format: Update format flags to follow HW spec
+
+Samuel Pitoiset (4):
+
+- radv: fix ignoring conditional rendering with vkCmdResolveImage()
+- radv: determine if HiZ/HiS is enabled earlier on GFX12
+- radv: add a workaround for buggy HiZ/HiS on GFX12
+- radv: apply the workaround for buggy HiZ/HiS on GFX12 for DGC
+
+Sviatoslav Peleshko (1):
+
+- vulkan/wsi/headless: Remove unnecessary wsi_configure_image()
+
+Tapani PÃ¤lli (3):
+
+- compiler/glsl: check that bias is not used outside fragment stage
+- mesa: clamp texbuf query size to MAX_TEXTURE_BUFFER_SIZE
+- mesa: various fixes for ClearTexImage/ClearTexSubImage
+
+Timothy Arceri (1):
+
+- glsl: fix regression in ubo cloning
+
+Timur KristÃ³f (4):
+
+- nir/xfb: Preserve some xfb information when gathering from intrinsics.
+- nir/opt_varyings: Fix assertion when deduplicating TCS outputs.
+- radv: Use buffers_written mask when gathering XFB info.
+- radv: Call nir_opt_undef too after nir_opt_varyings.
diff --git a/docs/relnotes/25.1.0.rst b/docs/relnotes/25.1.0.rst
deleted file mode 100644
index 65d18fe5143..00000000000
--- a/docs/relnotes/25.1.0.rst
+++ /dev/null
@@ -1,4108 +0,0 @@
-Mesa 25.1.0 Release Notes / 2025-05-07
-======================================
-
-Mesa 25.1.0 is a new development release. People who are concerned
-with stability and reliability should stick with a previous release or
-wait for Mesa 25.1.1.
-
-Mesa 25.1.0 implements the OpenGL 4.6 API, but the version reported by
-glGetString(GL_VERSION) or glGetIntegerv(GL_MAJOR_VERSION) /
-glGetIntegerv(GL_MINOR_VERSION) depends on the particular driver being used.
-Some drivers don't support all the features required in OpenGL 4.6. OpenGL
-4.6 is **only** available if requested at context creation.
-Compatibility contexts may report a lower version depending on each driver.
-
-Mesa 25.1.0 implements the Vulkan 1.4 API, but the version reported by
-the apiVersion property of the VkPhysicalDeviceProperties struct
-depends on the particular driver being used.
-
-SHA checksums
--------------
-
-::
-
-    TBD.
-
-
-New features
-------------
-
-- cl_khr_spirv_linkonce_odr in rusticl
-- storagePushConstant16 on panvk
-- storageInputOutput16 on panvk
-- VK_KHR_depth_stencil_resolve on panvk
-- VK_KHR_separate_depth_stencil_layouts on panvk
-- VK_EXT_separate_stencil_usage on panvk
-- VK_KHR_sampler_ycbcr_conversion on panvk/v10+
-- VK_EXT_ycbcr_2plane_444_formats on panvk/v10+
-- VK_EXT_ycbcr_image_arrays on panvk/v10+
-- VK_KHR_imageless_framebuffer on panvk
-- VK_KHR_uniform_buffer_standard_layout on panvk
-- VK_EXT_border_color_swizzle on panvk
-- VK_MESA_image_alignment_control on NVK
-- shaderFloat16 on panvk
-- VK_KHR_shader_subgroup_uniform_control_flow on panvk/v10+
-- VK_KHR_shader_maximal_reconvergence on panvk/v10+
-- VK_EXT_device_memory_report on RADV
-- VK_KHR_shader_subgroup_extended_types on panvk/v10+
-- shaderStorageImageExtendedFormats on panvk
-- VK_KHR_display on panvk
-- VK_EXT_display_control on panvk
-- EXT_shader_framebuffer_image_fetch on v3d
-- EXT_shader_framebuffer_image_fetch_coherent on v3d
-- KHR_blend_equation_advanced on v3d
-- KHR_blend_equation_advanced_coherent on v3d
-- KHR_partial_update on etnaviv
-- VK_KHR_line_rasterization on panvk
-- VK_EXT_line_rasterization on panvk
-- shaderImageGatherExtended on panvk
-- textureCompressionBC on panvk
-- VK_EXT_sample_locations on RADV for GFX10+
-- GL_ARB_shader_clock on panvk
-- VK_KHR_shader_float_controls on panvk
-- VK_KHR_shader_float_controls2 on panvk/v10+
-- storageBuffer8BitAccess on panvk
-- storagePushConstant8 on panvk
-- uniformAndStorageBuffer8BitAccess on panvk
-- MSAA with 8 and 16 sample counts on panvk
-- VK_KHR_spirv_1_4 on panvk/v10+
-- Mali G720 and G725 on Panfrost and panvk
-- dualSrcBlend on panvk
-- VK_KHR_dynamic_rendering_local_read on panvk
-- VK_EXT_subgroup_size_control on panvk/v10+
-- VK_KHR_format_feature_flags2 on panvk
-- shaderStorageImageReadWithoutFormat on panvk
-- shaderStorageImageWriteWithoutFormat on panvk
-- VK_EXT_direct_mode_display on panvk
-- Vulkan 1.2 on panvk/v10+
-
-
-Bug fixes
----------
-
-- RADV:RX 9070:Mesa-25.0.5 GTA 5 Enhanced GPU HANG
-- [ANV/DG2] nvpro-samples/vk_raytracing_tutorial_KHR/ray_tracing_reflections renders not all reflections
-- radv: Flickering in Kingdom Come: Deliverance II
-- RADV regression causes severe glitches in Hunt Showdown 1896 on Polaris
-- Z-Fighting in Tomb Raider IV - VI Remastered Linux
-- [anv] VK_ERROR_DEVICE_LOST on Linux 6.13.8 while playing Dota 2 on Intel Graphics
-- Variable Rate Shading (VRS) produces very aliased results on RADV with an AMD gpu
-- WWE 2k23 small "artifacts"
-- RadeonSI - ACO does not spill enough SGPRs despite low VGPR pressure in some scenarios
-- RADV: Performance Regression (~18%) on Vega 64 (GFX9) in Cyberpunk 2077 caused by commit 08918f08805f (MR 34361)
-- radeonsi: CL conformance test \`vector_swizzle` fails since 177427877bb50ad7ba24abfa13e55a2684d804df
-- [macOS] glapi_gentable.c:46:10: fatal error: 'glapitable.h' file not found
-- commit 90faadae regression - Warhammer 40,000: Space Marine 2 crashing
-- RADV: GPU hangs always at certain places in the game "Sniper Elite: Resistance"
-- Random mesa crashes in kwin_wayland on a 6600XT
-- Patch to fix clinfo on rusticl
-- radv/aco: Ghost of Tsushima hangs and causes gpu resets on RDNA 3 GPU
-- mesa-vulkan-driver-git.x86_64 causes strange colored rectangle artifacts in Final Fantasy XIV
-- NVK - Out of video memory error when starting Marvel Rivals
-- NVK - Out of video memory error when starting Marvel Rivals
-- RADV: Performance regression in Elden Ring on GFX8/Polaris
-- RADV: Performance regression in Elden Ring on GFX8/Polaris
-- Vulkan issues after sleeping on 9070 XT
-- ring gfx_0.0.0 timeout after waking from sleep - RX 9070
-- Confidential issue #12324
-- Confidential issue #12946
-- svga: how do I test this driver?
-- brw: new Xe2 CTS failures
-- [NVK] NAK assert in The Last of Us Part 2 shader
-- anv: S.T.A.L.K.E.R. 2: Heart of Chornobyl crashes after starting a new game
-- [ANV][LNL] - Lost Records: Bloom & Rage (1902960) - Title hangs on launch and subsequently crashes to desktop.
-- [BMG] Intel b580 battlemage: Fort Solis (Unreal Engine game) boots to menu, hangs while loading after hitting continue from the main menu
-- [ANV][LNL] -  NINJA GAIDEN 2 Black (3287520) - Environment assets are incorrectly rendered or missing.
-- [ANV][LNL] - The Headliners (3059070) - Title hangs a few minutes after launch.
-- anv, regression: Invisibly blinking cliffs & rocks in Satisfactory DX12 on BMG
-- [Feature request] Add HK support for VK_EXT_queue_family_foreign vulkan extension
-- vk/overlay: output_file option failing
-- The Last of Us Part I GPU hang on gfx1201
-- glsl: IR validation fails on some shaders after lower_precision (breaks GLSL-to-NIR)
-- [bisected, LNL] brw: 341e5117ecbc ("brw/nir: Treat load_const as convergent") regresses arb_gpu_shader5-interpolateAtOffset on LNL
-- vulkan regression mesa 24.3.4 to 25.0.0.rc3 with broadcom
-- AMD: broken Minetest trace on Vega iGPU
-- All OpenGL applications segfault
-- radv: nir_opt_varyings.c:2766: deduplicate_outputs: Assertion \`list_index == 0' failed.
-- vulkan/wsi: memory leak from wsi_CreateSwapchainKHR
-- [RADV][RDNA3][Phoenix3][APU] NARAKA: BLADEPOINT (1203220) gpu hang reproducible (ice/water regression mesa 24.1 bisected SAMPLE_MASK_TRACKER_WATERMARK=15) random (maybe other apps/games)
-- GPU hangs running Octopath Traveler II with 780M
-- GPU crash on Radeon 780M with Tales of Arise
-- The Last of Us - shadows flickering on gfx1201 without nohiz flag
-- brw: Hit unreachable nir_op_fsign case that brw_nir_lower_fsign missed
-- Panvk:Add Support for BCn (BC1âBC7) Texture Compression
-- anv: Dark pattern overlayed on objects in Eve Online DX11 mode on BMG
-- radv/aco: Strobing artifacts in Pacific Drive
-- aco: Distorted light halos, Star Citizen
-- Mesa 25 removes VA-API encoding for R9 390
-- debian-android build is huge
-- isl: CPCBCompressionEnable is now LosslessCompressionEnable
-- Video stuttering / anv: extend implicit fencing support
-- anv, bmg: Visual issues in AC Origins, Odyssey and Fenyx Rising when dxvk doesn't export PointSize
-- [ANV][LNL] - A Game About Digging A Hole (3244220) - Title throws an assertion failure on launch.
-- [ANV][BMG] - A Plague Tale: Requiem - Severe shadow flicker
-- [ANV][LNL] - Hogwarts Legacy (990080)  - Flickering artifacts visible on magical barrier.
-- brw: regression on Gfx9 dEQP-VK
-- HTML Docs fail to build from source with Sphinx 8.2.1
-- libglapi.dll ain't built anymore under Windows
-- anv/video: Timestamps are exposed in video encode queue, but it crashes
-- Getting a crash with manually built llvmpipe (OpenGL)
-- [RadeonSI] Blender assetshelf icons are borken in mesa >= 25.0.0
-- radeonsi regression after 24.3.4
-- misc OpenGL CTS failures
-- glBindVertexBuffer regression due to ID reuse
-- RADV: logic used to avoid running on CDNA is faulty
-- [ANV][LNL] - Company of Heroes 3 (1677280) - Circular banding is present on screen during gameplay.
-- video hardware acceleration issue with "VA"
-- [LNL/BMG] Assassin's Creed Valhalla trace replay hang
-- Vulkan conformanceVersion is reported as 0.0.0.0 in Mesa 25.0.0
-- X11 + Zink on NVK flickers older frames in Firefox based browsers
-- VRAM Abnormal use on mesa 25.0
-- [radv][regression] Multiple games detect the wrong amount of vram
-- Resident Evil 2 Remake flickers
-- OpConstantNull not supported for OpTypeCooperativeMatrixKHR
-- v3dv: vkcube-wayland crashes on raspberry pi 5 kernel 6.12 and latest mesa
-- GMSH Visualization Fails with radeonsi:can't compile a main shader part,  Fedora 41 AMD 7900xt
-- AMD VDPAU deinterlacing SIGSEGV
-- radv: vkd3d-proton test_primitive_restart_list_topology_stream_output randomly fails on NAVI2X
-- Mesa 24.1 introduced a Vulkan problem with DOOM 2016 on AMD 780M GPU
-- radeonsi: Firefox fails assertion requiring binding vertex elements before vertex_buffers
-- nouveau & zink+nvk: Flashing in Firefox and Thunderbird on Hyprland
-- Zink: Kopper's present thread causes Wayland protocol races
-- GLmatrix needs aligned malloc
-- Lavapipe crashes if no Position is output in mesh shader
-- radeonsi/video: Allocate video buffers with modifiers 7f7206f1a9d brake 'mplayer -vo vdpau...' on GFX8 (Polaris 20)
-- [RADV/aco][regression][bisected] - Avowed (2457220) - GPU hangs near Watermill outside of Dawnshore
-- radv/sqtt: assertion "layout transition marker should be only emitted inside a barrier marker"
-- mesa_shader_cache directory is created even if mesa_shader_cache_db is used.
-- nak: Fold i2b(b2i(x))
-- [radv] Glitchy ground geometry regression in Total War Warhammer III on RX 7600
-- NVK: Implement shaderSharedInt64Atomics
-- nvk: Implement VK_MESA_image_alignment_control
-- radeonsi: regression with running DaVinci Resolve under rusticl since 666a6eb871d5dec79362bdc5d16f15915eb52f96
-- [ANV][LNL] - Black Myth: Wukong (2358720) - Corruption is visible near the edge of water.
-- [ANV][LNL] - Hogwarts Legacy (990080) - Pixelated corruption is visible when looking out at the water.
-- radv/video/h265: pps.flags.transform_skip_enabled_flag = 1 randomly hangs GPU
-- turnip falls with \`assertion "errno == ETIME" failed`
-- [ANV][LNL] - Steel Rats (619700) - Game crashes after opening logos play before reaching main menu
-- nvk: Implement host-only descriptors
-- Gnome-shell Wayland fails to start with segfault at modifier-less driver
-- [ANV][LNL] - DYNASTY WARRIORS: ORIGINS (2384580) - Dithered transparency has vertical bands.
-- AMD Radeon R9 270 randomly causes video playback applications to crash with "amdgpu: The CS has been rejected"
-- ci: a306 jobs use a307 files
-- Rendering issues on GravityMark with RadeonSI ACO
-- Expose low latency encoding for radv vulkan video encode
-- i915: multiple tests assert with tgsi_ureg.h:893: ureg_swizzle: Assertion \`reg.File != TGSI_FILE_NULL' failed.
-- ci: debian-build-testing fails in nightly
-- shaders/closed/steam/deus-ex-mankind-divided/260.shader_test fails NIR validation
-- shaders/closed/steam/deus-ex-mankind-divided/260.shader_test fails NIR validation
-- panvk : vk_pipeline_cache_object_deserialize: Assertion \`reader.current == reader.end && !reader.overrun' failed.
-- 46a8d5e7ef61735416d0c54886a7a9930621ae2c causes a permission denied spam
-- [BUILD] Build Failure: Implicit Function Declaration 'timespec_sub_saturate' (loader_wayland_helper.c)
-- anv: \`MESA: warning: INTEL_HWCONFIG_MIN_GS_URB_ENTRIES (2) != devinfo->urb.min_entries[MESA_SHADER_GEOMETRY] (0)`
-- intel genX_acceleration_structure: missing dependency to bvh/header.spv.h
-- ci: what's going on with zink-venus-lavapipe ?
-
-
-Changes
--------
-
-Aaron Ruby (17):
-
-- gfxstream: Replace pre-processor (LINUX && !ANDROID) checks with LINUX_GUEST_BUILD
-- gfxstream: Make the virtgpu device discovery for LinuxVirtGpu more robust
-- gfxstream: Change "mesaOnly" nomenclature to be "guestOnly"
-- gfxstream: Add common interfaces in the VirtGpuDevice to query DrmInfo and PciBusInfo
-- gfxstream: Clean up the gfxstream_vk device and instance init
-- gfxstream: Fix precedence and ownership issues on Linux for imported FD and the VirtGpuResource
-- gfxstream: Add reference counting for GEM handles in LinuxVirtGpuBlob
-- gfxstream: Downgrade log severity when enabling params in LinuxVirtGpu
-- gfxstream: Remove vkGetImageSubresourceLayout ResourceTracker entry
-- gfxstream: Full emulation support for VK_EXT_image_drm_format_modifier
-- gfxstream: Resolve/clean-up inconsistencies with advertising emulated extensions
-- gfxstream: No VIRGL_BIND_LINEAR for ColorBuffers
-- gfxstream: Move virtgpu_gfxstream_protocols.h to the common location for house protocols
-- egl: Remove FallbackZink config item entirely
-- gbm/dri: Match zink autoloading from egl
-- drm-uapi: Sync virtgpu header
-- virtio: Remove virglrenderer_hw.h entirely
-
-Adam Jackson (8):
-
-- zink: Enable KHR_shader_subgroup
-- lvp: set subgroupQuadOperationsInAllStages to true
-- glx: Make #undef GLX_INDIRECT_RENDERING do something
-- mapi/glx: Remove xserver code generation
-- glx: Remove (almost) all usage of _X_HIDDEN / _X_INTERNAL
-- mapi/glx: Remove FASTCALL/PURE
-- loader: Stop looking in ${libdir}/tls/
-- meson: Simplify the power8 optimization logic
-
-Aditya Kumar (1):
-
-- gfxstream: Fix compiling gfxstream for musl libs
-
-Alejandro PiÃ±eiro (1):
-
-- nir: aliasing checks should be also done with index != 0
-
-Aleksi Sapon (3):
-
-- draw: fix gl_PrimitiveID in tessellation
-- llvmpipe: improve aniso filtering
-- lp: fix gnu-empty-initializer warning
-
-Alyssa Rosenzweig (226):
-
-- meson: factor out with_driver_using_cl
-- nir: add nir_function_intrinsics_pass
-- nir/lower_scratch_to_var: handle KERNELs
-- nir/lower_scratch_to_var: handle multi-function shaders
-- nir/print: extract nir_print_function_body
-- nir/serialize: add specialized function serialization
-- nir: introduce bindgen_return
-- nir: add nir_call_serialized helper
-- vtn: add vtn_bindgen2 tool
-- libcl: add MIN3/MAX3 macros like on the host
-- libcl: define GLSL-style compute built-ins
-- libagx: port to glsl-style compute builtins
-- asahi: port to vtn_bindgen2
-- nir: include __LINE__ in NIR_PASS validation results
-- libcl: add unreachable() macro
-- nir: add image_min_lod_agx
-- nir: add lod_bias_min_agx tex src
-- agx: lower min LOD for txf
-- agx: switch to nir_tex_src_lod_bias_min_agx
-- hk: pack has_border with clamp_0_sampler_index
-- hk: rearrange sampler image desc
-- hk: emulate EXT_image_view_min_lod
-- hk: advertise EXT_image_view_min_lod
-- Revert "hk: Stop using strings or common key types for meta keys"
-- intel: drop nir_lower_printf calls
-- intel/nir_lower_printf: modernize nir
-- intel: port to u_printf context + singleton
-- nir/lower_printf: hash format strings in nir_printf_fmt
-- nir: drop printf_base_identifier
-- nir: add nir_intrinsic_has_semantic helper
-- nir: switch intrinsic semantics to BIT
-- nir: mark subgroup/quadgroup ops
-- nir/gather_info: use subgroup/quadgroup flags
-- nir/opt_move_discards_to_top: use semantic
-- nir: mark a few more subgroup ops
-- libcl/vk: add common query copy write routine
-- nir: default-initialize next_stage
-- asahi: clang-format
-- asahi: fix libwrap.dylib
-- asahi: fix cull distance with GS
-- hk: implement calibrated timestamps
-- hk: fix increment CS invs
-- hk: do not incorrectly offset host-image-copy sources
-- asahi: bind zero-page
-- libagx: use zero page
-- asahi: use zero sink for vbuf
-- hk: use zero sink for null index buffer
-- hk: don't allocate zero sink
-- libagx: add missing null pointer check
-- asahi: perf debug indirect tess
-- asahi: use NIR_PASS to validate more
-- asahi: switch tib lower to intrinsic pass
-- libagx: fix subgroup id confusion
-- libagx: fix wraparound issue with robust draw kernel
-- libagx: use assert instead of 0xdeadbeef writes
-- asahi: add more alignment asserts
-- hk: reject non-2D modifiers
-- hk: unstub UnmapMemory2KHR
-- hk: unbind VAs
-- hk: fix buffer binding
-- hk: enable bufferDeviceAddressCaptureReplay
-- docs/asahi: update varying info
-- docs/asahi: add some section headers
-- docs/asahi: describe sparse page tables
-- asahi: rename Null layout
-- asahi: identify image mode enum
-- asahi: add sparse block XML
-- ail: model sparse page tables
-- ail: unit test sparse_table_size_B
-- ail: report mip_tail_first_lod for sparse
-- ail: report miptail stride
-- ail: move helpers to layout.h for sharing
-- ail: extract a blocksize helper
-- ail: expose ail_get_max_tile_size
-- ail: add ail_bytes_to_pages helper
-- ail: add ail_get_twiddled_block_B helper
-- ail: unit test ail_get_twiddled_block_B
-- asahi: assert page alignment in vm_bind
-- asahi: support unbinding VA in agx_va_free
-- agx: implement sparse residency queries
-- hk: ban sparse host-image-copy
-- hk: implement sparse
-- asahi: drop cargo culted disk cache disable
-- agx: fix uniform atomic opts
-- hk: ensure space with the dispatch
-- hk: pass cmdbuf, not control stream, into precomp dispatch
-- hk: assert more
-- hk: accelerate buffer copies with CL
-- hk: pass cmdbuf to perf_debug
-- libagx: fix ia_primitives with tessellation
-- libagx: vectorize tess level loads
-- hk: perf debug sparse binding
-- asahi,libagx,hk: don't set custom_target names
-- asahi: drop trivial depends
-- agx: assert shift bounds
-- agx: fix botched address fuses
-- hk: do not clamp txf for copy shaders
-- libagx: use 64-bit multiply for image atomic calculation
-- asahi: fix null deref in error path
-- hk: fake min/max filtering for proton
-- agx: handle rgb32 residency queries
-- hk: ban sparse RGB32
-- agx: handle sparse buffer images
-- asahi: support sparse in virtgpu
-- nir/builder: add nir_shader_tex_pass
-- treewide: use nir_shader_tex_pass
-- radv/nir_lower_viewport_to_zero: intrinsic pass
-- radv/nir_lower_view_index: intrinsic pass
-- radv/nir_lower_fs_barycentric: intrinsic pass
-- radv/nir_lower_intrinsics_early: intrinsic pass
-- radv/nir_lower_fs_intrinsics: intrinsic pass
-- nvk: rewrite query copy shader in CL C
-- docs/asahi: clarify twiddled vs GPU-tiled
-- ail: rename twiddled -> gpu tiled
-- ail: split compression up
-- asahi: rename wip modifier
-- asahi: drop silly
-- hk: drop silly
-- nir: add nir_progress/nir_no_progress helpers
-- asahi: clang-format
-- nir: clang-format
-- treewide: Switch to nir_progress
-- treewide: port remaining nir_metadata_preserve users
-- nir,nak: update comments referencing nir_metadata_preserve
-- nir: eliminate nir_metadata_preserve
-- nir: clean up progress
-- ir3: clean up progress manually
-- asahi: clang-format
-- vulkan: add common VK_PRINT_STR/VK_COPY_STR macros
-- hk: switch to common VK_COPY/PRINT_STR
-- anv,hasvk: switch to common VK_COPY/PRINT_STR
-- v3dv: switch to common VK_COPY/PRINT_STR
-- radv: use VK_COPY_STR
-- panfrost,panvk: fix clang warnings
-- vulkan: add helpers to work with executable statistics
-- util: add shader statistic framework
-- asahi: port to common stats framework
-- v3dv: fix clang warning
-- meson: make CL args common
-- meson: set NDEBUG appropriately for OpenCL
-- intel: use common CL args
-- meson,clc: set CL standard from meson
-- panfrost: clean up CL meson rules
-- panfrost: port to common stats framework
-- agx: call nir_lower_is_helper_invocation
-- pan/mdg: call nir_lower_is_helper_invocation
-- nir/lower_helper_writes: fix stores after discard
-- pan/lower_helper_invocation: clean up
-- bin: add script for applying review trailers
-- bin: add list of Mesa contributors
-- libcl: add u_foreach_bit
-- hk: fix cull distance confusion
-- asahi: integrate printf/abort support
-- libagx: do not use prefix sums for GS index buffer
-- asahi/gs: drop non-XFB prefix sums
-- asahi/gs: factor out output info
-- asahi/gs: avoid recalculating
-- asahi/gs: only prefix sum with XFB
-- libagx,asahi: hoist GS draw generation
-- asahi/gs: drop unused params
-- asahi/gs: report whether xfb is needed
-- asahi: do not dispatch count/pre-GS unless needed
-- hk: do not dispatch count/pre-GS unless needed
-- libagx: use indirect draw struct
-- libagx: clean up
-- tu: use the stats framework
-- v3dv: use the stats framework
-- drm-uapi: update drm_fourcc.h
-- ail: drop fake modifiers
-- libagx: reduce # of variants of unroll restart
-- asahi: add assert for max variant count
-- agx: fix ctz of zero with address calcs
-- agx: fix tg4 offset residency
-- hk: advertise semaphore extensions
-- hk: advertise bufferDeviceAddressCaptureReplayEXT
-- hk: fix unaligned copies
-- libagx: clean up query copy; bug fix
-- libagx: assert alignment for copies
-- libagx: use common heap allocs
-- asahi: fix printf without result buffer
-- asahi: fix depth buffer feedback loops
-- asahi: clang-format
-- glsl_to_nir: upcast array indices
-- nir/lower_blend: refactor logicop variables
-- nir/lower_blend: disable logic ops for unsupported formats
-- nir/lower_tex: use vector_insert_imm
-- vk/meta: generalize 3D blit code
-- asahi,hk: disentangle logicop_enable
-- agx: optimize nonuniform offset
-- hk: drop dead todo
-- hk: fix last VGT output component limits
-- hk: support colour <--> z/s copies
-- hk: advertise VK_EXT_queue_family_foreign
-- hk: advertise maintenance7
-- hk: advertise maintenance8
-- bin: add rebase mode
-- drm-uapi: add asahi uapi
-- asahi: disable virtio gpu for upstream
-- asahi: port to stable uAPI
-- asahi: remove unstable uapi header
-- gallium: wire up asahi driver
-- asahi: fix i/a queries with tess
-- panfrost: invert and rename no_ubo_to_push flag
-- panfrost: do not push "true" UBOs
-- asahi: shrink VA space for sparse emulation
-- asahi: add sparse emu helpers
-- asahi: fix zero bo leak
-- hk: bind for sparse emulation
-- hk: use ro maps
-- hk: advertise sparseResidencyBuffer
-- hk: drop soft fault assumption in hk_buffer_addr_range
-- util/simple_mtx: fix duplicate definition
-- nir: unvendor lod_bias(_agx)
-- nir: handle mismatched bias/lod bitsizes
-- nir: add sampler LOD bias lowering
-- hk: handle lod/min_lod size mismatch
-- agx: switch to common LOD bias lowering
-- hk: fix underbinding scratch
-- hk: fix tessellation + clipper queries
-- hk: fix null FS corner cases
-- agx: model sources as late-kill in demand calcs
-- agx: late-kill sources
-- agx: early-kill sources only if it won't shuffle
-- hk: fix patch count = 0 handling
-- asahi: fix possible null deref
-- asahi: do not use "Null" layout
-
-Andrew Wolfers (1):
-
-- vulkan: Add BGRA format support
-
-Antonino Maniscalco (2):
-
-- freedreno/crashdec: Avoid crashing on some traces
-- freedreno/crashdec: Add check for \`CP_BV_SQE_STAT_ADDR`
-
-Antonio Ospite (28):
-
-- ci/android: fix building deqp on Android
-- ci/android: add an android-angle-lavapipe job
-- ci/android: don't do unnecessary cleanup
-- ci/android: don't set HOME globally in cuttlefish-runner.sh
-- ci/android: disable audio in cuttlefish, it is not needed
-- ci/android: disable modem simulator in cuttlefish, it is not needed
-- ci/android: stop cuttlefish before copying the logs, to log everything
-- ci/android: increase the waiting time to stop the cuttlefish launcher
-- ci/android: bump CUTTLEFISH_BUILD_NUMBER
-- ci/android: use an x86_64_only cuttlefish image
-- ci/android: push /deqp-gles/mustpass/egl-main.txt.zst
-- ci/android: pass -vsock_guest_cid to launch_cvd
-- ci/android: move all dEQP handling in one place in cuttlefish-runner.sh
-- ci/android: add an android-deqp-runner.sh script
-- ci/android: add a job using android-cts instead of deqp-runner
-- ci/android: don't set EGL_PLATFORM on the host before launching cuttlefish
-- ci/android: increase the waiting time to stop the cuttlefish launcher
-- ci/android: factor out a generic android-runner.sh from cuttlefish-runner.sh
-- ci/android: remove some unnecessary adb commands from android-runner.sh
-- ci/android: check for ANGLE_TAG in android-deqp-runner.sh
-- ci/android: remove old mesa and ANGLE libraries before pushing new ones
-- ci/android: always push ANGLE libraries
-- ci/android: push also the intel vulkan driver
-- ci/android: handle ANGLE being installed under /system on Android 15+
-- ci/android: factor out GLES runtime version retrieval to a function
-- ci/android: only ship x86_64 artifacts in debian-android build job
-- ci/android: strip the artifacts of the debian-android job
-- meson: pass --no-pager to \`meson configure` command
-
-Ashley Smith (2):
-
-- panfrost: Reset syncobj after use to avoid kernel warnings
-- pan/bi: Enable ARB_shader_clock extension support
-
-Assadian, Navid (1):
-
-- amd/vpelib: More parameters to the segmentation process and introduce validation hook
-
-Autumn Ashton (5):
-
-- radv: Fix compute resolve rounding
-- radv: Enable fragmentShadingRateWithCustomSampleLocations
-- radv: Expose EXT_sample_locations everywhere
-- radv: Expose VK_SAMPLE_COUNT_1_BIT for sample position on GFX10+
-- ci/zink+radv: Add sample locations fails
-
-Bas Nieuwenhuizen (1):
-
-- radv: Move support check out of winsys.
-
-Benjamin Cheng (1):
-
-- d3d12/video_enc: Fix AV1 tile_info() coding
-
-Benjamin Lee (41):
-
-- panfrost: minor refactors in preparation for panvk 16-bit IO
-- panfrost: move handling for bifrost mediump lowering to pan_collect_varyings
-- panfrost: support 16-bit vertex attributes
-- panfrost: support 16-bit varyings
-- panvk: advertise storagePushConstant16 and storageInputOutput16
-- panvk: enable VK_KHR_depth_stencil_resolve
-- panvk: enable KHR_separate_depth_stencil_layouts
-- panvk: document missed extensions in new_features
-- panvk: implement VK_EXT_separate_stencil_usage
-- panfrost: remove NIR_PASS_V usage for noperspective lowering
-- meson: update wayland-protocols source_hash
-- panfrost: fix large int32->float16 conversions
-- panfrost: reorder lower_bit_size pass
-- panfrost: fix condition in bi_nir_is_replicated
-- panfrost/va: remove swizzle mod from LDEXP
-- panfrost: implement 16-bit ldexp
-- panvk: advertise shaderFloat16
-- panfrost: implement 16-bit pack/unpack intrinsics
-- panvk/csf: fix uninitialized read in utrace_clone_init_builder
-- panfrost/pps: fix omitting several counters
-- panfrost: fix libpan_v4 header include
-- panfrost/va: remove dead code for packing BRANCHZI.i16 lane mod
-- driconf: add uint64 type
-- panvk: add core mask driconf options
-- panfrost: add core mask driconf options
-- pan/va: add roundmode modifier to additional instructions
-- panfrost: implement float controls rounding mode
-- pan/va: preserve signed zero in f32->f16 conversions
-- pan/bi: refactor bi_instr_ftz to allow dontcare FTZ states
-- pan/bi: ignore ftz mode when scheduling int instructions
-- pan/bi: implement denorm behavior float controls
-- panvk/va: don't advertise independent denorm behavior
-- panvk: advertise VK_KHR_shader_float_controls
-- panvk: advertise VK_KHR_float_controls2
-- panfrost: define bi_swizzle alias values
-- panfrost: add bi_swizzle values for unused swizzles
-- panfrost/va: use 'lane' modifier for MKVEC.v2i8
-- panfrost: use bifrost instruction table for bi_lower_swizzle
-- panfrost/va: valhall-specific swizzle lowering
-- panvk: enable uniformAndStorageBuffer8BitAccess and storagePushConstant8
-- panvk: don't advertise VK_KHR_float_controls2 on bifrost
-
-Benjamin Otte (1):
-
-- lavapipe: Don't advertise support for multiplane drm formats
-
-Benjamin ROBIN (2):
-
-- util/disk_cache: Do not try to delete old cache if cache is disabled
-- docs: Update MESA_SHADER_CACHE_DIR env variable behavior
-
-Bo Hu (2):
-
-- gfxstream: Adding support for VK_KHR_global_priority extension
-- gfxstream: update code generator for simplified dep graph
-
-Boris Brezillon (29):
-
-- panvk: Don't clobber registers if the render pass was suspended
-- pan/decode: Fix the blend_count mask
-- panvk/csf: Don't free the resources twice when init_render_desc_ringbuf() fails
-- panvk: Initialize device virtual address space after the VM creation
-- vulkan/state: Fix input attachment map state initialization/copy
-- vk/pass: Add input attachment location info
-- vulkan/state: Fix default input attachment map values
-- panvk/jm: Don't force a preload if the previous batch didn't have draws
-- pan/bi: Allow depth/stencil tile buffer access using LD_TILE
-- pan/bi: Pass load_converted_output_pan target through a source
-- pan/bi: Pass an explicit sampleid to load_converted_output_pan
-- panvk/csf: Set invalidate_inherited_ctx only if the render pass is inherited
-- panvk: Re-order things in panvk_deserialize_shader()
-- panvk: Isolate CS specific bits in panvk_shader
-- panvk: Generate the earlyzs LUT at shader creation time
-- pan/earlyzs: Support the shader ZS read-only case and its optimization on v10+
-- panvk/jm: Move cmd_prepare_draw_sysvals() out of the layer loop
-- panvk: Support color attachment remapping
-- pan/bi: Introduce two intrinsics to support input attachment remapping
-- panvk: Optimize input attachment loads when we can
-- panvk: Skip BY_REGION barriers if we're in a render pass
-- panvk: Advertise KHR_dynamic_rendering_local_read support
-- pan/va: Support relaxed waits on read-only render targets
-- panvk/csf: Optimize read-only tile buffer access
-- panfrost: also consider z/s for tile-size
-- pan/earlyzs: Fix the read-only ZS optimization
-- panvk/csf: Pass less arguments to emit_vs_attrib()
-- panvk/csf: Fix instance attribute offseting
-- pan/format: Disable image storage on A8_UNORM
-
-Caio Oliveira (112):
-
-- intel/brw: Move fs_inst implementation code together
-- intel/brw: Rename fs_inst to brw_inst
-- intel/brw: Rename fs_inst_box to brw_inst_box
-- intel/brw: Move some larger functions from brw_inst.h to brw_inst.cpp
-- intel/brw: Remove brw_gs_compile struct
-- intel/brw: Rename file brw_fs_nir.cpp to brw_from_nir.cpp
-- intel/brw: Remove 'fs' prefix from brw_from_nir functions
-- anv: Add statistic for 'GRF registers' for Xe3+
-- intel/brw: Add brw_analysis.h
-- intel/brw: Use brw_analysis prefix for liveness analysis files
-- intel/brw: Use brw_analysis prefix for def analysis file
-- intel/brw: Use brw_analysis prefix for performance analysis files
-- intel/brw: Move idom_tree declaration to brw_analysis.h
-- intel/brw: Move analysis passes without own file to brw_analysis.cpp
-- intel/brw: Merge brw_ir_analysis.h into brw_analysis.h
-- intel/brw: Use brw prefix instead of namespace for dep analysis enum
-- intel/brw: Use brw prefix instead of namespace for analysis implementations
-- intel/brw: Remove 'using namespace brw' directives
-- intel/brw: Remove offsets and total_size from VGRF allocator
-- intel/brw: Pass fs_visitor around instead of the simple_allocator
-- intel/brw: Add functions to allocate VGRF space
-- intel/brw: Fold simple_allocator into the shader
-- intel/brw: Rename and move thread_payload types to own header
-- intel/brw: Merge brw_fs_visitor.cpp into brw_fs.cpp
-- intel/brw: Rename files brw_fs.cpp/h to brw_shader.cpp/h
-- intel/brw: Rename fs_visitor to brw_shader
-- intel/brw: Rename fs_copy_prop_dataflow to brw_copy_prop_dataflow
-- intel/brw: Rename a few remaining functions to remove fs prefix
-- intel/brw: Update outdated comments
-- intel/compiler: Use -Werror=vla
-- intel/brw: Use the builder DO() function in all places
-- intel/brw: Always have a (non-DO) block after a DO in the CFG
-- intel/brw: Don't need to repair CFG in brw_opt_combine_constants
-- brw: Reformat brw_gram.y and brw_lex.l
-- brw: Fix size in assembler when compacting
-- brw: Always verify EU compaction in debug mode
-- brw: Remove unused function
-- brw: Add block pointer in brw_inst
-- brw: Use brw_inst::block in Def analysis
-- brw: Use brw_inst::block in Combine Constants
-- brw: Use brw_inst::block in CSE
-- brw: Remove block parameter from brw_inst::remove()
-- brw: Simplify brw_builder "insert before inst" constructor
-- brw: Add explicit way to get an empty brw_builder
-- brw: Embed at_end() inside brw_builder(brw_shader \*) constructor
-- brw: Remove bblock_t parameters from various passes
-- brw: Make assembler strict about JIP and UIP order
-- brw: Add support for GOTO/JOIN in the assembler
-- brw: Rework label tracking in assembler
-- brw: Remove extra interface in brw_cfg types
-- brw: Remove dead code from control flow
-- brw: Add missing dependency classes to various passes
-- brw: Get the reference to brw_def_analysis only once in saturate propagation
-- brw: Move defs analysis back to its place in saturate propagation
-- brw: Simplify the test code for brw passes
-- brw: Add assembler support for DPAS
-- brw: Remove extra SHADER_OPCODE_FLOW emitted during NIR conversion
-- spirv: Update headers and metadata from latest Khronos commit
-- vulkan: Update XML and headers to 1.4.311
-- spirv: In SpecConstantOp handling don't adjust convert ops bit_size twice
-- brw: Fix decoding of 3-src destination stride in EU validation
-- brw: Allow generating destination with stride 2 in 3-src instructions
-- brw: Remove prefix gfx10 from enum types
-- brw: Make some integer check more explicit
-- brw: Add BRW_TYPE_BF for bfloat16
-- brw: Add BRW_TYPE_BF validation
-- brw: Consider bfloat16 in scoreboard
-- brw: Add EU assembler support for bfloat16
-- intel/executor: Add small example with bfloat
-- brw: Expand EU validation for DPAS
-- brw: Fix disassembler trying to decode 3src_hstride in Gfx9
-- brw: Remove brw_cfg::dump()
-- brw: Track num_instructions in a block
-- brw: Use block's num_instructions in scoreboard tests
-- brw: Track total_instructions in a shader
-- brw: Add analysis for block IP ranges
-- brw: Use brw_ip_ranges in passes
-- brw: Use brw_ip_ranges in scheduling / regalloc
-- brw: Use brw_ip_ranges in liveness analysis
-- brw: Remove adjust_block_ips and brw_inst::remove() with defer
-- intel/executor: Use getopt for command line arguments
-- intel/executor: Allow selecting a device to use
-- brw: Use control flow helpers in scoreboard tests
-- brw: Use SIMD16 shaders in scoreboard tests for Xe2+
-- brw: Stop setting SFID in scoreboard tests
-- brw: Return actual progress in brw_lower_scoreboard
-- brw: Add parser of SWSB annotations to use in tests
-- brw: Use new bld/exp style in scoreboard tests
-- brw: Remove HSW specific code from brw_compile_cs.cpp
-- brw: Add brw_builder::uniform()
-- brw: Fix invalid memory access in scoreboard test
-- brw: Fix memory leak in EU validation tests
-- intel/executor: Fix check for open() failure
-- brw: Properly handle cooperative matrices created with constants
-- spirv: Take a separate data_type when creating a new vtn_variable
-- brw: Add a few basic tests for register coalesce
-- brw: Clean up saturate propagation after non-defs version removal
-- brw: Add brw_range struct
-- brw: Use brw_range in IP ranges analysis
-- brw: Use brw_range when operating with live ranges
-- brw: Use brw_range to store VGRF ranges
-- brw: Use brw_range to store Vars ranges
-- brw: Use brw_range::last() to explicit get the last valid IP
-- brw: Make brw_range use half-open ranges
-- broadcom/ci: Skip test due to timeout
-- nir/load_store_vectorize: Skip new bit-sizes that are unaligned with high_offset
-- intel: Add intel_device_info::has_systolic
-- intel: Disable has_bfloat16 for MTL
-- brw: Allow DPAS with BF on Gfx125
-- brw: Update EU validation to allow packed BF mixed with packed F
-- intel/executor: Update bfloat example
-- intel/executor: Fix bfloat example for converting F to packed BF
-
-Caleb Callaway (3):
-
-- anv: add INTEL_DEBUG=rt_notrace
-- intel/compiler: fix lingering i965 references
-- intel/tools: fix 32b build for EU stall tool
-
-Casey Bowman (2):
-
-- vulkan/screenshot-layer: Add RGBA surface format support
-- vulkan/screenshot-layer: Correct queueFamilyIndex source
-
-Caterina Shablia (11):
-
-- panvk: enable imagelessFramebuffer
-- panvk: enable uniformBufferStandardLayout
-- nir: teach nir_lower_bit_size to handle ballot and ballot_relaxed
-- pan/bi: ensure src bit sizes of ballot{,_relaxed} and read_invocation
-- pan/bi: lower non-32-bit ballot{,_relaxed}
-- pan/bi: lower subgroups before lowering int64
-- panvk: enable subgroupExtendedTypes
-- panfrost: don't overwrite push uniforms and sysvals UBO with user's UBO
-- panfrost: update nr_uniform_buffers before dispatching XFB
-- panfrost: require buffer_count and pushed_words to be passed to panfrost_emit_const_buf
-- panfrost: move the comment closer to what it's about
-
-Charmaine Lee (1):
-
-- svga: remove tgsi semantic in shader compiler key
-
-Christian Gmeiner (20):
-
-- docs: Update perfetto with the latest status
-- docs: Update the list of drivers with CPU tracepoints
-- docs: Add perfetto driver specifics for V3D
-- etnaviv: isa: Add swizzle instruction
-- nir: Add bool return value to nir_lower_clip_halfz(..)
-- nir: Add bool return value to nir_lower_texcoord_replace(..)
-- etnaviv: nir: Return progress for etna_lower_alu(..)
-- etnaviv: nir: Return progress for etna_lower_io(..)
-- etnaviv: nir: Don't use deprecated NIR_PASS_V macro anymore.
-- zink/ntv: Only emit GeometryStreams cap if multiple streams are used
-- etnaviv/ci: Bring back GC7000
-- etnaviv/ci: Start using the revision number for GPU_VERSION
-- etnaviv/ci: Update flakes for gc7000-r6214
-- etnaviv/ci: Add gles2 run for GC3000
-- etnaviv/ci: Add missing rev to GC3000
-- etnaviv: rs: Factor out box alignment function
-- etnaviv: rs: Change param etna_get_rs_alignment_mask(..)
-- etnaviv: Add support for KHR_partial_update
-- mesa/formats: Add MESA_FORMAT_NV12
-- etnaviv: Add multi-planar YUV support
-
-Colin Marc (1):
-
-- vulkan/wsi: implement the Wayland color management protocol
-
-Collabora's Gfx CI Team (7):
-
-- Uprev Piglit to fc8179d319046f45346bcbcc5aaeabebdf151f03
-- Uprev Piglit to 04d901e49de6b650f9dceaf73220371273d87f73
-- Uprev Piglit to 708a9e365b18fdd881af989f75e1a6c1409cae8c
-- Uprev ANGLE to 1b34d2a18af12cc55a3bc74dd679c2937d10cc5c
-- Uprev ANGLE to 3818d37d5e94317f01810053b8f28c1f1e8b98e6
-- Uprev Piglit to 0ecdebb0f592
-- Uprev ANGLE to a3f2545f6bb3
-
-Connor Abbott (52):
-
-- tu: Constify frag_areas argument of tu_fdm_bin_apply_t
-- tu: Refactor fragment density map sampling
-- freedreno: Add VSC mask parameter to CP_SET_BIN_DATA5
-- tu: Implement bin merging for fragment density map
-- freedreno: Add a750+ "absolute" VSC bin mask
-- tu: Implement "absolute" bin mask on a750
-- tu: Make sure tiles being merged are adjacent
-- tu: Fix vertical tile merging check
-- tu: Fix static blend bandwidth calculation
-- tu: Remove useless prim_order state merging
-- ir3: Fix const allocation when parsing assembly
-- freedreno/decode: Push hostaddr->gpuaddr conversion into highlight_gpuaddr()
-- freedreno/crashdec: Use register for RB rptr
-- freedreno/crashdec: Handle hangs where the SQE is in RB
-- freedreno/crashdec: Fix and extend control reg dumping on a750
-- freedreno/crashdec: Dump CP_BV_SQE_UCODE_DBG
-- freedreno: Misc control registers updates
-- tu: Implement VK_KHR_maintenance7
-- tu: Plumb through VkMemoryBarrierAccessFlags3KHR
-- tu: Handle D32S8 -> R32 and R32 -> D32S8 copies
-- tu: Handle R8->D24S8 and D24S8->R8 copies
-- tu: Handle a pipelineStageCreationFeedbackCount of 0
-- ir3: Remove ir3_info::data
-- tu: Expose VK_KHR_maintenance8
-- compiler/shader_info: Better document require_full_quads
-- nir, compiler: Rename needs_quad_helper_invocations
-- compiler,nir: Gather needs_full_quad_helper_invocations info
-- ir3: Use needs_full_helper_invocations
-- tu: Fix binning_possible detection with bin merging
-- tu: Fix GMEM offset for multisample layered separate stencil
-- tu: Enable GMEM with layered rendering
-- tu: Fix size of frag_size_ir3 and frag_offset_ir3 driver params
-- tu: Fix reported FDM fragment size with multiview
-- tu: Fix layer_count with dynamic rendering + multiview
-- ir3: Split mad with scalar ALU
-- tu: Only allow power-of-two fragment areas
-- tu: Split out part of tiling config to vsc config
-- tu: Fix CmdClearAttachments with fragment density map
-- tu/fdm: Skip some patchpoints when binning
-- tu: Implement VK_QCOM_fragment_density_map_offset
-- vk/runtime: Use vk_command_buffer in renderpass wrappers
-- vk/runtime: Add common CmdEndRendering
-- tu: Implement VK_EXT_fragment_density_map_offset
-- ir3: Pass through access flags when lowering global accesses
-- nir/opt_preamble: Handle load_global_ir3
-- ir3: Move load/store vectorization to finalize
-- ir3: Vectorize shared memory loads/stores
-- tu: Fix flushing when using a staging buffer for copies
-- freedreno: Add compute_lb_size device info
-- freedreno/a6xx: Define CONSTANTRAMMODE
-- freedreno/a6xx, turnip: Set CONSTANTRAMMODE correctly
-- ir3: Take LB restriction on constlen into account on a7xx
-
-Corentin NoÃ«l (12):
-
-- venus/ci: Skip flaky test due to intermittent timeouts
-- ci: Update CrosVM and Virglrenderer
-- lavapipe: Remove doubly initialized features
-- lavapipe: Change lvp_cmd_type to anonymous enum
-- ci: Update CrosVM and Virglrenderer
-- virgl: nir: Don't use deprecated NIR_PASS_V macro anymore
-- nir: Add bool return value to nir_legacy_trivialize(..)
-- ntt: nir: Don't use deprecated NIR_PASS_V macro anymore
-- tnn: nir: Don't use deprecated NIR_PASS_V macro anymore
-- ci: Uprev virglrenderer to latest version on time
-- virgl: Close handle on resource info failure
-- virgl: Use drmCloseBufferHandle instead of calling dmIoctl directly
-
-Daniel SchÃ¼rmann (43):
-
-- aco/isel: fix empty exec tracking for uniform branches
-- aco/isel: move cf_info into separate struct cf_context
-- aco/isel: rename cf_context::has_divergent_branch
-- aco/isel: use cf_context in if_context to restore cf information
-- aco/isel: use cf_context in loop_context to restore cf information
-- aco/isel: add and use exec_info::empty() helper
-- aco/isel: fix assumptions about potential empty exec mask in nested control flow
-- aco/isel: remove loop nest information from exec_info
-- aco/isel: track control flow divergence in loops more accurately
-- nir: make divergence information metadata
-- nir: require nir_metadata_divergence if needed
-- amd: switch to nir_metadata_divergence
-- intel: switch to nir_metadata_divergence
-- nouveau: switch to nir_metadata_divergence
-- nir: only print divergence information if metadata is valid
-- nir/serialize: don't serialize divergence information
-- nir/validate: validate divergence metadata
-- nir/print: print phi sources sorted by predecessor blocks
-- aco/scheduler: always respect min_waves on GFX10+
-- aco/scheduler: stop rounding down the target number of waves on GFX10+
-- aco: unify get_addr_sgpr_from_waves() and get_addr_vgpr_from_waves() into one function
-- aco/scheduler: keep track of RegisterDemand at UpwardsCursor::insert_idx
-- aco/scheduler: keep track of RegisterDemand at DownwardsCursor::insert_idx{_clause}
-- aco/scheduler: remove unused include of unordered_set
-- aco/insert_exec_mask: Don't immediately set exec to zero in break/continue blocks
-- aco/insert_exec_mask: don't restore exec in continue_or_break blocks
-- aco/lower_branches: allow other instructions after s_andn2 in break blocks
-- aco/ssa_elimination: insert parallelcopies for p_phi immediately before branch
-- aco/ssa_elimination: refactor scratch_sgpr handling
-- aco/ssa_elimination: create a single parallelcopy instruction for linear and logical phis
-- aco/assembler: Fix short jumps over chained branches
-- aco/assembler: Don't insert chained branches into otherwise empty blocks
-- aco/tests: add more tests for chained branches
-- zink: lower {demote|terminate}_if to CF after lowering point smooth
-- nir: remove nir_lower_discard_if_to_cf option
-- nir: set SYSTEM_VALUE_HELPER_INVOCATION read for nir_intrinsic_is_helper_invocation
-- zink: clean up HelperInvocation code emission
-- zink: enable CapabilityDemoteToHelperInvocation and extension only if required
-- aco/lower_branches: properly consider exec mask needs of branch targets
-- aco: don't assume that demote doesn't cause an empty exec mask
-- aco/insert_exec_mask: if applicable, use s_wqm to restore exec after divergent CF
-- aco/insert_exec_mask: don't disable dead quads on demote in divergent CF
-- aco: Remove empty exec skipping after demote
-
-Daniel Stone (29):
-
-- ci/vvl: Use appropriate level of parallelism
-- ci: Move common testing packages to test-base
-- ci: Move apitrace to test-base container
-- ci: Add debian/arm32_test-* images
-- ci: Build libdrm for Android host builds
-- ci/angle: Use native toolchain for builds
-- ci/zink: Expand flake definition on radv
-- ci: Update kernel for Panthor scheduling fixes
-- ci/panfrost: Move G610 testing to pre-merge
-- ci: Re-enable Collabora CI
-- docs/ci: Fix nginx caching instructions
-- ci/lava: Fail faster when getting results
-- etnaviv: Add missing build dependency on generated header
-- ci/amd: Add new radeonsi fail seen in the wild
-- ci/zink: Flake out sparse tests
-- ci: Add daniels to restricted-trace users
-- ci: Re-enable trace jobs with updated Piglit
-- ci: Move softpipe issue from fail to flake
-- ci/amd: Disable radv-fossils
-- ci/windows: Don't copy non-existent libglapi.dll
-- ci/panfrost: Split inherit definitions into -inc
-- ci: Reduce build job timeouts
-- ci/softpipe: Add timeouts to softpipe jobs
-- ci/llvmpipe: Add llvmpipe and lavapipe timeouts
-- ci/virgl: Add timeout to software jobs
-- ci/docs: Add timeout to doc build
-- ci/microsoft: Add job timeouts and pin Piglit to GSt
-- ci: Make all job timeouts explicit
-- doc/ci: Update nginx caching snippets
-
-Danylo Piliaiev (28):
-
-- u_trace: print tracepoint params in csv output
-- util: Make debug_dump_flags thread safe
-- util: Add dump_debug_control_string to dump debug_control
-- tu: Add gmem disable reason to renderpass tracepoint
-- tu: Add info about debug options to command buffer tracepoint
-- tu: Get correct src view when storing gmem attachment
-- freedreno/fdl: Log mutability when dumping layout
-- tu: Handle mismatched mutability when resolving from GMEM
-- tu/a6xx: Emit VSC addresses for each bin to restore after preemption
-- nir/nir_lower_multiview: Don't assert if load_deref doesn't have var
-- ir3: Set need_full_quad depending on info.fs.require_full_quads
-- tu: Be more granular in calculating whether blend state reads color
-- tu: Fix NULL deref in trace_end_render_pass
-- freedreno/regs: Rename BINNING bit to FS_DISABLE in a few regs
-- ir3: Detect empty fragment shaders
-- tu/a7xx: Bypass invoking empty FS for D/S-only draw calls
-- ir3: Detect FS that write only color without other side effects
-- tu: Disable FS in certain cases even if FS is not empty
-- tu/lrz: Improve LRZ around stencil tests and reads_dest cases
-- tu: Use EARLY_Z also for stencil tests
-- ir3: Fix shaders that write only color classified as empty
-- freedreno: Bump kernel uapi (linux 6.14)
-- freedreno,tu: Read and pass to compiler uche_trap_base
-- tu: Implement VK_KHR_shader_clock
-- freedreno/a6xx: Implement ARB_shader_clock
-- tu,freedreno: Don't fallback to LINEAR with DRM_FORMAT_MOD_QCOM_COMPRESSED
-- ir3: VARYING_SLOT_LAYER output is used for binning
-- tu: Fix disable_fs state update condition
-
-Dave Airlie (24):
-
-- radv/video: move encoder to using a buffer instead of an image
-- radv/video: calculate colloc buffer size for h264 B frames.
-- radv/video: add h264 b frame encoding support.
-- vulkan/wsi/x11: don't use update_region for damage if not created
-- nak: adjust latencies on fp16/64 instructions on Turing
-- nvk: enable float16 on turing.
-- loader/nouveau: load zink as the GL driver for turing and above.
-- radv/video: don't try and send events on UVD devices.
-- vulkan/video: add simple parameter retrieval wrappers
-- radv/video: convert to using common parameter wrappers.
-- anv/video: convert to common parameters retrieval code
-- anv/video: don't write to params if not set.
-- vulkan/video: add support for inline session paramters.
-- radv: expose VK_KHR_video_mainteance2
-- anv: expose VK_KHR_video_maintenance2
-- gallivm: check for avx512vbmi and tell LLVM the correct answer.
-- nak: add reads after setting writes
-- nak: Add an a_has_pred parameter to waw_latency
-- nak: Add Turing latency information
-- nak: Add Ampere and Ada latency information
-- nvk: update nvidia class header files.
-- nvk: add ADA compute class to nv_push_dump
-- nvk: add hopper support to nv_push_dump
-- nak: add F2FP to sm75 instr latencies
-
-David Rosca (64):
-
-- ac/vcn_dec: Fix AV1 film grain on VCN5
-- radeonsi/video: Avoid stream handle duplicates in PID namespace
-- frontends/va: Don't try to switch to protected buffer in EndPicture
-- frontends/va: Add CreateContext flag to enable protected context
-- frontends/va: Require protected context for VAProtectedSliceDataBuffer
-- frontends/va: Switch to graphics context when creating protected surface
-- radeonsi/vcn: Use texture instead of video buffer for DPB buffers
-- radeonsi/video: Fix creating video buffers with AMD_DEBUG=tmz
-- frontends/vdpau: Set H264 chroma_format_idc
-- radeonsi/vcn: Set correct chroma format for H264 decode
-- radeonsi/uvd: Set correct chroma format for H264 decode
-- ci/amd: Remove VAAPI skips
-- frontends/va: Use transfer stride and offset in DeriveImage
-- radv/video: Fix setting balanced preset for HEVC encode with SAO enabled
-- radv/video: Move IB header from begin/end to encode_video
-- radeonsi: Use gfx for TMZ buffer clears
-- winsys/amdgpu: Add assert for secure submissions on compute ring
-- frontends/vdpau: Use extra reference buffer for AV1 film grain
-- ac/surface: Only allow linear modifier for subsampled 422 formats
-- ac/surface: Allow DCC for multi-plane formats on GFX12
-- radeonsi/vcn: Fix chroma pitch for JPEG decode
-- radeonsi/video: Allocate video buffers with modifiers
-- radeonsi/vcn: Add UDT support for VCN5
-- radeonsi/vcn: Rework decode ref handling
-- radeonsi/video: Fix crash when creating buffers without modifiers support
-- frontends/va: Set AV1 max_width/height to surface size
-- frontends/vdpau: Set AV1 max_width/height to surface size
-- Revert "radeonsi/vcn: Limit size to target size in AV1 decode"
-- pipe: Remove PIPE_AV1_ENC_FRAME_TYPE_SHOW_EXISTING
-- radeonsi/vcn: Set all pic params for H264 encode references
-- radeonsi/vcn: Add radeon_enc_av1_picture_type
-- radeonsi/vcn: Support H264 encode weighted_bipred_idc
-- radeonsi/video: Remove mpeg12 shader decoder support
-- gallium/vl: Fix video buffer supported format check
-- Revert "frontends/vdpau: Alloc interlaced surface for interlaced pics"
-- frontends/vdpau: Fix creating deinterlace filter for interleaved buffers
-- frontends/va: Support A8R8G8B8 format for processing
-- frontends/va: Use ARGB as default fourcc for RGB32 RT format
-- frontends/va: Don't filter supported formats according to config RT format
-- gallium/vl: Return YUV plane order for single plane formats
-- radeonsi/video: Only allow 64K_S swizzle mode for VCN < 2.2
-- radeonsi/vce: Support old VCE firmware
-- radeonsi/video: Allow DCC 256B block size with drm minor >= 63
-- gallium/vl: Fix rotation with scaling for compute shaders
-- gallium/vl: Fix mirror with rotation for compute shaders
-- frontends/va: Don't ignore rotation and mirror for conversions to RGB
-- ac/parse_ib: Fix parsing output format on VCN5
-- ac/parse_ib: Parse VCN DYNAMIC_REFLIST_BUFFER
-- radv: Use radv_format_to_pipe_format instead of vk_format_to_pipe_format
-- radv: Add radv_format_description to remap 10/12bit formats to 16bit
-- radeonsi/vcn: Disable AV1 unidir compound with rate control
-- egl/x11: Fix swap interval setup
-- radv/video: Fix msg header total size
-- radv/video: Fix encode session info for VCN3+
-- radv/video: Use ac_vcn_enc_init_cmds
-- radv/video: Always enable B pictures for H264 encode
-- radeonsi/vpe: Don't try to flush cs from buffer_map
-- radeonsi/vcn: Don't try to flush cs from buffer_map
-- radeonsi/uvd,vce: Don't try to flush cs from buffer_map
-- radeonsi/video: Remove cs argument from si_video_resize_buffer
-- radeonsi/vpe: Use float division to get scaling ratio
-- radeonsi/vpe: Fix process_frame return value
-- radeonsi/vpe: Use studio range for YUV and full for RGB by default
-- radeonsi/vcn: Fix decode target index for H264 interlaced streams
-
-David Tobolik (1):
-
-- rusticl/feat: LinkOnce ODR
-
-Dmitry Baryshkov (4):
-
-- freedreno/registers: allow skipping the validation
-- meson: add freedreno (turnip) Vulkan to arm64 defaults
-- meson: disable SIMD blake optimisations on x32 host
-- mesa-clc: add an option to force inclusion of OpenCL headers
-
-Dmitry Osipenko (1):
-
-- virtio/vpipe: Correct vdrm_vpipe_connect() definition
-
-Dudemanguy (1):
-
-- treewide: remove unneeded executable bit in non-scripting files
-
-Dylan Baker (6):
-
-- intel: output a depfile with mesa_clc
-- iris: Correctly set NOS for geometry shader state changes
-- iris: fix handling of GL_*_VERTEX_CONVENTION
-- intel/tools: deduplicate zlib_inflate function
-- intel/tools: move ascii85_decode to common code
-- intel/decoder: free memory in error case
-
-Ella Stanforth (4):
-
-- v3d/compiler: Implement load_output
-- v3d: enable framebuffer fetch
-- v3d: Fix fbfetch with discards.
-- v3d/compiler: Fixup output types for all 8 outputs
-
-Emma Anholt (6):
-
-- mesa/ffvs: Skip doing redundant stores of .xyz when doing lighting calculation.
-- ci/anv: Enable testing with Vulkan video encode/decode.
-- docs: Drop some weird unhelpful text about DRI2.
-- egl: Apply autopep8.
-- egl: Retire NOK_swap_region support.
-- egl: Retire NV_post_sub_buffer support.
-
-Emmanuel Gil Peyrot (1):
-
-- panvk: Initialize out array with the correct length
-
-Eric Engestrom (159):
-
-- VERSION: bump to 25.1
-- docs: reset new_features.txt
-- docs: update calendar for 25.0.0-rc1
-- docs/android: drop libglapi.so now that it's gone
-- ci/cuttlefish: drop \`rm libglapi.so` now that it's no longer loaded
-- gfxstream: drop unnecessary semi-colons
-- gfxstream: fix signedness of shifts
-- gfxstream: drop dead variables
-- gfxstream: use \`range` variable for its intended purpose
-- gfxstream: mark unused variables as such
-- docs: update calendar for 25.0.0-rc2
-- llvmpipe/tests: include math.h for INFINITY
-- ci: don't run on tag pipelines
-- ci: drop redundant condition
-- ci: only trigger the CI for release managers when pushing to staging branch
-- ci: run containers builds on staging branches
-- ci/yaml-toml-shell-py-test: don't run on post-merge pipelines
-- ci/yaml-toml-shell-py-test: run on direct push pipelines
-- ci: finish sorting vars
-- ci: rename generate-env.sh to export-gitlab-job-env-for-dut.sh
-- docs: update calendar for 25.0.0-rc3
-- ci: debian-testing-ubsan is used by tests
-- llvmpipe/ci: drop fraction for asan tests that takes 1.5 min without fraction
-- docs: add release notes for 25.0.0
-- docs: add sha sum for 25.0.0
-- docs: update calendar for 25.0.0
-- docs: add release calendar for 25.0.x cycle
-- docs/releasing: fix "release schedule" subsections nesting
-- docs/release-calendar: add 25.1 branchpoint & rc dates
-- ci/alpine: pin the release to avoid random unexpected changes
-- ci/alpine: control wayland & wayland-protocols versions
-- ci: move shader-db test job from build jobs yaml to test jobs yaml
-- ci/build: remove a couple of unnecessary "override needs: to the same value"
-- ci/build: move .use-debian/x86_64_build out of the generic .meson-build and into the debian/x86_64 jobs
-- ci/build: split meson-build into build-for-tests and build-only
-- ci/build: add explicit build-for-tests or build-only to all jobs
-- ci/build: lower the delay to start build-only jobs
-- docs: update gitlab docs urls
-- vtn_bindgen2: keep the printf blob local to avoid LTO issues
-- lavapipe/ci: add vkd3d job
-- ci/build: build-test the dri2 code
-- ci/b2c: fix comment location
-- ci/b2c: explain better why we don't clone mesa
-- ci/b2c: use B2C_JOB_TEMPLATE directly
-- ci/b2c: set default value for B2C_MACHINE_REGISTRATION_IMAGE in the job
-- ci/b2c: set default value for B2C_TELEGRAF_IMAGE in the job
-- ci/b2c: set default value for B2C_KERNEL_CMDLINE_EXTRAS in the job
-- ci/b2c: split B2C_JOB_VOLUME_EXCLUSIONS in the jinja template
-- ci/b2c: rename IMAGE_UNDER_TEST to B2C_IMAGE_UNDER_TEST
-- ci/b2c: pass through all the B2C_* variable without renaming them
-- ci/b2c: pass through all the CI_* variables as well
-- ci/b2c: set the registry proxy from the job
-- ci/b2c: use more readable "long" argument names
-- v3d/ci: mark traces humus/AmbientAperture and humus/DynamicBranching3 as flaky
-- docs: update calendar for 25.0.1
-- docs: add release notes for 25.0.1
-- docs: add sha sum for 25.0.1
-- wsi/x11: drop misleading reference to anv in var names
-- meson: simplify video-codecs option parsing
-- ci/deqp: backport fix for dEQP-VK.binding_model.buffer_device_address.*
-- meson: announce that clover is deprecated (slated for removal)
-- lvp/ci: document fixed tests
-- lvp/ci: skip tests that are timing out (>1 min)
-- lvp/ci: fix sorting of flakes
-- lvp/ci: remove duplicate flakes (noticed after sorting)
-- lvp/ci: document flakes seen over the last week
-- freedreno/ci: document fixed test
-- freedreno/ci: document flakes seen over the last week
-- nvk/ci: fix sorting of flakes
-- nvk/ci: document flakes seen over the last week
-- zink+nvk/ci: document new failures
-- zink+nvk/ci: fix sorting of flakes
-- zink+nvk/ci: document flakes seen over the last week
-- radv/ci: document flakes seen over the last week
-- zink+radv/ci: fix sorting of flakes
-- zink+radv/ci: document flakes seen over the last week
-- ci: document http proxy bug & disable farms relying on it
-- ci/container: fix image tags comment in trampoline script
-- ci/init-stage2: document that only lava jobs upload results to s3
-- ci/build: no need to list all the files that will go into the uploaded artifact
-- ci/piglit: drop usage of s3cp for a simple download
-- ci: always abort if the curl download fails
-- ci/baremetal: make sure we can follow redirects on s3 downloads
-- ci: do a regular GET request for /done files, instead of HEAD
-- ci: replace broken s3cp command with a simple curl call
-- ci: bump image tags
-- ci: drop placeholder-job tags to allow jobs to run
-- ci: document new llvmpipe & softpipe failures since the migration
-- ci: run shader-db & zink-lvp on kvm runners
-- ci: disable llvmpipe & virgl traces jobs
-- meson: do not compile libisaspec unless used
-- meson: do not compile libblake3 unless used
-- meson: do not compile libmesa_util_sse41 unless used
-- pick-ui: clean up formatting
-- pick-ui: fix enum value in test expectation
-- pick-ui: add missing field in test expectation
-- pick-ui: rename s/out/commit_message/ variable to make its contents clearer
-- pick-ui: fix parsing of multiple \`backport-to:` lines
-- docs: update calendar for 25.0.2
-- docs: add release notes for 25.0.2
-- docs: add sha sum for 25.0.2
-- rpi/ci: disable traces jobs
-- ci: re-enable igalia (rpi) farm
-- ci: document who are the farm admins
-- docs: fix last references to gallium-drivers=swrast
-- ci: remove last uses of deprecated \`swrast` alias for softpipe+llvmpipe
-- meson: drop deprecated \`swrast` alias for softpipe+llvmpipe
-- meson: move special value \`all` out of the middle of the list
-- rpi5/ci: sort flakes
-- rpi5/ci: drop duplicate flakes
-- ci: bump apitrace version
-- ci: drop packet.net tag on git archive job
-- ci: move aarch64 tag to .use-debian/arm64_build
-- ci: move android's kvm requirement to .use-debian/x86_64_test-android
-- ci: add FDO_RUNNER_JOB_PRIORITY_TAG_* to control priority of generic freedesktop runners
-- docs: remove the last 24.3 releases
-- virgl: fix typo inverting a condition
-- docs: update calendar for 25.0.3
-- docs: add release notes for 25.0.3
-- docs: add sha sum for 25.0.3
-- ci/build: drop LTO from fedora build
-- ci: rename ci-tron priority tag to avoid conflict with the generic fdo runners
-- ci/fluster: use http proxy when checking for the vector files
-- ci/fluster: don't overwrite FLUSTER_VECTORS_HOST_PATH to a different meaning
-- radeonsi/ci: update expectations
-- radv/ci: update expectations
-- freedreno/ci: update expectations
-- nvk/ci: update expectations
-- lvp/ci: update expectations
-- zink+nvk/ci: update expectations
-- zink+radv/ci: update expectations
-- zink+tu/ci: update expectations
-- zink+anv/ci: document a bunch of flaky glx tests that have been preventing merges all day
-- docs/ci: replace deprecated \`pages` job with \`pages: true`
-- docs/ci: add link to the website preview for convenience
-- docs/ci: add comment explaining what that long rule actually does
-- docs/ci: split pre-merge & merge pipeline rules
-- docs/ci: follow convention of only running jobs by default for Marge
-- ci: fix image tags indentation
-- ci/deqp: fix vulkan video build
-- VERSION: bump for 25.1.0-rc1
-- .pick_status.json: Update to d5ad7981401c2393cac38fc3215e8bbb97de06b9
-- .pick_status.json: Update to 1bf8542490679fa2a244e27fb2b04bbc3d122f74
-- meson: remove duplicate \`deprecated` for \`gallium-xa` option
-- meson: remove duplicate \`deprecated` for \`power8` option
-- .pick_status.json: Update to 5f3a3740dcc6d243f2ef14138fb1c09bcbb9b5fd
-- pick-ui: make \`Backport-to: 25.0` backport to 25.0 \*and more recent release branches*
-- .pick_status.json: Update to dd3e1190a2bdbc6b996152510407adb9a8cb5618
-- pick-ui: add missing dependency
-- [25.1 only] ci: don't treat misleading-indentation warnings are error on alpine
-- VERSION: bump for 25.1.0-rc2
-- .pick_status.json: Update to 3493500abb78a4dc22aba14840bba5c777fde745
-- .pick_status.json: Update to eeffb4e674d10db9aefebeca91c2d87c1676b81e
-- VERSION: bump for 25.1.0-rc3
-- .pick_status.json: Update to 615d0c9669595adf114a705f5b8ee88277aa99f2
-- .pick_status.json: Update to 7f0de1a51212881c9a7614327bf3e1fbc9784ddb
-- ci: drop tracking of removed folder
-- .pick_status.json: Update to c434050a0088ec3f07d63fd1019aea541632faed
-- .pick_status.json: Update to 84b9c281fe82dd66f2552687cecb61a8e22809d0
-
-Eric R. Smith (7):
-
-- panfrost: avoid potential divide by 0 calculating timer_resolution
-- panfrost: fix YUV center information for 422
-- panfrost: fix backward propagation of values in loops
-- panfrost: use an accessor function to read from bi_opcode_props
-- panfrost: consider xfb shader when calculating thread local storage size
-- panfrost,lima: use index size in panfrost minmax_cache
-- panfrost: fix transaction elimination crc valid calculation
-
-Erico Nunes (2):
-
-- ci: re-enable lima farm
-- panvk: disable VK_EXT_image_drm_format_modifier for arch < 10
-
-Erik Faye-Lund (57):
-
-- panvk: fix line-rasterization of bifrost
-- panvk: report strictLines as true
-- panvk/ci: add back incorrectly removed crash
-- pan/ci: add flaky tests to the flake-list
-- pan/ci: add fail from llvm 19 upgrade
-- pan/ci: add a couple of common flakes
-- panvk: correct number of read bytes for dynamic buffers
-- meson: rename meson_options.txt
-- panvk: report passing the VK CTS
-- panvk: rename helper
-- mesa/main: wire up glapi bits for EXT_multi_draw_indirect
-- pan/bi: use unreachable instead of DBG + assert
-- pan/bi: remove unused debug output
-- pan/genxml: rename field
-- panfrost: respect pipe_rasterizer_state::line_rectangular
-- panvk: disable shaderFloat16 on bifrost
-- docs/features: add missing panvk feature
-- docs/features: add VK_EXT_hdr_metadata
-- panvk: fix extension requirement
-- panvk: rework how we deal with extension-reqs
-- panvk: expose VK_KHR_display
-- panvk: expose EXT_display_control
-- panvk: correct VkPhysicalDeviceProperties::deviceName
-- panvk: enable KHR_line_rasterization support
-- panvk: add basic driconf infrastructure
-- panfrost: avoid accidental aliasing
-- panfrost: fix overflow-debugging
-- panfrost: use real array for panfrost_emit_plane
-- panvk: check for texture-compression support
-- panvk: expose textureCompressionBC when supported
-- mesa/main: fix regression in extension-checking
-- panvk/ci: disable some more slow tests
-- docs/features: update panvk support
-- panfrost: fixup typo in 16x sample-pattern
-- panfrost: correct tile-buffer size for some v7 GPUs
-- panvk/ci: move timeouts to crash
-- panfrost: properly align value
-- panfrost: allocate tile-buffer for dummy render-targets
-- panfrost: disable tile-pipelining when needed
-- panfrost: add color-attachment and msaa helpers
-- panvk: enable 8x and 16x msaa when supported
-- panvk: enable sampledImageIntegerSampleCounts for all MSAA formats
-- nir/lower_tex: use texture_mask instead of shifting on use
-- nir/lower_tex: avoid undefined-behavior
-- panvk: set shared_addr_format
-- panvk: enable KHR_spirv_1_4 on v10+
-- panvk: claim official conformance on v10
-- docs/panfrost: use anonymous hyperlinks
-- panvk: enable dualSrcBlend
-- docs/panvk: fixup extension support
-- docs/panvk: remove disabled extension
-- docs/panvk: fixup docs around float controls
-- docs/panvk: add VK\_-prefix for extension name
-- docs/panvk: document ycbr in terms of extensions
-- docs/panvk: document EXT extension aswell
-- docs/panvk: add missing new features
-- panvk: support vulkan 1.2 on v10+
-
-Ernst Persson (1):
-
-- intel/vulkan: Add bvh build dependency
-
-Faith Ekstrand (165):
-
-- nvk,nak: Only use u64 texture handles with codegen
-- nvk: Only pass sampler handles when needed
-- nak: Add support for bound and cbuf textures
-- nak: Optimize bindless to cbuf textures on Volta+
-- nak: Fix cbuf textures
-- nak: Stop setting .EF on tex ops
-- nak: Rename MemEvictionPriority::Unchanged to LastUse
-- nak: Add more MemEvictionPriorities
-- nak: Print .dc for OpTld4::z_cmpr
-- nak: Add MemEvictionPriorities to tex ops
-- nvk: Fix scissor bounds
-- nvk: Fix a typo in a comment
-- nak/repair_ssa: Use a worklist for get_ssa_or_phi()
-- nvk: Rename nvk_descriptor_set::mapped_ptr
-- nvk: Respect VK_DESCRIPTOR_POOL_CREATE_HOST_ONLY_BIT_EXT
-- nvk: Implement descriptorBufferPushDescriptors
-- nvk: Pull shaders from the state command buffer in nvk_cmd_process_cmds()
-- nvk: Handle shader==NULL in nvk_cmd_upload_qmd()
-- nvk: Allow sparse loads on EDB buffers
-- nak: Handle sparse texops with unused color destinations
-- nvk: Use suld for EDB uniform texel buffers
-- nvk: Align UBO/SSBO addresses down rather than up
-- nak: Use suld.constant when ACCESS_CAN_REORDER is set
-- nvk: Use suld.constant for EDB uniform texel buffers
-- nvk: Constify instance and pdev pointers
-- ci: Remove some NVK vkd3d fails
-- nak: Only use suld.constant on Ampere+
-- nak: Use MemScope::GPU instead of MemScop::System
-- zink: Use the correct array size for signal_values[]
-- zink: Use persistent semaphores for PIPE_FD_TYPE_SYNCOBJ
-- nvk/nvkmd: Fix logging of VA bind addresses
-- nvk: Don't bind a fragment shading rate image pre-Turing
-- nvk: Do not set INVALIDATE_SKED_CACHES pre-MaxwellB
-- nak: Handle tex ops with only one source
-- nak/nir: Don't provide dummy backend2 tex srcs
-- nvk: Fix indentation in begin_end_query()
-- nouveau/class_parser: Make strided element functions const
-- nak/qmd: Drop some unnecessary .try_into().unwrap()
-- nak/qmd: Add a nak_get_qmd_cbuf_desc_layout() helper
-- nvk: Handle pre-Turing dispatch indirect commands
-- nvk: Only support deviceGeneratedCommandsMultiDrawIndirectCount on Turing+
-- nvk: Only support compute shader derivatives on Turing+
-- nak/nir: Re-materialize load_const instructions in use blocks
-- nvk/image: Prefer vk_image values over pCreateInfo
-- nvk/image: Drop some unneeded initializers
-- nvk: Fix capitalization of statistics
-- nak: Fix NAK_DEBUG=spill for large FS outputs
-- nak: Handle any->Mem parallel copies
-- nak: Add a new ConstTracker struct
-- nak: Don't spill/fill const values
-- compiler/rust: Add u_printf_info to the rust bindings
-- nir: Add a get_io_index_src() helper
-- nir: Add a nir_opt_tex_skip_helpers optimization
-- nak: Set .NODEP on tex ops based on nir_opt_tex_skip_helpers()
-- zink: Don't present to Wayland surfaces asynchronously
-- zink: Revert "zink: enable single-plane modifiers for generic 2D exports"
-- egl/dri2: Rework get_wl_surface_proxy()
-- egl/wayland: Pass the original wl_surface to kopper
-- util/box: Add a intersect_2d helper
-- iris: Use pipe_box helpers for damage calculations
-- zink: Use pipe_box helpers for damage calculations
-- vulkan: Add device address helpers to vk_buffer
-- nvk: Use the new buffer device address infrastructure
-- panvk: Use the new buffer device address infrastructure
-- hk: Use the new buffer device address infrastructure
-- vulkan/meta: Use vk_buffer.device_address directly
-- zink: Set needs_barrier after transitioning to QUEUE_FAMILY_FOREIGN
-- zink: Check queue families when binding image resources
-- spirv: OpAsmTargetINTEL is untyped
-- spirv: Update the JSON and headers
-- vulkan: Update XML and headers to 1.4.309
-- nouveau/winsys: Stop asserting that imported BOs are aligned
-- nvk: Allow rendering to linear images with unaligned strides
-- nil: Relax alignment requirements for linear images
-- nil: Split linear and tiled image creation
-- nvk,nil: Stop panicing in image creation
-- vtn: Support cooperative matrices in OpConstantNull
-- loader/nouveau: Fix the comment in nouveau_zink_predicate()
-- egl/x11: Re-order an if statement
-- egl/kopper: Update the EGLSurface size after kopperSwapBuffers()
-- nak: Insert the annotation in the right spot in assign_regs
-- nak: Don't insert empty OpParCopy in assign_regs
-- nak: Always copy sources when handling vec/pack/mov ops
-- nak: Fix a SM check for OpPCnt
-- nak: Check num_regs(UGPR) instead of SM version
-- nak: Turing starts at SM73
-- nouveau/headers: Refactor class_parser
-- nouveau/headers: Drop unused Rust constants
-- nouveau/headers: Drop double-underscore from Rust names
-- nouveau/headers: Re-use Rust method types when possible
-- nvk: Reduce the size of nvk_image_view_capture
-- nvk: Free owned_gart_mem correctly
-- nvk: Fix a Volta check
-- nvk: Disable VK_EXT_post_depth_coverage on Maxwell A and earlier
-- nvk: Allocate QMDs from a heap on Maxwell A and earlier
-- nvk: Disable VK_EXT_device_generated_commands on Maxwell A and earlier
-- nvk: Don't set filterMinmax properties prior to Maxwell B
-- nvk: Disable sparse buffer binding prior to Maxwell B
-- nouveau/mme/fermi: Don't allow STATE and EMIT on the same op
-- nvk: Use the right sample mask for 8x/4pass on Maxwell A
-- nvk/nvkmd: Add a concept of incomplete pushes
-- nvk: Mark the push before an indirect push as incomplete
-- nak: hsetp2 and dsetp are slower on Volta
-- nvk: Bump the conformance version to 1.4.1.3
-- vulkan/wsi: Signal buffer memory object when blitting
-- venus: Assume wsi_mem->base_bo != NULL
-- venus: Don't report global priorities if globalPriorityQuery is unsupported
-- venus: Only claim modifiers in WSI if the host driver supports it
-- venus: Set wsi_device::supports_scanout = false
-- compiler/rust: Add a nir_alu_type wrapper
-- compiler/rust: Add more NIR intrinsic getters
-- nak: Implement nir_intrinsic_convert_alu_types
-- nak/nir: Use correct rounding for fp64 -> fp16 conversions
-- nak,nir: Generalize nak_nir_split_64bit_conversions and move it to NIR
-- nak: Move some calc_instr_deps items to a new file
-- nak: Box our RegTrackers
-- nak: Improve WS abstractions in hw_runner
-- nak: Add a QMD heap to hw_runner
-- nak: Disable lea64 and f2fp.pack_ab tests pre-Volta
-- nvk: Disable vulkanMemoryModel on Kepler and earlier
-- nvk: Use max_image_dimension for maxFramebufferWidth/Height
-- nvk: Disable 32k images on Pascal A
-- nak: Move has_fixed_latency to Op
-- nak: Add and use a ShaderModel::needs_scoreboard() helper
-- nak: Add latency helpers to ShaderModel and use them
-- nak: Move SM70 encoding and legalize to a separate file
-- nak: Move exec_latency into the per-SM files
-- nak: Move latency information into the per-SM files
-- nak: Move sched_common.rs to reg_tracker.rs
-- nak: Add GPU generation helpers
-- nak: Use is_volta() instead of sm == 70
-- nak: Put the cycle count assert behind a debug flag
-- nak: Handle delays > 15
-- nak: Add an Op::no_scoreboard() helper
-- intel/compiler: Use nir_split_conversions()
-- nak: Add a ChannelMask type
-- nak: Add support for suld/st.b
-- nak,nir: Add an image_load_raw_nv intrinsic
-- nak: Use suld.b on Kepler if we have a format
-- nak: Allow predicates in nir_intrinsic_as_uniform
-- nak: Add a NAK_DEBUG=panic option
-- nvk: Call vk_device_finish() last in nvk_DestroyDevice()
-- nvk/nvkmd: Check the correct flag for the Kepler GART workaround
-- nil: Multiply by array_stride_B instead of adding
-- nak/hw_tests: Feed predicate/carry sources with 0/1 data
-- nak: Add a plop2 test
-- nak: Add False and True to IntCmpOp
-- nak: Lower texture inputs for Kepler B
-- nak/legalize: Add a helper for lowering ineg
-- nak: Add stubs for Kepler B
-- nak: Add stubs for Fermi and Kepler A
-- nak: Move some legalization helpers from sm50 to common code
-- nak/sm50: Add zero_reg() and true_reg() helpers
-- nak/sm70: Add zero_reg() and true_reg() helpers
-- nak: Get rid of RegRef::zero
-- nvk: Disable VK_EXT_descriptor_buffer pre-Maxwell
-- nak/qmd: Rework cbuf size suffix handling
-- nak/qmd: Add support for shifted cbuf addresses
-- nak/qmd: Add QMD version 4.0 for Hopper
-- nvk: Handle shifted QMD cbuf addrs in indirect command processing
-- nak/legalize: Take a RegFile in copy_alu_src_and_lower_fmod
-- nak/legalize: Take a RegFile in copy_alu_src_and_lower_ineg()
-- nak/sm70: Fix the bit74_75_ar_mod assert
-- nvk: Maxwell+ is now conformant
-- nak: Set lower_pack_64_4x16
-
-Felix DeGrood (9):
-
-- vk/overlay-layer: fix regression in non-control pathway
-- intel/brw: support for dumping shader line numbers
-- anv: add INTEL_DEBUG=shaders-lineno
-- iris: add INTEL_DEBUG=shaders-lineno
-- drm-uapi: add eu_stall uapi
-- intel/perf: remove unnused argument from xe_perf_stream_read_error
-- intel/perf: add eu stall sampling support
-- util: add hash functions for u64 data type
-- intel/tools: create intel_monitor for sampling eu stalls
-
-GKraats (2):
-
-- x11: give error messages if Xorg only supports DRI2 and mesa only DRI3
-- EGL: legacy-x11=dri2 should support hardware driver
-
-Ganesh Belgur Ramachandra (1):
-
-- amd: use 128B compression for scanout images when drm.minor <63
-
-Georg Lehmann (83):
-
-- nir/lower_poly_line_smooth: don't emit control flow
-- nir/lower_poly_line_smooth: only smooth first color target
-- nir/lower_poly_line_smooth: support partial store_output
-- radv: remove radv_should_lower_poly_line_smooth
-- radv: inline radv_nir_lower_poly_line_smooth
-- nir/lower_poly_line_smooth: don't reject fp16
-- nir/lower_poly_line_smooth: use intrinsics_pass
-- nir/opt_move: don't move into critical sections
-- ac/nir/lower_ps: move exports after packing alu
-- nir/print: print large floats as mantissa + exponent
-- nir: range analysis for ffract
-- nir: fix range analysis for frcp
-- nir: fix frsq range analysis
-- nir: improve fsqrt range analysis
-- nir/opt_algebraic: optimize ffract(ffract(a))
-- nir/peephole_select: support demote for non CF HW
-- nir/peephole_select: handle demote and terminate in nir_opt_collapse_if
-- nir/peephole_select: don't special case nir_opt_collapse_if + limit = ~0
-- nir/peephole_select: don't include nir_search_helpers.h
-- nir/peephole_select: add options struct
-- nir/peephole_select: add option to allow discard without ~0 limit
-- nir/peephole_select: don't completely ignore ifs with dont_flatten
-- nir: replace nir_opt_conditional_discard with nir_opt_peephole_select
-- radv: remove separate discard peephole select
-- nir/opt_algebraic: optimize b2f(a != 0) * a
-- nir/search_helpers: look through vecs in is_only_used_as_float
-- nir/search_helpers: check tex source type in is_only_used_as_float
-- nir/builder: add nir_shader_phi_pass
-- nir/opt_phi_precision: use nir_shader_phi_pass
-- nir/opt_remove_phis: use nir_shader_phi_pass
-- aco/insert_exec: fix continue_or_break on gfx6-7
-- nir: add a pass to optimize phis to 1bit
-- nir/opt_algebraic: optimize ineg(a) == ineg(b)
-- nir/opt_algebraic: optimize ineg(a) == #b
-- nir/opt_algebraic: 0 >= a -> 0 == a
-- nir/opt_algebraic: optimize DXBC boolean bcsel
-- nir/opt_algebraic: optimize more boolean bcsel with constants
-- nir/opt_algebraic: optimize dxbc boolean not
-- nir/opt_algebraic: optimize constant shift of DXBC booleans
-- nir/opt_algebraic: optimize b2i(a) != -b2i(b)
-- radv: use nir_opt_phi_to_bool
-- nir/opt_varyings: clean up nir_progress usage
-- radv/nir_apply_pipeline_layout: clean up progress handling
-- radv/nir_lower_ray_queries: use nir_foreach_function_impl
-- nir/opt_algebraic: optimize bit_count(a) != 0
-- nir/opt_algebraic: optimize bcsel of b2f and constants
-- nir/opt_algebraic: optimize b2i/b2f comparision with non 0/1 constants
-- nir/opt_algebraic: optimize ~a == ~b and ~a == #b
-- nir/opt_algebraic: push comparisons with constants into bcsel with constant
-- nir/opt_algebraic: optimize more ine/ieq(umin(b2i, ), 0)
-- nir/opt_algebraic: optimize d3d a ? b : 0
-- aco/optimizer: delete combine_and_subbrev
-- radv: remove outdated vectorize TODO
-- ac/nir/mem_access_bit_sizes: split unaligned vec3 lds access to allow more read2/write2
-- aco/opt_postRA: split try_optimize_scc_nocompare in two functions
-- aco/opt_postRA: allow try_optimize_scc_nocompare for all instructions
-- aco/opt_postRA: remove scc != 0 with multiple uses
-- aco/opt_postRA: remove scc == 0 for more opcodes
-- aco/isel: use s_mul_i32 instead of s_cselect_b32 for a ? b : 0
-- radv: enable invariant geom for DOOM(2016)
-- radv: add dcc_decompress_gfx11 in radv_graphics_state_key
-- ac/nir/lower_ps_late: consider dcc decompression for null exports
-- radv/gfx10+: remove null exports if discard isn't used
-- aco: don't assume that v_interp_mov_f32 flushes denorms
-- aco/gfx11.5: remove vinterp ddx/ddy path
-- aco/validate: fix scalar source validation for DPP and gfx11+ VINTERP
-- nir/opt_algebraic: create ubfe from (a & mask) >> c
-- aco/ra: disallow vcc definitions for pseudo scalar trans instrs
-- nir: add option to keep mul24_relaxed
-- aco: implement mul24_relaxed
-- ac/llvm: support mul24_relaxed
-- ac/nir: set has_mul24_relaxed
-- aco/insert_exec: reset exec temporary after combined p_demote + p_end_wqm
-- spirv: clamp/sign-extend non 32bit ldexp exponents
-- aco/gfx9+: use d16 global/scratch/buffer loads
-- spirv: fix cooperative matrix by value function params
-- aco/gfx10: simpler solution to avoid store instructions in clauses
-- aco: form mixed MTBUF/MUBUF clauses
-- nir/opt_algebraic: optimize open coded ffract
-- nir/opt_algebraic: disable fsat(a + 1.0) opt if a can be NaN
-- aco: set opsel_hi to 1 for WMMA
-- aco/insert_exec: only restore wqm mask after control flow if necessary
-- aco/insert_exec: reset temporary when recreating wqm mask from exact mask
-
-Gert Wollny (1):
-
-- r600/sfn: gather info and set lowering 64 bit after nir_lower_io
-
-Giovanni Mascellani (2):
-
-- llvmpipe: Remove an outdated comment about subclassing pipe_screen.
-- lvp: Remove some dead code.
-
-Guilherme Gallo (30):
-
-- ci: Properly clean up rustup
-- ci: Remove cargo symlink workaround
-- ci/android: add missing pre/post build scripts
-- ci: setup-test-env: Prefer functions over aliases
-- ci: add _error_msg for internal messaging
-- ci: add support for structural tagging
-- ci: copy structural tag files to rootfs
-- ci/angle: add structured tag check to ANGLE build time
-- ci/angle: test-time structured tag checks
-- ci/angle: condense angle variables in one job
-- ci/angle: remove USE_ANGLE variable
-- ci/docs: add structured tagging documentation
-- ci/lava: Drop the repeating quotes on lava-test-case
-- ci/lava: Propagate errors in SSH tests
-- ci/lava: xtrace the lava_job_submitter call
-- ci/lava: Add U-Boot action timeout for rockchip DUTs
-- ci/lava: Properly detect VMWARE farm
-- ci: Specify the FARM variable for DUT jobs
-- ci: Simplify LAVA farm detection
-- ci/lava: Remove depthcharge-start timeout
-- ci/lava: Split boot action into deploy and boot
-- ci/lava: Tweak timeouts
-- ci/lava: Don't print empty lines when changing sections
-- Revert "ci: setup-test-env: Prefer functions over aliases"
-- ci/bin: update_tag: improve tag load
-- ci/update_tag: fix linter errors
-- ci/lava: Fix LAVA lima jobs
-- ci/lava: Fix LAVA lima jobs
-- ci/lava: Fetch kernel modules from overlay
-- ci: Add some unit tests for the duration field
-
-Gurchetan Singh (5):
-
-- gallium: drop const qualifier on return type
-- lavapipe: use quotes instead of angle bracket
-- gfxstream: check device exists before using it
-- gfxstream: refactor device initialization
-- gfxstream: follow the semantics desired by distro VK loader
-
-Hans-Kristian Arntzen (3):
-
-- radv: Always allow sparse on normal GFX/COMPUTE/DMA queues.
-- radv: Repurpose radv_legacy_sparse_binding drirc
-- radv: Always set 0 dispatch offset for indirect CS.
-
-Hyunjun Ko (12):
-
-- anv: Fix to set CDEF flter flag correctly for AV1 decoding
-- anv/video: clean-up duplicated code.
-- dri: fix a build error
-- kopper: implement to get sync values.
-- anv: fix maxDpbSlots and maxActiveReferencePictures for AV1 decoding.
-- anv: Add one more flag of VideoCapability for encoding.
-- anv: Do not support the tiling of DRM modifier if DECODE_DST
-- anv/ci: remove some expected failures of dEQP-VK.video.formats.*
-- vulkan/video: Do byte-alignment when building a h264 slice header
-- anv: Add stdSyntaxFlag values for h264/5 encoders
-- anv: Move rateControlMode to the video session.
-- anv: Use vk_video_derive_h265_scaling_list
-
-Iago Toral Quiroga (9):
-
-- v3dv: implement sync debug option
-- v3dv: serialize jobs after any barrier when debug sync is set
-- v3dv: fix missing access bit flag when checking for texel buffer reads
-- mesa: fix RGBA_SIGNED_COMPONENTS for lowered signed luminance
-- v3dv: fix crash on 32-bit builds
-- v3dv: rename v3dv_cmd_buffer_merge_barrier_state
-- v3dv: make cmd_buffer_serialize_job_if_needed take a barrier state
-- v3dv: improve handling of trailing barriers
-- pan/va: fix FAU validation
-
-Ian Romanick (38):
-
-- iris: Add missing nir_metadata_preserve in iris_lower_storage_image_derefs
-- crocus: Add missing nir_metadata_preserve in crocus_lower_storage_image_derefs
-- iris: Use nir_shader_intrinsics_pass in iris_lower_storage_image_derefs
-- crocus: Use nir_shader_intrinsics_pass in crocus_lower_storage_image_derefs
-- brw/copy: Fix handling of offset in extract_imm
-- brw/copy: Use extract_imm in try_constant_propagate_value
-- brw/copy: Allow constant propagation of some 64-bit integers
-- nir/algebraic: More (a == 0 || a == 1 || ...) patterns
-- nir/algebraic: Optimize zero comparisons of umax or umin
-- nir/algebraic: Simplify equality comparisons of b2T with 1 or 0
-- nir/algebraic: Undistribute b2i from logic-ops
-- brw/print: Don't let SHADER_OPCODE_FLOW affect indentation
-- brw: Fix typo in comment
-- brw/nir: Lower fsign again after last call to brw_nir_optimize
-- brw/opt: Move non-SSA register accounting after first brw_opt_split_virtual_grfs
-- brw: Add basic infrastructure for load_reg pseudo op
-- brw/copy: Prepare copy_propagation for load_reg
-- brw/coalesce: Prepare brw_opt_register_coalesce for load_reg
-- brw/algebraic: Constant folding for BROADCAST and SHUFFLE
-- brw: Add passes to generate and lower load_reg
-- brw/sat: Convert tests to use load_reg
-- brw/sat: Eliminate non-defs saturate propagation
-- brw/opt: Don't call brw_opt_copy_propagation before brw_lower_load_reg
-- brw/nir: Fix source handling of nir_intrinsic_load_barycentric_at_offset
-- brw/nir: Eliminate default parameter to get_nir_src
-- brw/algebraic: Optimize derivative of convergent value
-- brw/copy: Refactor source modifier type checking
-- brw/copy: Copy prop -X into Y&1
-- brw/nir: Optimize b2f(not(X)) using logical operations instead of arithmetic
-- brw/nir: Allow b2f(not(X)) optimization on Gfx12.5+
-- brw/nir: Use offset() for all uses of offs in emit_pixel_interpolater_alu_at_offset
-- nir/algebraic: Allow fmin(a,a) optimization when flush denorm to zero is not set
-- brw/algebraic: Clear condition modifier on optimized SEL instruction
-- brw/algebraic: Don't optimize float SEL.CMOD to MOV
-- elk/algebraic: Clear condition modifier on optimized SEL instruction
-- elk/algebraic: Don't optimize float SEL.CMOD to MOV
-- brw/cmod: Fix some errors when propagating from CMP to ADD.SAT
-- brw/cmod: Don't propagate from CMP to possible Inf + (-Inf)
-
-Ivan A. Melnikov (1):
-
-- gallium/radeon: Make sure radeonsi PCI IDs are also included
-
-Ivan Avdeev (2):
-
-- radv: add experimental support for AMD BC-250 board
-- radv,radeonsi: disable compute queue for BC250
-
-IvÃ¡n Briano (2):
-
-- anv: handle REMAINING_LAYERS in host image copy cases
-- brw: make HALT instruction act as barrier in new CSE pass
-
-James Hogan (8):
-
-- glsl: Expose gl_ViewID_OVR back to GLSL 1.30
-- mesa: Fix multiview attachment completeness check
-- mesa: Fix FramebufferTextureMultiviewOVR num_views check
-- mesa: Consider NumViews to reuse FBO attachments
-- mesa: Handle GL_FRAMEBUFFER_INCOMPLETE_VIEW_TARGETS_OVR
-- mesa: Check views don't exceed GL_MAX_ARRAY_TEXTURE_LAYERS
-- mesa: OVR_multiview framebuffer attachment parameters
-- mesa: Handle getting GL_MAX_VIEWS_OVR
-
-Jan Alexander Steffens (heftig) (1):
-
-- gfxstream: Use proper log format for 32-bit Vulkan
-
-Janne Grunau (8):
-
-- hk: Replace alloca with malloc in queue_submit
-- hk: Use rowPitch from VkImageDrmFormatModifierExplicitCreateInfoEXT
-- venus: Do not use instance pointer before NULL check
-- venus: virtgpu: Require stable wire format
-- asahi: build asahi_clc for -Dtools=asahi
-- asahi: Drop unnecessary idep_mesaclc dependency
-- panfrost: build panfrost_compile for -Dtools=panfrost
-- ci: Switch cross-builds to '-D tools=panfrost'
-
-Jason Macnak (6):
-
-- gfxstream: Move snapshot decoder replay into VkDecoderGlobalState
-- gfxstream: Remove unused handling mappers
-- gfxstream: Move the handle replay buffer into BoxedHandleManager
-- gfxstream: Remove duplicated boxed handle func declarations
-- gfxstream: Update variable names to avoid -Wshadow error
-- gfxstream: Remove extra dispatch variable
-
-Jeongik Cha (1):
-
-- gfxstream: Add AHARDWAREBUFFER_FORMAT_B8G8R8A8_UNORM in android_format_is_yuv
-
-Jesse Natalie (2):
-
-- meson: Enable /Zc:preprocessor for MSVC
-- CI/Windows: Update container deps
-
-Job Noorman (46):
-
-- freedreno/drm-shim: enable raytracing
-- ir3: fix emitting descriptor prefetches at end of preamble
-- ir3: add braces around complex if/else block
-- ir3/ra: handle phis with preferred regs first
-- ir3/parser: add helper to generate syntax errors based on gen
-- ir3/isa: fix (dis)asm of ldg.a/stg.a on a6xx
-- ir3: don't create SRC2 for isam without .v
-- ir3/legalize: use (sy) for ray_intersection WAR hazards
-- ir3/lower_tess: make all NIR passes report progress
-- ir3: don't use deprecated NIR_PASS_V anymore
-- ir3: reformat after previous commit
-- ir3/opt_prefetch_descriptors: fix crash after nir_progress rewrite
-- ir3: add reformatting commits to .git-blame-ignore-revs
-- nir/lower_phis_to_scalar: remove unused mem_ctx
-- nir/lower_phis_to_scalar: use nir_builder API where possible
-- nir/lower_phis_to_scalar: don't create moves for undef sources
-- nir/lower_subgroups: use build_cluster_mask for quad mask
-- ir3/ra: prevent reusing parent interval of reloaded sources
-- ir3: clear instruction uses when cloned
-- ir3/sched: unblock a0.x/a1.x after last use
-- ir3: add ir3_cursor_current_block helper
-- ir3/cse: add support for mov a0.x/a1.x
-- ir3: remove hash table for a1.x
-- ir3: add helper to create STC
-- ir3: fix false dependencies of rpt instructions
-- ir3/sched: handle dependencies between stc and const reads
-- ir3: split immediate state from rest of const state
-- ir3: make const_imm_index_to_reg helper public
-- ir3: fix max const size calculation for the binning pass
-- ir3: lower immediates to const regs in preamble on a7xx
-- ir3: keep inputs at start block when creating empty preamble
-- ir3/legalize: fix off-by-one error in kill_sched
-- ir3/legalize: take wrmask into account for delay updates
-- ir3: don't sync every TCS/GEOM block
-- ir3: run opt_if after opt_vectorize
-- ir3: make shpe a terminator
-- ir3/ra: assign interval offsets to new defs after shared RA
-- ir3: add ir3_aggressive_coalesce helper
-- ir3/ra: create merge sets for splits/collects inserted for shared RA
-- ir3/opt_preamble: take alias.rt into account for rewrite cost
-- ir3: remove spaces in shader stats
-- ir3/cp: add option to disable immediate to const lowering
-- ir3/cp: ignore alias sources for sam.s2en
-- ir3: run cp after ir3_imm_const_to_preamble
-- ir3/ra: add helper for getting a dst interval
-- ir3/ra: ignore phis handled by shared RA
-
-John Anthony (2):
-
-- panvk: Avoid division by zero for vkCmdCopyQueryPoolResults
-- panvk: Enable VK_EXT_direct_mode_display
-
-Jon Hunter (1):
-
-- freedreno/registers: Fix gen_header.py for older python3 versions
-
-Jordan Justen (5):
-
-- intel/dev: Add BMG PCI IDs (0xe210, 0xe215, 0xe216)
-- intel/dev: Stop checking hwconfig values at driver runtime
-- tools/intel_dev_info: Print hwconfig discrepancies
-- intel/dev: Ignore hwconfig difference due to WA 18040209780
-- intel/dev: Add BMG 0xe211 PCI ID
-
-Jose Fonseca (1):
-
-- glapi: Make _GLAPI_EXPORT a no-op on Windows.
-
-Jose Maria Casanova Crespo (3):
-
-- v3dv/ci: add new flakes
-- glapi: import noop_array and public stubs earlier.
-- v3dv: avoid TFU reading unmapped pages beyond the end of the buffers
-
-JosÃ© Roberto de Souza (20):
-
-- intel: Initialize upper 32bits of drm_xe_sync.handle
-- intel/dev: Improve max_cs_threads documentation
-- intel/dev: Call intel_device_info_update_after_hwconfig() from common code
-- intel/common: Retry GEM_CONTEXT_CREATE when PXP have not finished initialization
-- anv: Remove protected memory support from compute queue
-- intel: Sync xe_drm.h
-- anv: Move code adding protected memory type to common code
-- anv: Add support to create protected bo and protected exec_queue in Xe KMD
-- iris: Add support to create protected bo and protected exec_queue in Xe KMD
-- intel: Add function to check if PXP is supported in Xe KMD
-- iris: Replace BO_ALLOC_* macros by a enum
-- intel/hwconfig: Sync hwconfig with IGT
-- intel/hwconfig: Remove ignored intel_hwconfigs from apply_hwconfig_item()
-- intel/dev/xe3: Set max_slices and max_subslices_per_slice using hwconfig
-- intel/perf: Update intel_perf to match xe_drm.h
-- drm-uapi: Sync xe_drm.h
-- intel: Program XY_FAST_COLOR_BLT::Destination Mocs for gfx12
-- intel: Fix the MOCS values in XY_FAST_COLOR_BLT for Xe2+
-- intel: Fix the MOCS values in XY_BLOCK_COPY_BLT for Xe2+
-- intel/tools: Fix batch buffer decoder
-
-Juan A. Suarez Romero (31):
-
-- broadcom/compiler: move stores to the end of shader
-- Revert "st/mesa: move VS & TES output stores to the end before unlowering IO"
-- broadcom/ci: add new failures/flakes
-- v3dv: take into account GS when enabling line smooth
-- v3dv/ci: disable rpi5 job
-- vulkan: don't leak debug utils label name
-- v3dv: duplicate key for texel_buffer cache
-- vc4/ci: update expected results
-- broadcom/simulator: use string copy instead of memcpy
-- vc4/ci: update expected results
-- v3dv/ci: Skip tests causing OOM
-- Revert "v3dv/ci: disable rpi5 job"
-- v3d/v3dv/vc4: review all expected timeouts
-- v3dv: remove src_format from blit render pass creation
-- v3dv: don't batch regions with different depth offsets
-- v3dv: include depth offset on image view creation
-- vc4: check instruction before setting flags
-- v3dv: asserts struct is always non null
-- v3dv: check dynamic offset output
-- v3dv: asserts push constants data is valid
-- vc4: initialize register
-- vc4: add assertion on constant_fold
-- vc4: assert there are sources when emitting texture
-- broadcom/cle: assert attribute has a value
-- vc4: use safe iterator to remove instructions
-- broadcom/compiler: use safe iterator to remove instructions
-- broadcom/compiler: don't use VLA on emit alu
-- broadcom/compiler: initialize register
-- v3dv: don't check if DRM device is master
-- v3d(v)/ci: update expected results
-- ci: include duration in the CustomLogger
-
-Julia Zhang (5):
-
-- vulkan: handle device memory report requests
-- radv: add import and export handle_type in radv_alloc_memory
-- radv: add obj_id to radeon_winsys_bo
-- radv: emit device memory report for device memory events
-- radv: advertise VK_EXT_device_memory_report
-
-Jung-uk Kim (1):
-
-- FreeBSD: Disable support for "-mtls-dialect" for FreeBSD
-
-Juston Li (3):
-
-- anv: xe: fully initialize drm_xe_sync addr/handle union
-- iris: xe: fully initialize drm_xe_sync addr/handle union
-- wsi/common: android: disable KHR_present_[wait/id]
-
-K900 (1):
-
-- meson: support building with system libgbm
-
-Karmjit Mahil (3):
-
-- loader/wayland: Fix missing timespec.h include
-- tu: Fix Perfetto build error with vk_buffer
-- tu: Fix segfault in fail_submit KGSL path
-
-Karol Herbst (49):
-
-- ci/windows: Bump Vulkan SDK for SPIRV-Tools
-- clc: use SetUseHighestVersion when linking spirvs
-- mesa_clc: drop spirv version workaround
-- rusticl/mem: set bind flags for gl imports
-- rusticl/mesa: add PipeContext::device_reset_status
-- rusticl/queue: check device error status
-- clc: bump SPIR-V target to 1.6
-- rusticl/kernel: call nir_lower_variable_initializers earlier
-- rusticl: support SPIR-V 1.5 and 1.6
-- rusticl/mem: do not apply offset with in copy_image_to_buffer
-- rusticl/mesa: add buffer and texture variant for resource_copy_region
-- rusticl/mem: Buffer::copy_to_image layering
-- rusticl/mem: Image::copy_to_buffer layering
-- rusticl/mem: Image::copy_to_image layering
-- rusticl/mem: Image::write layering
-- rusticl/mem: accelerate Buffer::copy_rect
-- rusticl/mem: accelerate Buffer::write_rect
-- rusticl/mem: set num_samples and num_mip_levels to 0 when importing from GL
-- rusticl/platform: advertise all extensions supported by all devices
-- rusticl/util: add missing comment and assert to char_arr_to_cstr
-- intel/brw, lp: enable lower_pack_64_4x16
-- nir: Do not eliminate dead writes to shared memory in called functions.
-- rusticl/program: implement CL_INVALID_PROGRAM_EXECUTABLE check in clGetProgramInfo
-- rusticl/program: pass options by reference
-- rusticl/program: loop over all devices inside Program::build
-- rusticl/program: rework build_nirs so it only touches devices we care about
-- rusticl/program: fix building kernels
-- rusticl/program: simplify active_kernels check
-- rusticl/kernel: rename CSOWrapper to SharedCSOWrapper
-- rusticl/queue: make it unncessary to keep QueueContext Send
-- rusticl/queue: cache bound CSO
-- rusticl/mesa: remove Sync from PipeContext
-- nir/serialize: fix decoding of is_return and is_uniform
-- vtn: Support the UniformDecoration capability.
-- zink: don't apply the map_offset when mapping a staging resource in zink_buffer_map
-- iris: remove all clover support code
-- freedreno: remove all clover support code
-- llvmpipe: remove all clover support code
-- gallium: stop filling ir_target in various drivers
-- gallium: stop using PIPE_BIND_COMPUTE_RESOURCE in drivers
-- gallium: stop implementing set_compute_resources in various drivers
-- nouveau: ignore req_input_mem
-- rusticl/device: fix panic when disabling 3D image write support
-- nir_lower_mem_access_bit_sizes: fix negative chunk offsets
-- nak: fix handling of delays > 15
-- r600: fix r600_buffer_from_user_memory for rusticl
-- iris: parse global bindings for every gen
-- iris/xe: fix compute shader start address
-- iris/xe: take the grids variable_shared_mem into account
-
-Kenneth Graunke (37):
-
-- brw: Drop unused defines
-- brw: Eliminate fs_inst::shadow_compare
-- brw: Replace fs_inst::pi_noperspective with a logical control source
-- brw: Drop FB_WRITE_LOGICAL_SRC_DST_DEPTH source
-- brw: Replace fs_inst::last_rt with a logical control source
-- brw: Replace fs_inst::target field with logical FB read/write sources
-- brw: Use correct builder size for MEMORY_FENCE/INTERLOCK virtual opcodes
-- brw: Change destination of memory fences to UD type
-- brw: Eliminate the BTI source from MEMORY_FENCE/INTERLOCK opcodes
-- brw: Add latencies for HDC/RC memory fences
-- brw: Lower MEMORY_FENCE and INTERLOCK in lower_logical_sends
-- brw: Drop INTERPOLATE_AT mlen handling from size_read()
-- brw: Drop unnecessary mlen/header_size on virtual GET_BUFFER_SIZE op
-- nir: Eliminate dead writes to shared memory at the end of the program
-- brw: Rename shared function enums for clarity
-- isl: Delete redundant "use separate stencil?" check
-- isl: Drop compile time "use separate stencil" checks.
-- intel: Delete devinfo->must_use_separate_stencil
-- intel: Delete devinfo->has_surface_tile_offset
-- intel: Move devinfo->has_negative_rhw_bug into the elk compiler
-- intel: Move devinfo->has_compr4 into the elk compiler
-- intel/dev: Set minimum HS URB entries to 0.
-- intel/dev: Set max_wm_threads to 0 in the Gfx9+ devinfo structs
-- intel/dev: Rework device info macros for Gfx8+
-- intel/dev: Set a higher minimum number of URB entries for GS
-- intel: Use devinfo->urb.min_entries[GS and TCS] for setting URB configs
-- intel: Move unlit centroid workaround into the elk compiler
-- intel/decoder: Decode compute shaders in EXECUTE_INDIRECT_DISPATCH
-- brw: Make a helper to emit UNDEF for temporaries containing small types
-- brw: Emit UNDEF as needed in SSA-style builder helpers
-- brw: Skip unnecessary UNDEFs for comparisons
-- brw: Use a smaller type for masked sub-32-bit shift values
-- brw: Avoid regioning restrictions for u2u16/i2i16 narrowing conversions
-- brw: Track the largest VGRF size in liveness analysis
-- brw: Use live->max_vgrf_size in register coalescing
-- brw: Use live->max_vgrf_size in pre-RA scheduling
-- brw: Don't assert about MAX_VGRF_SIZE in brw_opt_split_virtual_grfs()
-
-Kenny Levinsen (1):
-
-- device-select: Support linux-dmabuf feedback
-
-Kevin Chuang (2):
-
-- anv/bvh: Fix encoder handling sparse buffer
-- anv/bvh: Fix copy shader handling sparse buffer
-
-Konstantin (1):
-
-- nir/tests: Do not rely on __LINE__
-
-Konstantin Seurer (68):
-
-- nir: Stop using instructions for debug info
-- spirv: Handle NonSemantic.Shader.DebugInfo.100
-- nir: Add variable debug info to instructions
-- nir/lower_vars_to_ssa: Annotate defs with variable names
-- vulkan: Stop using strings for BVH build pipeline keys
-- vulkan/meta: Remove object types from vk_meta_object_key_type
-- vulkan/meta: Stop using strings for meta keys
-- hk: Stop using strings or common key types for meta keys
-- radv/meta: Stop using strings for meta keys
-- lavapipe: Fix maintainance7 descriptor set limits
-- vulkan/cmd_queue: Simplify freeing cmd_queue entries
-- vulkan/cmd_queue: Add VK_CMD_TYPE_COUNT
-- vulkan/radix_sort: Stop force-unrolling loops
-- gallivm: Remove loop limiting
-- lavapipe: Implement some functions required by the common BVH framework
-- lavapipe: Use the common BVH framework
-- radv: Optimize fs builtins using static gfx state
-- gallivm: Split nir prepasses into aos/soa
-- gallivm/nir/aos: Remove the dependency on lp_bld_nir.c
-- gallivm/nir/soa: Remove the dependency on lp_bld_nir.c
-- gallivm/nir/soa: Lower bools to i1
-- gallivm/nir/soa: Implement robusst uniform loads without controlflow
-- gallivm/nir/soa: Select more IO to gather/scatter intrinsics
-- lavapipe: Move nir passes to a new directory
-- lavapipe: Lower descriptor sets in NIR
-- lavapipe: Initialize the compiler options of the noop fs
-- llvmpipe: Do not use coroutines when they are unnecessary
-- nir: Rename in-bounds-agx to in-bounds
-- nir: Do not emit amul if it is unsupported
-- lavapipe: Optimize buffer robustness
-- gallivm/nir/soa: Do not lower vectors to llvm arrays
-- nir/divergence_analysis: Handle load_const_buf_base_addr_lvp
-- gallivm/nir/soa: Use divergence analysis
-- lavapipe: Lower push constants in NIR
-- gallivm: Only guard tex/image ops if the exec mask can be zero
-- gallivm/nir/soa: Skip bounds checking for in-bounds access
-- gallivm/nir/soa: Properly skip empty else branches
-- lavapipe: Remove uniform inlining
-- vulkan: Add utilities for triggering renderdoc captures
-- radv: Lower ray query vars to structs
-- radv: Implement multidimensional ray query arrays
-- llvmpipe: Skip draw_mesh if the ms did not write gl_Position
-- nir: Test nir_minimize_call_live_states
-- nir/sweep: Fix handling instructions with debug info
-- nir/print: Do not print debug information when gathering it
-- gallivm: Create a debug builder and add GALLIVM_DEBUG=symbols
-- llvmpipe: Annotate functions with debug information
-- gallivm: Handle nir_instr_debug_info
-- gallivm: Emit debug info for definitions
-- gallivm: Add a debug variable for the exec mask
-- gallivm: Run nir_lower_load_const_to_scalar
-- lavapipe: Enable debug information if GALLIVM_DEBUG=symbols is set
-- radv/meta: Change the return type of get_r32g32b32_format to VkFormat
-- ci: Do not build hk on alpine
-- asahi: Only require IOKit for tooling
-- hk: Fix building without the gallium driver
-- spirv: Emit code for NonSemantic.DebugPrintf if supported
-- nir: Turn the format string index into a const index
-- radv: Handle nir_intrinsic_printf
-- clc: Print errors when initializing clang fails
-- clc: Allow bitfields
-- clc,libcl: Clean up CL includes
-- radv: Fix rayTracingPositionFetch with multiple geometies
-- lavapipe: Prefetch 56 bytes of node data during ray traversal
-- lavapipe: Run nir optimizations on ray tracing pipelines
-- lavapipe: pre-load tmax
-- lavapipe: Do not emit aabb handling if no isec shader is used
-- radv: Return VK_ERROR_INCOMPATIBLE_DRIVER for unsupported devices
-
-Lakshman Chandu Kondreddy (1):
-
-- freedreno: Add support for Adreno623 GPU
-
-Lars-Ivar Hesselberg Simonsen (9):
-
-- panfrost: Do not evaluate_per_sample for non-MSAA
-- Revert "panfrost: remove is_blit flag"
-- Revert "panfrost: fix hang by using MALI_PIXEL_KILL_WEAK_EARLY in color preload"
-- panvk: Set missing shader_modifies_coverage flag
-- panfrost: Use RUN_COMPUTE over RUN_COMPUTE_INDIRECT
-- panvk: Use RUN_COMPUTE over RUN_COMPUTE_INDIRECT
-- vulkan/wsi/wayland: Avoid duplicate colorspace entry
-- panvk: Add barrier for interleaved ZS copy cmds
-- vk/sync: Fix execution only barriers
-
-Leder, Brendan Steve (1):
-
-- amd/vpelib: Reformat index variables and update enum
-
-Leonard GÃ¶hrs (2):
-
-- etnaviv/ci: add pengutronix LAVA lab with one i.MX8MP device
-- ci: re-enable pengutronix farm
-
-LingMan (2):
-
-- meson: Update pest subproject family
-- meson: Sync subproject version numbers in \`packagefiles` with their \`.wrap` equivalents
-
-Lionel Landwerlin (137):
-
-- anv: fixup missing compiler dependency on tests
-- intel: move internal shader compile to vtn_bindgen2
-- compiler: drop vtn_bindgen
-- intel_clc: remove NIR output support
-- spirv: remove spirv_library_to_nir_builder
-- brw: fixup scoreboarding for find_live_channels
-- anv: reuse helper for compute push constants
-- anv: increase general state pool
-- anv: track the first 2MB of unused VA
-- anv: use heap size to program generate state heap
-- anv: add a helper for getting gfx push constant addresses
-- brw/anv: rework push constants for mesh/task shaders
-- brw: enable A64 pulling of push constants
-- anv: use A64 messages for push constants loads on Gfx12.5+
-- nir: add a high precision conversion unorm->float
-- anv: add source hashes for BVH building shaders
-- vulkan/wsi: propagate protected swapchain to images
-- vulkan: allow support for protected surfaces
-- anv: support protected surfaces with display platform
-- anv,driconf: Add sampler coordinate precision workaround for Dynasty Warriors
-- genxml: make component packing an array
-- genxml: add convenience dwords for packing components
-- brw: fix indentation
-- brw: remove nr_attribute_slots from vs_prog_data
-- brw: port vs input to lower_64bit_to_32_new
-- brw: update vulkan max attribute limit
-- brw: add a max HW vertices attribute limit
-- brw: enable vertex fetching component packing
-- blorp: emit 3DSTATE_VF
-- anv: disable VF statistics for memcpy
-- anv: enable vertex fetching component packing
-- anv: ensure Wa_16012775297 interacts correctly with Wa_18020335297
-- brw: use meaningful io locations for system values
-- brw: add support for no VF input slot compaction
-- brw: add documentation about slot compaction & component packing
-- brw: fix component packing starting index
-- anv: move RT stage bits to main header
-- anv: move reg_mask push constant field to gfx
-- anv: hold a prepacked COMPUTE_WALKER instruction on CS pipelines
-- anv: make gfx state flushing available externally
-- anv: make compute state flush helper visible
-- runtime: sort push constant layouts
-- anv: avoid memory type changes with INTEL_DEBUG=noccs
-- anv/ci/adl: update fail expectation for video
-- anv: fixup compute walker storage length
-- nir: add options to lower only some image atomics to global
-- brw: factor out base prog_data setting
-- brw: store source_hash in prog_data
-- anv: switch to use brw's prog_data source_hash
-- isl: report tiling address swizzles
-- isl: add usage for software detiling
-- isl: centralize supported tilings in a single function
-- isl: select a tiling for shader detiling
-- isl: add support for R64 storage image lowering
-- isl: add a helper to report what dimensions a tiling supports
-- nir: track lowered image intrinsics to globals
-- brw: include UGM fence when TGM + lowered image->global
-- brw: add support for 64bit storage images load/store
-- brw: add support for texel address lowering
-- anv: rename compressed format emulation helpers
-- anv: add mapping for VBO formats in format mapping
-- anv: add a is_sparse for image format support checks
-- u_trace: pass tracepoint flags to the read_timestamp callback
-- intel/ds: rework RT tracepoints
-- anv: fix missing 3DSTATE_PS:Kernel0MaximumPolysperThread programming
-- brw: optimize load payload with immediate headers
-- brw: avoid setting up the sampler header bits when unused
-- spirv: fix racy build
-- vulkan/runtime: ensure robustness state is fully initialized
-- vulkan/runtime: pass robustness state to preprocess vfunc
-- vulkan/runtime: add a multialloc vk_shader allocator
-- vulkan/runtime: store flags on descriptor set layouts
-- anv/iris: centralize TBIMR drirc
-- iris: remove duplicate TessellationDistributionMode programming
-- anv/iris: add drirc keys to disable VF/TE distribution
-- anv/apply_layout: split binding table building into its own function
-- intel/genxml: add a genX RT include header
-- genxml: simplify genX_rt_pack.h
-- brw: make intel_shader_enums.h opencl importable
-- anv/brw: move INTEL_MSAA_* flag computation to the compiler
-- anv: break down Wa_16014912113 in need/apply parts
-- anv: fixup indentation around Wa_16014912113
-- brw: avoid calling lower_indirect_derefs multiple times
-- anv: fill runtime buffer device_address field
-- anv: move index buffer entry point out of genX code
-- anv: move vertex buffer storage to 64bit address + mocs
-- anv: move xfb buffer storage to 64bit address + mocs
-- anv: track protection on anv_address
-- anv: use addresses for buffer<->image copies
-- anv: simplify internal blorp helper
-- anv: fix non page aligned descriptor bindings on <Gfx12.0
-- lavapipe: fill buffer address
-- vulkan/runtime: rely on vk_buffer::device_address
-- brw: fix spilling for Xe2+
-- brw: ensure VUE header writes in HS/DS/GS stages
-- anv: Set limit_trig_input_range option for Company of Heroes 3
-- anv: avoid early lower of the fp64 code
-- blorp: assert that shaders don't spill
-- blorp: relax depth/stencil<->color copy restriction
-- vulkan: add helper for color/depth-stencil capable formats
-- anv: relax depth/stencil<->color copy restrictions
-- anv: fix end of pipe timestamp query writes
-- anv: disable replication when we don't have both VS/FS stages
-- brw: always write the VUE header
-- anv: limit implict write with drirc
-- nir: add support for lowering non uniform texture offsets
-- elk: stop using intel_nir_lower_texture
-- brw: don't lower tg4 offsets without LOD
-- intel: move lower_texture to brw
-- brw: move texture offset packing to NIR
-- anv: enable non uniform texture offset lowering
-- anv: wire VkAccessFlagBits3KHR flags in internal helpers
-- anv: expose VK_KHR_maintenance8 support
-- intel/genxml: remove ISA fields
-- intel/genxml: add more engine tagging on instructions
-- intel/genxml: fixup engine filtering
-- intel/genxml: define post-sync operations for MI_FLUSH_DW
-- intel/genxml: add MI_FLUSH_DW to blitter engine
-- anv/genxml: use special genX video pack files
-- anv/hasvk: consider timeline semaphore support stable
-- docs: remove unused env variable
-- anv/hasvk: sort out debug options
-- anv: consolidate environment variables
-- anv: add shader-hash debug option
-- brw: fix shuffle with scalar/uniform index
-- anv: relax restriction on variable count descriptors
-- anv: fix self dependency computation
-- brw: fix Wa_22013689345 emission
-- iris: update Wa_1607156449 to use WA infrastructure
-- anv: update Wa_1607156449 to use WA infrastructure
-- intel/dev: remove ADLN references
-- anv: remove ALWAYS_INLINE from globally visible functions
-- anv/iris: implement Wa_18040903259
-- anv: use companion batch for operations with HIZ/STC_CCS destination
-- anv: force fragment shader execution when occlusion queries are active
-- intel: fix null render target setup logic
-- brw: add pre ray trace intrinsic moves
-
-Lorenzo Rossi (8):
-
-- nvk: fix preprocess buffer alignment
-- nvk: Fix MSAA sparse residency lowering crash
-- nir: support shared atomics in nir_lower_atomics
-- nvk, nak: Implement shaderSharedInt64Atomics
-- nak: Fold bool-int-bool conversions
-- nak: Flatten AttrAccess into instructions
-- nak: Fix SM50 rounding-mode encoding edge-case
-- nak: Simplify shl64 lowering on Maxwell
-
-LoÃ¯c Minier (1):
-
-- freedreno: check if GPU supported in fd_pipe_new2
-
-LoÃ¯c Molinari (5):
-
-- perfetto: Let MESA_TRACE_FUNC() take printf-like format arguments
-- panfrost: Add CPU traces
-- pan/kmod: Add drmIoctl() wrapper pan_kmod_ioctl() with CPU trace
-- docs: Add Panfrost to the list of drivers with CPU traces
-- mesa: Add CPU traces
-
-Lucas Fryzek (4):
-
-- anv: Release correct bo for RT scratch
-- vulkan/runtime: Add object type to DMR API
-- anv: Implement VK_EXT_device_memory_report
-- anv: Expose VK_EXT_device_memory_report
-
-Lucas Stach (19):
-
-- etnaviv: drm: fix instruction limit for cores with instruction cache
-- etnaviv: drop double masking in etna_emit_load_state
-- etnaviv: split large multi-state updates into multiple batches
-- etnaviv: emit PS start and end PC states only on shader changes
-- etnaviv: correct and rename shader range register check
-- etnaviv: replace open-coded shifts in shader range registers with macros
-- etnaviv: place FS right behind VS in unified instruction memory
-- etnaviv: allow larger shaders with unified instruction memory
-- kmsro: look for graphics capable screen as renderonly device
-- etnaviv: rs: fix slow/fast clear transitions
-- etnaviv/ci: remove dEQP-GLES2.functional.polygon_offset.default_enable fail
-- etnaviv: fix ETNA_MESA_DEBUG=no_early_z
-- etnaviv: Update headers from rnndb
-- etnaviv: enable forwarding ZW fragcoord components from RA to SH
-- etnaviv/ci: remove fragcoord related fails on GC7000
-- etnaviv: use pipe_resource in etna_resource_status
-- etnaviv: split PIPE_BUFFER resources from other types of resources
-- include: update GL headers from the registry
-- etnaviv: add context flush sw query
-
-Ludvig Lindau (1):
-
-- panvk: Get flush_id once per submit
-
-Maaz Mombasawala (3):
-
-- svga: Add all tgsi double instructions for shader codegen checks
-- nir: Add option to preserve double immediates in tgsi shader.
-- svga: Check float type when emitting atomic instructions
-
-MaciejDziuban (3):
-
-- vulkan: handle use_default_scaling_matrix_mask in h264 decoder
-- vulkan: Add default scaling lists for H265
-- radv: Use vk_video_derive_h265_scaling_list
-
-Marek OlÅ¡Ã¡k (128):
-
-- amd: drop support for LLVM 15, 16, 17
-- ci/debian-ppc64el: don't build AMD drivers due to having only LLVM 15
-- gallium,st/mesa: allow reporting compile failures from create_vs/fs/.._state
-- nine: change the vtxbuf dirty mask to bool
-- nine: always update vertex buffers after updating vertex elements
-- nine: remove unused last_vtxbuf_count
-- nine: bind exactly the number of vertex buffers as vertex elements need
-- cso_context: add cso_get_vertex_elements_for_bind, letting the caller bind it
-- gallium/u_threaded,st/mesa: add a merged set_vertex_elements_and_buffers call
-- radeonsi: add assertion requiring binding vertex elements before vertex_buffers
-- radeonsi: require that count in set_vertex_buffers matches vertex elements state
-- radeonsi: don't set num_vertex_buffers and don't unbind in set_vertex_buffers
-- radeonsi: simplify bind_vertex_elements due to being before set_vertex_buffers
-- radeonsi: print why draws are rejected
-- util: remove glthread enablement from app profiles
-- mesa: don't build st_format_test on Windows
-- glapi: remove dead code
-- glapi: inline functions or use equivalent alternatives
-- glapi: don't export always-private functions
-- mesa: remove a glapi workaround for Mesa 10.5 and older
-- glapi: fix build dependencies by putting all xml/py files into a single list
-- glapi: remove support for dynamically-registered functions
-- glapi: use an assertion in SET_by_offset instead of doing nothing
-- glapi: clarify the meaning of static_data.functions
-- glapi: remove check_table tests
-- glapi: generate static offsets from the list of GL functions automatically
-- glapi: remove unused functions from dispatch tables
-- glapi: move legacy imaging functions to the end of dispatch tables
-- glapi: verify that aliased functions don't have entries in dispatch tables
-- glapi: just use _gloffset_COUNT_ everywhere, which is always the function count
-- glthread: handle glFlush with HasExternallySharedImages more efficiently
-- glthread: rename scripts to match the names of generated files
-- glapi: disable python escape sequences in strings that use invalid ones
-- glapi: use static_data.libgl_public_functions directly
-- glapi: remove is_static_entry_point wrapper
-- glapi: inline entry_current_get()
-- glx: don't call GL functions directly, use the current dispatch instead
-- glx: fix hardcoded use of dispatch table index in glAreTexturesResidentEXT
-- glx: stop exporting GL functions from libGLX_mesa.so
-- glx: make it more obvious what libglapi_bridge is
-- glapi: remove unused python code
-- mesa: allocate GLmatrix aligned to 16 bytes
-- Remove osmesa
-- gallium/u_blitter: remove UTIL_BLITTER_ATTRIB_COLOR, use a constant buffer
-- gallium/u_blitter: change blitter_attrib from union to struct
-- meson: never use static glapi because shared glapi is also static and better
-- glx/xlib: switch glapi from static to shared (which is also static)
-- meson: remove with_shared_glapi variable (it's always true)
-- glapi: remove static glapi (it's dead code now)
-- glapi: remove duplicated generated header glapitable.h
-- glx: fix build with -Dlegacy-x11=dri2
-- egl: use the current dispatch to execute glFlush instead of get_proc_address
-- glapi: remove extension definitions that will likely never be implemented
-- ac/gpu_info: use max_good_cu_per_sa for computation of max_scratch_waves
-- ac,radeonsi: don't set num_slots/src/dest_type/write_mask when they're set automatically
-- Revert "ac/nir: clamp vertex color outputs in the right place"
-- ac/nir/cull: extract a helper calling accept_func
-- ac/nir/ngg: add an option to skip viewport-based culling
-- ac/cmdbuf: split meta_*_policy to dcc and htile variables
-- ac/cmdbuf: rework CB/DB cache controls for better perf
-- winsys/amdgpu: don't use 32-bit address space for IBs
-- radeonsi: use si_is_buffer_idle everywhere
-- radeonsi: move buffer reallocation to a separate function
-- radeonsi: enable NGG culling when the shader writes the viewport index
-- radeonsi: enable Z/S caching in GL2 by default except FurMark
-- radeonsi: use the restrict keyword for draw parameters
-- radeonsi: lower IO only if io_lowered == false
-- radeonsi: reflect blitter VS in si_context::num_vertex_elements
-- radeonsi: don't cull front/back faces in the hw if the shader culls them
-- ac,radeonsi: define all SDMA DCC fields & use them, enable compressed writes
-- radeonsi: remove clover support
-- glx: don't generate indirect GLX dispatch for ARB_imaging functions
-- glapi: make a separate copy of entry.c for each lib
-- glapi: replace mapi_func type with identical _glapi_proc
-- glapi: simplify codegen macros
-- glapi: merge all shared-glapi source files into one .c file
-- glapi: remove unused _mesa_glapi_Dispatch
-- glx: add a test to verify exported symbols
-- glapi: get the list of public GL functions from libgl-symbols.txt
-- glx: remove the hack that forced exporting GL functions from libGL
-- glapi: remove the GLAPI_PREFIX macro, just use gl as the function prefix
-- glapi: simplify headers of generated files
-- glapi: simplify mapi_abi.py
-- glapi: rename dispatch stubs to use function names instead of numbers
-- glapi: remove noop_generic callbacks
-- glapi: remove the option to set the nop handler
-- mesa: move dispatch.h and marshal_generated.h generation to glapi/gen
-- mesa: inline main/meson.build
-- glx: stop exporting EXT_texture_object functions from libGLX_mesa.so
-- glapi: fix x86 32-bit asm dispatch regression
-- amd: update addrlib
-- amd/addrlib: remove the DCC page fault workaround
-- ac/nir/cull: cull small prims using a point-triangle intersection test
-- glsl: return failure from gl_nir_validate_first_and_last_interface_explicit_locations
-- glsl: return failure from varying_matches_assign_locations
-- glsl: return failure from remove_unused_io_vars
-- glsl: stop calling nir_opt_combine_stores (redundant with nir_opt_vectorize_io)
-- glsl: remove a deprecated comment about nir_compact_varyings
-- glsl: always return true at the end of link_varyings
-- glsl: move code after link_varyings into link_varyings
-- st/mesa: don't do nir_remove_dead_variables on in/out twice
-- nir/opt_algebraic: lower 16-bit imul_high & umul_high
-- ac: define physical VGPRs for fake hw overrides
-- ac/nir/cull: rename skip_viewport_culling -> skip_viewport_state_culling
-- ac/nir/cull: always do frustum culling, skip only small prim culling
-- ac/surface: remove 64K_2D modifier with 64B max compressed blocks for gfx12
-- radeonsi: work around a primitive restart bug on gfx10-10.3
-- radeonsi: always use ACO callbacks to scalarize/vectorize 16-bit ALU
-- radeonsi: expose 16-bit NIR types for ALU, MEM, and LDS (no inputs/outputs)
-- radeonsi/ci: update gfx11 failures
-- radeonsi/ci: don't run GTF tests (they have been removed from glcts)
-- radeonsi: lower load/store bit sizes before load/store vectorization
-- radeonsi: add a VOP3P swizzle requirement for 16-bit packed math
-- radeonsi/ci: add gfx12 failures and flakes
-- radeonsi: make si_shader_selector::main_shader_part_* an iterable union
-- radeonsi: add ACO-specific main shader parts
-- winsys/amdgpu: don't add VM_ALWAYS_VALID buffers into the BO list
-- radeonsi: determine VM_ALWAYS_VALID accurately
-- ac/gpu_info: increase the attribute ring size for gfx12
-- ac/gpu_info: remove has_tmz_support function
-- ac/gpu_info: add payload_entry_size into ac_task_info
-- ac/gpu_info: add 256 to payload_entry_size to increase future task shader perf
-- ac/nir: set X=0 for task->mesh shader dispatch when Y or Z is 0
-- ac/surface: make gfx12_estimate_size reusable by gfx6
-- ac/surface: select 3D tile mode without overallocating too much for gfx6-8
-- radeonsi: always scalarize shared memory instructions
-- radeonsi: use nir_opt_shrink_vectors
-- radv: fix incorrect patch_outputs_read for TCS with dynamic state
-
-Mark Collins (4):
-
-- tu/kgsl: Remove zero CB queue submission fast path
-- tu/kgsl: Revert "Remove zero CB queue submission fast path"
-- tu/kgsl: Fix KGSL syncobj lifetime in no CB submit
-- ir3/a7xx: Add post-RA pass to track liveness and insert (last)
-
-Martin Krastev (7):
-
-- svga/ci: disable vmware farm
-- svga/ci: enable vmware farm
-- svga/ci: enable vmware farm
-- svga/ci: enable vmware farm
-- svga/ci: update EXTERNAL_KERNEL_TAG to new kernel
-- svga/ci: disable vmware farm
-- docs/svga: Add steps how to get VMware Workstation Pro on Linux
-
-Martin Roukala (nÃ© Peres) (42):
-
-- ci: fix the artifact name
-- ci: be explicit about the fact HW jobs do not need linter artifacts
-- ci/test/b2c: do not download the debian/\*_test-(gl|vk) artifacts
-- ci-templates: update to the latest upstream version
-- ci/build-deqp: delegate the deqp main commit check to github
-- ci/test: add arm32 b2c jobs
-- ci/debian/test-vk: remove software-properties-common
-- ci/debian/test-vk: trim down the container on a per-arch basis
-- ci/image-tags: bump the debian base tag
-- ci/b2c: add support for diskless DUTs
-- ci/b2c: de-duplicate the download of install.tar
-- etnaviv/ci: convert from baremetal to CI-Tron
-- ci: re-enable austriancoder's farm
-- zink/ci: use the debian-built-testing for nvk
-- zink/ci: update the radv expectations
-- radv/ci: bump tahiti's cpu cores
-- radv/ci: update expectations
-- freedreno/ci: update expectations
-- ci/b2c: fix the S3 artifact for amd64 manual vk/gl
-- radv/ci: document more Tahiti VKCTS flakes
-- turnip/ci: re-introduce the \`multiviewport` flakes
-- zink/ci: mark query-rgba-signed-components as fixed on more platforms
-- zink/ci: document more RADV flakes
-- radv/ci: add testing on RAPHAEL
-- radv/ci: reduce Renoir concurrency in vkcts
-- radv/ci: set a tight timeout on vkcts-navi31
-- radv/ci: document more flakes
-- zink/ci: document more radv flakes
-- zink/ci: document more GA106 flakes
-- zink/ci: increase the a750 job's timeout to 18 minutes
-- radv/ci: mark a whole subset of tests as flaky on tahiti
-- zink/ci: document more RADV flakes
-- zink/ci: document more NVK GA106 flakes
-- ci/b2c: allow jobs to opt-in into the new mars setup command
-- radv/ci: opt-in the new mars setup command
-- etnaviv/ci: opt-in the new mars setup command
-- nvk/ci: opt-in the new mars setup command
-- freedreno/ci: opt-in the new mars setup command
-- i915g/ci: opt-in the new mars setup command
-- r300g/ci: opt-in the new mars setup command
-- radv/ci: reduce the timeout of vkcts-tahiti to a more sensible time
-- radv/ci: add hawaii to CI
-
-Mary Guillemard (95):
-
-- panfrost: Fix group priorities in drm-shim
-- panfrost: Fix PROGRESS_LOAD destination register
-- pan/bi: Properly encode LEA_BUF_IMM
-- pan/bi: Remove shift lanes invalid encodings
-- pan/bi: Fix invalid CLPER encoding
-- pan/bi: Remove b3210 from valid swizzle
-- pan/bi: Use 2D dimension with TEX_FETCH with CUBE on Valhall
-- pan/decode: Fix indirect branch calculation for 64-bit
-- panfrost: Properly name CSF instruction UMIN32 source 0
-- panvk: Disallow unknown GPU models early in physical device init
-- pan/genxml: Stop using "constant" for struct fields in xml defs
-- pan/genxml: Rework gen_pack.py to support OpenCL
-- panfrost: Add base of OpenCL C infrastructure
-- bi: Optimize scratch access
-- panvk: Integrate libpan
-- panfrost: Integrate libpan in gallium driver
-- panvk: Add create_shader_from_binary
-- panvk: Move TLS preparation logic to cmd_dispatch_prepare_tls
-- panvk: Expose calculate_task_axis_and_increment on CSF
-- panvk: Implement precomp dispatch
-- panfrost: Implement precomp dispatch on Gallium
-- panfrost,panvk: Wire printf and abort support
-- ci: Transition to precomp-compiler
-- ci: Enable mesa-clc and precomp-compiler on debian-arm32
-- pan/bi: Fix scratch access optimization
-- panvk: Switch JM copy queries to CLC
-- panvk: Switch JM clear queries to CLC
-- pan/bi: Document removed instructions on v11
-- pan/bi: Do not run bi_fuse_small_int_to_f32 on v11+
-- pan/bi: Disallow dst swizzle optimization in case of conversion
-- pan/bi: Add round mode modifier to FADD
-- pan/bi: Stop using V2F32_TO_V2F16 on Valhall
-- pan/bi: Lower SWZ.v4i8 to multiple MKVEC.v2i8 on v11+
-- pan/bi: Stop using S16_TO_F32 in nir_texop_lod computation on v11+
-- pan/bi: Stop using V2F16_TO_V2S16 for barycentric_at_offset on v11+
-- pan/bi: Lower removed instructions in algebraic on v11+
-- pan/bi: Lower FROUND.v2s16 in nir_lower_bit_size on v11+
-- pan/bi: Lower hadd on v11+
-- pan/bi: Handle LD_VAR_BUF_IMM encoding changes on v11+
-- pan/bi: Properly extract primitive facing on v11+
-- pan/genxml: Define RUN_IDVS staging registers in an enum
-- panfrost: Remove write to TSD_3 in Gallium driver
-- pan/genxml: Define RUN_COMPUTE staging registers in an enum
-- pan/genxml: Define RUN_FRAGMENT staging registers in an enum
-- panfrost: Rework cs_sr_regXX to be a macro
-- panfrost: Switch Gallium driver to use cs_sr_regXX
-- panfrost: Use CSIF info for CSF registers count
-- panfrost: Avoid hard crash when major arch is unknown
-- panfrost: Rename CSF MOVE into MOVE48
-- panfrost: Fix FLUSH_CACHE2 other definition
-- panfrost: Rename CS ADD_IMMEDIATEXX to ADD_IMMXX
-- pan/genxml: Use DCD Flags in Draw struct on v9+
-- pan/bi: Disallow FAU special page 3 and WARP_ID on message instructions
-- pan/bi: Add unit tests for FAU special page 3 and WARP_ID
-- pan/bi: Run nir_lower_bit_size after algebraic
-- pan/bi: Run bifrost_nir_lower_algebraic_late while there is progress
-- pan/bi: Lower FREXPE.v2f16 and FREXPM.v2f16 on v11+
-- pan/bi: Fix out of range access in bi_instr_replicates
-- pan/bi: Ensure we select b0 with halfswizzle in va_lower_constants
-- nir: Add Panfrost specific shader_output intrinsic
-- pan/bi: Use shader_output intrinsic for IDVS
-- pan/bi: Add support for IDVS2 on Avalon
-- pan/bi: Lower IADD.v4s8 in algebraic on v11+
-- pan/bi: Allow no_psiz variant with IDVS2
-- pan/genxml: Rename UMIN32 opcode to COMPARE_SELECT32
-- pan/genxml: Add v12 definition
-- pan/genxml: Add v13 definition
-- pan/genxml: Build libpanfrost_decode for v12
-- pan/genxml: Build libpanfrost_decode for v13
-- pan/lib: Build for v12
-- pan/lib: Build for v13
-- pan/clc: Build for v12
-- pan/clc: Build for v13
-- panvk: Support 64x64 meta tile size for v12 in cmd_preload_render_area_border
-- pan/lib: Adapt CRC calculation to align to 64x64 on v12+
-- panfrost: Disable hierarchy levels based on multiple of tile_size
-- panvk: Use spd variant instead of pos_points when checking for vs shader presence
-- pan/earlyzs: Default to FORCE_EARLY for ZS update on v11+
-- panvk: Implement Z/S dependency tracking on v11+
-- panvk: Add v12 support
-- panvk: Add v13 support
-- panfrost: Add v12 support to the Gallium driver
-- panfrost: Add v13 support to the Gallium driver
-- panfrost/ci: Add Mali-G720 current expectations
-- panfrost/ci: Add Mali-G725 current expectations
-- panfrost: Advertize Mali-G720 support
-- panfrost: Advertize Mali-G725 support
-- panfrost: Update the release note to mention G720/G725 addition
-- panvk: Fix inverted ZS read flags in DCD2 on v11+
-- panfrost: Take tiler memory budget into account in pan_select_tiler_hierarchy_mask
-- panvk: reset dyn_bufs map count to 0 in create_copy_table
-- panvk: Take rasterization sample into account in indirect draw on v10+
-- panvk: Take resource index in valhall_lower_get_ssbo_size
-- pan/bi: Properly lower add/sub with saturation on v11+
-- pan/genxml: Fix inverted logic on nr_regs
-
-Matt Turner (22):
-
-- gallium: Fix typos
-- glsl: Fix typos
-- glx: Fix typos
-- intel: Fix typos
-- mapi: Fix typos
-- vulkan: Fix typos
-- gallium: Return NULL, not false, from functions returning pointers
-- nir: Return NULL, not false, from functions returning pointers
-- iris: Initialize pointer with NULL, not false
-- intel/compiler: Use FALLTHROUGH
-- glsl: Use FALLTHROUGH
-- glsl: Add missing break
-- intel/compiler: Use unreachable instead of assert(!"...")
-- intel/isl: Use unreachable instead of assert(!"...")
-- anv: Use unreachable instead of assert(!"...")
-- hasvk: Use unreachable instead of assert(!"...")
-- intel/decoder: Remove assert(!"...") in recoverable condition
-- intel/compiler: Add missing breaks
-- intel/compiler: Use correct enum type
-- iris: Remove ignored qualifier
-- intel/isl: Remove ignored qualifier
-- anv: Remove ignored qualifier
-
-MaÃ­ra Canal (4):
-
-- v3dv: VK_EXT_acquire_drm_display doesn't require a DRM master fd
-- v3dv: don't overwrite the primary fd if it's already set
-- broadcom/simulator: Expose V3D revision number in the simulator interface
-- broadcom/simulator: Fix Indirect CSD jobs for V3D 7.1.6+
-
-Mel Henning (31):
-
-- nvk: Use hw support for instancing on PASCAL_B+
-- nak/opt_copy_prop: Fix IAdd3 overflow check
-- nak/opt_copy_prop: Add force_alu_src_type
-- nak/opt_copy_prop: Force alu src for IAdd2X/IAdd3X
-- driconf: force_vk_vendor on Deep Rock Galactic+NVK
-- nak: Add OpLea
-- nak,nir: Add 32-bit nir_op_lea_nv and use it
-- nak: Add OpLeaX
-- nak,nir: Add 64-bit lea_nv
-- nouveau/mme: Print ip in mme_tu104_dump
-- nak: Add static cycle count statistic
-- nak: Add an occupancy statistic
-- nak/spill_values: Make Spill take &mut self
-- nak: Add spill/fill statistics
-- nvk: Don't zero imported memory
-- nvk: Add NVK_DEBUG=trash_memory
-- vulkan: Relax bda assert for zero-size buffers
-- nak: Add a simple postpass instruction scheduler
-- nak: Calc static cycle count in instr_sched
-- nak: Assert instr_sched matches calc_instr_deps
-- nak/instr_sched: Barriers activate after 2 cycles
-- nvk: SET_PS_{REGISTER,WARP}_WATERMARKS
-- nvk: Support blackwell in max_warps_per_mp_for_sm
-- nak/spill_values: Spill constants across edges if needed
-- nak: Handle idp4 ureg latencies
-- nvk: SET_STATISTICS_COUNTER at start of meta_begin
-- nvk: Override render enable for blits and resolves
-- wsi/headless: Override finish_create
-- nak: Remove hfma2 src 1 modifiers
-- nak: Add Src::is_unmodified() helper
-- nak: Check that swizzles are none
-
-Mi, Yanfeng (2):
-
-- anv: Support putting image base address and image params in surface state
-- anv: add emulated 64bit integer storage support
-
-Michael Cheng (5):
-
-- anv: Fix missing Perfetto trace for as build
-- Revert "anv: Fix missing Perfetto trace for as build"
-- vulkan : Pass in number of tlas/blas being built
-- anv: Change as_build to show num tlas/blas
-- vulkan: add leaves and ir_leaves sizes to encode for utrace.
-
-Michel DÃ¤nzer (1):
-
-- egl/glx/sw: Check xcb_query_extension_reply return value for MIT-SHM
-
-Mike Blumenkrantz (97):
-
-- zink: emit SpvCapabilityDemoteToHelperInvocation for IsHelperInvocation
-- zink: implement ops for KHR_shader_subgroup
-- aux/trace: trace tex2d_from_buf for samplers/images
-- gallium: add a pipe_tex2d_from_buf struct
-- rusticl: stop clearing shader images after every dispatch
-- zink: also refcount needs_present from frontbuffer flush
-- zink: delete some old DGC remnants
-- zink: guard rebar check against fallback heap detection
-- ac/surface: always allow LINEAR modifier for color formats
-- radv: fix error reporting for VkExternalMemoryTypeFlagBitsKHR
-- radv: stop blocking non-2D import/export ops
-- radv: print stringname for VkExternalMemoryHandleTypeFlagBits error
-- driconf: move a glthread viewperf option to global
-- driconf: add GL_EXT_shader_image_load_store for viewperf to fix crashing
-- zink: only enable unsynchronized_texture_subdata with HIC
-- zink: never try to oom flush during unsync texture upload
-- zink: apply layer/depth to clear handling
-- zink: wait on tc fence before checking for fd semaphore
-- zink: handle buffer import/export
-- zink: verify that adding a dmabuf bind actually chooses a modifier
-- zink: support cl_gl_sharing if dmabuf is supported
-- egl/x11: delete some dri2 remnants
-- zink: force cached mem for streaming uploads
-- zink: always fully unwrap contexts
-- zink: use a separate ralloc ctx for zink_program objects
-- zink: put zink_program::reference on separate cacheline
-- dri: delete INVALIDATE extension
-- zink: enable single-plane modifiers for generic 2D exports
-- zink: clamp UBO sizes instead of asserting
-- anv: support all dimensions of image for LINEAR dmabufs
-- aux/trace: truncate descriptor unbinds
-- zink: always check submit_count to disambiguate when checking/waiting
-- zink: don't reset all batch states when stalling
-- zink: alloc bo ids for non-slab bos too
-- zink: explicitly check usage in buffer barriers
-- svga/ci: disable vmware farm
-- llvmpipe: pass layer count to rast clear
-- gallium: fix pipe_framebuffer_state::view_mask
-- mesa: add error handling for OVR_multiview
-- mesa: avoid creating incomplete surfaces when multiview goes out of range
-- zink: improve precision on changes to depth bias between draws
-- zink: delete zink_batch_state::ref_lock
-- zink: split set_vertex_buffers to avoid conditionals
-- zink: start using ctx->vertex_state_changed again
-- zink: use VKCTX for vertex buffer binds and delete unused screen local
-- zink: only add fb surf refs on unbind
-- radv: rewrite radv_get_line_mode() conditional
-- radv: store num_attributes to shader info
-- radv: store vertex prolog simple input check to cmdbuf on vs bind
-- radv: roll line topology dynamic state changes into existing rast samples flag
-- radv: eliminate a memset in radv_get_vbo_info()
-- radv: inline some vertex descriptor functions
-- radv: split out dynamic vertex input descriptor writing
-- radv: move non_trivial_format calc to dynamic VI bind
-- radv: get vbo info directly into dgc upload
-- radv: don't unnecessarily flag prolog recalc when binding VBOs
-- zink: disable reordering on compute contexts
-- zink: extract some shader image resource binding code
-- zink: extract some samplerview bind/unbind code
-- zink: support crazy CL buffer-to-texture extension
-- st/drawpixels: move sv unref out to callers
-- gallium: eliminate frontend refcounting from samplerviews
-- gallium: make pipe_sampler_view::reference non-atomic
-- mesa: remove st_sampler_view::private_refcount
-- aux/trace: set sampler_view_release pointer
-- gallium: delete tests
-- util/tests: move u_half_test into half_float_test
-- gallium: delete u_cache
-- meson: add i915 to 'all' build for gallium-drivers
-- egl/x11: always expose EXT_swap_buffers_with_damage
-- egl: delete invalidate_available flag
-- egl: move _EGLDisplay DriverData association into dri2_display_create
-- egl: hoist dri2 display creation up a level
-- egl/x11: split out dri2 init entirely
-- egl: move kopper detection to display creation
-- egl/x11: hoist up dri2_get_xcb_connection call
-- egl/x11: simplify a kopper check on init
-- egl/x11: hoist up swrast/zink driver_name setting
-- egl/x11: hoist and document dri3_x11_connect() during init
-- egl: delete dri2_egl_driver_fail
-- egl/x11: consolidate LIBGL_DRI3_DISABLE use on init
-- egl/x11: unify swrast/kopper/dri3 paths a bit
-- gallium: delete pipe_surface::width and pipe_surface::height
-- zink: fix refcounting of zink_surface objects
-- zink: block streaming cached uploads on unsynchronized/persistent maps
-- zink: implement unsynchronized staging uploads for buffers
-- zink: block inferred loading for swrast
-- gallium/util: check nr_samples in pipe_surface_equal()
-- tu: check for valid descriptor set when binding descriptors
-- meson: deprecate gallium-nine
-- meson: deprecate gallium-xa
-- zink: don't set shared block stride without KHR_workgroup_memory_explicit_layout
-- zink: stop setting ArrayStride on image arrays
-- zink: use implicit stride in ntv for temp vars
-- ci: update VVL to current week
-- zink: verify that surface exists when adding implicit feedback loop
-- egl: fix sw fallback rejection in non-sw EGL_PLATFORM=device
-
-Mohamed Ahmed (7):
-
-- nvk: Add NVK_MAX_IMAGE_PLANES for images
-- nvk: Add NVK_MAX_SAMPLER_PLANES for samplers
-- nil: Use multiplanar init_info during image creation
-- nil: Force smallest block size for images meant for Vulkan Video
-- nvk: Set NIL_IMAGE_USAGE_VIDEO_BIT for images meant for video usage
-- nil: Add an API to clamp max image alignment
-- nvk: Implement VK_MESA_image_alignment_control
-
-Mykhailo Skorokhodov (1):
-
-- drirc/anv: force_vk_vendor=-1 for Drive Beyond Horizons
-
-Natalie Vock (30):
-
-- vulkan/bvh: Move leaf builder code to header
-- vulkan/bvh: Add option to override leaf builder SPIR-Vs
-- vulkan/bvh: Add optional fine-grained instance node bounds calculation
-- radv/bvh, vulkan/bvh: Move AccelerationStructureInstance to vk_build_helpers
-- radv/bvh: Remove unused build_instance helper
-- radv/bvh: Prefix RADV-specific node functions with radv\_
-- radv/bvh: Add custom leaf node builder
-- mailmap: Update my name
-- radv/rt: Don't allocate the traversal shader in a capture/replay range
-- aco/ra: Use iterators for linear VGPR copy extraction
-- aco/ra: Use struct for parallelcopies
-- aco/ra: Add option to skip renaming for parallelcopies
-- aco/ra: Handle temps fixed to different regs in different operands
-- aco/tests: Add tests for precolored operands in different regs
-- aco/ra: Assert operands only clear their own id
-- radv/rt: Limit monolithic pipelines to 50 stages
-- radv/rt: Guard leaf encoding by leaf node count
-- radv/rt: Flush L2 after writing internal node offset on GFX12
-- ac/llvm: Don't use getTriple() on LLVM21+
-- aco: Add get_temp_reg_changes helper
-- aco/spill: Invert reloads map
-- aco: Add RegisterDemand(Temp) constructor
-- aco/spill: Allow spilling live-through operands
-- radv/rt: Flush CP writes from the common BVH framework with INV_L2 on GFX12
-- vulkan/bvh: Move first PLOC task_count fetch inside PHASE
-- aco: Fix RT VGPR limit on Navi31/32, GFX11.5, GFX12
-- aco: Make private_segment_buffer/scratch_offset per-resume
-- radv: Add radv_emulate_rt drirc and enable for Indiana Jones TGC
-- radv: Add radv_enable_float16_gfx8 drirc and enable for Indiana Jones TGC
-- radv/ci: Test FP16 for GFX8
-
-Nikita Popov (2):
-
-- clover: Don't include libclc headers
-- clover: Fix MSVC build
-
-Nikolas Zimmermann (1):
-
-- etnaviv: drm: Add DRM_RDWR permissions to drmPrimeHandleToFD() call.
-
-Olivia Lee (1):
-
-- panfrost: allow promoting sysval UBO to push constants
-
-Patrick Lerda (27):
-
-- r600: fix r600_init_shader_caps() has_atomics issue
-- r600: fix evergreen_emit_vertex_buffers() related cl regression
-- r600: fix cayman sfn_nir_legalize_image_load_store ssa dominance
-- r600: prepare the lds constant buffer to be shared
-- r600: implement a conformant gl_VertexID with base offset
-- r600: fix the indirect draw 8-bits path
-- r600: fix emit_image_size() range base compatibility
-- r600: update evergreen_convert_border_color()
-- r600: update cayman_convert_border_color()
-- r600: fix cayman main non-deterministic behavior problem
-- r600: update the software fp64 support
-- radeonsi: fix clear_depth_stencil refcnt imbalance
-- r600: move stores to the end of shader when required
-- r600: fix clear_depth_stencil refcnt imbalance
-- r600: fix textures with swizzles limited to zero and one
-- r600: implement EXT_window_rectangles
-- r600: remove deprecated NIR_PASS_V
-- r600: fallback to util_blitter_draw_rectangle when required
-- r600: fix pa_su_vtx_cntl rounding mode
-- r600: fix points clipping
-- r600: enable ARB_compute_variable_group_size
-- r600: clean up not used fields detected by clang
-- i915: fix i915_set_vertex_buffers() related refcnt imbalance and remove redundancies
-- i915: fix slab_create() related memory leaks
-- i915: fix nir_to_tgsi() related memory leak
-- i915: fix draw_create_fragment_shader() related memory leak
-- mesa_interface: fix legacy dri2 compatibility
-
-Patrick Nicolas (1):
-
-- radv/video: Add low latency encoding
-
-Paul Gofman (1):
-
-- radv/amdgpu: Fix hash key in radv_amdgpu_winsys_destroy().
-
-Paulo Zanoni (10):
-
-- brw: increase brw_reg::subnr size to 6 bits
-- brw: don't always set cond_modifier on parsed assembly instructions
-- brw: don't mark instructions read from text assembly as compacted
-- brw: add instructions missing from is_control_flow()
-- brw: extend the NOP+WHILE workaround
-- drirc/anv: DiggingGame.exe needs force_vk_vendor=-1
-- intel/i915: restrict the RAM size restrictions to Anv
-- anv/xe: detect the newer xe.ko memory reporting model and act accordingly
-- anv: restore the old behavior of up to 75% of RAM for the system heap
-- anv: add ANV_SYS_MEM_LIMIT for debugging system memory restrictions
-
-Pavel OndraÄka (22):
-
-- i915/ci: use debian-build-testing instead of debian-testing
-- r300: remove some dead code in redeon_program_alu
-- r300: do not limit maximum TEX group for R300/R400
-- r300: copy propagate constant swizzles
-- ci: fix debian-build-testing BUILDTYPE
-- ci: disable LTO for nightly debian-build-testing
-- i915/ci: update expectations
-- i915: rework shader compile failures reporting
-- mesa: properly signal report_compile_error to drivers
-- nine: set pipe_shader_state.report_compile_errors
-- r300: stop reporting compile failures in finalize_nir
-- r300: forward all compile failures to state tracker
-- r300: do not include newline in the error messages
-- r300,i915: update CI expectations
-- r300: fix temps counting for shader-db stats
-- r300/ci: add dEQP job with RADEON_DEBUG=notcl
-- r300: remove usage of NIR_PASS_V
-- r300: fix INV and BIAS presubtract on R300/R400
-- r300: remove finalize_nir
-- r300: remove support for tgsi_texcoord
-- r300: fix crash when creating surfaces
-- r300/ci: update expectations
-
-Peyton Lee (6):
-
-- radeonsi/vpe: check reduction ratio
-- radeonsi/vpe: support geometric scaling
-- amd/gmlib: add gmlib for radeonsi
-- radeonsi/vpe: vpe support tonemapping
-- radeonsi/vpe: vpe support hdr input
-- radeonsi/vpe: fix background issue
-
-Philipp Zabel (3):
-
-- etnaviv/ml: Drop duplicated function reorder_for_hw_depthwise()
-- etnaviv/ml: Fix padding input/output tensor zero points
-- teflon: Log (un)supported operations
-
-Pierre-Eric Pelloux-Prayer (16):
-
-- radeonsi: update si_need_gfx_cs_space upper bound
-- winsys/amdgpu: treat cs overflow as context lost
-- radeonsi: disable dcc when external shader stores are used
-- tc: add missing TC_SENTINEL for TC_END_BATCH
-- mesa/st: call _mesa_glthread_finish before _mesa_make_current
-- tc: flag closed batches
-- st/mesa: fix nir_load_per_vertex_input parameter
-- radeonsi: cache u_trace_perfetto_active value
-- radeonsi: tag perfetto conditions as unlikely
-- radeonsi: add pid/tid to the vk_queue_submit event
-- radeonsi: guard perfetto support with ifdef in si_draw
-- ac/nir: fix nir_metadata value of ac_nir_lower_image_opcodes
-- radeonsi/video: require has_image_opcodes for full modifier support
-- radeonsi: use composed swizzle in cdna_emu_make_image_descriptor
-- winsys/amdgpu: disable VM_ALWAYS_VALID
-- radeonsi: fix potential use after free in si_set_debug_callback
-
-Pohsiang (John) Hsu (7):
-
-- d3d12: fix incorrect IsRefUsedByCurrentPic marking for P Frame
-- d3d12: log all the field of dpb buffer for better diagnostic, cosmetic space removal
-- d3d12: initialize ReconstructedPicTexture
-- d3d12: fix start code prevention in write_sei_nalu()
-- d3d12: fix d3d12_video_nalu_writer_h264::write_slice_svc_prefix
-- d3d12: use log2_max_pic_order_cnt_lsb_minus from upper layer
-- d3d12: use log2_max_pic_order_cnt_lsb_minus4 from upper layer for h264
-
-Qiang Yu (78):
-
-- lavapipe: fix min_vertex_pipeline_param
-- gallium: fix ddebug and noop screen caps init
-- gallium,clover: add compute caps used by clover only
-- r600: init compute caps without ir_type param
-- radeonsi: init compute caps without ir_type param
-- gallium,mesa: remove ir_type param when get_compute_param
-- gallium: add pipe_shader_caps and pipe_compute_caps
-- gallium: copy shader and compute caps for ddebug/noop/trace
-- tgsi: add tgsi_exec_init_shader_caps
-- gallivm: add gallivm_init_shader_caps
-- draw: add draw_init_shader_caps
-- agx: init shader and compute caps
-- crocus: init shader and compute caps
-- d3d12: init shader and compute caps
-- etnaviv: init shader caps
-- freedreno: init shader and compute caps
-- i915: init shader caps
-- iris: init shader and compute caps
-- lima: init shader caps
-- llvmpipe: init shader and compute caps
-- nouveau/nv30: init shader caps
-- nouveau/nv50: init shader and compute caps
-- nouveau/nvc0: init shader and compute caps
-- panfrost: init shader and compute caps
-- r300: init shader caps
-- r600: init shader and compute caps
-- radeonsi: init shader and compute caps
-- softpipe: init shader and compute caps
-- svga: init shader and compute caps
-- tegra: init shader and compute caps
-- v3d: init shader and compute caps
-- vc4: init shader caps
-- virgl: init shader and compute caps
-- zink: init shader and compute caps
-- nine: GET_SHADER_CAP use pipe_shader_caps
-- lavapipe: change min shader param to use pipe_shader_caps
-- gallium,mesa: replace get_shader_param with pipe_shader_caps access
-- clover: replace get_compute_param with pipe_compute_caps
-- gallium,mesa: replace get_compute_param with pipe_compute_caps
-- rusticl: replace get_shader_param with pipe_shader_caps
-- rusticl: replace get_compute_param with pipe_compute_caps
-- asahi: remove shader and compute get param
-- crocus: remove shader and compute get param
-- d3d12: remove shader and compute get param
-- etnaviv: remove shader get param
-- freedreno: remove shader and compute get param
-- i915: remove shader get param
-- iris: remove shader and compute get param
-- lima: remove shader get param
-- llvmpipe: remove shader and compute get param
-- nouveau/nv30: remove shader get param
-- nouveau/nv50: remove shader and compute get param
-- nouveau/nvc0: remove shader and compute get param
-- panfrost: remove shader and compute get param
-- r300: remove shader get param
-- r600: remove shader and compute get param
-- radeonsi: remove shader and compute get param
-- softpipe: remove shader and compute get param
-- svga: remove shader and compute get param
-- tegra: remove shader and compute get param
-- v3d: remove shader and compute get param
-- vc4: remove shader get param
-- virgl: remove shader and compute get param
-- zink: remove shader and compute get param
-- gallium/aux: remove aux shader param get function
-- gallium: remove screen shader and compute get param callback
-- doc,src: replace doc and comments for shader and compute cap
-- ac/surface: fix radv import dmabuf from radeonsi
-- gallium/ddebug: add missing modifier callback
-- radeonsi: fix has_non_uniform_tex_access info
-- radeonsi,util: add more usage for AMD_FORCE_SHADER_USE_ACO
-- radeonsi: fix GravityMark corruption when use aco
-- egl: decouple dmabuf import/export cap from xserver support
-- dri: dmabuf cap does not rely on winsys multibuffer support
-- glx/egl/x11: fix x11_dri3_check_multibuffer
-- kopper: remove unused function definition
-- dri,egl,glx: remove redundant usage of HAVE_X11_DRM
-- llvmpipe/ci: change for oes_egl_image_external_essl3
-
-Rebecca Mckeever (27):
-
-- pan/format: Use HW version to determine siting for YUV 422 formats
-- pan/texture: Only use plane_chroma_2p for chroma planes
-- vk/meta: Extend copy/fill/update helpers to support YCbCr
-- util/hash_table: Add _mesa_hash_table_u64_replace()
-- panvk: Allow a 32-bit binding value in desc id key and use 64-bit keys
-- panvk: Move single-plane views of multiplane formats to pview.planes[0]
-- panvk: Change immutable_samplers to panvk_sampler **
-- panvk: Create helper function for sampler descriptor emission
-- panvk: Update panvk_get_desc_stride prototype
-- panvk: Move mali_texture_packed structs in panvk_image_view to a union
-- panvk: Use multiple sampler planes and one texture descriptor per plane
-- panvk: Fix assertion in is_disjoint()
-- panvk: Add YCbCr sampler NIR lowering pass
-- panvk: Split get_format_properties into format features helper functions
-- panvk: Report formats not supported by HW as unsupported
-- panvk: Enable YCbCr support for v10+
-- vk/image: Add vk_image_can_be_aliased_to_yuv_plane() helper
-- panvk: Use vk_image_can_be_aliased_to_yuv_plane() helper
-- panvk: Allow 3-byte formats
-- panfrost: Add BI_OPCODE_WMASK to bi_instr_uses_helpers
-- panvk: Enable VK_KHR_shader_subgroup_uniform_control_flow for v10+
-- panvk: Enable VK_KHR_shader_maximal_reconvergence for v10+
-- panvk: Enable VK_KHR_shader_quad_control for v10+
-- panvk: Add STORAGE_IMAGE_BIT feature for formats supporting sampled images
-- panvk: Enable shaderStorageImageExtendedFormats
-- panvk: Remove lower_tg4_broadcom_swizzle from panvk_preprocess_nir()
-- panvk: Support shaderImageGatherExtended
-
-Renato Pereyra (1):
-
-- perfetto/android: align datasource names with tooling expectations
-
-Rhys Perry (41):
-
-- nir,aco,radv: add align_mul/offset to buffer_amd intrinsics
-- nir/opt_offsets: don't check NUW for unswizzled buffer_amd
-- ac/nir/ngg: update bit_sizes_int
-- nir/load_store_vectorize: handle load_buffer_amd/store_buffer_amd
-- ac/nir: set memory_modes for lowered TES input loads
-- radv: don't use bit_sizes_int to skip nir_lower_bit_size
-- radv: move nir_opt_shrink_vectors later
-- radv: DCE before nir_opt_shrink_vectors
-- nir/load_store_vectorize: fix sorting of vectors in add_to_entry_key
-- nir/algebraic: optimize ishl(iadd(iadd(a, #b), c), #d)
-- radv: vectorize descriptor loads
-- radv: vectorize lowered shader IO
-- nir/use_dominance: invalidate nir_metadata_instr_index
-- nir/opt_move: invalidate nir_metadata_instr_index
-- nir/lower_io_arrays_to_elements: invalidate metadata
-- nir/find_array_copies: invalidate nir_metadata_instr_index
-- nir/linking_helpers: invalidate metadata in nir_link_opt_varyings
-- radv/rt: correctly preserve metadata in move_rt_instructions
-- nir: add NIR_DEBUG=extended_validation
-- nir: add NIR_DEBUG=invalidate_metadata
-- nir/validate: assert that if condition dominates use
-- aco: validate operands fixed to definitions
-- aco/ra: reverse renaming of operands outside update_renames
-- aco/ra: unconditionally call undo_renames
-- radeonsi: fix invalidation of metadata in si_nir_lower_abi
-- ac/nir: don't cross swizzle elements when vectorizing buffer_amd intrinsic
-- ac/nir: set higher alignment for some swizzled store_buffer_amd
-- ac/nir: fix tess factor optimization when workgroup barriers are reduced
-- aco: insert dependency waits in certain situations
-- radv: improve radv_get_max_waves for multi-wave workgroups with LDS
-- radv: don't assume WGP mode in radv_get_max_waves
-- amd/drm-shim: add gfx1201
-- aco/ra: fix free register counting when moving variables
-- radv/winsys: increase gfx12 vgprs for null winsys
-- radv/winsys: set gart_page_size for null winsys
-- radv/winsys: set has_distributed_tess for null winsys
-- aco/gfx12: don't use second VALU for VOPD's OPX if there is a WaR
-- aco: combine VALU lanemask hazard into VALUMaskWriteHazard
-- aco/gfx11: create waitcnt for workgroup vmem barriers
-- aco: fix get_temp_reg_changes with clobbered operands
-- aco: swap the correct v_mov_b32 if there are two of them
-
-Rob Clark (17):
-
-- freedreno+tu: Add new virtgpu caps
-- tu: Suballoc VkEvent BOs
-- tu: Don't emit SP_PS_2D_WINDOW_OFFSET on a6xx
-- tc: Add missing tc_set_driver_thread()
-- freedreno: Wait for imported syncobj fences to be available
-- ci: Re enable fd-farm
-- freedreno/ci: Disable traces job until piglit is fixed
-- ci: Re enable fd-farm
-- ir3: Comment re-indent
-- tu/vdrm: Fix userspace fence cmds
-- tu: Avoid extraneous set_iova
-- tu: Add some func traces
-- util: Add drmSyncobj shim
-- panvk: Remove dependency on vk_device::drm_fd
-- vulkan: Use syncobj shim
-- virtio/vdrm: Add vtest backend
-- tu: vdrm vtest support
-
-Robert Mader (4):
-
-- llvmpipe: Take offset into account when importing dmabufs
-- llvmpipe: Free dummy_dmabuf on shutdown
-- gallivm: Re-add check for passmgr before disposing it
-- meson: Bump minimum version to 1.3.0
-
-Rohan Garg (7):
-
-- anv: refactor add_aux_surface_if_supported to use a common variable
-- anv,blorp,isl: handle compressed CPS surfaces through the depth stencil hw
-- anv: CPB surfaces that are used as color attachments or for stores cannot be compressed
-- anv: no need to handle transitions for CPB surfaces
-- anv: separate fast clear handling for compressed CPS
-- isl: enable CPB compression
-- anv: re enable compression for CPS surfaces on platforms other than Xe
-
-Roland Scheidegger (3):
-
-- llvmpipe: don't assert on exceeding if_stack size
-- llvmpipe: Fix overflow issues calculating loop iterations for aniso
-- llvmpipe: Fix alpha-to-coverage without dithering
-
-Ruijing Dong (1):
-
-- radeonsi/vcn: vcn5 roi fix
-
-Ryan Mckeever (5):
-
-- pan/format: Update format flags to follow HW spec
-- pan/format: Add PAN_BIND_STORAGE_IMAGE flag
-- panvk: Enable KHR_format_feature_flags2 and use them
-- panvk: shaderStorageImageReadWithoutFormat support
-- panvk: shaderStorageImageWriteWithoutFormat support
-
-Sagar Ghuge (12):
-
-- intel/genxml: Update BLEND_STATE_ENTRY structure
-- anv: Enable simpleFloatBlendEnable on Xe3+
-- iris: Enable simpleFloatBlendEnable on Xe3+
-- blorp: Enable SimpleFloatBlendEnable on Xe3+
-- intel/compiler: Drop primitive leaf desc load code
-- anv: Exclude non-standard block shapes on Xe2+
-- intel/compiler: Zero out the header for texel fetch
-- anv: CPS LOD Compensation Enable is deprecated on Xe2+
-- intel/compiler: Add support for MSAA typed load/store messages
-- intel/compiler: Lower sample index into coord for MSRT messages
-- intel/compiler: Don't lower 64bit data memory access on LSC
-- intel/compiler: Fix stackIDs on Xe2+
-
-Samuel Pitoiset (227):
-
-- ac,radv,radeonsi: add new GFX12_DCC_WRITE_COMPRESS_DISABLE tiling flag
-- radv/meta: add missing pipeline lookups
-- radv/nir: update radv_nir_opt_tid for derivative group quads
-- radv: implement derivative group quads on GFX12
-- radv: advertise computeDerivativeGroupQuads on GFX12
-- radv/meta: stop using string keys also for DGC and query objects
-- util/disk_cache: add a new helper to create a disk cache
-- vulkan/runtime: allow to use a different disk cache
-- radv: fix caching on-demand meta shaders
-- radv: fix adding the BO to cmdbuf list when starting conditional rendering
-- radv: fix fetching draw vertex data from counter buffers with transform feedback
-- radv: remove redundant drawCount == 0 for indirect mesh/task draws
-- radv: use radv_indirect_dispatch() more
-- radv: rework passing dispatch info via radv_dispatch_info
-- radv: rework passing draw info via radv_draw_info
-- radv: do not keep track of the streamout binding buffer
-- nir: adjust number of components for cmat_muladd_amd
-- radv/nir: add a struct for parameters to cooperative matrix lowering
-- radv/nir: add cooperative matrix lowering for GFX12
-- radv: advertise VK_KHR_cooperative_matrix on GFX12
-- radv/meta: use BDA for query resolves
-- radv/meta: compute the destination addr earlier for query resolves
-- radv/meta: simplify creating buffers for R32G32B32 operations
-- radv: remove unused device memory init/finish helpers
-- radv/video: pass addr to send_cmd()
-- radv/rmv: pass addr to log_resource_bind_locked()
-- radv: pass addr to radv_copy_buffer()
-- radv: rename radv_buffer::bo_va to addr
-- radv: compute radv_buffer::addr at bind time
-- radv: use radv_buffer::addr more
-- radv/video: fix missing image offset when computing VA
-- radv/meta: use BDA for clear HTILE mask
-- radv/meta: use BDA for copying VRS rates to HTILE
-- radv: use BDA for the uploaded parameters with DGC
-- radv: simplify determining VBO size
-- radv/meta: remove the heuristic that prefers CP DMA for GTT BOs
-- radv/meta: disable conditional rendering for fill/update buffer operations
-- radv/meta: inline copy_buffer()
-- radv: rename fill/copy memory helpers
-- radv/meta: add radv_{copy,fill,update}_memory() helpers
-- radv: compute VBO addr at bind time
-- radv: stop relying on VkBuffer for VBO
-- ac/gpu_info: add gfx12_supports_dcc_write_compress_disable
-- radv: add initial DCC support on GFX12
-- vulkan: add descriptor buffer support to compute astc decoder
-- radv/meta: switch to descriptor buffers
-- radv: remove radv_buffer_{init,finish}() helpers
-- radv: remove radv_buffer_view_{init,finish}() helpers
-- radv: fix adding the VRS image BO to the cmdbuf list on GFX11
-- radv/meta: add BOs to cmdbuf list earlier for image copy operations
-- radv/meta: pass the buffer addr to SDMA image buffer copy operations
-- radv/meta: use radv_copy_memory() instead of radv_copy_buffer()
-- radv/meta: remove the buffer dependency for image copy operations
-- radv: stop using image binding offset when exporting BO metadata
-- radv: remove redundant zero initialization when creating images
-- radv: rename radv_image::bindings::bo_va to addr
-- radv: compute radv_image::bindings::addr at bind time
-- radv: use radv_image::bindings::addr more
-- radv: fix adding the BO for unaligned SDMA copies to the cmdbuf list
-- vulkan: constify vk_acceleration_structure_get_va()
-- radv: use radv_CmdDispatchIndirect() in the accel struct path
-- radv/meta: use radv_copy_memory() for the FMASK copy
-- radv: use radv_copy_memory() for accel structure updates
-- radv/meta: inline radv_copy_buffer()
-- radv/meta: rename image<->buffer copies helpers
-- radv/video: fix adding the query pool BO to the cmdbuf list
-- radv: stop computing the UUID using the physical device cache key
-- radv: fix missing SQTT barriers for fbfetch color/depth decompressions
-- radv: reserve bits explicitly for cache key structs
-- vulkan: filter duplicate pNext struct at device creation
-- radv: replace radv_image::shareable by vk_image::external_handle_types
-- radv: remove meaningless TODOs in radv_GetDeviceImageMemoryRequirements()
-- radv: handle OOM error properly when selecting image modifier
-- radv/meta: inline radv_meta_get_view_layer()
-- radv/meta: remove useless assertion in when copy VRS to HTILE
-- radv: check HTILE compression for depth/stencil images per level
-- radv: enable DCC fast clears for 8bpp/16bpp on GFX11
-- radv: fix re-emitting fragment output state when resetting gfx pipeline state
-- docs: add missing RADV_PERFTEST=video_encode description
-- radv: fix trap handler exception options
-- radv: use radv_emulate_rt() more
-- radv: remove redundant radv_instance::drirc::rt_wave64
-- docs: adjust NGG culling options description
-- spirv: move workarounds to an inner struct in spirv_to_nir_options
-- spirv/tests: initialize compiler options in constructor
-- spirv/tests: add a test for NonSemantic.DebugBreak
-- spirv/tests: add a test for force_ssbo_non_uniform
-- spirv/tests: add a test for force_tex_non_uniform
-- spirv/tests: add a test for lower_terminate_to_discard
-- ci: update VKCTS main to ba86fb95004331f2cf571dd9adefe2458290ee11
-- radv: switch to device address from vk_buffer
-- ci/b2c: fix passing B2C_* variables
-- radv/ci: re-enable ET2C emulation testing on non-native GPUs
-- radv: add RADV_DEBUG=pso_history
-- ac,radv: add a workaround for a hw bug with primitive restart on GFX10-GFX10.3
-- radv/ci: enable RADV_PERFTEST=video_{decode,encode} on few GFX9+ GPUs
-- aco/tests: use GFX1201 instead of GFX1200
-- radv/winsys: use real info for GFX12 in the null winsys
-- radv: fix a GPU hang with inherited rendering and HiZ/HiS on GFX1201
-- radv/amdgpu: fix device deduplication
-- meson: add build-radv-tests option
-- ci: enable build-radv-tests for debian-clang and debian-vulkan
-- radv/winsys: enable has_timeline_syncobj for the null winsys
-- radv: add a small framework for RADV specific tests
-- radv/tests: add a test to verify that pipelineCacheUUID is invariant
-- radv/tests: add a test to verify that pipeline hash matches RGP<->Fossilize
-- radv/tests: add few tests that verify drirc options
-- radv: update conformance version
-- aco: do not apply OMOD/CLAMP for pseudo scalar trans instrs
-- radv/ci: enable RADV_PERFTEST=video_decode,video_encode on TAHITI,HAWAII and POLARIS10
-- ac/rgp: few fixes for GFX11.5
-- ac/rgp: add GFX12 definitions
-- ac/rgp: bump version to 1.6
-- ac/rgp: bump instrumentation API version to 1.5
-- ac/sqtt: fix registers programming for GFX12
-- radv: enable RGP on GFX12
-- radv: emit a dummy PS state for noop FS on GFX12
-- radv: track redundant register writes for PA_SC_HISZ_CONTROL on GFX12
-- radv: fix creating pipeline binary from the traversal shader
-- radv: use radv_sdma_emit_nop() more
-- radv: add more SDMA emit helpers
-- radv: add a helper to know whether compute queue is enabled
-- radv: remove meaningless comment when resetting SQTT trace
-- radv: add a helpers to know whether video decode/encode queues are enabled
-- docs: update documentation for RADV_PERFTEST=video_decode,video_encode
-- radv: fix bpe for the stencil aspect of depth/stencil copies on transfer queue
-- radv: fix compresed depth/stencil copies on transfer queue
-- radv: remove useless parameter to radv_sdma_get_buf_surf()
-- radv: cleanup passing the aspect mask for SDMA operations
-- radv: remove radv_force_pstate_peak_gfx11_dgpu=true for Helldivers 2
-- radv: use PM4 for setting specific graphics registers in the preamble
-- radv/meta: fix color<->depth/stencil image copies
-- radv/video: use a pointer to write the total task size
-- radv/video: rework command buffer emission
-- ci: uprev vkd3d-proton to 078f07f588c849c52fa21c8cfdd1c201465b1932
-- radv/ci: remove vkcts-navi21-llvm-valve completely
-- radv/ci: remove radv-stoney-flakes.txt
-- radv/ci: drop aco suffix for CI files
-- radv/ci: rename radv-gfx1200 to radv-gfx1201
-- radv/ci: delete empty radv-hawaii-skips.txt
-- radv: replace radeon_set_reg_seq by a macro
-- radv: switch all emit helpers to macros
-- radv: move the optimized context reg macros with other similar ones
-- radv: rework radeon_set_uconfig_perfctr_reg_seq to use amd_ip_type
-- radv: add new helper to emit PKT3_EVENT_WRITE for sampling queries
-- radv: add radeon_event_write() macros
-- radv/ci: fix renaming the VKCTS job for tahiti
-- radv: rework the shader pointer emit as macros
-- radv: apply some cosmetic changes for future begin/end CS sequences
-- radv: add a helper to emit indirect buffer for draws/dispatches
-- radv: add a helper to emit SPM muxsel
-- radv: slightly change the COND_EXEC for sampling performance counters
-- radv: use radv_cs_write_data_imm() more
-- radv: add more helpers to start/stop perfcounters
-- radv/video: slightly change radv_vcn_sq_header()
-- radv: add a helper to emit a PKT3_COPY_DATA with an immediate
-- radv: add a helper to emit PM4 commands to a CS
-- radv: skip FCE for comp-to-single fast clears with DCC MSAA
-- radv: rework radv_fast_clear_flush_image_inplace()
-- radv: add radv_fmask_color_expand()
-- radv: rework radv_handle_color_image_transition()
-- radv: inline radv_fast_clear_flush_image_inplace()
-- radv: make sure to always decompress FMASK before expanding it
-- radv: disable TC-compatible CMASK with {FMASK,DCC}_DECOMPRESS
-- ac,radv,radeonsi: use PM4 for shadowed registers
-- radv: do not trigger FCE or FMASK decompress on compute queue
-- radv: add queue family assertions when doing decompression passes
-- radv: remove useless use of radv_image_use_comp_to_single()
-- radv: only enable HTILE for depth/stencil attachment images
-- radv: rework command buffer emission with begin/end sequences
-- radv: switch back radeon_cmdbuf to use 32-bit counters
-- radv/ci: stop skipping one memory test due to timeouts
-- radv/ci: remove all skips for STONEY
-- ac/surface: fix selecting preferred alignments for HiZ/HiS on GFX12
-- Revert "radv: program SAMPLE_MASK_TRACKER_WATERMARK optimally for GFX11 APUs"
-- Revert "radeonsi/gfx11: program SAMPLE_MASK_TRACKER_WATERMARK optimally for APUs"
-- radv: fix ignoring conditional rendering with vkCmdResolveImage()
-- radv: add new helper to suspend/resume user conditional rendering
-- radv: rework suspend/resume user conditional rendering
-- ac,radv: remove has_scheduled_fence_dependency
-- ac/gpu_info: bump required DRM minor version to 3.42.0 (kernel 5.15+)
-- radv: remove useless FDCC_ENABLE bitfield clear on GFX12
-- radv: tidy up radv_emit_raster_state()
-- radv: restore DB_DFSM_CONTROL properly when POPS isn't used
-- radv: tidy up radv_emit_db_shader_control()
-- radv: split framebuffer color state emission for GFX12
-- radv: split framebuffer depth/stencil state emission for GFX12
-- radv: split null framebuffer state emission for GFX12
-- radv: stop emitting CB_FDCC_CONTROL to zero on GFX11-GFX11.5
-- radv: do not emit the VRS surface VA when it's not enabled
-- radv: add a fuction to emit the VRS surface on GFX11
-- radv: determine if HiZ/HiS is enabled earlier on GFX12
-- radv: add a workaround for buggy HiZ/HiS on GFX12
-- radv: apply the workaround for buggy HiZ/HiS on GFX12 for DGC
-- radv: add before/after draw functions for DGC
-- radv: move emitting raster and depth/stencil state slightly earlier
-- radv: emit conservative raster mode as part of the MSAA state
-- radv: configure COVERAGE_TO_SHADER_SELECT only if conservative rast is enabled
-- radv: track more MSAA related register writes
-- radv: regroup emitting all MSAA states in one function
-- radv: add clip rects state bit for emitting discard rectangles
-- radv: remove an old workaround for D3D9 with DXVK 2.3.0 and older
-- radv: move the disable_trunc_coord drirc at instance/pdev level
-- radv: move emitting more fb registers when rendering begins
-- radv: use consecutive registers for PA_SC_WINDOW_SCISSOR_{TL,BR}
-- radv: track redundant DB_RENDER_OVERRRIDE register writes on GFX12
-- radv: reduce the number of emitted DWORDS for MSAA 8x user sample locs
-- radv: tidy up radv_emit_raster_state()
-- radv: tidy up radv_emit_hw_ngg()
-- radv: add macros for paired context registers on GFX12
-- radv: use paired context regs when optimal on GFX12
-- radv: only enable DCC for invisible VRAM on GFX12
-- ci: update VKCTS main to 76c1572eaba42d7ddd9bb8eb5788e52dd932068e
-- radv: allocate the SPM BO in GTT for faster readback
-- radv: print more error messages during SPM initialization
-- ac/perfcounter: add support for GFX12
-- radv/sdma: simplify configuring the number of uncompressed DCC blocks
-- radv/sdma: use SDMA5_DCC_xxx bitfields
-- radv/sdma: remove redundant check for compression when getting metadata
-- radv/sdma: use the correct helper to get the number type field
-- radv/sdma: add a new flag to know if the surface is compressed
-- radv/sdma: add support for compression on GFX12
-- radv: set radv_disable_dcc=true for WWE 2k23
-- radv: fix re-emitting VRS state when rendering begins
-- radv: do not clear unwritten color attachments with dual-source blending
-- radv: disable SINGLE clear codes to workaround a hw bug with DCC on GFX11
-- radv: fix GPU hangs with image copies for ASTC/ETC2 formats on transfer queue
-
-Saroj Kumar (2):
-
-- mesa: Add GL_EXT_protected_textures support
-- radeonsi: Move buffer descriptor slot to the beginning
-
-Sasha Finkelstein (1):
-
-- vtn_bindgen2: Fix memory corruption
-
-Serdar Kocdemir (6):
-
-- gfxstream: Track more fence functions on host
-- gfxstream: Add VK_KHR_multiview support
-- gfxstream: track pipeline layouts on decoder
-- gfxstream: wrap semaphore functions on the host
-- gfxstream: Add dispatcher validity checks
-- gfxstream: Wrap vkEnumerateInstanceExtensionProperties for host
-
-Sergi Blanch Torne (8):
-
-- ci: disable Collabora's farm due to maintenance
-- Revert "ci: disable Collabora's farm due to maintenance"
-- ci: typo in debian-android in .build-for-tests-jobs
-- ci: disable Collabora's farm due to maintenance
-- Revert "ci: disable Collabora's farm due to maintenance"
-- ci: disable Collabora's farm due to maintenance
-- Revert "ci: disable Collabora's farm due to maintenance"
-- Uprev Piglit to ebdf60e0d4b0dc23e79373cb923fdee023eb3b2b
-
-Sergii Ushakov (1):
-
-- gfxstream: Emulate DMABUF with OPAQUE_FD
-
-SeÃ¡n de BÃºrca (8):
-
-- rusticl/mem: don't write more supported image formats than requested
-- rusticl/mem: don't create svm_pointers slice from null raw pointer
-- rusticl/mem: use cl_slice::from_raw_parts in place of std::slice
-- rusticl: rename CheckedPtr::copy_checked to match primitive method
-- rusticl: mark CheckedPtr::write_checked as unsafe
-- rusticl: add debug assertions to avoid truncating casts
-- rusticl: correct calculation of maximum allocation size
-- rusticl: cap max alloc size to i32 to avoid overflowing gallium
-
-Sil Vilerino (13):
-
-- d3d12: Fix HEVC range extension pic params validation
-- pipe: Add profiles for HEVC 422 8/10b and 444 10b
-- d3d12: Add support for Y210, Y410, YUY2 and HEVC 422 8/10b, HEVC 444 10b profiles
-- d3d12: Add NULL initialization for d3d12_video_enc::m_pVideoTexArrayDPBPool
-- d3d12: Add some missing members initialization for d3d12_video_buffer
-- d3d12: Increase DPB video texture array pool size for async queue depth
-- d3d12: Fix array of texture DPB cap detection
-- d3d12: Fix warning 4305 truncation from type1 to type2
-- nir.h: Fix warning C4800 forcing value to bool 'true' or 'false'
-- u_thread.h: Fix warning C4800 forcing value to bool 'true' or 'false'
-- d3d12: Fix warning C4800 forcing value to bool 'true' or 'false'
-- d3d12: Enable warnings C4056, C4305, C4351, C4756, C4800, C4291, C4020, C4624, C4309, C5105, C4024, C4189
-- d3d12: Cache the texture array cap requirement in encoder creation for calls to d3d12_video_create_dpb_buffer
-
-Simon Ser (9):
-
-- gbm: fix get_back_bo() failure with gbm_surface and implicit modifiers
-- pvr: replace dup() with os_dupfd_cloexec()
-- freedreno: replace dup() with os_dupfd_cloexec()
-- iris: replace dup() with os_dupfd_cloexec()
-- lavapipe: replace dup() with os_dupfd_cloexec()
-- venus: replace dup() with os_dupfd_cloexec()
-- panvk: replace dup() with os_dupfd_cloexec()
-- libsync: replace dup() with os_dupfd_cloexec()
-- vulkan/wsi/x11: replace dup() with os_dupfd_cloexec()
-
-StÃ©phane Cerveau (2):
-
-- anv: fix error code in GetPhysicalDeviceVideoFormatProperties
-- radv: video: rework maxActiveReferenceSlot/MaxDpbSlots
-
-Sushma Venkatesh Reddy (1):
-
-- intel/tools: Improve memory allocation failure handling in aubinator_error_decode_xe
-
-Sviatoslav Peleshko (3):
-
-- anv: Add full subgroups workaround for the shaders that use shared memory
-- drirc: Apply assume_full_subgroups_with_shared_memory to Resident Evil 2
-- vulkan/wsi/headless: Remove unnecessary wsi_configure_image()
-
-Tapani PÃ¤lli (25):
-
-- intel/genxml/anv: fix the layout of call stack handler struct
-- intel/dev: reduce warning noise from urb settings
-- intel/common: fix mi_builder_test issue
-- anv: handle non-wsi images in anv_layout_to_aux_state
-- anv: tighten condition for changing barrier layouts
-- anv: apply cache flushes on pipeline select with gfx20
-- iris: wait for imported fences to be available in iris_fence_await
-- intel/compiler: add a spec note about L1WT types being uncached
-- iris: remove dead code that cannot get hit anymore
-- intel/dev: update mesa_defs.json from internal database
-- anv: restrict TessellationDistributionLevel for Wa_16025857284
-- iris: restrict TessellationDistributionLevel for Wa_16025857284
-- intel/dev: reduce warning noise from urb settings II
-- isl: add usage field to isl_buffer_fill_state_info
-- iris: pass down buffer usage for isl_buffer_fill_state
-- anv: pass down buffer usage for isl_buffer_fill_state
-- isl/iris/anv: setup L1CacheControl based on surface and buffer usage
-- compiler/glsl: check that bias is not used outside fragment stage
-- intel/dev: update mesa_defs.json from internal database
-- mesa: clamp texbuf query size to MAX_TEXTURE_BUFFER_SIZE
-- mesa: various fixes for ClearTexImage/ClearTexSubImage
-- iris: force reallocate on eglCreateImage with GFX >= 20
-- iris: make sure to not mix compressed vs non-compressed
-- anv: put parenthesis to the set_sampler_size equation
-- intel/dev: update mesa_defs.json from internal database
-
-Taras Pisetskyi (1):
-
-- anv,driconf: Add sampler coordinate precision workaround for EVE Online
-
-Thomas H.P. Andersen (1):
-
-- nvk: use a valid allocation scope
-
-Tim Keller (1):
-
-- dril: Check for null config in dril_target.c
-
-Timothy Arceri (14):
-
-- util/disk_cache: dont create multidisk cache dir if unused
-- util/u_idalloc: fix util_idalloc_sparse_alloc_range()
-- ci: move llvmpipe fails to flakes
-- mesa: fix reuse of deleted buffer object
-- mesa: fix reuse of deleted texture object
-- mesa: fix potential race condition in with TexObjects
-- mesa: fix reuse of deleted sampler object
-- mesa: fix potential race conditions in with FrameBuffers
-- mesa: fix potential race condition in with RenderBuffers
-- mesa: fix potential race condition in with ATIShaders
-- mesa: fix potential race condition in with Programs
-- nir: fix uniform cloning helper
-- glsl: fix regression in ubo cloning
-- util/driconf: add force_gl_depth_component_type_int workaround
-
-Timur KristÃ³f (94):
-
-- radv: Move buffer related NIR meta shaders to radv_meta_nir.c
-- radv: Move blit NIR shaders to radv_meta_nir.c
-- radv: Move blit2d NIR shaders to radv_meta_nir.c
-- radv: Move buffer-image copy and clear NIR shaders to radv_meta_nir.c
-- radv: Move clear NIR shaders to radv_meta_nir.c
-- radv: Move VRS HTILE copy NIR shader to radv_meta_nir.c
-- radv: Move DCC retile NIR shader to radv_meta_nir.c
-- radv: Move expand depth stencil NIR shader to radv_meta_nir.c
-- radv: Move DCC decompress NIR shader to radv_meta_nir.c
-- radv: Move FMASK copy NIR shader to radv_meta_nir.c
-- radv: Move FMASK expand NIR shader to radv_nir_meta.c
-- radv: Move resolve NIR compute shaders to radv_meta_nir.c
-- radv: Move resolve NIR fragment shaders to radv_meta_nir.c
-- radv: Move resolve NIR fs to radv_meta_nir.c
-- radv: Move NIR helpers from radv_meta.c to radv_meta_nir.c
-- radv: Move NIR specific function declarations to radv_meta_nir.h
-- radv: Rename get_global_ids to radv_meta_nir_get_global_ids.
-- radv: Add missing copyright info to radv_meta_buffer.c
-- util/enum_operators: Don't define anything for OpenCL
-- nir: Add struct names where they were missing.
-- nir: Add missing extern "C" to nir_defines.h
-- nir: Add forward declarations of relevant structs to nir_defines.h
-- nir: Move some enums and structs to nir_defines.h
-- nir: Move nir_tcs_info to separate file.
-- nir: Move nir_shader_compiler_options to separate file.
-- nir: Don't include full nir.h in nir_xfb_info.h
-- nir: Don't include the full nir.h when not necessary.
-- spirv: Don't include full nir.h in nir_spirv.h
-- vk: Don't include full nir.h in headers.
-- glsl: Don't include full nir.h where not necessary.
-- ac/nir: Don't include nir.h in headers anymore.
-- ac/nir: Move surface related NIR functions to separate file.
-- aco: Don't include nir.h in aco_interface.h anymore.
-- ac: Don't include full nir.h anymore.
-- radv: Add missing includes and remove unnecessary NIR includes.
-- hk: Don't include full nir.h in hk_shader.h
-- zink: Don't include full nir.h where not necessary.
-- ttn: Don't include full nir.h where not necessary.
-- nak: Don't include full nir.h in nak.h
-- nvk: Don't include full nir.h in nvk_shader.h
-- nir: Don't include xxhash.h in nir.h, only where it is used.
-- nir: Don't include bitscan.h in nir.h, it's not actually used.
-- nir: Don't include u_printf.h in nir.h, only where necessary.
-- nir: Don't include u_format.h in nir.h, it's not actually used.
-- nir: Remove struct keyword from nir.h where possible.
-- nir: Add comment to indicate that NIR_PASS_V is deprecated.
-- nir: Add bool return value to nir_fixup_deref_modes.
-- nir: Add bool return value to nir_fixup_deref_types.
-- nir: Don't use deprecated NIR_PASS_V macro anymore.
-- radv: Stop using deprecated NIR_PASS_V with core NIR passes.
-- radv: Add bool return value to radv_nir_lower_abi.
-- radv: Add bool return value to radv_nir_apply_pipeline_layout.
-- radv: Add bool return value to ray tracing NIR lowerings.
-- ac/nir: Add bool return value to ac_nir_lower_ls_outputs_to_mem.
-- ac/nir: Add bool return value to ac_nir_lower_hs_inputs_to_mem.
-- ac/nir: Add bool return value to ac_nir_lower_hs_outputs_to_mem.
-- ac/nir: Add bool return value to ac_nir_lower_tes_inputs_to_mem.
-- ac/nir: Add bool return value to ac_nir_lower_es_outputs_to_mem.
-- ac/nir: Add bool return value to ac_nir_lower_gs_inputs_to_mem.
-- ac/nir: Add bool return value to ac_nir_lower_task_outputs_to_mem.
-- ac/nir: Add bool return value to ac_nir_lower_mesh_inputs_to_mem.
-- ac/nir: Add bool return value to ac_nir_lower_legacy_vs.
-- ac/nir: Add bool return value to ac_nir_lower_legacy_gs.
-- ac/nir/ngg: Add bool return value to ac_nir_lower_ngg_nogs.
-- ac/nir/ngg: Add bool return value to ac_nir_lower_ngg_gs.
-- ac/nir/ngg: Add bool return value to ac_nir_lower_ngg_mesh.
-- radv: Don't use deprecated NIR_PASS_V macro for AMD common NIR passes.
-- compiler/clc: Stop using deprecated NIR_PASS_V macro.
-- vulkan/runtime: Don't use deprecated NIR_PASS_V macro.
-- hk: Don't use deprecated NIR_PASS_V macro anymore.
-- glsl: Don't use deprecated NIR_PASS_V macro anymore.
-- nak: Don't use deprecated NIR_PASS_V macro anymore.
-- nvk: Don't use deprecated NIR_PASS_V macro anymore.
-- radv: Use flush postamble on GFX7 with different flags.
-- ac/nir/ngg: Run copy propagation.
-- ac/nir/ngg: Improve reuse of position value.
-- ac/nir/ngg: Remove inputs_needed_by_*
-- ac/nir/ngg: Prepare deferred shader part before adding culling code.
-- ac/nir/ngg: Gather info about what the deferred shader part uses.
-- ac/nir/ngg: Use deferred info for compacted arguments.
-- ac/nir/ngg: Remove cleanup_culling_shader_after_dce.
-- nir/xfb: Preserve some xfb information when gathering from intrinsics.
-- nir/opt_varyings: Fix assertion when deduplicating TCS outputs.
-- radv: Use buffers_written mask when gathering XFB info.
-- radv: Call nir_opt_undef too after nir_opt_varyings.
-- radv: Remove radv_streamout_info::num_outputs.
-- nir/print: Fix variable mode for arrayed output load intrinsics.
-- radv: Add radv_foreach_stage to ForEachMacros again.
-- radv: Inline radv_graphics_shaders_link_varyings_{first/second}.
-- radv: Refactor loops in radv_graphics_shaders_link_varyings.
-- radv: Move preparation and fixup to separate loops in varying optimization.
-- radv: Don't call nir_opt_varyings a second time when unnecessary.
-- radv: Clear dirty flag for MSAA state after emitting it.
-- radv: Clear dirty flag for clip rects state after emitting it.
-
-Tomeu Vizoso (4):
-
-- egl/surfaceless: Only choose drivers that expose the graphics capability
-- kopper: Explicitly choose zink
-- etnaviv/ml: Use etna_buffer_resource instead of etna_resource
-- etnaviv: Release screen->dummy_desc_reloc.bo
-
-Trigger Huang (2):
-
-- radeonsi: Fix perfcounter start event in si_pc_emit_start
-- radeonsi: Change program seqnece for perf counters
-
-Valentine Burley (84):
-
-- amd/ci: Revert to 6.6 kernel on Raven
-- zink/ci: Add a fraction for zink-venus-lvp
-- khronos-update: Update ANDROID guards in vk_android_native_buffer.h
-- zink/ci: Make zink-venus-lvp-full a nightly job
-- ci/intel-gpu-freq: Add Xe support
-- ci: Use new kernel with Intel Xe driver
-- ci/lava: Allow passing extra cmdline arguments
-- intel/ci: Drop redundant BOOT_METHOD variables
-- intel/ci: Add newer i915/ADL-P firmware to rootfs
-- intel/ci: Load Xe instead of i915 on ADL
-- intel/dev: Provide a toggle to avoid warnings about unsupported devices
-- intel/ci: Use INTEL_XE_IGNORE_EXPERIMENTAL_WARNING to reduce warnings
-- intel/ci: Update expectations for Xe
-- amd/ci: Fix fraction for radv-stoney-angle-full
-- ci/android: Don't build desktop GL CTS
-- ci/lava: Don't build VK-main for arm64
-- ci: Allow building ANGLE for multiple platforms
-- ci/android: Build and use ANGLE
-- ci/android: Check ANGLE version
-- ci: Move debian-android up to the build-for-tests stage
-- freedreno/ci: Unify naming for a306 jobs
-- zink/ci: Rename a618 suite and expectation files
-- ci/angle: Rework building ANGLE (again)
-- ci/lava: Build ANGLE for arm64
-- ci/android: Add build section for Cuttlefish
-- ci/angle: Use lld-19 for linking ANGLE
-- intel/ci: Fix manual rules for ANGLE jobs
-- ci/angle: Uprev ANGLE
-- ci: Update expectations from latest nightly
-- turnip/ci: Add nightly ANGLE jobs on a618 and a660
-- ci/container: Include ANGLE in the arm64 test-gl container
-- turnip/ci: Rename valve-freedreno-turnip-manual-rules
-- turnip/ci: Add a nightly ANGLE job on a750
-- radv/ci: Don't start X11 for ANGLE
-- anv/ci: Don't start X11 for ANGLE
-- ci: Simplify downloading kernel for crosvm
-- ci: Don't download the kernel image in lava_build.sh
-- intel/ci: Update GuC firmware for ADL-S and ADL-N
-- ci: Use new kernel that supports more Mediatek devices
-- anv/ci: Update expectations from latest nightly
-- intel/ci: Honor device-specific FDO_CI_CONCURRENT variables
-- intel/ci: Add brask and nissa
-- anv/ci: Migrate anv-adl-angle job to brask
-- intel/ci: Migrate intel-adl-cl and intel-adl-skqp to nissa
-- anv/ci: Increase parallelism of zink-anv-adl
-- lavapipe: Update driverVersion
-- anv/ci: Remove fixed test from xfails
-- zink/ci: Run more traces on Tiger Lake
-- zink/ci: Add trace testing on Alder Lake
-- anv/ci: Append -vk suffix to VKCTS job names
-- ci: Update kernel to include i.MX8MP dtb
-- panforst/ci: Migrate the G57 GL job to MT8195
-- panfrost/ci: Add a Piglit job on G57
-- panfrost/ci: Shorten Piglit job names
-- panfrost/ci: Pin g610-gl job to 4GB DUTs
-- tu: Switch to device address from vk_buffer
-- ci: Enable Perfetto in debian-no-libdrm for Turnip build testing
-- zink/ci: Work around recent OOM issues in zink-anv-adl
-- ci/deqp: Delete more uncompressed caselist files
-- ci: Add missing kvm runner tags
-- ci/android: Don't delete ninja after building LLVM
-- ci/android: Keep the LLVM install when rebuilding
-- ci/android: Update to LLVM 19 for Android
-- ci/android: Temporarily disable building llvmpipe
-- radv/ci: Delete obsolete vkcts-stoney-valve job
-- amd/ci: Rename AMD jobs to follow unified naming convention
-- ci: Disable the Google freedreno farm
-- panvk/ci: Migrate the G52 VK job to MT8186
-- ci: Make it possible to use ANGLE traces on other architectures
-- radv/ci: Update ANGLE version used for traces
-- ci/android: Remove platform-tools from test-android container
-- ci/android: Add section for downloading Android CTS
-- ci/container: Disable debian/arm32_test-vk container
-- ci/container: Remove double build sections in test-* containers
-- ci/container: Move calling strip-rootfs.sh to common scripts
-- ci/android: Add build section for uninstalling build software
-- ci/container: Drop unnecessary variables for image paths
-- intel/ci: Convert iris-kbl-piglit to deqp-runner suite
-- ci/piglit: Drop redundant PIGLIT_PROFILES variable
-- ci/piglit: Consolidate HWCI_TEST_SCRIPT for piglit traces
-- ci/piglit: Remove piglit-runner.sh script
-- ci/piglit: Consolidate identical skip lists for X11 and gbm
-- ci/lava: Consolidate piglit trace job definitions
-- zink/ci: Work around recent OOM issues in zink-anv-tgl
-
-Vasily Khoruzhick (20):
-
-- lima: ppir: handle ffma in the backend
-- lima: ppir: improve readability of ppir represantation dump
-- lima: ppir: fixup src node when replacing src for select and load_reg
-- lima: ppir: print index of the node that breaks node_to_instr
-- lima: ppir: fix diassembling atan and combiner codegen definition
-- lima: ppir: assert on unexpected pipeline dest for fmul and vmul
-- lima: ppir: add codegen for mov and mul on combiner unit
-- lima: ppir: use combiner unit for mul
-- lima: ppir: duplicate fneg and fabs if its source is an intrinsic
-- lima: ppir: fix regalloc bugs
-- lima: ppir: assign an index for discard block
-- lima: ppir: introduce an optimizer
-- lima: ppir: try scheduling root nodes into the same instruction
-- lima: ci: update deqp CI expectations
-- lima: ppir: add compactification pass
-- lima: ppir: reuse uniform load in instruction if possible
-- lima: ppir: reuse load_temp/store_temp nodes if possible
-- lima: ppir: assign actual index to discard block
-- lima: ppir: optimize branches
-- lima: ppir: try inserting nodes into successor instr for uncond branch
-
-Vignesh Raman (2):
-
-- s3_upload: improve url validation and error message
-- ci: Uprev kernel to 6.14
-
-Visan, Tiberiu (2):
-
-- amd/vpelib: Fix studio range
-- amd/vpelib: Apply normalization for full range
-
-Vlad Zahorodnii (3):
-
-- egl/wayland: Damage whole surface using wl_surface_damage_buffer()
-- vulkan/wsi/wayland: Damage whole surface using wl_surface_damage_buffer()
-- vulkan/wsi/wayland: Document why wl_surface_damage() code path ignores provided damage
-
-Xaver Hugl (6):
-
-- increase required wayland-protocols version to 1.41
-- vulkan/wsi: implement support for VK_EXT_hdr_metadata on Wayland
-- vulkan/wsi: handle the compositor not supporting extended target volume better
-- vulkan/wsi: don't use sRGB if the compositor doesn't support it
-- vulkan/wsi: validate HDR metadata to not cause protocol errors
-- vulkan/wsi: warn once when HDR metadata is skipped because of protocol errors
-
-Yinjie Yao (2):
-
-- gallium/pipe: Increase hevc max slice to 600
-- frontends/va: Handle properly when decoding more slices than limit
-
-Yiwei Zhang (124):
-
-- venus: scrub disallowed ycbcr features for rgba10x6
-- venus: further sanitize image props for rgba10x6
-- venus: refactor more to image format props sanitization
-- venus: enable VK_EXT_external_memory_acquire_unmodified if needed
-- venus: use dedicated allocation for ANB image memory import
-- venus: emulate a second graphics queue on Android
-- venus: sync venus protocol for below extensions
-- venus: group private data together with other 1.3 exts
-- venus: fix to handle pipeline flags2 from maint5
-- venus: support VK_EXT_blend_operation_advanced
-- venus: refactor to share more codes between pipeline state fillings
-- venus: support VK_EXT_sample_locations
-- venus: fix sampler locations feats and props scrub
-- venus: sync protocol to v1.3.302
-- Support 5 more promoted extensions
-- venus: fix maintenance5 props init and create flags2
-- venus: drop unused codes
-- venus: sync protocol for v1.4.307 release and update promoted entries
-- venus: updated to use core types for promoted extensions
-- venus: support VK_KHR_shader_subgroup_rotate
-- venus: support VK_KHR_shader_float_controls2
-- venus: support VK_EXT_pipeline_protected_access
-- venus: support VK_EXT_pipeline_robustness
-- venus: support VK_KHR_map_memory2
-- venus: support VK_KHR_global_priority
-- venus: support VK_KHR_dynamic_rendering_local_read
-- venus: a few tiny naming fixes
-- venus: support VK_KHR_maintenance6
-- venus: update second queue emulation for 1.4 requirement
-- venus: deprecate a few useless micros
-- venus: advertise 1.4 support
-- venus: fix 2 entry points from maint6
-- venus: fix sample location info validity
-- venus: limit second queue emulation to android framework
-- venus: temporarily disable 1.4 support
-- venus: suppress a few -Wmaybe-uninitialized
-- venus: drop unnecessary struct
-- venus: use sharing_mode from common vk_image
-- venus: fix image format cache miss with AHB usage query
-- venus: sync latest protocol v3 support for host copy
-- venus: extend image format cache for host copy props
-- venus: implement host image copy commands
-- vulkan/util: clean up copy_property and fix for setter
-- venus: enable VK_EXT_host_image_copy support
-- venus: re-enable 1.4 support
-- venus: align on wsi frontends support
-- venus: support wsi maintenance1 extensions
-- venus: sync protocol for the passthrough extensions
-- venus: added passthrough extension support - Part I
-- venus: added passthrough extension support - Part II
-- venus: added passthrough extension support - Part III
-- venus: added passthrough extension support - Part IV
-- venus: added passthrough extension support - Part V
-- venus: relax the requirement for sync2
-- venus: fix an obsolete protocol sync earlier
-- venus: fix a memory corruption in query records recycle
-- venus: sync protocol for ray tracing support
-- venus: add a debug option for ray tracing support
-- venus: support VK_KHR_deferred_host_operations
-- venus: add stubs for accel struct host commands
-- venus: implement VK_KHR_acceleration_structure - Part I
-- venus: implement VK_KHR_acceleration_structure - Part II
-- venus: implement VK_KHR_acceleration_structure - Part III
-- venus: enable VK_KHR_acceleration_structure
-- venus: support VK_KHR_ray_query
-- venus: prepare push template for ray tracing pipeline
-- venus: implement VK_KHR_ray_tracing_pipeline commands
-- venus: enable VK_KHR_ray_tracing_pipeline
-- venus: support VK_KHR_ray_tracing_position_fetch
-- venus: support VK_KHR_ray_tracing_maintenance1
-- lavapipe: set availability bit for accel struct host queries
-- lavapipe: fix accel struct device query copy
-- venus: use common memory report implementation
-- venus: fix to ignore dstSet for push descriptor
-- venus: extend async descriptor set alloc coverage
-- venus: relax 2 assertions for prime blit path
-- venus: sync protocol support for maint7
-- venus: sync protocol for accel struct indirect build encoding fix
-- pan/kmod: set DRM_RDWR for exported dma-bufs
-- venus: drop vn_call usage on apis without any returns
-- venus: sync latest protocol for more extension support
-- venus: add a few more trivial extensions
-- venus: support VK_EXT_filter_cubic
-- venus: support VK_EXT_legacy_dithering
-- venus: support VK_EXT_depth_bias_control
-- venus: support VK_EXT_depth_clamp_control
-- venus: support VK_EXT_attachment_feedback_loop_dynamic_state
-- venus: support VK_EXT_nested_command_buffer
-- venus: default to passthrough ray tracing support
-- venus: add a new debug option to revive memory budget support
-- venus: properly enable display platform extensions
-- venus: back out display control
-- venus: support VK_EXT_debug_report
-- venus: sync latest protocol for 2 more extensions
-- venus: support VK_EXT_pipeline_library_group_handles
-- venus: support VK_EXT_image_sliced_view_of_3d
-- panvk: disable VK_KHR_shader_quad_control
-- panvk: fix dependency for EXT_display_control
-- vulkan: update ALLOWED_ANDROID_VERSION for api level 34
-- vulkan: update ALLOWED_ANDROID_VERSION for api level 35
-- venus: rename common vk object base member to vk
-- venus: explicitly get vn_device from vk_device
-- venus: use common vk_command_pool
-- venus: use vk_command_pool internals
-- venus: use common vk_command_buffer
-- venus: use vk_command_buffer internals
-- venus: use common cmd pool_link
-- docs: demote VK_KHR_shader_relaxed_extended_instruction
-- venus: fix unexpected ring alive status expire upon owner thread switch
-- venus: fix ahb usage caching
-- venus: fix maint4 multi-planar memory requirements
-- venus: improve image memory requirement cache for image aliasing
-- venus: enable VK_EXT_debug_utils
-- virgl/venus/vtest: align capset and protocol with virglrenderer
-- panvk/csf: rework cache flush reduction
-- panvk: fix memory requirement query for aliased disjoint image
-- venus: support VK_KHR_maintenance7
-- venus: sync latest protocol
-- venus: support VK_EXT_buffer_device_address
-- venus: support VK_KHR_shader_relaxed_extended_instruction
-- venus: refactor format properties cache to be extensible
-- venus: support VK_EXT_multisampled_render_to_single_sampled
-- docs: update venus driver page
-- venus: fix missing renderer destructions
-
-Yogesh Mohan Marimuthu (7):
-
-- winsys/amdgpu: do not use rcs->csc
-- winsys/amdgpu: make csc context as array
-- winsys/amdgpu: amdgpu_cs_context is csc, amdgpu_cs is acs
-- winsys/radeon: struct radeon_cmdbuf is rcs instead of cs for consistency
-- winsys/amdgpu: same_queue variable should be set if there is only one queue
-- winsys/amdgpu: userqueue multi ctx jobs are guaranteed to be in sequence
-- winsys/amdgpu: userq non imported fence can be ignored for same ip_type
-
-Yurii Kolesnykov (1):
-
-- Get rid of 5 remaining references to glapitable.h
-
-Zan Dobersek (11):
-
-- tu/a750: invalidate vertex state before CP_DRAW_INDIRECT_MULTI
-- tu: make tu_debug_flags enum 64-bit
-- tu: use query index when retrieving performance query iovas
-- tu: performance query result writes must use dedicated union type
-- tu/a7xx: disable preemption during performance query measurement
-- freedreno: add common implementation of perfcntr-based derived counters
-- tu: support exposing derived counters through VK_KHR_performance_query
-- tu: fix zero-index perfcntr collection for derived counters
-- tu: disable logic operations for float and sRGB formats
-- freedreno/registers: add useful A6XX_SP_TP_MODE_CNTL bitfields
-- tu: allow D3D-compatible texture coordinate rounding
-
-Zhao, Jiali (1):
-
-- amd/vpelib: Fix studio output CSC
-
-forbiddenlake (2):
-
-- docs: Fix HTML build with Sphinx 8.2
-- ci/alpine: upgrade sphinx and hawkmoth to the latest versions
-
-irql-notlessorequal (7):
-
-- hasvk: Fix non-functioning version override.
-- elk: ensure VUE header writes in HS/DS/GS stages
-- elk: always write the VUE header
-- hasvk: Pre-plumbing needed for VK_KHR_maintenance5
-- hasvk: Implement VkPipelineCreateFlags2KHR support
-- hasvk: Implement VK calls and formats.
-- hasvk: Advertise VK_KHR_maintenance5
-
-lcagustini (1):
-
-- panvk: Advertise support for VK_EXT_border_color_swizzle
-
-liuqiang (1):
-
-- intel/brw: Remove redundant condition in components_read()
-
-llyyr (1):
-
-- vulkan/wsi/wayland: initialize surface colorspace with PASS_THROUGH_EXT
-
-sarbes (1):
-
-- lima: add genxml for texture descriptor
diff --git a/docs/relnotes/new_features.txt b/docs/relnotes/new_features.txt
new file mode 100644
index 00000000000..88388ee59b7
--- /dev/null
+++ b/docs/relnotes/new_features.txt
@@ -0,0 +1,22 @@
+removed clover frontend
+VK_EXT_vertex_input_dynamic_state/vertexInputDynamicState on panvk
+pushDescriptor on panvk
+VK_EXT_vertex_input_dynamic_state on panvk
+VK_EXT_vertex_attribute_divisor on panvk
+supportsNonZeroFirstInstance on panvk
+GL_ARB_blend_func_extended on v3d
+dualSrcBlend on v3dv
+VK_KHR_maintenance4 on panvk/v10+
+VK_KHR_maintenance5 on panvk/v10+
+VK_EXT_direct_mode_display on panvk
+VK_EXT_extended_dynamic_state[2] on panvk
+Vulkan 1.2 on panvk/v10+
+VK_KHR_shader_quad_control on panvk/v10+
+multiDrawIndirect on panvk/v10+
+VK_KHR_draw_indirect_count on panvk/v10+
+VK_KHR_shader_integer_dot_product on panvk
+VK_KHR_shader_terminate_invocation on panvk
+VK_EXT_shader_demote_to_helper_invocation on panvk
+VK_EXT_shader_replicated_composites on panvk
+VK_EXT_depth_bias_control on panvk
+VK_KHR_shader_bfloat16 on anv/gfx125+ and radv/gfx11+
diff --git a/docs/sourcetree.rst b/docs/sourcetree.rst
index c169e5a5d87..c3f205a98e9 100644
--- a/docs/sourcetree.rst
+++ b/docs/sourcetree.rst
@@ -132,7 +132,6 @@ each directory.
       -  **frontends** - These implement various libraries using the
          device drivers
 
-         -  **clover** - OpenCL frontend
          -  **d3d10umd** - D3D10 frontend for Windows only. It's similar to Microsoft WARP, but using LLVMpipe/Softpipe.
          -  **dri** - Meta frontend for DRI drivers, see mesa/state_tracker
          -  **glx** - Meta frontend for GLX
diff --git a/docs/submittingpatches.rst b/docs/submittingpatches.rst
index d13bffe80fa..4aeeeb28e04 100644
--- a/docs/submittingpatches.rst
+++ b/docs/submittingpatches.rst
@@ -413,7 +413,7 @@ Our documentation is written as `reStructuredText`_ files in the
 
 .. code-block:: sh
 
-   # Install dependencies (adapt for your distro)
+   # Install dependencies (adapt for your distribution)
    apk add coreutils graphviz py3-clang clang-dev musl-dev linux-headers
    pip3 install sphinx===5.1.1 mako===1.2.3 hawkmoth===0.16.0
 
diff --git a/include/drm-uapi/amdgpu_drm.h b/include/drm-uapi/amdgpu_drm.h
index da747e74a3d..5a48b0acc4d 100644
--- a/include/drm-uapi/amdgpu_drm.h
+++ b/include/drm-uapi/amdgpu_drm.h
@@ -502,6 +502,12 @@ struct drm_amdgpu_userq_fence_info {
 };
 
 struct drm_amdgpu_userq_wait {
+	/**
+	 * @waitq_id: Queue handle used by the userq wait IOCTL to retrieve the
+	 * wait queue and maintain the fence driver references in it.
+	 */
+	__u32	waitq_id;
+	__u32	pad;
 	/**
 	 * @syncobj_handles: The list of syncobj handles submitted by the user queue
 	 * job to get the va/value pairs.
@@ -1454,6 +1460,9 @@ struct drm_amdgpu_info_device {
 	__u32 csa_size;
 	/* context save area base virtual alignment for gfx11 */
 	__u32 csa_alignment;
+	/* Userq IP mask (1 << AMDGPU_HW_IP_*) */
+	__u32 userq_ip_mask;
+	__u32 pad;
 };
 
 struct drm_amdgpu_info_hw_ip {
diff --git a/include/meson.build b/include/meson.build
index 36b96dba445..19aab822ac3 100644
--- a/include/meson.build
+++ b/include/meson.build
@@ -89,7 +89,7 @@ if with_gallium_st_nine
     subdir : 'd3dadapter',
   )
 endif
-
+ 
 opencl_headers = files(
   'CL/cl.h',
   'CL/cl.hpp',
@@ -113,11 +113,3 @@ opencl_headers = files(
   'CL/opencl.h',
   'CL/opencl.hpp',
 )
-# Only install the headers if we are building a stand alone implementation and
-# not an ICD enabled implementation
-if with_gallium_clover and not with_opencl_icd
-  install_headers(
-    opencl_headers,
-    subdir: 'CL'
-  )
-endif
diff --git a/meson.build b/meson.build
index 58194e73b1f..cd802abeca5 100644
--- a/meson.build
+++ b/meson.build
@@ -743,24 +743,7 @@ if get_option('vmware-mks-stats')
   pre_args += '-DVMX86_STATS=1'
 endif
 
-_opencl = get_option('gallium-opencl')
 _rtti = get_option('cpp_rtti')
-if _opencl != 'disabled'
-  warning('Clover will be removed in Mesa 25.2')
-
-  if not with_gallium
-    error('OpenCL Clover implementation requires at least one gallium driver.')
-  endif
-  if not _rtti
-    error('The Clover OpenCL state tracker requires rtti')
-  endif
-
-  with_gallium_clover = true
-  with_opencl_icd = _opencl == 'icd'
-else
-  with_gallium_clover = false
-  with_opencl_icd = false
-endif
 
 with_gallium_rusticl = get_option('gallium-rusticl')
 if with_gallium_rusticl
@@ -829,7 +812,7 @@ else
 endif
 
 dep_clc = null_dep
-if with_gallium_clover or with_clc
+if with_clc
   dep_clc = dependency('libclc')
 endif
 
@@ -1716,15 +1699,6 @@ if with_amd_vk or with_gallium_radeonsi or with_gallium_r600
     llvm_modules += 'asmparser'
   endif
 endif
-if with_gallium_clover
-  llvm_modules += [
-    'linker', 'coverage', 'instrumentation', 'ipo', 'irreader',
-    'lto', 'option', 'objcarcopts', 'profiledata'
-  ]
-  # all-targets is needed to support static linking LLVM build with multiple targets
-  # windowsdriver is needded with LLVM>=15, but we don't know what LLVM verrsion we are using yet
-  llvm_optional_modules += ['all-targets', 'frontendopenmp', 'windowsdriver']
-endif
 if with_clc
   llvm_modules += ['coverage', 'target', 'linker', 'irreader', 'option', 'libdriver', 'lto']
   # all-targets is needed to support static linking LLVM build with multiple targets.
@@ -1750,8 +1724,6 @@ if with_amd_vk or with_gallium_radeonsi
   _llvm_version = '>= 18.0.0'
 elif with_clc or llvm_with_orcjit
   _llvm_version = '>= 15.0.0'
-elif with_gallium_clover
-  _llvm_version = '>= 11.0.0'
 else
   _llvm_version = '>= 5.0.0'
 endif
@@ -1771,7 +1743,7 @@ if _llvm.allowed()
     modules : llvm_modules,
     optional_modules : llvm_optional_modules,
     required : (
-      with_amd_vk or with_gallium_radeonsi or with_gallium_clover or with_clc
+      with_amd_vk or with_gallium_radeonsi or with_clc
       or _llvm.enabled()
     ),
     static : not _shared_llvm,
@@ -1825,8 +1797,6 @@ elif with_swrast_vk
   error('lavapipe requires LLVM and is enabled, but LLVM is disabled.')
 elif with_any_llvmpipe
   error('llvmpipe requires LLVM and is enabled, but LLVM is disabled.')
-elif with_gallium_clover
-  error('The OpenCL "Clover" state tracker requires LLVM, but LLVM is disabled.')
 elif with_clc
   error('The CLC compiler requires LLVM, but LLVM is disabled.')
 else
@@ -1876,7 +1846,7 @@ if dep_spirv_tools.found()
 endif
 
 dep_clang = null_dep
-if with_clc or with_gallium_clover
+if with_clc
   llvm_libdir = dep_llvm.get_variable(cmake : 'LLVM_LIBRARY_DIR', configtool: 'libdir')
 
   dep_clang = cpp.find_library('clang-cpp', dirs : llvm_libdir, required : false)
@@ -1891,7 +1861,7 @@ if with_clc or with_gallium_clover
     if dep_llvm.version().version_compare('>= 15.0')
       clang_modules += 'clangSupport'
     endif
-    if dep_llvm.version().version_compare('>= 16.0') or with_gallium_clover
+    if dep_llvm.version().version_compare('>= 16.0')
       clang_modules += 'clangASTMatchers'
     endif
     if dep_llvm.version().version_compare('>= 18.0')
@@ -2414,9 +2384,6 @@ if with_gallium
   if with_gallium_st_nine
     gallium_frontends += 'nine'
   endif
-  if with_gallium_clover
-    gallium_frontends += 'clover'
-  endif
   if with_gallium_rusticl
     gallium_frontends += 'rusticl'
   endif
diff --git a/meson.options b/meson.options
index 06ff1b24bd7..e6c9567ade8 100644
--- a/meson.options
+++ b/meson.options
@@ -146,15 +146,6 @@ option(
   description : 'build gallium D3D10 WDDM UMD frontend.',
 )
 
-option(
-  'gallium-opencl',
-  type : 'combo',
-  choices : ['icd', 'standalone', 'disabled'],
-  value : 'disabled',
-  description : 'build gallium "clover" OpenCL frontend.',
-  deprecated: true,
-)
-
 option(
   'gallium-rusticl',
   type : 'boolean',
@@ -165,7 +156,7 @@ option(
 option(
   'gallium-rusticl-enable-drivers',
   type : 'array',
-  value : ['auto', 'asahi'],
+  value : ['auto', 'asahi', 'radeonsi'],
   description : 'List of gallium drivers for which rusticl will be enabled ' +
                 'by default',
 )
@@ -581,8 +572,8 @@ option(
   type : 'integer',
   min : 25,
   max : 10000,
-  value : 25,
-  description : 'Android Platform SDK version. Default: Nougat version.'
+  value : 34,
+  description : 'Android Platform SDK version. Default: Android14 version.'
 )
 
 option(
diff --git a/src/amd/ci/gitlab-ci-inc.yml b/src/amd/ci/gitlab-ci-inc.yml
index 6eb4423ec94..fef66719454 100644
--- a/src/amd/ci/gitlab-ci-inc.yml
+++ b/src/amd/ci/gitlab-ci-inc.yml
@@ -35,7 +35,7 @@
       when: on_success
 
 .radeonsi-manual-rules:
-  stage: amd-postmerge
+  stage: amd-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -63,7 +63,7 @@
       when: on_success
 
 .radv-manual-rules:
-  stage: amd-postmerge
+  stage: amd-nightly
   rules:
     - !reference [.test, rules]
     - !reference [.vulkan-manual-rules, rules]
@@ -89,7 +89,7 @@
     - !reference [.radv-collabora-rules, rules]
 
 .radv-collabora-manual-rules:
-  stage: amd-postmerge
+  stage: amd-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -104,7 +104,7 @@
     - !reference [.radv-rules, rules]
 
 .radv-valve-manual-rules:
-  stage: amd-postmerge
+  stage: amd-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -129,7 +129,7 @@
       when: on_success
 
 .radeonsi-vaapi-manual-rules:
-  stage: amd-postmerge
+  stage: amd-nightly
   rules:
     - !reference [.test, rules]
     - !reference [.collabora-farm-manual-rules, rules]
@@ -146,7 +146,8 @@
     - !reference [.radeonsi-rules, rules]
 
 .radeonsi-valve-manual-rules:
-  stage: amd-postmerge
+  stage: amd-nightly
+  extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
     - !reference [.valve-farm-manual-rules, rules]
@@ -308,10 +309,6 @@
   variables:
     B2C_KERNEL_URL: https://fs.mupuf.org/linux-6.6-b2c-radv-ci # 6.6
 
-.b2c-deqp-test:
-  variables:
-    HWCI_TEST_SCRIPT: ./install/deqp-runner.sh
-
 .tahiti-test-valve:
   variables:
     FDO_CI_CONCURRENT: 24
@@ -463,20 +460,9 @@
 .vkcts-test-valve:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-deqp-test
   variables:
     DEQP_SUITE: radv-valve
 
-############### vkd3d-proton
-.vkd3d-kabini-valve:
-  extends:
-    - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
-    - .kabini-test-valve
-    - .radv-valve-manual-rules
-  variables:
-    GPU_VERSION: radv-kabini
-
 ############### Fluster tests ###############
 .radeonsi-raven-vaapi-fluster:
   extends:
@@ -484,8 +470,8 @@
   rules:
     - !reference [.radeonsi-vaapi-rules, rules]
     - changes:
-      - .gitlab-ci/fluster/*
-      - src/amd/ci/$GPU_VERSION-fluster-fails.txt
-      - src/amd/ci/$GPU_VERSION-fluster-flakes.txt
-      - src/amd/ci/$GPU_VERSION-fluster-skips.txt
+        - .gitlab-ci/fluster/*
+        - src/amd/ci/$GPU_VERSION-fluster-fails.txt
+        - src/amd/ci/$GPU_VERSION-fluster-flakes.txt
+        - src/amd/ci/$GPU_VERSION-fluster-skips.txt
       when: on_success
diff --git a/src/amd/ci/gitlab-ci.yml b/src/amd/ci/gitlab-ci.yml
index 1fd741d3d06..b35317fd730 100644
--- a/src/amd/ci/gitlab-ci.yml
+++ b/src/amd/ci/gitlab-ci.yml
@@ -4,7 +4,7 @@ include:
 # Run five jobs in parallel each running 1/55th of the test suite
 radv-stoney-vkcts:
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-vk
     - .radv-stoney-test:x86_64
   parallel: 5
   variables:
@@ -13,7 +13,7 @@ radv-stoney-vkcts:
 
 radv-stoney-angle:
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-gl
     - .radv-stoney-test:x86_64
     - .test-angle
   variables:
@@ -32,8 +32,9 @@ radv-stoney-angle-full:
 
 radeonsi-stoney-glcts-piglit:
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-gl
     - .radeonsi-stoney-test:x86_64
+    - .test-piglit
   parallel: 11
   variables:
     DEQP_SUITE: radeonsi-stoney
@@ -49,7 +50,7 @@ radeonsi-stoney-glcts-piglit-full:
 
 radeonsi-stoney-traces:
   extends:
-    - .lava-piglit-traces:x86_64
+    - .lava-x86_64-piglit-traces
     - .radeonsi-stoney-test:x86_64
   variables:
     EGL_PLATFORM: surfaceless
@@ -58,7 +59,7 @@ radeonsi-stoney-traces:
 
 radv-raven-vkcts:
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-vk
     - .radv-raven-test:x86_64
     - .lava-asus-CM1400CXA-dalboz:x86_64
   parallel: 9
@@ -68,7 +69,7 @@ radv-raven-vkcts:
 
 amd-raven-skqp:
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-gl
     - .amd-raven-test:x86_64
     - .lava-hp-x360-14a-cb0001xx-zork:x86_64
   variables:
@@ -80,7 +81,7 @@ amd-raven-skqp:
 # being disabled due to being flaky.
 .radv-raven-traces:
   extends:
-    - .lava-piglit-traces:x86_64
+    - .lava-x86_64-piglit-traces
     - .radv-raven-test:x86_64
     - .lava-asus-CM1400CXA-dalboz:x86_64
   variables:
@@ -91,7 +92,7 @@ amd-raven-skqp:
 
 radv-raven-traces-restricted:
   extends:
-    - .lava-piglit-traces:x86_64
+    - .lava-x86_64-piglit-traces
     - .radv-raven-test:x86_64
     - .lava-lenovo-TPad-C13-Yoga-zork:x86_64
     - .radv-collabora-restricted-rules
@@ -107,8 +108,9 @@ radv-raven-traces-restricted:
 
 radeonsi-raven-piglit:
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-gl
     - .radeonsi-raven-test:x86_64
+    - .test-piglit
     - .lava-lenovo-TPad-C13-Yoga-zork:x86_64
   parallel: 2
   variables:
@@ -118,8 +120,9 @@ radeonsi-raven-piglit:
 # lower image opcodes to emulate CDNA compute devices
 radeonsi-raven-cdna-lower-image-piglit:
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-gl
     - .radeonsi-raven-test:x86_64
+    - .test-piglit
     - .lava-lenovo-TPad-C13-Yoga-zork:x86_64
   variables:
     DEQP_SUITE: radeonsi-raven-cdna
@@ -127,7 +130,7 @@ radeonsi-raven-cdna-lower-image-piglit:
 
 radeonsi-raven-va:
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-video
     - .radeonsi-raven-test:x86_64
     - .radeonsi-vaapi-rules
     - .lava-hp-x360-14a-cb0001xx-zork:x86_64
@@ -147,7 +150,7 @@ radeonsi-raven-vaapi-fluster:
     - radeonsi-raven-va
     - .radeonsi-raven-vaapi-fluster
   timeout: 30m
-  parallel: 6
+  parallel: 2
   variables:
     FLUSTER_CODECS: VP9 H.264 H.265
     # FIXME: Downloading the vectors can take about 4-5 minutes
@@ -271,7 +274,7 @@ radv-vangogh-vkcts:
 .radeonsi-vangogh-glcts-common:
   extends:
     - .b2c-x86_64-test-gl
-    - .b2c-deqp-test
+    - .test-piglit
     - .vangogh-test-valve
   variables:
     GPU_VERSION: radeonsi-vangogh
@@ -358,7 +361,7 @@ radv-fossils:
 radv-tahiti-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .tahiti-test-valve
     - .radv-valve-manual-rules
   variables:
@@ -369,7 +372,7 @@ radv-tahiti-vkd3d:
 radv-hawaii-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .hawaii-test-valve
     - .radv-valve-manual-rules
   variables:
@@ -380,7 +383,7 @@ radv-hawaii-vkd3d:
 radv-polaris10-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .polaris10-test-valve-kws
     - .radv-valve-manual-rules
   variables:
@@ -391,7 +394,7 @@ radv-polaris10-vkd3d:
 radv-vega10-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .vega10-test-valve
     - .radv-valve-manual-rules
   variables:
@@ -402,7 +405,7 @@ radv-vega10-vkd3d:
 radv-renoir-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .renoir-test-valve
     - .radv-valve-manual-rules
   variables:
@@ -413,7 +416,7 @@ radv-renoir-vkd3d:
 radv-navi10-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .navi10-test-valve-mupuf
     - .radv-valve-manual-rules
   variables:
@@ -424,7 +427,7 @@ radv-navi10-vkd3d:
 radv-navi21-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .navi21-test-valve
     - .radv-valve-manual-rules
   variables:
@@ -435,7 +438,7 @@ radv-navi21-vkd3d:
 radv-vangogh-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .vangogh-test-valve
     - .radv-valve-manual-rules
   variables:
@@ -446,7 +449,7 @@ radv-vangogh-vkd3d:
 radv-raphael-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .raphael-test-valve
     - .radv-valve-manual-rules
   variables:
@@ -457,10 +460,19 @@ radv-raphael-vkd3d:
 radv-navi31-vkd3d:
   extends:
     - .b2c-test-radv-vk
-    - .b2c-vkd3d-proton-test
+    - .test-vkd3d-proton
     - .navi31-test-valve
     - .radv-valve-manual-rules
   variables:
     GPU_VERSION: radv-navi31
     # Random tests fail/crash when trying to run them in parallel
     FDO_CI_CONCURRENT: 1
+
+.radv-kabini-vkd3d:
+  extends:
+    - .b2c-test-radv-vk
+    - .test-vkd3d-proton
+    - .kabini-test-valve
+    - .radv-valve-manual-rules
+  variables:
+    GPU_VERSION: radv-kabini
diff --git a/src/amd/ci/radeonsi-raven-fails.txt b/src/amd/ci/radeonsi-raven-fails.txt
index 3d7ea01c6eb..7d1af063cbc 100644
--- a/src/amd/ci/radeonsi-raven-fails.txt
+++ b/src/amd/ci/radeonsi-raven-fails.txt
@@ -38,3 +38,6 @@ spec@!opengl 1.1@line-smooth-stipple,Fail
 spec@arb_viewport_array@display-list,Fail
 # since transition XORG -> WESTON
 glx@glx_arb_sync_control@waitformsc,Fail
+
+# Since switching to test-gl container based rootfs
+spec@arb_shader_texture_lod@execution@arb_shader_texture_lod-texgradcube,Fail
diff --git a/src/amd/ci/radeonsi-stoney-fails.txt b/src/amd/ci/radeonsi-stoney-fails.txt
index cea39fa696f..25eb4b922cc 100644
--- a/src/amd/ci/radeonsi-stoney-fails.txt
+++ b/src/amd/ci/radeonsi-stoney-fails.txt
@@ -151,3 +151,5 @@ KHR-GLES3.cull_distance.functional,Fail
 spec@ext_external_objects@vk-ping-pong-multi-sem,Fail
 spec@ext_external_objects@vk-ping-pong-single-sem,Crash
 
+# Since switching to test-gl container based rootfs
+spec@arb_shader_texture_lod@execution@arb_shader_texture_lod-texgradcube,Fail
diff --git a/src/amd/ci/radeonsi-vangogh-fails.txt b/src/amd/ci/radeonsi-vangogh-fails.txt
index 3ce61f84585..94584eadcdd 100644
--- a/src/amd/ci/radeonsi-vangogh-fails.txt
+++ b/src/amd/ci/radeonsi-vangogh-fails.txt
@@ -25,6 +25,7 @@ spec@arb_tessellation_shader@arb_tessellation_shader-tes-gs-max-output -small -s
 spec@arb_viewport_array@display-list,Fail
 spec@egl 1.4@eglterminate then unbind context,Fail
 spec@egl_khr_surfaceless_context@viewport,Fail
+spec@glsl-es-1.00@linker@glsl-mismatched-uniform-precision-unused,Fail
 spec@glsl-es-3.00@execution@built-in-functions@fs-packhalf2x16,Fail
 spec@glsl-es-3.00@execution@built-in-functions@vs-packhalf2x16,Fail
 spec@khr_texture_compression_astc@miptree-gles srgb-fp,Fail
diff --git a/src/amd/common/ac_gpu_info.c b/src/amd/common/ac_gpu_info.c
index 31ab81d432f..50f386ae2ac 100644
--- a/src/amd/common/ac_gpu_info.c
+++ b/src/amd/common/ac_gpu_info.c
@@ -202,6 +202,9 @@ struct drm_amdgpu_info_device {
 	uint32_t csa_size;
 	/* context save area base virtual alignment for gfx11 */
 	uint32_t csa_alignment;
+	/* Userq IP mask (1 << AMDGPU_HW_IP_*) */
+	uint32_t userq_ip_mask;
+	uint32_t pad;
 };
 struct drm_amdgpu_info_hw_ip {
    uint32_t hw_ip_version_major;
@@ -510,9 +513,8 @@ static void handle_env_var_force_family(struct radeon_info *info)
    exit(1);
 }
 
-enum ac_query_gpu_info_result
-ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
-                  bool require_pci_bus_info)
+bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
+                       bool require_pci_bus_info)
 {
    struct amdgpu_gpu_info amdinfo;
    struct drm_amdgpu_info_device device_info = {0};
@@ -536,7 +538,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
 
    if (!ac_query_pci_bus_info(fd, info)) {
       if (require_pci_bus_info)
-         return AC_QUERY_GPU_INFO_FAIL;
+         return false;
    }
 
    assert(info->drm_major == 3);
@@ -546,36 +548,51 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
       fprintf(stderr, "amdgpu: DRM version is %u.%u.%u, but this driver is "
                       "only compatible with 3.42.0 (kernel 5.15+) or later.\n",
               info->drm_major, info->drm_minor, info->drm_patchlevel);
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    uint64_t cap;
    r = drmGetCap(fd, DRM_CAP_SYNCOBJ, &cap);
    if (r != 0 || cap == 0) {
       fprintf(stderr, "amdgpu: syncobj support is missing but is required.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    /* Query hardware and driver information. */
    r = ac_drm_query_gpu_info(dev, &amdinfo);
    if (r) {
       fprintf(stderr, "amdgpu: ac_drm_query_gpu_info failed.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    r = ac_drm_query_info(dev, AMDGPU_INFO_DEV_INFO, sizeof(device_info), &device_info);
    if (r) {
       fprintf(stderr, "amdgpu: ac_drm_query_info(dev_info) failed.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
+   info->userq_ip_mask = device_info.userq_ip_mask;
+
    for (unsigned ip_type = 0; ip_type < AMD_NUM_IP_TYPES; ip_type++) {
       struct drm_amdgpu_info_hw_ip ip_info = {0};
 
       r = ac_drm_query_hw_ip_info(dev, ip_type, 0, &ip_info);
-      if (r || !ip_info.available_rings)
+      if (r)
          continue;
 
+      if (ip_info.available_rings) {
+         info->ip[ip_type].num_queues = util_bitcount(ip_info.available_rings);
+         /* Kernel can set both available_rings and userq_ip_mask. Clear userq_ip_mask. */
+         info->userq_ip_mask &= ~BITFIELD_BIT(ip_type);
+      } else if (info->userq_ip_mask & BITFIELD_BIT(ip_type)) {
+         /* info[ip_type].num_queues variable is also used to describe if that ip_type is
+          * supported or not. Setting this variable to 1 for userqueues.
+          */
+         info->ip[ip_type].num_queues = 1;
+      } else {
+         continue;
+      }
+
       /* Gfx6-8 don't set ip_discovery_version. */
       if (info->drm_minor >= 48 && ip_info.ip_discovery_version) {
          info->ip[ip_type].ver_major = (ip_info.ip_discovery_version >> 16) & 0xff;
@@ -598,7 +615,6 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
                   device_info.family == FAMILY_MDN)
             info->ip[AMD_IP_GFX].ver_minor = info->ip[AMD_IP_COMPUTE].ver_minor = 3;
       }
-      info->ip[ip_type].num_queues = util_bitcount(ip_info.available_rings);
 
       /* query ip count */
       r = ac_drm_query_hw_ip_count(dev, ip_type, &num_instances);
@@ -634,35 +650,35 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
    /* Only require gfx or compute. */
    if (!info->ip[AMD_IP_GFX].num_queues && !info->ip[AMD_IP_COMPUTE].num_queues) {
       fprintf(stderr, "amdgpu: failed to find gfx or compute.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    r = ac_drm_query_firmware_version(dev, AMDGPU_INFO_FW_GFX_ME, 0, 0, &info->me_fw_version,
                                      &info->me_fw_feature);
    if (r) {
       fprintf(stderr, "amdgpu: ac_drm_query_firmware_version(me) failed.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    r = ac_drm_query_firmware_version(dev, AMDGPU_INFO_FW_GFX_MEC, 0, 0, &info->mec_fw_version,
                                      &info->mec_fw_feature);
    if (r) {
       fprintf(stderr, "amdgpu: ac_drm_query_firmware_version(mec) failed.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    r = ac_drm_query_firmware_version(dev, AMDGPU_INFO_FW_GFX_PFP, 0, 0, &info->pfp_fw_version,
                                      &info->pfp_fw_feature);
    if (r) {
       fprintf(stderr, "amdgpu: ac_drm_query_firmware_version(pfp) failed.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    if (info->ip[AMD_IP_VCN_DEC].num_queues || info->ip[AMD_IP_VCN_UNIFIED].num_queues) {
       r = ac_drm_query_firmware_version(dev, AMDGPU_INFO_FW_VCN, 0, 0, &vidip_fw_version, &vidip_fw_feature);
       if (r) {
          fprintf(stderr, "amdgpu: ac_drm_query_firmware_version(vcn) failed.\n");
-         return AC_QUERY_GPU_INFO_FAIL;
+         return false;
       } else {
          info->vcn_dec_version = (vidip_fw_version & 0x0F000000) >> 24;
          info->vcn_enc_major_version = (vidip_fw_version & 0x00F00000) >> 20;
@@ -673,7 +689,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
          r = ac_drm_query_firmware_version(dev, AMDGPU_INFO_FW_VCE, 0, 0, &vidip_fw_version, &vidip_fw_feature);
          if (r) {
             fprintf(stderr, "amdgpu: ac_drm_query_firmware_version(vce) failed.\n");
-            return AC_QUERY_GPU_INFO_FAIL;
+            return false;
          } else
             info->vce_fw_version = vidip_fw_version;
       }
@@ -682,7 +698,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
          r = ac_drm_query_firmware_version(dev, AMDGPU_INFO_FW_UVD, 0, 0, &vidip_fw_version, &vidip_fw_feature);
          if (r) {
             fprintf(stderr, "amdgpu: ac_drm_query_firmware_version(uvd) failed.\n");
-            return AC_QUERY_GPU_INFO_FAIL;
+            return false;
          } else
             info->uvd_fw_version = vidip_fw_version;
       }
@@ -691,7 +707,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
    r = ac_drm_query_sw_info(dev, amdgpu_sw_info_address32_hi, &info->address32_hi);
    if (r) {
       fprintf(stderr, "amdgpu: amdgpu_query_sw_info(address32_hi) failed.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    struct drm_amdgpu_memory_info meminfo = {0};
@@ -699,7 +715,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
    r = ac_drm_query_info(dev, AMDGPU_INFO_MEMORY, sizeof(meminfo), &meminfo);
    if (r) {
       fprintf(stderr, "amdgpu: ac_drm_query_info(memory) failed.\n");
-      return AC_QUERY_GPU_INFO_FAIL;
+      return false;
    }
 
    /* Note: usable_heap_size values can be random and can't be relied on. */
@@ -838,7 +854,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
       else {
          fprintf(stderr, "amdgpu: Unknown gfx version: %u.%u\n",
                  info->ip[AMD_IP_GFX].ver_major, info->ip[AMD_IP_GFX].ver_minor);
-         return AC_QUERY_GPU_INFO_UNIMPLEMENTED_HW;
+         return false;
       }
 
       info->family_id = device_info.family;
@@ -853,7 +869,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
    if (!info->name) {
       fprintf(stderr, "amdgpu: unknown (family_id, chip_external_rev): (%u, %u)\n",
               device_info.family, device_info.external_rev);
-      return AC_QUERY_GPU_INFO_UNIMPLEMENTED_HW;
+      return false;
    }
 
    memset(info->lowercase_name, 0, sizeof(info->lowercase_name));
@@ -1131,7 +1147,8 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
     * on GFX6. Some CLEAR_STATE cause asic hang on radeon kernel, etc.
     * SPI_VS_OUT_CONFIG. So only enable GFX7 CLEAR_STATE on amdgpu kernel.
     */
-   info->has_clear_state = info->gfx_level >= GFX7 && info->gfx_level < GFX12;
+   info->has_clear_state = info->gfx_level >= GFX7 && info->gfx_level < GFX12 &&
+                           !(info->userq_ip_mask & BITFIELD_BIT(AMD_IP_GFX));
 
    info->has_distributed_tess =
       info->gfx_level >= GFX10 || (info->gfx_level >= GFX8 && info->max_se >= 2);
@@ -1551,6 +1568,10 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
                                        info->has_dedicated_vram &&
                                        info->drm_minor >= 47;
 
+   /* Compute the scratch WAVESIZE granularity in bytes. */
+   info->scratch_wavesize_granularity_shift = info->gfx_level >= GFX11 ? 8 : 10;
+   info->scratch_wavesize_granularity = BITFIELD_BIT(info->scratch_wavesize_granularity_shift);
+
    /* The maximum number of scratch waves. The number is only a function of the number of CUs.
     * It should be large enough to hold at least 1 threadgroup. Use the minimum per-SA CU count.
     *
@@ -1683,7 +1704,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
       r = ac_drm_query_uq_fw_area_info(dev, AMDGPU_HW_IP_GFX, 0, &fw_info);
       if (r) {
          fprintf(stderr, "amdgpu: amdgpu_query_uq_fw_area_info() failed.\n");
-         return AC_QUERY_GPU_INFO_FAIL;
+         return false;
       }
 
       info->has_fw_based_shadowing = true;
@@ -1712,10 +1733,90 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
       info->has_set_sh_pairs_packed = info->register_shadowing_required;
    }
 
+   /* This is the size of all TCS outputs in memory per workgroup.
+    * Hawaii can't handle num_workgroups > 256 with 8K per workgroup, so use 4K.
+    */
+   unsigned max_hs_out_vram_dwords_per_wg = info->family == CHIP_HAWAII ? 4096 : 8192;
+   unsigned max_hs_out_vram_dwords_enum;
+   unsigned max_workgroups_per_se;
+
+   switch (max_hs_out_vram_dwords_per_wg) {
+   case 8192:
+      max_hs_out_vram_dwords_enum = V_03093C_X_8K_DWORDS;
+      break;
+   case 4096:
+      max_hs_out_vram_dwords_enum = V_03093C_X_4K_DWORDS;
+      break;
+   case 2048:
+      max_hs_out_vram_dwords_enum = V_03093C_X_2K_DWORDS;
+      break;
+   case 1024:
+      max_hs_out_vram_dwords_enum = V_03093C_X_1K_DWORDS;
+      break;
+   default:
+      unreachable("invalid TCS workgroup size");
+   }
+
+   /* Vega10 should limit num_workgroups to 508 (127 per SE)
+    * Gfx7 should limit num_workgroups to 508 (127 per SE)
+    * Gfx6 should limit num_workgroups to 126 (63 per SE)
+    */
+   if (info->gfx_level >= GFX11) {
+      max_workgroups_per_se = 256;
+   } else if (info->gfx_level >= GFX10 ||
+              info->family == CHIP_VEGA12 || info->family == CHIP_VEGA20) {
+      max_workgroups_per_se = 128;
+   } else if (info->gfx_level >= GFX7 && info->family != CHIP_CARRIZO && info->family != CHIP_STONEY) {
+      max_workgroups_per_se = 127;
+   } else {
+      max_workgroups_per_se = 63;
+   }
+
+   /* Limit to 4 workgroups per CU for TCS, which exhausts LDS if each workgroup occupies 16KB.
+    * Note that the offchip allocation isn't deallocated until the corresponding TES waves finish.
+    */
+   unsigned num_offchip_wg_per_cu = 4;
+   unsigned num_workgroups_per_se = MIN2(num_offchip_wg_per_cu * info->max_good_cu_per_sa *
+                                         info->max_sa_per_se, max_workgroups_per_se);
+   unsigned num_workgroups = num_workgroups_per_se * info->max_se;
+
+   if (info->gfx_level >= GFX11) {
+      /* OFFCHIP_BUFFERING is per SE. */
+      info->hs_offchip_param = S_03093C_OFFCHIP_BUFFERING_GFX103(num_workgroups_per_se - 1) |
+                               S_03093C_OFFCHIP_GRANULARITY_GFX103(max_hs_out_vram_dwords_enum);
+   } else if (info->gfx_level >= GFX10_3) {
+      info->hs_offchip_param = S_03093C_OFFCHIP_BUFFERING_GFX103(num_workgroups - 1) |
+                               S_03093C_OFFCHIP_GRANULARITY_GFX103(max_hs_out_vram_dwords_enum);
+   } else if (info->gfx_level >= GFX7) {
+      info->hs_offchip_param = S_03093C_OFFCHIP_BUFFERING_GFX7(num_workgroups -
+                                                               (info->gfx_level >= GFX8 ? 1 : 0)) |
+                               S_03093C_OFFCHIP_GRANULARITY_GFX7(max_hs_out_vram_dwords_enum);
+   } else {
+      info->hs_offchip_param = S_0089B0_OFFCHIP_BUFFERING(num_workgroups) |
+                               S_0089B0_OFFCHIP_GRANULARITY(max_hs_out_vram_dwords_enum);
+   }
+
+   /* The typical size of tess factors of 1 TCS workgroup if all patches are triangles. */
+   unsigned typical_tess_factor_size_per_wg = (192 / 3) * 16;
+   unsigned num_tess_factor_wg_per_cu = 3;
+
+   info->hs_offchip_workgroup_dw_size = max_hs_out_vram_dwords_per_wg;
+   info->tess_offchip_ring_size = num_workgroups * max_hs_out_vram_dwords_per_wg * 4;
+   info->tess_factor_ring_size = typical_tess_factor_size_per_wg * num_tess_factor_wg_per_cu *
+                                 info->max_good_cu_per_sa * info->max_sa_per_se * info->max_se;
+   info->total_tess_ring_size = info->tess_offchip_ring_size + info->tess_factor_ring_size;
+
    /* GFX1013 is GFX10 plus ray tracing instructions */
    info->has_image_bvh_intersect_ray = info->gfx_level >= GFX10_3 ||
                                        info->family == CHIP_GFX1013;
 
+   if (info->gfx_level >= GFX12)
+      info->rt_ip_version = RT_3_1;
+   else if (info->gfx_level >= GFX11)
+      info->rt_ip_version = RT_2_0;
+   else if (info->has_image_bvh_intersect_ray)
+      info->rt_ip_version = RT_1_1;
+
    set_custom_cu_en_mask(info);
 
    const char *ib_filename = debug_get_option("AMD_PARSE_IB", NULL);
@@ -1748,7 +1849,7 @@ ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
          exit(0);
       }
    }
-   return AC_QUERY_GPU_INFO_SUCCESS;
+   return true;
 }
 
 void ac_compute_driver_uuid(char *uuid, size_t size)
@@ -2034,15 +2135,19 @@ void ac_print_gpu_info(const struct radeon_info *info, FILE *f)
    fprintf(f, "    max_scratch_waves = %i\n", info->max_scratch_waves);
    fprintf(f, "    has_scratch_base_registers = %i\n", info->has_scratch_base_registers);
    fprintf(f, "Ring info:\n");
-   fprintf(f, "    attribute_ring_size_per_se = %u KB\n",
-           DIV_ROUND_UP(info->attribute_ring_size_per_se, 1024));
-   if (info->gfx_level >= GFX12) {
-      fprintf(f, "    pos_ring_size_per_se = %u KB\n", DIV_ROUND_UP(info->pos_ring_size_per_se, 1024));
-      fprintf(f, "    prim_ring_size_per_se = %u KB\n", DIV_ROUND_UP(info->prim_ring_size_per_se, 1024));
+   if (info->gfx_level >= GFX11) {
+      fprintf(f, "    attribute_ring_size_per_se = %u KB\n",
+              DIV_ROUND_UP(info->attribute_ring_size_per_se, 1024));
+      if (info->gfx_level >= GFX12) {
+         fprintf(f, "    pos_ring_size_per_se = %u KB\n", DIV_ROUND_UP(info->pos_ring_size_per_se, 1024));
+         fprintf(f, "    prim_ring_size_per_se = %u KB\n", DIV_ROUND_UP(info->prim_ring_size_per_se, 1024));
+      }
+      fprintf(f, "    total_attribute_pos_prim_ring_size = %u KB\n",
+              DIV_ROUND_UP(info->total_attribute_pos_prim_ring_size, 1024));
    }
-   fprintf(f, "    total_attribute_pos_prim_ring_size = %u KB\n",
-           DIV_ROUND_UP(info->total_attribute_pos_prim_ring_size, 1024));
-
+   fprintf(f, "    hs_offchip_workgroup_size = %u B\n", info->hs_offchip_workgroup_dw_size * 4);
+   fprintf(f, "    tess_factor_ring_size = %u KB\n", DIV_ROUND_UP(info->tess_factor_ring_size, 1024));
+   fprintf(f, "    tess_offchip_ring_size = %u KB\n", DIV_ROUND_UP(info->tess_offchip_ring_size, 1024));
    fprintf(f, "Render backend info:\n");
    fprintf(f, "    pa_sc_tile_steering_override = 0x%x\n", info->pa_sc_tile_steering_override);
    fprintf(f, "    max_render_backends = %i\n", info->max_render_backends);
@@ -2382,96 +2487,6 @@ ac_get_compute_resource_limits(const struct radeon_info *info, unsigned waves_pe
    return compute_resource_limits;
 }
 
-void ac_get_hs_info(const struct radeon_info *info,
-                    struct ac_hs_info *hs)
-{
-   bool double_offchip_buffers = info->gfx_level >= GFX7 &&
-                                 info->family != CHIP_CARRIZO &&
-                                 info->family != CHIP_STONEY;
-   unsigned max_offchip_buffers_per_se;
-   unsigned max_offchip_buffers;
-   unsigned offchip_granularity;
-   unsigned hs_offchip_param;
-
-   hs->tess_offchip_block_dw_size =
-      info->family == CHIP_HAWAII ? 4096 : 8192;
-
-   /*
-    * Per RadeonSI:
-    * This must be one less than the maximum number due to a hw limitation.
-    * Various hardware bugs need this.
-    *
-    * Per AMDVLK:
-    * Vega10 should limit max_offchip_buffers to 508 (4 * 127).
-    * Gfx7 should limit max_offchip_buffers to 508
-    * Gfx6 should limit max_offchip_buffers to 126 (2 * 63)
-    *
-    * Follow AMDVLK here.
-    */
-   if (info->gfx_level >= GFX11) {
-      max_offchip_buffers_per_se = 256; /* TODO: we could decrease this to reduce memory/cache usage */
-   } else if (info->gfx_level >= GFX10) {
-      max_offchip_buffers_per_se = 128;
-   } else if (info->family == CHIP_VEGA12 || info->family == CHIP_VEGA20) {
-      /* Only certain chips can use the maximum value. */
-      max_offchip_buffers_per_se = double_offchip_buffers ? 128 : 64;
-   } else {
-      max_offchip_buffers_per_se = double_offchip_buffers ? 127 : 63;
-   }
-
-   max_offchip_buffers = max_offchip_buffers_per_se * info->max_se;
-
-   /* Hawaii has a bug with offchip buffers > 256 that can be worked
-    * around by setting 4K granularity.
-    */
-   if (hs->tess_offchip_block_dw_size == 4096) {
-      assert(info->family == CHIP_HAWAII);
-      offchip_granularity = V_03093C_X_4K_DWORDS;
-   } else {
-      assert(hs->tess_offchip_block_dw_size == 8192);
-      offchip_granularity = V_03093C_X_8K_DWORDS;
-   }
-
-   switch (info->gfx_level) {
-   case GFX6:
-      max_offchip_buffers = MIN2(max_offchip_buffers, 126);
-      break;
-   case GFX7:
-   case GFX8:
-   case GFX9:
-      max_offchip_buffers = MIN2(max_offchip_buffers, 508);
-      break;
-   case GFX10:
-      break;
-   default:
-      break;
-   }
-
-   hs->max_offchip_buffers = max_offchip_buffers;
-
-   if (info->gfx_level >= GFX11) {
-      /* OFFCHIP_BUFFERING is per SE. */
-      hs_offchip_param = S_03093C_OFFCHIP_BUFFERING_GFX103(max_offchip_buffers_per_se - 1) |
-                         S_03093C_OFFCHIP_GRANULARITY_GFX103(offchip_granularity);
-   } else if (info->gfx_level >= GFX10_3) {
-      hs_offchip_param = S_03093C_OFFCHIP_BUFFERING_GFX103(max_offchip_buffers - 1) |
-                         S_03093C_OFFCHIP_GRANULARITY_GFX103(offchip_granularity);
-   } else if (info->gfx_level >= GFX7) {
-      if (info->gfx_level >= GFX8)
-         --max_offchip_buffers;
-      hs_offchip_param = S_03093C_OFFCHIP_BUFFERING_GFX7(max_offchip_buffers) |
-                         S_03093C_OFFCHIP_GRANULARITY_GFX7(offchip_granularity);
-   } else {
-      hs_offchip_param = S_0089B0_OFFCHIP_BUFFERING(max_offchip_buffers);
-   }
-
-   hs->hs_offchip_param = hs_offchip_param;
-
-   hs->tess_factor_ring_size = 48 * 1024 * info->max_se;
-   hs->tess_offchip_ring_offset = align(hs->tess_factor_ring_size, 64 * 1024);
-   hs->tess_offchip_ring_size = hs->max_offchip_buffers * hs->tess_offchip_block_dw_size * 4;
-}
-
 static uint16_t get_task_num_entries(enum radeon_family fam)
 {
    /* Number of task shader ring entries. Needs to be a power of two.
diff --git a/src/amd/common/ac_gpu_info.h b/src/amd/common/ac_gpu_info.h
index c1744c42b50..010866a062a 100644
--- a/src/amd/common/ac_gpu_info.h
+++ b/src/amd/common/ac_gpu_info.h
@@ -218,6 +218,7 @@ struct radeon_info {
 
    enum vcn_version vcn_ip_version;
    enum sdma_version sdma_ip_version;
+   enum rt_version rt_ip_version;
 
    /* Kernel & winsys capabilities. */
    uint32_t drm_major; /* version */
@@ -243,7 +244,7 @@ struct radeon_info {
    bool has_tmz_support;
    bool has_trap_handler_support;
    bool kernel_has_modifiers;
-   bool use_userq;
+   uint32_t userq_ip_mask; /* AMD_IP_* bits */
 
    /* If the kernel driver uses CU reservation for high priority compute on gfx10+, it programs
     * a global CU mask in the hw that is AND'ed with CU_EN register fields set by userspace.
@@ -278,6 +279,8 @@ struct radeon_info {
    uint32_t min_wave64_vgpr_alloc;
    uint32_t max_vgpr_alloc;
    uint32_t wave64_vgpr_alloc_granularity;
+   uint32_t scratch_wavesize_granularity_shift;
+   uint32_t scratch_wavesize_granularity;
    uint32_t max_scratch_waves;
    bool has_scratch_base_registers;
 
@@ -290,6 +293,13 @@ struct radeon_info {
    uint32_t total_attribute_pos_prim_ring_size; /* GFX11+ */
    bool has_attr_ring;
 
+   /* Tessellation rings. */
+   uint32_t hs_offchip_param;
+   uint32_t hs_offchip_workgroup_dw_size;
+   uint32_t tess_factor_ring_size;
+   uint32_t tess_offchip_ring_size;
+   uint32_t total_tess_ring_size;
+
    /* Render backends (color + depth blocks). */
    uint32_t r300_num_gb_pipes;
    uint32_t r300_num_z_pipes;
@@ -328,14 +338,8 @@ struct radeon_info {
    bool has_image_bvh_intersect_ray;
 };
 
-enum ac_query_gpu_info_result {
-   AC_QUERY_GPU_INFO_SUCCESS,
-   AC_QUERY_GPU_INFO_FAIL,
-   AC_QUERY_GPU_INFO_UNIMPLEMENTED_HW,
-};
-
-enum ac_query_gpu_info_result ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
-                                                bool require_pci_bus_info);
+bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
+                       bool require_pci_bus_info);
 
 void ac_compute_driver_uuid(char *uuid, size_t size);
 
@@ -350,18 +354,6 @@ unsigned ac_get_compute_resource_limits(const struct radeon_info *info,
                                         unsigned waves_per_threadgroup, unsigned max_waves_per_sh,
                                         unsigned threadgroups_per_cu);
 
-struct ac_hs_info {
-   uint32_t tess_offchip_block_dw_size;
-   uint32_t max_offchip_buffers;
-   uint32_t hs_offchip_param;
-   uint32_t tess_factor_ring_size;
-   uint32_t tess_offchip_ring_offset;
-   uint32_t tess_offchip_ring_size;
-};
-
-void ac_get_hs_info(const struct radeon_info *info,
-                    struct ac_hs_info *hs);
-
 /* Task rings BO layout information.
  * This BO is shared between GFX and ACE queues so that the ACE and GFX
  * firmware can cooperate on task->mesh dispatches and is also used to
diff --git a/src/amd/common/ac_shader_util.c b/src/amd/common/ac_shader_util.c
index 18bece754a1..b86583f5f80 100644
--- a/src/amd/common/ac_shader_util.c
+++ b/src/amd/common/ac_shader_util.c
@@ -931,27 +931,20 @@ uint32_t ac_compute_num_tess_patches(const struct radeon_info *info, uint32_t nu
                                      uint32_t lds_per_patch, uint32_t wave_size,
                                      bool tess_uses_primid)
 {
-   /* The VGT HS block increments the patch ID unconditionally
-    * within a single threadgroup. This results in incorrect
-    * patch IDs when instanced draws are used.
+   /* The VGT HS block increments the patch ID unconditionally within a single threadgroup.
+    * This results in incorrect patch IDs when instanced draws are used.
     *
-    * The intended solution is to restrict threadgroups to
-    * a single instance by setting SWITCH_ON_EOI, which
-    * should cause IA to split instances up. However, this
-    * doesn't work correctly on GFX6 when there is no other
-    * SE to switch to.
+    * The intended solution is to restrict threadgroups to a single instance by setting
+    * SWITCH_ON_EOI, which should cause IA to split instances up. However, this doesn't work
+    * correctly on GFX6 when there is no other SE to switch to.
     */
    const bool has_primid_instancing_bug = info->gfx_level == GFX6 && info->max_se == 1;
    if (has_primid_instancing_bug && tess_uses_primid)
       return 1;
 
-   /* Ensure that we only need 4 waves per CU, so that we don't need to check
-    * resource usage (such as whether we have enough VGPRs to fit the whole
-    * threadgroup into the CU). It also ensures that the number of tcs in and out
-    * vertices per threadgroup are at most 256, which is the hw limit.
-    */
-   const unsigned max_verts_per_patch = MAX2(num_tcs_input_cp, num_tcs_output_cp);
-   unsigned num_patches = 256 / max_verts_per_patch;
+   /* 256 threads per workgroup is the hw limit. */
+   const unsigned num_threads_per_patch = MAX2(num_tcs_input_cp, num_tcs_output_cp);
+   unsigned num_patches = 256 / num_threads_per_patch;
 
    /* Not necessary for correctness, but higher numbers are slower.
     * The hardware can do more, but we prefer fully occupied waves.
@@ -966,11 +959,8 @@ uint32_t ac_compute_num_tess_patches(const struct radeon_info *info, uint32_t nu
       num_patches = MIN2(num_patches, 16); /* recommended */
 
    /* Make sure the output data fits in the offchip buffer */
-   if (vram_per_patch) {
-      const uint32_t tess_offchip_block_dw_size = info->family == CHIP_HAWAII ? 4096 : 8192;
-      num_patches =
-         MIN2(num_patches, (tess_offchip_block_dw_size * 4) / vram_per_patch);
-   }
+   if (vram_per_patch)
+      num_patches = MIN2(num_patches, (info->hs_offchip_workgroup_dw_size * 4) / vram_per_patch);
 
    /* Make sure that the data fits in LDS. This assumes the shaders only
     * use LDS for the inputs and outputs.
@@ -988,17 +978,17 @@ uint32_t ac_compute_num_tess_patches(const struct radeon_info *info, uint32_t nu
    /* Make sure that vector lanes are fully occupied by cutting off the last wave
     * if it's only partially filled.
     */
-   const unsigned temp_verts_per_tg = num_patches * max_verts_per_patch;
+   const unsigned threads_per_tg = num_patches * num_threads_per_patch;
 
-   if (temp_verts_per_tg > wave_size &&
-       (wave_size - temp_verts_per_tg % wave_size >= MAX2(max_verts_per_patch, 8)))
-      num_patches = (temp_verts_per_tg & ~(wave_size - 1)) / max_verts_per_patch;
+   if (threads_per_tg > wave_size &&
+       (wave_size - threads_per_tg % wave_size >= MAX2(num_threads_per_patch, 8)))
+      num_patches = (threads_per_tg & ~(wave_size - 1)) / num_threads_per_patch;
 
    if (info->gfx_level == GFX6) {
       /* GFX6 bug workaround, related to power management. Limit LS-HS
        * threadgroups to only one wave.
        */
-      const unsigned one_wave = wave_size / max_verts_per_patch;
+      const unsigned one_wave = wave_size / num_threads_per_patch;
       num_patches = MIN2(num_patches, one_wave);
    }
 
@@ -1030,10 +1020,23 @@ uint32_t ac_apply_cu_en(uint32_t value, uint32_t clear_mask, unsigned value_shif
           (((cu_en & spi_cu_en) << cu_en_shift) & cu_en_mask);
 }
 
-/* Return the register value and tune bytes_per_wave to increase scratch performance. */
-void ac_get_scratch_tmpring_size(const struct radeon_info *info,
-                                 unsigned bytes_per_wave, unsigned *max_seen_bytes_per_wave,
-                                 uint32_t *tmpring_size)
+/* Compute the optimal scratch wavesize. */
+uint32_t
+ac_compute_scratch_wavesize(const struct radeon_info *info, uint32_t bytes_per_wave)
+{
+   /* Add 1 scratch item to make the number of items odd. This should improve
+    * scratch performance by more randomly distributing scratch waves among
+    * memory channels.
+    */
+   if (bytes_per_wave)
+      bytes_per_wave |= info->scratch_wavesize_granularity;
+
+   return bytes_per_wave;
+}
+
+/* Return the scratch register value. */
+void ac_get_scratch_tmpring_size(const struct radeon_info *info, unsigned num_scratch_waves,
+                                 unsigned bytes_per_wave, uint32_t *tmpring_size)
 {
    /* SPI_TMPRING_SIZE and COMPUTE_TMPRING_SIZE are essentially scratch buffer descriptors.
     * WAVES means NUM_RECORDS. WAVESIZE is the size of each element, meaning STRIDE.
@@ -1048,28 +1051,16 @@ void ac_get_scratch_tmpring_size(const struct radeon_info *info,
     *
     * Shaders with SCRATCH_EN=0 don't allocate scratch space.
     */
-   const unsigned size_shift = info->gfx_level >= GFX11 ? 8 : 10;
-   const unsigned min_size_per_wave = BITFIELD_BIT(size_shift);
 
-   /* The LLVM shader backend should be reporting aligned scratch_sizes. */
-   assert((bytes_per_wave & BITFIELD_MASK(size_shift)) == 0 &&
+   /* The compiler shader backend should be reporting aligned scratch_sizes. */
+   assert((bytes_per_wave & BITFIELD_MASK(info->scratch_wavesize_granularity_shift)) == 0 &&
           "scratch size per wave should be aligned");
 
-   /* Add 1 scratch item to make the number of items odd. This should improve scratch
-    * performance by more randomly distributing scratch waves among memory channels.
-    */
-   if (bytes_per_wave)
-      bytes_per_wave |= min_size_per_wave;
-
-   *max_seen_bytes_per_wave = MAX2(*max_seen_bytes_per_wave, bytes_per_wave);
-
-   unsigned max_scratch_waves = info->max_scratch_waves;
    if (info->gfx_level >= GFX11)
-      max_scratch_waves /= info->max_se; /* WAVES is per SE */
+      num_scratch_waves /= info->max_se; /* WAVES is per SE */
 
-   /* TODO: We could decrease WAVES to make the whole buffer fit into the infinity cache. */
-   *tmpring_size = S_0286E8_WAVES(max_scratch_waves) |
-                   S_0286E8_WAVESIZE(*max_seen_bytes_per_wave >> size_shift);
+   *tmpring_size = S_0286E8_WAVES(num_scratch_waves) |
+                   S_0286E8_WAVESIZE(bytes_per_wave >> info->scratch_wavesize_granularity_shift);
 }
 
 /* Convert chip-agnostic memory access flags into hw-specific cache flags.
diff --git a/src/amd/common/ac_shader_util.h b/src/amd/common/ac_shader_util.h
index 35759fb60f2..d1936ce2540 100644
--- a/src/amd/common/ac_shader_util.h
+++ b/src/amd/common/ac_shader_util.h
@@ -301,9 +301,10 @@ uint32_t ac_compute_num_tess_patches(const struct radeon_info *info, uint32_t nu
 uint32_t ac_apply_cu_en(uint32_t value, uint32_t clear_mask, unsigned value_shift,
                         const struct radeon_info *info);
 
-void ac_get_scratch_tmpring_size(const struct radeon_info *info,
-                                 unsigned bytes_per_wave, unsigned *max_seen_bytes_per_wave,
-                                 uint32_t *tmpring_size);
+uint32_t ac_compute_scratch_wavesize(const struct radeon_info *info, uint32_t bytes_per_wave);
+
+void ac_get_scratch_tmpring_size(const struct radeon_info *info, unsigned num_scratch_waves,
+                                 unsigned bytes_per_wave, uint32_t *tmpring_size);
 
 unsigned
 ac_ngg_nogs_get_pervertex_lds_size(gl_shader_stage stage,
diff --git a/src/amd/common/amd_family.h b/src/amd/common/amd_family.h
index f345d024609..767a3b96303 100644
--- a/src/amd/common/amd_family.h
+++ b/src/amd/common/amd_family.h
@@ -255,6 +255,24 @@ enum sdma_version {
    SDMA_7_0 = SDMA_VERSION_VALUE(7, 0),
 };
 
+/* The enum values match PAL so they can be written into RRA files. */
+enum rt_version {
+   RT_NONE = 0x0,
+
+   RT_1_0 = 0x1,
+
+   /* GFX10.3 */
+   RT_1_1 = 0x2,
+
+   /* GFX11 */
+   RT_2_0 = 0x3,
+
+   RT_3_0 = 0x4,
+
+   /* GFX12 */
+   RT_3_1 = 0x6,
+};
+
 const char *ac_get_family_name(enum radeon_family family);
 enum amd_gfx_level ac_get_gfx_level(enum radeon_family family);
 const char *ac_get_llvm_processor_name(enum radeon_family family);
diff --git a/src/amd/common/nir/ac_nir.c b/src/amd/common/nir/ac_nir.c
index 17a255b0521..c74f9a21c83 100644
--- a/src/amd/common/nir/ac_nir.c
+++ b/src/amd/common/nir/ac_nir.c
@@ -62,6 +62,7 @@ void ac_nir_set_options(struct radeon_info *info, bool use_llvm,
    options->lower_iadd_sat = info->gfx_level <= GFX8;
    options->lower_hadd = true;
    options->lower_mul_32x16 = true;
+   options->lower_bfloat16_conversions = true,
    options->has_bfe = true;
    options->has_bfm = true;
    options->has_bitfield_select = true;
@@ -84,6 +85,7 @@ void ac_nir_set_options(struct radeon_info *info, bool use_llvm,
    options->has_msad = true;
    options->has_shfr32 = true;
    options->has_mul24_relaxed = true;
+   options->has_bfdot2_bfadd = true;
    options->lower_int64_options = nir_lower_imul64 | nir_lower_imul_high64 | nir_lower_imul_2x32_64 | nir_lower_divmod64 |
                                   nir_lower_minmax64 | nir_lower_iabs64 | nir_lower_iadd_sat64 | nir_lower_conv64;
    options->divergence_analysis_options = nir_divergence_view_index_uniform;
diff --git a/src/amd/common/nir/ac_nir.h b/src/amd/common/nir/ac_nir.h
index 1e4e13fae03..e78f43bfcaf 100644
--- a/src/amd/common/nir/ac_nir.h
+++ b/src/amd/common/nir/ac_nir.h
@@ -118,7 +118,8 @@ ac_nir_lower_tes_inputs_to_mem(nir_shader *shader,
                                ac_nir_map_io_driver_location map);
 
 void
-ac_nir_compute_tess_wg_info(const struct radeon_info *info, const struct shader_info *tcs_info,
+ac_nir_compute_tess_wg_info(const struct radeon_info *info, uint64_t outputs_read, uint64_t outputs_written,
+                            uint32_t patch_outputs_read, uint32_t patch_outputs_written, unsigned tcs_vertices_out,
                             unsigned wave_size, bool tess_uses_primid, bool all_invocations_define_tess_levels,
                             unsigned num_tcs_input_cp, unsigned lds_input_vertex_size,
                             unsigned num_mem_tcs_outputs, unsigned num_mem_tcs_patch_outputs,
diff --git a/src/amd/common/nir/ac_nir_lower_tess_io_to_mem.c b/src/amd/common/nir/ac_nir_lower_tess_io_to_mem.c
index 10d752b0c45..7ac41c2b1be 100644
--- a/src/amd/common/nir/ac_nir_lower_tess_io_to_mem.c
+++ b/src/amd/common/nir/ac_nir_lower_tess_io_to_mem.c
@@ -595,6 +595,9 @@ lower_hs_output_store(nir_builder *b,
             ac_nir_store_var_components(b, st->tcs_tess_level_outer, store_val,
                                         component, write_mask);
       }
+
+      if (semantics.no_varying)
+         st->tes_inputs_read &= ~BITFIELD64_BIT(semantics.location);
    }
 
    return NIR_LOWER_INSTR_PROGRESS_REPLACE;
@@ -1289,19 +1292,20 @@ ac_nir_lower_tes_inputs_to_mem(nir_shader *shader,
 }
 
 void
-ac_nir_compute_tess_wg_info(const struct radeon_info *info, const struct shader_info *tcs_info,
+ac_nir_compute_tess_wg_info(const struct radeon_info *info, uint64_t outputs_read, uint64_t outputs_written,
+                            uint32_t patch_outputs_read, uint32_t patch_outputs_written, unsigned tcs_vertices_out,
                             unsigned wave_size, bool tess_uses_primid, bool all_invocations_define_tess_levels,
                             unsigned num_tcs_input_cp, unsigned lds_input_vertex_size,
                             unsigned num_mem_tcs_outputs, unsigned num_mem_tcs_patch_outputs,
                             unsigned *num_patches_per_wg, unsigned *hw_lds_size)
 {
-   unsigned num_tcs_output_cp = tcs_info->tess.tcs_vertices_out;
+   unsigned num_tcs_output_cp = tcs_vertices_out;
    unsigned lds_output_vertex_size =
-      util_bitcount64(tcs_info->outputs_read & tcs_info->outputs_written & ~TESS_LVL_MASK) * 16;
+      util_bitcount64(outputs_read & outputs_written & ~TESS_LVL_MASK) * 16;
    unsigned lds_perpatch_output_patch_size =
       (util_bitcount64(all_invocations_define_tess_levels ?
-                          0 : tcs_info->outputs_written & TESS_LVL_MASK) +
-       util_bitcount(tcs_info->patch_outputs_read & tcs_info->patch_outputs_written)) * 16;
+                          0 : outputs_written & TESS_LVL_MASK) +
+       util_bitcount(patch_outputs_read & patch_outputs_written)) * 16;
 
    unsigned lds_per_patch = num_tcs_input_cp * lds_input_vertex_size +
                             num_tcs_output_cp * lds_output_vertex_size +
@@ -1310,21 +1314,22 @@ ac_nir_compute_tess_wg_info(const struct radeon_info *info, const struct shader_
    unsigned num_patches = ac_compute_num_tess_patches(info, num_tcs_input_cp, num_tcs_output_cp, mem_per_patch,
                                                       lds_per_patch, wave_size, tess_uses_primid);
    unsigned lds_size = lds_per_patch * num_patches;
-   unsigned mem_size = mem_per_patch * num_patches;
 
    /* The first vec4 is reserved for the tf0/1 shader message group vote. */
    if (info->gfx_level >= GFX11)
       lds_size += AC_HS_MSG_VOTE_LDS_BYTES;
 
-   /* SPI_SHADER_PGM_RSRC2_HS.LDS_SIZE specifies the allocation size for both LDS and the HS
-    * offchip ring buffer. LDS is only used for TCS inputs (with cross-invocation or indirect
-    * access only or if TCS in/out vertex counts are different) and for TCS outputs that are read
-    * (including tess level outputs if they need to be re-read in invocation 0), while the HS ring
-    * buffer is only used for TCS outputs consumed by TES.
+   /* SPI_SHADER_PGM_RSRC2_HS.LDS_SIZE specifies the allocation size only for LDS. The HS offchip
+    * ring buffer always uses a fixed allocation size per workgroup determined by
+    * info->hs_offchip_workgroup_dw_size.
+    *
+    * LDS is only used for TCS inputs (with cross-invocation or indirect access only or if TCS in/out
+    * vertex counts are different) and for TCS outputs that are read (including tess level outputs
+    * if they need to be re-read in invocation 0), while the HS ring buffer is only used for TCS
+    * outputs consumed by TES.
     */
-   unsigned merged_size = MAX2(lds_size, mem_size);
-   assert(merged_size <= (info->gfx_level >= GFX9 ? 65536 : 32768));
+   assert(lds_size <= (info->gfx_level >= GFX9 ? 65536 : 32768));
 
    *num_patches_per_wg = num_patches;
-   *hw_lds_size = DIV_ROUND_UP(merged_size, info->lds_encode_granularity);
+   *hw_lds_size = DIV_ROUND_UP(lds_size, info->lds_encode_granularity);
 }
diff --git a/src/amd/common/nir/ac_nir_meta_cs_blit.c b/src/amd/common/nir/ac_nir_meta_cs_blit.c
index 26b240a766b..174ebde9504 100644
--- a/src/amd/common/nir/ac_nir_meta_cs_blit.c
+++ b/src/amd/common/nir/ac_nir_meta_cs_blit.c
@@ -143,6 +143,11 @@ ac_create_blit_cs(const struct ac_cs_blit_options *options, const union ac_cs_bl
 
    nir_builder b = nir_builder_init_simple_shader(MESA_SHADER_COMPUTE, options->nir_options,
                                                   "blit_non_scaled_cs");
+   blake3_hasher blake3;
+   _mesa_blake3_init(&blake3);
+   _mesa_blake3_update(&blake3, b.shader->info.name, strlen(b.shader->info.name));
+   _mesa_blake3_update(&blake3, key, sizeof(*key));
+   _mesa_blake3_final(&blake3, b.shader->info.source_blake3);
    b.shader->info.use_aco_amd = options->use_aco ||
                                 (key->use_aco && aco_is_gpu_supported(options->info));
    b.shader->info.num_images = key->is_clear ? 1 : 2;
diff --git a/src/amd/compiler/aco_assembler.cpp b/src/amd/compiler/aco_assembler.cpp
index 5d12fb5000e..a80ea2af378 100644
--- a/src/amd/compiler/aco_assembler.cpp
+++ b/src/amd/compiler/aco_assembler.cpp
@@ -832,13 +832,13 @@ emit_mimg_instruction_gfx12(asm_context& ctx, std::vector<uint32_t>& out, const
    uint8_t vaddr[5] = {0, 0, 0, 0, 0};
    for (unsigned i = 3; i < instr->operands.size(); i++)
       vaddr[i - 3] = reg(ctx, instr->operands[i], 8);
-   unsigned num_vaddr = instr->operands.size() - 3;
-   for (unsigned i = 0; i < MIN2(instr->operands.back().size() - 1, 5 - num_vaddr); i++)
+   int num_vaddr = instr->operands.size() - 3;
+   for (int i = 0; i < (int)MIN2(instr->operands.back().size() - 1, ARRAY_SIZE(vaddr) - num_vaddr); i++)
       vaddr[num_vaddr + i] = reg(ctx, instr->operands.back(), 8) + i + 1;
 
    encoding = 0;
    if (!instr->definitions.empty())
-      encoding |= reg(ctx, instr->definitions[0], 8); /* VDATA */
+      encoding |= reg(ctx, instr->definitions.back(), 8); /* VDATA */
    else if (!instr->operands[2].isUndefined())
       encoding |= reg(ctx, instr->operands[2], 8); /* VDATA */
    encoding |= reg(ctx, instr->operands[0]) << 9;  /* T# (resource) */
diff --git a/src/amd/compiler/aco_form_hard_clauses.cpp b/src/amd/compiler/aco_form_hard_clauses.cpp
index 73dc3cd63e1..f37168406ff 100644
--- a/src/amd/compiler/aco_form_hard_clauses.cpp
+++ b/src/amd/compiler/aco_form_hard_clauses.cpp
@@ -53,7 +53,9 @@ get_type(Program* program, aco_ptr<Instruction>& instr)
       if (instr->isMIMG()) {
          switch (instr->opcode) {
          case aco_opcode::image_bvh_intersect_ray:
-         case aco_opcode::image_bvh64_intersect_ray: return clause_bvh;
+         case aco_opcode::image_bvh64_intersect_ray:
+         case aco_opcode::image_bvh_dual_intersect_ray:
+         case aco_opcode::image_bvh8_intersect_ray: return clause_bvh;
          case aco_opcode::image_atomic_swap:
          case aco_opcode::image_atomic_cmpswap:
          case aco_opcode::image_atomic_add:
diff --git a/src/amd/compiler/aco_insert_NOPs.cpp b/src/amd/compiler/aco_insert_NOPs.cpp
index a2142444110..831369649e1 100644
--- a/src/amd/compiler/aco_insert_NOPs.cpp
+++ b/src/amd/compiler/aco_insert_NOPs.cpp
@@ -1395,29 +1395,17 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
    }
 
    depctr_wait wait = parse_depctr_wait(instr.get());
-   unsigned va_vdst = wait.va_vdst;
-   unsigned vm_vsrc = 7;
-   unsigned sa_sdst = 1;
-
-   if (debug_flags & DEBUG_FORCE_WAITDEPS) {
-      bld.sopp(aco_opcode::s_waitcnt_depctr, 0x0000);
-      va_vdst = 0;
-      vm_vsrc = 0;
-      sa_sdst = 0;
-   } else if (instr->opcode == aco_opcode::s_waitcnt_depctr) {
-      /* va_vdst already obtained through parse_depctr_wait(). */
-      vm_vsrc = (instr->salu().imm >> 2) & 0x7;
-      sa_sdst = instr->salu().imm & 0x1;
-   } else if (instr->isLDSDIR() && state.program->gfx_level >= GFX12) {
-      vm_vsrc = instr->ldsdir().wait_vsrc ? 7 : 0;
-   }
+   if (debug_flags & DEBUG_FORCE_WAITDEPS)
+      wait = parse_depctr_wait(bld.sopp(aco_opcode::s_waitcnt_depctr, 0x0000));
+   else if (instr->isLDSDIR() && state.program->gfx_level >= GFX12)
+      wait.vm_vsrc = instr->ldsdir().wait_vsrc ? 7 : 0;
 
    if (instr->isLDSDIR()) {
       unsigned count = handle_lds_direct_valu_hazard(state, instr);
       LDSDIR_instruction* ldsdir = &instr->ldsdir();
-      if (count < va_vdst) {
+      if (count < wait.va_vdst) {
          ldsdir->wait_vdst = MIN2(ldsdir->wait_vdst, count);
-         va_vdst = MIN2(va_vdst, count);
+         wait.va_vdst = MIN2(wait.va_vdst, count);
       }
    }
 
@@ -1425,7 +1413,7 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
     * VALU reads VGPR written by transcendental instruction without 6+ VALU or 2+ transcendental
     * in-between.
     */
-   if (state.program->gfx_level < GFX11_5 && va_vdst > 0 && instr->isVALU()) {
+   if (state.program->gfx_level < GFX11_5 && wait.va_vdst > 0 && instr->isVALU()) {
       uint8_t num_valu = 15;
       uint8_t num_trans = 15;
       for (Operand& op : instr->operands) {
@@ -1439,14 +1427,14 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
       }
       if (num_trans <= 1 && num_valu <= 5) {
          bld.sopp(aco_opcode::s_waitcnt_depctr, 0x0fff);
-         va_vdst = 0;
+         wait.va_vdst = 0;
       }
    }
 
-   if (va_vdst > 0 && state.program->gfx_level < GFX12 &&
+   if (wait.va_vdst > 0 && state.program->gfx_level < GFX12 &&
        handle_valu_partial_forwarding_hazard(state, instr)) {
       bld.sopp(aco_opcode::s_waitcnt_depctr, 0x0fff);
-      va_vdst = 0;
+      wait.va_vdst = 0;
    }
 
    if (state.program->gfx_level < GFX12) {
@@ -1467,7 +1455,7 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
                /* s_waitcnt_depctr on sa_sdst */
                if (ctx.sgpr_read_by_valu_as_lanemask_then_wr_by_salu[reg]) {
                   imm &= 0xfffe;
-                  sa_sdst = 0;
+                  wait.sa_sdst = 0;
                }
 
                /* s_waitcnt_depctr on va_sdst (if non-VCC SGPR) or va_vcc (if VCC SGPR) */
@@ -1486,13 +1474,13 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
             bld.sopp(aco_opcode::s_waitcnt_depctr, imm);
       }
 
-      if (va_vdst == 0) {
+      if (wait.va_vdst == 0) {
          ctx.valu_since_wr_by_trans.reset();
          ctx.trans_since_wr_by_trans.reset();
          ctx.sgpr_read_by_valu_as_lanemask_then_wr_by_valu.reset();
       }
 
-      if (sa_sdst == 0)
+      if (wait.sa_sdst == 0)
          ctx.sgpr_read_by_valu_as_lanemask_then_wr_by_salu.reset();
 
       if (wait.va_sdst == 0) {
@@ -1579,7 +1567,7 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
                PhysReg reg = op.physReg().advance(i * 4);
                if (ctx.sgpr_read_by_valu_then_wr_by_salu.get(reg) < expiry_count) {
                   imm &= 0xfffe;
-                  sa_sdst = 0;
+                  wait.sa_sdst = 0;
                }
                if (instr->isVALU()) {
                   ctx.sgpr_read_by_valu.set(reg / 2);
@@ -1601,7 +1589,7 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
             bld.sopp(aco_opcode::s_waitcnt_depctr, imm);
       }
 
-      if (sa_sdst == 0)
+      if (wait.sa_sdst == 0)
          ctx.sgpr_read_by_valu_then_wr_by_salu.reset();
       else if (instr->isSALU() && !instr->isSOPP())
          ctx.sgpr_read_by_valu_then_wr_by_salu.inc();
@@ -1662,7 +1650,7 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
          fill_vgpr_bitset(ctx.vgpr_used_by_ds, op.physReg(), op.bytes());
    }
    wait_imm imm;
-   if (instr->isVALU() || instr->isEXP() || vm_vsrc == 0) {
+   if (instr->isVALU() || instr->isEXP() || wait.vm_vsrc == 0) {
       ctx.vgpr_used_by_vmem_load.reset();
       ctx.vgpr_used_by_vmem_sample.reset();
       ctx.vgpr_used_by_vmem_bvh.reset();
@@ -1700,7 +1688,8 @@ handle_instruction_gfx11(State& state, NOP_ctx_gfx11& ctx, aco_ptr<Instruction>&
 
    /* WMMA Hazards */
    if (instr_info.classes[(int)instr->opcode] == instr_class::wmma) {
-      assert(instr->operands.back().regClass() == instr->definitions[0].regClass());
+      assert(instr->operands.back().isConstant() ||
+             instr->operands.back().regClass() == instr->definitions[0].regClass());
 
       bool is_swmma = instr->operands.size() == 4;
       if (test_vgpr_bitset(ctx.vgpr_written_by_wmma, instr->operands[0]) ||
diff --git a/src/amd/compiler/aco_insert_exec_mask.cpp b/src/amd/compiler/aco_insert_exec_mask.cpp
index 10a4c9a9548..e3e32ce5666 100644
--- a/src/amd/compiler/aco_insert_exec_mask.cpp
+++ b/src/amd/compiler/aco_insert_exec_mask.cpp
@@ -363,9 +363,10 @@ add_coupling_code(exec_ctx& ctx, Block* block, std::vector<aco_ptr<Instruction>>
    }
 
    if (ctx.handle_wqm) {
-      if (block->kind & block_kind_top_level && ctx.info[idx].exec.size() == 2) {
+      if (ctx.info[idx].exec.size() == 2) {
          /* End WQM handling if not needed anymore */
          if (block->instructions[i]->opcode == aco_opcode::p_end_wqm) {
+            assert(block->kind & block_kind_top_level);
             ctx.info[idx].exec.back().type |= mask_type_global;
             transition_to_Exact(ctx, bld, idx);
             ctx.handle_wqm = false;
diff --git a/src/amd/compiler/aco_insert_waitcnt.cpp b/src/amd/compiler/aco_insert_waitcnt.cpp
index 7aabe615359..6916a0579e7 100644
--- a/src/amd/compiler/aco_insert_waitcnt.cpp
+++ b/src/amd/compiler/aco_insert_waitcnt.cpp
@@ -650,8 +650,8 @@ gen(Instruction* instr, wait_ctx& ctx)
 
       update_counters(ctx, ev, get_sync_info(instr));
 
-      if (!instr->definitions.empty())
-         insert_wait_entry(ctx, instr->definitions[0], ev, type);
+      for (auto& definition : instr->definitions)
+         insert_wait_entry(ctx, definition, ev, type);
 
       if (ctx.gfx_level == GFX6 && instr->format != Format::MIMG && instr->operands.size() == 4) {
          update_counters(ctx, event_vmem_gpr_lock);
diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 27a0fda6036..d6ae381effe 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -598,7 +598,7 @@ get_alu_src(struct isel_context* ctx, nir_alu_src src, unsigned size = 1)
          elems[i] = emit_extract_vector(ctx, vec, src.swizzle[i], elem_rc);
          vec_instr->operands[i] = Operand{elems[i]};
       }
-      Temp dst = ctx->program->allocateTmp(RegClass(vec.type(), elem_size * size / 4));
+      Temp dst = ctx->program->allocateTmp(RegClass::get(vec.type(), elem_size * size));
       vec_instr->definitions[0] = Definition(dst);
       ctx->block->instructions.emplace_back(std::move(vec_instr));
       ctx->allocated_vec.emplace(dst.id(), elems);
@@ -1732,6 +1732,9 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       } else if (dst.regClass() == v1 && instr->def.bit_size == 16) {
          emit_vop3p_instruction(ctx, instr, aco_opcode::v_pk_add_u16, dst);
          break;
+      } else if (dst.regClass() == s2 && ctx->program->gfx_level >= GFX12) {
+         emit_sop2_instruction(ctx, instr, aco_opcode::s_add_u64, dst, false);
+         break;
       }
 
       Temp src0 = get_alu_src(ctx, instr->src[0]);
@@ -1931,6 +1934,9 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       } else if (dst.regClass() == v1 && instr->def.bit_size == 16) {
          emit_vop3p_instruction(ctx, instr, aco_opcode::v_pk_sub_u16, dst);
          break;
+      } else if (dst.regClass() == s2 && ctx->program->gfx_level >= GFX12) {
+         emit_sop2_instruction(ctx, instr, aco_opcode::s_sub_u64, dst, false);
+         break;
       }
 
       Temp src0 = get_alu_src(ctx, instr->src[0]);
@@ -2429,6 +2435,14 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       emit_idot_instruction(ctx, instr, aco_opcode::v_dot2_u32_u16, dst, true);
       break;
    }
+   case nir_op_bfdot2_bfadd: {
+      Temp src0 = as_vgpr(ctx, get_alu_src(ctx, instr->src[0], 2));
+      Temp src1 = as_vgpr(ctx, get_alu_src(ctx, instr->src[1], 2));
+      Temp src2 = get_alu_src(ctx, instr->src[2], 1);
+
+      bld.vop3(aco_opcode::v_dot2_bf16_bf16, Definition(dst), src0, src1, src2);
+      break;
+   }
    case nir_op_cube_amd: {
       Temp in = get_alu_src(ctx, instr->src[0], 3);
       Temp src[3] = {emit_extract_vector(ctx, in, 0, v1), emit_extract_vector(ctx, in, 1, v1),
@@ -2983,6 +2997,35 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       bld.vop1(aco_opcode::v_cvt_f64_f32, Definition(dst), src);
       break;
    }
+   case nir_op_f2e4m3fn: {
+      Operand src0, src1;
+      if (instr->def.num_components == 2) {
+         Temp src = get_ssa_temp(ctx, instr->src[0].src.ssa);
+         RegClass rc = RegClass(src.regClass().type(), 1);
+         src0 = Operand(emit_extract_vector(ctx, src, instr->src[0].swizzle[0], rc));
+         src1 = Operand(emit_extract_vector(ctx, src, instr->src[0].swizzle[1], rc));
+      } else {
+         assert(instr->def.num_components == 1);
+         src0 = Operand(get_alu_src(ctx, instr->src[0]));
+         src1 = Operand::c32(0);
+      }
+      bld.vop3(aco_opcode::v_cvt_pk_fp8_f32, Definition(dst), src0, src1);
+      if (instr->def.num_components == 2)
+         emit_split_vector(ctx, dst, 2);
+      break;
+   }
+   case nir_op_e4m3fn2f: {
+      if (instr->def.num_components == 2) {
+         Temp src = get_alu_src(ctx, instr->src[0], 2);
+         bld.vop1(aco_opcode::v_cvt_pk_f32_fp8, Definition(dst), src);
+         emit_split_vector(ctx, dst, 2);
+      } else {
+         Temp src = get_alu_src(ctx, instr->src[0]);
+         assert(instr->def.num_components == 1);
+         bld.vop1(aco_opcode::v_cvt_f32_fp8, Definition(dst), src);
+      }
+      break;
+   }
    case nir_op_i2f16: {
       Temp src = get_alu_src(ctx, instr->src[0]);
       const unsigned input_size = instr->src[0].src.ssa->bit_size;
@@ -4777,7 +4820,7 @@ lower_global_address(Builder& bld, uint32_t offset_in, Temp* address_inout,
    if (bld.program->gfx_level >= GFX9)
       max_const_offset_plus_one = bld.program->dev.scratch_global_offset_max;
    else if (bld.program->gfx_level == GFX6)
-      max_const_offset_plus_one = 4096; /* MUBUF has a 12-bit unsigned offset field */
+      max_const_offset_plus_one = bld.program->dev.buf_offset_max + 1;
    uint64_t excess_offset = const_offset - (const_offset % max_const_offset_plus_one);
    const_offset %= max_const_offset_plus_one;
 
@@ -5291,9 +5334,10 @@ create_vec_from_array(isel_context* ctx, Temp arr[], unsigned cnt, RegType reg_t
 inline unsigned
 resolve_excess_vmem_const_offset(Builder& bld, Temp& voffset, unsigned const_offset)
 {
-   if (const_offset >= 4096) {
-      unsigned excess_const_offset = const_offset / 4096u * 4096u;
-      const_offset %= 4096u;
+   uint32_t limit = bld.program->dev.buf_offset_max + 1;
+   if (const_offset >= limit) {
+      unsigned excess_const_offset = const_offset / limit * limit;
+      const_offset %= limit;
 
       if (!voffset.id())
          voffset = bld.copy(bld.def(v1), Operand::c32(excess_const_offset));
@@ -5865,8 +5909,8 @@ image_type_to_components_count(enum glsl_sampler_dim dim, bool array)
 }
 
 static MIMG_instruction*
-emit_mimg(Builder& bld, aco_opcode op, Temp dst, Temp rsrc, Operand samp, std::vector<Temp> coords,
-          Operand vdata = Operand(v1))
+emit_mimg(Builder& bld, aco_opcode op, std::vector<Temp> dsts, Temp rsrc, Operand samp,
+          std::vector<Temp> coords, Operand vdata = Operand(v1))
 {
    bool is_vsample = !samp.isUndefined() || op == aco_opcode::image_msaa_load;
 
@@ -5909,11 +5953,9 @@ emit_mimg(Builder& bld, aco_opcode op, Temp dst, Temp rsrc, Operand samp, std::v
       coords.resize(nsa_size + 1);
    }
 
-   bool has_dst = dst.id() != 0;
-
-   aco_ptr<Instruction> mimg{create_instruction(op, Format::MIMG, 3 + coords.size(), has_dst)};
-   if (has_dst)
-      mimg->definitions[0] = Definition(dst);
+   aco_ptr<Instruction> mimg{create_instruction(op, Format::MIMG, 3 + coords.size(), dsts.size())};
+   for (unsigned i = 0; i < dsts.size(); ++i)
+      mimg->definitions[i] = Definition(dsts[i]);
    mimg->operands[0] = Operand(rsrc);
    mimg->operands[1] = samp;
    mimg->operands[2] = vdata;
@@ -5955,7 +5997,7 @@ visit_bvh64_intersect_ray_amd(isel_context* ctx, nir_intrinsic_instr* instr)
    }
 
    MIMG_instruction* mimg =
-      emit_mimg(bld, aco_opcode::image_bvh64_intersect_ray, dst, resource, Operand(s4), args);
+      emit_mimg(bld, aco_opcode::image_bvh64_intersect_ray, {dst}, resource, Operand(s4), args);
    mimg->dim = ac_image_1d;
    mimg->dmask = 0xf;
    mimg->unrm = true;
@@ -5964,6 +6006,38 @@ visit_bvh64_intersect_ray_amd(isel_context* ctx, nir_intrinsic_instr* instr)
    emit_split_vector(ctx, dst, instr->def.num_components);
 }
 
+void
+visit_bvh8_intersect_ray_amd(isel_context* ctx, nir_intrinsic_instr* instr)
+{
+   Builder bld(ctx->program, ctx->block);
+   Temp dst = get_ssa_temp(ctx, &instr->def);
+   Temp resource = get_ssa_temp(ctx, instr->src[0].ssa);
+   Temp bvh_base = as_vgpr(ctx, get_ssa_temp(ctx, instr->src[1].ssa));
+   Temp cull_mask = as_vgpr(ctx, get_ssa_temp(ctx, instr->src[2].ssa));
+   Temp tmax = as_vgpr(ctx, get_ssa_temp(ctx, instr->src[3].ssa));
+   Temp origin = as_vgpr(ctx, get_ssa_temp(ctx, instr->src[4].ssa));
+   Temp dir = as_vgpr(ctx, get_ssa_temp(ctx, instr->src[5].ssa));
+   Temp node_id = as_vgpr(ctx, get_ssa_temp(ctx, instr->src[6].ssa));
+
+   Temp result = bld.tmp(v10);
+   Temp new_origin = bld.tmp(v3);
+   Temp new_dir = bld.tmp(v3);
+
+   std::vector<Temp> args = {bvh_base,
+                             bld.pseudo(aco_opcode::p_create_vector, bld.def(v2), tmax, cull_mask),
+                             origin, dir, node_id};
+
+   MIMG_instruction* mimg = emit_mimg(bld, aco_opcode::image_bvh8_intersect_ray,
+                                      {new_origin, new_dir, result}, resource, Operand(s4), args);
+   mimg->dim = ac_image_1d;
+   mimg->dmask = 0xf;
+   mimg->unrm = true;
+   mimg->r128 = true;
+
+   bld.pseudo(aco_opcode::p_create_vector, Definition(dst), Operand(result), Operand(new_origin),
+              Operand(new_dir));
+}
+
 static std::vector<Temp>
 get_image_coords(isel_context* ctx, const nir_intrinsic_instr* instr)
 {
@@ -6172,7 +6246,7 @@ visit_image_load(isel_context* ctx, nir_intrinsic_instr* instr)
       }
 
       Operand vdata = is_sparse ? emit_tfe_init(bld, tmp) : Operand(v1);
-      MIMG_instruction* load = emit_mimg(bld, opcode, tmp, resource, Operand(s4), coords, vdata);
+      MIMG_instruction* load = emit_mimg(bld, opcode, {tmp}, resource, Operand(s4), coords, vdata);
       load->cache = get_cache_flags(ctx, nir_intrinsic_access(instr) | ACCESS_TYPE_LOAD);
       load->a16 = instr->src[1].ssa->bit_size == 16;
       load->d16 = d16;
@@ -6313,7 +6387,7 @@ visit_image_store(isel_context* ctx, nir_intrinsic_instr* instr)
    aco_opcode opcode = level_zero ? aco_opcode::image_store : aco_opcode::image_store_mip;
 
    MIMG_instruction* store =
-      emit_mimg(bld, opcode, Temp(0, v1), resource, Operand(s4), coords, Operand(data));
+      emit_mimg(bld, opcode, {}, resource, Operand(s4), coords, Operand(data));
    store->cache = cache;
    store->a16 = instr->src[1].ssa->bit_size == 16;
    store->d16 = d16;
@@ -6466,9 +6540,11 @@ visit_image_atomic(isel_context* ctx, nir_intrinsic_instr* instr)
 
    std::vector<Temp> coords = get_image_coords(ctx, instr);
    Temp resource = bld.as_uniform(get_ssa_temp(ctx, instr->src[0].ssa));
-   Temp tmp = return_previous ? (cmpswap ? bld.tmp(data.regClass()) : dst) : Temp(0, v1);
+   std::vector<Temp> tmps;
+   if (return_previous)
+      tmps = {(cmpswap ? bld.tmp(data.regClass()) : dst)};
    MIMG_instruction* mimg =
-      emit_mimg(bld, image_op, tmp, resource, Operand(s4), coords, Operand(data));
+      emit_mimg(bld, image_op, tmps, resource, Operand(s4), coords, Operand(data));
    mimg->cache = get_atomic_cache_flags(ctx, return_previous);
    mimg->dmask = (1 << data.size()) - 1;
    mimg->a16 = instr->src[1].ssa->bit_size == 16;
@@ -6480,7 +6556,7 @@ visit_image_atomic(isel_context* ctx, nir_intrinsic_instr* instr)
    mimg->sync = sync;
    ctx->program->needs_exact = true;
    if (return_previous && cmpswap)
-      bld.pseudo(aco_opcode::p_extract_vector, Definition(dst), tmp, Operand::zero());
+      bld.pseudo(aco_opcode::p_extract_vector, Definition(dst), tmps[0], Operand::zero());
    return;
 }
 
@@ -6635,7 +6711,9 @@ visit_load_global(isel_context* ctx, nir_intrinsic_instr* instr)
          info.resource = bld.as_uniform(info.resource);
       info.offset = Operand(bld.as_uniform(info.offset));
       info.cache = get_cache_flags(ctx, access | ACCESS_TYPE_SMEM);
-      emit_load(ctx, bld, info, smem_load_params);
+      EmitLoadParameters params = smem_load_params;
+      params.max_const_offset_plus_one = ctx->program->dev.smem_offset_max + 1;
+      emit_load(ctx, bld, info, params);
    } else {
       EmitLoadParameters params = global_load_params;
       info.cache = get_cache_flags(ctx, access);
@@ -6950,14 +7028,18 @@ visit_load_buffer(isel_context* ctx, nir_intrinsic_instr* intrin)
       info.component_stride = can_split ? vtx_info->chan_byte_size : 0;
       info.split_by_component_stride = false;
 
-      emit_load(ctx, bld, info, mtbuf_load_params);
+      EmitLoadParameters params = mtbuf_load_params;
+      params.max_const_offset_plus_one = ctx->program->dev.buf_offset_max + 1;
+      emit_load(ctx, bld, info, params);
    } else {
       assert(intrin->intrinsic == nir_intrinsic_load_buffer_amd);
 
       if (nir_intrinsic_access(intrin) & ACCESS_USES_FORMAT_AMD) {
          assert(!swizzled);
 
-         emit_load(ctx, bld, info, mubuf_load_format_params);
+         EmitLoadParameters params = mubuf_load_format_params;
+         params.max_const_offset_plus_one = ctx->program->dev.buf_offset_max + 1;
+         emit_load(ctx, bld, info, params);
       } else {
          const unsigned swizzle_element_size =
             swizzled ? (ctx->program->gfx_level <= GFX8 ? 4 : 16) : 0;
@@ -6967,7 +7049,9 @@ visit_load_buffer(isel_context* ctx, nir_intrinsic_instr* intrin)
          info.align_mul = align_mul;
          info.align_offset = align_offset;
 
-         emit_load(ctx, bld, info, mubuf_load_params);
+         EmitLoadParameters params = mubuf_load_params;
+         params.max_const_offset_plus_one = ctx->program->dev.buf_offset_max + 1;
+         emit_load(ctx, bld, info, params);
       }
    }
 }
@@ -7928,25 +8012,56 @@ create_fs_dual_src_export_gfx11(isel_context* ctx, const struct aco_export_mrt*
    ctx->program->has_color_exports = true;
 }
 
+static bool
+get_replicated_constant(nir_def* def, unsigned stride, uint32_t* constant)
+{
+   nir_scalar comp = nir_scalar_resolved(def, 0);
+   if (!nir_scalar_is_const(comp))
+      return false;
+
+   *constant = nir_scalar_as_uint(comp);
+
+   for (unsigned i = stride; i < def->num_components; i += stride) {
+      comp = nir_scalar_resolved(def, i);
+      if (!nir_scalar_is_const(comp) || nir_scalar_as_uint(comp) != *constant)
+         return false;
+   }
+   return true;
+}
+
 static void
 visit_cmat_muladd(isel_context* ctx, nir_intrinsic_instr* instr)
 {
    aco_opcode opcode = aco_opcode::num_opcodes;
-   unsigned signed_mask = 0;
-   bool clamp = false;
 
-   switch (instr->src[0].ssa->bit_size) {
-   case 16:
+   bitarray8 neg_lo = nir_intrinsic_neg_lo_amd(instr);
+   bitarray8 neg_hi = nir_intrinsic_neg_hi_amd(instr);
+
+   enum glsl_base_type type_a = nir_intrinsic_src_base_type(instr);
+   enum glsl_base_type type_b = nir_intrinsic_src_base_type2(instr);
+
+   switch (type_a) {
+   case GLSL_TYPE_FLOAT16:
       switch (instr->def.bit_size) {
       case 32: opcode = aco_opcode::v_wmma_f32_16x16x16_f16; break;
       case 16: opcode = aco_opcode::v_wmma_f16_16x16x16_f16; break;
       }
       break;
-   case 8:
+   case GLSL_TYPE_BFLOAT16:
+      switch (instr->def.bit_size) {
+      case 32: opcode = aco_opcode::v_wmma_f32_16x16x16_bf16; break;
+      case 16: opcode = aco_opcode::v_wmma_bf16_16x16x16_bf16; break;
+      }
+      break;
+   case GLSL_TYPE_UINT8:
+   case GLSL_TYPE_INT8: {
       opcode = aco_opcode::v_wmma_i32_16x16x16_iu8;
-      signed_mask = nir_intrinsic_cmat_signed_mask(instr);
-      clamp = nir_intrinsic_saturate(instr);
+      neg_lo[0] = type_a == GLSL_TYPE_INT8;
+      neg_lo[1] = type_b == GLSL_TYPE_INT8;
       break;
+   case GLSL_TYPE_FLOAT_E4M3FN: opcode = aco_opcode::v_wmma_f32_16x16x16_fp8_fp8; break;
+   }
+   default: unreachable("invalid cmat_muladd_amd type");
    }
 
    if (opcode == aco_opcode::num_opcodes)
@@ -7959,10 +8074,32 @@ visit_cmat_muladd(isel_context* ctx, nir_intrinsic_instr* instr)
    Operand B(as_vgpr(ctx, get_ssa_temp(ctx, instr->src[1].ssa)));
    Operand C(as_vgpr(ctx, get_ssa_temp(ctx, instr->src[2].ssa)));
 
+   uint32_t constant;
+   uint32_t acc_stride = ctx->program->gfx_level < GFX12 && instr->def.bit_size == 16 ? 2 : 1;
+   if (get_replicated_constant(instr->src[2].ssa, acc_stride, &constant)) {
+      unsigned constant_size = instr->def.bit_size;
+      if (opcode == aco_opcode::v_wmma_bf16_16x16x16_bf16) {
+         /* Bfloat16 uses the high bits of 32bit inline constants. */
+         constant <<= 16;
+         constant_size = 32;
+      }
+      Operand constC = Operand::get_const(ctx->program->gfx_level, constant, constant_size / 8);
+      if (!constC.isLiteral()) {
+         C = constC;
+      } else if (opcode != aco_opcode::v_wmma_i32_16x16x16_iu8) {
+         constant ^= 1 << (constant_size - 1);
+         constC = Operand::get_const(ctx->program->gfx_level, constant, constant_size / 8);
+         if (!constC.isLiteral()) {
+            C = constC;
+            neg_lo[2] ^= !neg_hi[2];
+         }
+      }
+   }
+
    VALU_instruction& vop3p = bld.vop3p(opcode, Definition(dst), A, B, C, 0, 0x7)->valu();
-   vop3p.neg_lo[0] = (signed_mask & 0x1) != 0;
-   vop3p.neg_lo[1] = (signed_mask & 0x2) != 0;
-   vop3p.clamp = clamp;
+   vop3p.neg_lo = neg_lo;
+   vop3p.neg_hi = neg_hi;
+   vop3p.clamp = nir_intrinsic_saturate(instr);
 
    emit_split_vector(ctx, dst, instr->def.num_components);
 }
@@ -8787,6 +8924,7 @@ visit_intrinsic(isel_context* ctx, nir_intrinsic_instr* instr)
       break;
    }
    case nir_intrinsic_bvh64_intersect_ray_amd: visit_bvh64_intersect_ray_amd(ctx, instr); break;
+   case nir_intrinsic_bvh8_intersect_ray_amd: visit_bvh8_intersect_ray_amd(ctx, instr); break;
    case nir_intrinsic_load_resume_shader_address_amd: {
       bld.pseudo(aco_opcode::p_resume_shader_address, Definition(get_ssa_temp(ctx, &instr->def)),
                  bld.def(s1, scc), Operand::c32(nir_intrinsic_call_idx(instr)));
@@ -9296,7 +9434,7 @@ visit_tex(isel_context* ctx, nir_tex_instr* instr)
       } else {
          Temp tg4_lod = bld.copy(bld.def(v1), Operand::zero());
          Temp size = bld.tmp(v2);
-         MIMG_instruction* tex = emit_mimg(bld, aco_opcode::image_get_resinfo, size, resource,
+         MIMG_instruction* tex = emit_mimg(bld, aco_opcode::image_get_resinfo, {size}, resource,
                                            Operand(s4), std::vector<Temp>{tg4_lod});
          tex->dim = dim;
          tex->dmask = 0x3;
@@ -9453,7 +9591,7 @@ visit_tex(isel_context* ctx, nir_tex_instr* instr)
                          ? aco_opcode::image_load
                          : aco_opcode::image_load_mip;
       Operand vdata = instr->is_sparse ? emit_tfe_init(bld, tmp_dst) : Operand(v1);
-      MIMG_instruction* tex = emit_mimg(bld, op, tmp_dst, resource, Operand(s4), args, vdata);
+      MIMG_instruction* tex = emit_mimg(bld, op, {tmp_dst}, resource, Operand(s4), args, vdata);
       if (instr->op == nir_texop_fragment_mask_fetch_amd)
          tex->dim = da ? ac_image_2darray : ac_image_2d;
       else
@@ -9632,7 +9770,8 @@ visit_tex(isel_context* ctx, nir_tex_instr* instr)
                           instr->sampler_dim != GLSL_SAMPLER_DIM_SUBPASS_MS;
 
    Operand vdata = instr->is_sparse ? emit_tfe_init(bld, tmp_dst) : Operand(v1);
-   MIMG_instruction* tex = emit_mimg(bld, opcode, tmp_dst, resource, Operand(sampler), args, vdata);
+   MIMG_instruction* tex =
+      emit_mimg(bld, opcode, {tmp_dst}, resource, Operand(sampler), args, vdata);
    tex->dim = dim;
    tex->dmask = dmask & 0xf;
    tex->da = da;
diff --git a/src/amd/compiler/aco_instruction_selection_setup.cpp b/src/amd/compiler/aco_instruction_selection_setup.cpp
index 72661e0c5a8..adaa055b7a0 100644
--- a/src/amd/compiler/aco_instruction_selection_setup.cpp
+++ b/src/amd/compiler/aco_instruction_selection_setup.cpp
@@ -413,6 +413,8 @@ init_context(isel_context* ctx, nir_shader* shader)
                       regclasses[alu_instr->src[0].src.ssa->index].type() == RegType::vgpr)
                      type = RegType::vgpr;
                   break;
+               case nir_op_f2e4m3fn:
+               case nir_op_e4m3fn2f:
                case nir_op_fmulz:
                case nir_op_ffmaz:
                case nir_op_f2f64:
@@ -438,6 +440,7 @@ init_context(isel_context* ctx, nir_shader* shader)
                case nir_op_sdot_2x16_iadd:
                case nir_op_udot_2x16_uadd_sat:
                case nir_op_sdot_2x16_iadd_sat:
+               case nir_op_bfdot2_bfadd:
                case nir_op_alignbyte_amd: type = RegType::vgpr; break;
                case nir_op_fmul:
                case nir_op_ffma:
@@ -562,6 +565,7 @@ init_context(isel_context* ctx, nir_shader* shader)
                case nir_intrinsic_load_initial_edgeflags_amd:
                case nir_intrinsic_gds_atomic_add_amd:
                case nir_intrinsic_bvh64_intersect_ray_amd:
+               case nir_intrinsic_bvh8_intersect_ray_amd:
                case nir_intrinsic_load_vector_arg_amd:
                case nir_intrinsic_ordered_xfb_counter_add_gfx11_amd:
                case nir_intrinsic_cmat_muladd_amd:
diff --git a/src/amd/compiler/aco_interface.cpp b/src/amd/compiler/aco_interface.cpp
index f69a260a6db..489aa731d6a 100644
--- a/src/amd/compiler/aco_interface.cpp
+++ b/src/amd/compiler/aco_interface.cpp
@@ -483,6 +483,8 @@ aco_nir_op_supports_packed_math_16bit(const nir_alu_instr* alu)
       return (shader->options->force_f2f16_rtz && !nir_is_rounding_mode_rtne(execution_mode, 16)) ||
              nir_is_rounding_mode_rtz(execution_mode, 16);
    }
+   case nir_op_f2e4m3fn:
+   case nir_op_e4m3fn2f:
    case nir_op_fadd:
    case nir_op_fsub:
    case nir_op_fmul:
diff --git a/src/amd/compiler/aco_ir.cpp b/src/amd/compiler/aco_ir.cpp
index f30f951510d..d7bcab565ac 100644
--- a/src/amd/compiler/aco_ir.cpp
+++ b/src/amd/compiler/aco_ir.cpp
@@ -168,7 +168,10 @@ init_program(Program* program, Stage stage, const struct aco_shader_info* info,
        program->family == CHIP_MI100 || program->family == CHIP_MI200)
       program->dev.fused_mad_mix = true;
 
-   if (program->gfx_level >= GFX11) {
+   if (program->gfx_level >= GFX12) {
+      program->dev.scratch_global_offset_min = -8388608;
+      program->dev.scratch_global_offset_max = 8388607;
+   } else if (program->gfx_level >= GFX11) {
       program->dev.scratch_global_offset_min = -4096;
       program->dev.scratch_global_offset_max = 4095;
    } else if (program->gfx_level >= GFX10 || program->gfx_level == GFX8) {
@@ -180,6 +183,20 @@ init_program(Program* program, Stage stage, const struct aco_shader_info* info,
       program->dev.scratch_global_offset_max = 4095;
    }
 
+   if (program->gfx_level >= GFX12)
+      program->dev.buf_offset_max = 0x7fffff;
+   else
+      program->dev.buf_offset_max = 0xfff;
+
+   if (program->gfx_level >= GFX12)
+      program->dev.smem_offset_max = 0x7fffff;
+   else if (program->gfx_level >= GFX8)
+      program->dev.smem_offset_max = 0xfffff;
+   else if (program->gfx_level >= GFX7)
+      program->dev.smem_offset_max = 0xffffffff;
+   else if (program->gfx_level >= GFX6)
+      program->dev.smem_offset_max = 0x3ff;
+
    if (program->gfx_level >= GFX12) {
       /* Same as GFX11, except one less for VSAMPLE. */
       program->dev.max_nsa_vgprs = 3;
@@ -568,6 +585,8 @@ can_use_opsel(amd_gfx_level gfx_level, aco_opcode op, int idx)
    case aco_opcode::v_interp_p10_rtz_f16_f32_inreg: return idx == 0 || idx == 2;
    case aco_opcode::v_interp_p2_f16_f32_inreg:
    case aco_opcode::v_interp_p2_rtz_f16_f32_inreg: return idx == -1 || idx == 0;
+   case aco_opcode::v_cvt_pk_fp8_f32:
+   case aco_opcode::v_cvt_pk_bf8_f32: return idx == -1;
    default:
       return gfx_level >= GFX11 && (get_gfx11_true16_mask(op) & BITFIELD_BIT(idx == -1 ? 3 : idx));
    }
@@ -699,6 +718,8 @@ get_gfx11_true16_mask(aco_opcode op)
    case aco_opcode::v_and_b16:
    case aco_opcode::v_or_b16:
    case aco_opcode::v_xor_b16: return 0x3 | 0x8;
+   case aco_opcode::v_cvt_pk_f32_fp8:
+   case aco_opcode::v_cvt_pk_f32_bf8:
    case aco_opcode::v_cvt_f32_f16:
    case aco_opcode::v_cvt_i32_i16:
    case aco_opcode::v_cvt_u32_u16: return 0x1;
@@ -1410,9 +1431,10 @@ should_form_clause(const Instruction* a, const Instruction* b)
    return false;
 }
 
-int
-get_op_fixed_to_def(Instruction* instr)
+aco::small_vec<uint32_t, 2>
+get_ops_fixed_to_def(Instruction* instr)
 {
+   aco::small_vec<uint32_t, 2> ops;
    if (instr->opcode == aco_opcode::v_interp_p2_f32 || instr->opcode == aco_opcode::v_mac_f32 ||
        instr->opcode == aco_opcode::v_fmac_f32 || instr->opcode == aco_opcode::v_mac_f16 ||
        instr->opcode == aco_opcode::v_fmac_f16 || instr->opcode == aco_opcode::v_mac_legacy_f32 ||
@@ -1421,23 +1443,28 @@ get_op_fixed_to_def(Instruction* instr)
        instr->opcode == aco_opcode::v_writelane_b32_e64 ||
        instr->opcode == aco_opcode::v_dot4c_i32_i8 || instr->opcode == aco_opcode::s_fmac_f32 ||
        instr->opcode == aco_opcode::s_fmac_f16) {
-      return 2;
+      ops.push_back(2);
    } else if (instr->opcode == aco_opcode::s_addk_i32 || instr->opcode == aco_opcode::s_mulk_i32 ||
               instr->opcode == aco_opcode::s_cmovk_i32) {
-      return 0;
+      ops.push_back(0);
    } else if (instr->isMUBUF() && instr->definitions.size() == 1 && instr->operands.size() == 4) {
-      return 3;
+      ops.push_back(3);
    } else if (instr->isMIMG() && instr->definitions.size() == 1 &&
               !instr->operands[2].isUndefined()) {
-      return 2;
+      ops.push_back(2);
+   } else if (instr->opcode == aco_opcode::image_bvh8_intersect_ray) {
+      /* VADDR starts at 3. */
+      ops.push_back(3 + 2);
+      ops.push_back(3 + 3);
    }
-   return -1;
+   return ops;
 }
 
 uint8_t
 get_vmem_type(enum amd_gfx_level gfx_level, Instruction* instr)
 {
-   if (instr->opcode == aco_opcode::image_bvh64_intersect_ray)
+   if (instr->opcode == aco_opcode::image_bvh64_intersect_ray ||
+       instr->opcode == aco_opcode::image_bvh8_intersect_ray)
       return vmem_bvh;
    else if (gfx_level >= GFX12 && instr->opcode == aco_opcode::image_msaa_load)
       return vmem_sampler;
diff --git a/src/amd/compiler/aco_ir.h b/src/amd/compiler/aco_ir.h
index a14fb760569..0ae387d637a 100644
--- a/src/amd/compiler/aco_ir.h
+++ b/src/amd/compiler/aco_ir.h
@@ -292,6 +292,7 @@ struct RegClass {
       v6 = 6 | (1 << 5),
       v7 = 7 | (1 << 5),
       v8 = 8 | (1 << 5),
+      v10 = 10 | (1 << 5),
       /* byte-sized register class */
       v1b = v1 | (1 << 7),
       v2b = v2 | (1 << 7),
@@ -360,6 +361,7 @@ static constexpr RegClass v5{RegClass::v5};
 static constexpr RegClass v6{RegClass::v6};
 static constexpr RegClass v7{RegClass::v7};
 static constexpr RegClass v8{RegClass::v8};
+static constexpr RegClass v10{RegClass::v10};
 static constexpr RegClass v1b{RegClass::v1b};
 static constexpr RegClass v2b{RegClass::v2b};
 static constexpr RegClass v3b{RegClass::v3b};
@@ -1625,15 +1627,14 @@ static_assert(sizeof(LDSDIR_instruction) == sizeof(Instruction) + 8, "Unexpected
 struct MUBUF_instruction : public Instruction {
    memory_sync_info sync;
    ac_hw_cache_flags cache;
-   bool offen : 1;           /* Supply an offset from VGPR (VADDR) */
-   bool idxen : 1;           /* Supply an index from VGPR (VADDR) */
-   bool addr64 : 1;          /* SI, CIK: Address size is 64-bit */
-   bool tfe : 1;             /* texture fail enable */
-   bool lds : 1;             /* Return read-data to LDS instead of VGPRs */
-   bool disable_wqm : 1;     /* Require an exec mask without helper invocations */
-   uint8_t padding0 : 2;
-   uint8_t padding1;
-   uint16_t offset; /* Unsigned byte offset - 12 bit */
+   uint32_t offset : 23;     /* Unsigned byte offset */
+   uint32_t offen : 1;       /* Supply an offset from VGPR (VADDR) */
+   uint32_t idxen : 1;       /* Supply an index from VGPR (VADDR) */
+   uint32_t addr64 : 1;      /* SI, CIK: Address size is 64-bit */
+   uint32_t tfe : 1;         /* texture fail enable */
+   uint32_t lds : 1;         /* Return read-data to LDS instead of VGPRs */
+   uint32_t disable_wqm : 1; /* Require an exec mask without helper invocations */
+   uint32_t padding : 3;
 };
 static_assert(sizeof(MUBUF_instruction) == sizeof(Instruction) + 8, "Unexpected padding");
 
@@ -1654,10 +1655,12 @@ struct MTBUF_instruction : public Instruction {
    bool idxen : 1;           /* Supply an index from VGPR (VADDR) */
    bool tfe : 1;             /* texture fail enable */
    bool disable_wqm : 1;     /* Require an exec mask without helper invocations */
-   uint8_t padding : 5;
-   uint16_t offset; /* Unsigned byte offset - 12 bit */
+   uint8_t padding0 : 5;
+   uint16_t padding1;
+   uint32_t offset : 23;     /* Unsigned byte offset */
+   uint32_t padding2 : 9;
 };
-static_assert(sizeof(MTBUF_instruction) == sizeof(Instruction) + 8, "Unexpected padding");
+static_assert(sizeof(MTBUF_instruction) == sizeof(Instruction) + 12, "Unexpected padding");
 
 /**
  * Vector Memory Image Instructions
@@ -1697,12 +1700,11 @@ static_assert(sizeof(MIMG_instruction) == sizeof(Instruction) + 8, "Unexpected p
 struct FLAT_instruction : public Instruction {
    memory_sync_info sync;
    ac_hw_cache_flags cache;
-   bool lds : 1;
-   bool nv : 1;
-   bool disable_wqm : 1; /* Require an exec mask without helper invocations */
-   uint8_t padding0 : 5;
-   uint8_t padding1;
-   int16_t offset; /* Vega/Navi only */
+   int32_t offset : 24;
+   uint32_t lds : 1;
+   uint32_t nv : 1;
+   uint32_t disable_wqm : 1; /* Require an exec mask without helper invocations */
+   uint32_t padding0 : 5;
 };
 static_assert(sizeof(FLAT_instruction) == sizeof(Instruction) + 8, "Unexpected padding");
 
@@ -2100,9 +2102,13 @@ struct DeviceInfo {
    bool xnack_enabled = false;
    bool sram_ecc_enabled = false;
 
-   int16_t scratch_global_offset_min;
-   int16_t scratch_global_offset_max;
+   int32_t scratch_global_offset_min;
+   int32_t scratch_global_offset_max;
    unsigned max_nsa_vgprs;
+
+   uint32_t buf_offset_max;
+   /* Note that GFX6/7 ignore the low 2 bits and this is only for positive offsets. */
+   uint32_t smem_offset_max;
 };
 
 enum class CompilationProgress {
@@ -2217,6 +2223,8 @@ private:
 struct ra_test_policy {
    /* Force RA to always use its pessimistic fallback algorithm */
    bool skip_optimistic_path = false;
+   /* Force get_reg() to always use its compact_relocate_vars() path */
+   bool use_compact_relocate = false;
 };
 
 void init();
@@ -2321,7 +2329,7 @@ void _aco_err(Program* program, const char* file, unsigned line, const char* fmt
 
 #define aco_err(program, ...)      _aco_err(program, __FILE__, __LINE__, __VA_ARGS__)
 
-int get_op_fixed_to_def(Instruction* instr);
+aco::small_vec<uint32_t, 2> get_ops_fixed_to_def(Instruction* instr);
 
 /* utilities for dealing with register demand */
 RegisterDemand get_live_changes(Instruction* instr);
diff --git a/src/amd/compiler/aco_live_var_analysis.cpp b/src/amd/compiler/aco_live_var_analysis.cpp
index 1b8c17dd959..b58b2a8ce2e 100644
--- a/src/amd/compiler/aco_live_var_analysis.cpp
+++ b/src/amd/compiler/aco_live_var_analysis.cpp
@@ -245,9 +245,15 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
       }
 
       /* Check if a definition clobbers some operand */
-      int op_idx = get_op_fixed_to_def(insn);
-      if (op_idx != -1)
+      auto fixed_ops = get_ops_fixed_to_def(insn);
+      for (auto op_idx : fixed_ops) {
+         assert(std::none_of(fixed_ops.begin(), fixed_ops.end(),
+                             [&](uint32_t i) {
+                                return i != op_idx && insn->operands[i].getTemp() ==
+                                                         insn->operands[op_idx].getTemp();
+                             }));
          insn->operands[op_idx].setClobbered(true);
+      }
 
       /* we need to do this in a separate loop because the next one can
        * setKill() for several operands at once and we don't want to
diff --git a/src/amd/compiler/aco_lower_to_hw_instr.cpp b/src/amd/compiler/aco_lower_to_hw_instr.cpp
index 145d3577ef1..d15687fec00 100644
--- a/src/amd/compiler/aco_lower_to_hw_instr.cpp
+++ b/src/amd/compiler/aco_lower_to_hw_instr.cpp
@@ -1398,16 +1398,19 @@ do_copy(lower_context* ctx, Builder& bld, const copy_operation& copy, bool* pres
    return did_copy;
 }
 
+void
+swap_bytes_bperm(Builder& bld, Definition def, Operand op)
+{
+   assert(def.physReg().reg() == op.physReg().reg());
+   uint8_t swiz[] = {4, 5, 6, 7};
+   std::swap(swiz[def.physReg().byte()], swiz[op.physReg().byte()]);
+   create_bperm(bld, swiz, def, Operand::zero());
+}
+
 void
 swap_subdword_gfx11(Builder& bld, Definition def, Operand op)
 {
-   if (def.physReg().reg() == op.physReg().reg()) {
-      assert(def.bytes() != 2); /* handled by caller */
-      uint8_t swiz[] = {4, 5, 6, 7};
-      std::swap(swiz[def.physReg().byte()], swiz[op.physReg().byte()]);
-      create_bperm(bld, swiz, def, Operand::zero());
-      return;
-   }
+   assert(def.physReg().reg() != op.physReg().reg()); /* handled by caller */
 
    if (def.bytes() == 2) {
       Operand def_as_op = Operand(def.physReg(), def.regClass());
@@ -1446,7 +1449,7 @@ swap_subdword_gfx11(Builder& bld, Definition def, Operand op)
        * into the same VGPR.
        */
       swap_subdword_gfx11(bld, Definition(def_other_half, v2b), Operand(op_half, v2b));
-      swap_subdword_gfx11(bld, def, Operand(def_other_half.advance(op.physReg().byte() & 1), v1b));
+      swap_bytes_bperm(bld, def, Operand(def_other_half.advance(op.physReg().byte() & 1), v1b));
       swap_subdword_gfx11(bld, Definition(def_other_half, v2b), Operand(op_half, v2b));
    }
 }
@@ -1532,6 +1535,9 @@ do_swap(lower_context* ctx, Builder& bld, const copy_operation& copy, bool prese
       } else if (def.bytes() == 2 && def.physReg().reg() == op.physReg().reg()) {
          bld.vop3(aco_opcode::v_alignbyte_b32, Definition(def.physReg(), v1), def_as_op, op,
                   Operand::c32(2u));
+      } else if (def.bytes() == 1 && def.physReg().reg() == op.physReg().reg() &&
+                 ctx->program->gfx_level >= GFX10) {
+         swap_bytes_bperm(bld, def, op);
       } else {
          assert(def.regClass().is_subdword());
          if (ctx->program->gfx_level >= GFX11) {
@@ -1595,6 +1601,40 @@ do_pack_2x16(lower_context* ctx, Builder& bld, Definition def, Operand lo, Opera
       return;
    }
 
+   if (ctx->program->gfx_level >= GFX10 && !lo.constantEquals(0) && !hi.constantEquals(0)) {
+      uint8_t swiz[4];
+      Operand ops[2] = {lo, hi};
+      for (unsigned i = 0; i < 2; i++) {
+         ops[i] =
+            ops[i].isConstant() ? Operand::c32((int32_t)(int16_t)ops[i].constantValue()) : ops[i];
+
+         swiz[i * 2 + 0] = i * 4 + ops[i].physReg().byte();
+         swiz[i * 2 + 1] = i * 4 + ops[i].physReg().byte() + 1;
+
+         if (ops[i].isLiteral()) {
+            Operand b0 = Operand::c32((int32_t)(int8_t)ops[i].constantValue());
+            Operand b1 = Operand::c32((int32_t)(int8_t)(ops[i].constantValue() >> 8));
+            if (!b0.isLiteral() &&
+                (b1.constantValue() == 0x00 || b1.constantValue() == 0xffffffff)) {
+               ops[i] = b0;
+               swiz[i * 2 + 1] = b1.constantValue() ? 13 : 12;
+            } else if (!b1.isLiteral() &&
+                       (b0.constantValue() == 0x00 || b0.constantValue() == 0xffffffff)) {
+               ops[i] = b1;
+               swiz[i * 2 + 0] = b0.constantValue() ? 13 : 12;
+               swiz[i * 2 + 1]--;
+            } else if (b0.constantValue() == b1.constantValue()) {
+               ops[i] = b0;
+               swiz[i * 2 + 1]--;
+            }
+         }
+      }
+      if (!ops[0].isLiteral() && !ops[1].isLiteral()) {
+         create_bperm(bld, swiz, def, ops[0], ops[1]);
+         return;
+      }
+   }
+
    Definition def_lo = Definition(def.physReg(), v2b);
    Definition def_hi = Definition(def.physReg().advance(2), v2b);
 
diff --git a/src/amd/compiler/aco_opcodes.py b/src/amd/compiler/aco_opcodes.py
index 361535bbf5e..6edbb26d724 100644
--- a/src/amd/compiler/aco_opcodes.py
+++ b/src/amd/compiler/aco_opcodes.py
@@ -184,7 +184,7 @@ class Format(IntEnum):
          return [('uint8_t', 'opsel', 0),
                  ('unsigned', 'wait_exp', 7)]
       elif self in [Format.FLAT, Format.GLOBAL, Format.SCRATCH]:
-         return [('int16_t', 'offset', 0),
+         return [('int32_t', 'offset', 0),
                  ('memory_sync_info', 'sync', 'memory_sync_info()'),
                  ('ac_hw_cache_flags', 'cache', '{{0, 0, 0, 0, 0}}'),
                  ('bool', 'lds', 'false'),
@@ -1867,6 +1867,8 @@ MIMG = {
    ("image_gather4_c_lz_o",      op(0x5f, gfx11=0x37)),
    ("image_bvh_intersect_ray",   op(gfx10=0xe6, gfx11=0x19)),
    ("image_bvh64_intersect_ray", op(gfx10=0xe7, gfx11=0x1a)),
+   ("image_bvh_dual_intersect_ray", op(gfx12=0x80)),
+   ("image_bvh8_intersect_ray",  op(gfx12=0x81)),
 }
 for (name, num) in MIMG:
    insn(name, num, Format.MIMG, InstrClass.VMem, is_atomic = "atomic" in name)
diff --git a/src/amd/compiler/aco_optimizer.cpp b/src/amd/compiler/aco_optimizer.cpp
index 486b8e11bd1..192e10638f3 100644
--- a/src/amd/compiler/aco_optimizer.cpp
+++ b/src/amd/compiler/aco_optimizer.cpp
@@ -589,7 +589,8 @@ can_apply_sgprs(opt_ctx& ctx, aco_ptr<Instruction>& instr)
           instr->opcode != aco_opcode::v_wmma_f16_16x16x16_f16 &&
           instr->opcode != aco_opcode::v_wmma_bf16_16x16x16_bf16 &&
           instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu8 &&
-          instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu4;
+          instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu4 &&
+          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_fp8_fp8;
 }
 
 /* only covers special cases */
@@ -648,7 +649,9 @@ alu_can_accept_constant(const aco_ptr<Instruction>& instr, unsigned operand)
    case aco_opcode::v_interp_p2_f16_f32_inreg:
    case aco_opcode::v_interp_p10_rtz_f16_f32_inreg:
    case aco_opcode::v_interp_p2_rtz_f16_f32_inreg:
+   case aco_opcode::v_dot2_bf16_bf16: /* TODO */
    case aco_opcode::v_wmma_f32_16x16x16_f16:
+   case aco_opcode::v_wmma_f32_16x16x16_fp8_fp8:
    case aco_opcode::v_wmma_f32_16x16x16_bf16:
    case aco_opcode::v_wmma_f16_16x16x16_f16:
    case aco_opcode::v_wmma_bf16_16x16x16_bf16:
@@ -830,14 +833,11 @@ smem_combine(opt_ctx& ctx, aco_ptr<Instruction>& instr)
 
       Temp base;
       uint32_t offset;
-      if (info.is_constant_or_literal(32) &&
-          ((ctx.program->gfx_level == GFX6 && info.val <= 0x3FF) ||
-           (ctx.program->gfx_level == GFX7 && info.val <= 0xFFFFFFFF) ||
-           (ctx.program->gfx_level >= GFX8 && info.val <= 0xFFFFF))) {
+      if (info.is_constant_or_literal(32) && info.val <= ctx.program->dev.smem_offset_max) {
          instr->operands[1] = Operand::c32(info.val);
       } else if (parse_base_offset(ctx, instr.get(), 1, &base, &offset, true) &&
-                 base.regClass() == s1 && offset <= 0xFFFFF && ctx.program->gfx_level >= GFX9 &&
-                 offset % 4u == 0) {
+                 base.regClass() == s1 && offset <= ctx.program->dev.smem_offset_max &&
+                 ctx.program->gfx_level >= GFX9 && offset % 4u == 0) {
          bool soe = smem.operands.size() >= (!smem.definitions.empty() ? 3 : 4);
          if (soe) {
             if (ctx.info[smem.operands.back().tempId()].is_constant_or_literal(32) &&
@@ -1502,35 +1502,38 @@ label_instruction(opt_ctx& ctx, aco_ptr<Instruction>& instr)
           * MUBUF accesses. */
          bool vaddr_prevent_overflow = swizzled && ctx.program->gfx_level < GFX9;
 
+         uint32_t const_max = ctx.program->dev.buf_offset_max;
+
          if (mubuf.offen && mubuf.idxen && i == 1 && info.is_vec() &&
              info.instr->operands.size() == 2 && info.instr->operands[0].isTemp() &&
              info.instr->operands[0].regClass() == v1 && info.instr->operands[1].isConstant() &&
-             mubuf.offset + info.instr->operands[1].constantValue() < 4096) {
+             mubuf.offset + info.instr->operands[1].constantValue() <= const_max) {
             instr->operands[1] = info.instr->operands[0];
             mubuf.offset += info.instr->operands[1].constantValue();
             mubuf.offen = false;
             continue;
          } else if (mubuf.offen && i == 1 && info.is_constant_or_literal(32) &&
-                    mubuf.offset + info.val < 4096) {
+                    mubuf.offset + info.val <= const_max) {
             assert(!mubuf.idxen);
             instr->operands[1] = Operand(v1);
             mubuf.offset += info.val;
             mubuf.offen = false;
             continue;
-         } else if (i == 2 && info.is_constant_or_literal(32) && mubuf.offset + info.val < 4096) {
+         } else if (i == 2 && info.is_constant_or_literal(32) &&
+                    mubuf.offset + info.val <= const_max) {
             instr->operands[2] = Operand::c32(0);
             mubuf.offset += info.val;
             continue;
          } else if (mubuf.offen && i == 1 &&
                     parse_base_offset(ctx, instr.get(), i, &base, &offset,
                                       vaddr_prevent_overflow) &&
-                    base.regClass() == v1 && mubuf.offset + offset < 4096) {
+                    base.regClass() == v1 && mubuf.offset + offset <= const_max) {
             assert(!mubuf.idxen);
             instr->operands[1].setTemp(base);
             mubuf.offset += offset;
             continue;
          } else if (i == 2 && parse_base_offset(ctx, instr.get(), i, &base, &offset, true) &&
-                    base.regClass() == s1 && mubuf.offset + offset < 4096 && !swizzled) {
+                    base.regClass() == s1 && mubuf.offset + offset <= const_max && !swizzled) {
             instr->operands[i].setTemp(base);
             mubuf.offset += offset;
             continue;
@@ -1545,7 +1548,8 @@ label_instruction(opt_ctx& ctx, aco_ptr<Instruction>& instr)
          if (mtbuf.offen && mtbuf.idxen && i == 1 && info.is_vec() &&
              info.instr->operands.size() == 2 && info.instr->operands[0].isTemp() &&
              info.instr->operands[0].regClass() == v1 && info.instr->operands[1].isConstant() &&
-             mtbuf.offset + info.instr->operands[1].constantValue() < 4096) {
+             mtbuf.offset + info.instr->operands[1].constantValue() <=
+                ctx.program->dev.buf_offset_max) {
             instr->operands[1] = info.instr->operands[0];
             mtbuf.offset += info.instr->operands[1].constantValue();
             mtbuf.offen = false;
diff --git a/src/amd/compiler/aco_register_allocation.cpp b/src/amd/compiler/aco_register_allocation.cpp
index e3eee992895..33b6c15acd8 100644
--- a/src/amd/compiler/aco_register_allocation.cpp
+++ b/src/amd/compiler/aco_register_allocation.cpp
@@ -200,7 +200,7 @@ get_stride(RegClass rc)
       uint32_t size = rc.size();
       if (size == 2) {
          return 2;
-      } else if (size >= 4) {
+      } else if (size >= 4 && util_is_power_of_two_or_zero(size)) {
          return 4;
       } else {
          return 1;
@@ -1271,7 +1271,7 @@ get_reg_impl(ra_ctx& ctx, const RegisterFile& reg_file, std::vector<parallelcopy
 {
    const PhysRegInterval& bounds = info.bounds;
    uint32_t size = info.size;
-   uint32_t stride = info.stride;
+   uint32_t stride = info.rc.is_subdword() ? DIV_ROUND_UP(info.stride, 4) : info.stride;
    RegClass rc = info.rc;
 
    /* check how many free regs we have */
@@ -1280,8 +1280,15 @@ get_reg_impl(ra_ctx& ctx, const RegisterFile& reg_file, std::vector<parallelcopy
    /* mark and count killed operands */
    unsigned killed_ops = 0;
    std::bitset<256> is_killed_operand; /* per-register */
+   std::bitset<256> is_precolored;     /* per-register */
    for (unsigned j = 0; !is_phi(instr) && j < instr->operands.size(); j++) {
       Operand& op = instr->operands[j];
+      if (op.isTemp() && op.isPrecolored() && !op.isFirstKillBeforeDef() &&
+          bounds.contains(op.physReg())) {
+         for (unsigned i = 0; i < op.size(); ++i) {
+            is_precolored[(op.physReg() & 0xff) + i] = true;
+         }
+      }
       if (op.isTemp() && op.isFirstKillBeforeDef() && bounds.contains(op.physReg()) &&
           !reg_file.test(PhysReg{op.physReg().reg()}, align(op.bytes() + op.physReg().byte(), 4))) {
          assert(op.isFixed());
@@ -1293,6 +1300,14 @@ get_reg_impl(ra_ctx& ctx, const RegisterFile& reg_file, std::vector<parallelcopy
          killed_ops += op.getTemp().size();
       }
    }
+   for (unsigned j = 0; !is_phi(instr) && j < instr->definitions.size(); j++) {
+      Definition& def = instr->definitions[j];
+      if (def.isTemp() && def.isPrecolored() && bounds.contains(def.physReg())) {
+         for (unsigned i = 0; i < def.size(); ++i) {
+            is_precolored[(def.physReg() & 0xff) + i] = true;
+         }
+      }
+   }
 
    assert((regs_free + ctx.num_linear_vgprs) >= size);
 
@@ -1337,6 +1352,10 @@ get_reg_impl(ra_ctx& ctx, const RegisterFile& reg_file, std::vector<parallelcopy
             }
             continue;
          }
+         if (is_precolored[j & 0xFF]) {
+            found = false;
+            break;
+         }
 
          if (reg_file[j] == 0 || reg_file[j] == last_var)
             continue;
@@ -1506,17 +1525,34 @@ compact_relocate_vars(ra_ctx& ctx, const std::vector<IDAndRegClass>& vars,
 
    std::sort(
       sorted.begin(), sorted.end(),
-      [&ctx](const IDAndInfo& a, const IDAndInfo& b)
+      [=, &ctx](const IDAndInfo& a, const IDAndInfo& b)
       {
-         unsigned a_stride = a.info.stride * (a.info.rc.is_subdword() ? 1 : 4);
-         unsigned b_stride = b.info.stride * (b.info.rc.is_subdword() ? 1 : 4);
-         if (a_stride > b_stride)
-            return true;
-         if (a_stride < b_stride)
-            return false;
+         unsigned a_stride = MAX2(a.info.stride * (a.info.rc.is_subdword() ? 1 : 4), 4);
+         unsigned b_stride = MAX2(b.info.stride * (b.info.rc.is_subdword() ? 1 : 4), 4);
+         /* Since the SGPR bounds should always be a multiple of two, we can place
+          * variables in this order:
+          * - the usual 4 SGPR aligned variables
+          * - then the 0xffffffff variable
+          * - then the unaligned variables
+          * - and finally the 2 SGPR aligned variables
+          * This way, we should always be able to place variables if the 0xffffffff one
+          * had a NPOT size.
+          *
+          * This also lets us avoid placing the 0xffffffff variable in VCC if it's s1/s2
+          * (required for pseudo-scalar transcendental) and places it first if it's a
+          * VGPR variable (required for ImageGather4D16Bug).
+          */
+         assert(a.info.rc.type() != RegType::sgpr || get_reg_bounds(ctx, a.info.rc).size % 2 == 0);
+         assert(a_stride == 16 || a_stride == 8 || a_stride == 4);
+         assert(b_stride == 16 || b_stride == 8 || b_stride == 4);
+         assert(a.info.rc.size() % (a_stride / 4u) == 0);
+         assert(b.info.rc.size() % (b_stride / 4u) == 0);
+         if ((a_stride == 16) != (b_stride == 16))
+            return a_stride > b_stride;
          if (a.id == 0xffffffff || b.id == 0xffffffff)
-            return a.id ==
-                   0xffffffff; /* place 0xffffffff before others if possible, not for any reason */
+            return a.id == 0xffffffff;
+         if (a_stride != b_stride)
+            return a_stride < b_stride;
          return ctx.assignments[a.id].reg < ctx.assignments[b.id].reg;
       });
 
@@ -1813,7 +1849,7 @@ get_reg(ra_ctx& ctx, const RegisterFile& reg_file, Temp temp,
 
    DefInfo info(ctx, instr, temp.regClass(), operand_index);
 
-   if (!ctx.policy.skip_optimistic_path) {
+   if (!ctx.policy.skip_optimistic_path && !ctx.policy.use_compact_relocate) {
       /* try to find space without live-range splits */
       res = get_reg_simple(ctx, reg_file, info);
 
@@ -1821,11 +1857,13 @@ get_reg(ra_ctx& ctx, const RegisterFile& reg_file, Temp temp,
          return *res;
    }
 
-   /* try to find space with live-range splits */
-   res = get_reg_impl(ctx, reg_file, parallelcopies, info, instr);
+   if (!ctx.policy.use_compact_relocate) {
+      /* try to find space with live-range splits */
+      res = get_reg_impl(ctx, reg_file, parallelcopies, info, instr);
 
-   if (res)
-      return *res;
+      if (res)
+         return *res;
+   }
 
    /* try compacting the linear vgprs to make more space */
    std::vector<parallelcopy> pc;
@@ -1850,20 +1888,34 @@ get_reg(ra_ctx& ctx, const RegisterFile& reg_file, Temp temp,
    if (!increase_register_file(ctx, info.rc)) {
       /* fallback algorithm: reallocate all variables at once (linear VGPRs should already be
        * compact at the end) */
+      const PhysRegInterval regs = get_reg_bounds(ctx, info.rc);
+
       unsigned def_size = info.rc.size();
+      std::vector<IDAndRegClass> def_vars;
       for (Definition def : instr->definitions) {
-         if (ctx.assignments[def.tempId()].assigned && def.regClass().type() == info.rc.type())
+         if (def.isPrecolored()) {
+            assert(!regs.contains({def.physReg(), def.size()}));
+            continue;
+         }
+         if (ctx.assignments[def.tempId()].assigned && def.regClass().type() == info.rc.type()) {
             def_size += def.regClass().size();
+            def_vars.emplace_back(def.tempId(), def.regClass());
+         }
       }
 
       unsigned killed_op_size = 0;
+      std::vector<IDAndRegClass> killed_op_vars;
       for (Operand op : instr->operands) {
-         if (op.isTemp() && op.isFirstKillBeforeDef() && op.regClass().type() == info.rc.type())
+         if (op.isPrecolored()) {
+            assert(!regs.contains({op.physReg(), op.size()}));
+            continue;
+         }
+         if (op.isTemp() && op.isFirstKillBeforeDef() && op.regClass().type() == info.rc.type()) {
             killed_op_size += op.regClass().size();
+            killed_op_vars.emplace_back(op.tempId(), op.regClass());
+         }
       }
 
-      const PhysRegInterval regs = get_reg_bounds(ctx, info.rc);
-
       /* reallocate passthrough variables and non-killed operands */
       std::vector<IDAndRegClass> vars;
       for (unsigned id : find_vars(ctx, reg_file, regs))
@@ -1873,19 +1925,9 @@ get_reg(ra_ctx& ctx, const RegisterFile& reg_file, Temp temp,
       PhysReg space = compact_relocate_vars(ctx, vars, parallelcopies, regs.lo());
 
       /* reallocate killed operands */
-      std::vector<IDAndRegClass> killed_op_vars;
-      for (Operand op : instr->operands) {
-         if (op.isFirstKillBeforeDef() && op.regClass().type() == info.rc.type())
-            killed_op_vars.emplace_back(op.tempId(), op.regClass());
-      }
       compact_relocate_vars(ctx, killed_op_vars, parallelcopies, space);
 
       /* reallocate definitions */
-      std::vector<IDAndRegClass> def_vars;
-      for (Definition def : instr->definitions) {
-         if (ctx.assignments[def.tempId()].assigned && def.regClass().type() == info.rc.type())
-            def_vars.emplace_back(def.tempId(), def.regClass());
-      }
       def_vars.emplace_back(0xffffffff, info.rc);
       return compact_relocate_vars(ctx, def_vars, parallelcopies, space);
    }
@@ -2104,9 +2146,12 @@ operand_can_use_reg(amd_gfx_level gfx_level, aco_ptr<Instruction>& instr, unsign
          return false;
       FALLTHROUGH;
    case Format::SOP2:
-   case Format::SOP1:
-      return get_op_fixed_to_def(instr.get()) != (int)idx ||
+   case Format::SOP1: {
+      auto fixed_ops = get_ops_fixed_to_def(instr.get());
+      return std::all_of(fixed_ops.begin(), fixed_ops.end(),
+                         [idx](auto op_idx) { return op_idx != idx; }) ||
              is_sgpr_writable_without_side_effects(gfx_level, reg);
+   }
    default:
       // TODO: there are more instructions with restrictions on registers
       return true;
@@ -2813,7 +2858,7 @@ get_affinities(ra_ctx& ctx)
             ctx.assignments[instr->operands[0].tempId()].m0 = true;
          }
 
-         int op_fixed_to_def0 = get_op_fixed_to_def(instr.get());
+         auto ops_fixed_to_defs = get_ops_fixed_to_def(instr.get());
          for (unsigned i = 0; i < instr->definitions.size(); i++) {
             const Definition& def = instr->definitions[i];
             if (!def.isTemp())
@@ -2827,8 +2872,8 @@ get_affinities(ra_ctx& ctx)
                Operand op;
                if (instr->opcode == aco_opcode::p_parallelcopy) {
                   op = instr->operands[i];
-               } else if (i == 0 && op_fixed_to_def0 != -1) {
-                  op = instr->operands[op_fixed_to_def0];
+               } else if (i < ops_fixed_to_defs.size()) {
+                  op = instr->operands[ops_fixed_to_defs[i]];
                } else if (vop3_can_use_vop2acc(ctx, instr.get())) {
                   op = instr->operands[2];
                } else if (i == 0 && sop2_can_use_sopk(ctx, instr.get())) {
@@ -3253,11 +3298,10 @@ register_allocation(Program* program, ra_test_policy policy)
           * We can't read from the old location because it's corrupted, and we can't write the new
           * location because that's used by a live-through operand.
           */
-         int op_fixed_to_def = get_op_fixed_to_def(instr.get());
-         if (op_fixed_to_def != -1) {
-            instr->definitions[0].setPrecolored(instr->operands[op_fixed_to_def].physReg());
-            instr->operands[op_fixed_to_def].setPrecolored(
-               instr->operands[op_fixed_to_def].physReg());
+         unsigned fixed_def_idx = 0;
+         for (auto op_idx : get_ops_fixed_to_def(instr.get())) {
+            instr->definitions[fixed_def_idx++].setPrecolored(instr->operands[op_idx].physReg());
+            instr->operands[op_idx].setPrecolored(instr->operands[op_idx].physReg());
          }
 
          /* handle fixed definitions first */
@@ -3351,19 +3395,16 @@ register_allocation(Program* program, ra_test_policy policy)
 
             if (!definition->isFixed()) {
                Temp tmp = definition->getTemp();
-               if (definition->regClass().is_subdword() && definition->bytes() < 4) {
-                  PhysReg reg = get_reg(ctx, register_file, tmp, parallelcopy, instr);
-                  definition->setFixed(reg);
-                  if (reg.byte() || register_file.test(reg, 4)) {
-                     bool allow_16bit_write = reg.byte() % 2 == 0 && !register_file.test(reg, 2);
-                     add_subdword_definition(program, instr, reg, allow_16bit_write);
-                     definition = &instr->definitions[i]; /* add_subdword_definition can invalidate
-                                                             the reference */
-                  }
-               } else {
-                  definition->setFixed(get_reg(ctx, register_file, tmp, parallelcopy, instr));
-               }
+               PhysReg reg = get_reg(ctx, register_file, tmp, parallelcopy, instr);
+               definition->setFixed(reg);
                update_renames(ctx, register_file, parallelcopy, instr);
+               if (definition->regClass().is_subdword() && definition->bytes() < 4 &&
+                   (reg.byte() || register_file.test(reg, 4))) {
+                  bool allow_16bit_write = reg.byte() % 2 == 0 && !register_file.test(reg, 2);
+                  add_subdword_definition(program, instr, reg, allow_16bit_write);
+                  /* add_subdword_definition can invalidate the reference */
+                  definition = &instr->definitions[i];
+               }
             }
 
             assert(
diff --git a/src/amd/compiler/aco_scheduler_ilp.cpp b/src/amd/compiler/aco_scheduler_ilp.cpp
index 886d2f7b15f..ee7a6ca5d14 100644
--- a/src/amd/compiler/aco_scheduler_ilp.cpp
+++ b/src/amd/compiler/aco_scheduler_ilp.cpp
@@ -29,14 +29,15 @@ using mask_t = uint16_t;
 static_assert(std::numeric_limits<mask_t>::digits >= num_nodes);
 
 struct VOPDInfo {
-   VOPDInfo() : is_opy_only(0), is_dst_odd(0), src_banks(0), has_literal(0), is_commutative(0) {}
-   uint16_t is_opy_only : 1;
+   VOPDInfo() : can_be_opx(0), is_dst_odd(0), src_banks(0), has_literal(0), is_commutative(0) {}
+   uint16_t can_be_opx : 1;
    uint16_t is_dst_odd : 1;
    uint16_t src_banks : 10; /* 0-3: src0, 4-7: src1, 8-9: src2 */
    uint16_t has_literal : 1;
    uint16_t is_commutative : 1;
    aco_opcode op = aco_opcode::num_opcodes;
    uint32_t literal = 0;
+   uint8_t port_vgprs[2] = {0, 0};
 };
 
 struct InstrInfo {
@@ -133,6 +134,7 @@ get_vopd_info(const SchedILPContext& ctx, const Instruction* instr)
       return VOPDInfo();
 
    VOPDInfo info;
+   info.can_be_opx = true;
    info.is_commutative = true;
    switch (instr->opcode) {
    case aco_opcode::v_fmac_f32: info.op = aco_opcode::v_dual_fmac_f32; break;
@@ -161,16 +163,16 @@ get_vopd_info(const SchedILPContext& ctx, const Instruction* instr)
    case aco_opcode::v_dot2c_f32_f16: info.op = aco_opcode::v_dual_dot2acc_f32_f16; break;
    case aco_opcode::v_add_u32:
       info.op = aco_opcode::v_dual_add_nc_u32;
-      info.is_opy_only = true;
+      info.can_be_opx = false;
       break;
    case aco_opcode::v_lshlrev_b32:
       info.op = aco_opcode::v_dual_lshlrev_b32;
-      info.is_opy_only = true;
+      info.can_be_opx = false;
       info.is_commutative = false;
       break;
    case aco_opcode::v_and_b32:
       info.op = aco_opcode::v_dual_and_b32;
-      info.is_opy_only = true;
+      info.can_be_opx = false;
       break;
    default: return VOPDInfo();
    }
@@ -189,8 +191,11 @@ get_vopd_info(const SchedILPContext& ctx, const Instruction* instr)
          op = Operand::get_const(ctx.program->gfx_level, util_bitreverse(op.constantValue()), 4);
 
       unsigned port = (instr->opcode == aco_opcode::v_fmamk_f32 && i == 1) ? 2 : i;
-      if (op.isOfType(RegType::vgpr))
+      if (op.isOfType(RegType::vgpr)) {
          info.src_banks |= 1 << (port * 4 + (op.physReg().reg() & bank_mask[port]));
+         if (port < 2)
+            info.port_vgprs[port] = op.physReg().reg();
+      }
 
       /* Check all operands because of fmaak/fmamk. */
       if (op.isLiteral()) {
@@ -213,64 +218,106 @@ get_vopd_info(const SchedILPContext& ctx, const Instruction* instr)
 }
 
 bool
-is_vopd_compatible(const VOPDInfo& a, const VOPDInfo& b, bool* swap)
+are_src_banks_compatible(enum amd_gfx_level gfx_level, const VOPDInfo& a, const VOPDInfo& b,
+                         bool swap)
 {
-   if ((a.is_opy_only && b.is_opy_only) || (a.is_dst_odd == b.is_dst_odd))
-      return false;
+   if (gfx_level >= GFX12 && a.op == aco_opcode::v_dual_mov_b32 &&
+       b.op == aco_opcode::v_dual_mov_b32) {
+      /* On GFX12+, OPY uses src2 if both OPX and OPY are v_dual_mov_b32, so there are no
+       * compatibility issues. */
+      return true;
+   }
+
+   uint16_t a_src_banks = a.src_banks;
+   uint8_t a_port_vgprs[2] = {a.port_vgprs[0], a.port_vgprs[1]};
+   if (swap) {
+      uint16_t src0 = a.src_banks & 0xf;
+      uint16_t src1 = a.src_banks & 0xf0;
+      uint16_t src2 = a.src_banks & 0x300;
+      a_src_banks = (src0 << 4) | (src1 >> 4) | src2;
+      std::swap(a_port_vgprs[0], a_port_vgprs[1]);
+   }
+
+   /* On GFX12+, we can skip checking a src0/src1 port if both SRCx and SRCy use the same VGPR and
+    * the same sized operand.
+    */
+   if (gfx_level >= GFX12) {
+      bool a_is_dot2cc =
+         a.op == aco_opcode::v_dual_dot2acc_f32_f16 || a.op == aco_opcode::v_dual_dot2acc_f32_bf16;
+      bool b_is_dot2cc =
+         b.op == aco_opcode::v_dual_dot2acc_f32_f16 || b.op == aco_opcode::v_dual_dot2acc_f32_bf16;
+      if (a_port_vgprs[0] == b.port_vgprs[0] && a_is_dot2cc == b_is_dot2cc)
+         a_src_banks &= ~0xf;
+      if (a_port_vgprs[1] == b.port_vgprs[1] && a_is_dot2cc == b_is_dot2cc)
+         a_src_banks &= ~0xf0;
+   }
+
+   return (a_src_banks & b.src_banks) == 0;
+}
+
+enum vopd_compatibility {
+   vopd_incompatible = 0x0,
+   vopd_first_is_opx = 0x1,
+   vopd_second_is_opx = 0x2,
+   vopd_need_swap = 0x4,
+};
+
+unsigned
+is_vopd_compatible(enum amd_gfx_level gfx_level, const VOPDInfo& a, const VOPDInfo& b)
+{
+   if ((!a.can_be_opx && !b.can_be_opx) || (a.is_dst_odd == b.is_dst_odd))
+      return vopd_incompatible;
 
    /* Both can use a literal, but it must be the same literal. */
    if (a.has_literal && b.has_literal && a.literal != b.literal)
-      return false;
+      return vopd_incompatible;
 
-   *swap = false;
+   unsigned compat = vopd_incompatible;
 
    /* The rest is checking src VGPR bank compatibility. */
-   if ((a.src_banks & b.src_banks) == 0)
-      return true;
+   if (are_src_banks_compatible(gfx_level, a, b, false)) {
+      if (a.can_be_opx)
+         compat |= vopd_first_is_opx;
+      if (b.can_be_opx)
+         compat |= vopd_second_is_opx;
+      return compat;
+   }
 
+   /* The rest of this function checks if we can resolve the VGPR bank incompatibility by swapping
+    * the operands of one of the instructions.
+    */
    if (!a.is_commutative && !b.is_commutative)
-      return false;
-
-   uint16_t src0 = a.src_banks & 0xf;
-   uint16_t src1 = a.src_banks & 0xf0;
-   uint16_t src2 = a.src_banks & 0x300;
-   uint16_t a_src_banks = (src0 << 4) | (src1 >> 4) | src2;
-   if ((a_src_banks & b.src_banks) != 0)
-      return false;
+      return vopd_incompatible;
 
-   /* If we have to turn v_mov_b32 into v_add_u32 but there is already an OPY-only instruction,
-    * we can't do it.
-    */
-   if (a.op == aco_opcode::v_dual_mov_b32 && !b.is_commutative && b.is_opy_only)
-      return false;
-   if (b.op == aco_opcode::v_dual_mov_b32 && !a.is_commutative && a.is_opy_only)
-      return false;
+   if (!are_src_banks_compatible(gfx_level, a, b, true))
+      return vopd_incompatible;
 
-   *swap = true;
+   /* Swapping v_mov_b32 makes it become an OPY-only opcode. */
+   if (a.can_be_opx && (b.is_commutative || a.op != aco_opcode::v_dual_mov_b32))
+      compat |= vopd_first_is_opx;
+   if (b.can_be_opx && (a.is_commutative || b.op != aco_opcode::v_dual_mov_b32))
+      compat |= vopd_second_is_opx;
 
-   return true;
+   return compat ? (compat | vopd_need_swap) : vopd_incompatible;
 }
 
-bool
-can_use_vopd(const SchedILPContext& ctx, unsigned idx, bool* prev_can_be_opx)
+unsigned
+can_use_vopd(const SchedILPContext& ctx, unsigned idx)
 {
-   VOPDInfo cur_vopd = ctx.vopd[idx];
+   VOPDInfo first_info = ctx.vopd[idx];
+   VOPDInfo second_info = ctx.prev_vopd_info;
    Instruction* first = ctx.nodes[idx].instr;
    Instruction* second = ctx.prev_info.instr;
 
    if (!second)
-      return false;
-
-   if (ctx.prev_vopd_info.op == aco_opcode::num_opcodes || cur_vopd.op == aco_opcode::num_opcodes)
-      return false;
+      return 0;
 
-   bool swap = false;
-   if (!is_vopd_compatible(ctx.prev_vopd_info, cur_vopd, &swap))
-      return false;
+   if (second_info.op == aco_opcode::num_opcodes || first_info.op == aco_opcode::num_opcodes)
+      return 0;
 
-   /* If we have to swap a v_mov_b32, it will become an OPY-only opcode. */
-   if (swap && !ctx.prev_vopd_info.is_commutative && cur_vopd.op == aco_opcode::v_dual_mov_b32)
-      cur_vopd.is_opy_only = true;
+   unsigned compat = is_vopd_compatible(ctx.program->gfx_level, first_info, second_info);
+   if (!compat)
+      return 0;
 
    assert(first->definitions.size() == 1);
    assert(first->definitions[0].size() == 1);
@@ -279,17 +326,16 @@ can_use_vopd(const SchedILPContext& ctx, unsigned idx, bool* prev_can_be_opx)
 
    /* Check for WaW dependency. */
    if (first->definitions[0].physReg() == second->definitions[0].physReg())
-      return false;
+      return 0;
 
    /* Check for RaW dependency. */
    for (Operand op : second->operands) {
       assert(op.size() == 1);
       if (first->definitions[0].physReg() == op.physReg())
-         return false;
+         return 0;
    }
 
    /* WaR dependencies are not a concern before GFX12. */
-   *prev_can_be_opx = true;
    if (ctx.program->gfx_level >= GFX12) {
       /* From RDNA4 ISA doc:
        * The OPX instruction must not overwrite sources of the OPY instruction".
@@ -300,11 +346,13 @@ can_use_vopd(const SchedILPContext& ctx, unsigned idx, bool* prev_can_be_opx)
          if (second->definitions[0].physReg() == op.physReg())
             war = true;
       }
-      if (war)
-         *prev_can_be_opx = false;
+      if (war) {
+         compat &= ~vopd_second_is_opx;
+         compat = compat & vopd_first_is_opx ? compat : 0;
+      }
    }
 
-   return *prev_can_be_opx || !cur_vopd.is_opy_only;
+   return compat;
 }
 
 Instruction_cycle_info
@@ -642,17 +690,18 @@ select_instruction_ilp(const SchedILPContext& ctx)
 }
 
 bool
-compare_nodes_vopd(const SchedILPContext& ctx, int num_vopd_odd_minus_even, bool* use_vopd,
-                   bool* prev_can_be_opx, unsigned current, unsigned candidate)
+compare_nodes_vopd(const SchedILPContext& ctx, int num_vopd_odd_minus_even, unsigned* vopd_compat,
+                   unsigned current, unsigned candidate)
 {
-   if (can_use_vopd(ctx, candidate, prev_can_be_opx)) {
+   unsigned candidate_compat = can_use_vopd(ctx, candidate);
+   if (candidate_compat) {
       /* If we can form a VOPD instruction, always prefer to do so. */
-      if (!*use_vopd) {
-         *use_vopd = true;
+      if (!*vopd_compat) {
+         *vopd_compat = candidate_compat;
          return true;
       }
    } else {
-      if (*use_vopd)
+      if (*vopd_compat)
          return false;
 
       /* Neither current nor candidate can form a VOPD instruction with the previously scheduled
@@ -677,13 +726,17 @@ compare_nodes_vopd(const SchedILPContext& ctx, int num_vopd_odd_minus_even, bool
       }
    }
 
-   return ctx.nodes[candidate].wait_cycles < ctx.nodes[current].wait_cycles;
+   if (ctx.nodes[candidate].wait_cycles < ctx.nodes[current].wait_cycles) {
+      *vopd_compat = candidate_compat;
+      return true;
+   }
+   return false;
 }
 
 unsigned
-select_instruction_vopd(const SchedILPContext& ctx, bool* use_vopd, bool* prev_can_be_opx)
+select_instruction_vopd(const SchedILPContext& ctx, unsigned* vopd_compat)
 {
-   *use_vopd = false;
+   *vopd_compat = 0;
 
    mask_t mask = ctx.active_mask;
    if (ctx.next_non_reorderable != UINT8_MAX)
@@ -703,14 +756,11 @@ select_instruction_vopd(const SchedILPContext& ctx, bool* use_vopd, bool* prev_c
       if (candidate.dependency_mask)
          continue;
 
-      bool prev_can_be_opx_for_i;
       if (cur == -1u) {
          cur = i;
-         *use_vopd = can_use_vopd(ctx, i, prev_can_be_opx);
-      } else if (compare_nodes_vopd(ctx, num_vopd_odd_minus_even, use_vopd, &prev_can_be_opx_for_i,
-                                    cur, i)) {
+         *vopd_compat = can_use_vopd(ctx, i);
+      } else if (compare_nodes_vopd(ctx, num_vopd_odd_minus_even, vopd_compat, cur, i)) {
          cur = i;
-         *prev_can_be_opx = prev_can_be_opx_for_i;
       }
    }
 
@@ -746,37 +796,33 @@ get_vopd_opcode_operands(const SchedILPContext& ctx, Instruction* instr, const V
 }
 
 Instruction*
-create_vopd_instruction(const SchedILPContext& ctx, unsigned idx, bool prev_can_be_opx)
+create_vopd_instruction(const SchedILPContext& ctx, unsigned idx, unsigned compat)
 {
-   Instruction* x = ctx.prev_info.instr;
-   Instruction* y = ctx.nodes[idx].instr;
+   Instruction* x = ctx.prev_info.instr;  /* second */
+   Instruction* y = ctx.nodes[idx].instr; /* first */
    VOPDInfo x_info = ctx.prev_vopd_info;
    VOPDInfo y_info = ctx.vopd[idx];
-   x_info.is_opy_only |= !prev_can_be_opx;
+   x_info.can_be_opx = x_info.can_be_opx && (compat & vopd_second_is_opx);
 
    bool swap_x = false, swap_y = false;
-   if (x_info.src_banks & y_info.src_banks) {
+   if (compat & vopd_need_swap) {
       assert(x_info.is_commutative || y_info.is_commutative);
       /* Avoid swapping v_mov_b32 because it will become an OPY-only opcode. */
-      if (x_info.op == aco_opcode::v_dual_mov_b32 && y_info.op == aco_opcode::v_dual_mov_b32) {
-         swap_x = x_info.is_opy_only;
-         swap_y = !swap_x;
-      } else if (x_info.op == aco_opcode::v_dual_mov_b32 && !y_info.is_commutative) {
+      if (x_info.op == aco_opcode::v_dual_mov_b32 && !y_info.is_commutative) {
          swap_x = true;
-         x_info.is_opy_only = true;
+         x_info.can_be_opx = false;
       } else {
          swap_x = x_info.is_commutative && x_info.op != aco_opcode::v_dual_mov_b32;
          swap_y = y_info.is_commutative && !swap_x;
       }
-      y_info.is_opy_only |= swap_y && y_info.op == aco_opcode::v_dual_mov_b32;
    }
 
-   if (x_info.is_opy_only) {
+   if (!x_info.can_be_opx) {
       std::swap(x, y);
       std::swap(x_info, y_info);
       std::swap(swap_x, swap_y);
    }
-   assert(!x_info.is_opy_only);
+   assert(x_info.can_be_opx);
 
    aco_opcode x_op, y_op;
    unsigned num_operands = 0;
@@ -806,16 +852,15 @@ do_schedule(SchedILPContext& ctx, It& insert_it, It& remove_it, It instructions_
    }
 
    ctx.prev_info.instr = NULL;
-   bool use_vopd = false;
-   bool prev_can_be_opx;
+   unsigned vopd_compat = 0;
 
    while (ctx.active_mask) {
-      unsigned next_idx = ctx.is_vopd ? select_instruction_vopd(ctx, &use_vopd, &prev_can_be_opx)
-                                      : select_instruction_ilp(ctx);
+      unsigned next_idx =
+         ctx.is_vopd ? select_instruction_vopd(ctx, &vopd_compat) : select_instruction_ilp(ctx);
       Instruction* next_instr = ctx.nodes[next_idx].instr;
 
-      if (use_vopd) {
-         std::prev(insert_it)->reset(create_vopd_instruction(ctx, next_idx, prev_can_be_opx));
+      if (vopd_compat) {
+         std::prev(insert_it)->reset(create_vopd_instruction(ctx, next_idx, vopd_compat));
          ctx.prev_info.instr = NULL;
       } else {
          (insert_it++)->reset(next_instr);
diff --git a/src/amd/compiler/aco_spill.cpp b/src/amd/compiler/aco_spill.cpp
index 8fd52790003..0daed1e2452 100644
--- a/src/amd/compiler/aco_spill.cpp
+++ b/src/amd/compiler/aco_spill.cpp
@@ -928,6 +928,7 @@ process_block(spill_ctx& ctx, unsigned block_idx, Block* block, RegisterDemand s
             float score = 0.0;
             Temp to_spill = Temp();
             bool spill_is_operand = false;
+            bool spill_is_clobbered = false;
             unsigned respill_slot = -1u;
             unsigned do_rematerialize = 0;
             unsigned avoid_respill = 0;
@@ -950,6 +951,7 @@ process_block(spill_ctx& ctx, unsigned block_idx, Block* block, RegisterDemand s
                if (can_rematerialize > do_rematerialize || loop_variable > avoid_respill ||
                    ctx.ssa_infos[t].score() > score) {
                   bool is_operand = false;
+                  bool is_clobbered = false;
                   bool can_spill = true;
                   for (auto& op : instr->operands) {
                      if (!op.isTemp() || op.getTemp() != var)
@@ -966,12 +968,13 @@ process_block(spill_ctx& ctx, unsigned block_idx, Block* block, RegisterDemand s
                         live_changes = get_temp_reg_changes(instr.get());
 
                      /* Don't spill operands if killing operands won't help with register pressure */
-                     if (RegisterDemand(op.getTemp()).exceeds(*live_changes)) {
+                     if (!op.isClobbered() && RegisterDemand(op.getTemp()).exceeds(*live_changes)) {
                         can_spill = false;
                         break;
                      }
 
                      is_operand = true;
+                     is_clobbered = op.isClobbered();
                      break;
                   }
                   if (!can_spill)
@@ -984,6 +987,7 @@ process_block(spill_ctx& ctx, unsigned block_idx, Block* block, RegisterDemand s
                   do_rematerialize = can_rematerialize;
                   avoid_respill = loop_variable || is_spilled_operand;
                   spill_is_operand = is_operand;
+                  spill_is_clobbered = is_clobbered;
 
                   /* This variable is spilled at the loop-header of the current loop.
                    * Re-use the spill-slot in order to avoid an extra store.
@@ -1000,7 +1004,8 @@ process_block(spill_ctx& ctx, unsigned block_idx, Block* block, RegisterDemand s
                /* We might not be able to spill all operands. Keep live_changes up-to-date so we
                 * stop when we spilled every operand we can.
                 */
-               *live_changes -= to_spill;
+               if (!spill_is_clobbered)
+                  *live_changes -= to_spill;
             }
 
             if (avoid_respill) {
@@ -1197,8 +1202,8 @@ setup_vgpr_spill_reload(spill_ctx& ctx, Block& block,
       offset_range =
          ctx.program->dev.scratch_global_offset_max - ctx.program->dev.scratch_global_offset_min;
    } else {
-      if (scratch_size < 4095)
-         offset_range = 4095 - scratch_size;
+      if (scratch_size < ctx.program->dev.buf_offset_max)
+         offset_range = ctx.program->dev.buf_offset_max - scratch_size;
       else
          offset_range = 0;
    }
diff --git a/src/amd/compiler/aco_validate.cpp b/src/amd/compiler/aco_validate.cpp
index 720a97cc244..02e97c798f1 100644
--- a/src/amd/compiler/aco_validate.cpp
+++ b/src/amd/compiler/aco_validate.cpp
@@ -887,6 +887,8 @@ validate_ir(Program* program)
                            program->gfx_level >= GFX12 ? (instr->operands.size() - 4) : 4;
                         if (instr->opcode != aco_opcode::image_bvh_intersect_ray &&
                             instr->opcode != aco_opcode::image_bvh64_intersect_ray &&
+                            instr->opcode != aco_opcode::image_bvh_dual_intersect_ray &&
+                            instr->opcode != aco_opcode::image_bvh8_intersect_ray &&
                             i < 3 + num_scalar) {
                            check(instr->operands[i].regClass() == v1,
                                  "first 4 GFX11 MIMG VADDR must be v1 if NSA is used", instr.get());
@@ -1472,11 +1474,13 @@ validate_ra(Program* program)
             assignments[def.tempId()].valid = true;
          }
 
-         int op_fixed_to_def = get_op_fixed_to_def(instr.get());
-         if (op_fixed_to_def != -1 &&
-             instr->definitions[0].physReg() != instr->operands[op_fixed_to_def].physReg()) {
-            err |= ra_fail(program, loc, Location(),
-                           "Operand %d must have the same register as definition", op_fixed_to_def);
+         unsigned fixed_def_idx = 0;
+         for (auto op_idx : get_ops_fixed_to_def(instr.get())) {
+            if (instr->definitions[fixed_def_idx++].physReg() !=
+                instr->operands[op_idx].physReg()) {
+               err |= ra_fail(program, loc, Location(),
+                              "Operand %d must have the same register as definition", op_idx);
+            }
          }
       }
    }
diff --git a/src/amd/compiler/tests/test_insert_nops.cpp b/src/amd/compiler/tests/test_insert_nops.cpp
index f1e12524ca5..96b372bbe81 100644
--- a/src/amd/compiler/tests/test_insert_nops.cpp
+++ b/src/amd/compiler/tests/test_insert_nops.cpp
@@ -2224,18 +2224,28 @@ BEGIN_TEST(insert_nops.setpc_gfx12)
 
    //! p_unit_test 9
    //! v1: %0:v[0] = v_mov_b32 %0:s[4]
-   //! v1: %0:v[1] = v_mov_b32 %0:s[5]
    //! v1: %0:v[2] = v_mov_b32 %0:vcc_lo
-   //! s1: %0:s[4] = s_mov_b32 0
-   //! s1: %0:s[5] = v_readfirstlane_b32 %0:v[0]
    //! s1: %0:vcc_lo = v_readfirstlane_b32 %0:v[1]
-   //! s_waitcnt_depctr va_vdst(0) va_sdst(0) va_vcc(0) sa_sdst(0)
+   //! s1: %0:s[4] = s_mov_b32 0
+   //! s_waitcnt_depctr va_vdst(0) va_vcc(0) sa_sdst(0)
    //! s_setpc_b64 0
    bld.pseudo(aco_opcode::p_unit_test, Operand::c32(9));
    bld.vop1(aco_opcode::v_mov_b32, Definition(PhysReg(256), v1), Operand(PhysReg(4), s1));
-   bld.vop1(aco_opcode::v_mov_b32, Definition(PhysReg(257), v1), Operand(PhysReg(5), s1));
    bld.vop1(aco_opcode::v_mov_b32, Definition(PhysReg(258), v1), Operand(PhysReg(vcc), s1));
+   bld.vop1(aco_opcode::v_readfirstlane_b32, Definition(vcc, s1), Operand(PhysReg(257), v1));
    bld.sop1(aco_opcode::s_mov_b32, Definition(PhysReg(4), s1), Operand::zero(4));
+   bld.sop1(aco_opcode::s_setpc_b64, Operand::zero(8));
+
+   //! p_unit_test 10
+   //! v1: %0:v[1] = v_mov_b32 %0:s[5]
+   //! v1: %0:v[2] = v_mov_b32 %0:vcc_lo
+   //! s1: %0:s[5] = v_readfirstlane_b32 %0:v[0]
+   //! s1: %0:vcc_lo = v_readfirstlane_b32 %0:v[1]
+   //! s_waitcnt_depctr va_vdst(0) va_sdst(0) va_vcc(0)
+   //! s_setpc_b64 0
+   bld.pseudo(aco_opcode::p_unit_test, Operand::c32(10));
+   bld.vop1(aco_opcode::v_mov_b32, Definition(PhysReg(257), v1), Operand(PhysReg(5), s1));
+   bld.vop1(aco_opcode::v_mov_b32, Definition(PhysReg(258), v1), Operand(PhysReg(vcc), s1));
    bld.vop1(aco_opcode::v_readfirstlane_b32, Definition(PhysReg(5), s1), Operand(PhysReg(256), v1));
    bld.vop1(aco_opcode::v_readfirstlane_b32, Definition(vcc, s1), Operand(PhysReg(257), v1));
    bld.sop1(aco_opcode::s_setpc_b64, Operand::zero(8));
diff --git a/src/amd/compiler/tests/test_regalloc.cpp b/src/amd/compiler/tests/test_regalloc.cpp
index 2155fc0f4bc..bd15d7562d7 100644
--- a/src/amd/compiler/tests/test_regalloc.cpp
+++ b/src/amd/compiler/tests/test_regalloc.cpp
@@ -670,3 +670,107 @@ BEGIN_TEST(regalloc.linear_vgpr.compact_for_future_phis)
       finish_ra_test(ra_test_policy());
    }
 END_TEST
+
+// TODO: If get_reg_impl() didn't fail here, only one of the s1 temporaries would be moved
+BEGIN_TEST(regalloc.pseudo_scalar_trans_vcc.get_reg_impl)
+   if (!setup_cs("", GFX12, CHIP_UNKNOWN))
+      return;
+
+   std::vector<Temp> tmps;
+   for (unsigned i = 0; i < 52; i++)
+      tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s2)));
+   tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s1)));
+   tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s1)));
+
+   //>> s1: %_:s[0] = v_s_sqrt_f32 0
+   bld.vop3(aco_opcode::v_s_sqrt_f32, bld.def(s1), Operand::c32(0));
+
+   //; for i in range(51):
+   //;    insert_pattern(f'p_unit_test %_:s[{4+i*2}-{5+i*2}]')
+   //! p_unit_test %_:vcc
+   //! p_unit_test %_:s[1]
+   //! p_unit_test %_:s[2]
+   for (Temp t : tmps)
+      bld.pseudo(aco_opcode::p_unit_test, t);
+
+   finish_ra_test(ra_test_policy());
+END_TEST
+
+BEGIN_TEST(regalloc.pseudo_scalar_trans_vcc.compact_relocate)
+   for (unsigned subvariant = 0; subvariant <= 3; subvariant++) {
+      const char* names[] = {"_fiftythree_s2", "_fiftythree_s2_one_s1",
+                             "_twentysix_s4_one_s2_one_s1", "_twentysix_s4_three_s1"};
+      if (!setup_cs("", GFX12, CHIP_UNKNOWN, names[subvariant]))
+         continue;
+
+      std::vector<Temp> tmps;
+      if (subvariant <= 1) {
+         for (unsigned i = 0; i < 53; i++)
+            tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s2, PhysReg(i * 2))));
+      } else if (subvariant >= 2) {
+         for (unsigned i = 0; i < 26; i++)
+            tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s4, PhysReg(i * 4))));
+      }
+      if (subvariant == 2) {
+         tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s2, PhysReg(104))));
+      } else if (subvariant == 3) {
+         tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s1, PhysReg(104))));
+         tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s1, PhysReg(105))));
+      }
+      if (subvariant >= 1)
+         tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s1, PhysReg(106))));
+
+      //~gfx12_twentysix_s4_one_s2_one_s1>> s1: %_:s[104] = v_s_sqrt_f32 0
+      //~gfx12_twentysix_s4_three_s1>> s1: %_:s[104] = v_s_sqrt_f32 0
+      //~gfx12_fiftythree_s2>> s1: %_:s[0] = v_s_sqrt_f32 0
+      //~gfx12_fiftythree_s2_one_s1>> s1: %_:s[0] = v_s_sqrt_f32 0
+      bld.vop3(aco_opcode::v_s_sqrt_f32, bld.def(s1), Operand::c32(0));
+
+      //; if variant in ['gfx12_fiftythree_s2', 'gfx12_fiftythree_s2_one_s1']:
+      //;    for i in range(52):
+      //;       insert_pattern(f'p_unit_test %_:s[{2+i*2}-{3+i*2}]')
+      //;    insert_pattern('p_unit_test %_:vcc')
+      //~gfx12_fiftythree_s2_one_s1! p_unit_test %_:s[1]
+      //; if variant in ['gfx12_twentysix_s4_one_s2_one_s1', 'gfx12_twentysix_s4_three_s1']:
+      //;    for i in range(26):
+      //;       insert_pattern(f'p_unit_test %_:s[{0+i*4}-{3+i*4}]')
+      //~gfx12_twentysix_s4_one_s2_one_s1! p_unit_test %_:vcc
+      //~gfx12_twentysix_s4_one_s2_one_s1! p_unit_test %_:s[105]
+      //~gfx12_twentysix_s4_three_s1! p_unit_test %_:s[105]
+      //~gfx12_twentysix_s4_three_s1! p_unit_test %_:vcc_lo
+      //~gfx12_twentysix_s4_three_s1! p_unit_test %_:vcc_hi
+      for (Temp t : tmps)
+         bld.pseudo(aco_opcode::p_unit_test, t);
+
+      finish_ra_test(ra_test_policy{.use_compact_relocate = true});
+   }
+END_TEST
+
+/* Without some care, we can use too many registers when the definition/killed-operand space is a
+ * NPOT size.
+ */
+BEGIN_TEST(regalloc.compact_relocate.npot_space)
+   if (!setup_cs("", GFX12, CHIP_UNKNOWN))
+      return;
+
+   std::vector<Temp> tmps;
+   for (unsigned i = 0; i < 25; i++)
+      tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s4, PhysReg(i * 4))));
+   tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s2, PhysReg(100))));
+   tmps.push_back(bld.pseudo(aco_opcode::p_unit_test, bld.def(s1, PhysReg(102))));
+
+   Temp desc = bld.pseudo(aco_opcode::p_unit_test, bld.def(s4, PhysReg(103)));
+   Temp offset = bld.pseudo(aco_opcode::p_unit_test, bld.def(s1, PhysReg(104)));
+
+   //>> s4: %30:s[100-103] = s_buffer_load_dwordx4 %_:s[100-103], %_:s[104]
+   bld.smem(aco_opcode::s_buffer_load_dwordx4, bld.def(s4), desc, offset);
+
+   //; for i in range(25):
+   //;    insert_pattern(f'p_unit_test %_:s[{i*4}-{3+i*4}]')
+   //! p_unit_test %_:vcc
+   //! p_unit_test %_:s[105]
+   for (Temp t : tmps)
+      bld.pseudo(aco_opcode::p_unit_test, t);
+
+   finish_ra_test(ra_test_policy{.use_compact_relocate = true});
+END_TEST
diff --git a/src/amd/compiler/tests/test_scheduler.cpp b/src/amd/compiler/tests/test_scheduler.cpp
index f48a7ec91e8..9b861f7a792 100644
--- a/src/amd/compiler/tests/test_scheduler.cpp
+++ b/src/amd/compiler/tests/test_scheduler.cpp
@@ -78,80 +78,90 @@ BEGIN_TEST(vopd_sched.commutative)
 END_TEST
 
 BEGIN_TEST(vopd_sched.mov_to_add_bfrev)
-   if (!setup_cs(NULL, GFX11, CHIP_UNKNOWN, "", 32))
-      return;
+   for (amd_gfx_level gfx : {GFX11, GFX12}) {
+      if (!setup_cs(NULL, gfx, CHIP_UNKNOWN, "", 32))
+         continue;
 
-   PhysReg reg_v0{256};
-   PhysReg reg_v1{257};
-   PhysReg reg_v2{258};
-   PhysReg reg_v3{259};
+      PhysReg reg_v0{256};
+      PhysReg reg_v1{257};
+      PhysReg reg_v2{258};
+      PhysReg reg_v3{259};
 
-   //>> p_unit_test 0
-   //! v1: %0:v[1] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[0] = v_dual_add_nc_u32 0, %0:v[2]
-   bld.pseudo(aco_opcode::p_unit_test, Operand::zero());
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v1, v1), Operand(reg_v2, v1));
+      //>> p_unit_test 0
+      //~gfx11! v1: %0:v[1] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[0] = v_dual_add_nc_u32 0, %0:v[2]
+      //~gfx12! v1: %0:v[1] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[0] = v_dual_mov_b32 %0:v[2]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::zero());
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v1, v1), Operand(reg_v2, v1));
 
-   /* We can't turn the v_mov_b32 into a v_add_u32 because then both instructions would be OPY-only.
-    */
-   bld.reset(program->create_and_insert_block());
-   //>> p_unit_test 1
-   //! v1: %0:v[0] = v_mov_b32 %0:v[2]
-   //! v1: %0:v[1] = v_lshlrev_b32 %0:v[2], %0:v[3]
-   bld.pseudo(aco_opcode::p_unit_test, Operand::c32(1));
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
-   bld.vop2(aco_opcode::v_lshlrev_b32, Definition(reg_v1, v1), Operand(reg_v2, v1),
-            Operand(reg_v3, v1));
+      /* We can't turn the v_mov_b32 into a v_add_u32 because then both instructions would be
+       * OPY-only.
+       */
+      bld.reset(program->create_and_insert_block());
+      //>> p_unit_test 1
+      //~gfx11! v1: %0:v[0] = v_mov_b32 %0:v[2]
+      //~gfx11! v1: %0:v[1] = v_lshlrev_b32 %0:v[2], %0:v[3]
+      //~gfx12! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_lshlrev_b32 %0:v[2], %0:v[3]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(1));
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
+      bld.vop2(aco_opcode::v_lshlrev_b32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v3, v1));
 
-   bld.reset(program->create_and_insert_block());
-   //>> p_unit_test 2
-   //! v1: %0:v[1] = v_lshlrev_b32 %0:v[2], %0:v[3]
-   //! v1: %0:v[0] = v_mov_b32 %0:v[2]
-   bld.pseudo(aco_opcode::p_unit_test, Operand::c32(2));
-   bld.vop2(aco_opcode::v_lshlrev_b32, Definition(reg_v1, v1), Operand(reg_v2, v1),
-            Operand(reg_v3, v1));
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
+      bld.reset(program->create_and_insert_block());
+      //>> p_unit_test 2
+      //~gfx11! v1: %0:v[1] = v_lshlrev_b32 %0:v[2], %0:v[3]
+      //~gfx11! v1: %0:v[0] = v_mov_b32 %0:v[2]
+      //~gfx12! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_lshlrev_b32 %0:v[2], %0:v[3]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(2));
+      bld.vop2(aco_opcode::v_lshlrev_b32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v3, v1));
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
 
-   bld.reset(program->create_and_insert_block());
-   //>> p_unit_test 3
-   //! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_and_b32 %0:v[3], %0:v[2]
-   bld.pseudo(aco_opcode::p_unit_test, Operand::c32(3));
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
-   bld.vop2(aco_opcode::v_and_b32, Definition(reg_v1, v1), Operand(reg_v2, v1),
-            Operand(reg_v3, v1));
+      bld.reset(program->create_and_insert_block());
+      //>> p_unit_test 3
+      //~gfx11! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_and_b32 %0:v[3], %0:v[2]
+      //~gfx12! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_and_b32 %0:v[2], %0:v[3]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(3));
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
+      bld.vop2(aco_opcode::v_and_b32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v3, v1));
 
-   bld.reset(program->create_and_insert_block());
-   //>> p_unit_test 4
-   //! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_and_b32 %0:v[3], %0:v[2]
-   bld.pseudo(aco_opcode::p_unit_test, Operand::c32(4));
-   bld.vop2(aco_opcode::v_and_b32, Definition(reg_v1, v1), Operand(reg_v2, v1),
-            Operand(reg_v3, v1));
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
+      bld.reset(program->create_and_insert_block());
+      //>> p_unit_test 4
+      //~gfx11! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_and_b32 %0:v[3], %0:v[2]
+      //~gfx12! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_and_b32 %0:v[2], %0:v[3]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(4));
+      bld.vop2(aco_opcode::v_and_b32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v3, v1));
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
 
-   /* The v_add_u32 should be OPY, not OPX. */
-   bld.reset(program->create_and_insert_block());
-   //>> p_unit_test 5
-   //! v1: %0:v[1] = v_dual_fmamk_f32 %0:v[2], %0:v[3], 0 :: v1: %0:v[0] = v_dual_add_nc_u32 0, %0:v[2]
-   bld.pseudo(aco_opcode::p_unit_test, Operand::c32(5));
-   bld.vop2(aco_opcode::v_fmamk_f32, Definition(reg_v1, v1), Operand(reg_v2, v1),
-            Operand(reg_v3, v1), Operand::zero());
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
+      /* The v_add_u32 should be OPY, not OPX. */
+      bld.reset(program->create_and_insert_block());
+      //>> p_unit_test 5
+      //~gfx11! v1: %0:v[1] = v_dual_fmamk_f32 %0:v[2], %0:v[3], 0 :: v1: %0:v[0] = v_dual_add_nc_u32 0, %0:v[2]
+      //~gfx12! v1: %0:v[0] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[1] = v_dual_fmamk_f32 %0:v[2], %0:v[3], 0
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(5));
+      bld.vop2(aco_opcode::v_fmamk_f32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v3, v1), Operand::zero());
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
 
-   bld.reset(program->create_and_insert_block());
-   //>> p_unit_test 6
-   //! v1: %0:v[1] = v_dual_fmamk_f32 %0:v[2], %0:v[3], 0 :: v1: %0:v[0] = v_dual_add_nc_u32 0, %0:v[2]
-   bld.pseudo(aco_opcode::p_unit_test, Operand::c32(6));
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
-   bld.vop2(aco_opcode::v_fmamk_f32, Definition(reg_v1, v1), Operand(reg_v2, v1),
-            Operand(reg_v3, v1), Operand::zero());
+      bld.reset(program->create_and_insert_block());
+      //>> p_unit_test 6
+      //~gfx11! v1: %0:v[1] = v_dual_fmamk_f32 %0:v[2], %0:v[3], 0 :: v1: %0:v[0] = v_dual_add_nc_u32 0, %0:v[2]
+      //~gfx12! v1: %0:v[1] = v_dual_fmamk_f32 %0:v[2], %0:v[3], 0 :: v1: %0:v[0] = v_dual_mov_b32 %0:v[2]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(6));
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v2, v1));
+      bld.vop2(aco_opcode::v_fmamk_f32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v3, v1), Operand::zero());
 
-   //>> p_unit_test 7
-   //! v1: %0:v[1] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[0] = v_dual_mov_b32 0x3c000000
-   bld.pseudo(aco_opcode::p_unit_test, Operand::c32(7));
-   bld.vop1(aco_opcode::v_bfrev_b32, Definition(reg_v0, v1), Operand::c32(60));
-   bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v1, v1), Operand(reg_v2, v1));
+      //>> p_unit_test 7
+      //! v1: %0:v[1] = v_dual_mov_b32 %0:v[2] :: v1: %0:v[0] = v_dual_mov_b32 0x3c000000
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(7));
+      bld.vop1(aco_opcode::v_bfrev_b32, Definition(reg_v0, v1), Operand::c32(60));
+      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v1, v1), Operand(reg_v2, v1));
 
-   finish_schedule_vopd_test();
+      finish_schedule_vopd_test();
+   }
 END_TEST
 
 BEGIN_TEST(vopd_sched.war)
@@ -162,7 +172,6 @@ BEGIN_TEST(vopd_sched.war)
       PhysReg reg_v0{256};
       PhysReg reg_v1{257};
       PhysReg reg_v3{259};
-      PhysReg reg_v5{261};
 
       //>> p_unit_test 0
       //~gfx11! v1: %0:v[1] = v_dual_add_f32 %0:v[3], %0:v[1] :: v1: %0:v[0] = v_dual_mul_f32 %0:v[1], %0:v[3]
@@ -185,13 +194,97 @@ BEGIN_TEST(vopd_sched.war)
       bld.vop2(aco_opcode::v_mul_f32, Definition(reg_v1, v1), Operand(reg_v3, v1),
                Operand(reg_v1, v1));
 
-      /* Test that we swap the right v_mov_b32. */
+      finish_schedule_vopd_test();
+   }
+END_TEST
+
+BEGIN_TEST(vopd_sched.same_vgpr)
+   for (amd_gfx_level gfx : {GFX11, GFX12}) {
+      if (!setup_cs(NULL, gfx, CHIP_UNKNOWN, "", 32))
+         continue;
+
+      PhysReg reg_v0{256};
+      PhysReg reg_v1{257};
+      PhysReg reg_v2{258};
+      PhysReg reg_v3{259};
+
+      //>> p_unit_test 0
+      //~gfx11! v1: %0:v[1] = v_dual_add_f32 %0:v[1], %0:v[2] :: v1: %0:v[0] = v_dual_add_f32 %0:v[2], %0:v[0]
+      //~gfx12! v1: %0:v[1] = v_dual_add_f32 %0:v[2], %0:v[1] :: v1: %0:v[0] = v_dual_add_f32 %0:v[2], %0:v[0]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::zero());
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v0, v1), Operand(reg_v2, v1),
+               Operand(reg_v0, v1));
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v1, v1));
+
+      //>> p_unit_test 1
+      //~gfx11! v1: %0:v[1] = v_dual_add_f32 %0:v[2], %0:v[1] :: v1: %0:v[0] = v_dual_add_f32 %0:v[0], %0:v[2]
+      //~gfx12! v1: %0:v[1] = v_dual_add_f32 %0:v[1], %0:v[2] :: v1: %0:v[0] = v_dual_add_f32 %0:v[0], %0:v[2]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(1));
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v0, v1), Operand(reg_v0, v1),
+               Operand(reg_v2, v1));
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v1, v1), Operand(reg_v1, v1),
+               Operand(reg_v2, v1));
+
       //>> p_unit_test 2
-      //~gfx11! v1: %0:v[1] = v_dual_mov_b32 %0:v[5] :: v1: %0:v[0] = v_dual_add_nc_u32 0, %0:v[1]
-      //~gfx12! v1: %0:v[0] = v_dual_mov_b32 %0:v[1] :: v1: %0:v[1] = v_dual_add_nc_u32 0, %0:v[5]
+      //~gfx11! v1: %0:v[1] = v_dual_add_f32 %0:v[3], %0:v[2] :: v1: %0:v[0] = v_dual_add_f32 %0:v[2], %0:v[3]
+      //~gfx12! v1: %0:v[1] = v_dual_add_f32 %0:v[2], %0:v[3] :: v1: %0:v[0] = v_dual_add_f32 %0:v[2], %0:v[3]
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(2));
-      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v0, v1), Operand(reg_v1, v1));
-      bld.vop1(aco_opcode::v_mov_b32, Definition(reg_v1, v1), Operand(reg_v5, v1));
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v0, v1), Operand(reg_v2, v1),
+               Operand(reg_v3, v1));
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v3, v1));
+
+      //>> p_unit_test 3
+      //~gfx11! v1: %0:v[0] = v_add_f32 %0:v[2], %0:v[2]
+      //~gfx11! v1: %0:v[1] = v_add_f32 %0:v[2], %0:v[2]
+      //~gfx12! v1: %0:v[1] = v_dual_add_f32 %0:v[2], %0:v[2] :: v1: %0:v[0] = v_dual_add_f32 %0:v[2], %0:v[2]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(3));
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v0, v1), Operand(reg_v2, v1),
+               Operand(reg_v2, v1));
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v2, v1));
+
+      /* the sources can't be swapped because src0 is an SGPR */
+      //>> p_unit_test 4
+      //~gfx11! v1: %0:v[1] = v_mul_f32 %0:s[1], %0:v[2]
+      //~gfx11! v1: %0:v[0] = v_mul_f32 %0:s[2], %0:v[2]
+      //~gfx12! v1: %0:v[0] = v_dual_mul_f32 %0:s[2], %0:v[2] :: v1: %0:v[1] = v_dual_mul_f32 %0:s[1], %0:v[2]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(4));
+      bld.vop2(aco_opcode::v_mul_f32, Definition(reg_v1, v1), Operand(PhysReg(1), s1),
+               Operand(reg_v2, v1));
+      bld.vop2(aco_opcode::v_mul_f32, Definition(reg_v0, v1), Operand(PhysReg(2), s1),
+               Operand(reg_v2, v1));
+
+      /* fmamk uses src2 for the second source, which doesn't allow the same VGPR */
+      //>> p_unit_test 5
+      //! v1: %0:v[0] = v_fmamk_f32 %0:v[0], %0:v[2], 0x80
+      //! v1: %0:v[1] = v_fmamk_f32 %0:v[1], %0:v[2], 0x80
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(5));
+      bld.vop2(aco_opcode::v_fmamk_f32, Definition(reg_v0, v1), Operand(reg_v0, v1),
+               Operand(reg_v2, v1), Operand::literal32(128));
+      bld.vop2(aco_opcode::v_fmamk_f32, Definition(reg_v1, v1), Operand(reg_v1, v1),
+               Operand(reg_v2, v1), Operand::literal32(128));
+
+      /* the two sources have to be the same size */
+      //>> p_unit_test 6
+      //! v1: %0:v[0] = v_add_f32 %0:v[2], %0:v[2]
+      //! v1: %0:v[1] = v_dot2c_f32_f16 %0:v[2], %0:v[2]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(6));
+      bld.vop2(aco_opcode::v_add_f32, Definition(reg_v0, v1), Operand(reg_v2, v1),
+               Operand(reg_v2, v1));
+      bld.vop2(aco_opcode::v_dot2c_f32_f16, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v2, v1));
+
+      //>> p_unit_test 7
+      //~gfx11! v1: %0:v[0] = v_dot2c_f32_f16 %0:v[2], %0:v[2], %0:v[0]
+      //~gfx11! v1: %0:v[1] = v_dot2c_f32_f16 %0:v[2], %0:v[2], %0:v[1]
+      //~gfx12! v1: %0:v[1] = v_dual_dot2acc_f32_f16 %0:v[2], %0:v[2], %0:v[1] :: v1: %0:v[0] = v_dual_dot2acc_f32_f16 %0:v[2], %0:v[2], %0:v[0]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(7));
+      bld.vop2(aco_opcode::v_dot2c_f32_f16, Definition(reg_v0, v1), Operand(reg_v2, v1),
+               Operand(reg_v2, v1), Operand(reg_v0, v1));
+      bld.vop2(aco_opcode::v_dot2c_f32_f16, Definition(reg_v1, v1), Operand(reg_v2, v1),
+               Operand(reg_v2, v1), Operand(reg_v1, v1));
 
       finish_schedule_vopd_test();
    }
diff --git a/src/amd/compiler/tests/test_to_hw_instr.cpp b/src/amd/compiler/tests/test_to_hw_instr.cpp
index eb26b97ed5f..c638016198b 100644
--- a/src/amd/compiler/tests/test_to_hw_instr.cpp
+++ b/src/amd/compiler/tests/test_to_hw_instr.cpp
@@ -29,34 +29,34 @@ BEGIN_TEST(to_hw_instr.swap_subdword)
    v128_hi.reg_b += 2;
    v129_hi.reg_b += 2;
 
-   for (amd_gfx_level lvl : {GFX8, GFX9, GFX11}) {
+   for (amd_gfx_level lvl : {GFX8, GFX9, GFX10, GFX11}) {
       if (!setup_cs(NULL, lvl))
          continue;
 
-      //~gfx(8|9|11)>> p_unit_test 0
+      //>> p_unit_test 0
       //~gfx8! v1: %0:v[0] = v_alignbyte_b32 %0:v[0][0:16], %0:v[0][16:32], 2
-      //~gfx(9|11)! v1: %0:v[0] = v_pack_b32_f16 hi(%0:v[0][16:32]), %0:v[0][0:16]
+      //~gfx(9|10|11)! v1: %0:v[0] = v_pack_b32_f16 hi(%0:v[0][16:32]), %0:v[0][0:16]
       bld.pseudo(aco_opcode::p_unit_test, Operand::zero());
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
                  Operand(v0_hi, v2b), Operand(v0_lo, v2b));
 
-      //~gfx(8|9|11)! p_unit_test 1
+      //! p_unit_test 1
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
-      //~gfx(9|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
-      //~gfx[89]! v2b: %0:v[1][16:32] = v_mov_b32 %0:v[0][16:32] dst_sel:uword1 dst_preserve src0_sel:uword1
+      //~gfx(9|10|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
+      //~gfx(8|9|10)! v2b: %0:v[1][16:32] = v_mov_b32 %0:v[0][16:32] dst_sel:uword1 dst_preserve src0_sel:uword1
       //~gfx11! v2b: %0:v[1][16:32] = v_mov_b16 hi(%0:v[0][16:32]) opsel_hi
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(1u));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v1), Definition(v1_lo, v2b),
                  Operand(v1_lo, v1), Operand(v0_lo, v2b));
 
-      //~gfx(8|9|11)! p_unit_test 2
-      //~gfx[89]! v2b: %0:v[0][16:32] = v_mov_b32 %0:v[1][16:32] dst_sel:uword1 dst_preserve src0_sel:uword1
-      //~gfx[89]! v2b: %0:v[1][16:32] = v_mov_b32 %0:v[0][0:16] dst_sel:uword1 dst_preserve src0_sel:uword0
-      //~gfx[89]! v2b: %0:v[1][0:16] = v_xor_b32 %0:v[1][0:16], %0:v[0][0:16] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword0
-      //~gfx[89]! v2b: %0:v[0][0:16] = v_xor_b32 %0:v[1][0:16], %0:v[0][0:16] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword0
-      //~gfx[89]! v2b: %0:v[1][0:16] = v_xor_b32 %0:v[1][0:16], %0:v[0][0:16] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword0
+      //! p_unit_test 2
+      //~gfx(8|9|10)! v2b: %0:v[0][16:32] = v_mov_b32 %0:v[1][16:32] dst_sel:uword1 dst_preserve src0_sel:uword1
+      //~gfx(8|9|10)! v2b: %0:v[1][16:32] = v_mov_b32 %0:v[0][0:16] dst_sel:uword1 dst_preserve src0_sel:uword0
+      //~gfx(8|9|10)! v2b: %0:v[1][0:16] = v_xor_b32 %0:v[1][0:16], %0:v[0][0:16] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword0
+      //~gfx(8|9|10)! v2b: %0:v[0][0:16] = v_xor_b32 %0:v[1][0:16], %0:v[0][0:16] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword0
+      //~gfx(8|9|10)! v2b: %0:v[1][0:16] = v_xor_b32 %0:v[1][0:16], %0:v[0][0:16] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword0
       //~gfx11! v2b: %0:v[0][16:32] = v_mov_b16 hi(%0:v[1][16:32]) opsel_hi
       //~gfx11! v2b: %0:v[1][16:32] = v_mov_b16 %0:v[0][0:16] opsel_hi
       //~gfx11! v2b: %0:v[0][0:16],  v2b: %0:v[1][0:16] = v_swap_b16 %0:v[1][0:16], %0:v[0][0:16]
@@ -65,39 +65,39 @@ BEGIN_TEST(to_hw_instr.swap_subdword)
                  Definition(v1_hi, v2b), Operand(v1_lo, v1), Operand(v0_lo, v2b),
                  Operand(v0_lo, v2b));
 
-      //~gfx(8|9|11)! p_unit_test 3
+      //! p_unit_test 3
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
-      //~gfx(9|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
-      //~gfx[89]! v2b: %0:v[1][0:16] = v_mov_b32 %0:v[0][0:16] dst_sel:uword0 dst_preserve src0_sel:uword0
-      //~gfx[89]! v1b: %0:v[1][16:24] = v_mov_b32 %0:v[0][16:24] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2
+      //~gfx(9|10|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
+      //~gfx(8|9|10)! v2b: %0:v[1][0:16] = v_mov_b32 %0:v[0][0:16] dst_sel:uword0 dst_preserve src0_sel:uword0
+      //~gfx(8|9|10)! v1b: %0:v[1][16:24] = v_mov_b32 %0:v[0][16:24] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2
       //~gfx11! v2b: %0:v[1][0:16] = v_mov_b16 %0:v[0][0:16]
       //~gfx11! v1: %0:v[1] = v_perm_b32 %0:v[1], %0:v[0], 0x7020504
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(3u));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v1), Definition(v1_b3, v1b),
                  Operand(v1_lo, v1), Operand(v0_b3, v1b));
 
-      //~gfx(8|9|11)! p_unit_test 4
+      //! p_unit_test 4
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
-      //~gfx(9|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
-      //~gfx[89]! v1b: %0:v[1][8:16] = v_mov_b32 %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1
-      //~gfx[89]! v2b: %0:v[1][16:32] = v_mov_b32 %0:v[0][16:32] dst_sel:uword1 dst_preserve src0_sel:uword1
+      //~gfx(9|10|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
+      //~gfx(8|9|10)! v1b: %0:v[1][8:16] = v_mov_b32 %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1
+      //~gfx(8|9|10)! v2b: %0:v[1][16:32] = v_mov_b32 %0:v[0][16:32] dst_sel:uword1 dst_preserve src0_sel:uword1
       //~gfx11! v1: %0:v[1] = v_perm_b32 %0:v[1], %0:v[0], 0x7060104
       //~gfx11! v2b: %0:v[1][16:32] = v_mov_b16 hi(%0:v[0][16:32]) opsel_hi
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(4u));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v1), Definition(v1_lo, v1b),
                  Operand(v1_lo, v1), Operand(v0_lo, v1b));
 
-      //~gfx(8|9|11)! p_unit_test 5
+      //! p_unit_test 5
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[0], %0:v[1]
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[0], %0:v[1]
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[0], %0:v[1]
-      //~gfx(9|11)! v1: %0:v[1],  v1: %0:v[0] = v_swap_b32 %0:v[0], %0:v[1]
-      //~gfx[89]! v1b: %0:v[0][8:16] = v_mov_b32 %0:v[1][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1
-      //~gfx[89]! v1b: %0:v[0][24:32] = v_mov_b32 %0:v[1][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3
+      //~gfx(9|10|11)! v1: %0:v[1],  v1: %0:v[0] = v_swap_b32 %0:v[0], %0:v[1]
+      //~gfx(8|9|10)! v1b: %0:v[0][8:16] = v_mov_b32 %0:v[1][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1
+      //~gfx(8|9|10)! v1b: %0:v[0][24:32] = v_mov_b32 %0:v[1][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3
       //~gfx11! v1: %0:v[0] = v_perm_b32 %0:v[0], %0:v[1], 0x7060104
       //~gfx11! v1: %0:v[0] = v_perm_b32 %0:v[0], %0:v[1], 0x3060504
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(5u));
@@ -105,35 +105,35 @@ BEGIN_TEST(to_hw_instr.swap_subdword)
                  Definition(v1_lo, v1), Operand(v1_lo, v1b), Operand(v1_hi, v1b),
                  Operand(v0_lo, v1));
 
-      //~gfx(8|9|11)! p_unit_test 6
+      //! p_unit_test 6
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
-      //~gfx(9|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
+      //~gfx(9|10|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(6u));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
                  Definition(v1_lo, v1), Operand(v1_lo, v2b), Operand(v1_hi, v2b),
                  Operand(v0_lo, v1));
 
-      //~gfx(8|9|11)! p_unit_test 7
+      //! p_unit_test 7
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[0], %0:v[1]
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[0], %0:v[1]
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[0], %0:v[1]
-      //~gfx(9|11)! v1: %0:v[1],  v1: %0:v[0] = v_swap_b32 %0:v[0], %0:v[1]
-      //~gfx(8|9|11)! v1: %0:v[0] = v_alignbyte_b32 %0:v[0][0:16], %0:v[0][16:32], 2
+      //~gfx(9|10|11)! v1: %0:v[1],  v1: %0:v[0] = v_swap_b32 %0:v[0], %0:v[1]
+      //! v1: %0:v[0] = v_alignbyte_b32 %0:v[0][0:16], %0:v[0][16:32], 2
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(7u));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
                  Definition(v1_lo, v1), Operand(v1_hi, v2b), Operand(v1_lo, v2b),
                  Operand(v0_lo, v1));
 
-      //~gfx(8|9|11)! p_unit_test 8
+      //! p_unit_test 8
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
-      //~gfx(9|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
-      //~gfx[89]! v1b: %0:v[1][24:32] = v_xor_b32 %0:v[1][24:32], %0:v[0][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3 src1_sel:ubyte3
-      //~gfx[89]! v1b: %0:v[0][24:32] = v_xor_b32 %0:v[1][24:32], %0:v[0][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3 src1_sel:ubyte3
-      //~gfx[89]! v1b: %0:v[1][24:32] = v_xor_b32 %0:v[1][24:32], %0:v[0][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3 src1_sel:ubyte3
+      //~gfx(9|10|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
+      //~gfx(8|9|10)! v1b: %0:v[1][24:32] = v_xor_b32 %0:v[1][24:32], %0:v[0][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3 src1_sel:ubyte3
+      //~gfx(8|9|10)! v1b: %0:v[0][24:32] = v_xor_b32 %0:v[1][24:32], %0:v[0][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3 src1_sel:ubyte3
+      //~gfx(8|9|10)! v1b: %0:v[1][24:32] = v_xor_b32 %0:v[1][24:32], %0:v[0][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3 src1_sel:ubyte3
       //~gfx11! v2b: %0:v[0][0:16],  v2b: %0:v[1][16:32] = v_swap_b16 hi(%0:v[1][16:32]), %0:v[0][0:16]
       //~gfx11! v1: %0:v[0] = v_perm_b32 %0:v[0], 0, 0x5060704
       //~gfx11! v2b: %0:v[0][0:16],  v2b: %0:v[1][16:32] = v_swap_b16 hi(%0:v[1][16:32]), %0:v[0][0:16]
@@ -141,28 +141,28 @@ BEGIN_TEST(to_hw_instr.swap_subdword)
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v3b), Definition(v1_lo, v3b),
                  Operand(v1_lo, v3b), Operand(v0_lo, v3b));
 
-      //~gfx(8|9|11)! p_unit_test 9
+      //! p_unit_test 9
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[0] = v_xor_b32 %0:v[1], %0:v[0]
       //~gfx8! v1: %0:v[1] = v_xor_b32 %0:v[1], %0:v[0]
-      //~gfx(9|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
-      //~gfx[89]! v1b: %0:v[1][24:32] = v_mov_b32 %0:v[0][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3
+      //~gfx(9|10|11)! v1: %0:v[0],  v1: %0:v[1] = v_swap_b32 %0:v[1], %0:v[0]
+      //~gfx(8|9|10)! v1b: %0:v[1][24:32] = v_mov_b32 %0:v[0][24:32] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3
       //~gfx11! v1: %0:v[1] = v_perm_b32 %0:v[1], %0:v[0], 0x3060504
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(9u));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v3b), Definition(v1_lo, v3b),
                  Definition(v0_b3, v1b), Operand(v1_lo, v3b), Operand(v0_lo, v3b),
                  Operand(v1_b3, v1b));
 
-      //~gfx(8|9|11)! p_unit_test 10
-      //~gfx[89]! v1b: %0:v[1][8:16] = v_xor_b32 %0:v[1][8:16], %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1 src1_sel:ubyte1
-      //~gfx[89]! v1b: %0:v[0][8:16] = v_xor_b32 %0:v[1][8:16], %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1 src1_sel:ubyte1
-      //~gfx[89]! v1b: %0:v[1][8:16] = v_xor_b32 %0:v[1][8:16], %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1 src1_sel:ubyte1
+      //! p_unit_test 10
+      //~gfx(8|9|10)! v1b: %0:v[1][8:16] = v_xor_b32 %0:v[1][8:16], %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1 src1_sel:ubyte1
+      //~gfx(8|9|10)! v1b: %0:v[0][8:16] = v_xor_b32 %0:v[1][8:16], %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1 src1_sel:ubyte1
+      //~gfx(8|9|10)! v1b: %0:v[1][8:16] = v_xor_b32 %0:v[1][8:16], %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte1 src1_sel:ubyte1
       //~gfx11! v2b: %0:v[0][16:32],  v2b: %0:v[1][0:16] = v_swap_b16 %0:v[1][0:16], %0:v[0][16:32] opsel_hi
       //~gfx11! v1: %0:v[0] = v_perm_b32 %0:v[0], 0, 0x5060704
       //~gfx11! v2b: %0:v[0][16:32],  v2b: %0:v[1][0:16] = v_swap_b16 %0:v[1][0:16], %0:v[0][16:32] opsel_hi
-      //~gfx[89]! v1b: %0:v[1][16:24] = v_xor_b32 %0:v[1][16:24], %0:v[0][16:24] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2 src1_sel:ubyte2
-      //~gfx[89]! v1b: %0:v[0][16:24] = v_xor_b32 %0:v[1][16:24], %0:v[0][16:24] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2 src1_sel:ubyte2
-      //~gfx[89]! v1b: %0:v[1][16:24] = v_xor_b32 %0:v[1][16:24], %0:v[0][16:24] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2 src1_sel:ubyte2
+      //~gfx(8|9|10)! v1b: %0:v[1][16:24] = v_xor_b32 %0:v[1][16:24], %0:v[0][16:24] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2 src1_sel:ubyte2
+      //~gfx(8|9|10)! v1b: %0:v[0][16:24] = v_xor_b32 %0:v[1][16:24], %0:v[0][16:24] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2 src1_sel:ubyte2
+      //~gfx(8|9|10)! v1b: %0:v[1][16:24] = v_xor_b32 %0:v[1][16:24], %0:v[0][16:24] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2 src1_sel:ubyte2
       //~gfx11! v2b: %0:v[0][0:16],  v2b: %0:v[1][16:32] = v_swap_b16 hi(%0:v[1][16:32]), %0:v[0][0:16]
       //~gfx11! v1: %0:v[0] = v_perm_b32 %0:v[0], 0, 0x7040506
       //~gfx11! v2b: %0:v[0][0:16],  v2b: %0:v[1][16:32] = v_swap_b16 hi(%0:v[1][16:32]), %0:v[0][0:16]
@@ -170,27 +170,27 @@ BEGIN_TEST(to_hw_instr.swap_subdword)
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_b1, v2b), Definition(v1_b1, v2b),
                  Operand(v1_b1, v2b), Operand(v0_b1, v2b));
 
-      //~gfx(8|9|11)! p_unit_test 11
-      //~gfx[89]! v2b: %0:v[1][0:16] = v_mov_b32 %0:v[0][16:32] dst_sel:uword0 dst_preserve src0_sel:uword1
+      //! p_unit_test 11
+      //~gfx(8|9|10)! v2b: %0:v[1][0:16] = v_mov_b32 %0:v[0][16:32] dst_sel:uword0 dst_preserve src0_sel:uword1
       //~gfx11! v2b: %0:v[1][0:16] = v_mov_b16 hi(%0:v[0][16:32])
-      //~gfx(8|9|11)! v1: %0:v[0] = v_mov_b32 42
+      //! v1: %0:v[0] = v_mov_b32 42
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(11u));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v1), Definition(v1_lo, v2b),
                  Operand::c32(42u), Operand(v0_hi, v2b));
 
-      //~gfx(8|9|11)! p_unit_test 12
+      //! p_unit_test 12
       //~gfx[89]! v1b: %0:v[0][24:32] = v_xor_b32 %0:v[0][24:32], %0:v[0][8:16] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3 src1_sel:ubyte1
       //~gfx[89]! v1b: %0:v[0][8:16] = v_xor_b32 %0:v[0][24:32], %0:v[0][8:16] dst_sel:ubyte1 dst_preserve src0_sel:ubyte3 src1_sel:ubyte1
       //~gfx[89]! v1b: %0:v[0][24:32] = v_xor_b32 %0:v[0][24:32], %0:v[0][8:16] dst_sel:ubyte3 dst_preserve src0_sel:ubyte3 src1_sel:ubyte1
-      //~gfx11! v1: %0:v[0] = v_perm_b32 %0:v[0], 0, 0x5060704
+      //~gfx(10|11)! v1: %0:v[0] = v_perm_b32 %0:v[0], 0, 0x5060704
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(12u));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_b1, v1b), Definition(v0_b3, v1b),
                  Operand(v0_b3, v1b), Operand(v0_b1, v1b));
 
-      //~gfx(8|9|11)! p_unit_test 13
-      //~gfx[89]! v2b: %0:v[129][16:32] = v_xor_b32 %0:v[129][16:32], %0:v[128][0:16] dst_sel:uword1 dst_preserve src0_sel:uword1 src1_sel:uword0
-      //~gfx[89]! v2b: %0:v[128][0:16] = v_xor_b32 %0:v[129][16:32], %0:v[128][0:16] dst_sel:uword0 dst_preserve src0_sel:uword1 src1_sel:uword0
-      //~gfx[89]! v2b: %0:v[129][16:32] = v_xor_b32 %0:v[129][16:32], %0:v[128][0:16] dst_sel:uword1 dst_preserve src0_sel:uword1 src1_sel:uword0
+      //! p_unit_test 13
+      //~gfx(8|9|10)! v2b: %0:v[129][16:32] = v_xor_b32 %0:v[129][16:32], %0:v[128][0:16] dst_sel:uword1 dst_preserve src0_sel:uword1 src1_sel:uword0
+      //~gfx(8|9|10)! v2b: %0:v[128][0:16] = v_xor_b32 %0:v[129][16:32], %0:v[128][0:16] dst_sel:uword0 dst_preserve src0_sel:uword1 src1_sel:uword0
+      //~gfx(8|9|10)! v2b: %0:v[129][16:32] = v_xor_b32 %0:v[129][16:32], %0:v[128][0:16] dst_sel:uword1 dst_preserve src0_sel:uword1 src1_sel:uword0
       //~gfx11! v2b: %0:v[128][0:16] = v_xor_b16 hi(%0:v[129][16:32]), %0:v[128][0:16]
       //~gfx11! v2b: %0:v[129][16:32] = v_xor_b16 hi(%0:v[129][16:32]), %0:v[128][0:16] opsel_hi
       //~gfx11! v2b: %0:v[128][0:16] = v_xor_b16 hi(%0:v[129][16:32]), %0:v[128][0:16]
@@ -198,10 +198,10 @@ BEGIN_TEST(to_hw_instr.swap_subdword)
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v128_lo, v2b), Definition(v129_hi, v2b),
                  Operand(v129_hi, v2b), Operand(v128_lo, v2b));
 
-      //~gfx(8|9|11)! p_unit_test 14
-      //~gfx[89]! v2b: %0:v[129][0:16] = v_xor_b32 %0:v[129][0:16], %0:v[128][16:32] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword1
-      //~gfx[89]! v2b: %0:v[128][16:32] = v_xor_b32 %0:v[129][0:16], %0:v[128][16:32] dst_sel:uword1 dst_preserve src0_sel:uword0 src1_sel:uword1
-      //~gfx[89]! v2b: %0:v[129][0:16] = v_xor_b32 %0:v[129][0:16], %0:v[128][16:32] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword1
+      //! p_unit_test 14
+      //~gfx(8|9|10)! v2b: %0:v[129][0:16] = v_xor_b32 %0:v[129][0:16], %0:v[128][16:32] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword1
+      //~gfx(8|9|10)! v2b: %0:v[128][16:32] = v_xor_b32 %0:v[129][0:16], %0:v[128][16:32] dst_sel:uword1 dst_preserve src0_sel:uword0 src1_sel:uword1
+      //~gfx(8|9|10)! v2b: %0:v[129][0:16] = v_xor_b32 %0:v[129][0:16], %0:v[128][16:32] dst_sel:uword0 dst_preserve src0_sel:uword0 src1_sel:uword1
       //~gfx11! v2b: %0:v[128][16:32] = v_xor_b16 %0:v[129][0:16], hi(%0:v[128][16:32]) opsel_hi
       //~gfx11! v2b: %0:v[129][0:16] = v_xor_b16 %0:v[129][0:16], hi(%0:v[128][16:32])
       //~gfx11! v2b: %0:v[128][16:32] = v_xor_b16 %0:v[129][0:16], hi(%0:v[128][16:32]) opsel_hi
@@ -209,8 +209,17 @@ BEGIN_TEST(to_hw_instr.swap_subdword)
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v128_hi, v2b), Definition(v129_lo, v2b),
                  Operand(v129_lo, v2b), Operand(v128_hi, v2b));
 
+      //! p_unit_test 15
+      //~gfx[89]! v1b: %0:v[0][16:24] = v_xor_b32 %0:v[0][16:24], %0:v[0][0:8] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2 src1_sel:ubyte0
+      //~gfx[89]!v1b: %0:v[0][0:8] = v_xor_b32 %0:v[0][16:24], %0:v[0][0:8] dst_sel:ubyte0 dst_preserve src0_sel:ubyte2 src1_sel:ubyte0
+      //~gfx[89]!v1b: %0:v[0][16:24] = v_xor_b32 %0:v[0][16:24], %0:v[0][0:8] dst_sel:ubyte2 dst_preserve src0_sel:ubyte2 src1_sel:ubyte0
+      //~gfx(10|11)! v1: %0:v[0] = v_perm_b32 %0:v[0], 0, 0x7040506
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(15u));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v1b), Definition(v0_hi, v1b),
+                 Operand(v0_hi, v1b), Operand(v0_lo, v1b));
+
       //~gfx11! s_sendmsg sendmsg(dealloc_vgprs)
-      //~gfx(8|9|11)! s_endpgm
+      //! s_endpgm
 
       finish_to_hw_instr_test();
    }
@@ -725,7 +734,7 @@ BEGIN_TEST(to_hw_instr.pack2x16_constant)
    v0_hi.reg_b += 2;
    v1_hi.reg_b += 2;
 
-   for (amd_gfx_level lvl : {GFX10, GFX11}) {
+   for (amd_gfx_level lvl : {GFX9, GFX10, GFX11}) {
       if (!setup_cs(NULL, lvl))
          continue;
 
@@ -733,7 +742,9 @@ BEGIN_TEST(to_hw_instr.pack2x16_constant)
       program->blocks[0].fp_mode.denorm16_64 = fp_denorm_flush;
 
       //>> p_unit_test 0
-      //! v1: %_:v[0] = v_alignbyte_b32 0x3800, %_:v[1][16:32], 2
+      //~gfx9! v2b: %_:v[0][0:16] = v_lshrrev_b32 16, %_:v[1][16:32]
+      //~gfx9! v1: %_:v[0] = v_or_b32 0x38000000, %_:v[0]
+      //~gfx(10|11)! v1: %_:v[0] = v_alignbyte_b32 0x3800, %_:v[1][16:32], 2
       bld.pseudo(aco_opcode::p_unit_test, Operand::zero());
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
                  Operand(v1_hi, v2b), Operand::c16(0x3800));
@@ -745,7 +756,7 @@ BEGIN_TEST(to_hw_instr.pack2x16_constant)
                  Operand(v1_hi, v2b), Operand::zero(2));
 
       //! p_unit_test 2
-      //~gfx10! v2b: %_:v[0][0:16] = v_and_b32 0xffff, %_:v[1][0:16]
+      //~gfx(9|10)! v2b: %_:v[0][0:16] = v_and_b32 0xffff, %_:v[1][0:16]
       //~gfx11! v1: %_:v[0] = v_cvt_u32_u16 %_:v[1][0:16]
       bld.pseudo(aco_opcode::p_unit_test, Operand::c32(2));
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
@@ -763,6 +774,70 @@ BEGIN_TEST(to_hw_instr.pack2x16_constant)
       bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
                  Operand::zero(2), Operand(v1_lo, v2b));
 
+      //! p_unit_test 5
+      //~gfx9! v2b: %_:v[0][16:32] = v_lshlrev_b32 16, %_:v[1][0:16]
+      //~gfx9! v1: %_:v[0] = v_or_b32 0xff10, %_:v[0]
+      //~gfx(10|11)! v1: %_:v[0] = v_perm_b32 %_:v[1], 16, 0x5040d00
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(5));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
+                 Operand::c16(0xff10), Operand(v1_lo, v2b));
+
+      //! p_unit_test 6
+      //~gfx9! v2b: %_:v[0][16:32] = v_lshlrev_b32 16, %_:v[1][0:16]
+      //~gfx9! v1: %_:v[0] = v_or_b32 0x1000, %_:v[0]
+      //~gfx(10|11)! v1: %_:v[0] = v_perm_b32 %_:v[1], 16, 0x504000c
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(6));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
+                 Operand::c16(0x1000), Operand(v1_lo, v2b));
+
+      //! p_unit_test 7
+      //~gfx9! v2b: %_:v[0][0:16] = v_and_b32 0xffff, %_:v[1][0:16]
+      //~gfx9! v1: %_:v[0] = v_or_b32 0xff100000, %_:v[0]
+      //~gfx(10|11)! v1: %_:v[0] = v_perm_b32 16, %_:v[1], 0xd040100
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(7));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
+                 Operand(v1_lo, v2b), Operand::c16(0xff10));
+
+      //! p_unit_test 8
+      //~gfx9! v2b: %_:v[0][0:16] = v_and_b32 0xffff, %_:v[1][0:16]
+      //~gfx9! v1: %_:v[0] = v_or_b32 0x10ff0000, %_:v[0]
+      //~gfx(10|11)! v1: %_:v[0] = v_perm_b32 16, %_:v[1], 0x40d0100
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(8));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
+                 Operand(v1_lo, v2b), Operand::c16(0x10ff));
+
+      //! p_unit_test 9
+      //~gfx9! v2b: %_:v[0][0:16] = v_and_b32 0xffff, %_:v[1][0:16]
+      //~gfx9! v1: %_:v[0] = v_or_b32 0x10100000, %_:v[0]
+      //~gfx(10|11)! v1: %_:v[0] = v_perm_b32 16, %_:v[1], 0x4040100
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(9));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
+                 Operand(v1_lo, v2b), Operand::c16(0x1010));
+
+      //! p_unit_test 10
+      //~gfx(9|10)! v2b: %_:v[0][0:16] = v_and_b32 0xffff, %_:v[1][0:16]
+      //~gfx11! v1: %_:v[0] = v_cvt_u32_u16 %_:v[1][0:16]
+      //! v1: %_:v[0] = v_or_b32 0x10110000, %_:v[0]
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(10));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
+                 Operand(v1_lo, v2b), Operand::c16(0x1011));
+
+      //! p_unit_test 11
+      //~gfx9! v2b: %_:v[0][0:16] = v_and_b32 0xffff, %_:v[1][0:16]
+      //~gfx9! v1: %_:v[0] = v_or_b32 0xfff00000, %_:v[0]
+      //~gfx(10|11)! v1: %_:v[0] = v_perm_b32 -16, %_:v[1], 0x5040100
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(11));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
+                 Operand(v1_lo, v2b), Operand::c16(0xfff0));
+
+      //! p_unit_test 12
+      //~gfx9! v2b: %_:v[0][0:16] = v_and_b32 0xffff, %_:v[1][0:16]
+      //~gfx9! v1: %_:v[0] = v_or_b32 0xf00000, %_:v[0]
+      //~gfx(10|11)! v1: %_:v[0] = v_perm_b32 -16, %_:v[1], 0xc040100
+      bld.pseudo(aco_opcode::p_unit_test, Operand::c32(12));
+      bld.pseudo(aco_opcode::p_parallelcopy, Definition(v0_lo, v2b), Definition(v0_hi, v2b),
+                 Operand(v1_lo, v2b), Operand::c16(0x00f0));
+
       //~gfx11! s_sendmsg sendmsg(dealloc_vgprs)
       //! s_endpgm
 
diff --git a/src/amd/llvm/ac_llvm_build.c b/src/amd/llvm/ac_llvm_build.c
index 427189e9b80..7704dcce52b 100644
--- a/src/amd/llvm/ac_llvm_build.c
+++ b/src/amd/llvm/ac_llvm_build.c
@@ -61,12 +61,14 @@ void ac_llvm_context_init(struct ac_llvm_context *ctx, struct ac_llvm_compiler *
    ctx->i64 = LLVMIntTypeInContext(ctx->context, 64);
    ctx->i128 = LLVMIntTypeInContext(ctx->context, 128);
    ctx->intptr = ctx->i32;
+   ctx->bf16 = LLVMBFloatTypeInContext(ctx->context);
    ctx->f16 = LLVMHalfTypeInContext(ctx->context);
    ctx->f32 = LLVMFloatTypeInContext(ctx->context);
    ctx->f64 = LLVMDoubleTypeInContext(ctx->context);
    ctx->v4i8 = LLVMVectorType(ctx->i8, 4);
    ctx->v2i16 = LLVMVectorType(ctx->i16, 2);
    ctx->v4i16 = LLVMVectorType(ctx->i16, 4);
+   ctx->v2bf16 = LLVMVectorType(ctx->bf16, 2);
    ctx->v2f16 = LLVMVectorType(ctx->f16, 2);
    ctx->v4f16 = LLVMVectorType(ctx->f16, 4);
    ctx->v2i32 = LLVMVectorType(ctx->i32, 2);
diff --git a/src/amd/llvm/ac_llvm_build.h b/src/amd/llvm/ac_llvm_build.h
index 319737eab53..0fe02a67526 100644
--- a/src/amd/llvm/ac_llvm_build.h
+++ b/src/amd/llvm/ac_llvm_build.h
@@ -79,12 +79,14 @@ struct ac_llvm_context {
    LLVMTypeRef i64;
    LLVMTypeRef i128;
    LLVMTypeRef intptr;
+   LLVMTypeRef bf16;
    LLVMTypeRef f16;
    LLVMTypeRef f32;
    LLVMTypeRef f64;
    LLVMTypeRef v4i8;
    LLVMTypeRef v2i16;
    LLVMTypeRef v4i16;
+   LLVMTypeRef v2bf16;
    LLVMTypeRef v2f16;
    LLVMTypeRef v4f16;
    LLVMTypeRef v2i32;
diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 714dfe39e4d..60ac9a447d0 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -612,9 +612,13 @@ static bool visit_alu(struct ac_nir_context *ctx, const nir_alu_instr *instr)
       else
          result = LLVMBuildSub(ctx->ac.builder, src[0], src[1], "");
       break;
-   case nir_op_imul:
    case nir_op_imul24_relaxed:
+      result = ac_build_intrinsic(&ctx->ac, "llvm.amdgcn.mul.i24", ctx->ac.i32, src, 2, 0);
+      break;
    case nir_op_umul24_relaxed:
+      result = ac_build_intrinsic(&ctx->ac, "llvm.amdgcn.mul.u24", ctx->ac.i32, src, 2, 0);
+      break;
+   case nir_op_imul:
       if (instr->no_unsigned_wrap)
          result = LLVMBuildNUWMul(ctx->ac.builder, src[0], src[1], "");
       else if (instr->no_signed_wrap)
@@ -1222,6 +1226,15 @@ static bool visit_alu(struct ac_nir_context *ctx, const nir_alu_instr *instr)
       break;
    }
 
+   case nir_op_bfdot2_bfadd: {
+      const char *name = "llvm.amdgcn.fdot2";
+      src[0] = LLVMBuildBitCast(ctx->ac.builder, src[0], ctx->ac.v2bf16, "");
+      src[1] = LLVMBuildBitCast(ctx->ac.builder, src[1], ctx->ac.v2bf16, "");
+      src[2] = LLVMBuildBitCast(ctx->ac.builder, src[2], ctx->ac.bf16, "");
+      result = ac_build_intrinsic(&ctx->ac, name, def_type, src, 3, 0);
+      break;
+   }
+
    case nir_op_msad_4x8:
       result = ac_build_intrinsic(&ctx->ac, "llvm.amdgcn.msad.u8", ctx->ac.i32,
                                   (LLVMValueRef[]){src[1], src[0], src[2]}, 3, 0);
diff --git a/src/amd/vulkan/bvh/README.md b/src/amd/vulkan/bvh/README.md
new file mode 100644
index 00000000000..c9727f06281
--- /dev/null
+++ b/src/amd/vulkan/bvh/README.md
@@ -0,0 +1,157 @@
+
+# GFX12
+
+GFX12 introduces a new BVH encoding for the image_bvh_dual_intersect_ray and image_bvh8_intersect_ray instructions.
+
+## BVH8 box node
+
+| bitsize/range | name | description |
+| ------------ | ---- | ----------- |
+| 32 | `internal_child_offset` | Offset of child BVH8 box nodes in units of 8 bytes. |
+| 32 | `primitive_child_offset` | Offset of child primitive nodes in units of 8 bytes. |
+| 32 | `unused` | Used by amdvlk for storing the parent node ID. |
+| 32 | `origin_x` | x-offset applied to all child AABBs. |
+| 32 | `origin_y` | y-offset applied to all child AABBs. |
+| 32 | `origin_z` | z-offset applied to all child AABBs. |
+| 8 | `exponent_x` | |
+| 8 | `exponent_y` | |
+| 8 | `exponent_z` | |
+| 4 | `unused` | |
+| 4 | `child_count_minus_one` | |
+| 32 | `obb_matrix_index` | Selects a matrix for transforming the ray before performing intersection tests. `0x7F` to disable OBB. |
+| 96x8 | `children[8]` | |
+
+`children[8]` element layout:
+
+| bitsize/range | name | description |
+| ------------ | ---- | ----------- |
+| 12 | `min_x` | Fixed point child AABB coordinate. |
+| 12 | `min_y` | |
+| 4 | `cull_flags` | |
+| 4 | `unused` | |
+| 12 | `min_z` | |
+| 12 | `max_x` | |
+| 8 | `cull_mask` | |
+| 12 | `max_y` | |
+| 4 | `node_type` | |
+| 4 | `node_size` | Increment for the child offset in units of 128 bytes. |
+
+The coordinates of child AABBs are encoded as follows:
+- min: `floor((x - origin_x) / extent)`
+- max: `ceil((x - origin_x) / extent) - 1`
+
+image_bvh8_intersect_ray will return the node IDs of the child nodes.
+
+## Primitive node
+
+Highlevel layout:
+
+| bitsize/range | name | description |
+| ------------ | ---- | ----------- |
+| 52 | `header` | Misc information about this node. |
+| | `vertex_prefixes[3]` | |
+| | `data` | Compressed vertex positions followed by primitive/geometry index data. |
+| 29x`triangle_pair_count` | `pair_desc[triangle_pair_count]` | Misc information about a triangle pair. |
+
+`header` layout:
+
+| bitsize/range | name | description |
+| ------------ | ---- | ----------- |
+| 5 | `x_vertex_bits_minus_one` | |
+| 5 | `y_vertex_bits_minus_one` | |
+| 5 | `z_vertex_bits_minus_one` | |
+| 5 | `trailing_zero_bits` | |
+| 4 | `geometry_index_base_bits_div_2` | |
+| 4 | `geometry_index_bits_div_2` | |
+| 3 | `triangle_pair_count_minus_one` | |
+| 1 | `vertex_type` | |
+| 5 | `primitive_index_base_bits` | |
+| 5 | `primitive_index_bits` | |
+| 10 | `indices_midpoint` | Bit offset where the geometry and primitive indices start (geometry indices in negative direction, primitive indices in positive direction) |
+
+The `data` field is split in three sections:
+1. Vertex data, this is a list of floats which share the same
+   prefix and the same number of trailing zero bits. The decompressed
+   value (for example the x component of a vertex) is
+   `(prefix << 32 - prefix_bits_x) | read(x_vertex_bits) << trailing_zero_bits` where `prefix_bits_x` is derived from
+   `x_vertex_bits` and `trailing_zero_bits`
+   (`32 - x_vertex_bits - trailing_zero_bits`).
+2. Geometry indices.
+3. Primitive indices.
+
+Geometry indices are encoded the same way with the only difference being that geometry indices are read/written in negative direction starting from `indices_midpoint`. The indices section starts with a `*_index_base_bits`-bit value `*_index_base` which is the index of the first triangle. Subsequent triangles use indices calculated based on a `*_index_bits`-bit value:
+- `*_index = read(*_index_bits)` if `*_index_bits >= *_index_base_bits`
+- `*_index = read(*_index_bits) | (*_index_base & ~BITFIELD_MASK(*_index_bits))` otherwise.
+
+`pair_desc(s)` layout:
+
+| bitsize/range | name | description |
+| ------------ | ---- | ----------- |
+| 1 | `prim_range_stop` | |
+| 1 | `tri1_double_sided` | |
+| 1 | `tri1_opaque` | |
+| 4 | `tri1_v0_index` | Indices into `data`, `0xF` for procedural nodes. |
+| 4 | `tri1_v1_index` | `0xF` for procedural nodes. |
+| 4 | `tri1_v2_index` | |
+| `tri0` has identical fields: |
+| 1 | `tri0_double_sided` | |
+| 1 | `tri0_opaque` | |
+| 4 | `tri0_v0_index` | |
+| 4 | `tri0_v1_index` | |
+| 4 | `tri0_v2_index` | |
+
+image_bvh8_intersect_ray will return the following data for triangle nodes:
+
+| VGPR index | value |
+| ---------- | ----- |
+| 0 | t0 |
+| 1 | `(procedural0 << 31) \| u0` |
+| 2 | `(opaque0 << 31) \| v0` |
+| 3 | `(primitive_index0 << 1) \| backface0` |
+| 4 | t1 |
+| 5 | `(procedural1 << 31) \| u1` |
+| 6 | `(opaque1 << 31) \| v1` |
+| 7 | `(primitive_index1 << 1) \| backface1` |
+| 8 | `(geometry_index0 << 2) \| navigation_bits` |
+| 9 | `(geometry_index1 << 2) \| navigation_bits` |
+
+image_bvh8_intersect_ray will return the following data for procedural nodes:
+
+| VGPR index | value |
+| ---------- | ----- |
+| 3 | `primitive_index0 << 1` |
+| 8 | `(geometry_index0 << 2) \| navigation_bits` |
+| 9 | `(geometry_index1 << 2) \| navigation_bits` |
+
+`navigation_bits` is 0 if there are more triangle pairs to process, 1 if this was the last triangle pair and 3 if `prim_range_stop` is set.
+
+## Instance node
+
+| bitsize/range | name | description |
+| ------------ | ---- | ----------- |
+| 32x3x4 | `world_to_object` | |
+| 62 | `bvh_addr` | Units of 4 bytes. |
+| 1 | `aabbs` | Does the BLAS (only) contain AABBs? Used for pointer flag based culling. |
+| 1 | `unused` | |
+| 32 | `unused` | |
+| 24 | `user_data` | Returned by the intersect instruction for instance nodes. |
+| 8 | `cull_mask` | |
+| The instance node can have up to 4 quantized child nodes: |
+| 32 | `origin_x` | x-offset applied to all child AABBs. |
+| 32 | `origin_y` | y-offset applied to all child AABBs. |
+| 32 | `origin_z` | z-offset applied to all child AABBs. |
+| 8 | `exponent_x` | |
+| 8 | `exponent_y` | |
+| 8 | `exponent_z` | |
+| 4 | `unused` | |
+| 4 | `child_count_minus_one` | |
+| 96x4 | `children[4]` | |
+
+image_bvh8_intersect_ray will return:
+
+| VGPR index | value |
+| ---------- | ----- |
+| 2 | BLAS addr lo |
+| 3 | BLAS addr hi |
+| 6 | `user_data` |
+| 7 | `(child_ids[0] & 0xFF) \| ((child_ids[1] & 0xFF) << 8) \| ((child_ids[2] & 0xFF) << 16) \| ((child_ids[3] & 0xFF) << 24)` |
diff --git a/src/amd/vulkan/bvh/build_helpers.h b/src/amd/vulkan/bvh/build_helpers.h
index be05eac8856..14258005d7f 100644
--- a/src/amd/vulkan/bvh/build_helpers.h
+++ b/src/amd/vulkan/bvh/build_helpers.h
@@ -17,6 +17,10 @@ TYPE(radv_bvh_aabb_node, 4);
 TYPE(radv_bvh_instance_node, 8);
 TYPE(radv_bvh_box16_node, 4);
 TYPE(radv_bvh_box32_node, 4);
+TYPE(radv_gfx12_box_node, 4);
+TYPE(radv_gfx12_instance_node, 8);
+TYPE(radv_gfx12_instance_node_user_data, 4);
+TYPE(radv_gfx12_primitive_node, 4);
 
 uint32_t
 id_to_offset(uint32_t id)
@@ -67,87 +71,6 @@ ir_type_to_bvh_type(uint32_t type)
    return RADV_BVH_INVALID_NODE;
 }
 
-bool
-radv_build_triangle(inout vk_aabb bounds, VOID_REF dst_ptr, vk_bvh_geometry_data geom_data, uint32_t global_id)
-{
-   bool is_valid = true;
-   triangle_indices indices = load_indices(geom_data.indices, geom_data.index_format, global_id);
-
-   triangle_vertices vertices = load_vertices(geom_data.data, indices, geom_data.vertex_format, geom_data.stride);
-
-   /* An inactive triangle is one for which the first (X) component of any vertex is NaN. If any
-    * other vertex component is NaN, and the first is not, the behavior is undefined. If the vertex
-    * format does not have a NaN representation, then all triangles are considered active.
-    */
-   if (isnan(vertices.vertex[0].x) || isnan(vertices.vertex[1].x) || isnan(vertices.vertex[2].x))
-#if ALWAYS_ACTIVE
-      is_valid = false;
-#else
-      return false;
-#endif
-
-   if (geom_data.transform != NULL) {
-      mat4 transform = mat4(1.0);
-
-      for (uint32_t col = 0; col < 4; col++)
-         for (uint32_t row = 0; row < 3; row++)
-            transform[col][row] = DEREF(INDEX(float, geom_data.transform, col + row * 4));
-
-      for (uint32_t i = 0; i < 3; i++)
-         vertices.vertex[i] = transform * vertices.vertex[i];
-   }
-
-   REF(radv_bvh_triangle_node) node = REF(radv_bvh_triangle_node)(dst_ptr);
-
-   bounds.min = vec3(INFINITY);
-   bounds.max = vec3(-INFINITY);
-
-   for (uint32_t coord = 0; coord < 3; coord++)
-      for (uint32_t comp = 0; comp < 3; comp++) {
-         DEREF(node).coords[coord][comp] = vertices.vertex[coord][comp];
-         bounds.min[comp] = min(bounds.min[comp], vertices.vertex[coord][comp]);
-         bounds.max[comp] = max(bounds.max[comp], vertices.vertex[coord][comp]);
-      }
-
-   DEREF(node).triangle_id = global_id;
-   DEREF(node).geometry_id_and_flags = geom_data.geometry_id;
-   DEREF(node).id = 9;
-
-   return is_valid;
-}
-
-bool
-radv_build_aabb(inout vk_aabb bounds, VOID_REF src_ptr, VOID_REF dst_ptr, uint32_t geometry_id, uint32_t global_id)
-{
-   bool is_valid = true;
-   REF(radv_bvh_aabb_node) node = REF(radv_bvh_aabb_node)(dst_ptr);
-
-   for (uint32_t vec = 0; vec < 2; vec++)
-      for (uint32_t comp = 0; comp < 3; comp++) {
-         float coord = DEREF(INDEX(float, src_ptr, comp + vec * 3));
-
-         if (vec == 0)
-            bounds.min[comp] = coord;
-         else
-            bounds.max[comp] = coord;
-      }
-
-   /* An inactive AABB is one for which the minimum X coordinate is NaN. If any other component is
-    * NaN, and the first is not, the behavior is undefined.
-    */
-   if (isnan(bounds.min.x))
-#if ALWAYS_ACTIVE
-      is_valid = false;
-#else
-      return false;
-#endif
-
-   DEREF(node).primitive_id = global_id;
-   DEREF(node).geometry_id_and_flags = geometry_id;
-
-   return is_valid;
-}
-
 uint32_t
 radv_encode_sbt_offset_and_flags(uint32_t src)
 {
diff --git a/src/amd/vulkan/bvh/build_interface.h b/src/amd/vulkan/bvh/build_interface.h
index c0c06c98fed..8dd856c7c54 100644
--- a/src/amd/vulkan/bvh/build_interface.h
+++ b/src/amd/vulkan/bvh/build_interface.h
@@ -35,6 +35,16 @@ struct encode_args {
    uint32_t geometry_type;
 };
 
+struct encode_gfx12_args {
+   VOID_REF intermediate_bvh;
+   VOID_REF output_base;
+   REF(vk_ir_header) header;
+   uint32_t output_bvh_offset;
+   uint32_t leaf_node_offsets_offset;
+   uint32_t leaf_node_count;
+   uint32_t geometry_type;
+};
+
 struct header_args {
    REF(vk_ir_header) src;
    REF(radv_accel_struct_header) dst;
diff --git a/src/amd/vulkan/bvh/bvh.h b/src/amd/vulkan/bvh/bvh.h
index d15ad5f276b..162242f88a3 100644
--- a/src/amd/vulkan/bvh/bvh.h
+++ b/src/amd/vulkan/bvh/bvh.h
@@ -58,10 +58,12 @@ struct radv_accel_struct_header {
    uint64_t size;
 
    /* Everything after this gets updated/copied from the CPU. */
+   uint32_t geometry_type;
    uint32_t geometry_count;
    uint32_t primitive_base_indices_offset;
    uint64_t instance_offset;
    uint64_t instance_count;
+   uint32_t leaf_node_offsets_offset;
    uint32_t build_flags;
 };
 
@@ -114,4 +116,60 @@ struct radv_bvh_box32_node {
 #define RADV_BVH_ROOT_NODE    radv_bvh_node_box32
 #define RADV_BVH_INVALID_NODE 0xffffffffu
 
+/* GFX12 */
+
+#define RADV_GFX12_BVH_NODE_SIZE 128
+
+struct radv_gfx12_box_child {
+   uint32_t dword0;
+   uint32_t dword1;
+   uint32_t dword2;
+};
+
+#ifndef VULKAN
+typedef struct radv_gfx12_box_child radv_gfx12_box_child;
+#endif
+
+struct radv_gfx12_box_node {
+   uint32_t internal_base_id;
+   uint32_t primitive_base_id;
+   uint32_t unused;
+   vec3 origin;
+   uint32_t child_count_exponents;
+   uint32_t obb_matrix_index;
+   radv_gfx12_box_child children[8];
+};
+
+struct radv_gfx12_instance_node {
+   mat3x4 wto_matrix;
+   uint64_t pointer_flags_bvh_addr;
+   uint32_t unused;
+   uint32_t cull_mask_user_data;
+   vec3 origin;
+   uint32_t child_count_exponents;
+   radv_gfx12_box_child children[4];
+};
+
+struct radv_gfx12_instance_node_user_data {
+   mat3x4 otw_matrix;
+   uint32_t custom_instance;
+   uint32_t instance_index;
+   uint32_t bvh_offset;
+   uint32_t padding;
+   uint64_t blas_addr;
+   uint32_t primitive_base_indices_offset;
+   uint32_t leaf_node_offsets_offset;
+   uint32_t unused[12];
+};
+
+/* Size of the primitive header section in bits. */
+#define RADV_GFX12_PRIMITIVE_NODE_HEADER_SIZE 52
+
+/* Size of a primitive pair description in bits. */
+#define RADV_GFX12_PRIMITIVE_NODE_PAIR_DESC_SIZE 29
+
+struct radv_gfx12_primitive_node {
+   uint32_t dwords[32];
+};
+
 #endif /* BVH_H */
diff --git a/src/amd/vulkan/bvh/copy.comp b/src/amd/vulkan/bvh/copy.comp
index 52fac4e0bd3..2df5285c19f 100644
--- a/src/amd/vulkan/bvh/copy.comp
+++ b/src/amd/vulkan/bvh/copy.comp
@@ -71,7 +71,10 @@ main(void)
          DEREF(REF(uvec4)(copy_src_addr + offset));
 
       /* Do the adjustment inline in the same invocation that copies the data so that we don't have
-       * to synchronize. */
+       * to synchronize. This is only possible on pre-GFX12 HW because leaf nodes have a different
+       * order on GFX12.
+       */
+#if !GFX12
       if (offset < node_end && offset >= node_offset &&
           (offset - node_offset) % SIZEOF(radv_bvh_instance_node) == 0) {
          uint64_t idx = (offset - node_offset) / SIZEOF(radv_bvh_instance_node);
@@ -85,5 +88,6 @@ main(void)
             DEREF(REF(radv_bvh_instance_node)(copy_dst_addr + offset)).bvh_ptr = addr_to_node(blas_addr + bvh_offset);
          }
       }
+#endif
    }
 }
diff --git a/src/amd/vulkan/bvh/copy_blas_addrs_gfx12.comp b/src/amd/vulkan/bvh/copy_blas_addrs_gfx12.comp
new file mode 100644
index 00000000000..40e96256267
--- /dev/null
+++ b/src/amd/vulkan/bvh/copy_blas_addrs_gfx12.comp
@@ -0,0 +1,65 @@
+/*
+ * Copyright Â© 2022 Valve Corporation
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#version 460
+
+#extension GL_GOOGLE_include_directive : require
+
+#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int16 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int32 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int64 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
+#extension GL_EXT_scalar_block_layout : require
+#extension GL_EXT_buffer_reference : require
+#extension GL_EXT_buffer_reference2 : require
+
+layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;
+
+#include "build_interface.h"
+
+layout(push_constant) uniform CONSTS
+{
+   copy_args args;
+};
+
+void
+main(void)
+{
+   uint32_t global_id = gl_GlobalInvocationID.x;
+   uint32_t total_invocations = gl_NumWorkGroups.x * 64;
+
+   uint64_t accel_struct_addr = args.mode == RADV_COPY_MODE_SERIALIZE ? args.src_addr : args.dst_addr;
+   uint64_t serialized_addr = args.mode == RADV_COPY_MODE_SERIALIZE ? args.dst_addr : args.src_addr;
+
+   uint64_t blas_addrs = serialized_addr + SIZEOF(radv_accel_struct_serialization_header);
+
+   radv_accel_struct_serialization_header serialization_header =
+      DEREF(REF(radv_accel_struct_serialization_header)(serialized_addr));
+
+   radv_accel_struct_header header = DEREF(REF(radv_accel_struct_header)(accel_struct_addr));
+
+   for (uint32_t i = global_id; i < serialization_header.instance_count; i += total_invocations) {
+      uint64_t instance_offset_addr = accel_struct_addr + (header.leaf_node_offsets_offset + i * 4);
+      uint64_t instance_addr = accel_struct_addr + (header.bvh_offset + DEREF(REF(uint32_t)(instance_offset_addr)));
+      REF(radv_gfx12_instance_node) instance_node = REF(radv_gfx12_instance_node)(instance_addr);
+      REF(radv_gfx12_instance_node_user_data) instance_data =
+         REF(radv_gfx12_instance_node_user_data)(instance_addr + SIZEOF(radv_gfx12_instance_node));
+
+      if (args.mode == RADV_COPY_MODE_SERIALIZE) {
+         DEREF(INDEX(uint64_t, blas_addrs, i)) = DEREF(instance_data).blas_addr;
+      } else {
+         uint32_t bvh_offset = DEREF(instance_data).bvh_offset;
+
+         /* Replace the address while keeping the pointer flags. */
+         uint64_t pointer_flags_bvh_addr = DEREF(instance_node).pointer_flags_bvh_addr;
+         uint64_t blas_addr = DEREF(INDEX(uint64_t, blas_addrs, i));
+         DEREF(instance_node).pointer_flags_bvh_addr =
+            (pointer_flags_bvh_addr & 0xFFC0000000000000ul) | addr_to_node(blas_addr + bvh_offset);
+         DEREF(instance_data).blas_addr = blas_addr;
+      }
+   }
+}
diff --git a/src/amd/vulkan/bvh/encode.comp b/src/amd/vulkan/bvh/encode.comp
index f54cbdc843a..2941a716a0c 100644
--- a/src/amd/vulkan/bvh/encode.comp
+++ b/src/amd/vulkan/bvh/encode.comp
@@ -22,6 +22,7 @@ layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;
 
 #include "build_helpers.h"
 #include "build_interface.h"
+#include "encode.h"
 
 layout(push_constant) uniform CONSTS {
    encode_args args;
@@ -50,13 +51,9 @@ main()
 
          vk_ir_triangle_node src_node =
             DEREF(REF(vk_ir_triangle_node)(OFFSET(args.intermediate_bvh, gl_GlobalInvocationID.x * ir_leaf_node_size)));
-         REF(radv_bvh_triangle_node) dst_node =
-            REF(radv_bvh_triangle_node)(OFFSET(args.output_bvh, dst_leaf_offset + gl_GlobalInvocationID.x * output_leaf_node_size));
+         VOID_REF dst_node = OFFSET(args.output_bvh, dst_leaf_offset + gl_GlobalInvocationID.x * output_leaf_node_size);
 
-         DEREF(dst_node).coords = src_node.coords;
-         DEREF(dst_node).triangle_id = src_node.triangle_id;
-         DEREF(dst_node).geometry_id_and_flags = src_node.geometry_id_and_flags;
-         DEREF(dst_node).id = 9;
+         radv_encode_triangle_gfx10_3(dst_node, src_node);
 
          break;
       }
@@ -66,11 +63,9 @@ main()
 
          vk_ir_aabb_node src_node =
             DEREF(REF(vk_ir_aabb_node)(OFFSET(args.intermediate_bvh, gl_GlobalInvocationID.x * ir_leaf_node_size)));
-         REF(radv_bvh_aabb_node) dst_node =
-            REF(radv_bvh_aabb_node)(OFFSET(args.output_bvh, dst_leaf_offset + gl_GlobalInvocationID.x * output_leaf_node_size));
+         VOID_REF dst_node = OFFSET(args.output_bvh, dst_leaf_offset + gl_GlobalInvocationID.x * output_leaf_node_size);
 
-         DEREF(dst_node).primitive_id = src_node.primitive_id;
-         DEREF(dst_node).geometry_id_and_flags = src_node.geometry_id_and_flags;
+         radv_encode_aabb_gfx10_3(dst_node, src_node);
 
          break;
       }
@@ -196,23 +191,7 @@ main()
             if (type == vk_ir_node_instance) {
                vk_ir_instance_node src_node =
                   DEREF(REF(vk_ir_instance_node)(OFFSET(args.intermediate_bvh, offset)));
-               REF(radv_bvh_instance_node) dst_node =
-                  REF(radv_bvh_instance_node)(OFFSET(args.output_bvh, dst_offset));
-
-               radv_accel_struct_header blas_header =
-                  DEREF(REF(radv_accel_struct_header)(src_node.base_ptr));
-
-               DEREF(dst_node).bvh_ptr = addr_to_node(src_node.base_ptr + blas_header.bvh_offset);
-               DEREF(dst_node).bvh_offset = blas_header.bvh_offset;
-
-               mat4 transform = mat4(src_node.otw_matrix);
-               mat4 inv_transform = transpose(inverse(transpose(transform)));
-               DEREF(dst_node).wto_matrix = mat3x4(inv_transform);
-               DEREF(dst_node).otw_matrix = mat3x4(transform);
-
-               DEREF(dst_node).custom_instance_and_mask = src_node.custom_instance_and_mask;
-               DEREF(dst_node).sbt_offset_and_flags = radv_encode_sbt_offset_and_flags(src_node.sbt_offset_and_flags);
-               DEREF(dst_node).instance_id = src_node.instance_id;
+               radv_encode_instance_gfx10_3(OFFSET(args.output_bvh, dst_offset), src_node);
             }
          }
 
diff --git a/src/amd/vulkan/bvh/encode.h b/src/amd/vulkan/bvh/encode.h
new file mode 100644
index 00000000000..25abeb2ac8d
--- /dev/null
+++ b/src/amd/vulkan/bvh/encode.h
@@ -0,0 +1,324 @@
+/*
+ * Copyright Â© 2022 Friedrich Vock
+ * Copyright Â© 2025 Valve Corporation
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+/* Helpers for encoding BVH nodes on different HW generations. */
+
+#ifndef RADV_BVH_ENCODE_H
+#define RADV_BVH_ENCODE_H
+
+#include "build_helpers.h"
+
+void
+radv_encode_triangle_gfx10_3(VOID_REF dst_addr, vk_ir_triangle_node src)
+{
+   REF(radv_bvh_triangle_node) dst = REF(radv_bvh_triangle_node)(dst_addr);
+
+   DEREF(dst).coords = src.coords;
+   DEREF(dst).triangle_id = src.triangle_id;
+   DEREF(dst).geometry_id_and_flags = src.geometry_id_and_flags;
+   DEREF(dst).id = 9;
+}
+
+void
+radv_encode_aabb_gfx10_3(VOID_REF dst_addr, vk_ir_aabb_node src)
+{
+   REF(radv_bvh_aabb_node) dst = REF(radv_bvh_aabb_node)(dst_addr);
+
+   DEREF(dst).primitive_id = src.primitive_id;
+   DEREF(dst).geometry_id_and_flags = src.geometry_id_and_flags;
+}
+
+void
+radv_encode_instance_gfx10_3(VOID_REF dst_addr, vk_ir_instance_node src)
+{
+   REF(radv_bvh_instance_node) dst = REF(radv_bvh_instance_node)(dst_addr);
+
+   radv_accel_struct_header blas_header = DEREF(REF(radv_accel_struct_header)(src.base_ptr));
+
+   DEREF(dst).bvh_ptr = addr_to_node(src.base_ptr + blas_header.bvh_offset);
+   DEREF(dst).bvh_offset = blas_header.bvh_offset;
+
+   mat4 transform = mat4(src.otw_matrix);
+   mat4 inv_transform = transpose(inverse(transpose(transform)));
+   DEREF(dst).wto_matrix = mat3x4(inv_transform);
+   DEREF(dst).otw_matrix = mat3x4(transform);
+
+   DEREF(dst).custom_instance_and_mask = src.custom_instance_and_mask;
+   DEREF(dst).sbt_offset_and_flags = radv_encode_sbt_offset_and_flags(src.sbt_offset_and_flags);
+   DEREF(dst).instance_id = src.instance_id;
+}
+
+struct bit_writer {
+   uint64_t addr;
+   uint32_t offset;
+   uint32_t temp;
+   uint32_t count;
+   uint32_t total_count;
+};
+
+void
+bit_writer_init(out bit_writer writer, uint64_t addr)
+{
+   writer.addr = addr;
+   writer.offset = 0;
+   writer.temp = 0;
+   writer.count = 0;
+   writer.total_count = 0;
+}
+
+void
+bit_writer_write(inout bit_writer writer, uint32_t data, uint32_t bit_size)
+{
+   writer.total_count += bit_size;
+
+   if (writer.count + bit_size >= 32) {
+      writer.temp = writer.temp | (data << writer.count);
+
+      REF(uint32_t) dst = REF(uint32_t)(writer.addr + writer.offset);
+      DEREF(dst) = writer.temp;
+      writer.offset += 4;
+
+      bit_size = bit_size - (32 - writer.count);
+      if (writer.count == 0)
+         data = 0;
+      else
+         data = data >> (32 - writer.count);
+
+      writer.temp = 0;
+      writer.count = 0;
+   }
+
+   writer.temp = writer.temp | (data << writer.count);
+   writer.count += bit_size;
+}
+
+void
+bit_writer_skip_to(inout bit_writer writer, uint32_t target)
+{
+   /* Flush the remaining data. */
+   if (writer.count > 0) {
+      REF(uint32_t) dst = REF(uint32_t)(writer.addr + writer.offset);
+      DEREF(dst) = writer.temp;
+   }
+
+   writer.count = target % 32;
+   writer.total_count = target;
+   writer.offset = (target / 32) * 4;
+}
+
+void
+bit_writer_finish(inout bit_writer writer)
+{
+   /* Flush the remaining data. */
+   if (writer.count > 0) {
+      REF(uint32_t) dst = REF(uint32_t)(writer.addr + writer.offset);
+      DEREF(dst) = writer.temp;
+   }
+
+   writer.temp = 0;
+   writer.count = 0;
+   writer.total_count = 0;
+}
+
+void
+radv_encode_triangle_gfx12(VOID_REF dst, vk_ir_triangle_node src)
+{
+   bit_writer child_writer;
+   bit_writer_init(child_writer, dst);
+
+   bit_writer_write(child_writer, 31, 5); /* x_vertex_bits_minus_one */
+   bit_writer_write(child_writer, 31, 5); /* y_vertex_bits_minus_one */
+   bit_writer_write(child_writer, 31, 5); /* z_vertex_bits_minus_one */
+   bit_writer_write(child_writer, 0, 5);  /* trailing_zero_bits */
+   bit_writer_write(child_writer, 14, 4); /* geometry_index_base_bits_div_2 */
+   bit_writer_write(child_writer, 14, 4); /* geometry_index_bits_div_2 */
+   bit_writer_write(child_writer, 0, 3);  /* triangle_pair_count_minus_one */
+   bit_writer_write(child_writer, 0, 1);  /* vertex_type */
+   bit_writer_write(child_writer, 28, 5); /* primitive_index_base_bits */
+   bit_writer_write(child_writer, 28, 5); /* primitive_index_bits */
+   /* header + 9 floats + geometry_id */
+   bit_writer_write(child_writer, RADV_GFX12_PRIMITIVE_NODE_HEADER_SIZE + 9 * 32 + 28, 10);
+
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[0][0]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[0][1]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[0][2]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[1][0]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[1][1]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[1][2]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[2][0]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[2][1]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.coords[2][2]), 32);
+
+   bit_writer_write(child_writer, src.geometry_id_and_flags & 0xfffffff, 28);
+   bit_writer_write(child_writer, src.triangle_id, 28);
+
+   bit_writer_skip_to(child_writer, 32 * 32 - RADV_GFX12_PRIMITIVE_NODE_PAIR_DESC_SIZE);
+
+   uint32_t opaque = (src.geometry_id_and_flags & VK_GEOMETRY_OPAQUE) != 0 ? 1 : 0;
+
+   bit_writer_write(child_writer, 1, 1);      /* prim_range_stop */
+   bit_writer_write(child_writer, 0, 1);      /* tri1_double_sided */
+   bit_writer_write(child_writer, 0, 1);      /* tri1_opaque */
+   bit_writer_write(child_writer, 0, 4);      /* tri1_v0_index */
+   bit_writer_write(child_writer, 0, 4);      /* tri1_v1_index */
+   bit_writer_write(child_writer, 0, 4);      /* tri1_v2_index */
+   bit_writer_write(child_writer, 0, 1);      /* tri0_double_sided */
+   bit_writer_write(child_writer, opaque, 1); /* tri0_opaque */
+   bit_writer_write(child_writer, 0, 4);      /* tri0_v0_index */
+   bit_writer_write(child_writer, 1, 4);      /* tri0_v1_index */
+   bit_writer_write(child_writer, 2, 4);      /* tri0_v2_index */
+
+   bit_writer_finish(child_writer);
+}
+
+void
+radv_encode_aabb_gfx12(VOID_REF dst, vk_ir_aabb_node src)
+{
+   bit_writer child_writer;
+   bit_writer_init(child_writer, dst);
+
+   bit_writer_write(child_writer, 0, 5);  /* x_vertex_bits_minus_one */
+   bit_writer_write(child_writer, 0, 5);  /* y_vertex_bits_minus_one */
+   bit_writer_write(child_writer, 0, 5);  /* z_vertex_bits_minus_one */
+   bit_writer_write(child_writer, 0, 5);  /* trailing_zero_bits */
+   bit_writer_write(child_writer, 14, 4); /* geometry_index_base_bits_div_2 */
+   bit_writer_write(child_writer, 14, 4); /* geometry_index_bits_div_2 */
+   bit_writer_write(child_writer, 0, 3);  /* triangle_pair_count_minus_one */
+   bit_writer_write(child_writer, 0, 1);  /* vertex_type */
+   bit_writer_write(child_writer, 28, 5); /* primitive_index_base_bits */
+   bit_writer_write(child_writer, 28, 5); /* primitive_index_bits */
+   /* header + 6 floats + geometry_id */
+   bit_writer_write(child_writer, RADV_GFX12_PRIMITIVE_NODE_HEADER_SIZE + 6 * 32 + 28, 10);
+
+   bit_writer_write(child_writer, floatBitsToUint(src.base.aabb.min.x), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.base.aabb.min.y), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.base.aabb.min.z), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.base.aabb.max.x), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.base.aabb.max.y), 32);
+   bit_writer_write(child_writer, floatBitsToUint(src.base.aabb.max.z), 32);
+
+   bit_writer_write(child_writer, src.geometry_id_and_flags & 0xfffffff, 28);
+   bit_writer_write(child_writer, src.primitive_id, 28);
+
+   bit_writer_skip_to(child_writer, 32 * 32 - RADV_GFX12_PRIMITIVE_NODE_PAIR_DESC_SIZE);
+
+   uint32_t opaque = (src.geometry_id_and_flags & VK_GEOMETRY_OPAQUE) != 0 ? 1 : 0;
+
+   bit_writer_write(child_writer, 1, 1);      /* prim_range_stop */
+   bit_writer_write(child_writer, 0, 1);      /* tri1_double_sided */
+   bit_writer_write(child_writer, 0, 1);      /* tri1_opaque */
+   bit_writer_write(child_writer, 0, 4);      /* tri1_v0_index */
+   bit_writer_write(child_writer, 0, 4);      /* tri1_v1_index */
+   bit_writer_write(child_writer, 0, 4);      /* tri1_v2_index */
+   bit_writer_write(child_writer, 0, 1);      /* tri0_double_sided */
+   bit_writer_write(child_writer, opaque, 1); /* tri0_opaque */
+   bit_writer_write(child_writer, 0xf, 4);    /* tri0_v0_index */
+   bit_writer_write(child_writer, 0xf, 4);    /* tri0_v1_index */
+   bit_writer_write(child_writer, 0, 4);      /* tri0_v2_index */
+
+   bit_writer_finish(child_writer);
+}
+
+/* Writes both the HW node and user data. */
+void
+radv_encode_instance_gfx12(VOID_REF dst, vk_ir_instance_node src)
+{
+   bit_writer child_writer;
+   bit_writer_init(child_writer, dst);
+
+   radv_accel_struct_header blas_header = DEREF(REF(radv_accel_struct_header)(src.base_ptr));
+
+   mat4 transform = mat4(src.otw_matrix);
+   mat4 wto_matrix = transpose(inverse(transpose(transform)));
+
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[0][0]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[0][1]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[0][2]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[0][3]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[1][0]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[1][1]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[1][2]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[1][3]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[2][0]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[2][1]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[2][2]), 32);
+   bit_writer_write(child_writer, floatBitsToUint(wto_matrix[2][3]), 32);
+
+   uint32_t flags = src.sbt_offset_and_flags >> 24;
+   uint32_t instance_pointer_flags = 0;
+   if ((flags & VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR) != 0)
+      instance_pointer_flags |= 1;
+   if ((flags & VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR) != 0)
+      instance_pointer_flags |= 2;
+   if ((flags & VK_GEOMETRY_INSTANCE_TRIANGLE_FACING_CULL_DISABLE_BIT_KHR) != 0 ||
+       blas_header.geometry_type == VK_GEOMETRY_TYPE_AABBS_KHR)
+      instance_pointer_flags |= 4;
+   if ((flags & VK_GEOMETRY_INSTANCE_TRIANGLE_FLIP_FACING_BIT_KHR) != 0)
+      instance_pointer_flags |= 8;
+
+   if (blas_header.geometry_type == VK_GEOMETRY_TYPE_TRIANGLES_KHR)
+      instance_pointer_flags |= 512;
+   else
+      instance_pointer_flags |= 256;
+
+   uint64_t bvh_addr = addr_to_node(src.base_ptr + blas_header.bvh_offset);
+   bit_writer_write(child_writer, uint32_t(bvh_addr & 0xffffffff), 32);
+   bit_writer_write(child_writer, uint32_t(bvh_addr >> 32) | (instance_pointer_flags << (54 - 32)), 32);
+   bit_writer_write(child_writer, src.custom_instance_and_mask & 0xffffff, 32);
+   bit_writer_write(child_writer, src.sbt_offset_and_flags & 0xffffff, 24);
+   bit_writer_write(child_writer, src.custom_instance_and_mask >> 24, 8);
+
+   bit_writer_write(child_writer, floatBitsToUint(blas_header.aabb.min.x), 32);
+   bit_writer_write(child_writer, floatBitsToUint(blas_header.aabb.min.y), 32);
+   bit_writer_write(child_writer, floatBitsToUint(blas_header.aabb.min.z), 32);
+
+   vec3 child_extent = blas_header.aabb.max - blas_header.aabb.min;
+   uvec3 child_extent_exponents = uvec3(ceil(clamp(log2(child_extent) + 127.0, vec3(0.0), vec3(255))));
+
+   bit_writer_write(child_writer, child_extent_exponents.x, 8);
+   bit_writer_write(child_writer, child_extent_exponents.y, 8);
+   bit_writer_write(child_writer, child_extent_exponents.z, 8);
+   bit_writer_write(child_writer, 0, 4);
+   bit_writer_write(child_writer, 0, 4);
+
+   bit_writer_write(child_writer, 0, 12);
+   bit_writer_write(child_writer, 0, 12);
+   bit_writer_write(child_writer, 4, 8);
+   bit_writer_write(child_writer, 0, 12);
+   bit_writer_write(child_writer, 0xfff, 12);
+   bit_writer_write(child_writer, 0xff, 8);
+   bit_writer_write(child_writer, 0xfff, 12);
+   bit_writer_write(child_writer, 0xfff, 12);
+   bit_writer_write(child_writer, radv_bvh_node_box32, 4);
+   bit_writer_write(child_writer, 1, 4);
+
+   for (uint32_t remaining_child_index = 0; remaining_child_index < 3; remaining_child_index++) {
+      bit_writer_write(child_writer, 0xfff, 12);
+      bit_writer_write(child_writer, 0xfff, 12);
+      bit_writer_write(child_writer, 0xff, 8);
+      bit_writer_write(child_writer, 0xfff, 12);
+      bit_writer_write(child_writer, 0, 12);
+      bit_writer_write(child_writer, 0, 8);
+      bit_writer_write(child_writer, 0, 12);
+      bit_writer_write(child_writer, 0, 12);
+      bit_writer_write(child_writer, 0, 8);
+   }
+
+   bit_writer_finish(child_writer);
+
+   REF(radv_gfx12_instance_node_user_data) user_data =
+      REF(radv_gfx12_instance_node_user_data)(dst + RADV_GFX12_BVH_NODE_SIZE);
+   DEREF(user_data).otw_matrix = src.otw_matrix;
+   DEREF(user_data).custom_instance = src.custom_instance_and_mask & 0xffffff;
+   DEREF(user_data).instance_index = src.instance_id;
+   DEREF(user_data).bvh_offset = blas_header.bvh_offset;
+   DEREF(user_data).blas_addr = src.base_ptr;
+   DEREF(user_data).primitive_base_indices_offset = blas_header.primitive_base_indices_offset;
+   DEREF(user_data).leaf_node_offsets_offset = blas_header.leaf_node_offsets_offset;
+}
+
+#endif
diff --git a/src/amd/vulkan/bvh/encode_gfx12.comp b/src/amd/vulkan/bvh/encode_gfx12.comp
new file mode 100644
index 00000000000..805b662e6fd
--- /dev/null
+++ b/src/amd/vulkan/bvh/encode_gfx12.comp
@@ -0,0 +1,306 @@
+/*
+ * Copyright Â© 2022 Friedrich Vock
+ * Copyright Â© 2025 Valve Corporation
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#version 460
+
+#extension GL_GOOGLE_include_directive : require
+
+#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int16 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int32 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int64 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
+#extension GL_EXT_scalar_block_layout : require
+#extension GL_EXT_buffer_reference : require
+#extension GL_EXT_buffer_reference2 : require
+#extension GL_KHR_memory_scope_semantics : require
+#extension GL_KHR_shader_subgroup_basic : require
+#extension GL_KHR_shader_subgroup_shuffle : require
+#extension GL_KHR_shader_subgroup_ballot : require
+#extension GL_KHR_shader_subgroup_clustered : require
+
+layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;
+
+#define GFX12
+#define USE_GLOBAL_SYNC
+
+#include "build_helpers.h"
+#include "build_interface.h"
+#include "encode.h"
+#include "invocation_cluster.h"
+
+layout(push_constant) uniform CONSTS
+{
+   encode_gfx12_args args;
+};
+
+void
+set_parent(uint32_t child, uint32_t parent)
+{
+   uint64_t addr = args.output_base + args.output_bvh_offset - child / 16 * 4 - 4;
+   DEREF(REF(uint32_t)(addr)) = parent;
+}
+
+void
+encode_gfx12(uint32_t ir_leaf_node_size, REF(vk_ir_box_node) intermediate_internal_nodes, uint32_t node_index)
+{
+   /* Each invocation cluster encodes one internal node. */
+   radv_invocation_cluster cluster;
+   radv_invocation_cluster_init(cluster, 8);
+
+   REF(vk_ir_box_node) src_node = INDEX(vk_ir_box_node, intermediate_internal_nodes, node_index);
+   vk_ir_box_node src = DEREF(src_node);
+   bool is_root_node = node_index == DEREF(args.header).ir_internal_node_count - 1;
+
+   for (;;) {
+      /* Make changes to the current node's BVH offset value visible. */
+      memoryBarrier(gl_ScopeDevice, gl_StorageSemanticsBuffer,
+                    gl_SemanticsAcquireRelease | gl_SemanticsMakeAvailable | gl_SemanticsMakeVisible);
+
+      uint32_t bvh_offset;
+      if (cluster.invocation_index == 0) {
+         bvh_offset = is_root_node ? id_to_offset(RADV_BVH_ROOT_NODE) : DEREF(src_node).bvh_offset;
+      }
+      bvh_offset = radv_read_invocation(cluster, 0, bvh_offset);
+
+      if (bvh_offset == VK_UNKNOWN_BVH_OFFSET)
+         continue;
+
+      if (bvh_offset == VK_NULL_BVH_OFFSET)
+         break;
+
+      REF(radv_gfx12_box_node) dst = REF(radv_gfx12_box_node)(args.output_base + (args.output_bvh_offset + bvh_offset));
+
+      uint32_t node_id = pack_node_id(bvh_offset, radv_bvh_node_box32);
+
+      uint32_t child = RADV_BVH_INVALID_NODE;
+      if (cluster.invocation_index < 2)
+         child = src.children[cluster.invocation_index];
+
+      while (true) {
+         uint32_t valid_children = radv_ballot(cluster, child != RADV_BVH_INVALID_NODE);
+         if ((valid_children & 0x80) != 0 || valid_children == 0)
+            break;
+
+         float surface_area = -1.0;
+         bool is_valid_internal = child != RADV_BVH_INVALID_NODE && ir_id_to_type(child) == vk_ir_node_internal;
+         if (is_valid_internal) {
+            vk_aabb child_aabb = DEREF(REF(vk_ir_node) OFFSET(args.intermediate_bvh, ir_id_to_offset(child))).aabb;
+            surface_area = aabb_surface_area(child_aabb);
+         }
+
+         float max_surface_area = subgroupClusteredMax(surface_area, 8);
+
+         uint32_t collapse_index = findLSB(radv_ballot(cluster, is_valid_internal && surface_area == max_surface_area));
+         if (collapse_index == 0xffffffff)
+            break;
+
+         uint32_t right;
+         if (cluster.invocation_index == collapse_index) {
+            REF(vk_ir_box_node) child_node = REF(vk_ir_box_node) OFFSET(args.intermediate_bvh, ir_id_to_offset(child));
+            DEREF(child_node).bvh_offset = VK_NULL_BVH_OFFSET;
+
+            uint32_t left = DEREF(child_node).children[0];
+            right = DEREF(child_node).children[1];
+
+            if (left == RADV_BVH_INVALID_NODE) {
+               left = right;
+               right = RADV_BVH_INVALID_NODE;
+            }
+
+            child = left;
+         }
+         right = radv_read_invocation(cluster, collapse_index, right);
+
+         if (cluster.invocation_index == findMSB(valid_children) + 1)
+            child = right;
+      }
+
+      bool is_valid = child != RADV_BVH_INVALID_NODE;
+      bool is_valid_primitive = is_valid && ir_id_to_type(child) != vk_ir_node_internal;
+      bool is_valid_internal = is_valid && ir_id_to_type(child) == vk_ir_node_internal;
+
+      uint32_t child_leaf_node_count = bitCount(radv_ballot(cluster, is_valid_primitive));
+      uint32_t child_internal_node_count = bitCount(radv_ballot(cluster, is_valid_internal));
+
+      uint32_t leaf_node_size;
+      switch (args.geometry_type) {
+      case VK_GEOMETRY_TYPE_TRIANGLES_KHR:
+      case VK_GEOMETRY_TYPE_AABBS_KHR:
+         leaf_node_size = RADV_GFX12_BVH_NODE_SIZE;
+         break;
+      default:
+         /* instances */
+         leaf_node_size = 2 * RADV_GFX12_BVH_NODE_SIZE;
+         break;
+      }
+
+      uint32_t child_leaf_nodes_size = child_leaf_node_count * leaf_node_size;
+      uint32_t child_internal_nodes_size = child_internal_node_count * RADV_GFX12_BVH_NODE_SIZE;
+
+      uint32_t dst_leaf_offset;
+      uint32_t dst_internal_offset;
+      if (cluster.invocation_index == 0) {
+         dst_leaf_offset = atomicAdd(DEREF(args.header).dst_leaf_node_offset, child_leaf_nodes_size);
+         dst_internal_offset = atomicAdd(DEREF(args.header).dst_node_offset, child_internal_nodes_size);
+      }
+      dst_leaf_offset = radv_read_invocation(cluster, 0, dst_leaf_offset);
+      dst_internal_offset = radv_read_invocation(cluster, 0, dst_internal_offset);
+
+      uint32_t child_index = 0;
+      uint32_t dst_offset = 0;
+      if (is_valid_internal) {
+         child_index = bitCount(radv_ballot(cluster, true) & ((1u << cluster.invocation_index) - 1));
+         dst_offset = dst_internal_offset + child_index * RADV_GFX12_BVH_NODE_SIZE;
+
+         uint32_t offset = ir_id_to_offset(child);
+         REF(vk_ir_box_node) child_node = REF(vk_ir_box_node) OFFSET(args.intermediate_bvh, offset);
+         DEREF(child_node).bvh_offset = dst_offset;
+      }
+      if (is_valid_primitive) {
+         child_index = bitCount(radv_ballot(cluster, true) & ((1u << cluster.invocation_index) - 1));
+         dst_offset = dst_leaf_offset + child_index * leaf_node_size;
+         child_index += child_internal_node_count;
+      }
+
+      vec3 origin = src.base.aabb.min;
+      vec3 extent = src.base.aabb.max - src.base.aabb.min;
+
+      extent = uintBitsToFloat((floatBitsToUint(extent) + uvec3(0x7fffff)) & 0x7f800000);
+      uvec3 extent_exponents = floatBitsToUint(extent) >> 23;
+
+      uint32_t valid_child_count = child_leaf_node_count + child_internal_node_count;
+      if (cluster.invocation_index == 0) {
+         DEREF(dst).internal_base_id = pack_node_id(dst_internal_offset, 0);
+         DEREF(dst).primitive_base_id = pack_node_id(dst_leaf_offset, 0);
+         DEREF(dst).origin = origin;
+         DEREF(dst).child_count_exponents = extent_exponents.x | (extent_exponents.y << 8) |
+                                            (extent_exponents.z << 16) | ((valid_child_count - 1) << 28);
+         DEREF(dst).obb_matrix_index = 0x7f;
+      }
+
+      if (is_valid) {
+         uint32_t type = ir_id_to_type(child);
+         uint32_t offset = ir_id_to_offset(child);
+
+         uint32_t child_node_size_128b = 1;
+         uint32_t encoded_type = 0;
+         uint32_t cull_mask = 0xff;
+         if (type == vk_ir_node_internal) {
+            encoded_type = 5;
+         } else {
+            /* Write leaf node offset. */
+            uint32_t leaf_index = offset / ir_leaf_node_size;
+            REF(uint32_t) child_dst_offset = REF(uint32_t)(args.output_base + args.leaf_node_offsets_offset);
+            child_dst_offset = INDEX(uint32_t, child_dst_offset, leaf_index);
+            DEREF(child_dst_offset) = dst_offset;
+
+            VOID_REF dst_leaf_addr = args.output_base + args.output_bvh_offset + dst_offset;
+
+            switch (args.geometry_type) {
+            case VK_GEOMETRY_TYPE_TRIANGLES_KHR: {
+               vk_ir_triangle_node src_node = DEREF(REF(vk_ir_triangle_node)(OFFSET(args.intermediate_bvh, offset)));
+               radv_encode_triangle_gfx12(dst_leaf_addr, src_node);
+               break;
+            }
+            case VK_GEOMETRY_TYPE_AABBS_KHR: {
+               vk_ir_aabb_node src_node = DEREF(REF(vk_ir_aabb_node)(OFFSET(args.intermediate_bvh, offset)));
+               radv_encode_aabb_gfx12(dst_leaf_addr, src_node);
+               break;
+            }
+            default:
+               /* instances */
+               encoded_type = 6;
+               child_node_size_128b = 2;
+
+               vk_ir_instance_node src_node = DEREF(REF(vk_ir_instance_node)(OFFSET(args.intermediate_bvh, offset)));
+               radv_encode_instance_gfx12(dst_leaf_addr, src_node);
+
+               cull_mask = src_node.custom_instance_and_mask >> 24;
+
+               break;
+            }
+         }
+
+         vk_aabb child_aabb = DEREF(REF(vk_ir_node) OFFSET(args.intermediate_bvh, offset)).aabb;
+
+         radv_gfx12_box_child box_child;
+         /* TODO: subtree flags culling */
+         box_child.dword0 =
+            min(uint32_t(floor((child_aabb.min.x - origin.x) / extent.x * float(0x1000))), 0xfff) |
+            (min(uint32_t(floor((child_aabb.min.y - origin.y) / extent.y * float(0x1000))), 0xfff) << 12);
+         /* TODO: subtree mask culling */
+         box_child.dword1 =
+            min(uint32_t(floor((child_aabb.min.z - origin.z) / extent.z * float(0x1000))), 0xfff) |
+            (min(uint32_t(ceil((child_aabb.max.x - origin.x) / extent.x * float(0x1000))) - 1, 0xfff) << 12) |
+            (cull_mask << 24);
+         box_child.dword2 =
+            min(uint32_t(ceil((child_aabb.max.y - origin.y) / extent.y * float(0x1000))) - 1, 0xfff) |
+            (min(uint32_t(ceil((child_aabb.max.z - origin.z) / extent.z * float(0x1000))) - 1, 0xfff) << 12) |
+            (encoded_type << 24) | (child_node_size_128b << 28);
+         DEREF(dst).children[child_index] = box_child;
+
+         set_parent(pack_node_id(dst_offset, encoded_type), node_id);
+      } else {
+         child_index =
+            bitCount(radv_ballot(cluster, true) & ((1u << cluster.invocation_index) - 1)) + valid_child_count;
+         radv_gfx12_box_child null_child;
+         null_child.dword0 = 0xffffffff;
+         null_child.dword1 = 0xfff;
+         null_child.dword2 = 0;
+         DEREF(dst).children[child_index] = null_child;
+      }
+
+      /* Make changes to the children's BVH offset value available to the other invocations. */
+      memoryBarrier(gl_ScopeDevice, gl_StorageSemanticsBuffer,
+                    gl_SemanticsAcquireRelease | gl_SemanticsMakeAvailable | gl_SemanticsMakeVisible);
+      break;
+   }
+
+   if (is_root_node && cluster.invocation_index == 0) {
+      REF(radv_accel_struct_header) header = REF(radv_accel_struct_header)(args.output_base);
+      DEREF(header).aabb = src.base.aabb;
+      DEREF(header).bvh_offset = args.output_bvh_offset;
+
+      set_parent(RADV_BVH_ROOT_NODE, RADV_BVH_INVALID_NODE);
+   }
+}
+
+void
+main()
+{
+   uint32_t ir_leaf_node_size;
+   switch (args.geometry_type) {
+   case VK_GEOMETRY_TYPE_TRIANGLES_KHR: {
+      ir_leaf_node_size = SIZEOF(vk_ir_triangle_node);
+      break;
+   }
+   case VK_GEOMETRY_TYPE_AABBS_KHR: {
+      ir_leaf_node_size = SIZEOF(vk_ir_aabb_node);
+      break;
+   }
+   default:
+      /* instances */
+      ir_leaf_node_size = SIZEOF(vk_ir_instance_node);
+      break;
+   }
+
+   uint32_t intermediate_leaf_nodes_size = args.leaf_node_count * ir_leaf_node_size;
+   REF(vk_ir_box_node) intermediate_internal_nodes =
+      REF(vk_ir_box_node) OFFSET(args.intermediate_bvh, intermediate_leaf_nodes_size);
+
+   uint32_t ir_internal_node_count = DEREF(args.header).ir_internal_node_count;
+   uint32_t encode_invocation_count = ir_internal_node_count * 8;
+
+   uint32_t global_id = gl_GlobalInvocationID.x;
+   if (global_id >= encode_invocation_count)
+      return;
+
+   /* Revert the order so we start at the root */
+   uint32_t node_index = ir_internal_node_count - 1 - global_id / 8;
+   encode_gfx12(ir_leaf_node_size, intermediate_internal_nodes, node_index);
+}
diff --git a/src/amd/vulkan/bvh/invocation_cluster.h b/src/amd/vulkan/bvh/invocation_cluster.h
new file mode 100644
index 00000000000..ba206ae46bf
--- /dev/null
+++ b/src/amd/vulkan/bvh/invocation_cluster.h
@@ -0,0 +1,39 @@
+/*
+ * Copyright Â© 2025 Valve Corporation
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+/* Helpers for encoding BVH nodes on different HW generations. */
+
+#ifndef RADV_BVH_INVOCATION_CLUSTER_H
+#define RADV_BVH_INVOCATION_CLUSTER_H
+
+struct radv_invocation_cluster {
+   uint32_t invocation_index;
+   uint32_t cluster_index;
+   uint32_t cluster_size;
+};
+
+/* cluster_size has to be a power of two and <32. */
+void
+radv_invocation_cluster_init(out radv_invocation_cluster cluster, uint32_t cluster_size)
+{
+   cluster.invocation_index = gl_SubgroupInvocationID & (cluster_size - 1);
+   cluster.cluster_index = gl_SubgroupInvocationID / cluster_size;
+   cluster.cluster_size = cluster_size;
+}
+
+#define radv_read_invocation(cluster, index, value)                                                                    \
+   subgroupShuffle(value, (gl_SubgroupInvocationID & (~(cluster.cluster_size - 1))) + index)
+
+uint32_t
+radv_ballot(radv_invocation_cluster cluster, bool value)
+{
+   uvec4 ballot = subgroupBallot(value);
+   uint64_t ballot64 = uint64_t(ballot.x) | (uint64_t(ballot.y) << 32ul);
+   uint32_t cluster_shift = gl_SubgroupInvocationID & (~(cluster.cluster_size - 1));
+   return uint32_t((ballot64 >> cluster_shift) & ((1u << cluster.cluster_size) - 1));
+}
+
+#endif
diff --git a/src/amd/vulkan/bvh/meson.build b/src/amd/vulkan/bvh/meson.build
index ea08a9b364a..e3ab68cbd25 100644
--- a/src/amd/vulkan/bvh/meson.build
+++ b/src/amd/vulkan/bvh/meson.build
@@ -3,9 +3,24 @@
 
 # source file, output name, defines
 bvh_shaders = [
+  [
+    'copy_blas_addrs_gfx12.comp',
+    'copy_blas_addrs_gfx12',
+    [],
+  ],
   [
     'copy.comp',
     'copy',
+    ['GFX12=0'],
+  ],
+  [
+    'copy.comp',
+    'copy_gfx12',
+    ['GFX12=1'],
+  ],
+  [
+    'encode_gfx12.comp',
+    'encode_gfx12',
     [],
   ],
   [
@@ -28,6 +43,11 @@ bvh_shaders = [
     'update',
     [],
   ],
+  [
+    'update_gfx12.comp',
+    'update_gfx12',
+    [],
+  ],
   [
     'leaf.comp',
     'radv_leaf',
@@ -47,6 +67,8 @@ bvh_includes = files(
   'build_helpers.h',
   'build_interface.h',
   'bvh.h',
+  'encode.h',
+  'update.h',
   vk_bvh_include_dir + '/vk_build_helpers.h',
   vk_bvh_include_dir + '/vk_bvh.h',
 )
diff --git a/src/amd/vulkan/bvh/update.comp b/src/amd/vulkan/bvh/update.comp
index 8012d23f2ce..71f5314b056 100644
--- a/src/amd/vulkan/bvh/update.comp
+++ b/src/amd/vulkan/bvh/update.comp
@@ -21,6 +21,7 @@
 layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;
 
 #include "build_interface.h"
+#include "update.h"
 
 layout(push_constant) uniform CONSTS {
     update_args args;
@@ -56,10 +57,10 @@ void main() {
     vk_aabb bounds;
     bool is_active;
     if (args.geom_data.geometry_type == VK_GEOMETRY_TYPE_TRIANGLES_KHR) {
-        is_active = radv_build_triangle(bounds, dst_ptr, args.geom_data, gl_GlobalInvocationID.x);
+        is_active = radv_build_triangle(bounds, dst_ptr, args.geom_data, gl_GlobalInvocationID.x, false);
     } else {
         VOID_REF src_ptr = OFFSET(args.geom_data.data, src_offset);
-        is_active = radv_build_aabb(bounds, src_ptr, dst_ptr, args.geom_data.geometry_id, gl_GlobalInvocationID.x);
+        is_active = radv_build_aabb(bounds, src_ptr, dst_ptr, args.geom_data.geometry_id, gl_GlobalInvocationID.x, false);
     }
 
     if (!is_active)
diff --git a/src/amd/vulkan/bvh/update.h b/src/amd/vulkan/bvh/update.h
new file mode 100644
index 00000000000..8012f022961
--- /dev/null
+++ b/src/amd/vulkan/bvh/update.h
@@ -0,0 +1,107 @@
+/*
+ * Copyright Â© 2022 Konstantin Seurer
+ * Copyright Â© 2025 Valve Corporation
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#ifndef RADV_BVH_UPDATE_H
+#define RADV_BVH_UPDATE_H
+
+#include "encode.h"
+
+bool
+radv_build_triangle(inout vk_aabb bounds, VOID_REF dst_ptr, vk_bvh_geometry_data geom_data, uint32_t global_id,
+                    bool gfx12)
+{
+   bool is_valid = true;
+   triangle_indices indices = load_indices(geom_data.indices, geom_data.index_format, global_id);
+
+   triangle_vertices vertices = load_vertices(geom_data.data, indices, geom_data.vertex_format, geom_data.stride);
+
+   /* An inactive triangle is one for which the first (X) component of any vertex is NaN. If any
+    * other vertex component is NaN, and the first is not, the behavior is undefined. If the vertex
+    * format does not have a NaN representation, then all triangles are considered active.
+    */
+   if (isnan(vertices.vertex[0].x) || isnan(vertices.vertex[1].x) || isnan(vertices.vertex[2].x))
+#if ALWAYS_ACTIVE
+      is_valid = false;
+#else
+      return false;
+#endif
+
+   if (geom_data.transform != NULL) {
+      mat4 transform = mat4(1.0);
+
+      for (uint32_t col = 0; col < 4; col++)
+         for (uint32_t row = 0; row < 3; row++)
+            transform[col][row] = DEREF(INDEX(float, geom_data.transform, col + row * 4));
+
+      for (uint32_t i = 0; i < 3; i++)
+         vertices.vertex[i] = transform * vertices.vertex[i];
+   }
+
+   vk_ir_triangle_node node;
+
+   bounds.min = vec3(INFINITY);
+   bounds.max = vec3(-INFINITY);
+
+   for (uint32_t coord = 0; coord < 3; coord++) {
+      for (uint32_t comp = 0; comp < 3; comp++) {
+         node.coords[coord][comp] = vertices.vertex[coord][comp];
+         bounds.min[comp] = min(bounds.min[comp], vertices.vertex[coord][comp]);
+         bounds.max[comp] = max(bounds.max[comp], vertices.vertex[coord][comp]);
+      }
+   }
+
+   node.triangle_id = global_id;
+   node.geometry_id_and_flags = geom_data.geometry_id;
+
+   if (gfx12)
+      radv_encode_triangle_gfx12(dst_ptr, node);
+   else
+      radv_encode_triangle_gfx10_3(dst_ptr, node);
+
+   return is_valid;
+}
+
+bool
+radv_build_aabb(inout vk_aabb bounds, VOID_REF src_ptr, VOID_REF dst_ptr, uint32_t geometry_id, uint32_t global_id,
+                bool gfx12)
+{
+   bool is_valid = true;
+
+   for (uint32_t vec = 0; vec < 2; vec++)
+      for (uint32_t comp = 0; comp < 3; comp++) {
+         float coord = DEREF(INDEX(float, src_ptr, comp + vec * 3));
+
+         if (vec == 0)
+            bounds.min[comp] = coord;
+         else
+            bounds.max[comp] = coord;
+      }
+
+   /* An inactive AABB is one for which the minimum X coordinate is NaN. If any other component is
+    * NaN, and the first is not, the behavior is undefined.
+    */
+   if (isnan(bounds.min.x))
+#if ALWAYS_ACTIVE
+      is_valid = false;
+#else
+      return false;
+#endif
+
+   vk_ir_aabb_node node;
+   node.base.aabb = bounds;
+   node.primitive_id = global_id;
+   node.geometry_id_and_flags = geometry_id;
+
+   if (gfx12)
+      radv_encode_aabb_gfx12(dst_ptr, node);
+   else
+      radv_encode_aabb_gfx10_3(dst_ptr, node);
+
+   return is_valid;
+}
+
+#endif
diff --git a/src/amd/vulkan/bvh/update_gfx12.comp b/src/amd/vulkan/bvh/update_gfx12.comp
new file mode 100644
index 00000000000..7f1a1c71b2a
--- /dev/null
+++ b/src/amd/vulkan/bvh/update_gfx12.comp
@@ -0,0 +1,213 @@
+/*
+ * Copyright Â© 2025 Valve Corporation
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#version 460
+
+#extension GL_GOOGLE_include_directive : require
+
+#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int16 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int32 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_int64 : require
+#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
+#extension GL_EXT_scalar_block_layout : require
+#extension GL_EXT_buffer_reference : require
+#extension GL_EXT_buffer_reference2 : require
+#extension GL_KHR_memory_scope_semantics : require
+
+layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;
+
+#include "build_interface.h"
+#include "update.h"
+
+layout(push_constant) uniform CONSTS
+{
+   update_args args;
+};
+
+uint32_t
+fetch_parent_node(VOID_REF bvh, uint32_t node)
+{
+   uint64_t addr = bvh - node / 16 * 4 - 4;
+   return DEREF(REF(uint32_t)(addr));
+}
+
+void
+main()
+{
+   uint32_t bvh_offset = DEREF(args.src).bvh_offset;
+
+   VOID_REF src_bvh = OFFSET(args.src, bvh_offset);
+   VOID_REF dst_bvh = OFFSET(args.dst, bvh_offset);
+
+   VOID_REF leaf_node_offsets = OFFSET(args.src, DEREF(args.src).leaf_node_offsets_offset);
+
+   uint32_t leaf_node_size;
+   if (args.geom_data.geometry_type == VK_GEOMETRY_TYPE_TRIANGLES_KHR)
+      leaf_node_size = SIZEOF(radv_gfx12_primitive_node);
+   else if (args.geom_data.geometry_type == VK_GEOMETRY_TYPE_AABBS_KHR)
+      leaf_node_size = SIZEOF(radv_gfx12_primitive_node);
+   else
+      leaf_node_size = SIZEOF(radv_gfx12_instance_node) + SIZEOF(radv_gfx12_instance_node_user_data);
+
+   uint32_t leaf_node_id = args.geom_data.first_id + gl_GlobalInvocationID.x;
+   uint32_t first_leaf_offset = id_to_offset(RADV_BVH_ROOT_NODE) + SIZEOF(radv_gfx12_box_node);
+
+   uint32_t dst_offset = DEREF(INDEX(uint32_t, leaf_node_offsets, leaf_node_id));
+   VOID_REF dst_ptr = OFFSET(dst_bvh, dst_offset);
+   uint32_t src_offset = gl_GlobalInvocationID.x * args.geom_data.stride;
+
+   vk_aabb bounds;
+   bool is_active;
+   if (args.geom_data.geometry_type == VK_GEOMETRY_TYPE_TRIANGLES_KHR) {
+      is_active = radv_build_triangle(bounds, dst_ptr, args.geom_data, gl_GlobalInvocationID.x, true);
+   } else {
+      VOID_REF src_ptr = OFFSET(args.geom_data.data, src_offset);
+      is_active = radv_build_aabb(bounds, src_ptr, dst_ptr, args.geom_data.geometry_id, gl_GlobalInvocationID.x, true);
+   }
+
+   if (!is_active)
+      return;
+
+   DEREF(INDEX(vk_aabb, args.leaf_bounds, (dst_offset - first_leaf_offset) / leaf_node_size)) = bounds;
+   memoryBarrier(gl_ScopeDevice, gl_StorageSemanticsBuffer,
+                 gl_SemanticsAcquireRelease | gl_SemanticsMakeAvailable | gl_SemanticsMakeVisible);
+
+   uint32_t node_id = pack_node_id(dst_offset, 0);
+   uint32_t parent_id = fetch_parent_node(src_bvh, node_id);
+   uint32_t internal_nodes_offset = first_leaf_offset + args.leaf_node_count * leaf_node_size;
+   while (parent_id != RADV_BVH_INVALID_NODE) {
+      uint32_t offset = id_to_offset(parent_id);
+
+      uint32_t parent_index = (offset - internal_nodes_offset) / SIZEOF(radv_gfx12_box_node) + 1;
+      if (parent_id == RADV_BVH_ROOT_NODE)
+         parent_index = 0;
+
+      /* Make accesses to internal nodes in dst_bvh available and visible */
+      memoryBarrier(gl_ScopeDevice, gl_StorageSemanticsBuffer,
+                    gl_SemanticsAcquireRelease | gl_SemanticsMakeAvailable | gl_SemanticsMakeVisible);
+
+      REF(radv_gfx12_box_node) src_node = REF(radv_gfx12_box_node) OFFSET(src_bvh, offset);
+      REF(radv_gfx12_box_node) dst_node = REF(radv_gfx12_box_node) OFFSET(dst_bvh, offset);
+
+      uint32_t valid_child_count_minus_one = DEREF(src_node).child_count_exponents >> 28;
+
+      /* Check if all children have been processed. As this is an atomic the last path coming from
+       * a child will pass here, while earlier paths break.
+       */
+      uint32_t ready_child_count = atomicAdd(
+         DEREF(INDEX(uint32_t, args.internal_ready_count, parent_index)), 1, gl_ScopeDevice, gl_StorageSemanticsBuffer,
+         gl_SemanticsAcquireRelease | gl_SemanticsMakeAvailable | gl_SemanticsMakeVisible);
+
+      if (ready_child_count != valid_child_count_minus_one)
+         break;
+
+      uint32_t child_internal_id = DEREF(src_node).internal_base_id;
+      uint32_t child_primitive_id = DEREF(src_node).primitive_base_id;
+
+      DEREF(dst_node).internal_base_id = child_internal_id;
+      DEREF(dst_node).primitive_base_id = child_primitive_id;
+
+      uint32_t child_offsets[8];
+      vk_aabb total_bounds = vk_aabb(vec3(INFINITY), vec3(-INFINITY));
+      for (uint32_t i = 0; i <= valid_child_count_minus_one; i++) {
+         radv_gfx12_box_child child = DEREF(src_node).children[i];
+         uint32_t child_type = (child.dword2 >> 24) & 0xf;
+         uint32_t child_size_id = (child.dword2 >> 28) * RADV_GFX12_BVH_NODE_SIZE / 8;
+
+         uint32_t child_id;
+         if (child_type == radv_bvh_node_box32) {
+            child_id = child_internal_id;
+            child_internal_id += child_size_id;
+         } else {
+            child_id = child_primitive_id;
+            child_primitive_id += child_size_id;
+         }
+
+         child_offsets[i] = id_to_offset(child_id);
+
+         uint32_t child_offset = child_offsets[i];
+         vk_aabb child_aabb;
+         if (child_offset == dst_offset) {
+            child_aabb = bounds;
+         } else {
+            uint32_t child_index;
+            if (child_offset >= internal_nodes_offset) {
+               child_index =
+                  (child_offset - internal_nodes_offset) / SIZEOF(radv_gfx12_box_node) + 1 + args.leaf_node_count;
+            } else {
+               child_index = (child_offset - first_leaf_offset) / leaf_node_size;
+            }
+
+            child_aabb = DEREF(INDEX(vk_aabb, args.leaf_bounds, child_index));
+         }
+
+         total_bounds.min = min(total_bounds.min, child_aabb.min);
+         total_bounds.max = max(total_bounds.max, child_aabb.max);
+      }
+
+      vec3 origin = total_bounds.min;
+      vec3 extent = total_bounds.max - total_bounds.min;
+
+      extent = uintBitsToFloat((floatBitsToUint(extent) + uvec3(0x7fffff)) & 0x7f800000);
+      uvec3 extent_exponents = floatBitsToUint(extent) >> 23;
+
+      DEREF(dst_node).origin = origin;
+      DEREF(dst_node).child_count_exponents = extent_exponents.x | (extent_exponents.y << 8) |
+                                              (extent_exponents.z << 16) | (valid_child_count_minus_one << 28);
+      DEREF(dst_node).obb_matrix_index = 0x7f;
+
+      for (uint32_t i = 0; i <= valid_child_count_minus_one; i++) {
+         uint32_t child_offset = child_offsets[i];
+         vk_aabb child_aabb;
+         if (child_offset == dst_offset) {
+            child_aabb = bounds;
+         } else {
+            uint32_t child_index;
+            if (child_offset >= internal_nodes_offset) {
+               child_index =
+                  (child_offset - internal_nodes_offset) / SIZEOF(radv_gfx12_box_node) + 1 + args.leaf_node_count;
+            } else {
+               child_index = (child_offset - first_leaf_offset) / leaf_node_size;
+            }
+
+            child_aabb = DEREF(INDEX(vk_aabb, args.leaf_bounds, child_index));
+         }
+
+         radv_gfx12_box_child child = DEREF(src_node).children[i];
+
+         radv_gfx12_box_child box_child;
+         box_child.dword0 =
+            (child.dword0 & 0xFF000000) |
+            min(uint32_t(floor((child_aabb.min.x - origin.x) / extent.x * float(0x1000))), 0xfff) |
+            (min(uint32_t(floor((child_aabb.min.y - origin.y) / extent.y * float(0x1000))), 0xfff) << 12);
+         box_child.dword1 =
+            (child.dword1 & 0xFF000000) |
+            min(uint32_t(floor((child_aabb.min.z - origin.z) / extent.z * float(0x1000))), 0xfff) |
+            (min(uint32_t(ceil((child_aabb.max.x - origin.x) / extent.x * float(0x1000))) - 1, 0xfff) << 12);
+         box_child.dword2 =
+            (child.dword2 & 0xFF000000) |
+            min(uint32_t(ceil((child_aabb.max.y - origin.y) / extent.y * float(0x1000))) - 1, 0xfff) |
+            (min(uint32_t(ceil((child_aabb.max.z - origin.z) / extent.z * float(0x1000))) - 1, 0xfff) << 12);
+         DEREF(dst_node).children[i] = box_child;
+      }
+
+      for (uint32_t i = valid_child_count_minus_one + 1; i < 8; i++) {
+         radv_gfx12_box_child null_child;
+         null_child.dword0 = 0xffffffff;
+         null_child.dword1 = 0xfff;
+         null_child.dword2 = 0;
+         DEREF(dst_node).children[i] = null_child;
+      }
+
+      if (parent_id == RADV_BVH_ROOT_NODE)
+         DEREF(args.dst).aabb = total_bounds;
+
+      DEREF(INDEX(vk_aabb, args.leaf_bounds, parent_index + args.leaf_node_count)) = total_bounds;
+
+      parent_id = fetch_parent_node(src_bvh, parent_id);
+   }
+}
diff --git a/src/amd/vulkan/meson.build b/src/amd/vulkan/meson.build
index 343ecdfb317..0e6eca9683f 100644
--- a/src/amd/vulkan/meson.build
+++ b/src/amd/vulkan/meson.build
@@ -146,6 +146,8 @@ libradv_files = files(
   'radv_radeon_winsys.h',
   'radv_rmv.c',
   'radv_rmv.h',
+  'radv_rra_gfx10_3.c',
+  'radv_rra_gfx12.c',
   'radv_rra.c',
   'radv_rra.h',
   'radv_sampler.c',
diff --git a/src/amd/vulkan/meta/radv_meta.h b/src/amd/vulkan/meta/radv_meta.h
index 35017b41b6a..2db9b7aaf44 100644
--- a/src/amd/vulkan/meta/radv_meta.h
+++ b/src/amd/vulkan/meta/radv_meta.h
@@ -65,42 +65,10 @@ struct radv_meta_saved_state {
    unsigned active_occlusion_queries;
 };
 
-enum radv_blit_ds_layout {
-   RADV_BLIT_DS_LAYOUT_TILE_ENABLE,
-   RADV_BLIT_DS_LAYOUT_TILE_DISABLE,
-   RADV_BLIT_DS_LAYOUT_COUNT,
+enum radv_copy_flags {
+   RADV_COPY_FLAGS_DEVICE_LOCAL = 1 << 0,
 };
 
-static inline enum radv_blit_ds_layout
-radv_meta_blit_ds_to_type(VkImageLayout layout)
-{
-   return (layout == VK_IMAGE_LAYOUT_GENERAL) ? RADV_BLIT_DS_LAYOUT_TILE_DISABLE : RADV_BLIT_DS_LAYOUT_TILE_ENABLE;
-}
-
-static inline VkImageLayout
-radv_meta_blit_ds_to_layout(enum radv_blit_ds_layout ds_layout)
-{
-   return ds_layout == RADV_BLIT_DS_LAYOUT_TILE_ENABLE ? VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL : VK_IMAGE_LAYOUT_GENERAL;
-}
-
-enum radv_meta_dst_layout {
-   RADV_META_DST_LAYOUT_GENERAL,
-   RADV_META_DST_LAYOUT_OPTIMAL,
-   RADV_META_DST_LAYOUT_COUNT,
-};
-
-static inline enum radv_meta_dst_layout
-radv_meta_dst_layout_from_layout(VkImageLayout layout)
-{
-   return (layout == VK_IMAGE_LAYOUT_GENERAL) ? RADV_META_DST_LAYOUT_GENERAL : RADV_META_DST_LAYOUT_OPTIMAL;
-}
-
-static inline VkImageLayout
-radv_meta_dst_layout_to_layout(enum radv_meta_dst_layout layout)
-{
-   return layout == RADV_META_DST_LAYOUT_OPTIMAL ? VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL : VK_IMAGE_LAYOUT_GENERAL;
-}
-
 extern const VkFormat radv_fs_key_format_exemplars[NUM_META_FS_KEYS];
 
 enum radv_meta_object_key_type {
@@ -110,8 +78,8 @@ enum radv_meta_object_key_type {
    RADV_META_OBJECT_KEY_BLIT2D_COLOR,
    RADV_META_OBJECT_KEY_BLIT2D_DEPTH,
    RADV_META_OBJECT_KEY_BLIT2D_STENCIL,
-   RADV_META_OBJECT_KEY_FILL_BUFFER,
-   RADV_META_OBJECT_KEY_COPY_BUFFER,
+   RADV_META_OBJECT_KEY_FILL_MEMORY,
+   RADV_META_OBJECT_KEY_COPY_MEMORY,
    RADV_META_OBJECT_KEY_COPY_IMAGE_TO_BUFFER,
    RADV_META_OBJECT_KEY_COPY_BUFFER_TO_IMAGE,
    RADV_META_OBJECT_KEY_COPY_BUFFER_TO_IMAGE_R32G32B32,
@@ -180,8 +148,8 @@ struct radv_meta_blit2d_buffer {
    uint64_t size;
    uint32_t offset;
    uint32_t pitch;
-   uint8_t bs;
    VkFormat format;
+   enum radv_copy_flags copy_flags;
 };
 
 struct radv_meta_blit2d_rect {
@@ -190,14 +158,10 @@ struct radv_meta_blit2d_rect {
    uint32_t width, height;
 };
 
-void radv_meta_begin_blit2d(struct radv_cmd_buffer *cmd_buffer, struct radv_meta_saved_state *save);
-
 void radv_meta_blit2d(struct radv_cmd_buffer *cmd_buffer, struct radv_meta_blit2d_surf *src_img,
                       struct radv_meta_blit2d_buffer *src_buf, struct radv_meta_blit2d_surf *dst,
                       struct radv_meta_blit2d_rect *rect);
 
-void radv_meta_end_blit2d(struct radv_cmd_buffer *cmd_buffer, struct radv_meta_saved_state *save);
-
 void radv_meta_image_to_buffer(struct radv_cmd_buffer *cmd_buffer, struct radv_meta_blit2d_surf *src,
                                struct radv_meta_blit2d_buffer *dst, struct radv_meta_blit2d_rect *rect);
 
@@ -253,17 +217,24 @@ uint32_t radv_clear_dcc(struct radv_cmd_buffer *cmd_buffer, struct radv_image *i
 uint32_t radv_clear_htile(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *image,
                           const VkImageSubresourceRange *range, uint32_t value, bool is_clear);
 
-void radv_update_buffer_cp(struct radv_cmd_buffer *cmd_buffer, uint64_t va, const void *data, uint64_t size);
+void radv_update_memory_cp(struct radv_cmd_buffer *cmd_buffer, uint64_t va, const void *data, uint64_t size);
 
 void radv_meta_decode_etc(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, VkImageLayout layout,
                           const VkImageSubresourceLayers *subresource, VkOffset3D offset, VkExtent3D extent);
 void radv_meta_decode_astc(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, VkImageLayout layout,
                            const VkImageSubresourceLayers *subresource, VkOffset3D offset, VkExtent3D extent);
 
-uint32_t radv_fill_buffer(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *image,
-                          struct radeon_winsys_bo *bo, uint64_t va, uint64_t size, uint32_t value);
+uint32_t radv_fill_buffer(struct radv_cmd_buffer *cmd_buffer, struct radeon_winsys_bo *bo, uint64_t va, uint64_t size,
+                          uint32_t value);
+
+uint32_t radv_fill_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t va, uint64_t size, uint32_t value,
+                          enum radv_copy_flags copy_flags);
+
+uint32_t radv_fill_image(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *image, uint64_t offset,
+                         uint64_t size, uint32_t value);
 
-void radv_copy_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t src_va, uint64_t dst_va, uint64_t size);
+void radv_copy_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t src_va, uint64_t dst_va, uint64_t size,
+                      enum radv_copy_flags src_copy_flags, enum radv_copy_flags dst_copy_flags);
 
 void radv_cmd_buffer_clear_attachment(struct radv_cmd_buffer *cmd_buffer, const VkClearAttachment *attachment);
 
diff --git a/src/amd/vulkan/meta/radv_meta_blit.c b/src/amd/vulkan/meta/radv_meta_blit.c
index 7fde2677f6a..54139e6a41c 100644
--- a/src/amd/vulkan/meta/radv_meta_blit.c
+++ b/src/amd/vulkan/meta/radv_meta_blit.c
@@ -289,12 +289,10 @@ meta_emit_blit(struct radv_cmd_buffer *cmd_buffer, struct radv_image_view *src_i
 
    VkRenderingAttachmentInfo color_att;
    if (src_image->vk.aspects == VK_IMAGE_ASPECT_COLOR_BIT) {
-      unsigned dst_layout = radv_meta_dst_layout_from_layout(dst_image_layout);
-
       color_att = (VkRenderingAttachmentInfo){
          .sType = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO,
          .imageView = radv_image_view_to_handle(dst_iview),
-         .imageLayout = radv_meta_dst_layout_to_layout(dst_layout),
+         .imageLayout = dst_image_layout,
          .loadOp = VK_ATTACHMENT_LOAD_OP_LOAD,
          .storeOp = VK_ATTACHMENT_STORE_OP_STORE,
       };
@@ -304,12 +302,10 @@ meta_emit_blit(struct radv_cmd_buffer *cmd_buffer, struct radv_image_view *src_i
 
    VkRenderingAttachmentInfo depth_att;
    if (src_image->vk.aspects & VK_IMAGE_ASPECT_DEPTH_BIT) {
-      enum radv_blit_ds_layout ds_layout = radv_meta_blit_ds_to_type(dst_image_layout);
-
       depth_att = (VkRenderingAttachmentInfo){
          .sType = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO,
          .imageView = radv_image_view_to_handle(dst_iview),
-         .imageLayout = radv_meta_blit_ds_to_layout(ds_layout),
+         .imageLayout = dst_image_layout,
          .loadOp = VK_ATTACHMENT_LOAD_OP_LOAD,
          .storeOp = VK_ATTACHMENT_STORE_OP_STORE,
       };
@@ -318,12 +314,10 @@ meta_emit_blit(struct radv_cmd_buffer *cmd_buffer, struct radv_image_view *src_i
 
    VkRenderingAttachmentInfo stencil_att;
    if (src_image->vk.aspects & VK_IMAGE_ASPECT_STENCIL_BIT) {
-      enum radv_blit_ds_layout ds_layout = radv_meta_blit_ds_to_type(dst_image_layout);
-
       stencil_att = (VkRenderingAttachmentInfo){
          .sType = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO,
          .imageView = radv_image_view_to_handle(dst_iview),
-         .imageLayout = radv_meta_blit_ds_to_layout(ds_layout),
+         .imageLayout = dst_image_layout,
          .loadOp = VK_ATTACHMENT_LOAD_OP_LOAD,
          .storeOp = VK_ATTACHMENT_STORE_OP_STORE,
       };
diff --git a/src/amd/vulkan/meta/radv_meta_buffer.c b/src/amd/vulkan/meta/radv_meta_buffer.c
index 5c63d77b0aa..d5d59908885 100644
--- a/src/amd/vulkan/meta/radv_meta_buffer.c
+++ b/src/amd/vulkan/meta/radv_meta_buffer.c
@@ -23,9 +23,9 @@ struct fill_constants {
 };
 
 static VkResult
-get_fill_pipeline(struct radv_device *device, VkPipeline *pipeline_out, VkPipelineLayout *layout_out)
+get_fill_memory_pipeline(struct radv_device *device, VkPipeline *pipeline_out, VkPipelineLayout *layout_out)
 {
-   enum radv_meta_object_key_type key = RADV_META_OBJECT_KEY_FILL_BUFFER;
+   enum radv_meta_object_key_type key = RADV_META_OBJECT_KEY_FILL_MEMORY;
    VkResult result;
 
    const VkPushConstantRange pc_range = {
@@ -44,7 +44,7 @@ get_fill_pipeline(struct radv_device *device, VkPipeline *pipeline_out, VkPipeli
       return VK_SUCCESS;
    }
 
-   nir_shader *cs = radv_meta_nir_build_buffer_fill_shader(device);
+   nir_shader *cs = radv_meta_nir_build_fill_memory_shader(device);
 
    const VkPipelineShaderStageCreateInfo stage_info = {
       .sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
@@ -75,9 +75,9 @@ struct copy_constants {
 };
 
 static VkResult
-get_copy_pipeline(struct radv_device *device, VkPipeline *pipeline_out, VkPipelineLayout *layout_out)
+get_copy_memory_pipeline(struct radv_device *device, VkPipeline *pipeline_out, VkPipelineLayout *layout_out)
 {
-   enum radv_meta_object_key_type key = RADV_META_OBJECT_KEY_COPY_BUFFER;
+   enum radv_meta_object_key_type key = RADV_META_OBJECT_KEY_COPY_MEMORY;
    VkResult result;
 
    const VkPushConstantRange pc_range = {
@@ -96,7 +96,7 @@ get_copy_pipeline(struct radv_device *device, VkPipeline *pipeline_out, VkPipeli
       return VK_SUCCESS;
    }
 
-   nir_shader *cs = radv_meta_nir_build_buffer_copy_shader(device);
+   nir_shader *cs = radv_meta_nir_build_copy_memory_shader(device);
 
    const VkPipelineShaderStageCreateInfo stage_info = {
       .sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
@@ -129,7 +129,7 @@ radv_compute_fill_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t va, uint64
    VkPipeline pipeline;
    VkResult result;
 
-   result = get_fill_pipeline(device, &pipeline, &layout);
+   result = get_fill_memory_pipeline(device, &pipeline, &layout);
    if (result != VK_SUCCESS) {
       vk_command_buffer_set_error(&cmd_buffer->vk, result);
       return;
@@ -164,7 +164,7 @@ radv_compute_copy_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t src_va, ui
    VkPipeline pipeline;
    VkResult result;
 
-   result = get_copy_pipeline(device, &pipeline, &layout);
+   result = get_copy_memory_pipeline(device, &pipeline, &layout);
    if (result != VK_SUCCESS) {
       vk_command_buffer_set_error(&cmd_buffer->vk, result);
       return;
@@ -190,11 +190,29 @@ radv_compute_copy_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t src_va, ui
    radv_meta_restore(&saved_state, cmd_buffer);
 }
 
+static bool
+radv_prefer_compute_or_cp_dma(const struct radv_device *device, uint64_t size, enum radv_copy_flags src_copy_flags,
+                              enum radv_copy_flags dst_copy_flags)
+{
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+   bool use_compute = size >= RADV_BUFFER_OPS_CS_THRESHOLD;
+
+   if (pdev->info.gfx_level >= GFX10 && pdev->info.has_dedicated_vram) {
+      if (!(src_copy_flags & RADV_COPY_FLAGS_DEVICE_LOCAL) || !(dst_copy_flags & RADV_COPY_FLAGS_DEVICE_LOCAL)) {
+         /* Prefer CP DMA for GTT on dGPUS due to slow PCIe. */
+         use_compute = false;
+      }
+   }
+
+   return use_compute;
+}
+
 static uint32_t
-radv_fill_memory(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *image, uint64_t va, uint64_t size,
-                 uint32_t value)
+radv_fill_memory_internal(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *image, uint64_t va,
+                          uint64_t size, uint32_t value, enum radv_copy_flags copy_flags)
 {
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
+   bool use_compute = radv_prefer_compute_or_cp_dma(device, size, copy_flags, copy_flags);
    uint32_t flush_bits = 0;
 
    assert(!(va & 3));
@@ -202,7 +220,7 @@ radv_fill_memory(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *im
 
    if (cmd_buffer->qf == RADV_QUEUE_TRANSFER) {
       radv_sdma_fill_memory(device, cmd_buffer->cs, va, size, value);
-   } else if (size >= RADV_BUFFER_OPS_CS_THRESHOLD) {
+   } else if (use_compute) {
       radv_compute_fill_memory(cmd_buffer, va, size, value);
 
       flush_bits = RADV_CMD_FLAG_CS_PARTIAL_FLUSH | RADV_CMD_FLAG_INV_VCACHE |
@@ -215,15 +233,42 @@ radv_fill_memory(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *im
 }
 
 uint32_t
-radv_fill_buffer(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *image, struct radeon_winsys_bo *bo,
-                 uint64_t va, uint64_t size, uint32_t value)
+radv_fill_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t va, uint64_t size, uint32_t value,
+                 enum radv_copy_flags copy_flags)
+{
+   return radv_fill_memory_internal(cmd_buffer, NULL, va, size, value, copy_flags);
+}
+
+uint32_t
+radv_fill_image(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *image, uint64_t offset, uint64_t size,
+                uint32_t value)
+{
+   struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
+   const uint64_t va = image->bindings[0].addr + offset;
+   struct radeon_winsys_bo *bo = image->bindings[0].bo;
+   enum radv_copy_flags copy_flags = 0;
+
+   if (bo->initial_domain & RADEON_DOMAIN_VRAM)
+      copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
+
+   radv_cs_add_buffer(device->ws, cmd_buffer->cs, bo);
+
+   return radv_fill_memory_internal(cmd_buffer, image, va, size, value, copy_flags);
+}
+
+uint32_t
+radv_fill_buffer(struct radv_cmd_buffer *cmd_buffer, struct radeon_winsys_bo *bo, uint64_t va, uint64_t size,
+                 uint32_t value)
 {
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
+   enum radv_copy_flags copy_flags = 0;
+
+   if (bo->initial_domain & RADEON_DOMAIN_VRAM)
+      copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
 
-   if (bo)
-      radv_cs_add_buffer(device->ws, cmd_buffer->cs, bo);
+   radv_cs_add_buffer(device->ws, cmd_buffer->cs, bo);
 
-   return radv_fill_memory(cmd_buffer, image, va, size, value);
+   return radv_fill_memory(cmd_buffer, va, size, value, copy_flags);
 }
 
 VKAPI_ATTR void VKAPI_CALL
@@ -237,16 +282,18 @@ radv_CmdFillBuffer(VkCommandBuffer commandBuffer, VkBuffer dstBuffer, VkDeviceSi
 
    fillSize = vk_buffer_range(&dst_buffer->vk, dstOffset, fillSize) & ~3ull;
 
-   radv_fill_buffer(cmd_buffer, NULL, dst_buffer->bo, vk_buffer_address(&dst_buffer->vk, dstOffset), fillSize, data);
+   radv_fill_buffer(cmd_buffer, dst_buffer->bo, vk_buffer_address(&dst_buffer->vk, dstOffset), fillSize, data);
 
    radv_resume_conditional_rendering(cmd_buffer);
 }
 
 void
-radv_copy_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t src_va, uint64_t dst_va, uint64_t size)
+radv_copy_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t src_va, uint64_t dst_va, uint64_t size,
+                 enum radv_copy_flags src_copy_flags, enum radv_copy_flags dst_copy_flags)
 {
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
-   const bool use_compute = !(size & 3) && !(src_va & 3) && !(dst_va & 3) && size >= RADV_BUFFER_OPS_CS_THRESHOLD;
+   const bool use_compute = !(size & 3) && !(src_va & 3) && !(dst_va & 3) &&
+                            radv_prefer_compute_or_cp_dma(device, size, src_copy_flags, dst_copy_flags);
 
    if (cmd_buffer->qf == RADV_QUEUE_TRANSFER) {
       radv_sdma_copy_memory(device, cmd_buffer->cs, src_va, dst_va, size);
@@ -264,6 +311,12 @@ radv_CmdCopyBuffer2(VkCommandBuffer commandBuffer, const VkCopyBufferInfo2 *pCop
    VK_FROM_HANDLE(radv_buffer, src_buffer, pCopyBufferInfo->srcBuffer);
    VK_FROM_HANDLE(radv_buffer, dst_buffer, pCopyBufferInfo->dstBuffer);
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
+   enum radv_copy_flags src_copy_flags = 0, dst_copy_flags = 0;
+
+   if (src_buffer->bo->initial_domain & RADEON_DOMAIN_VRAM)
+      src_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
+   if (dst_buffer->bo->initial_domain & RADEON_DOMAIN_VRAM)
+      dst_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
 
    radv_suspend_conditional_rendering(cmd_buffer);
 
@@ -275,14 +328,14 @@ radv_CmdCopyBuffer2(VkCommandBuffer commandBuffer, const VkCopyBufferInfo2 *pCop
       const uint64_t src_va = vk_buffer_address(&src_buffer->vk, region->srcOffset);
       const uint64_t dst_va = vk_buffer_address(&dst_buffer->vk, region->dstOffset);
 
-      radv_copy_memory(cmd_buffer, src_va, dst_va, region->size);
+      radv_copy_memory(cmd_buffer, src_va, dst_va, region->size, src_copy_flags, dst_copy_flags);
    }
 
    radv_resume_conditional_rendering(cmd_buffer);
 }
 
 void
-radv_update_buffer_cp(struct radv_cmd_buffer *cmd_buffer, uint64_t va, const void *data, uint64_t size)
+radv_update_memory_cp(struct radv_cmd_buffer *cmd_buffer, uint64_t va, const void *data, uint64_t size)
 {
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
    uint64_t words = size / 4;
@@ -306,7 +359,8 @@ radv_update_buffer_cp(struct radv_cmd_buffer *cmd_buffer, uint64_t va, const voi
 }
 
 static void
-radv_update_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t va, uint64_t size, const void *data)
+radv_update_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t va, uint64_t size, const void *data,
+                   enum radv_copy_flags dst_copy_flags)
 {
    assert(!(size & 3));
    assert(!(va & 3));
@@ -315,15 +369,19 @@ radv_update_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t va, uint64_t siz
       return;
 
    if (size < RADV_BUFFER_UPDATE_THRESHOLD && cmd_buffer->qf != RADV_QUEUE_TRANSFER) {
-      radv_update_buffer_cp(cmd_buffer, va, data, size);
+      radv_update_memory_cp(cmd_buffer, va, data, size);
    } else {
+      enum radv_copy_flags src_copy_flags = 0;
       uint32_t buf_offset;
 
       radv_cmd_buffer_upload_data(cmd_buffer, size, data, &buf_offset);
 
+      if (cmd_buffer->upload.upload_bo->initial_domain & RADEON_DOMAIN_VRAM)
+         src_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
+
       const uint64_t src_va = radv_buffer_get_va(cmd_buffer->upload.upload_bo) + buf_offset;
 
-      radv_copy_memory(cmd_buffer, src_va, va, size);
+      radv_copy_memory(cmd_buffer, src_va, va, size, src_copy_flags, dst_copy_flags);
    }
 }
 
@@ -335,12 +393,16 @@ radv_CmdUpdateBuffer(VkCommandBuffer commandBuffer, VkBuffer dstBuffer, VkDevice
    VK_FROM_HANDLE(radv_buffer, dst_buffer, dstBuffer);
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
    const uint64_t dst_va = vk_buffer_address(&dst_buffer->vk, dstOffset);
+   enum radv_copy_flags dst_copy_flags = 0;
+
+   if (dst_buffer->bo->initial_domain & RADEON_DOMAIN_VRAM)
+      dst_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
 
    radv_suspend_conditional_rendering(cmd_buffer);
 
    radv_cs_add_buffer(device->ws, cmd_buffer->cs, dst_buffer->bo);
 
-   radv_update_memory(cmd_buffer, dst_va, dataSize, pData);
+   radv_update_memory(cmd_buffer, dst_va, dataSize, pData, dst_copy_flags);
 
    radv_resume_conditional_rendering(cmd_buffer);
 }
diff --git a/src/amd/vulkan/meta/radv_meta_bufimage.c b/src/amd/vulkan/meta/radv_meta_bufimage.c
index 7ff991d555a..199f9629e28 100644
--- a/src/amd/vulkan/meta/radv_meta_bufimage.c
+++ b/src/amd/vulkan/meta/radv_meta_bufimage.c
@@ -622,6 +622,7 @@ fixup_gfx9_cs_copy(struct radv_cmd_buffer *cmd_buffer, const struct radv_meta_bl
    const struct radeon_surf *surf = &image->planes[0].surface;
    const struct radeon_info *gpu_info = &pdev->info;
    struct ac_surf_info surf_info = radv_get_ac_surf_info(device, image);
+   enum radv_copy_flags img_copy_flags = 0, mem_copy_flags = 0;
 
    /* GFX10 will use a different workaround unless this is not a 2D image */
    if (gpu_info->gfx_level < GFX9 || (gpu_info->gfx_level >= GFX10 && image->vk.image_type == VK_IMAGE_TYPE_2D) ||
@@ -654,6 +655,10 @@ fixup_gfx9_cs_copy(struct radv_cmd_buffer *cmd_buffer, const struct radv_meta_bl
       cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_CS_PARTIAL_FLUSH | RADV_CMD_FLAG_INV_L2 | RADV_CMD_FLAG_INV_VCACHE;
    }
 
+   if (image->bindings[0].bo && (image->bindings[0].bo->initial_domain & RADEON_DOMAIN_VRAM))
+      img_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
+   mem_copy_flags |= buf_bsurf->copy_flags;
+
    for (uint32_t y = 0; y < mip_extent.height; y++) {
       uint32_t coordY = y + mip_offset.y;
       /* If the default copy algorithm (done previously) has already seen this
@@ -670,9 +675,9 @@ fixup_gfx9_cs_copy(struct radv_cmd_buffer *cmd_buffer, const struct radv_meta_bl
          /* buf_bsurf->offset already includes the layer offset */
          const uint64_t mem_va = buf_bsurf->addr + buf_bsurf->offset + y * buf_bsurf->pitch * surf->bpe + x * surf->bpe;
          if (to_image) {
-            radv_copy_memory(cmd_buffer, mem_va, img_va, surf->bpe);
+            radv_copy_memory(cmd_buffer, mem_va, img_va, surf->bpe, mem_copy_flags, img_copy_flags);
          } else {
-            radv_copy_memory(cmd_buffer, img_va, mem_va, surf->bpe);
+            radv_copy_memory(cmd_buffer, img_va, mem_va, surf->bpe, img_copy_flags, mem_copy_flags);
          }
       }
    }
diff --git a/src/amd/vulkan/meta/radv_meta_clear.c b/src/amd/vulkan/meta/radv_meta_clear.c
index 33ea7691ac0..13cf0b3faba 100644
--- a/src/amd/vulkan/meta/radv_meta_clear.c
+++ b/src/amd/vulkan/meta/radv_meta_clear.c
@@ -810,8 +810,7 @@ radv_clear_cmask(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, c
       size = slice_size * vk_image_subresource_layer_count(&image->vk, range);
    }
 
-   return radv_fill_buffer(cmd_buffer, image, image->bindings[0].bo, image->bindings[0].addr + cmask_offset, size,
-                           value);
+   return radv_fill_image(cmd_buffer, image, cmask_offset, size, value);
 }
 
 uint32_t
@@ -828,8 +827,7 @@ radv_clear_fmask(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, c
    fmask_offset += slice_size * range->baseArrayLayer;
    size = slice_size * vk_image_subresource_layer_count(&image->vk, range);
 
-   return radv_fill_buffer(cmd_buffer, image, image->bindings[0].bo, image->bindings[0].addr + fmask_offset, size,
-                           value);
+   return radv_fill_image(cmd_buffer, image, fmask_offset, size, value);
 }
 
 uint32_t
@@ -876,8 +874,7 @@ radv_clear_dcc(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, con
       if (!size)
          continue;
 
-      flush_bits |=
-         radv_fill_buffer(cmd_buffer, image, image->bindings[0].bo, image->bindings[0].addr + dcc_offset, size, value);
+      flush_bits |= radv_fill_image(cmd_buffer, image, dcc_offset, size, value);
    }
 
    return flush_bits;
@@ -1096,8 +1093,7 @@ radv_clear_htile(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *im
 
          if (htile_mask == UINT_MAX) {
             /* Clear the whole HTILE buffer. */
-            flush_bits |= radv_fill_buffer(cmd_buffer, image, image->bindings[0].bo,
-                                           image->bindings[0].addr + htile_offset, size, value);
+            flush_bits |= radv_fill_image(cmd_buffer, image, htile_offset, size, value);
          } else {
             /* Only clear depth or stencil bytes in the HTILE buffer. */
             flush_bits |= clear_htile_mask(cmd_buffer, image, image->bindings[0].bo,
@@ -1112,8 +1108,7 @@ radv_clear_htile(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *im
 
       if (htile_mask == UINT_MAX) {
          /* Clear the whole HTILE buffer. */
-         flush_bits = radv_fill_buffer(cmd_buffer, image, image->bindings[0].bo, image->bindings[0].addr + htile_offset,
-                                       size, value);
+         flush_bits = radv_fill_image(cmd_buffer, image, htile_offset, size, value);
       } else {
          /* Only clear depth or stencil bytes in the HTILE buffer. */
          flush_bits = clear_htile_mask(cmd_buffer, image, image->bindings[0].bo, image->bindings[0].addr + htile_offset,
diff --git a/src/amd/vulkan/meta/radv_meta_copy.c b/src/amd/vulkan/meta/radv_meta_copy.c
index a80d2e326f6..d30679dacc7 100644
--- a/src/amd/vulkan/meta/radv_meta_copy.c
+++ b/src/amd/vulkan/meta/radv_meta_copy.c
@@ -32,10 +32,9 @@ vk_format_for_size(int bs)
 }
 
 static struct radv_meta_blit2d_surf
-blit_surf_for_image_level_layer(struct radv_image *image, VkImageLayout layout, const VkImageSubresourceLayers *subres,
-                                VkImageAspectFlags aspect_mask)
+blit_surf_for_image_level_layer(struct radv_image *image, VkImageLayout layout, const VkImageSubresourceLayers *subres)
 {
-   VkFormat format = radv_get_aspect_format(image, aspect_mask);
+   VkFormat format = radv_get_aspect_format(image, subres->aspectMask);
 
    if (!radv_dcc_enabled(image, subres->mipLevel) && !(radv_tc_compat_htile_enabled(image, subres->mipLevel)))
       format = vk_format_for_size(vk_format_get_blocksize(format));
@@ -48,7 +47,7 @@ blit_surf_for_image_level_layer(struct radv_image *image, VkImageLayout layout,
       .level = subres->mipLevel,
       .layer = subres->baseArrayLayer,
       .image = image,
-      .aspect_mask = aspect_mask,
+      .aspect_mask = subres->aspectMask,
       .current_layout = layout,
    };
 }
@@ -98,7 +97,8 @@ transfer_copy_memory_image(struct radv_cmd_buffer *cmd_buffer, uint64_t buffer_v
 
 static void
 copy_memory_to_image(struct radv_cmd_buffer *cmd_buffer, uint64_t buffer_addr, uint64_t buffer_size,
-                     struct radv_image *image, VkImageLayout layout, const VkBufferImageCopy2 *region)
+                     enum radv_copy_flags src_copy_flags, struct radv_image *image, VkImageLayout layout,
+                     const VkBufferImageCopy2 *region)
 {
    if (cmd_buffer->qf == RADV_QUEUE_TRANSFER) {
       transfer_copy_memory_image(cmd_buffer, buffer_addr, image, region, true);
@@ -140,8 +140,7 @@ copy_memory_to_image(struct radv_cmd_buffer *cmd_buffer, uint64_t buffer_addr, u
    };
 
    /* Create blit surfaces */
-   struct radv_meta_blit2d_surf img_bsurf =
-      blit_surf_for_image_level_layer(image, layout, &region->imageSubresource, region->imageSubresource.aspectMask);
+   struct radv_meta_blit2d_surf img_bsurf = blit_surf_for_image_level_layer(image, layout, &region->imageSubresource);
 
    if (!radv_is_buffer_format_supported(img_bsurf.format, NULL)) {
       uint32_t queue_mask = radv_image_queue_family_mask(image, cmd_buffer->qf, cmd_buffer->qf);
@@ -169,10 +168,10 @@ copy_memory_to_image(struct radv_cmd_buffer *cmd_buffer, uint64_t buffer_addr, u
    struct radv_meta_blit2d_buffer buf_bsurf = {
       .addr = buffer_addr,
       .size = buffer_size,
-      .bs = img_bsurf.bs,
       .format = img_bsurf.format,
       .offset = region->bufferOffset,
       .pitch = buf_layout.row_stride_B / buf_layout.element_size_B,
+      .copy_flags = src_copy_flags,
    };
 
    if (image->vk.image_type == VK_IMAGE_TYPE_3D)
@@ -218,6 +217,10 @@ radv_CmdCopyBufferToImage2(VkCommandBuffer commandBuffer, const VkCopyBufferToIm
    VK_FROM_HANDLE(radv_image, dst_image, pCopyBufferToImageInfo->dstImage);
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
    const struct radv_physical_device *pdev = radv_device_physical(device);
+   enum radv_copy_flags src_copy_flags = 0;
+
+   if (src_buffer->bo->initial_domain & RADEON_DOMAIN_VRAM)
+      src_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
 
    radv_suspend_conditional_rendering(cmd_buffer);
 
@@ -230,11 +233,11 @@ radv_CmdCopyBufferToImage2(VkCommandBuffer commandBuffer, const VkCopyBufferToIm
 
       radv_cs_add_buffer(device->ws, cmd_buffer->cs, dst_image->bindings[bind_idx].bo);
 
-      copy_memory_to_image(cmd_buffer, src_buffer->vk.device_address, src_buffer->vk.size, dst_image,
+      copy_memory_to_image(cmd_buffer, src_buffer->vk.device_address, src_buffer->vk.size, src_copy_flags, dst_image,
                            pCopyBufferToImageInfo->dstImageLayout, region);
    }
 
-   if (radv_is_format_emulated(pdev, dst_image->vk.format) && cmd_buffer->qf != RADV_QUEUE_TRANSFER) {
+   if (radv_is_format_emulated(pdev, dst_image->vk.format)) {
       cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_CS_PARTIAL_FLUSH | RADV_CMD_FLAG_PS_PARTIAL_FLUSH |
                                       radv_src_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_ALL_COMMANDS_BIT,
                                                             VK_ACCESS_TRANSFER_WRITE_BIT, 0, dst_image, NULL) |
@@ -262,7 +265,8 @@ radv_CmdCopyBufferToImage2(VkCommandBuffer commandBuffer, const VkCopyBufferToIm
 
 static void
 copy_image_to_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t buffer_addr, uint64_t buffer_size,
-                     struct radv_image *image, VkImageLayout layout, const VkBufferImageCopy2 *region)
+                     enum radv_copy_flags dst_copy_flags, struct radv_image *image, VkImageLayout layout,
+                     const VkBufferImageCopy2 *region)
 {
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
    if (cmd_buffer->qf == RADV_QUEUE_TRANSFER) {
@@ -300,8 +304,7 @@ copy_image_to_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t buffer_addr, u
    };
 
    /* Create blit surfaces */
-   struct radv_meta_blit2d_surf img_info =
-      blit_surf_for_image_level_layer(image, layout, &region->imageSubresource, region->imageSubresource.aspectMask);
+   struct radv_meta_blit2d_surf img_info = blit_surf_for_image_level_layer(image, layout, &region->imageSubresource);
 
    if (!radv_is_buffer_format_supported(img_info.format, NULL)) {
       uint32_t queue_mask = radv_image_queue_family_mask(image, cmd_buffer->qf, cmd_buffer->qf);
@@ -328,10 +331,10 @@ copy_image_to_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t buffer_addr, u
    struct radv_meta_blit2d_buffer buf_info = {
       .addr = buffer_addr,
       .size = buffer_size,
-      .bs = img_info.bs,
       .format = img_info.format,
       .offset = region->bufferOffset,
       .pitch = buf_extent_el.width,
+      .copy_flags = dst_copy_flags,
    };
 
    if (image->vk.image_type == VK_IMAGE_TYPE_3D)
@@ -349,7 +352,7 @@ copy_image_to_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t buffer_addr, u
       /* Perform Blit */
       radv_meta_image_to_buffer(cmd_buffer, &img_info, &buf_info, &rect);
 
-      buf_info.offset += buf_extent_el.width * buf_extent_el.height * buf_info.bs;
+      buf_info.offset += buf_extent_el.width * buf_extent_el.height * img_info.bs;
       img_info.layer++;
       if (image->vk.image_type == VK_IMAGE_TYPE_3D)
          slice_3d++;
@@ -367,6 +370,10 @@ radv_CmdCopyImageToBuffer2(VkCommandBuffer commandBuffer, const VkCopyImageToBuf
    VK_FROM_HANDLE(radv_image, src_image, pCopyImageToBufferInfo->srcImage);
    VK_FROM_HANDLE(radv_buffer, dst_buffer, pCopyImageToBufferInfo->dstBuffer);
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
+   enum radv_copy_flags dst_copy_flags = 0;
+
+   if (dst_buffer->bo->initial_domain & RADEON_DOMAIN_VRAM)
+      dst_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
 
    radv_suspend_conditional_rendering(cmd_buffer);
 
@@ -379,7 +386,7 @@ radv_CmdCopyImageToBuffer2(VkCommandBuffer commandBuffer, const VkCopyImageToBuf
 
       radv_cs_add_buffer(device->ws, cmd_buffer->cs, src_image->bindings[bind_idx].bo);
 
-      copy_image_to_memory(cmd_buffer, dst_buffer->vk.device_address, dst_buffer->vk.size, src_image,
+      copy_image_to_memory(cmd_buffer, dst_buffer->vk.device_address, dst_buffer->vk.size, dst_copy_flags, src_image,
                            pCopyImageToBufferInfo->srcImageLayout, region);
    }
 
@@ -509,11 +516,11 @@ copy_image(struct radv_cmd_buffer *cmd_buffer, struct radv_image *src_image, VkI
    }
 
    /* Create blit surfaces */
-   struct radv_meta_blit2d_surf b_src = blit_surf_for_image_level_layer(
-      src_image, src_image_layout, &region->srcSubresource, region->srcSubresource.aspectMask);
+   struct radv_meta_blit2d_surf b_src =
+      blit_surf_for_image_level_layer(src_image, src_image_layout, &region->srcSubresource);
 
-   struct radv_meta_blit2d_surf b_dst = blit_surf_for_image_level_layer(
-      dst_image, dst_image_layout, &region->dstSubresource, region->dstSubresource.aspectMask);
+   struct radv_meta_blit2d_surf b_dst =
+      blit_surf_for_image_level_layer(dst_image, dst_image_layout, &region->dstSubresource);
 
    uint32_t dst_queue_mask = radv_image_queue_family_mask(dst_image, cmd_buffer->qf, cmd_buffer->qf);
    bool dst_compressed =
@@ -664,7 +671,7 @@ radv_CmdCopyImage2(VkCommandBuffer commandBuffer, const VkCopyImageInfo2 *pCopyI
                  region);
    }
 
-   if (radv_is_format_emulated(pdev, dst_image->vk.format) && cmd_buffer->qf != RADV_QUEUE_TRANSFER) {
+   if (radv_is_format_emulated(pdev, dst_image->vk.format)) {
       cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_CS_PARTIAL_FLUSH | RADV_CMD_FLAG_PS_PARTIAL_FLUSH |
                                       radv_src_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_ALL_COMMANDS_BIT,
                                                             VK_ACCESS_TRANSFER_WRITE_BIT, 0, dst_image, NULL) |
diff --git a/src/amd/vulkan/meta/radv_meta_fmask_copy.c b/src/amd/vulkan/meta/radv_meta_fmask_copy.c
index cec50a73ca5..284852b2f83 100644
--- a/src/amd/vulkan/meta/radv_meta_fmask_copy.c
+++ b/src/amd/vulkan/meta/radv_meta_fmask_copy.c
@@ -93,6 +93,7 @@ static void
 radv_fixup_copy_dst_metadata(struct radv_cmd_buffer *cmd_buffer, const struct radv_image *src_image,
                              const struct radv_image *dst_image)
 {
+   enum radv_copy_flags src_copy_flags = 0, dst_copy_flags = 0;
    uint64_t src_va, dst_va, size;
 
    assert(src_image->planes[0].surface.cmask_size == dst_image->planes[0].surface.cmask_size &&
@@ -102,12 +103,17 @@ radv_fixup_copy_dst_metadata(struct radv_cmd_buffer *cmd_buffer, const struct ra
           dst_image->planes[0].surface.fmask_offset + dst_image->planes[0].surface.fmask_size ==
              dst_image->planes[0].surface.cmask_offset);
 
+   if (src_image->bindings[0].bo && (src_image->bindings[0].bo->initial_domain & RADEON_DOMAIN_VRAM))
+      src_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
+   if (dst_image->bindings[0].bo && (dst_image->bindings[0].bo->initial_domain & RADEON_DOMAIN_VRAM))
+      dst_copy_flags |= RADV_COPY_FLAGS_DEVICE_LOCAL;
+
    /* Copy CMASK+FMASK. */
    size = src_image->planes[0].surface.cmask_size + src_image->planes[0].surface.fmask_size;
    src_va = src_image->bindings[0].addr + src_image->planes[0].surface.fmask_offset;
    dst_va = dst_image->bindings[0].addr + dst_image->planes[0].surface.fmask_offset;
 
-   radv_copy_memory(cmd_buffer, src_va, dst_va, size);
+   radv_copy_memory(cmd_buffer, src_va, dst_va, size, src_copy_flags, dst_copy_flags);
 }
 
 bool
diff --git a/src/amd/vulkan/meta/radv_meta_resolve_fs.c b/src/amd/vulkan/meta/radv_meta_resolve_fs.c
index a64879c2c54..19d5bd811ff 100644
--- a/src/amd/vulkan/meta/radv_meta_resolve_fs.c
+++ b/src/amd/vulkan/meta/radv_meta_resolve_fs.c
@@ -429,8 +429,6 @@ radv_meta_resolve_fragment_image(struct radv_cmd_buffer *cmd_buffer, struct radv
 {
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
    struct radv_meta_saved_state saved_state;
-   unsigned dst_layout = radv_meta_dst_layout_from_layout(dst_image_layout);
-   VkImageLayout layout = radv_meta_dst_layout_to_layout(dst_layout);
 
    radv_meta_save(&saved_state, cmd_buffer,
                   RADV_META_SAVE_GRAPHICS_PIPELINE | RADV_META_SAVE_CONSTANTS | RADV_META_SAVE_DESCRIPTORS);
@@ -499,7 +497,7 @@ radv_meta_resolve_fragment_image(struct radv_cmd_buffer *cmd_buffer, struct radv
    const VkRenderingAttachmentInfo color_att = {
       .sType = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO,
       .imageView = radv_image_view_to_handle(&dst_iview),
-      .imageLayout = layout,
+      .imageLayout = dst_image_layout,
       .loadOp = VK_ATTACHMENT_LOAD_OP_LOAD,
       .storeOp = VK_ATTACHMENT_STORE_OP_STORE,
    };
diff --git a/src/amd/vulkan/nir/radv_meta_nir.c b/src/amd/vulkan/nir/radv_meta_nir.c
index 032987b64be..b635afc1203 100644
--- a/src/amd/vulkan/nir/radv_meta_nir.c
+++ b/src/amd/vulkan/nir/radv_meta_nir.c
@@ -95,13 +95,6 @@ radv_meta_nir_build_resolve_shader_core(struct radv_device *device, nir_builder
    }
 }
 
-nir_def *
-radv_meta_nir_load_descriptor(nir_builder *b, unsigned desc_set, unsigned binding)
-{
-   nir_def *rsrc = nir_vulkan_resource_index(b, 3, 32, nir_imm_int(b, 0), .desc_set = desc_set, .binding = binding);
-   return nir_trim_vector(b, rsrc, 2);
-}
-
 nir_def *
 radv_meta_nir_get_global_ids(nir_builder *b, unsigned num_components)
 {
@@ -130,7 +123,7 @@ radv_meta_nir_break_on_count(nir_builder *b, nir_variable *var, nir_def *count)
 }
 
 nir_shader *
-radv_meta_nir_build_buffer_fill_shader(struct radv_device *dev)
+radv_meta_nir_build_fill_memory_shader(struct radv_device *dev)
 {
    nir_builder b = radv_meta_nir_init_shader(dev, MESA_SHADER_COMPUTE, "meta_buffer_fill");
    b.shader->info.workgroup_size[0] = 64;
@@ -152,7 +145,7 @@ radv_meta_nir_build_buffer_fill_shader(struct radv_device *dev)
 }
 
 nir_shader *
-radv_meta_nir_build_buffer_copy_shader(struct radv_device *dev)
+radv_meta_nir_build_copy_memory_shader(struct radv_device *dev)
 {
    nir_builder b = radv_meta_nir_init_shader(dev, MESA_SHADER_COMPUTE, "meta_buffer_copy");
    b.shader->info.workgroup_size[0] = 64;
diff --git a/src/amd/vulkan/nir/radv_meta_nir.h b/src/amd/vulkan/nir/radv_meta_nir.h
index 892a579f081..5e63ed68fa4 100644
--- a/src/amd/vulkan/nir/radv_meta_nir.h
+++ b/src/amd/vulkan/nir/radv_meta_nir.h
@@ -31,8 +31,8 @@ nir_def *radv_meta_nir_get_global_ids(nir_builder *b, unsigned num_components);
 
 void radv_meta_nir_break_on_count(nir_builder *b, nir_variable *var, nir_def *count);
 
-nir_shader *radv_meta_nir_build_buffer_fill_shader(struct radv_device *dev);
-nir_shader *radv_meta_nir_build_buffer_copy_shader(struct radv_device *dev);
+nir_shader *radv_meta_nir_build_fill_memory_shader(struct radv_device *dev);
+nir_shader *radv_meta_nir_build_copy_memory_shader(struct radv_device *dev);
 
 nir_shader *radv_meta_nir_build_blit_vertex_shader(struct radv_device *dev);
 nir_shader *radv_meta_nir_build_blit_copy_fragment_shader(struct radv_device *dev, enum glsl_sampler_dim tex_dim);
@@ -50,7 +50,6 @@ nir_shader *radv_meta_nir_build_cleari_r32g32b32_compute_shader(struct radv_devi
 
 typedef nir_def *(*radv_meta_nir_texel_fetch_build_func)(struct nir_builder *, struct radv_device *, nir_def *, bool,
                                                          bool);
-nir_def *radv_meta_nir_load_descriptor(nir_builder *b, unsigned desc_set, unsigned binding);
 nir_def *radv_meta_nir_build_blit2d_texel_fetch(struct nir_builder *b, struct radv_device *device, nir_def *tex_pos,
                                                 bool is_3d, bool is_multisampled);
 nir_def *radv_meta_nir_build_blit2d_buffer_fetch(struct nir_builder *b, struct radv_device *device, nir_def *tex_pos,
diff --git a/src/amd/vulkan/nir/radv_nir.h b/src/amd/vulkan/nir/radv_nir.h
index 2d087231031..dd96f38095a 100644
--- a/src/amd/vulkan/nir/radv_nir.h
+++ b/src/amd/vulkan/nir/radv_nir.h
@@ -71,6 +71,8 @@ bool radv_nir_lower_io_to_mem(struct radv_device *device, struct radv_shader_sta
 
 bool radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_level, unsigned wave_size);
 
+bool radv_nir_opt_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_level);
+
 bool radv_nir_lower_draw_id_to_zero(nir_shader *shader);
 
 bool radv_nir_remap_color_attachment(nir_shader *shader, const struct radv_graphics_state_key *gfx_state);
diff --git a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
index 932dac57d37..73e736ef753 100644
--- a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
+++ b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
@@ -60,47 +60,46 @@ typedef struct {
    unsigned wave_size;
 } lower_cmat_params;
 
+static unsigned
+radv_nir_cmat_bits(struct glsl_cmat_description desc)
+{
+   return glsl_base_type_bit_size(desc.element_type);
+}
+
 static unsigned
 radv_nir_cmat_length(struct glsl_cmat_description desc, const lower_cmat_params *params)
 {
    if (params->gfx_level >= GFX12) {
       assert(desc.cols == 16 && desc.rows == 16);
       return 256 / params->wave_size;
+   } else if (desc.use != GLSL_CMAT_USE_ACCUMULATOR) {
+      return 16;
    } else {
-      return desc.use != GLSL_CMAT_USE_ACCUMULATOR
-                ? 16
-                : (desc.cols * desc.rows / params->wave_size * 32 / glsl_base_type_bit_size(desc.element_type));
+      return desc.cols * desc.rows / params->wave_size * (radv_nir_cmat_bits(desc) == 16 ? 2 : 1);
    }
 }
 
 static unsigned
 radv_nir_cmat_length_mul(struct glsl_cmat_description desc, const lower_cmat_params *params)
 {
-   if (params->gfx_level >= GFX12) {
+   if (params->gfx_level >= GFX12 || desc.use != GLSL_CMAT_USE_ACCUMULATOR) {
       return 1;
    } else {
-      /* For C matrices we have 1 VGPR per element even if the element type is
-       * < 32 bits. So with 8 fp16 elements we implement that with a f16vec16.
+      /* For  GFX11 C matrices we have 1 VGPR per element even if the element type is
+       * 16bits. So with 8 fp16 elements we implement that with a f16vec16.
        * We then use the coefficient generated by this function to figure out
        * how many elements we really have.
        */
-      return desc.use == GLSL_CMAT_USE_ACCUMULATOR ? (32 / glsl_base_type_bit_size(desc.element_type)) : 1;
+      return radv_nir_cmat_bits(desc) == 16 ? 2 : 1;
    }
 }
 
-static unsigned
-radv_nir_cmat_bits(struct glsl_cmat_description desc)
-{
-   return glsl_base_type_bit_size(desc.element_type);
-}
-
 static nir_def *
 radv_nir_load_cmat(nir_builder *b, const lower_cmat_params *params, nir_def *src)
 {
    nir_deref_instr *deref = nir_instr_as_deref(src->parent_instr);
    struct glsl_cmat_description desc = *glsl_get_cmat_description(deref->type);
-   return nir_build_load_deref(b, radv_nir_cmat_length(desc, params), glsl_base_type_bit_size(desc.element_type), src,
-                               0);
+   return nir_build_load_deref(b, radv_nir_cmat_length(desc, params), radv_nir_cmat_bits(desc), src, 0);
 }
 
 static const struct glsl_type *
@@ -167,13 +166,15 @@ radv_get_base_row(nir_builder *b, struct glsl_cmat_description desc, const lower
    if (params->gfx_level >= GFX12) {
       base_row = nir_udiv_imm(b, local_idx, 16);
 
-      if (desc.use == GLSL_CMAT_USE_ACCUMULATOR && params->wave_size == 64) {
+      if ((desc.use == GLSL_CMAT_USE_ACCUMULATOR || radv_nir_cmat_bits(desc) == 8) && params->wave_size == 64) {
          /* Switch rows from lanes 16..31 to 32..47, offset right shift by -2
           * to get implicit * 4.
           */
          base_row = nir_ushr_imm(b, nir_bitfield_reverse(b, base_row), 30 - 2);
+      } else if ((desc.use == GLSL_CMAT_USE_ACCUMULATOR || radv_nir_cmat_bits(desc) == 8) && params->wave_size == 32) {
+         base_row = nir_imul_imm(b, base_row, 8);
       } else {
-         base_row = nir_imul_imm(b, base_row, desc.use == GLSL_CMAT_USE_ACCUMULATOR && params->wave_size == 32 ? 8 : 4);
+         base_row = nir_imul_imm(b, base_row, 4);
       }
    } else {
       base_row = desc.use == GLSL_CMAT_USE_ACCUMULATOR ? nir_udiv_imm(b, local_idx, 16) : nir_imm_int(b, 0);
@@ -182,6 +183,87 @@ radv_get_base_row(nir_builder *b, struct glsl_cmat_description desc, const lower
    return base_row;
 }
 
+static unsigned
+radv_get_row_iter(struct glsl_cmat_description desc, const lower_cmat_params *params, unsigned i)
+{
+   if (params->gfx_level >= GFX12) {
+      /* 8bit and ACC are indexed normally, 16bit A/B is weird. */
+      if (desc.use != GLSL_CMAT_USE_ACCUMULATOR && params->wave_size == 32 && radv_nir_cmat_bits(desc) >= 16)
+         return i + (i & 4);
+      else
+         return i;
+   } else {
+      if (desc.use != GLSL_CMAT_USE_ACCUMULATOR)
+         return i;
+      else
+         return i * params->wave_size / 16;
+   }
+}
+
+static nir_def *
+convert_base_type(nir_builder *b, nir_def *src, enum glsl_base_type src_type, enum glsl_base_type dst_type)
+{
+   if (dst_type == src_type)
+      return src;
+
+   if (src_type == GLSL_TYPE_BFLOAT16) {
+      src = nir_bf2f(b, src);
+      return convert_base_type(b, src, GLSL_TYPE_FLOAT, dst_type);
+   } else if (dst_type == GLSL_TYPE_BFLOAT16) {
+      src = convert_base_type(b, src, src_type, GLSL_TYPE_FLOAT);
+      return nir_f2bf(b, src);
+   } else if (src_type == GLSL_TYPE_FLOAT_E4M3FN) {
+      src = nir_e4m3fn2f(b, src);
+      return convert_base_type(b, src, GLSL_TYPE_FLOAT, dst_type);
+   } else if (dst_type == GLSL_TYPE_FLOAT_E4M3FN) {
+      src = convert_base_type(b, src, src_type, GLSL_TYPE_FLOAT);
+      return nir_f2e4m3fn(b, src);
+   }
+
+   nir_op op = nir_type_conversion_op(nir_get_nir_type_for_glsl_base_type(src_type),
+                                      nir_get_nir_type_for_glsl_base_type(dst_type), nir_rounding_mode_undef);
+
+   return nir_build_alu1(b, op, src);
+}
+
+static nir_def *
+radv_swizzle_gfx12_8bit_mat(nir_builder *b, nir_def *src, unsigned wave_size)
+{
+   assert(src->bit_size == 8);
+
+   src = nir_extract_bits(b, &src, 1, 0, src->num_components / 4, 32);
+
+   nir_def *res;
+
+   if (wave_size == 64) {
+      assert(src->num_components == 1);
+
+      nir_def *swapped = nir_rotate(b, src, nir_imm_int(b, 32), .cluster_size = 64);
+      swapped = nir_rotate(b, swapped, nir_imm_int(b, 16), .cluster_size = 32);
+
+      nir_def *cond = nir_inverse_ballot(b, 1, nir_imm_intN_t(b, 0xffffffff0000ull, 64));
+
+      res = nir_bcsel(b, cond, swapped, src);
+   } else {
+      assert(src->num_components == 2);
+
+      nir_def *src0 = nir_channel(b, src, 0);
+      nir_def *src1 = nir_channel(b, src, 1);
+
+      nir_def *swapped0 = nir_rotate(b, src0, nir_imm_int(b, 16), .cluster_size = 32);
+      nir_def *swapped1 = nir_rotate(b, src1, nir_imm_int(b, 16), .cluster_size = 32);
+
+      nir_def *cond = nir_inverse_ballot(b, 1, nir_imm_intN_t(b, 0xffff0000, 32));
+
+      nir_def *res0 = nir_bcsel(b, cond, swapped1, src0);
+      nir_def *res1 = nir_bcsel(b, cond, swapped0, src1);
+
+      res = nir_vec2(b, res0, res1);
+   }
+
+   return nir_extract_bits(b, &res, 1, 0, res->num_components * 4, 8);
+}
+
 bool
 radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_level, unsigned wave_size)
 {
@@ -292,12 +374,11 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
 
                unsigned length = radv_nir_cmat_length(desc, &params);
                unsigned mul = radv_nir_cmat_length_mul(desc, &params);
-               unsigned lanes_per_iter = desc.use == GLSL_CMAT_USE_ACCUMULATOR ? params.wave_size : 16;
                nir_def *vars[16];
                if (mul > 1) {
                   for (unsigned i = 0; i < length; ++i)
                      if (i % mul != 0)
-                        vars[i] = nir_undef(&b, 1, glsl_base_type_bit_size(desc.element_type));
+                        vars[i] = nir_undef(&b, 1, radv_nir_cmat_bits(desc));
                }
 
                unsigned idx_bits = deref->def.bit_size;
@@ -305,16 +386,10 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
 
                for (unsigned i = 0; i < length / mul; ++i) {
                   nir_def *col_offset = inner_idx;
-                  nir_def *row_offset;
-                  uint32_t row_iter;
 
-                  if (gfx_level >= GFX12) {
-                     row_iter = desc.use != GLSL_CMAT_USE_ACCUMULATOR && wave_size == 32 ? i + (i & 4) : i;
-                  } else {
-                     row_iter = i * lanes_per_iter / 16;
-                  }
+                  uint32_t row_iter = radv_get_row_iter(desc, &params, i);
 
-                  row_offset = nir_iadd_imm(&b, base_row, row_iter);
+                  nir_def *row_offset = nir_iadd_imm(&b, base_row, row_iter);
 
                   if (layout == GLSL_MATRIX_LAYOUT_ROW_MAJOR) {
                      nir_def *tmp = col_offset;
@@ -328,9 +403,8 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                   row_offset = nir_u2uN(&b, row_offset, idx_bits);
 
                   nir_deref_instr *iter_deref = nir_build_deref_ptr_as_array(&b, deref, col_offset);
-                  iter_deref =
-                     nir_build_deref_cast(&b, &iter_deref->def, deref->modes, glsl_scalar_type(desc.element_type),
-                                          glsl_base_type_bit_size(desc.element_type) / 8);
+                  iter_deref = nir_build_deref_cast(&b, &iter_deref->def, deref->modes,
+                                                    glsl_scalar_type(desc.element_type), radv_nir_cmat_bits(desc) / 8);
                   iter_deref = nir_build_deref_ptr_as_array(&b, iter_deref, row_offset);
 
                   vars[i * mul] = nir_load_deref(&b, iter_deref);
@@ -367,7 +441,6 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
 
                unsigned length = radv_nir_cmat_length(desc, &params);
                unsigned mul = radv_nir_cmat_length_mul(desc, &params);
-               unsigned lanes_per_iter = desc.use == GLSL_CMAT_USE_ACCUMULATOR ? params.wave_size : 16;
                nir_def *vars[16];
                for (unsigned i = 0; i < length; ++i)
                   vars[i] = nir_channel(&b, src, i);
@@ -377,16 +450,10 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
 
                for (unsigned i = 0; i < length / mul; ++i) {
                   nir_def *col_offset = inner_idx;
-                  nir_def *row_offset;
-                  uint32_t row_iter;
 
-                  if (gfx_level >= GFX12) {
-                     row_iter = desc.use != GLSL_CMAT_USE_ACCUMULATOR && wave_size == 32 ? i + (i & 4) : i;
-                  } else {
-                     row_iter = i * lanes_per_iter / 16;
-                  }
+                  uint32_t row_iter = radv_get_row_iter(desc, &params, i);
 
-                  row_offset = nir_iadd_imm(&b, base_row, row_iter);
+                  nir_def *row_offset = nir_iadd_imm(&b, base_row, row_iter);
 
                   if (layout == GLSL_MATRIX_LAYOUT_ROW_MAJOR) {
                      nir_def *tmp = col_offset;
@@ -400,9 +467,8 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                   row_offset = nir_u2uN(&b, row_offset, idx_bits);
 
                   nir_deref_instr *iter_deref = nir_build_deref_ptr_as_array(&b, deref, col_offset);
-                  iter_deref =
-                     nir_build_deref_cast(&b, &iter_deref->def, deref->modes, glsl_scalar_type(desc.element_type),
-                                          glsl_base_type_bit_size(desc.element_type) / 8);
+                  iter_deref = nir_build_deref_cast(&b, &iter_deref->def, deref->modes,
+                                                    glsl_scalar_type(desc.element_type), radv_nir_cmat_bits(desc) / 8);
                   iter_deref = nir_build_deref_ptr_as_array(&b, iter_deref, row_offset);
 
                   nir_store_deref(&b, iter_deref, vars[i * mul], 1);
@@ -419,44 +485,73 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                nir_def *A = radv_nir_load_cmat(&b, &params, intr->src[1].ssa);
                nir_def *B = radv_nir_load_cmat(&b, &params, intr->src[2].ssa);
                nir_def *C = radv_nir_load_cmat(&b, &params, intr->src[3].ssa);
-               nir_def *ret;
 
-               ret = nir_cmat_muladd_amd(&b, A, B, C, .saturate = nir_intrinsic_saturate(intr),
-                                         .cmat_signed_mask = nir_intrinsic_cmat_signed_mask(intr));
+               nir_deref_instr *a_deref = nir_instr_as_deref(intr->src[1].ssa->parent_instr);
+               nir_deref_instr *b_deref = nir_instr_as_deref(intr->src[2].ssa->parent_instr);
+               struct glsl_cmat_description a_desc = *glsl_get_cmat_description(a_deref->type);
+               struct glsl_cmat_description b_desc = *glsl_get_cmat_description(b_deref->type);
 
-               nir_store_deref(&b, nir_instr_as_deref(intr->src[0].ssa->parent_instr), ret,
-                               nir_component_mask(ret->num_components));
+               const nir_cmat_signed cmat_signed_mask = nir_intrinsic_cmat_signed_mask(intr);
+
+               enum glsl_base_type a_element_type =
+                  glsl_apply_signedness_to_base_type(a_desc.element_type, cmat_signed_mask & NIR_CMAT_A_SIGNED);
+               enum glsl_base_type b_element_type =
+                  glsl_apply_signedness_to_base_type(b_desc.element_type, cmat_signed_mask & NIR_CMAT_B_SIGNED);
+
+               nir_def *ret = nir_cmat_muladd_amd(&b, A, B, C, .saturate = nir_intrinsic_saturate(intr),
+                                                  .src_base_type = a_element_type, .src_base_type2 = b_element_type);
+
+               nir_deref_instr *dst_deref = nir_instr_as_deref(intr->src[0].ssa->parent_instr);
+               nir_store_deref(&b, dst_deref, ret, nir_component_mask(ret->num_components));
                nir_instr_remove(instr);
                progress = true;
                break;
             }
-            case nir_intrinsic_cmat_unary_op: {
+            case nir_intrinsic_cmat_convert: {
                nir_deref_instr *dst_deref = nir_instr_as_deref(intr->src[0].ssa->parent_instr);
                nir_deref_instr *src_deref = nir_instr_as_deref(intr->src[1].ssa->parent_instr);
-               struct glsl_cmat_description desc = *glsl_get_cmat_description(dst_deref->type);
+               struct glsl_cmat_description dst_desc = *glsl_get_cmat_description(dst_deref->type);
                struct glsl_cmat_description src_desc = *glsl_get_cmat_description(src_deref->type);
                nir_def *src = radv_nir_load_cmat(&b, &params, intr->src[1].ssa);
-               nir_op op = nir_intrinsic_alu_op(intr);
 
-               if (gfx_level < GFX12 && glsl_base_type_bit_size(src_desc.element_type) == 16 &&
-                   glsl_base_type_bit_size(desc.element_type) == 32 && desc.use == GLSL_CMAT_USE_ACCUMULATOR) {
+               const nir_cmat_signed cmat_signed_mask = nir_intrinsic_cmat_signed_mask(intr);
+
+               enum glsl_base_type dst_element_type = glsl_apply_signedness_to_base_type(
+                  dst_desc.element_type, cmat_signed_mask & NIR_CMAT_RESULT_SIGNED);
+               enum glsl_base_type src_element_type = glsl_apply_signedness_to_base_type(
+                  src_desc.element_type, cmat_signed_mask & NIR_CMAT_A_SIGNED);
+
+               unsigned dst_mul = radv_nir_cmat_length_mul(dst_desc, &params);
+               unsigned src_mul = radv_nir_cmat_length_mul(src_desc, &params);
+
+               if (src_mul > dst_mul) {
                   nir_def *components[NIR_MAX_VEC_COMPONENTS];
-                  for (unsigned i = 0; i * 2 < src->num_components; ++i) {
-                     components[i] = nir_channel(&b, src, i * 2);
+                  unsigned scale = src_mul / dst_mul;
+                  for (unsigned i = 0; i * scale < src->num_components; ++i) {
+                     components[i] = nir_channel(&b, src, i * scale);
                   }
-                  src = nir_vec(&b, components, src->num_components / 2);
+                  src = nir_vec(&b, components, src->num_components / scale);
                }
 
-               nir_def *ret = nir_build_alu1(&b, op, src);
+               if (dst_desc.use != GLSL_CMAT_USE_ACCUMULATOR && gfx_level >= GFX12 &&
+                   radv_nir_cmat_bits(src_desc) == 8 && radv_nir_cmat_bits(dst_desc) > 8)
+                  src = radv_swizzle_gfx12_8bit_mat(&b, src, wave_size);
+
+               nir_def *ret = convert_base_type(&b, src, src_element_type, dst_element_type);
+
+               if (dst_desc.use != GLSL_CMAT_USE_ACCUMULATOR && gfx_level >= GFX12 &&
+                   radv_nir_cmat_bits(dst_desc) == 8 && radv_nir_cmat_bits(src_desc) > 8)
+                  ret = radv_swizzle_gfx12_8bit_mat(&b, ret, wave_size);
 
-               if (gfx_level < GFX12 && glsl_base_type_bit_size(src_desc.element_type) == 32 &&
-                   glsl_base_type_bit_size(desc.element_type) == 16 && desc.use == GLSL_CMAT_USE_ACCUMULATOR) {
+               if (dst_mul > src_mul) {
                   nir_def *components[NIR_MAX_VEC_COMPONENTS];
+                  unsigned scale = dst_mul / src_mul;
                   for (unsigned i = 0; i < ret->num_components; ++i) {
-                     components[i * 2] = nir_channel(&b, ret, i);
-                     components[i * 2 + 1] = nir_undef(&b, 1, 16);
+                     components[i * scale] = nir_channel(&b, ret, i);
+                     for (unsigned j = 1; j < scale; j++)
+                        components[i * scale + j] = nir_undef(&b, 1, ret->bit_size);
                   }
-                  ret = nir_vec(&b, components, ret->num_components * 2);
+                  ret = nir_vec(&b, components, ret->num_components * scale);
                }
 
                nir_store_deref(&b, dst_deref, ret, nir_component_mask(ret->num_components));
@@ -464,6 +559,16 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                progress = true;
                break;
             }
+            case nir_intrinsic_cmat_unary_op: {
+               nir_def *src = radv_nir_load_cmat(&b, &params, intr->src[1].ssa);
+               nir_op op = nir_intrinsic_alu_op(intr);
+               nir_def *ret = nir_build_alu1(&b, op, src);
+               nir_store_deref(&b, nir_instr_as_deref(intr->src[0].ssa->parent_instr), ret,
+                               nir_component_mask(ret->num_components));
+               nir_instr_remove(instr);
+               progress = true;
+               break;
+            }
             case nir_intrinsic_cmat_scalar_op: {
                nir_def *src1 = radv_nir_load_cmat(&b, &params, intr->src[1].ssa);
                nir_op op = nir_intrinsic_alu_op(intr);
@@ -523,3 +628,119 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
 
    return nir_progress(progress, func->impl, 0);
 }
+
+static bool
+apply_component_mods(nir_scalar *comp, unsigned num_comps, unsigned stride, nir_op alu_op)
+{
+   for (unsigned i = 0; i < num_comps; i++) {
+      nir_scalar s = comp[i * stride];
+      if (!nir_scalar_is_alu(s) || nir_scalar_alu_op(s) != alu_op)
+         return false;
+   }
+
+   for (unsigned i = 0; i < num_comps; i++)
+      comp[i * stride] = nir_scalar_chase_alu_src(comp[i * stride], 0);
+
+   return true;
+}
+
+/* Apply neg_lo/neg_hi modifiers to A/B and neg/abs to C. */
+static bool
+opt_cmat_modifiers(nir_builder *b, nir_intrinsic_instr *intrin, enum amd_gfx_level gfx_level, unsigned src_idx)
+{
+   unsigned length_mul = src_idx == 2 && intrin->src[2].ssa->bit_size == 16 && gfx_level < GFX12 ? 2 : 1;
+   nir_scalar comp[NIR_MAX_VEC_COMPONENTS] = {0};
+   nir_def *src = intrin->src[src_idx].ssa;
+
+   for (unsigned i = 0; i < src->num_components; i += length_mul)
+      comp[i] = nir_scalar_resolved(src, i);
+
+   unsigned neg_lo = nir_intrinsic_neg_lo_amd(intrin);
+   unsigned neg_hi = nir_intrinsic_neg_hi_amd(intrin);
+
+   bool progress = false;
+   if (src_idx == 2) {
+      unsigned num_comp = src->num_components / length_mul;
+      if (apply_component_mods(comp, num_comp, length_mul, nir_op_fneg)) {
+         neg_lo ^= (~neg_hi) & BITFIELD_BIT(src_idx);
+         progress = true;
+      }
+      if (apply_component_mods(comp, num_comp, length_mul, nir_op_fabs)) {
+         neg_hi |= BITFIELD_BIT(src_idx);
+         progress = true;
+      }
+   } else {
+      unsigned num_comp = src->num_components / 2;
+      if (apply_component_mods(comp, num_comp, 2, nir_op_fneg)) {
+         neg_lo ^= BITFIELD_BIT(src_idx);
+         progress = true;
+      }
+      if (apply_component_mods(comp + 1, num_comp, 2, nir_op_fneg)) {
+         neg_hi ^= BITFIELD_BIT(src_idx);
+         progress = true;
+      }
+   }
+
+   if (!progress)
+      return false;
+
+   nir_intrinsic_set_neg_lo_amd(intrin, neg_lo);
+   nir_intrinsic_set_neg_hi_amd(intrin, neg_hi);
+
+   /* Avoid creating a new vec if we don't have to. */
+   nir_def *new_src = comp[0].def;
+   for (unsigned i = 0; i < src->num_components; i += length_mul) {
+      if (comp[i].def != new_src || comp[i].comp != i) {
+         new_src = NULL;
+         break;
+      }
+   }
+
+   if (!new_src) {
+      b->cursor = nir_before_instr(&intrin->instr);
+      if (length_mul > 1) {
+         nir_scalar undef = nir_get_scalar(nir_undef(b, 1, src->bit_size), 0);
+         for (unsigned i = 0; i < src->num_components; i += length_mul) {
+            for (unsigned j = 1; j < length_mul; j++)
+               comp[i + j] = undef;
+         }
+      }
+
+      new_src = nir_vec_scalars(b, comp, src->num_components);
+   }
+
+   nir_src_rewrite(&intrin->src[src_idx], new_src);
+   return true;
+}
+
+static bool
+opt_cmat(nir_builder *b, nir_intrinsic_instr *intrin, void *data)
+{
+   enum amd_gfx_level gfx_level = *(enum amd_gfx_level *)data;
+
+   if (intrin->intrinsic != nir_intrinsic_cmat_muladd_amd)
+      return false;
+
+   enum glsl_base_type a_type = nir_intrinsic_src_base_type(intrin);
+
+   if (glsl_base_type_is_integer(a_type))
+      return false;
+
+   bool progress = false;
+
+   if (a_type == GLSL_TYPE_FLOAT16) {
+      for (unsigned i = 0; i < 2; i++)
+         progress |= opt_cmat_modifiers(b, intrin, gfx_level, i);
+   }
+
+   if (a_type == GLSL_TYPE_FLOAT16 || intrin->def.bit_size == 32)
+      progress |= opt_cmat_modifiers(b, intrin, gfx_level, 2);
+
+   return progress;
+}
+
+bool
+radv_nir_opt_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_level)
+{
+   return nir_shader_intrinsics_pass(shader, opt_cmat, nir_metadata_control_flow, &gfx_level);
+}
diff --git a/src/amd/vulkan/nir/radv_nir_lower_ray_queries.c b/src/amd/vulkan/nir/radv_nir_lower_ray_queries.c
index cc6b4c832d6..2dc30e5a474 100644
--- a/src/amd/vulkan/nir/radv_nir_lower_ray_queries.c
+++ b/src/amd/vulkan/nir/radv_nir_lower_ray_queries.c
@@ -241,8 +241,11 @@ enum rq_intersection_type { intersection_type_none, intersection_type_triangle,
 
 static void
 lower_rq_initialize(nir_builder *b, nir_intrinsic_instr *instr, struct ray_query_vars *vars, nir_deref_instr *rq,
-                    struct radv_instance *instance)
+                    struct radv_device *device)
 {
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+   struct radv_instance *instance = radv_physical_device_instance(pdev);
+
    nir_deref_instr *closest = rq_deref(b, rq, closest);
    nir_deref_instr *candidate = rq_deref(b, rq, candidate);
 
@@ -270,7 +273,7 @@ lower_rq_initialize(nir_builder *b, nir_intrinsic_instr *instr, struct ray_query
       b, 1, 32, nir_iadd_imm(b, accel_struct, offsetof(struct radv_accel_struct_header, bvh_offset)),
       .access = ACCESS_NON_WRITEABLE);
    nir_def *bvh_base = nir_iadd(b, accel_struct, nir_u2u64(b, bvh_offset));
-   bvh_base = build_addr_to_node(b, bvh_base);
+   bvh_base = build_addr_to_node(device, b, bvh_base, instr->src[2].ssa);
 
    rq_store(b, rq, root_bvh_base, bvh_base);
    rq_store(b, rq, trav_bvh_base, bvh_base);
@@ -320,44 +323,27 @@ lower_rq_load(struct radv_device *device, nir_builder *b, nir_intrinsic_instr *i
       return isec_load(b, intersection, frontface);
    case nir_ray_query_value_intersection_geometry_index:
       return nir_iand_imm(b, isec_load(b, intersection, geometry_id_and_flags), 0xFFFFFF);
-   case nir_ray_query_value_intersection_instance_custom_index: {
-      nir_def *instance_node_addr = isec_load(b, intersection, instance_addr);
-      return nir_iand_imm(
-         b,
-         nir_build_load_global(
-            b, 1, 32,
-            nir_iadd_imm(b, instance_node_addr, offsetof(struct radv_bvh_instance_node, custom_instance_and_mask))),
-         0xFFFFFF);
-   }
-   case nir_ray_query_value_intersection_instance_id: {
-      nir_def *instance_node_addr = isec_load(b, intersection, instance_addr);
-      return nir_build_load_global(
-         b, 1, 32, nir_iadd_imm(b, instance_node_addr, offsetof(struct radv_bvh_instance_node, instance_id)));
-   }
+   case nir_ray_query_value_intersection_instance_custom_index:
+      return radv_load_custom_instance(device, b, isec_load(b, intersection, instance_addr));
+   case nir_ray_query_value_intersection_instance_id:
+      return radv_load_instance_id(device, b, isec_load(b, intersection, instance_addr));
    case nir_ray_query_value_intersection_instance_sbt_index:
       return nir_iand_imm(b, isec_load(b, intersection, sbt_offset_and_flags), 0xFFFFFF);
    case nir_ray_query_value_intersection_object_ray_direction: {
-      nir_def *instance_node_addr = isec_load(b, intersection, instance_addr);
       nir_def *wto_matrix[3];
-      nir_build_wto_matrix_load(b, instance_node_addr, wto_matrix);
+      radv_load_wto_matrix(device, b, isec_load(b, intersection, instance_addr), wto_matrix);
       return nir_build_vec3_mat_mult(b, rq_load(b, rq, direction), wto_matrix, false);
    }
    case nir_ray_query_value_intersection_object_ray_origin: {
-      nir_def *instance_node_addr = isec_load(b, intersection, instance_addr);
       nir_def *wto_matrix[3];
-      nir_build_wto_matrix_load(b, instance_node_addr, wto_matrix);
+      radv_load_wto_matrix(device, b, isec_load(b, intersection, instance_addr), wto_matrix);
       return nir_build_vec3_mat_mult(b, rq_load(b, rq, origin), wto_matrix, true);
    }
    case nir_ray_query_value_intersection_object_to_world: {
-      nir_def *instance_node_addr = isec_load(b, intersection, instance_addr);
-      nir_def *rows[3];
-      for (unsigned r = 0; r < 3; ++r)
-         rows[r] = nir_build_load_global(
-            b, 4, 32,
-            nir_iadd_imm(b, instance_node_addr, offsetof(struct radv_bvh_instance_node, otw_matrix) + r * 16));
-
-      return nir_vec3(b, nir_channel(b, rows[0], column), nir_channel(b, rows[1], column),
-                      nir_channel(b, rows[2], column));
+      nir_def *otw_matrix[3];
+      radv_load_otw_matrix(device, b, isec_load(b, intersection, instance_addr), otw_matrix);
+      return nir_vec3(b, nir_channel(b, otw_matrix[0], column), nir_channel(b, otw_matrix[1], column),
+                      nir_channel(b, otw_matrix[2], column));
    }
    case nir_ray_query_value_intersection_primitive_index:
       return isec_load(b, intersection, primitive_id);
@@ -371,10 +357,8 @@ lower_rq_load(struct radv_device *device, nir_builder *b, nir_intrinsic_instr *i
       return intersection_type;
    }
    case nir_ray_query_value_intersection_world_to_object: {
-      nir_def *instance_node_addr = isec_load(b, intersection, instance_addr);
-
       nir_def *wto_matrix[3];
-      nir_build_wto_matrix_load(b, instance_node_addr, wto_matrix);
+      radv_load_wto_matrix(device, b, isec_load(b, intersection, instance_addr), wto_matrix);
 
       nir_def *vals[3];
       for (unsigned i = 0; i < 3; ++i)
@@ -477,6 +461,8 @@ static nir_def *
 lower_rq_proceed(nir_builder *b, nir_intrinsic_instr *instr, struct ray_query_vars *vars, nir_deref_instr *rq,
                  struct radv_device *device)
 {
+   struct radv_physical_device *pdev = radv_device_physical(device);
+
    nir_deref_instr *closest = rq_deref(b, rq, closest);
    nir_deref_instr *candidate = rq_deref(b, rq, candidate);
 
@@ -543,7 +529,11 @@ lower_rq_proceed(nir_builder *b, nir_intrinsic_instr *instr, struct ray_query_va
 
    nir_push_if(b, rq_load(b, rq, incomplete));
    {
-      nir_def *incomplete = radv_build_ray_traversal(device, b, &args);
+      nir_def *incomplete;
+      if (radv_use_bvh8(pdev))
+         incomplete = radv_build_ray_traversal_gfx12(device, b, &args);
+      else
+         incomplete = radv_build_ray_traversal(device, b, &args);
       rq_store(b, rq, incomplete, nir_iand(b, rq_load(b, rq, incomplete), incomplete));
    }
    nir_pop_if(b, NULL);
@@ -571,7 +561,7 @@ bool
 radv_nir_lower_ray_queries(struct nir_shader *shader, struct radv_device *device)
 {
    const struct radv_physical_device *pdev = radv_device_physical(device);
-   struct radv_instance *instance = radv_physical_device_instance(pdev);
+
    bool progress = false;
    struct hash_table *query_ht = _mesa_pointer_hash_table_create(NULL);
 
@@ -626,7 +616,7 @@ radv_nir_lower_ray_queries(struct nir_shader *shader, struct radv_device *device
                lower_rq_generate_intersection(&builder, intrinsic, rq);
                break;
             case nir_intrinsic_rq_initialize:
-               lower_rq_initialize(&builder, intrinsic, vars, rq, instance);
+               lower_rq_initialize(&builder, intrinsic, vars, rq, device);
                break;
             case nir_intrinsic_rq_load:
                new_dest = lower_rq_load(device, &builder, intrinsic, rq);
diff --git a/src/amd/vulkan/nir/radv_nir_rt_common.c b/src/amd/vulkan/nir/radv_nir_rt_common.c
index e5bc4ea05d8..c41cb625864 100644
--- a/src/amd/vulkan/nir/radv_nir_rt_common.c
+++ b/src/amd/vulkan/nir/radv_nir_rt_common.c
@@ -267,11 +267,27 @@ intersect_ray_amd_software_tri(struct radv_device *device, nir_builder *b, nir_d
 }
 
 nir_def *
-build_addr_to_node(nir_builder *b, nir_def *addr)
+build_addr_to_node(struct radv_device *device, nir_builder *b, nir_def *addr, nir_def *flags)
 {
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
    const uint64_t bvh_size = 1ull << 42;
    nir_def *node = nir_ushr_imm(b, addr, 3);
-   return nir_iand_imm(b, node, (bvh_size - 1) << 3);
+   node = nir_iand_imm(b, node, (bvh_size - 1) << 3);
+
+   if (radv_use_bvh8(pdev)) {
+      /* The HW ray flags are the same bits as the API flags.
+       * - SpvRayFlagsTerminateOnFirstHitKHRMask, SpvRayFlagsSkipClosestHitShaderKHRMask are handled in shader code.
+       * - SpvRayFlagsSkipTrianglesKHRMask, SpvRayFlagsSkipAABBsKHRMask do not work.
+       */
+      flags = nir_iand_imm(b, flags,
+                           SpvRayFlagsOpaqueKHRMask | SpvRayFlagsNoOpaqueKHRMask |
+                              SpvRayFlagsCullBackFacingTrianglesKHRMask | SpvRayFlagsCullFrontFacingTrianglesKHRMask |
+                              SpvRayFlagsCullOpaqueKHRMask | SpvRayFlagsCullNoOpaqueKHRMask);
+      node = nir_ior(b, node, nir_ishl_imm(b, nir_u2u64(b, flags), 54));
+   }
+
+   return node;
 }
 
 static nir_def *
@@ -302,20 +318,57 @@ nir_build_vec3_mat_mult(nir_builder *b, nir_def *vec, nir_def *matrix[], bool tr
    return nir_vec(b, result_components, 3);
 }
 
-void
-nir_build_wto_matrix_load(nir_builder *b, nir_def *instance_addr, nir_def **out)
-{
-   unsigned offset = offsetof(struct radv_bvh_instance_node, wto_matrix);
-   for (unsigned i = 0; i < 3; ++i) {
-      out[i] = nir_build_load_global(b, 4, 32, nir_iadd_imm(b, instance_addr, offset + i * 16), .align_mul = 64,
-                                     .align_offset = offset + i * 16);
-   }
-}
-
 nir_def *
 radv_load_vertex_position(struct radv_device *device, nir_builder *b, nir_def *instance_addr, nir_def *geometry_id,
                           nir_def *primitive_id, uint32_t index)
 {
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
+   if (radv_use_bvh8(pdev)) {
+      nir_def *addr_offsets =
+         nir_build_load_global(b, 4, 32,
+                               nir_iadd_imm(b, instance_addr,
+                                            sizeof(struct radv_gfx12_instance_node) +
+                                               offsetof(struct radv_gfx12_instance_node_user_data, blas_addr)));
+      nir_def *bvh_offset =
+         nir_build_load_global(b, 1, 32,
+                               nir_iadd_imm(b, instance_addr,
+                                            sizeof(struct radv_gfx12_instance_node) +
+                                               offsetof(struct radv_gfx12_instance_node_user_data, bvh_offset)));
+
+      nir_def *addr = nir_pack_64_2x32(b, nir_channels(b, addr_offsets, 0x3));
+
+      nir_def *base_index_offset =
+         nir_iadd(b, nir_channel(b, addr_offsets, 2), nir_imul_imm(b, geometry_id, sizeof(uint32_t)));
+      nir_def *base_index = nir_build_load_global(b, 1, 32, nir_iadd(b, addr, nir_u2u64(b, base_index_offset)));
+
+      nir_def *offset_offset = nir_iadd(b, nir_channel(b, addr_offsets, 3),
+                                        nir_imul_imm(b, nir_iadd(b, base_index, primitive_id), sizeof(uint32_t)));
+      nir_def *offset = nir_build_load_global(b, 1, 32, nir_iadd(b, addr, nir_u2u64(b, offset_offset)));
+      offset = nir_iadd(b, offset, bvh_offset);
+
+      /* Assume that vertices are uncompressed. */
+      offset = nir_iadd_imm(b, offset,
+                            ROUND_DOWN_TO(RADV_GFX12_PRIMITIVE_NODE_HEADER_SIZE / 8, 4) + index * 3 * sizeof(float));
+
+      nir_def *data[4];
+      for (uint32_t i = 0; i < ARRAY_SIZE(data); i++) {
+         data[i] = nir_build_load_global(b, 1, 32, nir_iadd(b, addr, nir_u2u64(b, offset)));
+         offset = nir_iadd_imm(b, offset, 4);
+      }
+
+      uint32_t subdword_offset = RADV_GFX12_PRIMITIVE_NODE_HEADER_SIZE % 32;
+
+      nir_def *vertices[3];
+      for (uint32_t i = 0; i < ARRAY_SIZE(vertices); i++) {
+         nir_def *lo = nir_ubitfield_extract_imm(b, data[i], subdword_offset, 32 - subdword_offset);
+         nir_def *hi = nir_ubitfield_extract_imm(b, data[i + 1], 0, subdword_offset);
+         vertices[i] = nir_ior(b, lo, nir_ishl_imm(b, hi, 32 - subdword_offset));
+      }
+
+      return nir_vec3(b, vertices[0], vertices[1], vertices[2]);
+   }
+
    nir_def *bvh_addr_id =
       nir_build_load_global(b, 1, 64, nir_iadd_imm(b, instance_addr, offsetof(struct radv_bvh_instance_node, bvh_ptr)));
    nir_def *bvh_addr = build_node_to_addr(device, b, bvh_addr_id, true);
@@ -335,6 +388,74 @@ radv_load_vertex_position(struct radv_device *device, nir_builder *b, nir_def *i
    return nir_build_load_global(b, 3, 32, nir_iadd(b, bvh_addr, nir_u2u64(b, offset)));
 }
 
+void
+radv_load_wto_matrix(struct radv_device *device, nir_builder *b, nir_def *instance_addr, nir_def **out)
+{
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
+   unsigned offset = offsetof(struct radv_bvh_instance_node, wto_matrix);
+   if (radv_use_bvh8(pdev))
+      offset = offsetof(struct radv_gfx12_instance_node, wto_matrix);
+
+   for (unsigned i = 0; i < 3; ++i) {
+      out[i] = nir_build_load_global(b, 4, 32, nir_iadd_imm(b, instance_addr, offset + i * 16), .align_mul = 64,
+                                     .align_offset = (offset + i * 16) % 64);
+   }
+}
+
+void
+radv_load_otw_matrix(struct radv_device *device, nir_builder *b, nir_def *instance_addr, nir_def **out)
+{
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
+   unsigned offset = offsetof(struct radv_bvh_instance_node, otw_matrix);
+   if (radv_use_bvh8(pdev))
+      offset =
+         sizeof(struct radv_gfx12_instance_node) + offsetof(struct radv_gfx12_instance_node_user_data, otw_matrix);
+
+   for (unsigned i = 0; i < 3; ++i) {
+      out[i] = nir_build_load_global(b, 4, 32, nir_iadd_imm(b, instance_addr, offset + i * 16), .align_mul = 64,
+                                     .align_offset = (offset + i * 16) % 64);
+   }
+}
+
+nir_def *
+radv_load_custom_instance(struct radv_device *device, nir_builder *b, nir_def *instance_addr)
+{
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
+   if (radv_use_bvh8(pdev)) {
+      return nir_build_load_global(
+         b, 1, 32,
+         nir_iadd_imm(b, instance_addr,
+                      sizeof(struct radv_gfx12_instance_node) +
+                         offsetof(struct radv_gfx12_instance_node_user_data, custom_instance)));
+   }
+
+   return nir_iand_imm(
+      b,
+      nir_build_load_global(
+         b, 1, 32, nir_iadd_imm(b, instance_addr, offsetof(struct radv_bvh_instance_node, custom_instance_and_mask))),
+      0xFFFFFF);
+}
+
+nir_def *
+radv_load_instance_id(struct radv_device *device, nir_builder *b, nir_def *instance_addr)
+{
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
+   if (radv_use_bvh8(pdev)) {
+      return nir_build_load_global(
+         b, 1, 32,
+         nir_iadd_imm(b, instance_addr,
+                      sizeof(struct radv_gfx12_instance_node) +
+                         offsetof(struct radv_gfx12_instance_node_user_data, instance_index)));
+   }
+
+   return nir_build_load_global(b, 1, 32,
+                                nir_iadd_imm(b, instance_addr, offsetof(struct radv_bvh_instance_node, instance_id)));
+}
+
 /* When a hit is opaque the any_hit shader is skipped for this hit and the hit
  * is assumed to be an actual hit. */
 static nir_def *
@@ -355,8 +476,15 @@ create_bvh_descriptor(nir_builder *b, const struct radv_physical_device *pdev, s
     * use the same descriptor, which avoids divergence when different rays hit different
     * instances at the cost of having to use 64-bit node ids. */
    const uint64_t bvh_size = 1ull << 42;
-   nir_def *desc = nir_imm_ivec4(b, 0, 1u << 31 /* Enable box sorting */, (bvh_size - 1) & 0xFFFFFFFFu,
-                                 ((bvh_size - 1) >> 32) | (1u << 24 /* Return IJ for triangles */) | (1u << 31));
+
+   const uint32_t sort_triangles_first = radv_use_bvh8(pdev) ? BITFIELD_BIT(52 - 32) : 0;
+   const uint32_t box_sort_enable = BITFIELD_BIT(63 - 32);
+   const uint32_t triangle_return_mode = BITFIELD_BIT(120 - 96); /* Return IJ for triangles */
+
+   uint32_t dword0 = 0;
+   nir_def *dword1 = nir_imm_intN_t(b, sort_triangles_first | box_sort_enable, 32);
+   uint32_t dword2 = (bvh_size - 1) & 0xFFFFFFFFu;
+   uint32_t dword3 = ((bvh_size - 1) >> 32) | triangle_return_mode | (1u << 31);
 
    if (pdev->info.gfx_level >= GFX11) {
       /* Instead of the default box sorting (closest point), use largest for terminate_on_first_hit rays and midpoint
@@ -366,16 +494,24 @@ create_bvh_descriptor(nir_builder *b, const struct radv_physical_device *pdev, s
 
       /* Only use largest/midpoint sorting when all invocations have the same ray flags, otherwise
        * fall back to the default closest point. */
-      nir_def *box_sort = nir_imm_int(b, 1u << 31);
-      box_sort = nir_bcsel(b, nir_vote_any(b, 1, ray_flags->terminate_on_first_hit), box_sort,
-                           nir_imm_int(b, (box_sort_midpoint << 21) | (1u << 31)));
-      box_sort = nir_bcsel(b, nir_vote_all(b, 1, ray_flags->terminate_on_first_hit),
-                           nir_imm_int(b, (box_sort_largest << 21) | (1u << 31)), box_sort);
+      dword1 = nir_bcsel(b, nir_vote_any(b, 1, ray_flags->terminate_on_first_hit), dword1,
+                         nir_imm_int(b, (box_sort_midpoint << 21) | sort_triangles_first | box_sort_enable));
+      dword1 = nir_bcsel(b, nir_vote_all(b, 1, ray_flags->terminate_on_first_hit),
+                         nir_imm_int(b, (box_sort_largest << 21) | sort_triangles_first | box_sort_enable), dword1);
+   }
 
-      desc = nir_vector_insert(b, desc, box_sort, nir_imm_int(b, 1));
+   if (radv_use_bvh8(pdev)) {
+      /* compressed_format_en */
+      dword3 |= BITFIELD_BIT(115 - 96);
+      /* wide_sort_en */
+      dword3 |= BITFIELD_BIT(117 - 96);
+      /* instance_en */
+      dword3 |= BITFIELD_BIT(118 - 96);
+      /* pointer_flags */
+      dword3 |= BITFIELD_BIT(119 - 96);
    }
 
-   return desc;
+   return nir_vec4(b, nir_imm_intN_t(b, dword0, 32), dword1, nir_imm_intN_t(b, dword2, 32), nir_imm_intN_t(b, dword3, 32));
 }
 
 static void
@@ -436,6 +572,36 @@ insert_traversal_triangle_case(struct radv_device *device, nir_builder *b, const
    nir_pop_if(b, NULL);
 }
 
+static void
+insert_traversal_triangle_case_gfx12(struct radv_device *device, nir_builder *b,
+                                     const struct radv_ray_traversal_args *args, const struct radv_ray_flags *ray_flags,
+                                     nir_def *result, nir_def *bvh_node)
+{
+   if (!args->triangle_cb)
+      return;
+
+   struct radv_triangle_intersection intersection;
+   intersection.t = nir_channel(b, result, 0);
+
+   nir_push_if(b, nir_iand(b, nir_flt(b, intersection.t, nir_load_deref(b, args->vars.tmax)),
+                           nir_flt(b, args->tmin, intersection.t)));
+   {
+      intersection.frontface = nir_inot(b, nir_test_mask(b, nir_channel(b, result, 3), 1));
+      intersection.base.node_addr = build_node_to_addr(device, b, bvh_node, false);
+      intersection.base.primitive_id = nir_ishr_imm(b, nir_channel(b, result, 3), 1);
+      intersection.base.geometry_id_and_flags = nir_ishr_imm(b, nir_channel(b, result, 8), 2);
+      intersection.base.opaque = nir_inot(b, nir_test_mask(b, nir_channel(b, result, 2), 1u << 31));
+      intersection.barycentrics = nir_fabs(b, nir_channels(b, result, 0x3 << 1));
+
+      nir_push_if(b, nir_bcsel(b, intersection.base.opaque, ray_flags->no_cull_opaque, ray_flags->no_cull_no_opaque));
+      {
+         args->triangle_cb(b, &intersection, args, ray_flags);
+      }
+      nir_pop_if(b, NULL);
+   }
+   nir_pop_if(b, NULL);
+}
+
 static void
 insert_traversal_aabb_case(struct radv_device *device, nir_builder *b, const struct radv_ray_traversal_args *args,
                            const struct radv_ray_flags *ray_flags, nir_def *bvh_node)
@@ -463,11 +629,31 @@ insert_traversal_aabb_case(struct radv_device *device, nir_builder *b, const str
    nir_pop_if(b, NULL);
 }
 
-static nir_def *
-fetch_parent_node(nir_builder *b, nir_def *bvh, nir_def *node)
+static void
+insert_traversal_aabb_case_gfx12(struct radv_device *device, nir_builder *b, const struct radv_ray_traversal_args *args,
+                                 const struct radv_ray_flags *ray_flags, nir_def *result, nir_def *bvh_node)
 {
-   nir_def *offset = nir_iadd_imm(b, nir_imul_imm(b, nir_udiv_imm(b, node, 8), 4), 4);
+   if (!args->aabb_cb)
+      return;
+
+   struct radv_leaf_intersection intersection;
+   intersection.node_addr = build_node_to_addr(device, b, bvh_node, false);
+   intersection.primitive_id = nir_ishr_imm(b, nir_channel(b, result, 3), 1);
+   intersection.geometry_id_and_flags = nir_ishr_imm(b, nir_channel(b, result, 8), 2);
+   intersection.opaque = nir_inot(b, nir_test_mask(b, nir_channel(b, result, 2), 1u << 31));
+
+   nir_push_if(b, nir_bcsel(b, intersection.opaque, ray_flags->no_cull_opaque, ray_flags->no_cull_no_opaque));
+   {
+      args->aabb_cb(b, &intersection, args);
+   }
+   nir_pop_if(b, NULL);
+}
 
+static nir_def *
+fetch_parent_node(struct radv_device *device, nir_builder *b, nir_def *bvh, nir_def *node)
+{
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+   nir_def *offset = nir_iadd_imm(b, nir_imul_imm(b, nir_udiv_imm(b, node, radv_use_bvh8(pdev) ? 16 : 8), 4), 4);
    return nir_build_load_global(b, 1, 32, nir_isub(b, bvh, nir_u2u64(b, offset)), .align_mul = 4);
 }
 
@@ -544,7 +730,7 @@ radv_build_ray_traversal(struct radv_device *device, nir_builder *b, const struc
             nir_def *prev = nir_load_deref(b, args->vars.previous_node);
             nir_def *bvh_addr = build_node_to_addr(device, b, nir_load_deref(b, args->vars.bvh_base), true);
 
-            nir_def *parent = fetch_parent_node(b, bvh_addr, prev);
+            nir_def *parent = fetch_parent_node(device, b, bvh_addr, prev);
             nir_push_if(b, nir_ieq_imm(b, parent, RADV_BVH_INVALID_NODE));
             {
                nir_store_var(b, incomplete, nir_imm_false(b), 0x1);
@@ -612,7 +798,7 @@ radv_build_ray_traversal(struct radv_device *device, nir_builder *b, const struc
                   nir_build_load_global(b, 4, 32, instance_node_addr, .align_mul = 64, .align_offset = 0);
 
                nir_def *wto_matrix[3];
-               nir_build_wto_matrix_load(b, instance_node_addr, wto_matrix);
+               radv_load_wto_matrix(device, b, instance_node_addr, wto_matrix);
 
                nir_store_deref(b, args->vars.sbt_offset_and_flags, nir_channel(b, instance_data, 3), 1);
 
@@ -715,3 +901,205 @@ radv_build_ray_traversal(struct radv_device *device, nir_builder *b, const struc
 
    return nir_load_var(b, incomplete);
 }
+
+nir_def *
+radv_build_ray_traversal_gfx12(struct radv_device *device, nir_builder *b, const struct radv_ray_traversal_args *args)
+{
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
+   nir_variable *incomplete = nir_local_variable_create(b->impl, glsl_bool_type(), "incomplete");
+   nir_store_var(b, incomplete, nir_imm_true(b), 0x1);
+
+   struct radv_ray_flags ray_flags = {
+      .force_opaque = radv_test_flag(b, args, SpvRayFlagsOpaqueKHRMask, true),
+      .force_not_opaque = radv_test_flag(b, args, SpvRayFlagsNoOpaqueKHRMask, true),
+      .terminate_on_first_hit = radv_test_flag(b, args, SpvRayFlagsTerminateOnFirstHitKHRMask, true),
+      .no_cull_front = radv_test_flag(b, args, SpvRayFlagsCullFrontFacingTrianglesKHRMask, false),
+      .no_cull_back = radv_test_flag(b, args, SpvRayFlagsCullBackFacingTrianglesKHRMask, false),
+      .no_cull_opaque = radv_test_flag(b, args, SpvRayFlagsCullOpaqueKHRMask, false),
+      .no_cull_no_opaque = radv_test_flag(b, args, SpvRayFlagsCullNoOpaqueKHRMask, false),
+      .no_skip_triangles = radv_test_flag(b, args, SpvRayFlagsSkipTrianglesKHRMask, false),
+      .no_skip_aabbs = radv_test_flag(b, args, SpvRayFlagsSkipAABBsKHRMask, false),
+   };
+
+   nir_def *desc = create_bvh_descriptor(b, pdev, &ray_flags);
+
+   nir_push_loop(b);
+   {
+      nir_push_if(b, nir_ieq_imm(b, nir_load_deref(b, args->vars.current_node), RADV_BVH_INVALID_NODE));
+      {
+         /* Early exit if we never overflowed the stack, to avoid having to backtrack to
+          * the root for no reason. */
+         nir_push_if(b, nir_ilt_imm(b, nir_load_deref(b, args->vars.stack), args->stack_base + args->stack_stride));
+         {
+            nir_store_var(b, incomplete, nir_imm_false(b), 0x1);
+            nir_jump(b, nir_jump_break);
+         }
+         nir_pop_if(b, NULL);
+
+         nir_def *stack_instance_exit =
+            nir_ige(b, nir_load_deref(b, args->vars.top_stack), nir_load_deref(b, args->vars.stack));
+         nir_def *root_instance_exit =
+            nir_ieq(b, nir_load_deref(b, args->vars.previous_node), nir_load_deref(b, args->vars.instance_bottom_node));
+         nir_if *instance_exit = nir_push_if(b, nir_ior(b, stack_instance_exit, root_instance_exit));
+         instance_exit->control = nir_selection_control_dont_flatten;
+         {
+            nir_store_deref(b, args->vars.top_stack, nir_imm_int(b, -1), 1);
+            nir_store_deref(b, args->vars.previous_node, nir_load_deref(b, args->vars.instance_top_node), 1);
+            nir_store_deref(b, args->vars.instance_bottom_node, nir_imm_int(b, RADV_BVH_NO_INSTANCE_ROOT), 1);
+
+            nir_store_deref(b, args->vars.bvh_base, args->root_bvh_base, 1);
+            nir_store_deref(b, args->vars.origin, args->origin, 7);
+            nir_store_deref(b, args->vars.dir, args->dir, 7);
+         }
+         nir_pop_if(b, NULL);
+
+         nir_push_if(
+            b, nir_ige(b, nir_load_deref(b, args->vars.stack_low_watermark), nir_load_deref(b, args->vars.stack)));
+         {
+            nir_def *prev = nir_load_deref(b, args->vars.previous_node);
+            nir_def *bvh_addr = build_node_to_addr(device, b, nir_load_deref(b, args->vars.bvh_base), true);
+
+            nir_def *parent = fetch_parent_node(device, b, bvh_addr, prev);
+            nir_push_if(b, nir_ieq_imm(b, parent, RADV_BVH_INVALID_NODE));
+            {
+               nir_store_var(b, incomplete, nir_imm_false(b), 0x1);
+               nir_jump(b, nir_jump_break);
+            }
+            nir_pop_if(b, NULL);
+            nir_store_deref(b, args->vars.current_node, parent, 0x1);
+         }
+         nir_push_else(b, NULL);
+         {
+            nir_store_deref(b, args->vars.stack,
+                            nir_iadd_imm(b, nir_load_deref(b, args->vars.stack), -args->stack_stride), 1);
+
+            nir_def *stack_ptr =
+               nir_umod_imm(b, nir_load_deref(b, args->vars.stack), args->stack_stride * args->stack_entries);
+            nir_def *bvh_node = args->stack_load_cb(b, stack_ptr, args);
+            nir_store_deref(b, args->vars.current_node, bvh_node, 0x1);
+            nir_store_deref(b, args->vars.previous_node, nir_imm_int(b, RADV_BVH_INVALID_NODE), 0x1);
+         }
+         nir_pop_if(b, NULL);
+      }
+      nir_push_else(b, NULL);
+      {
+         nir_store_deref(b, args->vars.previous_node, nir_imm_int(b, RADV_BVH_INVALID_NODE), 0x1);
+      }
+      nir_pop_if(b, NULL);
+
+      nir_def *bvh_node = nir_load_deref(b, args->vars.current_node);
+
+      nir_def *prev_node = nir_load_deref(b, args->vars.previous_node);
+      nir_store_deref(b, args->vars.previous_node, bvh_node, 0x1);
+      nir_store_deref(b, args->vars.current_node, nir_imm_int(b, RADV_BVH_INVALID_NODE), 0x1);
+
+      nir_def *global_bvh_node = nir_iadd(b, nir_load_deref(b, args->vars.bvh_base), nir_u2u64(b, bvh_node));
+
+      nir_def *result =
+         nir_bvh8_intersect_ray_amd(b, 32, desc, nir_unpack_64_2x32(b, nir_load_deref(b, args->vars.bvh_base)),
+                                    nir_ishr_imm(b, args->cull_mask, 24), nir_load_deref(b, args->vars.tmax),
+                                    nir_load_deref(b, args->vars.origin), nir_load_deref(b, args->vars.dir), bvh_node);
+
+      nir_push_if(b, nir_test_mask(b, bvh_node, BITFIELD64_BIT(ffs(radv_bvh_node_box16) - 1)));
+      {
+         nir_push_if(b, nir_test_mask(b, bvh_node, BITFIELD64_BIT(ffs(radv_bvh_node_instance) - 1)));
+         {
+            if (args->vars.iteration_instance_count) {
+               nir_def *iteration_instance_count = nir_load_deref(b, args->vars.iteration_instance_count);
+               iteration_instance_count = nir_iadd_imm(b, iteration_instance_count, 1 << 16);
+               nir_store_deref(b, args->vars.iteration_instance_count, iteration_instance_count, 0x1);
+            }
+
+            nir_def *next_node = nir_iand_imm(b, nir_channel(b, result, 7), 0xff);
+            nir_push_if(b, nir_ieq_imm(b, next_node, 0xff));
+            nir_jump(b, nir_jump_continue);
+            nir_pop_if(b, NULL);
+
+            /* instance */
+            nir_def *instance_node_addr = build_node_to_addr(device, b, global_bvh_node, false);
+            nir_store_deref(b, args->vars.instance_addr, instance_node_addr, 1);
+
+            nir_store_deref(b, args->vars.sbt_offset_and_flags, nir_channel(b, result, 6), 1);
+
+            nir_store_deref(b, args->vars.origin, nir_channels(b, result, 0x7 << 10), 0x7);
+            nir_store_deref(b, args->vars.dir, nir_channels(b, result, 0x7 << 13), 0x7);
+
+            nir_store_deref(b, args->vars.top_stack, nir_load_deref(b, args->vars.stack), 1);
+            nir_store_deref(b, args->vars.bvh_base, nir_pack_64_2x32(b, nir_channels(b, result, 0x3 << 2)), 1);
+
+            /* Push the instance root node onto the stack */
+            nir_store_deref(b, args->vars.current_node, next_node, 0x1);
+            nir_store_deref(b, args->vars.instance_bottom_node, next_node, 1);
+            nir_store_deref(b, args->vars.instance_top_node, bvh_node, 1);
+         }
+         nir_push_else(b, NULL);
+         {
+            /* box */
+            nir_push_if(b, nir_ieq_imm(b, prev_node, RADV_BVH_INVALID_NODE));
+            {
+               nir_def *new_nodes[8];
+               for (unsigned i = 0; i < 8; ++i)
+                  new_nodes[i] = nir_channel(b, result, i);
+
+               for (unsigned i = 1; i < 8; ++i)
+                  nir_push_if(b, nir_ine_imm(b, new_nodes[i], RADV_BVH_INVALID_NODE));
+
+               for (unsigned i = 8; i-- > 1;) {
+                  nir_def *stack = nir_load_deref(b, args->vars.stack);
+                  nir_def *stack_ptr = nir_umod_imm(b, stack, args->stack_entries * args->stack_stride);
+                  args->stack_store_cb(b, stack_ptr, new_nodes[i], args);
+                  nir_store_deref(b, args->vars.stack, nir_iadd_imm(b, stack, args->stack_stride), 1);
+
+                  if (i == 1) {
+                     nir_def *new_watermark =
+                        nir_iadd_imm(b, nir_load_deref(b, args->vars.stack), -args->stack_entries * args->stack_stride);
+                     new_watermark = nir_imax(b, nir_load_deref(b, args->vars.stack_low_watermark), new_watermark);
+                     nir_store_deref(b, args->vars.stack_low_watermark, new_watermark, 0x1);
+                  }
+
+                  nir_pop_if(b, NULL);
+               }
+               nir_store_deref(b, args->vars.current_node, new_nodes[0], 0x1);
+            }
+            nir_push_else(b, NULL);
+            {
+               nir_def *next = nir_imm_int(b, RADV_BVH_INVALID_NODE);
+               for (unsigned i = 0; i < 7; ++i) {
+                  next = nir_bcsel(b, nir_ieq(b, prev_node, nir_channel(b, result, i)), nir_channel(b, result, i + 1),
+                                   next);
+               }
+               nir_store_deref(b, args->vars.current_node, next, 0x1);
+            }
+            nir_pop_if(b, NULL);
+         }
+         nir_pop_if(b, NULL);
+      }
+      nir_push_else(b, NULL);
+      {
+         nir_push_if(b, nir_test_mask(b, nir_channel(b, result, 1), 1u << 31));
+         {
+            nir_push_if(b, ray_flags.no_skip_aabbs);
+            insert_traversal_aabb_case_gfx12(device, b, args, &ray_flags, result, global_bvh_node);
+            nir_pop_if(b, NULL);
+         }
+         nir_push_else(b, NULL);
+         {
+            nir_push_if(b, ray_flags.no_skip_triangles);
+            insert_traversal_triangle_case_gfx12(device, b, args, &ray_flags, result, global_bvh_node);
+            nir_pop_if(b, NULL);
+         }
+         nir_pop_if(b, NULL);
+      }
+      nir_pop_if(b, NULL);
+
+      if (args->vars.iteration_instance_count) {
+         nir_def *iteration_instance_count = nir_load_deref(b, args->vars.iteration_instance_count);
+         iteration_instance_count = nir_iadd_imm(b, iteration_instance_count, 1);
+         nir_store_deref(b, args->vars.iteration_instance_count, iteration_instance_count, 0x1);
+      }
+   }
+   nir_pop_loop(b, NULL);
+
+   return nir_load_var(b, incomplete);
+}
diff --git a/src/amd/vulkan/nir/radv_nir_rt_common.h b/src/amd/vulkan/nir/radv_nir_rt_common.h
index 66021a9d0ba..aaef6ca72cd 100644
--- a/src/amd/vulkan/nir/radv_nir_rt_common.h
+++ b/src/amd/vulkan/nir/radv_nir_rt_common.h
@@ -14,15 +14,21 @@
 
 struct radv_device;
 
-nir_def *build_addr_to_node(nir_builder *b, nir_def *addr);
+nir_def *build_addr_to_node(struct radv_device *device, nir_builder *b, nir_def *addr, nir_def *flags);
 
 nir_def *nir_build_vec3_mat_mult(nir_builder *b, nir_def *vec, nir_def *matrix[], bool translation);
 
-void nir_build_wto_matrix_load(nir_builder *b, nir_def *instance_addr, nir_def **out);
-
 nir_def *radv_load_vertex_position(struct radv_device *device, nir_builder *b, nir_def *instance_addr,
                                    nir_def *geometry_id, nir_def *primitive_id, uint32_t index);
 
+void radv_load_wto_matrix(struct radv_device *device, nir_builder *b, nir_def *instance_addr, nir_def **out);
+
+void radv_load_otw_matrix(struct radv_device *device, nir_builder *b, nir_def *instance_addr, nir_def **out);
+
+nir_def *radv_load_custom_instance(struct radv_device *device, nir_builder *b, nir_def *instance_addr);
+
+nir_def *radv_load_instance_id(struct radv_device *device, nir_builder *b, nir_def *instance_addr);
+
 struct radv_ray_traversal_args;
 
 struct radv_ray_flags {
@@ -146,4 +152,7 @@ struct radv_ray_traversal_args {
 nir_def *radv_build_ray_traversal(struct radv_device *device, nir_builder *b,
                                   const struct radv_ray_traversal_args *args);
 
+nir_def *radv_build_ray_traversal_gfx12(struct radv_device *device, nir_builder *b,
+                                        const struct radv_ray_traversal_args *args);
+
 #endif /* RADV_NIR_RT_COMMON_H */
diff --git a/src/amd/vulkan/nir/radv_nir_rt_shader.c b/src/amd/vulkan/nir/radv_nir_rt_shader.c
index d066665e671..086726052ec 100644
--- a/src/amd/vulkan/nir/radv_nir_rt_shader.c
+++ b/src/amd/vulkan/nir/radv_nir_rt_shader.c
@@ -530,11 +530,7 @@ radv_lower_rt_instruction(nir_builder *b, nir_instr *instr, void *_data)
       break;
    }
    case nir_intrinsic_load_ray_instance_custom_index: {
-      nir_def *instance_node_addr = nir_load_var(b, vars->instance_addr);
-      nir_def *custom_instance_and_mask = nir_build_load_global(
-         b, 1, 32,
-         nir_iadd_imm(b, instance_node_addr, offsetof(struct radv_bvh_instance_node, custom_instance_and_mask)));
-      ret = nir_iand_imm(b, custom_instance_and_mask, 0xFFFFFF);
+      ret = radv_load_custom_instance(vars->device, b, nir_load_var(b, vars->instance_addr));
       break;
    }
    case nir_intrinsic_load_primitive_id: {
@@ -547,9 +543,7 @@ radv_lower_rt_instruction(nir_builder *b, nir_instr *instr, void *_data)
       break;
    }
    case nir_intrinsic_load_instance_id: {
-      nir_def *instance_node_addr = nir_load_var(b, vars->instance_addr);
-      ret = nir_build_load_global(
-         b, 1, 32, nir_iadd_imm(b, instance_node_addr, offsetof(struct radv_bvh_instance_node, instance_id)));
+      ret = radv_load_instance_id(vars->device, b, nir_load_var(b, vars->instance_addr));
       break;
    }
    case nir_intrinsic_load_ray_flags: {
@@ -564,7 +558,7 @@ radv_lower_rt_instruction(nir_builder *b, nir_instr *instr, void *_data)
       unsigned c = nir_intrinsic_column(intr);
       nir_def *instance_node_addr = nir_load_var(b, vars->instance_addr);
       nir_def *wto_matrix[3];
-      nir_build_wto_matrix_load(b, instance_node_addr, wto_matrix);
+      radv_load_wto_matrix(vars->device, b, instance_node_addr, wto_matrix);
 
       nir_def *vals[3];
       for (unsigned i = 0; i < 3; ++i)
@@ -575,26 +569,21 @@ radv_lower_rt_instruction(nir_builder *b, nir_instr *instr, void *_data)
    }
    case nir_intrinsic_load_ray_object_to_world: {
       unsigned c = nir_intrinsic_column(intr);
-      nir_def *instance_node_addr = nir_load_var(b, vars->instance_addr);
-      nir_def *rows[3];
-      for (unsigned r = 0; r < 3; ++r)
-         rows[r] = nir_build_load_global(
-            b, 4, 32,
-            nir_iadd_imm(b, instance_node_addr, offsetof(struct radv_bvh_instance_node, otw_matrix) + r * 16));
-      ret = nir_vec3(b, nir_channel(b, rows[0], c), nir_channel(b, rows[1], c), nir_channel(b, rows[2], c));
+      nir_def *otw_matrix[3];
+      radv_load_otw_matrix(vars->device, b, nir_load_var(b, vars->instance_addr), otw_matrix);
+      ret = nir_vec3(b, nir_channel(b, otw_matrix[0], c), nir_channel(b, otw_matrix[1], c),
+                     nir_channel(b, otw_matrix[2], c));
       break;
    }
    case nir_intrinsic_load_ray_object_origin: {
-      nir_def *instance_node_addr = nir_load_var(b, vars->instance_addr);
       nir_def *wto_matrix[3];
-      nir_build_wto_matrix_load(b, instance_node_addr, wto_matrix);
+      radv_load_wto_matrix(vars->device, b, nir_load_var(b, vars->instance_addr), wto_matrix);
       ret = nir_build_vec3_mat_mult(b, nir_load_var(b, vars->origin), wto_matrix, true);
       break;
    }
    case nir_intrinsic_load_ray_object_direction: {
-      nir_def *instance_node_addr = nir_load_var(b, vars->instance_addr);
       nir_def *wto_matrix[3];
-      nir_build_wto_matrix_load(b, instance_node_addr, wto_matrix);
+      radv_load_wto_matrix(vars->device, b, nir_load_var(b, vars->instance_addr), wto_matrix);
       ret = nir_build_vec3_mat_mult(b, nir_load_var(b, vars->direction), wto_matrix, false);
       break;
    }
@@ -1526,6 +1515,8 @@ radv_build_traversal(struct radv_device *device, struct radv_ray_tracing_pipelin
 
    struct rt_traversal_vars trav_vars = init_traversal_vars(b);
 
+   nir_def *cull_mask_and_flags = nir_load_var(b, vars->cull_mask_and_flags);
+
    nir_store_var(b, trav_vars.hit, nir_imm_false(b), 1);
 
    nir_def *accel_struct = nir_load_var(b, vars->accel_struct);
@@ -1533,7 +1524,7 @@ radv_build_traversal(struct radv_device *device, struct radv_ray_tracing_pipelin
       b, 1, 32, nir_iadd_imm(b, accel_struct, offsetof(struct radv_accel_struct_header, bvh_offset)),
       .access = ACCESS_NON_WRITEABLE);
    nir_def *root_bvh_base = nir_iadd(b, accel_struct, nir_u2u64(b, bvh_offset));
-   root_bvh_base = build_addr_to_node(b, root_bvh_base);
+   root_bvh_base = build_addr_to_node(device, b, root_bvh_base, cull_mask_and_flags);
 
    nir_store_var(b, trav_vars.bvh_base, root_bvh_base, 1);
 
@@ -1589,7 +1580,6 @@ radv_build_traversal(struct radv_device *device, struct radv_ray_tracing_pipelin
       .pipeline = pipeline,
    };
 
-   nir_def *cull_mask_and_flags = nir_load_var(b, vars->cull_mask_and_flags);
    struct radv_ray_traversal_args args = {
       .root_bvh_base = root_bvh_base,
       .flags = cull_mask_and_flags,
@@ -1617,7 +1607,10 @@ radv_build_traversal(struct radv_device *device, struct radv_ray_tracing_pipelin
 
    nir_def *original_tmax = nir_load_var(b, vars->tmax);
 
-   radv_build_ray_traversal(device, b, &args);
+   if (radv_use_bvh8(pdev))
+      radv_build_ray_traversal_gfx12(device, b, &args);
+   else
+      radv_build_ray_traversal(device, b, &args);
 
    if (vars->device->rra_trace.ray_history_addr)
       radv_build_end_trace_token(b, vars, original_tmax, nir_load_var(b, trav_vars.hit),
diff --git a/src/amd/vulkan/radv_acceleration_structure.c b/src/amd/vulkan/radv_acceleration_structure.c
index 1bc7b6b3173..5ba851a53cd 100644
--- a/src/amd/vulkan/radv_acceleration_structure.c
+++ b/src/amd/vulkan/radv_acceleration_structure.c
@@ -16,10 +16,18 @@
 #include "vk_acceleration_structure.h"
 #include "vk_common_entrypoints.h"
 
+static const uint32_t copy_blas_addrs_gfx12_spv[] = {
+#include "bvh/copy_blas_addrs_gfx12.spv.h"
+};
+
 static const uint32_t copy_spv[] = {
 #include "bvh/copy.spv.h"
 };
 
+static const uint32_t copy_gfx12_spv[] = {
+#include "bvh/copy_gfx12.spv.h"
+};
+
 static const uint32_t encode_spv[] = {
 #include "bvh/encode.spv.h"
 };
@@ -28,6 +36,10 @@ static const uint32_t encode_compact_spv[] = {
 #include "bvh/encode_compact.spv.h"
 };
 
+static const uint32_t encode_gfx12_spv[] = {
+#include "bvh/encode_gfx12.spv.h"
+};
+
 static const uint32_t header_spv[] = {
 #include "bvh/header.spv.h"
 };
@@ -36,6 +48,10 @@ static const uint32_t update_spv[] = {
 #include "bvh/update.spv.h"
 };
 
+static const uint32_t update_gfx12_spv[] = {
+#include "bvh/update_gfx12.spv.h"
+};
+
 static const uint32_t leaf_spv[] = {
 #include "bvh/radv_leaf.spv.h"
 };
@@ -47,6 +63,7 @@ static const uint32_t leaf_always_active_spv[] = {
 struct acceleration_structure_layout {
    uint32_t geometry_info_offset;
    uint32_t primitive_base_indices_offset;
+   uint32_t leaf_node_offsets_offset;
    uint32_t bvh_offset;
    uint32_t leaf_nodes_offset;
    uint32_t internal_nodes_offset;
@@ -68,26 +85,50 @@ radv_get_acceleration_structure_layout(struct radv_device *device, uint32_t leaf
                                        const VkAccelerationStructureBuildGeometryInfoKHR *build_info,
                                        struct acceleration_structure_layout *accel_struct)
 {
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
    uint32_t internal_count = MAX2(leaf_count, 2) - 1;
 
    VkGeometryTypeKHR geometry_type = vk_get_as_geometry_type(build_info);
 
    uint32_t bvh_leaf_size;
-   switch (geometry_type) {
-   case VK_GEOMETRY_TYPE_TRIANGLES_KHR:
-      bvh_leaf_size = sizeof(struct radv_bvh_triangle_node);
-      break;
-   case VK_GEOMETRY_TYPE_AABBS_KHR:
-      bvh_leaf_size = sizeof(struct radv_bvh_aabb_node);
-      break;
-   case VK_GEOMETRY_TYPE_INSTANCES_KHR:
-      bvh_leaf_size = sizeof(struct radv_bvh_instance_node);
-      break;
-   default:
-      unreachable("Unknown VkGeometryTypeKHR");
+   uint32_t bvh_node_size_gcd;
+   if (radv_use_bvh8(pdev)) {
+      switch (geometry_type) {
+      case VK_GEOMETRY_TYPE_TRIANGLES_KHR:
+         bvh_leaf_size = sizeof(struct radv_gfx12_primitive_node);
+         break;
+      case VK_GEOMETRY_TYPE_AABBS_KHR:
+         bvh_leaf_size = sizeof(struct radv_gfx12_primitive_node);
+         break;
+      case VK_GEOMETRY_TYPE_INSTANCES_KHR:
+         bvh_leaf_size = sizeof(struct radv_gfx12_instance_node) + sizeof(struct radv_gfx12_instance_node_user_data);
+         break;
+      default:
+         unreachable("Unknown VkGeometryTypeKHR");
+      }
+      bvh_node_size_gcd = RADV_GFX12_BVH_NODE_SIZE;
+   } else {
+      switch (geometry_type) {
+      case VK_GEOMETRY_TYPE_TRIANGLES_KHR:
+         bvh_leaf_size = sizeof(struct radv_bvh_triangle_node);
+         break;
+      case VK_GEOMETRY_TYPE_AABBS_KHR:
+         bvh_leaf_size = sizeof(struct radv_bvh_aabb_node);
+         break;
+      case VK_GEOMETRY_TYPE_INSTANCES_KHR:
+         bvh_leaf_size = sizeof(struct radv_bvh_instance_node);
+         break;
+      default:
+         unreachable("Unknown VkGeometryTypeKHR");
+      }
+      bvh_node_size_gcd = 64;
    }
 
-   uint64_t bvh_size = bvh_leaf_size * leaf_count + sizeof(struct radv_bvh_box32_node) * internal_count;
+   uint32_t internal_node_size =
+      radv_use_bvh8(pdev) ? sizeof(struct radv_gfx12_box_node) : sizeof(struct radv_bvh_box32_node);
+
+   uint64_t bvh_size = bvh_leaf_size * leaf_count + internal_node_size * internal_count;
    uint32_t offset = 0;
    offset += sizeof(struct radv_accel_struct_header);
 
@@ -101,23 +142,30 @@ radv_get_acceleration_structure_layout(struct radv_device *device, uint32_t leaf
       offset += sizeof(uint32_t) * build_info->geometryCount;
    }
 
+   /* On GFX12, we need additional space for leaf node offsets since they do not have the same
+    * order as the application provided data.
+    */
+   accel_struct->leaf_node_offsets_offset = offset;
+   if (radv_use_bvh8(pdev))
+      offset += leaf_count * 4;
+
    /* Parent links, which have to go directly before bvh_offset as we index them using negative
     * offsets from there. */
-   offset += bvh_size / 64 * 4;
+   offset += bvh_size / bvh_node_size_gcd * 4;
 
    /* The BVH and hence bvh_offset needs 64 byte alignment for RT nodes. */
    offset = ALIGN(offset, 64);
    accel_struct->bvh_offset = offset;
 
    /* root node */
-   offset += sizeof(struct radv_bvh_box32_node);
+   offset += internal_node_size;
 
    accel_struct->leaf_nodes_offset = offset;
    offset += bvh_leaf_size * leaf_count;
 
    accel_struct->internal_nodes_offset = offset;
    /* Factor out the root node. */
-   offset += sizeof(struct radv_bvh_box32_node) * (internal_count - 1);
+   offset += internal_node_size * (internal_count - 1);
 
    accel_struct->size = offset;
 }
@@ -134,7 +182,7 @@ radv_get_scratch_layout(struct radv_device *device, uint32_t leaf_count, struct
 
    uint32_t update_offset = 0;
 
-   update_offset += sizeof(vk_aabb) * leaf_count;
+   update_offset += sizeof(vk_aabb) * (leaf_count + internal_count);
    scratch->internal_ready_count_offset = update_offset;
 
    update_offset += sizeof(uint32_t) * internal_count;
@@ -154,6 +202,10 @@ radv_GetAccelerationStructureBuildSizesKHR(VkDevice _device, VkAccelerationStruc
    STATIC_ASSERT(sizeof(struct radv_bvh_instance_node) == 128);
    STATIC_ASSERT(sizeof(struct radv_bvh_box16_node) == 64);
    STATIC_ASSERT(sizeof(struct radv_bvh_box32_node) == 128);
+   STATIC_ASSERT(sizeof(struct radv_gfx12_box_node) == RADV_GFX12_BVH_NODE_SIZE);
+   STATIC_ASSERT(sizeof(struct radv_gfx12_primitive_node) == RADV_GFX12_BVH_NODE_SIZE);
+   STATIC_ASSERT(sizeof(struct radv_gfx12_instance_node) == RADV_GFX12_BVH_NODE_SIZE);
+   STATIC_ASSERT(sizeof(struct radv_gfx12_instance_node_user_data) == RADV_GFX12_BVH_NODE_SIZE);
 
    if (radv_device_init_accel_struct_build_state(device) != VK_SUCCESS)
       return;
@@ -170,6 +222,7 @@ radv_device_finish_accel_struct_build_state(struct radv_device *device)
    struct vk_device_dispatch_table *dispatch = &device->vk.dispatch_table;
 
    dispatch->DestroyPipeline(_device, state->accel_struct_build.copy_pipeline, &state->alloc);
+   dispatch->DestroyPipeline(_device, state->accel_struct_build.copy_blas_addrs_gfx12_pipeline, &state->alloc);
    dispatch->DestroyPipeline(_device, state->accel_struct_build.encode_pipeline, &state->alloc);
    dispatch->DestroyPipeline(_device, state->accel_struct_build.encode_compact_pipeline, &state->alloc);
    dispatch->DestroyPipeline(_device, state->accel_struct_build.header_pipeline, &state->alloc);
@@ -257,7 +310,11 @@ radv_device_init_null_accel_struct(struct radv_device *device)
    VkDevice _device = radv_device_to_handle(device);
 
    uint32_t bvh_offset = ALIGN(sizeof(struct radv_accel_struct_header), 64);
-   uint32_t size = bvh_offset + sizeof(struct radv_bvh_box32_node);
+   uint32_t size = bvh_offset;
+   if (radv_use_bvh8(pdev))
+      size += sizeof(struct radv_gfx12_box_node);
+   else
+      size += sizeof(struct radv_bvh_box32_node);
 
    VkResult result;
 
@@ -321,28 +378,44 @@ radv_device_init_null_accel_struct(struct radv_device *device)
    };
    memcpy(data, &header, sizeof(struct radv_accel_struct_header));
 
-   struct radv_bvh_box32_node root = {
-      .children =
-         {
-            RADV_BVH_INVALID_NODE,
-            RADV_BVH_INVALID_NODE,
-            RADV_BVH_INVALID_NODE,
-            RADV_BVH_INVALID_NODE,
-         },
-   };
+   if (radv_use_bvh8(pdev)) {
+      struct radv_gfx12_box_node root = {
+         .obb_matrix_index = 0x7f,
+      };
 
-   for (uint32_t child = 0; child < 4; child++) {
-      root.coords[child] = (vk_aabb){
-         .min.x = NAN,
-         .min.y = NAN,
-         .min.z = NAN,
-         .max.x = NAN,
-         .max.y = NAN,
-         .max.z = NAN,
+      for (uint32_t child = 0; child < 8; child++) {
+         root.children[child] = (struct radv_gfx12_box_child){
+            .dword0 = 0xffffffff,
+            .dword1 = 0xfff,
+            .dword2 = 0,
+         };
+      }
+
+      memcpy((uint8_t *)data + bvh_offset, &root, sizeof(struct radv_gfx12_box_node));
+   } else {
+      struct radv_bvh_box32_node root = {
+         .children =
+            {
+               RADV_BVH_INVALID_NODE,
+               RADV_BVH_INVALID_NODE,
+               RADV_BVH_INVALID_NODE,
+               RADV_BVH_INVALID_NODE,
+            },
       };
-   }
 
-   memcpy((uint8_t *)data + bvh_offset, &root, sizeof(struct radv_bvh_box32_node));
+      for (uint32_t child = 0; child < 4; child++) {
+         root.coords[child] = (vk_aabb){
+            .min.x = NAN,
+            .min.y = NAN,
+            .min.z = NAN,
+            .max.x = NAN,
+            .max.y = NAN,
+            .max.z = NAN,
+         };
+      }
+
+      memcpy((uint8_t *)data + bvh_offset, &root, sizeof(struct radv_bvh_box32_node));
+   }
 
    vk_common_UnmapMemory(_device, memory);
 
@@ -385,8 +458,15 @@ radv_get_update_scratch_size(struct vk_device *vk_device, uint32_t leaf_count)
 }
 
 static uint32_t
-radv_get_encode_key(VkAccelerationStructureTypeKHR type, VkBuildAccelerationStructureFlagBitsKHR flags)
+radv_get_encode_key(struct vk_device *vk_device, VkAccelerationStructureTypeKHR type,
+                    VkBuildAccelerationStructureFlagBitsKHR flags)
 {
+   struct radv_device *device = container_of(vk_device, struct radv_device, vk);
+   struct radv_physical_device *pdev = radv_device_physical(device);
+
+   if (radv_use_bvh8(pdev))
+      return RADV_ENCODE_KEY_COMPACT;
+
    if (flags & VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_COMPACTION_BIT_KHR)
       return RADV_ENCODE_KEY_COMPACT;
 
@@ -400,9 +480,10 @@ radv_encode_bind_pipeline(VkCommandBuffer commandBuffer, uint32_t key)
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
 
    bool compact = key & RADV_ENCODE_KEY_COMPACT;
-   device->vk.dispatch_table.CmdBindPipeline(commandBuffer, VK_PIPELINE_BIND_POINT_COMPUTE,
-                                             compact ? device->meta_state.accel_struct_build.encode_compact_pipeline
-                                                     : device->meta_state.accel_struct_build.encode_pipeline);
+   VkPipeline pipeline = compact ? device->meta_state.accel_struct_build.encode_compact_pipeline
+                                 : device->meta_state.accel_struct_build.encode_pipeline;
+
+   device->vk.dispatch_table.CmdBindPipeline(commandBuffer, VK_PIPELINE_BIND_POINT_COMPUTE, pipeline);
 
    return VK_SUCCESS;
 }
@@ -421,7 +502,7 @@ radv_encode_as(VkCommandBuffer commandBuffer, const VkAccelerationStructureBuild
 
    if (key & RADV_ENCODE_KEY_COMPACT) {
       uint32_t dst_offset = layout.internal_nodes_offset - layout.bvh_offset;
-      radv_update_buffer_cp(cmd_buffer, intermediate_header_addr + offsetof(struct vk_ir_header, dst_node_offset),
+      radv_update_memory_cp(cmd_buffer, intermediate_header_addr + offsetof(struct vk_ir_header, dst_node_offset),
                             &dst_offset, sizeof(uint32_t));
       if (radv_device_physical(device)->info.cp_sdma_ge_use_system_memory_scope)
          cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_INV_L2;
@@ -447,6 +528,57 @@ radv_encode_as(VkCommandBuffer commandBuffer, const VkAccelerationStructureBuild
    radv_compute_dispatch(cmd_buffer, &dispatch);
 }
 
+static void
+radv_encode_as_gfx12(VkCommandBuffer commandBuffer, const VkAccelerationStructureBuildGeometryInfoKHR *build_info,
+                     const VkAccelerationStructureBuildRangeInfoKHR *build_range_infos,
+                     VkDeviceAddress intermediate_as_addr, VkDeviceAddress intermediate_header_addr,
+                     uint32_t leaf_count, uint32_t key, struct vk_acceleration_structure *dst)
+{
+   VK_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, commandBuffer);
+   struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
+
+   struct acceleration_structure_layout layout;
+   radv_get_acceleration_structure_layout(device, leaf_count, build_info, &layout);
+
+   struct vk_ir_header header = {
+      .sync_data =
+         {
+            .current_phase_end_counter = TASK_INDEX_INVALID,
+            /* Will be updated by the first PLOC shader invocation */
+            .task_counts = {TASK_INDEX_INVALID, TASK_INDEX_INVALID},
+         },
+      .dst_node_offset = layout.internal_nodes_offset - layout.bvh_offset,
+      .dst_leaf_node_offset = layout.leaf_nodes_offset - layout.bvh_offset,
+   };
+
+   const uint8_t *update_data = ((const uint8_t *)&header + offsetof(struct vk_ir_header, sync_data));
+   radv_update_memory_cp(cmd_buffer, intermediate_header_addr + offsetof(struct vk_ir_header, sync_data), update_data,
+                         sizeof(struct vk_ir_header) - offsetof(struct vk_ir_header, sync_data));
+   if (radv_device_physical(device)->info.cp_sdma_ge_use_system_memory_scope)
+      cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_INV_L2;
+
+   const struct encode_gfx12_args args = {
+      .intermediate_bvh = intermediate_as_addr,
+      .output_base = vk_acceleration_structure_get_va(dst),
+      .header = intermediate_header_addr,
+      .output_bvh_offset = layout.bvh_offset,
+      .leaf_node_offsets_offset = layout.leaf_node_offsets_offset,
+      .leaf_node_count = leaf_count,
+      .geometry_type = vk_get_as_geometry_type(build_info),
+   };
+   vk_common_CmdPushConstants(commandBuffer, device->meta_state.accel_struct_build.encode_p_layout,
+                              VK_SHADER_STAGE_COMPUTE_BIT, 0, sizeof(args), &args);
+
+   uint32_t internal_count = MAX2(leaf_count, 2) - 1;
+
+   struct radv_dispatch_info dispatch = {
+      .ordered = true,
+      .blocks = {DIV_ROUND_UP(internal_count * 8, 64), 1, 1},
+   };
+
+   radv_compute_dispatch(cmd_buffer, &dispatch);
+}
+
 static VkResult
 radv_init_header_bind_pipeline(VkCommandBuffer commandBuffer, uint32_t key)
 {
@@ -486,7 +618,7 @@ radv_init_header(VkCommandBuffer commandBuffer, const VkAccelerationStructureBui
    radv_get_acceleration_structure_layout(device, leaf_count, build_info, &layout);
 
    if (key & RADV_ENCODE_KEY_COMPACT) {
-      base = offsetof(struct radv_accel_struct_header, geometry_count);
+      base = offsetof(struct radv_accel_struct_header, geometry_type);
 
       struct header_args args = {
          .src = intermediate_header_addr,
@@ -505,6 +637,7 @@ radv_init_header(VkCommandBuffer commandBuffer, const VkAccelerationStructureBui
 
    header.instance_offset = layout.bvh_offset + sizeof(struct radv_bvh_box32_node);
    header.instance_count = instance_count;
+   header.leaf_node_offsets_offset = layout.leaf_node_offsets_offset;
    header.compacted_size = layout.size;
 
    header.copy_dispatch_size[0] = DIV_ROUND_UP(header.compacted_size, 16 * 64);
@@ -519,10 +652,11 @@ radv_init_header(VkCommandBuffer commandBuffer, const VkAccelerationStructureBui
                  sizeof(uint64_t) * header.instance_count;
 
    header.build_flags = build_info->flags;
+   header.geometry_type = vk_get_as_geometry_type(build_info);
    header.geometry_count = build_info->geometryCount;
    header.primitive_base_indices_offset = layout.primitive_base_indices_offset;
 
-   radv_update_buffer_cp(cmd_buffer, vk_acceleration_structure_get_va(dst) + base, (const char *)&header + base,
+   radv_update_memory_cp(cmd_buffer, vk_acceleration_structure_get_va(dst) + base, (const char *)&header + base,
                          sizeof(header) - base);
 
    if (device->rra_trace.accel_structs) {
@@ -540,9 +674,8 @@ radv_init_header(VkCommandBuffer commandBuffer, const VkAccelerationStructureBui
          geometry_infos[i].primitive_count = build_range_infos[i].primitiveCount;
       }
 
-      radv_CmdUpdateBuffer(commandBuffer, vk_buffer_to_handle(dst->buffer),
-                           dst->offset + layout.geometry_info_offset, geometry_infos_size,
-                           geometry_infos);
+      radv_CmdUpdateBuffer(commandBuffer, vk_buffer_to_handle(dst->buffer), dst->offset + layout.geometry_info_offset,
+                           geometry_infos_size, geometry_infos);
 
       free(geometry_infos);
    }
@@ -580,8 +713,8 @@ radv_init_update_scratch(VkCommandBuffer commandBuffer, VkDeviceAddress scratch,
    radv_get_scratch_layout(device, leaf_count, &layout);
 
    /* Prepare ready counts for internal nodes */
-   radv_fill_buffer(cmd_buffer, NULL, NULL, scratch + layout.internal_ready_count_offset,
-                    layout.update_size - layout.internal_ready_count_offset, 0x0);
+   radv_fill_memory(cmd_buffer, scratch + layout.internal_ready_count_offset,
+                    layout.update_size - layout.internal_ready_count_offset, 0x0, RADV_COPY_FLAGS_DEVICE_LOCAL);
 }
 
 static void
@@ -627,7 +760,8 @@ radv_update_as(VkCommandBuffer commandBuffer, const VkAccelerationStructureBuild
       const uint64_t src_va = vk_acceleration_structure_get_va(src);
       const uint64_t dst_va = vk_acceleration_structure_get_va(dst);
 
-      radv_copy_memory(cmd_buffer, src_va, dst_va, layout.bvh_offset);
+      radv_copy_memory(cmd_buffer, src_va, dst_va, layout.bvh_offset, RADV_COPY_FLAGS_DEVICE_LOCAL,
+                       RADV_COPY_FLAGS_DEVICE_LOCAL);
    }
 
    struct scratch_layout layout;
@@ -672,31 +806,11 @@ static const struct radix_sort_vk_target_config radix_sort_config = {
    .scatter.block_rows = 14,
 };
 
-static const struct vk_acceleration_structure_build_ops build_ops = {
-   .begin_debug_marker = vk_accel_struct_cmd_begin_debug_marker,
-   .end_debug_marker = vk_accel_struct_cmd_end_debug_marker,
-   .get_as_size = radv_get_as_size,
-   .get_update_scratch_size = radv_get_update_scratch_size,
-   .get_encode_key[0] = radv_get_encode_key,
-   .get_encode_key[1] = radv_get_encode_key,
-   .encode_bind_pipeline[0] = radv_encode_bind_pipeline,
-   .encode_bind_pipeline[1] = radv_init_header_bind_pipeline,
-   .encode_as[0] = radv_encode_as,
-   .encode_as[1] = radv_init_header,
-   .init_update_scratch = radv_init_update_scratch,
-   .update_bind_pipeline[0] = radv_update_bind_pipeline,
-   .update_as[0] = radv_update_as,
-   .leaf_spirv_override = leaf_spv,
-   .leaf_spirv_override_size = sizeof(leaf_spv),
-   .leaf_always_active_spirv_override = leaf_always_active_spv,
-   .leaf_always_active_spirv_override_size = sizeof(leaf_always_active_spv),
-};
-
 static void
 radv_write_buffer_cp(VkCommandBuffer commandBuffer, VkDeviceAddress addr, void *data, uint32_t size)
 {
    VK_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, commandBuffer);
-   radv_update_buffer_cp(cmd_buffer, addr, data, size);
+   radv_update_memory_cp(cmd_buffer, addr, data, size);
 }
 
 static void
@@ -721,30 +835,55 @@ static void
 radv_cmd_fill_buffer_addr(VkCommandBuffer commandBuffer, VkDeviceAddress addr, VkDeviceSize size, uint32_t data)
 {
    VK_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, commandBuffer);
-   radv_fill_buffer(cmd_buffer, NULL, NULL, addr, size, data);
+   radv_fill_memory(cmd_buffer, addr, size, data, RADV_COPY_FLAGS_DEVICE_LOCAL);
 }
 
 VkResult
 radv_device_init_accel_struct_build_state(struct radv_device *device)
 {
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
    VkResult result = VK_SUCCESS;
    mtx_lock(&device->meta_state.mtx);
 
    if (device->meta_state.accel_struct_build.radix_sort)
       goto exit;
 
-   result = create_build_pipeline_spv(device, encode_spv, sizeof(encode_spv), sizeof(struct encode_args),
-                                      &device->meta_state.accel_struct_build.encode_pipeline,
-                                      &device->meta_state.accel_struct_build.encode_p_layout);
-   if (result != VK_SUCCESS)
-      goto exit;
+   if (radv_use_bvh8(pdev)) {
+      result =
+         create_build_pipeline_spv(device, encode_gfx12_spv, sizeof(encode_gfx12_spv), sizeof(struct encode_gfx12_args),
+                                   &device->meta_state.accel_struct_build.encode_compact_pipeline,
+                                   &device->meta_state.accel_struct_build.encode_p_layout);
+      if (result != VK_SUCCESS)
+         goto exit;
 
-   result =
-      create_build_pipeline_spv(device, encode_compact_spv, sizeof(encode_compact_spv), sizeof(struct encode_args),
-                                &device->meta_state.accel_struct_build.encode_compact_pipeline,
-                                &device->meta_state.accel_struct_build.encode_p_layout);
-   if (result != VK_SUCCESS)
-      goto exit;
+      result = create_build_pipeline_spv(device, update_gfx12_spv, sizeof(update_gfx12_spv), sizeof(struct update_args),
+                                         &device->meta_state.accel_struct_build.update_pipeline,
+                                         &device->meta_state.accel_struct_build.update_p_layout);
+
+      if (result != VK_SUCCESS)
+         goto exit;
+   } else {
+      result = create_build_pipeline_spv(device, encode_spv, sizeof(encode_spv), sizeof(struct encode_args),
+                                         &device->meta_state.accel_struct_build.encode_pipeline,
+                                         &device->meta_state.accel_struct_build.encode_p_layout);
+      if (result != VK_SUCCESS)
+         goto exit;
+
+      result =
+         create_build_pipeline_spv(device, encode_compact_spv, sizeof(encode_compact_spv), sizeof(struct encode_args),
+                                   &device->meta_state.accel_struct_build.encode_compact_pipeline,
+                                   &device->meta_state.accel_struct_build.encode_p_layout);
+      if (result != VK_SUCCESS)
+         goto exit;
+
+      result = create_build_pipeline_spv(device, update_spv, sizeof(update_spv), sizeof(struct update_args),
+                                         &device->meta_state.accel_struct_build.update_pipeline,
+                                         &device->meta_state.accel_struct_build.update_p_layout);
+
+      if (result != VK_SUCCESS)
+         goto exit;
+   }
 
    result = create_build_pipeline_spv(device, header_spv, sizeof(header_spv), sizeof(struct header_args),
                                       &device->meta_state.accel_struct_build.header_pipeline,
@@ -752,16 +891,36 @@ radv_device_init_accel_struct_build_state(struct radv_device *device)
    if (result != VK_SUCCESS)
       goto exit;
 
-   result = create_build_pipeline_spv(device, update_spv, sizeof(update_spv), sizeof(struct update_args),
-                                      &device->meta_state.accel_struct_build.update_pipeline,
-                                      &device->meta_state.accel_struct_build.update_p_layout);
-   if (result != VK_SUCCESS)
-      goto exit;
-
    device->meta_state.accel_struct_build.radix_sort = vk_create_radix_sort_u64(
       radv_device_to_handle(device), &device->meta_state.alloc, device->meta_state.cache, radix_sort_config);
 
-   device->vk.as_build_ops = &build_ops;
+   device->meta_state.accel_struct_build.build_ops = (struct vk_acceleration_structure_build_ops){
+      .begin_debug_marker = vk_accel_struct_cmd_begin_debug_marker,
+      .end_debug_marker = vk_accel_struct_cmd_end_debug_marker,
+      .get_as_size = radv_get_as_size,
+      .get_update_scratch_size = radv_get_update_scratch_size,
+      .get_encode_key[0] = radv_get_encode_key,
+      .get_encode_key[1] = radv_get_encode_key,
+      .encode_bind_pipeline[0] = radv_encode_bind_pipeline,
+      .encode_bind_pipeline[1] = radv_init_header_bind_pipeline,
+      .encode_as[1] = radv_init_header,
+      .init_update_scratch = radv_init_update_scratch,
+      .update_bind_pipeline[0] = radv_update_bind_pipeline,
+      .update_as[0] = radv_update_as,
+   };
+
+   if (radv_use_bvh8(pdev)) {
+      device->meta_state.accel_struct_build.build_ops.encode_as[0] = radv_encode_as_gfx12;
+   } else {
+      device->meta_state.accel_struct_build.build_ops.encode_as[0] = radv_encode_as;
+      device->meta_state.accel_struct_build.build_ops.leaf_spirv_override = leaf_spv;
+      device->meta_state.accel_struct_build.build_ops.leaf_spirv_override_size = sizeof(leaf_spv);
+      device->meta_state.accel_struct_build.build_ops.leaf_always_active_spirv_override = leaf_always_active_spv;
+      device->meta_state.accel_struct_build.build_ops.leaf_always_active_spirv_override_size =
+         sizeof(leaf_always_active_spv);
+   }
+
+   device->vk.as_build_ops = &device->meta_state.accel_struct_build.build_ops;
    device->vk.write_buffer_cp = radv_write_buffer_cp;
    device->vk.flush_buffer_write_cp = radv_flush_buffer_write_cp;
    device->vk.cmd_dispatch_unaligned = radv_cmd_dispatch_unaligned;
@@ -781,12 +940,30 @@ exit:
 static VkResult
 radv_device_init_accel_struct_copy_state(struct radv_device *device)
 {
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+   VkResult result;
+
    mtx_lock(&device->meta_state.mtx);
 
-   VkResult result = create_build_pipeline_spv(device, copy_spv, sizeof(copy_spv), sizeof(struct copy_args),
-                                               &device->meta_state.accel_struct_build.copy_pipeline,
-                                               &device->meta_state.accel_struct_build.copy_p_layout);
+   if (radv_use_bvh8(pdev)) {
+      result = create_build_pipeline_spv(device, copy_gfx12_spv, sizeof(copy_gfx12_spv), sizeof(struct copy_args),
+                                         &device->meta_state.accel_struct_build.copy_pipeline,
+                                         &device->meta_state.accel_struct_build.copy_p_layout);
+
+      if (result != VK_SUCCESS)
+         goto exit;
+
+      result = create_build_pipeline_spv(device, copy_blas_addrs_gfx12_spv, sizeof(copy_blas_addrs_gfx12_spv),
+                                         sizeof(struct copy_args),
+                                         &device->meta_state.accel_struct_build.copy_blas_addrs_gfx12_pipeline,
+                                         &device->meta_state.accel_struct_build.copy_p_layout);
+   } else {
+      result = create_build_pipeline_spv(device, copy_spv, sizeof(copy_spv), sizeof(struct copy_args),
+                                         &device->meta_state.accel_struct_build.copy_pipeline,
+                                         &device->meta_state.accel_struct_build.copy_p_layout);
+   }
 
+exit:
    mtx_unlock(&device->meta_state.mtx);
    return result;
 }
@@ -877,6 +1054,7 @@ radv_CmdCopyMemoryToAccelerationStructureKHR(VkCommandBuffer commandBuffer,
    VK_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, commandBuffer);
    VK_FROM_HANDLE(vk_acceleration_structure, dst, pInfo->dst);
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
+   const struct radv_physical_device *pdev = radv_device_physical(device);
    struct radv_meta_saved_state saved_state;
 
    VkResult result = radv_device_init_accel_struct_copy_state(device);
@@ -902,6 +1080,21 @@ radv_CmdCopyMemoryToAccelerationStructureKHR(VkCommandBuffer commandBuffer,
                               sizeof(consts), &consts);
 
    vk_common_CmdDispatch(commandBuffer, 512, 1, 1);
+
+   if (radv_use_bvh8(pdev)) {
+      /* Wait for the main copy dispatch to finish. */
+      cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_CS_PARTIAL_FLUSH |
+                                      radv_src_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
+                                                            VK_ACCESS_2_SHADER_WRITE_BIT, 0, NULL, NULL) |
+                                      radv_dst_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
+                                                            VK_ACCESS_2_SHADER_READ_BIT, 0, NULL, NULL);
+
+      radv_CmdBindPipeline(radv_cmd_buffer_to_handle(cmd_buffer), VK_PIPELINE_BIND_POINT_COMPUTE,
+                           device->meta_state.accel_struct_build.copy_blas_addrs_gfx12_pipeline);
+
+      vk_common_CmdDispatch(commandBuffer, 256, 1, 1);
+   }
+
    radv_meta_restore(&saved_state, cmd_buffer);
 }
 
@@ -943,6 +1136,20 @@ radv_CmdCopyAccelerationStructureToMemoryKHR(VkCommandBuffer commandBuffer,
    radv_CmdDispatchIndirect(commandBuffer, vk_buffer_to_handle(src->buffer),
                             src->offset + offsetof(struct radv_accel_struct_header, copy_dispatch_size));
 
+   if (radv_use_bvh8(pdev)) {
+      /* Wait for the main copy dispatch to finish. */
+      cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_CS_PARTIAL_FLUSH |
+                                      radv_src_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
+                                                            VK_ACCESS_2_SHADER_WRITE_BIT, 0, NULL, NULL) |
+                                      radv_dst_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
+                                                            VK_ACCESS_2_SHADER_READ_BIT, 0, NULL, NULL);
+
+      radv_CmdBindPipeline(radv_cmd_buffer_to_handle(cmd_buffer), VK_PIPELINE_BIND_POINT_COMPUTE,
+                           device->meta_state.accel_struct_build.copy_blas_addrs_gfx12_pipeline);
+
+      vk_common_CmdDispatch(commandBuffer, 256, 1, 1);
+   }
+
    radv_meta_restore(&saved_state, cmd_buffer);
 
    /* Set the header of the serialized data. */
@@ -950,5 +1157,5 @@ radv_CmdCopyAccelerationStructureToMemoryKHR(VkCommandBuffer commandBuffer,
    memcpy(header_data, pdev->driver_uuid, VK_UUID_SIZE);
    memcpy(header_data + VK_UUID_SIZE, pdev->cache_uuid, VK_UUID_SIZE);
 
-   radv_update_buffer_cp(cmd_buffer, pInfo->dst.deviceAddress, header_data, sizeof(header_data));
+   radv_update_memory_cp(cmd_buffer, pInfo->dst.deviceAddress, header_data, sizeof(header_data));
 }
diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index 08528a64b1b..087f6eba0e8 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -1962,26 +1962,22 @@ radv_emit_ps_epilog_state(struct radv_cmd_buffer *cmd_buffer, struct radv_shader
    struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
    const struct radv_physical_device *pdev = radv_device_physical(device);
    struct radv_shader *ps_shader = cmd_buffer->state.shaders[MESA_SHADER_FRAGMENT];
+   uint32_t pgm_rsrc1 = 0;
 
    if (cmd_buffer->state.emitted_ps_epilog == ps_epilog)
       return;
 
    assert(ps_shader->config.num_shared_vgprs == 0);
    if (G_00B848_VGPRS(ps_epilog->rsrc1) > G_00B848_VGPRS(ps_shader->config.rsrc1)) {
-      uint32_t rsrc1 = ps_shader->config.rsrc1;
-      rsrc1 = (rsrc1 & C_00B848_VGPRS) | (ps_epilog->rsrc1 & ~C_00B848_VGPRS);
-
-      radeon_begin(cmd_buffer->cs);
-      radeon_set_sh_reg(ps_shader->info.regs.pgm_rsrc1, rsrc1);
-      radeon_end();
+      pgm_rsrc1 = (ps_shader->config.rsrc1 & C_00B848_VGPRS) | (ps_epilog->rsrc1 & ~C_00B848_VGPRS);
    }
 
    radv_cs_add_buffer(device->ws, cmd_buffer->cs, ps_epilog->bo);
 
-   assert((ps_epilog->va >> 32) == pdev->info.address32_hi);
-
    const uint32_t epilog_pc_offset = radv_get_user_sgpr_loc(ps_shader, AC_UD_EPILOG_PC);
    radeon_begin(cmd_buffer->cs);
+   if (pgm_rsrc1)
+      radeon_set_sh_reg(ps_shader->info.regs.pgm_rsrc1, pgm_rsrc1);
    radeon_emit_32bit_pointer(epilog_pc_offset, ps_epilog->va, &pdev->info);
    radeon_end();
 
@@ -2260,39 +2256,31 @@ radv_emit_vertex_shader(struct radv_cmd_buffer *cmd_buffer)
       assert(vs->info.next_stage == MESA_SHADER_TESS_CTRL || vs->info.next_stage == MESA_SHADER_GEOMETRY);
 
       const struct radv_shader *next_stage = cmd_buffer->state.shaders[vs->info.next_stage];
+      uint32_t rsrc1, rsrc2;
 
       if (!vs->info.vs.has_prolog) {
-         uint32_t rsrc1, rsrc2;
+         if (vs->info.next_stage == MESA_SHADER_TESS_CTRL) {
+            radv_shader_combine_cfg_vs_tcs(vs, next_stage, &rsrc1, NULL);
+         } else {
+            radv_shader_combine_cfg_vs_gs(device, vs, next_stage, &rsrc1, &rsrc2);
+         }
+      }
 
-         radeon_begin(cmd_buffer->cs);
+      const uint32_t next_stage_pc_offset = radv_get_user_sgpr_loc(vs, AC_UD_NEXT_STAGE_PC);
 
-         radeon_set_sh_reg(vs->info.regs.pgm_lo, vs->va >> 8);
+      radeon_begin(cmd_buffer->cs);
+      radeon_emit_32bit_pointer(next_stage_pc_offset, next_stage->va, &pdev->info);
 
+      if (!vs->info.vs.has_prolog) {
+         radeon_set_sh_reg(vs->info.regs.pgm_lo, vs->va >> 8);
          if (vs->info.next_stage == MESA_SHADER_TESS_CTRL) {
-            radv_shader_combine_cfg_vs_tcs(vs, next_stage, &rsrc1, NULL);
-
             radeon_set_sh_reg(vs->info.regs.pgm_rsrc1, rsrc1);
          } else {
-            radv_shader_combine_cfg_vs_gs(vs, next_stage, &rsrc1, &rsrc2);
-
-            unsigned lds_size;
-            if (next_stage->info.is_ngg) {
-               lds_size = DIV_ROUND_UP(next_stage->info.ngg_info.lds_size, pdev->info.lds_encode_granularity);
-            } else {
-               lds_size = next_stage->info.gs_ring_info.lds_size;
-            }
-
             radeon_set_sh_reg_seq(vs->info.regs.pgm_rsrc1, 2);
             radeon_emit(rsrc1);
-            radeon_emit(rsrc2 | S_00B22C_LDS_SIZE(lds_size));
+            radeon_emit(rsrc2);
          }
-
-         radeon_end();
       }
-
-      const uint32_t next_stage_pc_offset = radv_get_user_sgpr_loc(vs, AC_UD_NEXT_STAGE_PC);
-      radeon_begin(cmd_buffer->cs);
-      radeon_emit_32bit_pointer(next_stage_pc_offset, next_stage->va, &pdev->info);
       radeon_end();
       return;
    }
@@ -2335,21 +2323,14 @@ radv_emit_tess_eval_shader(struct radv_cmd_buffer *cmd_buffer)
       const struct radv_shader *gs = cmd_buffer->state.shaders[MESA_SHADER_GEOMETRY];
       uint32_t rsrc1, rsrc2;
 
-      radv_shader_combine_cfg_tes_gs(tes, gs, &rsrc1, &rsrc2);
-
-      unsigned lds_size;
-      if (gs->info.is_ngg) {
-         lds_size = DIV_ROUND_UP(gs->info.ngg_info.lds_size, pdev->info.lds_encode_granularity);
-      } else {
-         lds_size = gs->info.gs_ring_info.lds_size;
-      }
+      radv_shader_combine_cfg_tes_gs(device, tes, gs, &rsrc1, &rsrc2);
 
       radeon_begin(cmd_buffer->cs);
       radeon_set_sh_reg(tes->info.regs.pgm_lo, tes->va >> 8);
 
       radeon_set_sh_reg_seq(tes->info.regs.pgm_rsrc1, 2);
       radeon_emit(rsrc1);
-      radeon_emit(rsrc2 | S_00B22C_LDS_SIZE(lds_size));
+      radeon_emit(rsrc2);
 
       const uint32_t next_stage_pc_offset = radv_get_user_sgpr_loc(tes, AC_UD_NEXT_STAGE_PC);
       radeon_emit_32bit_pointer(next_stage_pc_offset, gs->va, &pdev->info);
@@ -2453,21 +2434,22 @@ radv_emit_geometry_shader(struct radv_cmd_buffer *cmd_buffer)
 
    if (gs->info.merged_shader_compiled_separately) {
       const uint32_t vgt_esgs_ring_itemsize_offset = radv_get_user_sgpr_loc(gs, AC_UD_VGT_ESGS_RING_ITEMSIZE);
-
-      assert(vgt_esgs_ring_itemsize_offset);
-
-      radeon_set_sh_reg(vgt_esgs_ring_itemsize_offset, es->info.esgs_itemsize / 4);
+      const uint32_t ngg_lds_layout_offset = radv_get_user_sgpr_loc(gs, AC_UD_NGG_LDS_LAYOUT);
+      uint32_t ngg_lds_layout = 0;
 
       if (gs->info.is_ngg) {
-         const uint32_t ngg_lds_layout_offset = radv_get_user_sgpr_loc(gs, AC_UD_NGG_LDS_LAYOUT);
-
          assert(ngg_lds_layout_offset);
          assert(!(gs->info.ngg_info.esgs_ring_size & 0xffff0000) && !(gs->info.ngg_info.scratch_lds_base & 0xffff0000));
 
-         radeon_set_sh_reg(ngg_lds_layout_offset,
-                           SET_SGPR_FIELD(NGG_LDS_LAYOUT_GS_OUT_VERTEX_BASE, gs->info.ngg_info.esgs_ring_size) |
-                              SET_SGPR_FIELD(NGG_LDS_LAYOUT_SCRATCH_BASE, gs->info.ngg_info.scratch_lds_base));
+         ngg_lds_layout = SET_SGPR_FIELD(NGG_LDS_LAYOUT_GS_OUT_VERTEX_BASE, gs->info.ngg_info.esgs_ring_size) |
+                          SET_SGPR_FIELD(NGG_LDS_LAYOUT_SCRATCH_BASE, gs->info.ngg_info.scratch_lds_base);
       }
+
+      assert(vgt_esgs_ring_itemsize_offset);
+
+      radeon_set_sh_reg(vgt_esgs_ring_itemsize_offset, es->info.esgs_itemsize / 4);
+      if (ngg_lds_layout)
+         radeon_set_sh_reg(ngg_lds_layout_offset, ngg_lds_layout);
    }
 
    radeon_end();
@@ -2489,6 +2471,24 @@ radv_emit_vgt_gs_out(struct radv_cmd_buffer *cmd_buffer, uint32_t vgt_gs_out_pri
    radeon_end();
 }
 
+static void
+radv_gfx11_emit_meshlet(struct radv_cmd_buffer *cmd_buffer, const struct radv_shader *ms)
+{
+   const struct radv_device *device = radv_cmd_buffer_device(cmd_buffer);
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+   struct radeon_cmdbuf *cs = cmd_buffer->cs;
+
+   assert(pdev->info.gfx_level >= GFX11);
+
+   radeon_begin(cs);
+   radeon_set_sh_reg_seq(R_00B2B0_SPI_SHADER_GS_MESHLET_DIM, 2);
+   radeon_emit(ms->info.regs.ms.spi_shader_gs_meshlet_dim);
+   radeon_emit(ms->info.regs.ms.spi_shader_gs_meshlet_exp_alloc);
+   if (pdev->info.gfx_level >= GFX12)
+      radeon_set_sh_reg(R_00B2B8_SPI_SHADER_GS_MESHLET_CTRL, ms->info.regs.ms.spi_shader_gs_meshlet_ctrl);
+   radeon_end();
+}
+
 static void
 radv_emit_mesh_shader(struct radv_cmd_buffer *cmd_buffer)
 {
@@ -2504,18 +2504,11 @@ radv_emit_mesh_shader(struct radv_cmd_buffer *cmd_buffer)
    radeon_opt_set_context_reg(cmd_buffer, R_028B38_VGT_GS_MAX_VERT_OUT, RADV_TRACKED_VGT_GS_MAX_VERT_OUT,
                               ms->info.regs.vgt_gs_max_vert_out);
    radeon_set_uconfig_reg_idx(&pdev->info, R_030908_VGT_PRIMITIVE_TYPE, 1, V_008958_DI_PT_POINTLIST);
-
-   if (pdev->mesh_fast_launch_2) {
-      radeon_set_sh_reg_seq(R_00B2B0_SPI_SHADER_GS_MESHLET_DIM, 2);
-      radeon_emit(ms->info.regs.ms.spi_shader_gs_meshlet_dim);
-      radeon_emit(ms->info.regs.ms.spi_shader_gs_meshlet_exp_alloc);
-
-      if (pdev->info.gfx_level >= GFX12)
-         radeon_set_sh_reg(R_00B2B8_SPI_SHADER_GS_MESHLET_CTRL, ms->info.regs.ms.spi_shader_gs_meshlet_ctrl);
-   }
-
    radeon_end();
 
+   if (pdev->mesh_fast_launch_2)
+      radv_gfx11_emit_meshlet(cmd_buffer, ms);
+
    radv_emit_vgt_gs_out(cmd_buffer, gs_out);
 }
 
@@ -5111,7 +5104,8 @@ emit_prolog_regs(struct radv_cmd_buffer *cmd_buffer, const struct radv_shader *v
 
    if (vs_shader->info.merged_shader_compiled_separately) {
       if (vs_shader->info.next_stage == MESA_SHADER_GEOMETRY) {
-         radv_shader_combine_cfg_vs_gs(vs_shader, cmd_buffer->state.shaders[MESA_SHADER_GEOMETRY], &rsrc1, &rsrc2);
+         radv_shader_combine_cfg_vs_gs(device, vs_shader, cmd_buffer->state.shaders[MESA_SHADER_GEOMETRY], &rsrc1,
+                                       &rsrc2);
       } else {
          assert(vs_shader->info.next_stage == MESA_SHADER_TESS_CTRL);
 
@@ -5133,20 +5127,7 @@ emit_prolog_regs(struct radv_cmd_buffer *cmd_buffer, const struct radv_shader *v
    radeon_set_sh_reg(vs_shader->info.regs.pgm_rsrc1, rsrc1);
 
    if (vs_shader->info.merged_shader_compiled_separately) {
-      if (vs_shader->info.next_stage == MESA_SHADER_GEOMETRY) {
-         const struct radv_shader *gs = cmd_buffer->state.shaders[MESA_SHADER_GEOMETRY];
-         unsigned lds_size;
-
-         if (gs->info.is_ngg) {
-            lds_size = DIV_ROUND_UP(gs->info.ngg_info.lds_size, pdev->info.lds_encode_granularity);
-         } else {
-            lds_size = gs->info.gs_ring_info.lds_size;
-         }
-
-         radeon_set_sh_reg(vs_shader->info.regs.pgm_rsrc2, rsrc2 | S_00B22C_LDS_SIZE(lds_size));
-      } else {
-         radeon_set_sh_reg(vs_shader->info.regs.pgm_rsrc2, rsrc2);
-      }
+      radeon_set_sh_reg(vs_shader->info.regs.pgm_rsrc2, rsrc2);
    }
 
    radeon_end();
@@ -9878,8 +9859,7 @@ radv_emit_userdata_task(const struct radv_cmd_state *cmd_state, struct radeon_cm
    }
 
    if (draw_id_offset) {
-      radeon_set_sh_reg_seq(draw_id_offset, 1);
-      radeon_emit(0);
+      radeon_set_sh_reg(draw_id_offset, 0);
    }
 
    radeon_end();
@@ -10134,8 +10114,7 @@ radv_emit_indirect_mesh_draw_packets(struct radv_cmd_buffer *cmd_buffer, const s
       unsigned reg = state->vtx_base_sgpr + (mesh_shader->info.cs.uses_grid_size ? 12 : 0);
 
       radeon_begin(cs);
-      radeon_set_sh_reg_seq(reg, 1);
-      radeon_emit(0);
+      radeon_set_sh_reg(reg, 0);
       radeon_end();
    }
 
@@ -12397,10 +12376,8 @@ radv_emit_rt_stack_size(struct radv_cmd_buffer *cmd_buffer)
    uint32_t scratch_bytes_per_wave = rt_prolog->config.scratch_bytes_per_wave;
    const uint32_t wave_size = rt_prolog->info.wave_size;
 
-   /* The hardware register is specified as a multiple of 64 or 256 DWORDS. */
-   const unsigned scratch_alloc_granule = pdev->info.gfx_level >= GFX11 ? 256 : 1024;
-
-   scratch_bytes_per_wave += align(cmd_buffer->state.rt_stack_size * wave_size, scratch_alloc_granule);
+   scratch_bytes_per_wave +=
+      align(cmd_buffer->state.rt_stack_size * wave_size, pdev->info.scratch_wavesize_granularity);
 
    cmd_buffer->compute_scratch_size_per_wave_needed =
       MAX2(cmd_buffer->compute_scratch_size_per_wave_needed, scratch_bytes_per_wave);
@@ -12660,7 +12637,7 @@ radv_trace_trace_rays(struct radv_cmd_buffer *cmd_buffer, const VkTraceRaysIndir
                                    radv_dst_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_ALL_COMMANDS_BIT,
                                                          VK_ACCESS_2_SHADER_READ_BIT, 0, NULL, NULL);
 
-   radv_update_buffer_cp(cmd_buffer,
+   radv_update_memory_cp(cmd_buffer,
                          device->rra_trace.ray_history_addr + offsetof(struct radv_ray_history_header, dispatch_index),
                          &dispatch_index, sizeof(dispatch_index));
 }
@@ -12992,9 +12969,8 @@ radv_init_dcc(struct radv_cmd_buffer *cmd_buffer, struct radv_image *image, cons
 
       /* Initialize the mipmap levels without DCC. */
       if (size != image->planes[0].surface.meta_size) {
-         flush_bits |= radv_fill_buffer(cmd_buffer, image, image->bindings[0].bo,
-                                        image->bindings[0].addr + image->planes[0].surface.meta_offset + size,
-                                        image->planes[0].surface.meta_size - size, 0xffffffff);
+         flush_bits |= radv_fill_image(cmd_buffer, image, image->planes[0].surface.meta_offset + size,
+                                       image->planes[0].surface.meta_size - size, 0xffffffff);
       }
    }
 
@@ -13367,10 +13343,28 @@ radv_barrier(struct radv_cmd_buffer *cmd_buffer, uint32_t dep_count, const VkDep
                          sample_locs_info->sampleLocationsCount);
          }
 
+         uint32_t src_qf_index = dep_info->pImageMemoryBarriers[i].srcQueueFamilyIndex;
+         uint32_t dst_qf_index = dep_info->pImageMemoryBarriers[i].dstQueueFamilyIndex;
+
+         /* The src and dst queue family indices may contrain arbitrary values
+          * that should be ignored if they are equal. For example, see
+          * VUID-VkBufferMemoryBarrier-buffer-09095 (Vulkan spec 1.4.313).
+          *
+          *   If buffer was created with a sharing mode of
+          *   VK_SHARING_MODE_EXCLUSIVE, and srcQueueFamilyIndex and
+          *   dstQueueFamilyIndex are not equal, srcQueueFamilyIndex must be
+          *   VK_QUEUE_FAMILY_EXTERNAL, VK_QUEUE_FAMILY_FOREIGN_EXT, or a valid
+          *   queue family
+          */
+         if (src_qf_index == dst_qf_index)
+         {
+            src_qf_index = VK_QUEUE_FAMILY_IGNORED;
+            dst_qf_index = VK_QUEUE_FAMILY_IGNORED;
+         }
+
          radv_handle_image_transition(
             cmd_buffer, image, dep_info->pImageMemoryBarriers[i].oldLayout, dep_info->pImageMemoryBarriers[i].newLayout,
-            dep_info->pImageMemoryBarriers[i].srcQueueFamilyIndex,
-            dep_info->pImageMemoryBarriers[i].dstQueueFamilyIndex, &dep_info->pImageMemoryBarriers[i].subresourceRange,
+            src_qf_index, dst_qf_index, &dep_info->pImageMemoryBarriers[i].subresourceRange,
             sample_locs_info ? &sample_locations : NULL);
       }
    }
diff --git a/src/amd/vulkan/radv_cs.h b/src/amd/vulkan/radv_cs.h
index c989483cc42..69eab9f5390 100644
--- a/src/amd/vulkan/radv_cs.h
+++ b/src/amd/vulkan/radv_cs.h
@@ -236,8 +236,7 @@ radeon_check_space(struct radeon_winsys *ws, struct radeon_cmdbuf *cs, unsigned
 #define radeon_emit_32bit_pointer(sh_offset, va, info)                                                                 \
    do {                                                                                                                \
       assert((va) == 0 || ((va) >> 32) == (info)->address32_hi);                                                       \
-      radeon_set_sh_reg_seq(sh_offset, 1);                                                                             \
-      radeon_emit(va);                                                                                                 \
+      radeon_set_sh_reg(sh_offset, va);                                                                                \
    } while (0)
 
 #define radeon_emit_64bit_pointer(sh_offset, va)                                                                       \
diff --git a/src/amd/vulkan/radv_debug.h b/src/amd/vulkan/radv_debug.h
index 2379a1fc364..31388a5d21d 100644
--- a/src/amd/vulkan/radv_debug.h
+++ b/src/amd/vulkan/radv_debug.h
@@ -71,6 +71,7 @@ enum {
    RADV_DEBUG_DUMP_ASM = 1ull << 56,
    RADV_DEBUG_DUMP_BACKEND_IR = 1ull << 57,
    RADV_DEBUG_PSO_HISTORY = 1ull << 58,
+   RADV_DEBUG_BVH4 = 1ull << 59,
    RADV_DEBUG_DUMP_SHADERS = RADV_DEBUG_DUMP_VS | RADV_DEBUG_DUMP_TCS | RADV_DEBUG_DUMP_TES | RADV_DEBUG_DUMP_GS |
                              RADV_DEBUG_DUMP_PS | RADV_DEBUG_DUMP_TASK | RADV_DEBUG_DUMP_MESH | RADV_DEBUG_DUMP_CS |
                              RADV_DEBUG_DUMP_NIR | RADV_DEBUG_DUMP_ASM | RADV_DEBUG_DUMP_BACKEND_IR,
diff --git a/src/amd/vulkan/radv_device.h b/src/amd/vulkan/radv_device.h
index a718f8d7e70..e9a9a65a496 100644
--- a/src/amd/vulkan/radv_device.h
+++ b/src/amd/vulkan/radv_device.h
@@ -100,8 +100,10 @@ struct radv_meta_state {
       VkPipeline update_pipeline;
       VkPipelineLayout copy_p_layout;
       VkPipeline copy_pipeline;
+      VkPipeline copy_blas_addrs_gfx12_pipeline;
 
       struct radix_sort_vk *radix_sort;
+      struct vk_acceleration_structure_build_ops build_ops;
       struct vk_acceleration_structure_build_args build_args;
 
       struct {
diff --git a/src/amd/vulkan/radv_instance.c b/src/amd/vulkan/radv_instance.c
index 7aebf073dfd..4946a5aebd0 100644
--- a/src/amd/vulkan/radv_instance.c
+++ b/src/amd/vulkan/radv_instance.c
@@ -86,6 +86,7 @@ static const struct debug_control radv_debug_options[] = {{"nofastclears", RADV_
                                                           {"asm", RADV_DEBUG_DUMP_ASM},
                                                           {"ir", RADV_DEBUG_DUMP_BACKEND_IR},
                                                           {"pso_history", RADV_DEBUG_PSO_HISTORY},
+                                                          {"bvh4", RADV_DEBUG_BVH4},
                                                           {NULL, 0}};
 
 const char *
diff --git a/src/amd/vulkan/radv_physical_device.c b/src/amd/vulkan/radv_physical_device.c
index 3db3353b6c2..744b20ccc84 100644
--- a/src/amd/vulkan/radv_physical_device.c
+++ b/src/amd/vulkan/radv_physical_device.c
@@ -157,6 +157,13 @@ radv_emulate_rt(const struct radv_physical_device *pdev)
    return !pdev->info.has_image_bvh_intersect_ray && instance->drirc.emulate_rt;
 }
 
+bool
+radv_use_bvh8(const struct radv_physical_device *pdev)
+{
+   const struct radv_instance *instance = radv_physical_device_instance(pdev);
+   return pdev->info.gfx_level >= GFX12 && !radv_emulate_rt(pdev) && !(instance->debug_flags & RADV_DEBUG_BVH4);
+}
+
 static void
 parse_hex(char *out, const char *in, unsigned length)
 {
@@ -186,6 +193,7 @@ radv_physical_device_init_cache_key(struct radv_physical_device *pdev)
    key->disable_sinking_load_input_fs = instance->drirc.disable_sinking_load_input_fs;
    key->disable_trunc_coord = instance->drirc.disable_trunc_coord;
    key->emulate_rt = radv_emulate_rt(pdev);
+   key->bvh8 = radv_use_bvh8(pdev);
    key->ge_wave32 = pdev->ge_wave_size == 32;
    key->invariant_geom = !!(instance->debug_flags & RADV_DEBUG_INVARIANT_GEOM);
    key->no_fmask = !!(instance->debug_flags & RADV_DEBUG_NO_FMASK);
@@ -570,6 +578,7 @@ radv_physical_device_get_supported_extensions(const struct radv_physical_device
       .KHR_sampler_ycbcr_conversion = true,
       .KHR_separate_depth_stencil_layouts = true,
       .KHR_shader_atomic_int64 = true,
+      .KHR_shader_bfloat16 = pdev->info.gfx_level >= GFX11,
       .KHR_shader_clock = true,
       .KHR_shader_draw_parameters = true,
       .KHR_shader_expect_assume = true,
@@ -1296,6 +1305,11 @@ radv_physical_device_get_features(const struct radv_physical_device *pdev, struc
 
       /* VK_EXT_device_memory_report */
       .deviceMemoryReport = true,
+
+      /* VK_KHR_shader_bfloat16 */
+      .shaderBFloat16Type = true,
+      .shaderBFloat16DotProduct = pdev->info.gfx_level >= GFX12, /* v_dot2_bf16_bf16 isn't working on GFX11. */
+      .shaderBFloat16CooperativeMatrix = radv_cooperative_matrix_enabled(pdev),
    };
 }
 
@@ -2062,23 +2076,19 @@ radv_physical_device_try_create(struct radv_instance *instance, drmDevicePtr drm
 
 #ifdef _WIN32
    pdev->ws = radv_null_winsys_create();
-   if (!pdev->ws)
-      result = VK_ERROR_OUT_OF_HOST_MEMORY;
 #else
    if (drm_device) {
       bool reserve_vmid = instance->vk.trace_mode & RADV_TRACE_MODE_RGP;
 
-      result = radv_amdgpu_winsys_create(fd, instance->debug_flags, instance->perftest_flags, reserve_vmid, is_virtio,
-                                         &pdev->ws);
+      pdev->ws =
+         radv_amdgpu_winsys_create(fd, instance->debug_flags, instance->perftest_flags, reserve_vmid, is_virtio);
    } else {
       pdev->ws = radv_null_winsys_create();
-      if (!pdev->ws)
-         result = VK_ERROR_OUT_OF_HOST_MEMORY;
    }
 #endif
 
-   if (result != VK_SUCCESS) {
-      result = vk_errorf(instance, result, "failed to initialize winsys");
+   if (!pdev->ws) {
+      result = vk_errorf(instance, VK_ERROR_INITIALIZATION_FAILED, "failed to initialize winsys");
       goto fail_base;
    }
 
@@ -2281,7 +2291,6 @@ radv_physical_device_try_create(struct radv_instance *instance, drmDevicePtr drm
 
    pdev->gs_table_depth = ac_get_gs_table_depth(pdev->info.gfx_level, pdev->info.family);
 
-   ac_get_hs_info(&pdev->info, &pdev->hs);
    ac_get_task_info(&pdev->info, &pdev->task_info);
    radv_get_binning_settings(pdev, &pdev->binning_settings);
 
@@ -2837,34 +2846,31 @@ VKAPI_ATTR VkResult VKAPI_CALL
 radv_GetPhysicalDeviceCooperativeMatrixPropertiesKHR(VkPhysicalDevice physicalDevice, uint32_t *pPropertyCount,
                                                      VkCooperativeMatrixPropertiesKHR *pProperties)
 {
+   VK_FROM_HANDLE(radv_physical_device, pdev, physicalDevice);
    VK_OUTARRAY_MAKE_TYPED(VkCooperativeMatrixPropertiesKHR, out, pProperties, pPropertyCount);
 
-   vk_outarray_append_typed(VkCooperativeMatrixPropertiesKHR, &out, p)
-   {
-      *p = (struct VkCooperativeMatrixPropertiesKHR){.sType = VK_STRUCTURE_TYPE_COOPERATIVE_MATRIX_PROPERTIES_KHR,
-                                                     .MSize = 16,
-                                                     .NSize = 16,
-                                                     .KSize = 16,
-                                                     .AType = VK_COMPONENT_TYPE_FLOAT16_KHR,
-                                                     .BType = VK_COMPONENT_TYPE_FLOAT16_KHR,
-                                                     .CType = VK_COMPONENT_TYPE_FLOAT16_KHR,
-                                                     .ResultType = VK_COMPONENT_TYPE_FLOAT16_KHR,
-                                                     .saturatingAccumulation = false,
-                                                     .scope = VK_SCOPE_SUBGROUP_KHR};
-   }
-
-   vk_outarray_append_typed(VkCooperativeMatrixPropertiesKHR, &out, p)
-   {
-      *p = (struct VkCooperativeMatrixPropertiesKHR){.sType = VK_STRUCTURE_TYPE_COOPERATIVE_MATRIX_PROPERTIES_KHR,
-                                                     .MSize = 16,
-                                                     .NSize = 16,
-                                                     .KSize = 16,
-                                                     .AType = VK_COMPONENT_TYPE_FLOAT16_KHR,
-                                                     .BType = VK_COMPONENT_TYPE_FLOAT16_KHR,
-                                                     .CType = VK_COMPONENT_TYPE_FLOAT32_KHR,
-                                                     .ResultType = VK_COMPONENT_TYPE_FLOAT32_KHR,
-                                                     .saturatingAccumulation = false,
-                                                     .scope = VK_SCOPE_SUBGROUP_KHR};
+   for (unsigned bfloat = 0; bfloat < 2; bfloat++) {
+      for (unsigned fp32 = 0; fp32 < 2; fp32++) {
+         VkComponentTypeKHR ab_type = bfloat ? VK_COMPONENT_TYPE_BFLOAT16_KHR : VK_COMPONENT_TYPE_FLOAT16_KHR;
+         VkComponentTypeKHR cd_type = fp32 ? VK_COMPONENT_TYPE_FLOAT32_KHR : ab_type;
+
+         if (pdev->info.gfx_level < GFX12 && bfloat && !fp32)
+            continue; /* BF16 accumulator isn't working correctly on GFX11. */
+
+         vk_outarray_append_typed(VkCooperativeMatrixPropertiesKHR, &out, p)
+         {
+            *p = (struct VkCooperativeMatrixPropertiesKHR){.sType = VK_STRUCTURE_TYPE_COOPERATIVE_MATRIX_PROPERTIES_KHR,
+                                                           .MSize = 16,
+                                                           .NSize = 16,
+                                                           .KSize = 16,
+                                                           .AType = ab_type,
+                                                           .BType = ab_type,
+                                                           .CType = cd_type,
+                                                           .ResultType = cd_type,
+                                                           .saturatingAccumulation = false,
+                                                           .scope = VK_SCOPE_SUBGROUP_KHR};
+         }
+      }
    }
 
    for (unsigned asigned = 0; asigned < 2; asigned++) {
diff --git a/src/amd/vulkan/radv_physical_device.h b/src/amd/vulkan/radv_physical_device.h
index f53307ece06..af0a5475a8d 100644
--- a/src/amd/vulkan/radv_physical_device.h
+++ b/src/amd/vulkan/radv_physical_device.h
@@ -48,6 +48,7 @@ struct radv_physical_device_cache_key {
    uint32_t disable_sinking_load_input_fs : 1;
    uint32_t disable_trunc_coord : 1;
    uint32_t emulate_rt : 1;
+   uint32_t bvh8 : 1;
    uint32_t ge_wave32 : 1;
    uint32_t invariant_geom : 1;
    uint32_t no_fmask : 1;
@@ -157,7 +158,6 @@ struct radv_physical_device {
 
    uint32_t gs_table_depth;
 
-   struct ac_hs_info hs;
    struct ac_task_info task_info;
 
    struct radv_binning_settings binning_settings;
@@ -258,6 +258,8 @@ bool radv_enable_rt(const struct radv_physical_device *pdev);
 
 bool radv_emulate_rt(const struct radv_physical_device *pdev);
 
+bool radv_use_bvh8(const struct radv_physical_device *pdev);
+
 uint32_t radv_find_memory_index(const struct radv_physical_device *pdev, VkMemoryPropertyFlags flags);
 
 VkResult create_null_physical_device(struct vk_instance *vk_instance);
diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index 5b98d9f7907..fa8bdd49cb9 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -265,6 +265,10 @@ opt_vectorize_callback(const nir_instr *instr, const void *_)
       return 1;
 
    const nir_alu_instr *alu = nir_instr_as_alu(instr);
+
+   if (alu->op == nir_op_f2e4m3fn || alu->op == nir_op_e4m3fn2f)
+      return 2;
+
    const unsigned bit_size = alu->def.bit_size;
    if (bit_size != 16)
       return 1;
@@ -539,6 +543,9 @@ radv_postprocess_nir(struct radv_device *device, const struct radv_graphics_stat
       stage->nir, io_to_mem || lowered_ngg || stage->stage == MESA_SHADER_COMPUTE || stage->stage == MESA_SHADER_TASK,
       gfx_level >= GFX8);
 
+   if (stage->nir->info.cs.has_cooperative_matrix)
+      NIR_PASS(_, stage->nir, radv_nir_opt_cooperative_matrix, gfx_level);
+
    NIR_PASS(_, stage->nir, nir_lower_fp16_casts, nir_lower_fp16_split_fp64);
 
    if (ac_nir_might_lower_bit_size(stage->nir)) {
diff --git a/src/amd/vulkan/radv_query.c b/src/amd/vulkan/radv_query.c
index 21654fd7e86..9d35f5d7622 100644
--- a/src/amd/vulkan/radv_query.c
+++ b/src/amd/vulkan/radv_query.c
@@ -2535,13 +2535,13 @@ radv_CmdResetQueryPool(VkCommandBuffer commandBuffer, VkQueryPool queryPool, uin
     */
    cmd_buffer->state.flush_bits |= cmd_buffer->active_query_flush_bits;
 
-   flush_bits |= radv_fill_buffer(cmd_buffer, NULL, pool->bo, radv_buffer_get_va(pool->bo) + firstQuery * pool->stride,
+   flush_bits |= radv_fill_buffer(cmd_buffer, pool->bo, radv_buffer_get_va(pool->bo) + firstQuery * pool->stride,
                                   queryCount * pool->stride, value);
 
    if (pool->vk.query_type == VK_QUERY_TYPE_PIPELINE_STATISTICS ||
        (pool->vk.query_type == VK_QUERY_TYPE_MESH_PRIMITIVES_GENERATED_EXT && pdev->info.gfx_level >= GFX11)) {
       flush_bits |=
-         radv_fill_buffer(cmd_buffer, NULL, pool->bo,
+         radv_fill_buffer(cmd_buffer, pool->bo,
                           radv_buffer_get_va(pool->bo) + pool->availability_offset + firstQuery * 4, queryCount * 4, 0);
    }
 
diff --git a/src/amd/vulkan/radv_queue.c b/src/amd/vulkan/radv_queue.c
index 837c6af77d4..5b110c4dd1f 100644
--- a/src/amd/vulkan/radv_queue.c
+++ b/src/amd/vulkan/radv_queue.c
@@ -313,10 +313,11 @@ radv_fill_shader_rings(struct radv_device *device, uint32_t *desc, struct radeon
    desc += 8;
 
    if (tess_rings_bo) {
-      radv_set_ring_buffer(pdev, tess_rings_bo, 0, pdev->hs.tess_factor_ring_size, false, false, true, 0, 0, &desc[0]);
+      radv_set_ring_buffer(pdev, tess_rings_bo, pdev->info.tess_offchip_ring_size, pdev->info.tess_factor_ring_size,
+                           false, false, true, 0, 0, &desc[0]);
 
-      radv_set_ring_buffer(pdev, tess_rings_bo, pdev->hs.tess_offchip_ring_offset, pdev->hs.tess_offchip_ring_size,
-                           false, false, true, 0, 0, &desc[4]);
+      radv_set_ring_buffer(pdev, tess_rings_bo, 0, pdev->info.tess_offchip_ring_size, false, false, true, 0, 0,
+                           &desc[4]);
    }
 
    desc += 8;
@@ -397,8 +398,8 @@ radv_emit_tess_factor_ring(struct radv_device *device, struct radeon_cmdbuf *cs,
    if (!tess_rings_bo)
       return;
 
-   tf_ring_size = pdev->hs.tess_factor_ring_size / 4;
-   tf_va = radv_buffer_get_va(tess_rings_bo);
+   tf_ring_size = pdev->info.tess_factor_ring_size / 4;
+   tf_va = radv_buffer_get_va(tess_rings_bo) + pdev->info.tess_offchip_ring_size;
 
    radv_cs_add_buffer(device->ws, cs, tess_rings_bo);
 
@@ -421,11 +422,11 @@ radv_emit_tess_factor_ring(struct radv_device *device, struct radeon_cmdbuf *cs,
          radeon_set_uconfig_reg(R_030944_VGT_TF_MEMORY_BASE_HI, S_030944_BASE_HI(tf_va >> 40));
       }
 
-      radeon_set_uconfig_reg(R_03093C_VGT_HS_OFFCHIP_PARAM, pdev->hs.hs_offchip_param);
+      radeon_set_uconfig_reg(R_03093C_VGT_HS_OFFCHIP_PARAM, pdev->info.hs_offchip_param);
    } else {
       radeon_set_config_reg(R_008988_VGT_TF_RING_SIZE, S_008988_SIZE(tf_ring_size));
       radeon_set_config_reg(R_0089B8_VGT_TF_MEMORY_BASE, tf_va >> 8);
-      radeon_set_config_reg(R_0089B0_VGT_HS_OFFCHIP_PARAM, pdev->hs.hs_offchip_param);
+      radeon_set_config_reg(R_0089B0_VGT_HS_OFFCHIP_PARAM, pdev->info.hs_offchip_param);
    }
 
    radeon_end();
@@ -492,10 +493,13 @@ radv_emit_graphics_scratch(struct radv_device *device, struct radeon_cmdbuf *cs,
 {
    const struct radv_physical_device *pdev = radv_device_physical(device);
    const struct radeon_info *gpu_info = &pdev->info;
+   uint32_t tmpring_size;
 
    if (!scratch_bo)
       return;
 
+   ac_get_scratch_tmpring_size(gpu_info, waves, size_per_wave, &tmpring_size);
+
    radv_cs_add_buffer(device->ws, cs, scratch_bo);
 
    radeon_begin(cs);
@@ -503,16 +507,12 @@ radv_emit_graphics_scratch(struct radv_device *device, struct radeon_cmdbuf *cs,
    if (gpu_info->gfx_level >= GFX11) {
       uint64_t va = radv_buffer_get_va(scratch_bo);
 
-      /* WAVES is per SE for SPI_TMPRING_SIZE. */
-      waves /= gpu_info->max_se;
-
       radeon_set_context_reg_seq(R_0286E8_SPI_TMPRING_SIZE, 3);
-      radeon_emit(S_0286E8_WAVES(waves) | S_0286E8_WAVESIZE(DIV_ROUND_UP(size_per_wave, 256)));
+      radeon_emit(tmpring_size);
       radeon_emit(va >> 8);  /* SPI_GFX_SCRATCH_BASE_LO */
       radeon_emit(va >> 40); /* SPI_GFX_SCRATCH_BASE_HI */
    } else {
-      radeon_set_context_reg(R_0286E8_SPI_TMPRING_SIZE,
-                             S_0286E8_WAVES(waves) | S_0286E8_WAVESIZE(DIV_ROUND_UP(size_per_wave, 1024)));
+      radeon_set_context_reg(R_0286E8_SPI_TMPRING_SIZE, tmpring_size);
    }
 
    radeon_end();
@@ -524,6 +524,7 @@ radv_emit_compute_scratch(struct radv_device *device, struct radeon_cmdbuf *cs,
 {
    const struct radv_physical_device *pdev = radv_device_physical(device);
    const struct radeon_info *gpu_info = &pdev->info;
+   uint32_t tmpring_size;
    uint64_t scratch_va;
    uint32_t rsrc1;
 
@@ -538,6 +539,8 @@ radv_emit_compute_scratch(struct radv_device *device, struct radeon_cmdbuf *cs,
    else
       rsrc1 |= S_008F04_SWIZZLE_ENABLE_GFX6(1);
 
+   ac_get_scratch_tmpring_size(gpu_info, waves, size_per_wave, &tmpring_size);
+
    radv_cs_add_buffer(device->ws, cs, compute_scratch_bo);
 
    radeon_begin(cs);
@@ -554,9 +557,7 @@ radv_emit_compute_scratch(struct radv_device *device, struct radeon_cmdbuf *cs,
    radeon_emit(scratch_va);
    radeon_emit(rsrc1);
 
-   radeon_set_sh_reg(R_00B860_COMPUTE_TMPRING_SIZE,
-                     S_00B860_WAVES(waves) |
-                        S_00B860_WAVESIZE(DIV_ROUND_UP(size_per_wave, gpu_info->gfx_level >= GFX11 ? 256 : 1024)));
+   radeon_set_sh_reg(R_00B860_COMPUTE_TMPRING_SIZE, tmpring_size);
 
    radeon_end();
 }
@@ -915,12 +916,6 @@ radv_emit_graphics(struct radv_device *device, struct radeon_cmdbuf *cs)
       ac_pm4_set_reg(pm4, R_028000_DB_RENDER_CONTROL, 0);
    }
 
-   if (pdev->info.family >= CHIP_NAVI31 && pdev->info.family <= CHIP_GFX1150) {
-      /* Disable SINGLE clear codes on GFX11 (including first GFX11.5 rev) to workaround a hw bug
-       * with DCC. */
-      ac_pm4_set_reg(pm4, R_028424_CB_FDCC_CONTROL, S_028424_DISABLE_CONSTANT_ENCODE_SINGLE(1));
-   }
-
    ac_pm4_finalize(pm4);
    radv_emit_pm4_commands(cs, pm4);
    ac_pm4_free_state(pm4);
@@ -1003,12 +998,11 @@ radv_update_preamble_cs(struct radv_queue_state *queue, struct radv_device *devi
    }
 
    if (!queue->ring_info.tess_rings && needs->tess_rings) {
-      uint64_t tess_rings_size = pdev->hs.tess_offchip_ring_offset + pdev->hs.tess_offchip_ring_size;
-      result = radv_bo_create(device, NULL, tess_rings_size, 256, RADEON_DOMAIN_VRAM, ring_bo_flags,
+      result = radv_bo_create(device, NULL, pdev->info.total_tess_ring_size, 256, RADEON_DOMAIN_VRAM, ring_bo_flags,
                               RADV_BO_PRIORITY_SCRATCH, 0, true, &tess_rings_bo);
       if (result != VK_SUCCESS)
          goto fail;
-      radv_rmv_log_command_buffer_bo_create(device, tess_rings_bo, 0, 0, tess_rings_size);
+      radv_rmv_log_command_buffer_bo_create(device, tess_rings_bo, 0, 0, pdev->info.total_tess_ring_size);
    }
 
    if (!queue->ring_info.task_rings && needs->task_rings) {
@@ -1345,6 +1339,10 @@ radv_update_preambles(struct radv_queue_state *queue, struct radv_device *device
          ? MIN2(needs.compute_scratch_waves, UINT32_MAX / needs.compute_scratch_size_per_wave)
          : 0;
 
+   /* Compute the optimal scratch wavesize. */
+   needs.scratch_size_per_wave = ac_compute_scratch_wavesize(&pdev->info, needs.scratch_size_per_wave);
+   needs.compute_scratch_size_per_wave = ac_compute_scratch_wavesize(&pdev->info, needs.compute_scratch_size_per_wave);
+
    if (pdev->info.gfx_level >= GFX11 && queue->qf == RADV_QUEUE_GENERAL) {
       needs.ge_rings = true;
    }
diff --git a/src/amd/vulkan/radv_rra.c b/src/amd/vulkan/radv_rra.c
index 26bcfcd89a1..6b05390b3b2 100644
--- a/src/amd/vulkan/radv_rra.c
+++ b/src/amd/vulkan/radv_rra.c
@@ -6,7 +6,6 @@
 
 #include "radv_rra.h"
 #include "bvh/bvh.h"
-#include "util/half_float.h"
 #include "amd_family.h"
 #include "radv_device.h"
 #include "radv_entrypoints.h"
@@ -56,14 +55,6 @@ struct rra_file_chunk_description {
 
 static_assert(sizeof(struct rra_file_chunk_description) == 64, "rra_file_chunk_description does not match RRA spec");
 
-static uint64_t
-node_to_addr(uint64_t node)
-{
-   node &= ~7ull;
-   node <<= 19;
-   return ((int64_t)node) >> 16;
-}
-
 static void
 rra_dump_header(FILE *output, uint64_t chunk_descriptions_offset, uint64_t chunk_descriptions_size)
 {
@@ -192,89 +183,9 @@ rra_dump_asic_info(const struct radeon_info *gpu_info, FILE *output)
    fwrite(&asic_info, sizeof(struct rra_asic_info), 1, output);
 }
 
-enum rra_bvh_type {
-   RRA_BVH_TYPE_TLAS,
-   RRA_BVH_TYPE_BLAS,
-};
-
-struct rra_accel_struct_chunk_header {
-   /*
-    * Declaring this as uint64_t would make the compiler insert padding to
-    * satisfy alignment restrictions.
-    */
-   uint32_t virtual_address[2];
-   uint32_t metadata_offset;
-   uint32_t metadata_size;
-   uint32_t header_offset;
-   uint32_t header_size;
-   enum rra_bvh_type bvh_type;
-};
-
-static_assert(sizeof(struct rra_accel_struct_chunk_header) == 28,
-              "rra_accel_struct_chunk_header does not match RRA spec");
-
-struct rra_accel_struct_post_build_info {
-   uint32_t bvh_type : 1;
-   uint32_t reserved1 : 5;
-   uint32_t tri_compression_mode : 2;
-   uint32_t fp16_interior_mode : 2;
-   uint32_t reserved2 : 6;
-   uint32_t build_flags : 16;
-};
-
-static_assert(sizeof(struct rra_accel_struct_post_build_info) == 4,
-              "rra_accel_struct_post_build_info does not match RRA spec");
-
-struct rra_accel_struct_header {
-   struct rra_accel_struct_post_build_info post_build_info;
-   /*
-    * Size of the internal acceleration structure metadata in the
-    * proprietary drivers. Seems to always be 128.
-    */
-   uint32_t metadata_size;
-   uint32_t file_size;
-   uint32_t primitive_count;
-   uint32_t active_primitive_count;
-   uint32_t unused1;
-   uint32_t geometry_description_count;
-   VkGeometryTypeKHR geometry_type;
-   uint32_t internal_nodes_offset;
-   uint32_t leaf_nodes_offset;
-   uint32_t geometry_infos_offset;
-   uint32_t leaf_ids_offset;
-   uint32_t interior_fp32_node_count;
-   uint32_t interior_fp16_node_count;
-   uint32_t leaf_node_count;
-   uint32_t rt_driver_interface_version;
-   uint64_t unused2;
-   uint32_t half_fp32_node_count;
-   char unused3[44];
-};
-
-#define RRA_ROOT_NODE_OFFSET align(sizeof(struct rra_accel_struct_header), 64)
-
-static_assert(sizeof(struct rra_accel_struct_header) == 120, "rra_accel_struct_header does not match RRA spec");
-
-struct rra_accel_struct_metadata {
-   uint64_t virtual_address;
-   uint32_t byte_size;
-   char unused[116];
-};
-
-static_assert(sizeof(struct rra_accel_struct_metadata) == 128, "rra_accel_struct_metadata does not match RRA spec");
-
-struct rra_geometry_info {
-   uint32_t primitive_count : 29;
-   uint32_t flags : 3;
-   uint32_t unknown;
-   uint32_t leaf_node_list_offset;
-};
-
-static_assert(sizeof(struct rra_geometry_info) == 12, "rra_geometry_info does not match RRA spec");
-
 static struct rra_accel_struct_header
-rra_fill_accel_struct_header_common(struct radv_accel_struct_header *header, size_t parent_id_table_size,
-                                    size_t leaf_node_data_size, size_t internal_node_data_size,
+rra_fill_accel_struct_header_common(const struct radv_physical_device *pdev, struct radv_accel_struct_header *header,
+                                    size_t parent_id_table_size, struct rra_bvh_info *bvh_info,
                                     uint64_t primitive_count)
 {
    struct rra_accel_struct_header result = {
@@ -288,89 +199,39 @@ rra_fill_accel_struct_header_common(struct radv_accel_struct_header *header, siz
       /* TODO: calculate active primitives */
       .active_primitive_count = primitive_count,
       .geometry_description_count = header->geometry_count,
-      .interior_fp32_node_count = internal_node_data_size / sizeof(struct radv_bvh_box32_node),
+      .interior_fp32_node_count = bvh_info->internal_nodes_size / sizeof(struct radv_bvh_box32_node),
       .leaf_node_count = primitive_count,
       .rt_driver_interface_version = 8 << 16,
+      .rt_ip_version = pdev->info.rt_ip_version,
    };
 
+   if (!radv_use_bvh8(pdev))
+      result.rt_ip_version = MIN2(result.rt_ip_version, RT_1_1);
+
    result.metadata_size = sizeof(struct rra_accel_struct_metadata) + parent_id_table_size;
-   result.file_size =
-      result.metadata_size + sizeof(struct rra_accel_struct_header) + internal_node_data_size + leaf_node_data_size;
+   result.file_size = result.metadata_size + sizeof(struct rra_accel_struct_header) + bvh_info->internal_nodes_size +
+                      bvh_info->leaf_nodes_size;
 
    result.internal_nodes_offset = sizeof(struct rra_accel_struct_metadata);
-   result.leaf_nodes_offset = result.internal_nodes_offset + internal_node_data_size;
-   result.geometry_infos_offset = result.leaf_nodes_offset + leaf_node_data_size;
+   result.leaf_nodes_offset = result.internal_nodes_offset + bvh_info->internal_nodes_size;
+   result.geometry_infos_offset = result.leaf_nodes_offset + bvh_info->leaf_nodes_size;
    result.leaf_ids_offset = result.geometry_infos_offset;
-   if (!header->instance_count)
+   if (header->instance_count) {
+      if (radv_use_bvh8(pdev))
+         result.leaf_ids_offset += bvh_info->instance_sideband_data_size;
+   } else {
       result.leaf_ids_offset += header->geometry_count * sizeof(struct rra_geometry_info);
+   }
 
    return result;
 }
 
-struct rra_box32_node {
-   uint32_t children[4];
-   float coords[4][2][3];
-   uint32_t reserved[4];
-};
-
-struct rra_box16_node {
-   uint32_t children[4];
-   float16_t coords[4][2][3];
-};
-
-/*
- * RRA files contain this struct in place of hardware
- * instance nodes. They're named "instance desc" internally.
- */
-struct rra_instance_node {
-   float wto_matrix[12];
-   uint32_t custom_instance_id : 24;
-   uint32_t mask : 8;
-   uint32_t sbt_offset : 24;
-   uint32_t instance_flags : 8;
-   uint64_t blas_va : 54;
-   uint64_t hw_instance_flags : 10;
-   uint32_t instance_id;
-   uint32_t unused1;
-   uint32_t blas_metadata_size;
-   uint32_t unused2;
-   float otw_matrix[12];
-};
-
-static_assert(sizeof(struct rra_instance_node) == 128, "rra_instance_node does not match RRA spec!");
-
-/*
- * Format RRA uses for aabb nodes
- */
-struct rra_aabb_node {
-   float aabb[2][3];
-   uint32_t unused1[6];
-   uint32_t geometry_id : 28;
-   uint32_t flags : 4;
-   uint32_t primitive_id;
-   uint32_t unused[2];
-};
-
-static_assert(sizeof(struct rra_aabb_node) == 64, "rra_aabb_node does not match RRA spec!");
-
-struct rra_triangle_node {
-   float coords[3][3];
-   uint32_t reserved[3];
-   uint32_t geometry_id : 28;
-   uint32_t flags : 4;
-   uint32_t triangle_id;
-   uint32_t reserved2;
-   uint32_t id;
-};
-
-static_assert(sizeof(struct rra_triangle_node) == 64, "rra_triangle_node does not match RRA spec!");
-
 static void
-rra_dump_tlas_header(struct radv_accel_struct_header *header, size_t parent_id_table_size, size_t leaf_node_data_size,
-                     size_t internal_node_data_size, uint64_t primitive_count, FILE *output)
+rra_dump_tlas_header(const struct radv_physical_device *pdev, struct radv_accel_struct_header *header,
+                     size_t parent_id_table_size, struct rra_bvh_info *bvh_info, uint64_t primitive_count, FILE *output)
 {
-   struct rra_accel_struct_header file_header = rra_fill_accel_struct_header_common(
-      header, parent_id_table_size, leaf_node_data_size, internal_node_data_size, primitive_count);
+   struct rra_accel_struct_header file_header =
+      rra_fill_accel_struct_header_common(pdev, header, parent_id_table_size, bvh_info, primitive_count);
    file_header.post_build_info.bvh_type = RRA_BVH_TYPE_TLAS;
    file_header.geometry_type = VK_GEOMETRY_TYPE_INSTANCES_KHR;
 
@@ -378,31 +239,19 @@ rra_dump_tlas_header(struct radv_accel_struct_header *header, size_t parent_id_t
 }
 
 static void
-rra_dump_blas_header(struct radv_accel_struct_header *header, size_t parent_id_table_size,
-                     struct radv_accel_struct_geometry_info *geometry_infos, size_t leaf_node_data_size,
-                     size_t internal_node_data_size, uint64_t primitive_count, FILE *output)
+rra_dump_blas_header(const struct radv_physical_device *pdev, struct radv_accel_struct_header *header,
+                     size_t parent_id_table_size, struct radv_accel_struct_geometry_info *geometry_infos,
+                     struct rra_bvh_info *bvh_info, uint64_t primitive_count, FILE *output)
 {
-   struct rra_accel_struct_header file_header = rra_fill_accel_struct_header_common(
-      header, parent_id_table_size, leaf_node_data_size, internal_node_data_size, primitive_count);
+   struct rra_accel_struct_header file_header =
+      rra_fill_accel_struct_header_common(pdev, header, parent_id_table_size, bvh_info, primitive_count);
    file_header.post_build_info.bvh_type = RRA_BVH_TYPE_BLAS;
    file_header.geometry_type = header->geometry_count ? geometry_infos->type : VK_GEOMETRY_TYPE_TRIANGLES_KHR;
 
    fwrite(&file_header, sizeof(struct rra_accel_struct_header), 1, output);
 }
 
-static uint32_t
-rra_parent_table_index_from_offset(uint32_t offset, uint32_t parent_table_size)
-{
-   uint32_t max_parent_table_index = parent_table_size / sizeof(uint32_t) - 1;
-   return max_parent_table_index - (offset - RRA_ROOT_NODE_OFFSET) / 64;
-}
-
-struct rra_validation_context {
-   bool failed;
-   char location[31];
-};
-
-static void PRINTFLIKE(2, 3) rra_validation_fail(struct rra_validation_context *ctx, const char *message, ...)
+void PRINTFLIKE(2, 3) rra_validation_fail(struct rra_validation_context *ctx, const char *message, ...)
 {
    if (!ctx->failed) {
       fprintf(stderr, "radv: rra: Validation failed at %s:\n", ctx->location);
@@ -438,301 +287,9 @@ rra_validate_header(struct radv_rra_accel_struct_data *accel_struct, const struc
    return ctx.failed;
 }
 
-static bool
-is_internal_node(uint32_t type)
-{
-   return type == radv_bvh_node_box16 || type == radv_bvh_node_box32;
-}
-
-static const char *node_type_names[8] = {
-   [radv_bvh_node_triangle + 0] = "triangle0",
-   [radv_bvh_node_triangle + 1] = "triangle1",
-   [radv_bvh_node_triangle + 2] = "triangle2",
-   [radv_bvh_node_triangle + 3] = "triangle3",
-   [radv_bvh_node_box16] = "box16",
-   [radv_bvh_node_box32] = "box32",
-   [radv_bvh_node_instance] = "instance",
-   [radv_bvh_node_aabb] = "aabb",
-};
-
-static bool
-rra_validate_node(struct hash_table_u64 *accel_struct_vas, uint8_t *data, void *node, uint32_t geometry_count,
-                  uint32_t size, bool is_bottom_level, uint32_t depth)
-{
-   struct rra_validation_context ctx = {0};
-
-   if (depth > 1024) {
-      rra_validation_fail(&ctx, "depth > 1024");
-      return true;
-   }
-
-   uint32_t cur_offset = (uint8_t *)node - data;
-   snprintf(ctx.location, sizeof(ctx.location), "internal node (offset=%u)", cur_offset);
-
-   /* The child ids are located at offset=0 for both box16 and box32 nodes. */
-   uint32_t *children = node;
-   for (uint32_t i = 0; i < 4; ++i) {
-      if (children[i] == 0xFFFFFFFF)
-         continue;
-
-      uint32_t type = children[i] & 7;
-      uint32_t offset = (children[i] & (~7u)) << 3;
-
-      if (!is_internal_node(type) && is_bottom_level == (type == radv_bvh_node_instance))
-         rra_validation_fail(&ctx,
-                             is_bottom_level ? "%s node in BLAS (child index %u)" : "%s node in TLAS (child index %u)",
-                             node_type_names[type], i);
-
-      if (offset > size) {
-         rra_validation_fail(&ctx, "Invalid child offset (child index %u)", i);
-         continue;
-      }
-
-      struct rra_validation_context child_ctx = {0};
-      snprintf(child_ctx.location, sizeof(child_ctx.location), "%s node (offset=%u)", node_type_names[type], offset);
-
-      if (is_internal_node(type)) {
-         ctx.failed |=
-            rra_validate_node(accel_struct_vas, data, data + offset, geometry_count, size, is_bottom_level, depth + 1);
-      } else if (type == radv_bvh_node_instance) {
-         struct radv_bvh_instance_node *src = (struct radv_bvh_instance_node *)(data + offset);
-         uint64_t blas_va = node_to_addr(src->bvh_ptr) - src->bvh_offset;
-         if (!_mesa_hash_table_u64_search(accel_struct_vas, blas_va))
-            rra_validation_fail(&child_ctx, "Invalid instance node pointer 0x%llx (offset: 0x%x)",
-                                (unsigned long long)src->bvh_ptr, src->bvh_offset);
-      } else if (type == radv_bvh_node_aabb) {
-         struct radv_bvh_aabb_node *src = (struct radv_bvh_aabb_node *)(data + offset);
-         if ((src->geometry_id_and_flags & 0xFFFFFFF) >= geometry_count)
-            rra_validation_fail(&ctx, "geometry_id >= geometry_count");
-      } else {
-         struct radv_bvh_triangle_node *src = (struct radv_bvh_triangle_node *)(data + offset);
-         if ((src->geometry_id_and_flags & 0xFFFFFFF) >= geometry_count)
-            rra_validation_fail(&ctx, "geometry_id >= geometry_count");
-      }
-
-      ctx.failed |= child_ctx.failed;
-   }
-   return ctx.failed;
-}
-
-struct rra_transcoding_context {
-   const uint8_t *src;
-   uint8_t *dst;
-   uint32_t dst_leaf_offset;
-   uint32_t dst_internal_offset;
-   uint32_t *parent_id_table;
-   uint32_t parent_id_table_size;
-   uint32_t *leaf_node_ids;
-   uint32_t *leaf_indices;
-};
-
-static void
-rra_transcode_triangle_node(struct rra_transcoding_context *ctx, const struct radv_bvh_triangle_node *src)
-{
-   struct rra_triangle_node *dst = (struct rra_triangle_node *)(ctx->dst + ctx->dst_leaf_offset);
-   ctx->dst_leaf_offset += sizeof(struct rra_triangle_node);
-
-   for (int i = 0; i < 3; ++i)
-      for (int j = 0; j < 3; ++j)
-         dst->coords[i][j] = src->coords[i][j];
-   dst->triangle_id = src->triangle_id;
-   dst->geometry_id = src->geometry_id_and_flags & 0xfffffff;
-   dst->flags = src->geometry_id_and_flags >> 28;
-   dst->id = src->id;
-}
-
-static void
-rra_transcode_aabb_node(struct rra_transcoding_context *ctx, const struct radv_bvh_aabb_node *src, vk_aabb bounds)
-{
-   struct rra_aabb_node *dst = (struct rra_aabb_node *)(ctx->dst + ctx->dst_leaf_offset);
-   ctx->dst_leaf_offset += sizeof(struct rra_aabb_node);
-
-   dst->aabb[0][0] = bounds.min.x;
-   dst->aabb[0][1] = bounds.min.y;
-   dst->aabb[0][2] = bounds.min.z;
-   dst->aabb[1][0] = bounds.max.x;
-   dst->aabb[1][1] = bounds.max.y;
-   dst->aabb[1][2] = bounds.max.z;
-
-   dst->geometry_id = src->geometry_id_and_flags & 0xfffffff;
-   dst->flags = src->geometry_id_and_flags >> 28;
-   dst->primitive_id = src->primitive_id;
-}
-
-static void
-rra_transcode_instance_node(struct rra_transcoding_context *ctx, const struct radv_bvh_instance_node *src)
-{
-   uint64_t blas_va = node_to_addr(src->bvh_ptr) - src->bvh_offset;
-
-   struct rra_instance_node *dst = (struct rra_instance_node *)(ctx->dst + ctx->dst_leaf_offset);
-   ctx->dst_leaf_offset += sizeof(struct rra_instance_node);
-
-   dst->custom_instance_id = src->custom_instance_and_mask & 0xffffff;
-   dst->mask = src->custom_instance_and_mask >> 24;
-   dst->sbt_offset = src->sbt_offset_and_flags & 0xffffff;
-   dst->instance_flags = src->sbt_offset_and_flags >> 24;
-   dst->blas_va = (blas_va + sizeof(struct rra_accel_struct_metadata)) >> 3;
-   dst->instance_id = src->instance_id;
-   dst->blas_metadata_size = sizeof(struct rra_accel_struct_metadata);
-
-   memcpy(dst->wto_matrix, src->wto_matrix.values, sizeof(dst->wto_matrix));
-   memcpy(dst->otw_matrix, src->otw_matrix.values, sizeof(dst->otw_matrix));
-}
-
-static uint32_t rra_transcode_node(struct rra_transcoding_context *ctx, uint32_t parent_id, uint32_t src_id,
-                                   vk_aabb bounds);
-
-static void
-rra_transcode_box16_node(struct rra_transcoding_context *ctx, const struct radv_bvh_box16_node *src)
-{
-   uint32_t dst_offset = ctx->dst_internal_offset;
-   ctx->dst_internal_offset += sizeof(struct rra_box16_node);
-   struct rra_box16_node *dst = (struct rra_box16_node *)(ctx->dst + dst_offset);
-
-   memcpy(dst->coords, src->coords, sizeof(dst->coords));
-
-   for (uint32_t i = 0; i < 4; ++i) {
-      if (src->children[i] == 0xffffffff) {
-         dst->children[i] = 0xffffffff;
-         continue;
-      }
-
-      vk_aabb bounds = {
-         .min =
-            {
-               _mesa_half_to_float(src->coords[i][0][0]),
-               _mesa_half_to_float(src->coords[i][0][1]),
-               _mesa_half_to_float(src->coords[i][0][2]),
-            },
-         .max =
-            {
-               _mesa_half_to_float(src->coords[i][1][0]),
-               _mesa_half_to_float(src->coords[i][1][1]),
-               _mesa_half_to_float(src->coords[i][1][2]),
-            },
-      };
-
-      dst->children[i] = rra_transcode_node(ctx, radv_bvh_node_box16 | (dst_offset >> 3), src->children[i], bounds);
-   }
-}
-
-static void
-rra_transcode_box32_node(struct rra_transcoding_context *ctx, const struct radv_bvh_box32_node *src)
-{
-   uint32_t dst_offset = ctx->dst_internal_offset;
-   ctx->dst_internal_offset += sizeof(struct rra_box32_node);
-   struct rra_box32_node *dst = (struct rra_box32_node *)(ctx->dst + dst_offset);
-
-   memcpy(dst->coords, src->coords, sizeof(dst->coords));
-
-   for (uint32_t i = 0; i < 4; ++i) {
-      if (isnan(src->coords[i].min.x)) {
-         dst->children[i] = 0xffffffff;
-         continue;
-      }
-
-      dst->children[i] =
-         rra_transcode_node(ctx, radv_bvh_node_box32 | (dst_offset >> 3), src->children[i], src->coords[i]);
-   }
-}
-
-static uint32_t
-get_geometry_id(const void *node, uint32_t node_type)
-{
-   if (node_type == radv_bvh_node_triangle) {
-      const struct radv_bvh_triangle_node *triangle = node;
-      return triangle->geometry_id_and_flags & 0xFFFFFFF;
-   }
-
-   if (node_type == radv_bvh_node_aabb) {
-      const struct radv_bvh_aabb_node *aabb = node;
-      return aabb->geometry_id_and_flags & 0xFFFFFFF;
-   }
-
-   return 0;
-}
-
-static uint32_t
-rra_transcode_node(struct rra_transcoding_context *ctx, uint32_t parent_id, uint32_t src_id, vk_aabb bounds)
-{
-   uint32_t node_type = src_id & 7;
-   uint32_t src_offset = (src_id & (~7u)) << 3;
-
-   uint32_t dst_offset;
-
-   const void *src_child_node = ctx->src + src_offset;
-   if (is_internal_node(node_type)) {
-      dst_offset = ctx->dst_internal_offset;
-      if (node_type == radv_bvh_node_box32)
-         rra_transcode_box32_node(ctx, src_child_node);
-      else
-         rra_transcode_box16_node(ctx, src_child_node);
-   } else {
-      dst_offset = ctx->dst_leaf_offset;
-
-      if (node_type == radv_bvh_node_triangle)
-         rra_transcode_triangle_node(ctx, src_child_node);
-      else if (node_type == radv_bvh_node_aabb)
-         rra_transcode_aabb_node(ctx, src_child_node, bounds);
-      else if (node_type == radv_bvh_node_instance)
-         rra_transcode_instance_node(ctx, src_child_node);
-   }
-
-   uint32_t parent_id_index = rra_parent_table_index_from_offset(dst_offset, ctx->parent_id_table_size);
-   ctx->parent_id_table[parent_id_index] = parent_id;
-
-   uint32_t dst_id = node_type | (dst_offset >> 3);
-   if (!is_internal_node(node_type))
-      ctx->leaf_node_ids[ctx->leaf_indices[get_geometry_id(src_child_node, node_type)]++] = dst_id;
-
-   return dst_id;
-}
-
-struct rra_bvh_info {
-   uint32_t leaf_nodes_size;
-   uint32_t internal_nodes_size;
-   struct rra_geometry_info *geometry_infos;
-};
-
-static void
-rra_gather_bvh_info(const uint8_t *bvh, uint32_t node_id, struct rra_bvh_info *dst)
-{
-   uint32_t node_type = node_id & 7;
-
-   switch (node_type) {
-   case radv_bvh_node_box16:
-      dst->internal_nodes_size += sizeof(struct rra_box16_node);
-      break;
-   case radv_bvh_node_box32:
-      dst->internal_nodes_size += sizeof(struct rra_box32_node);
-      break;
-   case radv_bvh_node_instance:
-      dst->leaf_nodes_size += sizeof(struct rra_instance_node);
-      break;
-   case radv_bvh_node_triangle:
-      dst->leaf_nodes_size += sizeof(struct rra_triangle_node);
-      break;
-   case radv_bvh_node_aabb:
-      dst->leaf_nodes_size += sizeof(struct rra_aabb_node);
-      break;
-   default:
-      break;
-   }
-
-   const void *node = bvh + ((node_id & (~7u)) << 3);
-   if (is_internal_node(node_type)) {
-      /* The child ids are located at offset=0 for both box16 and box32 nodes. */
-      const uint32_t *children = node;
-      for (uint32_t i = 0; i < 4; i++)
-         if (children[i] != 0xffffffff)
-            rra_gather_bvh_info(bvh, children[i], dst);
-   } else {
-      dst->geometry_infos[get_geometry_id(node, node_type)].primitive_count++;
-   }
-}
-
 static VkResult
-rra_dump_acceleration_structure(struct radv_rra_accel_struct_data *accel_struct, uint8_t *data,
+rra_dump_acceleration_structure(const struct radv_physical_device *pdev,
+                                struct radv_rra_accel_struct_data *accel_struct, uint8_t *data,
                                 struct hash_table_u64 *accel_struct_vas, bool should_validate, FILE *output)
 {
    struct radv_accel_struct_header *header = (struct radv_accel_struct_header *)data;
@@ -748,9 +305,18 @@ rra_dump_acceleration_structure(struct radv_rra_accel_struct_data *accel_struct,
       if (rra_validate_header(accel_struct, header)) {
          return VK_ERROR_VALIDATION_FAILED_EXT;
       }
-      if (rra_validate_node(accel_struct_vas, data + header->bvh_offset, data + header->bvh_offset + src_root_offset,
-                            header->geometry_count, accel_struct->size, !is_tlas, 0)) {
-         return VK_ERROR_VALIDATION_FAILED_EXT;
+      if (radv_use_bvh8(pdev)) {
+         if (rra_validate_node_gfx12(accel_struct_vas, data + header->bvh_offset,
+                                     data + header->bvh_offset + src_root_offset, header->geometry_count,
+                                     accel_struct->size, !is_tlas, 0)) {
+            return VK_ERROR_VALIDATION_FAILED_EXT;
+         }
+      } else {
+         if (rra_validate_node_gfx10_3(accel_struct_vas, data + header->bvh_offset,
+                                       data + header->bvh_offset + src_root_offset, header->geometry_count,
+                                       accel_struct->size, !is_tlas, 0)) {
+            return VK_ERROR_VALIDATION_FAILED_EXT;
+         }
       }
    }
 
@@ -771,7 +337,10 @@ rra_dump_acceleration_structure(struct radv_rra_accel_struct_data *accel_struct,
    struct rra_bvh_info bvh_info = {
       .geometry_infos = rra_geometry_infos,
    };
-   rra_gather_bvh_info(data + header->bvh_offset, RADV_BVH_ROOT_NODE, &bvh_info);
+   if (radv_use_bvh8(pdev))
+      rra_gather_bvh_info_gfx12(data + header->bvh_offset, RADV_BVH_ROOT_NODE, &bvh_info);
+   else
+      rra_gather_bvh_info_gfx10_3(data + header->bvh_offset, RADV_BVH_ROOT_NODE, &bvh_info);
 
    leaf_indices = calloc(header->geometry_count, sizeof(struct rra_geometry_info));
    if (!leaf_indices) {
@@ -793,6 +362,8 @@ rra_dump_acceleration_structure(struct radv_rra_accel_struct_data *accel_struct,
 
    uint32_t node_parent_table_size =
       ((bvh_info.leaf_nodes_size + bvh_info.internal_nodes_size) / 64) * sizeof(uint32_t);
+   if (radv_use_bvh8(pdev))
+      node_parent_table_size = 0;
 
    node_parent_table = calloc(node_parent_table_size, 1);
    if (!node_parent_table) {
@@ -805,7 +376,9 @@ rra_dump_acceleration_structure(struct radv_rra_accel_struct_data *accel_struct,
       result = VK_ERROR_OUT_OF_HOST_MEMORY;
       goto exit;
    }
-   dst_structure_data = calloc(RRA_ROOT_NODE_OFFSET + bvh_info.internal_nodes_size + bvh_info.leaf_nodes_size, 1);
+   dst_structure_data = calloc(RRA_ROOT_NODE_OFFSET + bvh_info.internal_nodes_size + bvh_info.leaf_nodes_size +
+                                  bvh_info.instance_sideband_data_size,
+                               1);
    if (!dst_structure_data) {
       result = VK_ERROR_OUT_OF_HOST_MEMORY;
       goto exit;
@@ -816,13 +389,20 @@ rra_dump_acceleration_structure(struct radv_rra_accel_struct_data *accel_struct,
       .dst = dst_structure_data,
       .dst_leaf_offset = RRA_ROOT_NODE_OFFSET + bvh_info.internal_nodes_size,
       .dst_internal_offset = RRA_ROOT_NODE_OFFSET,
+      .dst_instance_sideband_data_offset =
+         RRA_ROOT_NODE_OFFSET + bvh_info.internal_nodes_size + bvh_info.leaf_nodes_size,
       .parent_id_table = node_parent_table,
       .parent_id_table_size = node_parent_table_size,
       .leaf_node_ids = leaf_node_ids,
       .leaf_indices = leaf_indices,
    };
 
-   rra_transcode_node(&ctx, 0xFFFFFFFF, RADV_BVH_ROOT_NODE, header->aabb);
+   if (radv_use_bvh8(pdev)) {
+      ctx.dst_internal_offset += sizeof(struct radv_gfx12_box_node);
+      rra_transcode_node_gfx12(&ctx, 0xFFFFFFFF, RADV_BVH_ROOT_NODE, RRA_ROOT_NODE_OFFSET);
+   } else {
+      rra_transcode_node_gfx10_3(&ctx, 0xFFFFFFFF, RADV_BVH_ROOT_NODE, header->aabb);
+   }
 
    struct rra_accel_struct_chunk_header chunk_header = {
       .metadata_offset = 0,
@@ -845,8 +425,12 @@ rra_dump_acceleration_structure(struct radv_rra_accel_struct_data *accel_struct,
     * the top bits are masked away.
     * In order to make sure BLASes can be found in the hashmap, we have
     * to replicate that mask here.
+    * On GFX12, we mask away the top 16 bits because the instance BLAS addresses
+    * use pointer flags.
     */
    uint64_t va = accel_struct->va & 0x1FFFFFFFFFFFFFF;
+   if (radv_use_bvh8(pdev))
+      va &= 0xFFFFFFFFFFFF;
    memcpy(chunk_header.virtual_address, &va, sizeof(uint64_t));
 
    struct rra_accel_struct_metadata rra_metadata = {
@@ -861,15 +445,13 @@ rra_dump_acceleration_structure(struct radv_rra_accel_struct_data *accel_struct,
    fwrite(node_parent_table, 1, node_parent_table_size, output);
 
    if (is_tlas)
-      rra_dump_tlas_header(header, node_parent_table_size, bvh_info.leaf_nodes_size, bvh_info.internal_nodes_size,
-                           primitive_count, output);
+      rra_dump_tlas_header(pdev, header, node_parent_table_size, &bvh_info, primitive_count, output);
    else
-      rra_dump_blas_header(header, node_parent_table_size, geometry_infos, bvh_info.leaf_nodes_size,
-                           bvh_info.internal_nodes_size, primitive_count, output);
+      rra_dump_blas_header(pdev, header, node_parent_table_size, geometry_infos, &bvh_info, primitive_count, output);
 
    /* Write acceleration structure data  */
-   fwrite(dst_structure_data + RRA_ROOT_NODE_OFFSET, 1, bvh_info.internal_nodes_size + bvh_info.leaf_nodes_size,
-          output);
+   fwrite(dst_structure_data + RRA_ROOT_NODE_OFFSET, 1,
+          bvh_info.internal_nodes_size + bvh_info.leaf_nodes_size + bvh_info.instance_sideband_data_size, output);
 
    if (!is_tlas)
       fwrite(rra_geometry_infos, sizeof(struct rra_geometry_info), header->geometry_count, output);
@@ -1424,7 +1006,7 @@ radv_rra_dump_trace(VkQueue vk_queue, char *filename)
          continue;
 
       accel_struct_offsets[written_accel_struct_count] = (uint64_t)ftell(file);
-      result = rra_dump_acceleration_structure(data, mapped_data, device->rra_trace.accel_struct_vas,
+      result = rra_dump_acceleration_structure(pdev, data, mapped_data, device->rra_trace.accel_struct_vas,
                                                device->rra_trace.validate_as, file);
 
       rra_unmap_accel_struct_data(&copy_ctx, i);
diff --git a/src/amd/vulkan/radv_rra.h b/src/amd/vulkan/radv_rra.h
index f0669b8e227..c5af1d8f735 100644
--- a/src/amd/vulkan/radv_rra.h
+++ b/src/amd/vulkan/radv_rra.h
@@ -11,8 +11,12 @@
 #ifndef RADV_RRA_H
 #define RADV_RRA_H
 
+#include "util/hash_table.h"
 #include "util/simple_mtx.h"
 #include "util/u_dynarray.h"
+#include "util/u_math.h"
+
+#include "bvh/vk_bvh.h"
 
 #include <vulkan/vulkan.h>
 
@@ -183,4 +187,134 @@ void radv_destroy_rra_accel_struct_data(VkDevice device, struct radv_rra_accel_s
 
 VkResult radv_rra_dump_trace(VkQueue vk_queue, char *filename);
 
+enum rra_bvh_type {
+   RRA_BVH_TYPE_TLAS,
+   RRA_BVH_TYPE_BLAS,
+};
+
+struct rra_accel_struct_chunk_header {
+   /*
+    * Declaring this as uint64_t would make the compiler insert padding to
+    * satisfy alignment restrictions.
+    */
+   uint32_t virtual_address[2];
+   uint32_t metadata_offset;
+   uint32_t metadata_size;
+   uint32_t header_offset;
+   uint32_t header_size;
+   enum rra_bvh_type bvh_type;
+};
+
+static_assert(sizeof(struct rra_accel_struct_chunk_header) == 28,
+              "rra_accel_struct_chunk_header does not match RRA spec");
+
+struct rra_accel_struct_post_build_info {
+   uint32_t bvh_type : 1;
+   uint32_t reserved1 : 5;
+   uint32_t tri_compression_mode : 2;
+   uint32_t fp16_interior_mode : 2;
+   uint32_t reserved2 : 6;
+   uint32_t build_flags : 16;
+};
+
+static_assert(sizeof(struct rra_accel_struct_post_build_info) == 4,
+              "rra_accel_struct_post_build_info does not match RRA spec");
+
+struct rra_accel_struct_header {
+   struct rra_accel_struct_post_build_info post_build_info;
+   /*
+    * Size of the internal acceleration structure metadata in the
+    * proprietary drivers. Seems to always be 128.
+    */
+   uint32_t metadata_size;
+   uint32_t file_size;
+   uint32_t primitive_count;
+   uint32_t active_primitive_count;
+   uint32_t unused1;
+   uint32_t geometry_description_count;
+   VkGeometryTypeKHR geometry_type;
+   uint32_t internal_nodes_offset;
+   uint32_t leaf_nodes_offset;
+   uint32_t geometry_infos_offset;
+   uint32_t leaf_ids_offset;
+   uint32_t interior_fp32_node_count;
+   uint32_t interior_fp16_node_count;
+   uint32_t leaf_node_count;
+   uint32_t rt_driver_interface_version;
+   uint64_t unused2;
+   uint32_t rt_ip_version;
+   char unused3[44];
+};
+
+static_assert(sizeof(struct rra_accel_struct_header) == 120, "rra_accel_struct_header does not match RRA spec");
+
+struct rra_accel_struct_metadata {
+   uint64_t virtual_address;
+   uint32_t byte_size;
+   char unused[116];
+};
+
+static_assert(sizeof(struct rra_accel_struct_metadata) == 128, "rra_accel_struct_metadata does not match RRA spec");
+
+struct rra_geometry_info {
+   uint32_t primitive_count : 29;
+   uint32_t flags : 3;
+   uint32_t unknown;
+   uint32_t leaf_node_list_offset;
+};
+
+static_assert(sizeof(struct rra_geometry_info) == 12, "rra_geometry_info does not match RRA spec");
+
+#define RRA_ROOT_NODE_OFFSET align(sizeof(struct rra_accel_struct_header), 64)
+
+struct rra_validation_context {
+   bool failed;
+   char location[31];
+};
+
+void PRINTFLIKE(2, 3) rra_validation_fail(struct rra_validation_context *ctx, const char *message, ...);
+
+static inline uint64_t
+radv_node_to_addr(uint64_t node)
+{
+   node &= ~7ull;
+   node <<= 19;
+   return ((int64_t)node) >> 16;
+}
+
+struct rra_bvh_info {
+   uint32_t leaf_nodes_size;
+   uint32_t internal_nodes_size;
+   uint32_t instance_sideband_data_size;
+   struct rra_geometry_info *geometry_infos;
+};
+
+struct rra_transcoding_context {
+   const uint8_t *src;
+   uint8_t *dst;
+   uint32_t dst_leaf_offset;
+   uint32_t dst_internal_offset;
+   uint32_t dst_instance_sideband_data_offset;
+   uint32_t *parent_id_table;
+   uint32_t parent_id_table_size;
+   uint32_t *leaf_node_ids;
+   uint32_t *leaf_indices;
+};
+
+bool rra_validate_node_gfx10_3(struct hash_table_u64 *accel_struct_vas, uint8_t *data, void *node,
+                               uint32_t geometry_count, uint32_t size, bool is_bottom_level, uint32_t depth);
+
+void rra_gather_bvh_info_gfx10_3(const uint8_t *bvh, uint32_t node_id, struct rra_bvh_info *dst);
+
+uint32_t rra_transcode_node_gfx10_3(struct rra_transcoding_context *ctx, uint32_t parent_id, uint32_t src_id,
+                                    vk_aabb bounds);
+
+bool rra_validate_node_gfx12(struct hash_table_u64 *accel_struct_vas, uint8_t *data, void *node,
+                             uint32_t geometry_count, uint32_t size, bool is_bottom_level, uint32_t depth);
+
+void rra_gather_bvh_info_gfx12(const uint8_t *bvh, uint32_t node_id, struct rra_bvh_info *dst);
+
+void rra_transcode_node_gfx12(struct rra_transcoding_context *ctx, uint32_t parent_id, uint32_t src_id,
+                              uint32_t dst_offset);
+
 #endif /* RADV_RRA_H */
diff --git a/src/amd/vulkan/radv_rra_gfx10_3.c b/src/amd/vulkan/radv_rra_gfx10_3.c
new file mode 100644
index 00000000000..14cee1bbe75
--- /dev/null
+++ b/src/amd/vulkan/radv_rra_gfx10_3.c
@@ -0,0 +1,351 @@
+/*
+ * Copyright Â© 2022 Friedrich Vock
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+/* GFX10_3-GFX11 specific code for RRA. */
+
+#include "bvh/bvh.h"
+#include "radv_rra.h"
+
+#include "util/half_float.h"
+
+struct rra_box32_node {
+   uint32_t children[4];
+   float coords[4][2][3];
+   uint32_t reserved[4];
+};
+
+struct rra_box16_node {
+   uint32_t children[4];
+   float16_t coords[4][2][3];
+};
+
+/*
+ * RRA files contain this struct in place of hardware
+ * instance nodes. They're named "instance desc" internally.
+ */
+struct rra_instance_node {
+   float wto_matrix[12];
+   uint32_t custom_instance_id : 24;
+   uint32_t mask : 8;
+   uint32_t sbt_offset : 24;
+   uint32_t instance_flags : 8;
+   uint64_t blas_va : 54;
+   uint64_t hw_instance_flags : 10;
+   uint32_t instance_id;
+   uint32_t unused1;
+   uint32_t blas_metadata_size;
+   uint32_t unused2;
+   float otw_matrix[12];
+};
+
+static_assert(sizeof(struct rra_instance_node) == 128, "rra_instance_node does not match RRA spec!");
+
+/*
+ * Format RRA uses for aabb nodes
+ */
+struct rra_aabb_node {
+   float aabb[2][3];
+   uint32_t unused1[6];
+   uint32_t geometry_id : 28;
+   uint32_t flags : 4;
+   uint32_t primitive_id;
+   uint32_t unused[2];
+};
+
+static_assert(sizeof(struct rra_aabb_node) == 64, "rra_aabb_node does not match RRA spec!");
+
+struct rra_triangle_node {
+   float coords[3][3];
+   uint32_t reserved[3];
+   uint32_t geometry_id : 28;
+   uint32_t flags : 4;
+   uint32_t triangle_id;
+   uint32_t reserved2;
+   uint32_t id;
+};
+
+static_assert(sizeof(struct rra_triangle_node) == 64, "rra_triangle_node does not match RRA spec!");
+
+static uint32_t
+rra_parent_table_index_from_offset(uint32_t offset, uint32_t parent_table_size)
+{
+   uint32_t max_parent_table_index = parent_table_size / sizeof(uint32_t) - 1;
+   return max_parent_table_index - (offset - RRA_ROOT_NODE_OFFSET) / 64;
+}
+
+static bool
+is_internal_node(uint32_t type)
+{
+   return type == radv_bvh_node_box16 || type == radv_bvh_node_box32;
+}
+
+static const char *node_type_names[8] = {
+   [radv_bvh_node_triangle + 0] = "triangle0",
+   [radv_bvh_node_triangle + 1] = "triangle1",
+   [radv_bvh_node_triangle + 2] = "triangle2",
+   [radv_bvh_node_triangle + 3] = "triangle3",
+   [radv_bvh_node_box16] = "box16",
+   [radv_bvh_node_box32] = "box32",
+   [radv_bvh_node_instance] = "instance",
+   [radv_bvh_node_aabb] = "aabb",
+};
+
+bool
+rra_validate_node_gfx10_3(struct hash_table_u64 *accel_struct_vas, uint8_t *data, void *node, uint32_t geometry_count,
+                          uint32_t size, bool is_bottom_level, uint32_t depth)
+{
+   struct rra_validation_context ctx = {0};
+
+   if (depth > 1024) {
+      rra_validation_fail(&ctx, "depth > 1024");
+      return true;
+   }
+
+   uint32_t cur_offset = (uint8_t *)node - data;
+   snprintf(ctx.location, sizeof(ctx.location), "internal node (offset=%u)", cur_offset);
+
+   /* The child ids are located at offset=0 for both box16 and box32 nodes. */
+   uint32_t *children = node;
+   for (uint32_t i = 0; i < 4; ++i) {
+      if (children[i] == 0xFFFFFFFF)
+         continue;
+
+      uint32_t type = children[i] & 7;
+      uint32_t offset = (children[i] & (~7u)) << 3;
+
+      if (!is_internal_node(type) && is_bottom_level == (type == radv_bvh_node_instance))
+         rra_validation_fail(&ctx,
+                             is_bottom_level ? "%s node in BLAS (child index %u)" : "%s node in TLAS (child index %u)",
+                             node_type_names[type], i);
+
+      if (offset > size) {
+         rra_validation_fail(&ctx, "Invalid child offset (child index %u)", i);
+         continue;
+      }
+
+      struct rra_validation_context child_ctx = {0};
+      snprintf(child_ctx.location, sizeof(child_ctx.location), "%s node (offset=%u)", node_type_names[type], offset);
+
+      if (is_internal_node(type)) {
+         ctx.failed |= rra_validate_node_gfx10_3(accel_struct_vas, data, data + offset, geometry_count, size,
+                                                 is_bottom_level, depth + 1);
+      } else if (type == radv_bvh_node_instance) {
+         struct radv_bvh_instance_node *src = (struct radv_bvh_instance_node *)(data + offset);
+         uint64_t blas_va = radv_node_to_addr(src->bvh_ptr) - src->bvh_offset;
+         if (!_mesa_hash_table_u64_search(accel_struct_vas, blas_va))
+            rra_validation_fail(&child_ctx, "Invalid instance node pointer 0x%llx (offset: 0x%x)",
+                                (unsigned long long)src->bvh_ptr, src->bvh_offset);
+      } else if (type == radv_bvh_node_aabb) {
+         struct radv_bvh_aabb_node *src = (struct radv_bvh_aabb_node *)(data + offset);
+         if ((src->geometry_id_and_flags & 0xFFFFFFF) >= geometry_count)
+            rra_validation_fail(&ctx, "geometry_id >= geometry_count");
+      } else {
+         struct radv_bvh_triangle_node *src = (struct radv_bvh_triangle_node *)(data + offset);
+         if ((src->geometry_id_and_flags & 0xFFFFFFF) >= geometry_count)
+            rra_validation_fail(&ctx, "geometry_id >= geometry_count");
+      }
+
+      ctx.failed |= child_ctx.failed;
+   }
+   return ctx.failed;
+}
+
+static uint32_t
+get_geometry_id(const void *node, uint32_t node_type)
+{
+   if (node_type == radv_bvh_node_triangle) {
+      const struct radv_bvh_triangle_node *triangle = node;
+      return triangle->geometry_id_and_flags & 0xFFFFFFF;
+   }
+
+   if (node_type == radv_bvh_node_aabb) {
+      const struct radv_bvh_aabb_node *aabb = node;
+      return aabb->geometry_id_and_flags & 0xFFFFFFF;
+   }
+
+   return 0;
+}
+
+void
+rra_gather_bvh_info_gfx10_3(const uint8_t *bvh, uint32_t node_id, struct rra_bvh_info *dst)
+{
+   uint32_t node_type = node_id & 7;
+
+   switch (node_type) {
+   case radv_bvh_node_box16:
+      dst->internal_nodes_size += sizeof(struct rra_box16_node);
+      break;
+   case radv_bvh_node_box32:
+      dst->internal_nodes_size += sizeof(struct rra_box32_node);
+      break;
+   case radv_bvh_node_instance:
+      dst->leaf_nodes_size += sizeof(struct rra_instance_node);
+      break;
+   case radv_bvh_node_triangle:
+      dst->leaf_nodes_size += sizeof(struct rra_triangle_node);
+      break;
+   case radv_bvh_node_aabb:
+      dst->leaf_nodes_size += sizeof(struct rra_aabb_node);
+      break;
+   default:
+      break;
+   }
+
+   const void *node = bvh + ((node_id & (~7u)) << 3);
+   if (is_internal_node(node_type)) {
+      /* The child ids are located at offset=0 for both box16 and box32 nodes. */
+      const uint32_t *children = node;
+      for (uint32_t i = 0; i < 4; i++)
+         if (children[i] != 0xffffffff)
+            rra_gather_bvh_info_gfx10_3(bvh, children[i], dst);
+   } else {
+      dst->geometry_infos[get_geometry_id(node, node_type)].primitive_count++;
+   }
+}
+
+static void
+rra_transcode_triangle_node(struct rra_transcoding_context *ctx, const struct radv_bvh_triangle_node *src)
+{
+   struct rra_triangle_node *dst = (struct rra_triangle_node *)(ctx->dst + ctx->dst_leaf_offset);
+   ctx->dst_leaf_offset += sizeof(struct rra_triangle_node);
+
+   for (int i = 0; i < 3; ++i)
+      for (int j = 0; j < 3; ++j)
+         dst->coords[i][j] = src->coords[i][j];
+   dst->triangle_id = src->triangle_id;
+   dst->geometry_id = src->geometry_id_and_flags & 0xfffffff;
+   dst->flags = src->geometry_id_and_flags >> 28;
+   dst->id = src->id;
+}
+
+static void
+rra_transcode_aabb_node(struct rra_transcoding_context *ctx, const struct radv_bvh_aabb_node *src, vk_aabb bounds)
+{
+   struct rra_aabb_node *dst = (struct rra_aabb_node *)(ctx->dst + ctx->dst_leaf_offset);
+   ctx->dst_leaf_offset += sizeof(struct rra_aabb_node);
+
+   dst->aabb[0][0] = bounds.min.x;
+   dst->aabb[0][1] = bounds.min.y;
+   dst->aabb[0][2] = bounds.min.z;
+   dst->aabb[1][0] = bounds.max.x;
+   dst->aabb[1][1] = bounds.max.y;
+   dst->aabb[1][2] = bounds.max.z;
+
+   dst->geometry_id = src->geometry_id_and_flags & 0xfffffff;
+   dst->flags = src->geometry_id_and_flags >> 28;
+   dst->primitive_id = src->primitive_id;
+}
+
+static void
+rra_transcode_instance_node(struct rra_transcoding_context *ctx, const struct radv_bvh_instance_node *src)
+{
+   uint64_t blas_va = radv_node_to_addr(src->bvh_ptr) - src->bvh_offset;
+
+   struct rra_instance_node *dst = (struct rra_instance_node *)(ctx->dst + ctx->dst_leaf_offset);
+   ctx->dst_leaf_offset += sizeof(struct rra_instance_node);
+
+   dst->custom_instance_id = src->custom_instance_and_mask & 0xffffff;
+   dst->mask = src->custom_instance_and_mask >> 24;
+   dst->sbt_offset = src->sbt_offset_and_flags & 0xffffff;
+   dst->instance_flags = src->sbt_offset_and_flags >> 24;
+   dst->blas_va = (blas_va + sizeof(struct rra_accel_struct_metadata)) >> 3;
+   dst->instance_id = src->instance_id;
+   dst->blas_metadata_size = sizeof(struct rra_accel_struct_metadata);
+
+   memcpy(dst->wto_matrix, src->wto_matrix.values, sizeof(dst->wto_matrix));
+   memcpy(dst->otw_matrix, src->otw_matrix.values, sizeof(dst->otw_matrix));
+}
+
+static void
+rra_transcode_box16_node(struct rra_transcoding_context *ctx, const struct radv_bvh_box16_node *src)
+{
+   uint32_t dst_offset = ctx->dst_internal_offset;
+   ctx->dst_internal_offset += sizeof(struct rra_box16_node);
+   struct rra_box16_node *dst = (struct rra_box16_node *)(ctx->dst + dst_offset);
+
+   memcpy(dst->coords, src->coords, sizeof(dst->coords));
+
+   for (uint32_t i = 0; i < 4; ++i) {
+      if (src->children[i] == 0xffffffff) {
+         dst->children[i] = 0xffffffff;
+         continue;
+      }
+
+      vk_aabb bounds = {
+         .min =
+            {
+               _mesa_half_to_float(src->coords[i][0][0]),
+               _mesa_half_to_float(src->coords[i][0][1]),
+               _mesa_half_to_float(src->coords[i][0][2]),
+            },
+         .max =
+            {
+               _mesa_half_to_float(src->coords[i][1][0]),
+               _mesa_half_to_float(src->coords[i][1][1]),
+               _mesa_half_to_float(src->coords[i][1][2]),
+            },
+      };
+
+      dst->children[i] =
+         rra_transcode_node_gfx10_3(ctx, radv_bvh_node_box16 | (dst_offset >> 3), src->children[i], bounds);
+   }
+}
+
+static void
+rra_transcode_box32_node(struct rra_transcoding_context *ctx, const struct radv_bvh_box32_node *src)
+{
+   uint32_t dst_offset = ctx->dst_internal_offset;
+   ctx->dst_internal_offset += sizeof(struct rra_box32_node);
+   struct rra_box32_node *dst = (struct rra_box32_node *)(ctx->dst + dst_offset);
+
+   memcpy(dst->coords, src->coords, sizeof(dst->coords));
+
+   for (uint32_t i = 0; i < 4; ++i) {
+      if (isnan(src->coords[i].min.x)) {
+         dst->children[i] = 0xffffffff;
+         continue;
+      }
+
+      dst->children[i] =
+         rra_transcode_node_gfx10_3(ctx, radv_bvh_node_box32 | (dst_offset >> 3), src->children[i], src->coords[i]);
+   }
+}
+
+uint32_t
+rra_transcode_node_gfx10_3(struct rra_transcoding_context *ctx, uint32_t parent_id, uint32_t src_id, vk_aabb bounds)
+{
+   uint32_t node_type = src_id & 7;
+   uint32_t src_offset = (src_id & (~7u)) << 3;
+
+   uint32_t dst_offset;
+
+   const void *src_child_node = ctx->src + src_offset;
+   if (is_internal_node(node_type)) {
+      dst_offset = ctx->dst_internal_offset;
+      if (node_type == radv_bvh_node_box32)
+         rra_transcode_box32_node(ctx, src_child_node);
+      else
+         rra_transcode_box16_node(ctx, src_child_node);
+   } else {
+      dst_offset = ctx->dst_leaf_offset;
+
+      if (node_type == radv_bvh_node_triangle)
+         rra_transcode_triangle_node(ctx, src_child_node);
+      else if (node_type == radv_bvh_node_aabb)
+         rra_transcode_aabb_node(ctx, src_child_node, bounds);
+      else if (node_type == radv_bvh_node_instance)
+         rra_transcode_instance_node(ctx, src_child_node);
+   }
+
+   uint32_t parent_id_index = rra_parent_table_index_from_offset(dst_offset, ctx->parent_id_table_size);
+   ctx->parent_id_table[parent_id_index] = parent_id;
+
+   uint32_t dst_id = node_type | (dst_offset >> 3);
+   if (!is_internal_node(node_type))
+      ctx->leaf_node_ids[ctx->leaf_indices[get_geometry_id(src_child_node, node_type)]++] = dst_id;
+
+   return dst_id;
+}
diff --git a/src/amd/vulkan/radv_rra_gfx12.c b/src/amd/vulkan/radv_rra_gfx12.c
new file mode 100644
index 00000000000..4cad241a38b
--- /dev/null
+++ b/src/amd/vulkan/radv_rra_gfx12.c
@@ -0,0 +1,184 @@
+/*
+ * Copyright Â© 2025 Valve Corporation
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+/* GFX12 specific code for RRA. */
+
+#include "bvh/bvh.h"
+#include "radv_rra.h"
+
+#include "util/bitset.h"
+
+struct rra_instance_sideband_data {
+   uint32_t instance_index;
+   uint32_t custom_instance_and_flags;
+   uint32_t blas_metadata_size;
+   uint32_t padding;
+   mat3x4 otw_matrix;
+};
+
+bool
+rra_validate_node_gfx12(struct hash_table_u64 *accel_struct_vas, uint8_t *data, void *node, uint32_t geometry_count,
+                        uint32_t size, bool is_bottom_level, uint32_t depth)
+{
+   struct rra_validation_context ctx = {0};
+
+   if (depth > 1024) {
+      rra_validation_fail(&ctx, "depth > 1024");
+      return true;
+   }
+
+   uint32_t cur_offset = (uint8_t *)node - data;
+   snprintf(ctx.location, sizeof(ctx.location), "internal node (offset=%u)", cur_offset);
+
+   return ctx.failed;
+}
+
+static uint32_t
+get_geometry_id(const void *node, uint32_t node_type)
+{
+   if (node_type == radv_bvh_node_instance)
+      return 0;
+
+   uint32_t indices_midpoint = BITSET_EXTRACT(node, 42, 10);
+   return BITSET_EXTRACT(node, indices_midpoint - 28, 28);
+}
+
+void
+rra_gather_bvh_info_gfx12(const uint8_t *bvh, uint32_t node_id, struct rra_bvh_info *dst)
+{
+   uint32_t node_type = node_id & 7;
+
+   switch (node_type) {
+   case radv_bvh_node_box32:
+      dst->internal_nodes_size += sizeof(struct radv_gfx12_box_node);
+      break;
+   case radv_bvh_node_instance:
+      dst->leaf_nodes_size += sizeof(struct radv_gfx12_instance_node);
+      dst->instance_sideband_data_size += sizeof(struct rra_instance_sideband_data);
+      break;
+   case radv_bvh_node_triangle:
+      dst->leaf_nodes_size += sizeof(struct radv_gfx12_primitive_node);
+      break;
+   default:
+      unreachable("Invalid node type");
+      break;
+   }
+
+   const void *node = bvh + ((node_id & (~7u)) << 3);
+   if (node_type == radv_bvh_node_box32) {
+      const struct radv_gfx12_box_node *src = node;
+
+      uint32_t valid_child_count_minus_one = src->child_count_exponents >> 28;
+
+      uint32_t internal_id = src->internal_base_id;
+      uint32_t primitive_id = src->primitive_base_id;
+      for (uint32_t i = 0; i <= valid_child_count_minus_one; i++) {
+         uint32_t child_type = (src->children[i].dword2 >> 24) & 0xf;
+         uint32_t child_size = src->children[i].dword2 >> 28;
+
+         uint32_t child_id;
+         if (child_type == radv_bvh_node_box32) {
+            child_id = internal_id | child_type;
+            internal_id += (child_size * RADV_GFX12_BVH_NODE_SIZE) >> 3;
+         } else {
+            child_id = primitive_id | child_type;
+            primitive_id += (child_size * RADV_GFX12_BVH_NODE_SIZE) >> 3;
+         }
+
+         rra_gather_bvh_info_gfx12(bvh, child_id, dst);
+      }
+   } else {
+      dst->geometry_infos[get_geometry_id(node, node_type)].primitive_count++;
+   }
+}
+
+static void
+rra_transcode_box8_node(struct rra_transcoding_context *ctx, const struct radv_gfx12_box_node *src, uint32_t parent_id,
+                        uint32_t dst_offset)
+{
+   struct radv_gfx12_box_node *dst = (struct radv_gfx12_box_node *)(ctx->dst + dst_offset);
+
+   memcpy(dst, src, sizeof(struct radv_gfx12_box_node));
+   dst->internal_base_id = ctx->dst_internal_offset >> 3;
+   dst->primitive_base_id = ctx->dst_leaf_offset >> 3;
+   dst->unused = parent_id;
+
+   uint32_t valid_child_count_minus_one = dst->child_count_exponents >> 28;
+
+   uint32_t internal_child_count = 0;
+   uint32_t leaf_child_count = 0;
+   for (uint32_t i = 0; i <= valid_child_count_minus_one; ++i) {
+      uint32_t child_type = (src->children[i].dword2 >> 24) & 0xf;
+      if (child_type == radv_bvh_node_box32)
+         internal_child_count++;
+      else
+         leaf_child_count++;
+   }
+
+   uint32_t dst_internal_offset = ctx->dst_internal_offset;
+   ctx->dst_internal_offset += internal_child_count * RADV_GFX12_BVH_NODE_SIZE;
+
+   uint32_t dst_leaf_offset = ctx->dst_leaf_offset;
+   ctx->dst_leaf_offset += leaf_child_count * RADV_GFX12_BVH_NODE_SIZE;
+
+   uint32_t internal_id = src->internal_base_id;
+   uint32_t primitive_id = src->primitive_base_id;
+   for (uint32_t i = 0; i <= valid_child_count_minus_one; ++i) {
+      uint32_t child_type = (src->children[i].dword2 >> 24) & 0xf;
+      uint32_t child_size = src->children[i].dword2 >> 28;
+
+      uint32_t child_id;
+      uint32_t child_dst_offset;
+      if (child_type == radv_bvh_node_box32) {
+         child_id = internal_id | child_type;
+         internal_id += (child_size * RADV_GFX12_BVH_NODE_SIZE) >> 3;
+         child_dst_offset = dst_internal_offset;
+         dst_internal_offset += RADV_GFX12_BVH_NODE_SIZE;
+      } else {
+         child_id = primitive_id | child_type;
+         primitive_id += (child_size * RADV_GFX12_BVH_NODE_SIZE) >> 3;
+         child_dst_offset = dst_leaf_offset;
+         dst_leaf_offset += RADV_GFX12_BVH_NODE_SIZE;
+      }
+
+      rra_transcode_node_gfx12(ctx, radv_bvh_node_box32 | (dst_offset >> 3), child_id, child_dst_offset);
+
+      dst->children[i].dword2 = (dst->children[i].dword2 & 0x0fffffff) | (1 << 28);
+   }
+}
+
+void
+rra_transcode_node_gfx12(struct rra_transcoding_context *ctx, uint32_t parent_id, uint32_t src_id, uint32_t dst_offset)
+{
+   uint32_t node_type = src_id & 7;
+   uint32_t src_offset = (src_id & (~7u)) << 3;
+
+   const void *src_child_node = ctx->src + src_offset;
+   if (node_type == radv_bvh_node_box32) {
+      rra_transcode_box8_node(ctx, src_child_node, parent_id, dst_offset);
+   } else {
+      memcpy(ctx->dst + dst_offset, src_child_node, RADV_GFX12_BVH_NODE_SIZE);
+
+      if (node_type == radv_bvh_node_instance) {
+         struct radv_gfx12_instance_node *dst = (void *)(ctx->dst + dst_offset);
+
+         struct rra_instance_sideband_data *sideband_data = (void *)(ctx->dst + ctx->dst_instance_sideband_data_offset);
+         ctx->dst_instance_sideband_data_offset += sizeof(struct rra_instance_sideband_data);
+
+         const struct radv_gfx12_instance_node_user_data *user_data =
+            (const void *)((const uint8_t *)src_child_node + sizeof(struct radv_gfx12_instance_node));
+
+         dst->pointer_flags_bvh_addr = dst->pointer_flags_bvh_addr - (user_data->bvh_offset >> 3) +
+                                       (sizeof(struct rra_accel_struct_metadata) >> 3);
+         dst->unused = parent_id;
+
+         sideband_data->instance_index = user_data->instance_index;
+         sideband_data->custom_instance_and_flags = user_data->custom_instance;
+         sideband_data->blas_metadata_size = offsetof(struct rra_accel_struct_metadata, unused);
+         sideband_data->otw_matrix = user_data->otw_matrix;
+      }
+   }
+}
diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index fefe917af5c..59415ce91f4 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -82,6 +82,10 @@ vectorize_vec2_16bit(const nir_instr *instr, const void *_)
       return 0;
 
    const nir_alu_instr *alu = nir_instr_as_alu(instr);
+
+   if (alu->op == nir_op_f2e4m3fn || alu->op == nir_op_e4m3fn2f)
+      return 2;
+
    const unsigned bit_size = alu->def.bit_size;
    if (bit_size == 16)
       return 2;
@@ -519,9 +523,7 @@ radv_shader_spirv_to_nir(struct radv_device *device, const struct radv_shader_st
       /* Lower shared variables early to prevent the over allocation of shared memory in
        * radv_nir_lower_ray_queries.  */
       if (nir->info.stage == MESA_SHADER_COMPUTE) {
-         if (!nir->info.shared_memory_explicit_layout)
-            NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, nir_var_mem_shared, shared_var_info);
-
+         NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, nir_var_mem_shared, shared_var_info);
          NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_shared, nir_address_format_32bit_offset);
       }
 
@@ -626,10 +628,7 @@ radv_shader_spirv_to_nir(struct radv_device *device, const struct radv_shader_st
       if (nir->info.stage == MESA_SHADER_TASK || nir->info.stage == MESA_SHADER_MESH)
          var_modes |= nir_var_mem_task_payload;
 
-      if (!nir->info.shared_memory_explicit_layout)
-         NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, var_modes, shared_var_info);
-      else if (var_modes & ~nir_var_mem_shared)
-         NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, var_modes & ~nir_var_mem_shared, shared_var_info);
+      NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, var_modes, shared_var_info);
       NIR_PASS(_, nir, nir_lower_explicit_io, var_modes, nir_address_format_32bit_offset);
 
       if (nir->info.zero_initialize_shared_memory && nir->info.shared_size > 0) {
@@ -2140,7 +2139,8 @@ radv_postprocess_binary_config(struct radv_device *device, struct radv_shader_bi
    case MESA_SHADER_ANY_HIT:
    case MESA_SHADER_COMPUTE:
    case MESA_SHADER_TASK:
-      config->rsrc1 |= S_00B848_MEM_ORDERED(radv_mem_ordered(pdev)) | S_00B848_WGP_MODE(wgp_mode);
+      config->rsrc1 |= S_00B848_MEM_ORDERED(radv_mem_ordered(pdev)) | S_00B848_WGP_MODE(wgp_mode) |
+                       S_00B848_FP16_OVFL(info->uses_f2e4m3fn);
       config->rsrc2 |= S_00B84C_TGID_X_EN(info->cs.uses_block_id[0]) | S_00B84C_TGID_Y_EN(info->cs.uses_block_id[1]) |
                        S_00B84C_TGID_Z_EN(info->cs.uses_block_id[2]) |
                        S_00B84C_TIDIG_COMP_CNT(info->cs.uses_thread_id[2]   ? 2
@@ -2296,9 +2296,11 @@ radv_shader_combine_cfg_vs_tcs(const struct radv_shader *vs, const struct radv_s
 }
 
 void
-radv_shader_combine_cfg_vs_gs(const struct radv_shader *vs, const struct radv_shader *gs, uint32_t *rsrc1_out,
-                              uint32_t *rsrc2_out)
+radv_shader_combine_cfg_vs_gs(const struct radv_device *device, const struct radv_shader *vs,
+                              const struct radv_shader *gs, uint32_t *rsrc1_out, uint32_t *rsrc2_out)
 {
+   const struct radv_physical_device *pdev = radv_device_physical(device);
+
    assert(G_00B12C_USER_SGPR(vs->config.rsrc2) == G_00B12C_USER_SGPR(gs->config.rsrc2));
 
    if (rsrc1_out) {
@@ -2316,22 +2318,30 @@ radv_shader_combine_cfg_vs_gs(const struct radv_shader *vs, const struct radv_sh
 
    if (rsrc2_out) {
       uint32_t rsrc2 = vs->config.rsrc2;
+      uint32_t lds_size;
 
       if (G_00B22C_ES_VGPR_COMP_CNT(gs->config.rsrc2) > G_00B22C_ES_VGPR_COMP_CNT(rsrc2))
          rsrc2 = (rsrc2 & C_00B22C_ES_VGPR_COMP_CNT) | (gs->config.rsrc2 & ~C_00B22C_ES_VGPR_COMP_CNT);
 
       rsrc2 |= gs->config.rsrc2 & ~(C_00B12C_SCRATCH_EN & C_00B12C_SO_EN & C_00B12C_SO_BASE0_EN & C_00B12C_SO_BASE1_EN &
                                     C_00B12C_SO_BASE2_EN & C_00B12C_SO_BASE3_EN);
+      if (gs->info.is_ngg) {
+         lds_size = DIV_ROUND_UP(gs->info.ngg_info.lds_size, pdev->info.lds_encode_granularity);
+      } else {
+         lds_size = gs->info.gs_ring_info.lds_size;
+      }
+
+      rsrc2 |= S_00B22C_LDS_SIZE(lds_size);
 
       *rsrc2_out = rsrc2;
    }
 }
 
 void
-radv_shader_combine_cfg_tes_gs(const struct radv_shader *tes, const struct radv_shader *gs, uint32_t *rsrc1_out,
-                               uint32_t *rsrc2_out)
+radv_shader_combine_cfg_tes_gs(const struct radv_device *device, const struct radv_shader *tes,
+                               const struct radv_shader *gs, uint32_t *rsrc1_out, uint32_t *rsrc2_out)
 {
-   radv_shader_combine_cfg_vs_gs(tes, gs, rsrc1_out, rsrc2_out);
+   radv_shader_combine_cfg_vs_gs(device, tes, gs, rsrc1_out, rsrc2_out);
 
    if (rsrc2_out) {
       *rsrc2_out |= S_00B22C_OC_LDS_EN(1);
@@ -3599,9 +3609,11 @@ radv_get_tess_wg_info(const struct radv_physical_device *pdev, const struct shad
 {
    const uint32_t lds_input_vertex_size = get_tcs_input_vertex_stride(tcs_num_lds_inputs);
 
-   ac_nir_compute_tess_wg_info(&pdev->info, tcs_info, pdev->ge_wave_size, false, all_invocations_define_tess_levels,
-                               tcs_num_input_vertices, lds_input_vertex_size, tcs_num_vram_outputs,
-                               tcs_num_vram_patch_outputs, num_patches_per_wg, hw_lds_size);
+   ac_nir_compute_tess_wg_info(&pdev->info, tcs_info->outputs_read, tcs_info->outputs_written,
+                               tcs_info->patch_outputs_read, tcs_info->patch_outputs_written,
+                               tcs_info->tess.tcs_vertices_out, pdev->ge_wave_size, false,
+                               all_invocations_define_tess_levels, tcs_num_input_vertices, lds_input_vertex_size,
+                               tcs_num_vram_outputs, tcs_num_vram_patch_outputs, num_patches_per_wg, hw_lds_size);
 }
 
 VkResult
diff --git a/src/amd/vulkan/radv_shader.h b/src/amd/vulkan/radv_shader.h
index 9687ea7be8a..4ea29285b25 100644
--- a/src/amd/vulkan/radv_shader.h
+++ b/src/amd/vulkan/radv_shader.h
@@ -724,11 +724,11 @@ enum radv_pipeline_type;
 void radv_shader_combine_cfg_vs_tcs(const struct radv_shader *vs, const struct radv_shader *tcs, uint32_t *rsrc1_out,
                                     uint32_t *rsrc2_out);
 
-void radv_shader_combine_cfg_vs_gs(const struct radv_shader *vs, const struct radv_shader *gs, uint32_t *rsrc1_out,
-                                   uint32_t *rsrc2_out);
+void radv_shader_combine_cfg_vs_gs(const struct radv_device *device, const struct radv_shader *vs,
+                                   const struct radv_shader *gs, uint32_t *rsrc1_out, uint32_t *rsrc2_out);
 
-void radv_shader_combine_cfg_tes_gs(const struct radv_shader *tes, const struct radv_shader *gs, uint32_t *rsrc1_out,
-                                    uint32_t *rsrc2_out);
+void radv_shader_combine_cfg_tes_gs(const struct radv_device *device, const struct radv_shader *tes,
+                                    const struct radv_shader *gs, uint32_t *rsrc1_out, uint32_t *rsrc2_out);
 
 const struct radv_userdata_info *radv_get_user_sgpr_info(const struct radv_shader *shader, int idx);
 
diff --git a/src/amd/vulkan/radv_shader_info.c b/src/amd/vulkan/radv_shader_info.c
index 0513e55b3fa..cc0f7db0706 100644
--- a/src/amd/vulkan/radv_shader_info.c
+++ b/src/amd/vulkan/radv_shader_info.c
@@ -314,6 +314,7 @@ gather_intrinsic_info(const nir_shader *nir, const nir_intrinsic_instr *instr, s
       gather_intrinsic_store_output_info(nir, instr, info, consider_force_vrs);
       break;
    case nir_intrinsic_bvh64_intersect_ray_amd:
+   case nir_intrinsic_bvh8_intersect_ray_amd:
       info->cs.uses_rt = true;
       break;
    case nir_intrinsic_load_poly_line_smooth_enabled:
@@ -344,6 +345,18 @@ gather_tex_info(const nir_shader *nir, const nir_tex_instr *instr, struct radv_s
    }
 }
 
+static void
+gather_alu_info(const nir_shader *nir, const nir_alu_instr *instr, struct radv_shader_info *info)
+{
+   switch (instr->op) {
+   case nir_op_f2e4m3fn:
+      info->uses_f2e4m3fn = true;
+      break;
+   default:
+      break;
+   }
+}
+
 static void
 gather_info_block(const nir_shader *nir, const nir_block *block, struct radv_shader_info *info,
                   const struct radv_graphics_state_key *gfx_state, const struct radv_shader_stage_key *stage_key,
@@ -357,6 +370,8 @@ gather_info_block(const nir_shader *nir, const nir_block *block, struct radv_sha
       case nir_instr_type_tex:
          gather_tex_info(nir, nir_instr_as_tex(instr), info);
          break;
+      case nir_instr_type_alu:
+         gather_alu_info(nir, nir_instr_as_alu(instr), info);
       default:
          break;
       }
@@ -997,8 +1012,7 @@ gather_shader_info_fs(const struct radv_device *device, const nir_shader *nir,
       info->ps.spi_shader_col_format = gfx_state->ps.epilog.spi_shader_col_format;
 
       /* Clear color attachments that aren't exported by the FS to match IO shader arguments. */
-      if (!info->ps.mrt0_is_dual_src)
-         info->ps.spi_shader_col_format &= info->ps.colors_written;
+      info->ps.spi_shader_col_format &= info->ps.colors_written;
 
       info->ps.cb_shader_mask = ac_get_cb_shader_mask(info->ps.spi_shader_col_format);
    }
@@ -1842,6 +1856,7 @@ radv_nir_shader_info_merge(const struct radv_shader_stage *src, struct radv_shad
    dst_info->desc_set_used_mask |= src_info->desc_set_used_mask;
    dst_info->uses_view_index |= src_info->uses_view_index;
    dst_info->uses_prim_id |= src_info->uses_prim_id;
+   dst_info->uses_f2e4m3fn |= src_info->uses_f2e4m3fn;
    dst_info->inline_push_constant_mask |= src_info->inline_push_constant_mask;
 
    /* Only inline all push constants if both allows it. */
diff --git a/src/amd/vulkan/radv_shader_info.h b/src/amd/vulkan/radv_shader_info.h
index eb70b764ab5..c6afbc216a0 100644
--- a/src/amd/vulkan/radv_shader_info.h
+++ b/src/amd/vulkan/radv_shader_info.h
@@ -89,6 +89,7 @@ struct radv_shader_info {
    bool uses_view_index;
    bool uses_invocation_id;
    bool uses_prim_id;
+   bool uses_f2e4m3fn;
    uint8_t wave_size;
    uint8_t ballot_bit_size;
    struct radv_userdata_locations user_sgprs_locs;
diff --git a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys.c b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys.c
index a2ebb948e9d..8122c1da3df 100644
--- a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys.c
+++ b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys.c
@@ -22,6 +22,31 @@
 #include "vk_drm_syncobj.h"
 #include "xf86drm.h"
 
+static bool
+do_winsys_init(struct radv_amdgpu_winsys *ws, int fd)
+{
+   if (!ac_query_gpu_info(fd, ws->dev, &ws->info, true))
+      return false;
+
+   /*
+    * Override the max submits on video queues.
+    * If you submit multiple session contexts in the same IB sequence the
+    * hardware gets upset as it expects a kernel fence to be emitted to reset
+    * the session context in the hardware.
+    * Avoid this problem by never submitted more than one IB at a time.
+    * This possibly should be fixed in the kernel, and if it is this can be
+    * resolved.
+    */
+   for (enum amd_ip_type ip_type = AMD_IP_UVD; ip_type <= AMD_IP_VCN_ENC; ip_type++)
+      ws->info.max_submitted_ibs[ip_type] = 1;
+
+   ws->info.ip[AMD_IP_SDMA].num_queues = MIN2(ws->info.ip[AMD_IP_SDMA].num_queues, MAX_RINGS_PER_TYPE);
+   ws->info.ip[AMD_IP_COMPUTE].num_queues = MIN2(ws->info.ip[AMD_IP_COMPUTE].num_queues, MAX_RINGS_PER_TYPE);
+
+   ws->use_ib_bos = true;
+   return true;
+}
+
 static void
 radv_amdgpu_winsys_query_info(struct radeon_winsys *rws, struct radeon_info *gpu_info)
 {
@@ -130,7 +155,7 @@ radv_amdgpu_winsys_destroy(struct radeon_winsys *rws)
 
    simple_mtx_lock(&winsys_creation_mutex);
    if (!--ws->refcount) {
-      _mesa_hash_table_remove_key(winsyses, (void *)ac_drm_device_get_cookie(ws->dev));
+      _mesa_hash_table_remove_key(winsyses, ws->dev);
 
       /* Clean the hashtable up if empty, though there is no
        * empty function. */
@@ -170,12 +195,9 @@ radv_amdgpu_winsys_get_sync_types(struct radeon_winsys *rws)
    return ws->sync_types;
 }
 
-VkResult
-radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags, bool reserve_vmid, bool is_virtio,
-                          struct radeon_winsys **winsys)
+struct radeon_winsys *
+radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags, bool reserve_vmid, bool is_virtio)
 {
-   VkResult result = VK_SUCCESS;
-
    uint32_t drm_major, drm_minor, r;
    ac_drm_device *dev;
    struct radv_amdgpu_winsys *ws = NULL;
@@ -183,7 +205,7 @@ radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags,
    r = ac_drm_device_initialize(fd, is_virtio, &drm_major, &drm_minor, &dev);
    if (r) {
       fprintf(stderr, "radv/amdgpu: failed to initialize device.\n");
-      return VK_ERROR_INITIALIZATION_FAILED;
+      return NULL;
    }
 
    /* We have to keep this lock till insertion. */
@@ -192,7 +214,6 @@ radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags,
       winsyses = _mesa_pointer_hash_table_create(NULL);
    if (!winsyses) {
       fprintf(stderr, "radv/amdgpu: failed to alloc winsys hash table.\n");
-      result = VK_ERROR_OUT_OF_HOST_MEMORY;
       goto fail;
    }
 
@@ -211,22 +232,19 @@ radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags,
           ((debug_flags & RADV_DEBUG_HANG) && !ws->debug_log_bos) ||
           ((debug_flags & RADV_DEBUG_NO_IBS) && ws->use_ib_bos) || (perftest_flags != ws->perftest)) {
          fprintf(stderr, "radv/amdgpu: Found options that differ from the existing winsys.\n");
-         return VK_ERROR_INITIALIZATION_FAILED;
+         return NULL;
       }
 
       /* RADV_DEBUG_ZERO_VRAM is the only option that is allowed to be set again. */
       if (debug_flags & RADV_DEBUG_ZERO_VRAM)
          ws->zero_all_vram_allocs = true;
 
-      *winsys = &ws->base;
-      return VK_SUCCESS;
+      return &ws->base;
    }
 
    ws = calloc(1, sizeof(struct radv_amdgpu_winsys));
-   if (!ws) {
-      result = VK_ERROR_OUT_OF_HOST_MEMORY;
+   if (!ws)
       goto fail;
-   }
 
    ws->refcount = 1;
    ws->dev = dev;
@@ -234,29 +252,8 @@ radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags,
    ws->info.drm_major = drm_major;
    ws->info.drm_minor = drm_minor;
    ws->info.is_virtio = is_virtio;
-
-   enum ac_query_gpu_info_result info_result = ac_query_gpu_info(fd, ws->dev, &ws->info, true);
-   if (info_result != AC_QUERY_GPU_INFO_SUCCESS) {
-      result = info_result == AC_QUERY_GPU_INFO_FAIL ? VK_ERROR_INITIALIZATION_FAILED : VK_ERROR_INCOMPATIBLE_DRIVER;
+   if (!do_winsys_init(ws, fd))
       goto winsys_fail;
-   }
-
-   /*
-    * Override the max submits on video queues.
-    * If you submit multiple session contexts in the same IB sequence the
-    * hardware gets upset as it expects a kernel fence to be emitted to reset
-    * the session context in the hardware.
-    * Avoid this problem by never submitted more than one IB at a time.
-    * This possibly should be fixed in the kernel, and if it is this can be
-    * resolved.
-    */
-   for (enum amd_ip_type ip_type = AMD_IP_UVD; ip_type <= AMD_IP_VCN_ENC; ip_type++)
-      ws->info.max_submitted_ibs[ip_type] = 1;
-
-   ws->info.ip[AMD_IP_SDMA].num_queues = MIN2(ws->info.ip[AMD_IP_SDMA].num_queues, MAX_RINGS_PER_TYPE);
-   ws->info.ip[AMD_IP_COMPUTE].num_queues = MIN2(ws->info.ip[AMD_IP_COMPUTE].num_queues, MAX_RINGS_PER_TYPE);
-
-   ws->use_ib_bos = true;
 
    ws->debug_all_bos = !!(debug_flags & RADV_DEBUG_ALL_BOS);
    ws->debug_log_bos = debug_flags & RADV_DEBUG_HANG;
@@ -268,7 +265,6 @@ radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags,
       r = ac_drm_vm_reserve_vmid(ws->dev, 0);
       if (r) {
          fprintf(stderr, "radv/amdgpu: failed to reserve vmid.\n");
-         result = VK_ERROR_INITIALIZATION_FAILED;
          goto winsys_fail;
       }
    }
@@ -315,9 +311,7 @@ radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags,
    _mesa_hash_table_insert(winsyses, (void *)ac_drm_device_get_cookie(dev), ws);
    simple_mtx_unlock(&winsys_creation_mutex);
 
-   *winsys = &ws->base;
-
-   return result;
+   return &ws->base;
 
 winsys_fail:
    free(ws);
@@ -328,5 +322,5 @@ fail:
    }
    simple_mtx_unlock(&winsys_creation_mutex);
    ac_drm_device_deinitialize(dev);
-   return result;
+   return NULL;
 }
diff --git a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys_public.h b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys_public.h
index 438d9285b65..9e0dc71d3bc 100644
--- a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys_public.h
+++ b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys_public.h
@@ -12,8 +12,8 @@
 #ifndef RADV_AMDGPU_WINSYS_PUBLIC_H
 #define RADV_AMDGPU_WINSYS_PUBLIC_H
 
-VkResult radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags, bool reserve_vmid,
-                                   bool is_virtio, struct radeon_winsys **winsys);
+struct radeon_winsys *radv_amdgpu_winsys_create(int fd, uint64_t debug_flags, uint64_t perftest_flags,
+                                                bool reserve_vmid, bool is_virtio);
 
 struct radeon_winsys *radv_dummy_winsys_create(void);
 
diff --git a/src/asahi/compiler/README.md b/src/asahi/compiler/README.md
index 192aca1d667..0fc72520dca 100644
--- a/src/asahi/compiler/README.md
+++ b/src/asahi/compiler/README.md
@@ -15,9 +15,12 @@ The following section describes the ABI used by non-monolithic programs.
 Registers have the following layout at the beginning of the vertex shader
 (written by the vertex prolog):
 
-* `r0-r4` and `r7` undefined. This avoids preloading into the nesting counter or
+* `r0-r3` and `r7` undefined. This avoids preloading into the nesting counter or
   having unaligned values. The prolog is free to use these registers as
   temporaries.
+* `r4` is the zero-based vertex ID if the vertex shader is running as a hardware
+  compute shader, useful to avoid a redundant special register read in the main
+  shader. Undefined in hardware vertex shaders.
 * `r5-r6` retain their usual meanings, even if the vertex shader is running as a
   hardware compute shader. This allows software index fetch code to run in the
   prolog without contaminating the main shader key.
diff --git a/src/asahi/compiler/agx_compile.c b/src/asahi/compiler/agx_compile.c
index 626871a31c0..e541017c883 100644
--- a/src/asahi/compiler/agx_compile.c
+++ b/src/asahi/compiler/agx_compile.c
@@ -8,6 +8,7 @@
 #include "agx_compile.h"
 #include "asahi/clc/asahi_clc.h"
 #include "asahi/layout/layout.h"
+#include "asahi/lib/agx_abi.h"
 #include "compiler/nir/nir_builder.h"
 #include "util/bitset.h"
 #include "util/glheader.h"
@@ -98,16 +99,23 @@ agx_tess_coord_y(agx_builder *b)
    return agx_cached_preload(b->shader, 6, AGX_SIZE_32);
 }
 
+static agx_index
+agx_vertex_id_zero_base(agx_builder *b)
+{
+   return agx_cached_preload(b->shader, AGX_ABI_VIN_VERTEX_ID_ZERO_BASE,
+                             AGX_SIZE_32);
+}
+
 static agx_index
 agx_vertex_id(agx_builder *b)
 {
-   return agx_cached_preload(b->shader, 10, AGX_SIZE_32);
+   return agx_cached_preload(b->shader, AGX_ABI_VIN_VERTEX_ID, AGX_SIZE_32);
 }
 
 static agx_index
 agx_instance_id(agx_builder *b)
 {
-   return agx_cached_preload(b->shader, 12, AGX_SIZE_32);
+   return agx_cached_preload(b->shader, AGX_ABI_VIN_INSTANCE_ID, AGX_SIZE_32);
 }
 
 #define VARYING_NUM_COMPONENTS (VARYING_SLOT_MAX * 4)
@@ -1416,6 +1424,10 @@ agx_emit_intrinsic(agx_builder *b, nir_intrinsic_instr *instr)
                          agx_get_sr_coverage(b, 32, AGX_SR_IS_ACTIVE_THREAD),
                          agx_zero(), AGX_ICOND_UEQ, false);
 
+   case nir_intrinsic_load_vertex_id_zero_base:
+      assert(stage == MESA_SHADER_COMPUTE && "only for SW VS");
+      return agx_mov_to(b, dst, agx_abs(agx_vertex_id_zero_base(b)));
+
    case nir_intrinsic_load_vertex_id:
       /* We don't assert the HW stage since we use this same ABI with SW VS */
       return agx_mov_to(b, dst, agx_abs(agx_vertex_id(b)));
diff --git a/src/asahi/compiler/agx_compile.h b/src/asahi/compiler/agx_compile.h
index 92857285c67..97503d3bac9 100644
--- a/src/asahi/compiler/agx_compile.h
+++ b/src/asahi/compiler/agx_compile.h
@@ -198,6 +198,15 @@ struct agx_shader_part {
    void *binary;
 };
 
+static inline bool
+agx_is_shader_empty(struct agx_shader_part *s)
+{
+   /* Last instruction is a stop, so if there's one instruction, there is
+    * nothing but a stop. The shader is thus empty.
+    */
+   return (s->info.stats.instrs == 1);
+}
+
 #define AGX_MAX_RTS (8)
 
 enum agx_format {
diff --git a/src/asahi/compiler/agx_nir_algebraic.py b/src/asahi/compiler/agx_nir_algebraic.py
index 5f3dee16fc0..302b9b8c3d3 100644
--- a/src/asahi/compiler/agx_nir_algebraic.py
+++ b/src/asahi/compiler/agx_nir_algebraic.py
@@ -105,9 +105,15 @@ for T, sizes, one in [('f', [16, 32], 1.0),
 # This needs to be a separate pass that runs after lower_selects, in order to
 # pick up patterns like b2f32(iand(...))
 opt_selects = [
+        (('bcsel', ('ior(is_used_once)', ('inot', a), b), c, d),
+         ('bcsel', a, ('bcsel', b, c, d), c)),
+
         (('bcsel', ('ior(is_used_once)', a, b), c, d),
          ('bcsel', a, c, ('bcsel', b, c, d))),
 
+        (('bcsel', ('iand(is_used_once)', ('inot', a), b), c, d),
+         ('bcsel', a, d, ('bcsel', b, c, d))),
+
         (('bcsel', ('iand(is_used_once)', a, b), c, d),
          ('bcsel', a, ('bcsel', b, c, d), d)),
 ]
diff --git a/src/asahi/compiler/agx_nir_lower_discard_zs_emit.c b/src/asahi/compiler/agx_nir_lower_discard_zs_emit.c
index e1c721da4a1..07bf42aa714 100644
--- a/src/asahi/compiler/agx_nir_lower_discard_zs_emit.c
+++ b/src/asahi/compiler/agx_nir_lower_discard_zs_emit.c
@@ -97,7 +97,7 @@ lower_discard(nir_builder *b, nir_intrinsic_instr *intr, UNUSED void *data)
       killed_samples = nir_bcsel(b, intr->src[0].ssa, all_samples, no_samples);
 
    /* This will get lowered later as needed */
-   nir_discard_agx(b, killed_samples);
+   nir_demote_samples(b, killed_samples);
    nir_instr_remove(&intr->instr);
    return true;
 }
diff --git a/src/asahi/compiler/agx_nir_lower_sample_mask.c b/src/asahi/compiler/agx_nir_lower_sample_mask.c
index 37a40c8c848..9fccffceb64 100644
--- a/src/asahi/compiler/agx_nir_lower_sample_mask.c
+++ b/src/asahi/compiler/agx_nir_lower_sample_mask.c
@@ -65,7 +65,7 @@
  * 5. zs_emit may be used in the shader exactly once to trigger tests.
  * sample_mask with 0 may be used to discard early.
  *
- * This pass lowers discard_agx to sample_mask instructions satisfying these
+ * This pass lowers demote_samples to sample_mask instructions satisfying these
  * rules. Other passes should not generate sample_mask instructions, as there
  * are too many footguns.
  */
@@ -78,7 +78,7 @@ static bool
 lower_discard_to_sample_mask_0(nir_builder *b, nir_intrinsic_instr *intr,
                                UNUSED void *data)
 {
-   if (intr->intrinsic != nir_intrinsic_discard_agx)
+   if (intr->intrinsic != nir_intrinsic_demote_samples)
       return false;
 
    b->cursor = nir_before_instr(&intr->instr);
@@ -95,7 +95,7 @@ last_discard_in_block(nir_block *block)
          continue;
 
       nir_intrinsic_instr *intr = nir_instr_as_intrinsic(instr);
-      if (intr->intrinsic == nir_intrinsic_discard_agx)
+      if (intr->intrinsic == nir_intrinsic_demote_samples)
          return intr;
    }
 
diff --git a/src/asahi/compiler/agx_register_allocate.c b/src/asahi/compiler/agx_register_allocate.c
index ea091558bd3..b7b4e5ad88e 100644
--- a/src/asahi/compiler/agx_register_allocate.c
+++ b/src/asahi/compiler/agx_register_allocate.c
@@ -352,13 +352,12 @@ find_regs_simple(struct ra_ctx *rctx, enum ra_class cls, unsigned count,
  * Postcondition: at least one register in the returned region is already free.
  */
 static unsigned
-find_best_region_to_evict(struct ra_ctx *rctx, enum ra_class cls, unsigned size,
+find_best_region_to_evict(struct ra_ctx *rctx, unsigned size,
                           BITSET_WORD *already_evicted)
 {
    assert(util_is_power_of_two_or_zero(size) && "precondition");
-   assert((rctx->bound[cls] % size) == 0 &&
+   assert((rctx->bound[RA_GPR] % size) == 0 &&
           "register file size must be aligned to the maximum vector size");
-   assert(cls == RA_GPR);
 
    /* Useful for testing RA */
    bool invert = false;
@@ -366,7 +365,7 @@ find_best_region_to_evict(struct ra_ctx *rctx, enum ra_class cls, unsigned size,
    unsigned best_base = ~0;
    unsigned best_moves = invert ? 0 : ~0;
 
-   for (unsigned base = 0; base + size <= rctx->bound[cls]; base += size) {
+   for (unsigned base = 0; base + size <= rctx->bound[RA_GPR]; base += size) {
       /* The first k registers are preallocated and unevictable, so must be
        * skipped. By itself, this does not pose a problem. We are allocating n
        * registers, but this region has at most n-k free.  Since there are at
@@ -398,7 +397,7 @@ find_best_region_to_evict(struct ra_ctx *rctx, enum ra_class cls, unsigned size,
          /* We need a move for each blocked register (TODO: we only need a
           * single move for 32-bit pairs, could optimize to use that instead.)
           */
-         if (BITSET_TEST(rctx->used_regs[cls], reg))
+         if (BITSET_TEST(rctx->used_regs[RA_GPR], reg))
             moves++;
          else
             any_free = true;
@@ -414,7 +413,7 @@ find_best_region_to_evict(struct ra_ctx *rctx, enum ra_class cls, unsigned size,
       }
    }
 
-   assert(best_base < rctx->bound[cls] &&
+   assert(best_base < rctx->bound[RA_GPR] &&
           "not enough registers (should have spilled already)");
    return best_base;
 }
@@ -489,7 +488,7 @@ assign_regs_by_copying(struct ra_ctx *rctx, agx_index dest, const agx_instr *I,
       /* We need to shuffle some variables to make room. Look for a range of
        * the register file that is partially blocked.
        */
-      unsigned new_reg = find_best_region_to_evict(rctx, RA_GPR, nr, clobbered);
+      unsigned new_reg = find_best_region_to_evict(rctx, nr, clobbered);
 
       /* Blocked registers need to get reassigned. Add them to the worklist. */
       for (unsigned i = 0; i < nr; ++i) {
diff --git a/src/asahi/genxml/cmdbuf.xml b/src/asahi/genxml/cmdbuf.xml
index 605b81fb06a..5c565a92769 100644
--- a/src/asahi/genxml/cmdbuf.xml
+++ b/src/asahi/genxml/cmdbuf.xml
@@ -268,10 +268,10 @@
     -->
     <field name="Level offset (sw)" size="27" start="128" type="uint" modifier="shr(7)"/>
     <field name="Aligned width MSAA (sw)" size="15" start="128" type="uint"/>
-    <field name="Tile width (sw)" size="3" start="155" type="uint" modifier="log2"/>
-    <field name="Tile height (sw)" size="3" start="158" type="uint" modifier="log2"/>
-    <field name="Layer stride (sw)" size="27" start="161" type="uint" modifier="shr(7)"/>
-    <field name="Sample count log2 (sw)" size="2" start="188" type="uint"/>
+    <field name="Sample count log2 (sw)" size="2" start="143" type="uint"/>
+    <field name="Tile width (sw)" size="4" start="155" type="uint" modifier="log2"/>
+    <field name="Tile height (sw)" size="4" start="159" type="uint" modifier="log2"/>
+    <field name="Layer stride (sw)" size="27" start="163" type="uint" modifier="shr(7)"/>
     <field name="Buffer offset (sw)" size="32" start="128" type="uint"/>
   </struct>
 
@@ -1097,20 +1097,25 @@
     <value name="16" value="2"/>
   </enum>
 
+  <enum name="ZLS Tiling">
+    <value name="GPU" value="0"/>
+    <value name="Twiddled" value="1"/>
+  </enum>
+
   <struct name="ZLS Control" size="8">
     <field name="Unknown 0" start="0" size="1" type="bool"/>
-    <field name="Unknown 1" start="1" size="1" type="bool"/>
-    <field name="Z Compress 1" start="2" size="1" type="bool"/>
-    <field name="Unknown 3" start="3" size="1" type="bool"/>
-    <field name="S Compress 1" start="4" size="1" type="bool"/>
-    <field name="Unknown 5" start="5" size="1" type="bool"/>
-    <field name="Z Compress 2" start="6" size="1" type="bool"/>
-    <field name="Unknown 7" start="7" size="1" type="bool"/>
-    <field name="S Compress 2" start="8" size="1" type="bool"/>
-    <field name="S Load Enable" start="14" size="1" type="bool"/>
-    <field name="Z Load Enable" start="15" size="1" type="bool"/>
-    <field name="S Store Enable" start="18" size="1" type="bool"/>
-    <field name="Z Store Enable" start="19" size="1" type="bool"/>
+    <field name="Z Load Tiling" start="1" size="1" type="ZLS Tiling"/>
+    <field name="Z Load Compress" start="2" size="1" type="bool"/>
+    <field name="S Load Tiling" start="3" size="1" type="ZLS Tiling"/>
+    <field name="S Load Compress" start="4" size="1" type="bool"/>
+    <field name="Z Store Tiling" start="5" size="1" type="ZLS Tiling"/>
+    <field name="Z Store Compress" start="6" size="1" type="bool"/>
+    <field name="S Store Tiling" start="7" size="1" type="ZLS Tiling"/>
+    <field name="S Store Compress" start="8" size="1" type="bool"/>
+    <field name="S Load" start="14" size="1" type="bool"/>
+    <field name="Z Load" start="15" size="1" type="bool"/>
+    <field name="S Store" start="18" size="1" type="bool"/>
+    <field name="Z Store" start="19" size="1" type="bool"/>
     <field name="Z Format" start="25" size="2" type="ZLS Format"/>
     <field name="Z Resolve" start="56" size="1" type="bool"/>
     <field name="S Resolve" start="58" size="1" type="bool"/>
diff --git a/src/asahi/layout/layout.c b/src/asahi/layout/layout.c
index d92df24f6e7..2690c6c4d8e 100644
--- a/src/asahi/layout/layout.c
+++ b/src/asahi/layout/layout.c
@@ -4,6 +4,8 @@
  */
 
 #include "layout.h"
+#include "util/format/u_format.h"
+#include "util/u_math.h"
 
 static void
 ail_initialize_linear(struct ail_layout *layout)
@@ -64,7 +66,7 @@ ail_get_block_size_B(struct ail_layout *layout)
 }
 
 static void
-ail_initialize_twiddled(struct ail_layout *layout)
+ail_initialize_gpu_tiled(struct ail_layout *layout)
 {
    unsigned offset_B = 0;
    unsigned blocksize_B = ail_get_block_size_B(layout);
@@ -211,6 +213,57 @@ ail_initialize_twiddled(struct ail_layout *layout)
    layout->size_B = (uint64_t)layout->layer_stride_B * layout->depth_px;
 }
 
+static void
+ail_initialize_twiddled(struct ail_layout *layout)
+{
+   unsigned offset_B = 0;
+   unsigned blocksize_B = ail_get_block_size_B(layout);
+   unsigned w_el = util_format_get_nblocksx(layout->format, layout->width_px);
+   unsigned h_el = util_format_get_nblocksy(layout->format, layout->height_px);
+   bool compressed = util_format_is_compressed(layout->format);
+
+   for (unsigned l = 0; l < layout->levels; ++l) {
+      unsigned alloc_w_el = u_minify(util_next_power_of_two(w_el), l);
+      unsigned alloc_h_el = u_minify(util_next_power_of_two(h_el), l);
+      unsigned logical_w_el = util_next_power_of_two(u_minify(w_el, l));
+      unsigned logical_h_el = util_next_power_of_two(u_minify(h_el, l));
+
+      /* AGX: Even the exceptions have exceptions */
+      if (compressed) {
+         logical_w_el = alloc_w_el;
+         logical_h_el = alloc_h_el;
+      }
+
+      unsigned size_el = alloc_w_el * alloc_h_el;
+      layout->level_offsets_B[l] = offset_B;
+      offset_B = ALIGN_POT(offset_B + (blocksize_B * size_el), AIL_CACHELINE);
+
+      unsigned minor_el = MIN2(logical_w_el, logical_h_el);
+      layout->stride_el[l] = logical_w_el;
+      layout->tilesize_el[l] = (struct ail_tile){minor_el, minor_el};
+   }
+
+   /* Add the end offset so we can easily recover the size of a level */
+   assert(layout->levels < ARRAY_SIZE(layout->level_offsets_B));
+   layout->level_offsets_B[layout->levels] = offset_B;
+
+   /* Determine the start of the miptail. From that level on, we can no longer
+    * precisely bind at page granularity.
+    */
+   /* XXX TODO */
+   layout->mip_tail_first_lod = 0;
+
+   /* Determine the stride of the miptail. Sparse arrayed images inherently
+    * require page-aligned layers to be able to bind individual layers.
+    */
+   unsigned tail_offset_B = layout->level_offsets_B[layout->mip_tail_first_lod];
+   layout->mip_tail_stride = align(offset_B - tail_offset_B, AIL_PAGESIZE);
+
+   layout->page_aligned_layers = true;
+   layout->layer_stride_B = ALIGN_POT(offset_B, AIL_PAGESIZE);
+   layout->size_B = (uint64_t)layout->layer_stride_B * layout->depth_px;
+}
+
 static void
 ail_initialize_compression(struct ail_layout *layout)
 {
@@ -313,6 +366,9 @@ ail_make_miptree(struct ail_layout *layout)
       ail_initialize_linear(layout);
       break;
    case AIL_TILING_GPU:
+      ail_initialize_gpu_tiled(layout);
+      break;
+   case AIL_TILING_TWIDDLED:
       ail_initialize_twiddled(layout);
       break;
    default:
diff --git a/src/asahi/layout/layout.h b/src/asahi/layout/layout.h
index d195fd048ea..05959557439 100644
--- a/src/asahi/layout/layout.h
+++ b/src/asahi/layout/layout.h
@@ -30,6 +30,11 @@ enum ail_tiling {
     * GPU-tiled. Always allowed.
     */
    AIL_TILING_GPU,
+
+   /**
+    * Fully twiddled.
+    */
+   AIL_TILING_TWIDDLED,
 };
 
 /*
@@ -247,10 +252,18 @@ ail_get_linear_pixel_B(const struct ail_layout *layout, ASSERTED unsigned level,
 static inline uint32_t
 ail_space_bits(unsigned x)
 {
-   assert(x < 128 && "offset must be inside the tile");
+   uint32_t accum = 0;
+
+   /* With fully twiddled images, we can have up to 16384x16384 tiles,
+    * justifying stopping the loop at 14.
+    */
+   assert(x < (1 << 14) && "offset must be inside the tile");
+
+   for (unsigned i = 0; i < 14; ++i) {
+      accum |= (x & (1 << i)) << i;
+   }
 
-   return ((x & 1) << 0) | ((x & 2) << 1) | ((x & 4) << 2) | ((x & 8) << 3) |
-          ((x & 16) << 4) | ((x & 32) << 5) | ((x & 64) << 6);
+   return accum;
 }
 
 #define MOD_POT(x, y) (x) & ((y) - 1)
diff --git a/src/asahi/lib/agx_abi.h b/src/asahi/lib/agx_abi.h
index 22f54145a2a..2b6737f5e1e 100644
--- a/src/asahi/lib/agx_abi.h
+++ b/src/asahi/lib/agx_abi.h
@@ -8,9 +8,10 @@
 
 /* See compiler/README.md for the ABI */
 
-#define AGX_ABI_VIN_ATTRIB(i)   (2 * (8 + i))
-#define AGX_ABI_VIN_VERTEX_ID   (2 * 5)
-#define AGX_ABI_VIN_INSTANCE_ID (2 * 6)
+#define AGX_ABI_VIN_ATTRIB(i)           (2 * (8 + i))
+#define AGX_ABI_VIN_VERTEX_ID_ZERO_BASE (2 * 4)
+#define AGX_ABI_VIN_VERTEX_ID           (2 * 5)
+#define AGX_ABI_VIN_INSTANCE_ID         (2 * 6)
 
 #define AGX_ABI_FIN_SAMPLE_MASK (2)
 
diff --git a/src/asahi/lib/agx_helpers.h b/src/asahi/lib/agx_helpers.h
index bc5859404ce..39ea69e03d3 100644
--- a/src/asahi/lib/agx_helpers.h
+++ b/src/asahi/lib/agx_helpers.h
@@ -84,6 +84,8 @@ agx_translate_layout(enum ail_tiling tiling)
    switch (tiling) {
    case AIL_TILING_GPU:
       return AGX_LAYOUT_GPU;
+   case AIL_TILING_TWIDDLED:
+      return AGX_LAYOUT_TWIDDLED;
    case AIL_TILING_LINEAR:
       return AGX_LAYOUT_LINEAR;
    }
@@ -91,6 +93,54 @@ agx_translate_layout(enum ail_tiling tiling)
    unreachable("Invalid tiling");
 }
 
+static inline enum agx_zls_tiling
+agx_translate_zls_tiling(enum ail_tiling tiling)
+{
+   switch (tiling) {
+   case AIL_TILING_GPU:
+      return AGX_ZLS_TILING_GPU;
+   case AIL_TILING_TWIDDLED:
+      return AGX_ZLS_TILING_TWIDDLED;
+   default:
+      unreachable("Invalid ZLS tiling");
+   }
+}
+
+struct agx_zls {
+   bool z_load, z_store;
+   bool s_load, s_store;
+};
+
+static inline void
+agx_pack_zls_control(struct agx_zls_control_packed *packed,
+                     const struct ail_layout *z, const struct ail_layout *s,
+                     struct agx_zls *args)
+{
+   agx_pack(packed, ZLS_CONTROL, cfg) {
+      if (z) {
+         cfg.z_store = args->z_store;
+         cfg.z_load = args->z_load;
+         cfg.z_load_compress = cfg.z_store_compress = z->compressed;
+         cfg.z_load_tiling = cfg.z_store_tiling =
+            agx_translate_zls_tiling(z->tiling);
+
+         if (z->format == PIPE_FORMAT_Z16_UNORM) {
+            cfg.z_format = AGX_ZLS_FORMAT_16;
+         } else {
+            cfg.z_format = AGX_ZLS_FORMAT_32F;
+         }
+      }
+
+      if (s) {
+         cfg.s_load = args->s_load;
+         cfg.s_store = args->s_store;
+         cfg.s_load_compress = cfg.s_store_compress = s->compressed;
+         cfg.s_load_tiling = cfg.s_store_tiling =
+            agx_translate_zls_tiling(s->tiling);
+      }
+   }
+}
+
 static enum agx_sample_count
 agx_translate_sample_count(unsigned samples)
 {
diff --git a/src/asahi/lib/agx_nir_lower_gs.c b/src/asahi/lib/agx_nir_lower_gs.c
index d64c9125101..da3718945de 100644
--- a/src/asahi/lib/agx_nir_lower_gs.c
+++ b/src/asahi/lib/agx_nir_lower_gs.c
@@ -28,23 +28,16 @@ struct lower_gs_state {
    int static_count[MAX_VERTEX_STREAMS];
    nir_variable *outputs[NUM_TOTAL_VARYING_SLOTS][MAX_PRIM_OUT_SIZE];
 
-   /* Per-input primitive stride of the output index buffer */
-   unsigned max_indices;
-
-   /* The count buffer contains `count_stride_el` 32-bit words in a row for each
-    * input primitive, for `input_primitives * count_stride_el * 4` total bytes.
-    */
-   unsigned count_stride_el;
-
    /* The index of each counter in the count buffer, or -1 if it's not in the
     * count buffer.
     *
-    * Invariant: count_stride_el == sum(count_index[i][j] >= 0).
+    * Invariant: info->count_words == sum(count_index[i] >= 0).
     */
    int count_index[MAX_VERTEX_STREAMS];
 
    bool rasterizer_discard;
-   bool prefix_summing;
+
+   struct agx_gs_info *info;
 };
 
 /* Helpers for loading from the geometry state buffer */
@@ -96,9 +89,13 @@ add_counter(nir_builder *b, nir_def *counter, nir_def *increment)
 }
 
 /* Helpers for lowering I/O to variables */
+struct lower_output_to_var_state {
+   nir_variable *outputs[NUM_TOTAL_VARYING_SLOTS];
+};
+
 static void
 lower_store_to_var(nir_builder *b, nir_intrinsic_instr *intr,
-                   struct agx_lower_output_to_var_state *state)
+                   struct lower_output_to_var_state *state)
 {
    b->cursor = nir_instr_remove(&intr->instr);
    nir_io_semantics sem = nir_intrinsic_io_semantics(intr);
@@ -127,8 +124,8 @@ lower_store_to_var(nir_builder *b, nir_intrinsic_instr *intr,
    nir_store_var(b, var, value, BITFIELD_BIT(component));
 }
 
-bool
-agx_lower_output_to_var(nir_builder *b, nir_instr *instr, void *data)
+static bool
+lower_output_to_var(nir_builder *b, nir_instr *instr, void *data)
 {
    if (instr->type != nir_instr_type_intrinsic)
       return false;
@@ -227,7 +224,7 @@ lower_gs_inputs(nir_builder *b, nir_intrinsic_instr *intr, void *_)
    if (intr->intrinsic != nir_intrinsic_load_per_vertex_input)
       return false;
 
-   b->cursor = nir_instr_remove(&intr->instr);
+   b->cursor = nir_before_instr(&intr->instr);
 
    /* Calculate the vertex ID we're pulling, based on the topology class */
    nir_def *vert_in_prim = intr->src[0].ssa;
@@ -239,7 +236,7 @@ lower_gs_inputs(nir_builder *b, nir_intrinsic_instr *intr, void *_)
       nir_iadd(b, nir_imul(b, nir_load_instance_id(b), verts), vertex);
 
    nir_def *val = agx_load_per_vertex_input(b, intr, unrolled);
-   nir_def_rewrite_uses(&intr->def, val);
+   nir_def_replace(&intr->def, val);
    return true;
 }
 
@@ -256,10 +253,9 @@ calc_unrolled_id(nir_builder *b)
 }
 
 static unsigned
-output_vertex_id_stride(nir_shader *gs)
+output_vertex_id_pot_stride(const nir_shader *gs)
 {
-   /* round up to power of two for cheap multiply/division */
-   return util_next_power_of_two(MAX2(gs->info.gs.vertices_out, 1));
+   return util_next_power_of_two(gs->info.gs.vertices_out);
 }
 
 /* Variant of calc_unrolled_id that uses a power-of-two stride for indices. This
@@ -274,7 +270,8 @@ output_vertex_id_stride(nir_shader *gs)
 static nir_def *
 calc_unrolled_index_id(nir_builder *b)
 {
-   unsigned vertex_stride = output_vertex_id_stride(b->shader);
+   /* We know this is a dynamic topology and hence indexed */
+   unsigned vertex_stride = output_vertex_id_pot_stride(b->shader);
    nir_def *primitives_log2 = load_geometry_param(b, primitives_log2);
 
    nir_def *instance = nir_ishl(b, load_instance_id(b), primitives_log2);
@@ -292,7 +289,7 @@ load_xfb_count_address(nir_builder *b, struct lower_gs_state *state,
       return NULL;
 
    nir_def *prim_offset_el =
-      nir_imul_imm(b, unrolled_id, state->count_stride_el);
+      nir_imul_imm(b, unrolled_id, state->info->count_words);
 
    nir_def *offset_el = nir_iadd_imm(b, prim_offset_el, index);
 
@@ -306,14 +303,14 @@ write_xfb_counts(nir_builder *b, nir_intrinsic_instr *intr,
 {
    /* Store each required counter */
    nir_def *id =
-      state->prefix_summing ? calc_unrolled_id(b) : nir_imm_int(b, 0);
+      state->info->prefix_sum ? calc_unrolled_id(b) : nir_imm_int(b, 0);
 
    nir_def *addr =
       load_xfb_count_address(b, state, id, nir_intrinsic_stream_id(intr));
    if (!addr)
       return;
 
-   if (state->prefix_summing) {
+   if (state->info->prefix_sum) {
       nir_store_global(b, addr, 4, intr->src[2].ssa, nir_component_mask(1));
    } else {
       nir_global_atomic(b, 32, addr, intr->src[2].ssa,
@@ -359,8 +356,7 @@ lower_id(nir_builder *b, nir_intrinsic_instr *intr, void *data)
    else
       return false;
 
-   b->cursor = nir_instr_remove(&intr->instr);
-   nir_def_rewrite_uses(&intr->def, id);
+   nir_def_replace(&intr->def, id);
    return true;
 }
 
@@ -396,9 +392,10 @@ agx_nir_create_geometry_count_shader(nir_shader *gs,
 }
 
 struct lower_gs_rast_state {
+   nir_def *raw_instance_id;
    nir_def *instance_id, *primitive_id, *output_id;
-   struct agx_lower_output_to_var_state outputs;
-   struct agx_lower_output_to_var_state selected;
+   struct lower_output_to_var_state outputs;
+   struct lower_output_to_var_state selected;
 };
 
 static void
@@ -440,11 +437,15 @@ lower_to_gs_rast(nir_builder *b, nir_intrinsic_instr *intr, void *data)
       return true;
 
    case nir_intrinsic_load_primitive_id:
-      nir_def_rewrite_uses(&intr->def, state->primitive_id);
+      nir_def_replace(&intr->def, state->primitive_id);
       return true;
 
    case nir_intrinsic_load_instance_id:
-      nir_def_rewrite_uses(&intr->def, state->instance_id);
+      /* Don't lower recursively */
+      if (state->raw_instance_id == &intr->def)
+         return false;
+
+      nir_def_replace(&intr->def, state->instance_id);
       return true;
 
    case nir_intrinsic_load_flat_mask:
@@ -584,13 +585,12 @@ strip_side_effect_from_main(nir_builder *b, nir_intrinsic_instr *intr,
  * shades each rasterized output vertex in parallel.
  */
 static nir_shader *
-agx_nir_create_gs_rast_shader(const nir_shader *gs, bool *side_effects_for_rast)
+agx_nir_create_gs_rast_shader(const nir_shader *gs, bool *side_effects_for_rast,
+                              const struct lower_gs_state *state)
 {
    /* Don't muck up the original shader */
    nir_shader *shader = nir_shader_clone(NULL, gs);
 
-   unsigned max_verts = output_vertex_id_stride(shader);
-
    /* Turn into a vertex shader run only for rasterization. Transform feedback
     * was handled in the prepass.
     */
@@ -615,22 +615,45 @@ agx_nir_create_gs_rast_shader(const nir_shader *gs, bool *side_effects_for_rast)
    if (shader->info.gs.output_primitive != MESA_PRIM_POINTS)
       shader->info.outputs_written &= ~VARYING_BIT_PSIZ;
 
-   /* See calc_unrolled_index_id */
-   nir_def *raw_id = nir_load_vertex_id(b);
-   nir_def *output_id = nir_umod_imm(b, raw_id, max_verts);
-   nir_def *unrolled = nir_udiv_imm(b, raw_id, max_verts);
+   nir_def *raw_vertex_id = nir_load_vertex_id(b);
+   struct lower_gs_rast_state rs = {.raw_instance_id = nir_load_instance_id(b)};
 
-   nir_def *primitives_log2 = load_geometry_param(b, primitives_log2);
-   nir_def *instance_id = nir_ushr(b, unrolled, primitives_log2);
-   nir_def *primitive_id = nir_iand(
-      b, unrolled,
-      nir_iadd_imm(b, nir_ishl(b, nir_imm_int(b, 1), primitives_log2), -1));
-
-   struct lower_gs_rast_state rast_state = {
-      .instance_id = instance_id,
-      .primitive_id = primitive_id,
-      .output_id = output_id,
-   };
+   switch (state->info->shape) {
+   case AGX_GS_SHAPE_DYNAMIC_INDEXED: {
+      unsigned stride = output_vertex_id_pot_stride(gs);
+
+      nir_def *unrolled = nir_udiv_imm(b, raw_vertex_id, stride);
+      nir_def *primitives_log2 = load_geometry_param(b, primitives_log2);
+      nir_def *bit = nir_ishl(b, nir_imm_int(b, 1), primitives_log2);
+
+      rs.output_id = nir_umod_imm(b, raw_vertex_id, stride);
+      rs.instance_id = nir_ushr(b, unrolled, primitives_log2);
+      rs.primitive_id = nir_iand(b, unrolled, nir_iadd_imm(b, bit, -1));
+      break;
+   }
+
+   case AGX_GS_SHAPE_STATIC_INDEXED:
+   case AGX_GS_SHAPE_STATIC_PER_PRIM: {
+      nir_def *stride = load_geometry_param(b, gs_grid[0]);
+
+      rs.output_id = raw_vertex_id;
+      rs.instance_id = nir_udiv(b, rs.raw_instance_id, stride);
+      rs.primitive_id = nir_umod(b, rs.raw_instance_id, stride);
+      break;
+   }
+
+   case AGX_GS_SHAPE_STATIC_PER_INSTANCE: {
+      unsigned stride = MAX2(state->info->max_indices, 1);
+
+      rs.output_id = nir_umod_imm(b, raw_vertex_id, stride);
+      rs.primitive_id = nir_udiv_imm(b, raw_vertex_id, stride);
+      rs.instance_id = rs.raw_instance_id;
+      break;
+   }
+
+   default:
+      unreachable("invalid shape");
+   }
 
    u_foreach_bit64(slot, shader->info.outputs_written) {
       const char *slot_name =
@@ -641,24 +664,24 @@ agx_nir_create_gs_rast_shader(const nir_shader *gs, bool *side_effects_for_rast)
                     (slot == VARYING_SLOT_VIEWPORT);
       unsigned comps = scalar ? 1 : 4;
 
-      rast_state.outputs.outputs[slot] = nir_variable_create(
+      rs.outputs.outputs[slot] = nir_variable_create(
          shader, nir_var_shader_temp, glsl_vector_type(GLSL_TYPE_UINT, comps),
          ralloc_asprintf(shader, "%s-temp", slot_name));
 
-      rast_state.selected.outputs[slot] = nir_variable_create(
+      rs.selected.outputs[slot] = nir_variable_create(
          shader, nir_var_shader_temp, glsl_vector_type(GLSL_TYPE_UINT, comps),
          ralloc_asprintf(shader, "%s-selected", slot_name));
    }
 
    nir_shader_intrinsics_pass(shader, lower_to_gs_rast,
-                              nir_metadata_control_flow, &rast_state);
+                              nir_metadata_control_flow, &rs);
 
    b->cursor = nir_after_impl(b->impl);
 
    /* Forward each selected output to the rasterizer */
    u_foreach_bit64(slot, shader->info.outputs_written) {
-      assert(rast_state.selected.outputs[slot] != NULL);
-      nir_def *value = nir_load_var(b, rast_state.selected.outputs[slot]);
+      assert(rs.selected.outputs[slot] != NULL);
+      nir_def *value = nir_load_var(b, rs.selected.outputs[slot]);
 
       /* We set NIR_COMPACT_ARRAYS so clip/cull distance needs to come all in
        * DIST0. Undo the offset if we need to.
@@ -710,13 +733,10 @@ previous_xfb_primitives(nir_builder *b, struct lower_gs_state *state,
        * we can calculate the base.
        */
       return nir_imul_imm(b, unrolled_id, static_count);
-   } else if (state->prefix_summing) {
-      /* Otherwise, we need to load from the prefix sum buffer. Note that the
-       * sums are inclusive, so index 0 is nonzero. This requires a little
-       * fixup here. We use a saturating unsigned subtraction so we don't read
-       * out-of-bounds for zero.
-       *
-       * TODO: Optimize this.
+   } else if (state->info->prefix_sum) {
+      /* If we prefix summed, load from the sum buffer. Note that the sums are
+       * inclusive, so index 0 is nonzero. This requires a little fixup here. We
+       * use a saturating unsigned subtraction so we don't read out-of-bounds.
        */
       nir_def *prim_minus_1 = nir_usub_sat(b, unrolled_id, nir_imm_int(b, 1));
       nir_def *addr = load_xfb_count_address(b, state, prim_minus_1, stream);
@@ -751,23 +771,17 @@ lower_end_primitive(nir_builder *b, nir_intrinsic_instr *intr,
    libagx_end_primitive(
       b, load_geometry_param(b, output_index_buffer), intr->src[0].ssa,
       intr->src[1].ssa, intr->src[2].ssa,
-      nir_imul_imm(b, calc_unrolled_id(b), state->max_indices),
+      nir_imul_imm(b, calc_unrolled_id(b), state->info->max_indices),
       calc_unrolled_index_id(b),
       nir_imm_bool(b, b->shader->info.gs.output_primitive != MESA_PRIM_POINTS));
 }
 
-static unsigned
-verts_in_output_prim(nir_shader *gs)
-{
-   return mesa_vertices_per_prim(gs->info.gs.output_primitive);
-}
-
 static void
 write_xfb(nir_builder *b, struct lower_gs_state *state, unsigned stream,
           nir_def *index_in_strip, nir_def *prim_id_in_invocation)
 {
    struct nir_xfb_info *xfb = b->shader->xfb_info;
-   unsigned verts = verts_in_output_prim(b->shader);
+   unsigned verts = nir_verts_in_output_prim(b->shader);
 
    /* Get the index of this primitive in the XFB buffer. That is, the base for
     * this invocation for the stream plus the offset within this invocation.
@@ -849,7 +863,7 @@ lower_emit_vertex_xfb(nir_builder *b, nir_intrinsic_instr *intr,
     * we're writing strips, that means we output XFB for each vertex after the
     * first complete primitive is formed.
     */
-   unsigned first_prim = verts_in_output_prim(b->shader) - 1;
+   unsigned first_prim = nir_verts_in_output_prim(b->shader) - 1;
    nir_def *index_in_strip = intr->src[1].ssa;
 
    nir_push_if(b, nir_uge_imm(b, index_in_strip, first_prim));
@@ -874,11 +888,11 @@ lower_emit_vertex_xfb(nir_builder *b, nir_intrinsic_instr *intr,
     * vertex.
     */
    u_foreach_bit64(slot, b->shader->info.outputs_written) {
-      /* Note: if we're outputting points, verts_in_output_prim will be 1, so
-       * this loop will not execute. This is intended: points are self-contained
-       * primitives and do not need these copies.
+      /* Note: if we're outputting points, nir_verts_in_output_prim will be 1,
+       * so this loop will not execute. This is intended: points are
+       * self-contained primitives and do not need these copies.
        */
-      for (int v = verts_in_output_prim(b->shader) - 1; v >= 1; --v) {
+      for (int v = nir_verts_in_output_prim(b->shader) - 1; v >= 1; --v) {
          nir_def *value = nir_load_var(b, state->outputs[slot][v - 1]);
 
          nir_store_var(b, state->outputs[slot][v], value,
@@ -891,13 +905,16 @@ static bool
 lower_gs_instr(nir_builder *b, nir_intrinsic_instr *intr, void *state)
 {
    b->cursor = nir_before_instr(&intr->instr);
+   struct lower_gs_state *state_ = state;
 
    switch (intr->intrinsic) {
    case nir_intrinsic_set_vertex_and_primitive_count: {
+      if (state_->info->shape != AGX_GS_SHAPE_DYNAMIC_INDEXED)
+         break;
+
       /* Points write their index buffer here, other primitives write on end. We
        * also pad the index buffer here for the rasterization stream.
        */
-      struct lower_gs_state *state_ = state;
       if (b->shader->info.gs.output_primitive == MESA_PRIM_POINTS) {
          lower_end_primitive(b, intr, state);
       }
@@ -906,14 +923,17 @@ lower_gs_instr(nir_builder *b, nir_intrinsic_instr *intr, void *state)
          libagx_pad_index_gs(b, load_geometry_param(b, output_index_buffer),
                              intr->src[0].ssa, intr->src[1].ssa,
                              calc_unrolled_id(b),
-                             nir_imm_int(b, state_->max_indices));
+                             nir_imm_int(b, state_->info->max_indices));
       }
 
       break;
    }
 
    case nir_intrinsic_end_primitive_with_counter: {
-      unsigned min = verts_in_output_prim(b->shader);
+      if (state_->info->shape != AGX_GS_SHAPE_DYNAMIC_INDEXED)
+         break;
+
+      unsigned min = nir_verts_in_output_prim(b->shader);
 
       /* We only write out complete primitives */
       nir_push_if(b, nir_uge_imm(b, intr->src[1].ssa, min));
@@ -1108,8 +1128,8 @@ rewrite_invocation_id(nir_builder *b, nir_intrinsic_instr *intr, void *data)
    if (intr->intrinsic != nir_intrinsic_load_invocation_id)
       return false;
 
-   b->cursor = nir_instr_remove(&intr->instr);
-   nir_def_rewrite_uses(&intr->def, nir_u2uN(b, data, intr->def.bit_size));
+   b->cursor = nir_before_instr(&intr->instr);
+   nir_def_replace(&intr->def, nir_u2uN(b, data, intr->def.bit_size));
    return true;
 }
 
@@ -1196,6 +1216,164 @@ calculate_max_indices(enum mesa_prim prim, unsigned verts, signed static_verts,
       return verts + (verts / mesa_vertices_per_prim(prim));
 }
 
+struct topology_ctx {
+   struct agx_gs_info *info;
+   uint32_t topology[384];
+};
+
+static bool
+evaluate_topology(nir_builder *b, nir_intrinsic_instr *intr, void *data)
+{
+   bool points = b->shader->info.gs.output_primitive == MESA_PRIM_POINTS;
+   bool end_prim = intr->intrinsic == nir_intrinsic_end_primitive_with_counter;
+   bool set_prim =
+      intr->intrinsic == nir_intrinsic_set_vertex_and_primitive_count;
+
+   struct topology_ctx *ctx = data;
+   struct agx_gs_info *info = ctx->info;
+   if (!(set_prim && points) && !end_prim)
+      return false;
+
+   assert(!(end_prim && points) && "should have been deleted");
+
+   /* Only consider the rasterization stream. */
+   if (nir_intrinsic_stream_id(intr) != 0)
+      return false;
+
+   /* All end primitives must be executed exactly once. That happens if
+    * everything is in the start block.
+    *
+    * Strictly we could relax this (to handle if-statements interleaved with
+    * other stuff).
+    */
+   if (intr->instr.block != nir_start_block(b->impl)) {
+      info->shape = AGX_GS_SHAPE_DYNAMIC_INDEXED;
+      return false;
+   }
+
+   /* The topology must be static */
+   if (!nir_src_is_const(intr->src[0]) || !nir_src_is_const(intr->src[1]) ||
+       !nir_src_is_const(intr->src[2])) {
+
+      info->shape = AGX_GS_SHAPE_DYNAMIC_INDEXED;
+      return false;
+   }
+
+   unsigned min = nir_verts_in_output_prim(b->shader);
+
+   if (nir_src_as_uint(intr->src[1]) >= min) {
+      _libagx_end_primitive(ctx->topology, nir_src_as_uint(intr->src[0]),
+                            nir_src_as_uint(intr->src[1]),
+                            nir_src_as_uint(intr->src[2]), 0, 0, !points);
+   }
+
+   return false;
+}
+
+/*
+ * Pattern match the index buffer with restart against a list topology:
+ *
+ *    0, 1, 2, -1, 3, 4, 5, -1, ...
+ */
+static bool
+match_list_topology(struct agx_gs_info *info, uint32_t count,
+                    uint32_t *topology)
+{
+   unsigned count_with_restart = count + 1;
+
+   /* Must be an integer number of primitives */
+   if (info->max_indices % count_with_restart)
+      return false;
+
+   /* Must match the list topology */
+   for (unsigned i = 0; i < info->max_indices; ++i) {
+      bool restart = (i % count_with_restart) == count;
+      uint32_t expected = restart ? -1 : (i - (i / count_with_restart));
+
+      if (topology[i] != expected)
+         return false;
+   }
+
+   /* If we match, rewrite the topology and drop indexing */
+   info->shape = AGX_GS_SHAPE_STATIC_PER_INSTANCE;
+   info->mode = u_decomposed_prim(info->mode);
+   info->max_indices = (info->max_indices / count_with_restart) * count;
+   return true;
+}
+
+static bool
+is_strip_topology(uint32_t *indices, uint32_t index_count)
+{
+   for (unsigned i = 0; i < index_count; ++i) {
+      if (indices[i] != i)
+         return false;
+   }
+
+   return true;
+}
+
+/*
+ * To handle the general case of geometry shaders generating dynamic topologies,
+ * we translate geometry shaders into compute shaders that write an index
+ * buffer. In practice, many geometry shaders have static topologies that can be
+ * determined at compile-time. By identifying these, we can avoid the dynamic
+ * index buffer allocation and writes. optimize_static_topology tries to
+ * statically determine the topology, then translating it to one of:
+ *
+ * 1. Non-indexed line/triangle lists without instancing.
+ * 2. Non-indexed line/triangle strips, instanced per input primitive.
+ * 3. Static index buffer, instanced per input primitive.
+ *
+ * If the geometry shader has no side effect, the only job of the compute shader
+ * is writing this index buffer, so this optimization effectively eliminates the
+ * compute dispatch entirely. That means simple VS+GS pipelines turn into simple
+ * VS(compute) + GS(vertex) sequences without auxiliary programs.
+ */
+static void
+optimize_static_topology(struct agx_gs_info *info, nir_shader *gs)
+{
+   struct topology_ctx ctx = {.info = info};
+   nir_shader_intrinsics_pass(gs, evaluate_topology, nir_metadata_all, &ctx);
+   if (info->shape == AGX_GS_SHAPE_DYNAMIC_INDEXED)
+      return;
+
+   /* Points are always lists */
+   if (gs->info.gs.output_primitive == MESA_PRIM_POINTS) {
+      info->shape = AGX_GS_SHAPE_STATIC_PER_INSTANCE;
+      return;
+   }
+
+   /* Try to pattern match a list topology */
+   unsigned count = nir_verts_in_output_prim(gs);
+   if (match_list_topology(info, count, ctx.topology))
+      return;
+
+   /* Instancing means we can always drop the trailing restart index */
+   info->max_indices--;
+
+   /* Try to pattern match a strip topology */
+   if (is_strip_topology(ctx.topology, info->max_indices)) {
+      info->shape = AGX_GS_SHAPE_STATIC_PER_PRIM;
+      return;
+   }
+
+   /* Otherwise, use a small static index buffer. There's no theoretical reason
+    * to bound this, but we want small serialized shader info structs. We assume
+    * that large static index buffers are rare and hence fall back to dynamic.
+    */
+   if (info->max_indices >= ARRAY_SIZE(info->topology)) {
+      info->shape = AGX_GS_SHAPE_DYNAMIC_INDEXED;
+      return;
+   }
+
+   for (unsigned i = 0; i < info->max_indices; ++i) {
+      assert((ctx.topology[i] < 0xFF || ctx.topology[i] == ~0) && "small");
+      info->topology[i] = ctx.topology[i];
+   }
+
+   info->shape = AGX_GS_SHAPE_STATIC_INDEXED;
+}
+
 bool
 agx_nir_lower_gs(nir_shader *gs, bool rasterizer_discard, nir_shader **gs_count,
                  nir_shader **gs_copy, nir_shader **pre_gs,
@@ -1271,6 +1449,13 @@ agx_nir_lower_gs(nir_shader *gs, bool rasterizer_discard, nir_shader **gs_count,
     */
    struct lower_gs_state gs_state = {
       .rasterizer_discard = rasterizer_discard,
+      .info = info,
+   };
+
+   *info = (struct agx_gs_info){
+      .mode = gs->info.gs.output_primitive,
+      .xfb = gs->xfb_info != NULL,
+      .shape = -1,
    };
 
    int static_vertices[4] = {0}, static_primitives[4] = {0};
@@ -1282,19 +1467,25 @@ agx_nir_lower_gs(nir_shader *gs, bool rasterizer_discard, nir_shader **gs_count,
     */
    for (unsigned i = 0; i < MAX_VERTEX_STREAMS; ++i) {
       gs_state.count_index[i] =
-         (gs_state.static_count[i] < 0) ? gs_state.count_stride_el++ : -1;
+         (gs_state.static_count[i] < 0) ? info->count_words++ : -1;
    }
 
    /* Using the gathered static counts, choose the index buffer stride. */
-   gs_state.max_indices = calculate_max_indices(
+   info->max_indices = calculate_max_indices(
       gs->info.gs.output_primitive, gs->info.gs.vertices_out,
       static_vertices[0], static_primitives[0]);
 
-   gs_state.prefix_summing =
-      gs_state.count_stride_el > 0 && gs->xfb_info != NULL;
+   info->prefix_sum = info->count_words > 0 && gs->xfb_info != NULL;
+
+   if (static_vertices[0] >= 0 && static_primitives[0] >= 0) {
+      optimize_static_topology(info, gs);
+   } else {
+      info->shape = AGX_GS_SHAPE_DYNAMIC_INDEXED;
+   }
 
    bool side_effects_for_rast = false;
-   *gs_copy = agx_nir_create_gs_rast_shader(gs, &side_effects_for_rast);
+   *gs_copy =
+      agx_nir_create_gs_rast_shader(gs, &side_effects_for_rast, &gs_state);
 
    NIR_PASS(_, gs, nir_shader_intrinsics_pass, lower_id,
             nir_metadata_control_flow, NULL);
@@ -1306,13 +1497,13 @@ agx_nir_lower_gs(nir_shader *gs, bool rasterizer_discard, nir_shader **gs_count,
    NIR_PASS(_, gs, nir_remove_dead_variables, nir_var_function_temp, NULL);
 
    /* If there is any unknown count, we need a geometry count shader */
-   if (gs_state.count_stride_el > 0)
+   if (info->count_words > 0)
       *gs_count = agx_nir_create_geometry_count_shader(gs, &gs_state);
    else
       *gs_count = NULL;
 
    /* Geometry shader outputs are staged to temporaries */
-   struct agx_lower_output_to_var_state state = {0};
+   struct lower_output_to_var_state state = {0};
 
    u_foreach_bit64(slot, gs->info.outputs_written) {
       /* After enough optimizations, the shader metadata can go out of sync, fix
@@ -1336,7 +1527,7 @@ agx_nir_lower_gs(nir_shader *gs, bool rasterizer_discard, nir_shader **gs_count,
       state.outputs[slot] = gs_state.outputs[slot][0];
    }
 
-   NIR_PASS(_, gs, nir_shader_instructions_pass, agx_lower_output_to_var,
+   NIR_PASS(_, gs, nir_shader_instructions_pass, lower_output_to_var,
             nir_metadata_control_flow, &state);
 
    NIR_PASS(_, gs, nir_shader_intrinsics_pass, lower_gs_instr,
@@ -1390,18 +1581,9 @@ agx_nir_lower_gs(nir_shader *gs, bool rasterizer_discard, nir_shader **gs_count,
 
    /* Create auxiliary programs */
    *pre_gs = agx_nir_create_pre_gs(
-      &gs_state, gs->xfb_info, verts_in_output_prim(gs),
+      &gs_state, gs->xfb_info, nir_verts_in_output_prim(gs),
       gs->info.gs.active_stream_mask, gs->info.gs.invocations);
 
-   /* Signal what primitive we want to draw the GS Copy VS with */
-   *info = (struct agx_gs_info){
-      .mode = gs->info.gs.output_primitive,
-      .count_words = gs_state.count_stride_el,
-      .prefix_sum = gs_state.prefix_summing,
-      .max_indices = gs_state.max_indices,
-      .xfb = gs->xfb_info != NULL,
-   };
-
    return true;
 }
 
@@ -1425,13 +1607,7 @@ lower_vs_before_gs(nir_builder *b, nir_intrinsic_instr *intr, void *data)
    nir_io_semantics sem = nir_intrinsic_io_semantics(intr);
    nir_def *location = nir_iadd_imm(b, intr->src[1].ssa, sem.location);
 
-   /* We inline the outputs_written because it's known at compile-time, even
-    * with shader objects. This lets us constant fold a bit of address math.
-    */
-   nir_def *mask = nir_imm_int64(b, b->shader->info.outputs_written);
-
-   nir_def *buffer;
-   nir_def *nr_verts;
+   nir_def *buffer, *nr_verts, *instance_id, *primitive_id;
    if (b->shader->info.stage == MESA_SHADER_VERTEX) {
       buffer = nir_load_vs_output_buffer_agx(b);
       nr_verts =
@@ -1444,11 +1620,21 @@ lower_vs_before_gs(nir_builder *b, nir_intrinsic_instr *intr, void *data)
       buffer = libagx_tes_buffer(b, nir_load_tess_param_buffer_agx(b));
    }
 
-   nir_def *linear_id = nir_iadd(b, nir_imul(b, load_instance_id(b), nr_verts),
-                                 load_primitive_id(b));
+   if (b->shader->info.stage == MESA_SHADER_VERTEX &&
+       !b->shader->info.vs.tes_agx) {
+      primitive_id = nir_load_vertex_id_zero_base(b);
+      instance_id = nir_load_instance_id(b);
+   } else {
+      primitive_id = load_primitive_id(b);
+      instance_id = load_instance_id(b);
+   }
 
-   nir_def *addr =
-      libagx_vertex_output_address(b, buffer, mask, linear_id, location);
+   nir_def *linear_id =
+      nir_iadd(b, nir_imul(b, instance_id, nr_verts), primitive_id);
+
+   nir_def *addr = libagx_vertex_output_address(
+      b, buffer, nir_imm_int64(b, b->shader->info.outputs_written), linear_id,
+      location);
 
    assert(nir_src_bit_size(intr->src[0]) == 32);
    addr = nir_iadd_imm(b, addr, nir_intrinsic_component(intr) * 4);
diff --git a/src/asahi/lib/agx_nir_lower_gs.h b/src/asahi/lib/agx_nir_lower_gs.h
index 2747de3c254..fc3080f1e6d 100644
--- a/src/asahi/lib/agx_nir_lower_gs.h
+++ b/src/asahi/lib/agx_nir_lower_gs.h
@@ -7,18 +7,10 @@
 
 #include <stdbool.h>
 #include <stdint.h>
+#include "libagx/geometry.h"
 #include "nir.h"
 #include "shader_enums.h"
 
-enum mesa_prim;
-
-struct agx_lower_output_to_var_state {
-   struct nir_variable *outputs[NUM_TOTAL_VARYING_SLOTS];
-};
-
-bool agx_lower_output_to_var(struct nir_builder *b, struct nir_instr *instr,
-                             void *data);
-
 struct nir_def *agx_load_per_vertex_input(struct nir_builder *b,
                                           nir_intrinsic_instr *intr,
                                           struct nir_def *vertex);
@@ -45,6 +37,12 @@ struct agx_gs_info {
 
    /* Whether a prefix sum is required on the count outputs. Implies xfb */
    bool prefix_sum;
+
+   /* Shape of the rasterization draw, named by the instance ID */
+   enum agx_gs_shape shape;
+
+   /* Static topology used if shape = AGX_GS_SHAPE_STATIC_INDEXED */
+   uint8_t topology[64];
 };
 
 bool agx_nir_lower_gs(struct nir_shader *gs, bool rasterizer_discard,
diff --git a/src/asahi/lib/agx_nir_lower_msaa.c b/src/asahi/lib/agx_nir_lower_msaa.c
index 06636141b37..888e5d729dd 100644
--- a/src/asahi/lib/agx_nir_lower_msaa.c
+++ b/src/asahi/lib/agx_nir_lower_msaa.c
@@ -27,7 +27,7 @@ lower_to_per_sample(nir_builder *b, nir_intrinsic_instr *intr, void *data)
    case nir_intrinsic_load_local_pixel_agx:
    case nir_intrinsic_store_local_pixel_agx:
    case nir_intrinsic_store_zs_agx:
-   case nir_intrinsic_discard_agx:
+   case nir_intrinsic_demote_samples:
    case nir_intrinsic_sample_mask_agx: {
       /* Fragment I/O inside the loop should only affect active samples. */
       unsigned mask_index =
diff --git a/src/asahi/lib/agx_nir_lower_sample_intrinsics.c b/src/asahi/lib/agx_nir_lower_sample_intrinsics.c
index c0b8776f76a..9cbdeffb4f9 100644
--- a/src/asahi/lib/agx_nir_lower_sample_intrinsics.c
+++ b/src/asahi/lib/agx_nir_lower_sample_intrinsics.c
@@ -175,7 +175,7 @@ lower(nir_builder *b, nir_intrinsic_instr *intr, void *data)
       if (*ignore_sample_mask_without_msaa)
          mask = select_if_msaa_else_0(b, mask);
 
-      nir_discard_agx(b, mask);
+      nir_demote_samples(b, mask);
       nir_instr_remove(&intr->instr);
 
       b->shader->info.fs.uses_discard = true;
@@ -196,8 +196,8 @@ lower(nir_builder *b, nir_intrinsic_instr *intr, void *data)
  * The load_sample_id intrinsics themselves are lowered later, with different
  * lowerings for monolithic vs epilogs.
  *
- * Note that fragment I/O (like store_local_pixel_agx and discard_agx) does not
- * get lowered here, because that lowering is different for monolithic vs FS
+ * Note that fragment I/O (like store_local_pixel_agx and demote_samples) does
+ * not get lowered here, because that lowering is different for monolithic vs FS
  * epilogs even though there's no dependency on sample count.
  */
 bool
diff --git a/src/asahi/lib/agx_nir_lower_tess.c b/src/asahi/lib/agx_nir_lower_tess.c
index aaf16a46b3a..584847d79b3 100644
--- a/src/asahi/lib/agx_nir_lower_tess.c
+++ b/src/asahi/lib/agx_nir_lower_tess.c
@@ -15,18 +15,6 @@
 #include "nir_intrinsics_indices.h"
 #include "shader_enums.h"
 
-static nir_def *
-tcs_patch_id(nir_builder *b)
-{
-   return nir_channel(b, nir_load_workgroup_id(b), 0);
-}
-
-static nir_def *
-tcs_instance_id(nir_builder *b)
-{
-   return nir_channel(b, nir_load_workgroup_id(b), 1);
-}
-
 static nir_def *
 tcs_unrolled_id(nir_builder *b)
 {
@@ -111,10 +99,10 @@ lower_tcs_impl(nir_builder *b, nir_intrinsic_instr *intr)
       return NIR_LOWER_INSTR_PROGRESS_REPLACE;
 
    case nir_intrinsic_load_primitive_id:
-      return tcs_patch_id(b);
+      return nir_channel(b, nir_load_workgroup_id(b), 0);
 
    case nir_intrinsic_load_instance_id:
-      return tcs_instance_id(b);
+      return nir_channel(b, nir_load_workgroup_id(b), 1);
 
    case nir_intrinsic_load_invocation_id:
       if (b->shader->info.tess.tcs_vertices_out == 1)
@@ -236,9 +224,6 @@ lower_tes(nir_builder *b, nir_intrinsic_instr *intr, void *data)
 static bool
 lower_tes_indexing(nir_builder *b, nir_intrinsic_instr *intr, void *data)
 {
-   if (intr->intrinsic == nir_intrinsic_load_instance_id)
-      unreachable("todo");
-
    if (intr->intrinsic != nir_intrinsic_load_vertex_id)
       return false;
 
diff --git a/src/asahi/lib/agx_nir_prolog_epilog.c b/src/asahi/lib/agx_nir_prolog_epilog.c
index c95ce81baa9..c26d1a11e0b 100644
--- a/src/asahi/lib/agx_nir_prolog_epilog.c
+++ b/src/asahi/lib/agx_nir_prolog_epilog.c
@@ -193,6 +193,11 @@ agx_nir_vs_prolog(nir_builder *b, const void *key_)
       nir_export_agx(b, nir_channel(b, vec, c), .base = AGX_ABI_VIN_ATTRIB(i));
    }
 
+   if (!key->hw) {
+      nir_export_agx(b, nir_channel(b, nir_load_global_invocation_id(b, 32), 0),
+                     .base = AGX_ABI_VIN_VERTEX_ID_ZERO_BASE);
+   }
+
    nir_export_agx(b, nir_load_vertex_id(b), .base = AGX_ABI_VIN_VERTEX_ID);
    nir_export_agx(b, nir_load_instance_id(b), .base = AGX_ABI_VIN_INSTANCE_ID);
 
@@ -447,7 +452,8 @@ agx_nir_fs_epilog(nir_builder *b, const void *key_)
 
    /* Alpha-to-coverage must be lowered before alpha-to-one */
    if (key->blend.alpha_to_coverage)
-      NIR_PASS(_, b->shader, agx_nir_lower_alpha_to_coverage, tib.nr_samples);
+      NIR_PASS(_, b->shader, nir_lower_alpha_to_coverage, tib.nr_samples,
+               false);
 
    /* Depth/stencil writes must be deferred until after all discards,
     * particularly alpha-to-coverage.
@@ -468,7 +474,7 @@ agx_nir_fs_epilog(nir_builder *b, const void *key_)
 
    /* Alpha-to-one must be lowered before blending */
    if (key->blend.alpha_to_one)
-      NIR_PASS(_, b->shader, agx_nir_lower_alpha_to_one);
+      NIR_PASS(_, b->shader, nir_lower_alpha_to_one);
 
    NIR_PASS(_, b->shader, nir_lower_blend, &opts);
 
@@ -550,7 +556,7 @@ lower_output_to_epilog(nir_builder *b, nir_intrinsic_instr *intr, void *data)
       return true;
    }
 
-   if (intr->intrinsic == nir_intrinsic_discard_agx &&
+   if (intr->intrinsic == nir_intrinsic_demote_samples &&
        b->shader->info.fs.early_fragment_tests) {
 
       if (!ctx->masked_samples) {
@@ -697,7 +703,7 @@ agx_nir_fs_prolog(nir_builder *b, const void *key_)
    /* First, insert code for any emulated features */
    if (key->api_sample_mask != 0xff) {
       /* Kill samples that are NOT covered by the mask */
-      nir_discard_agx(b, nir_imm_intN_t(b, key->api_sample_mask ^ 0xff, 16));
+      nir_demote_samples(b, nir_imm_intN_t(b, key->api_sample_mask ^ 0xff, 16));
       b->shader->info.fs.uses_discard = true;
    }
 
diff --git a/src/asahi/lib/agx_tilebuffer.h b/src/asahi/lib/agx_tilebuffer.h
index ae227483e2d..da0acf58cea 100644
--- a/src/asahi/lib/agx_tilebuffer.h
+++ b/src/asahi/lib/agx_tilebuffer.h
@@ -106,11 +106,6 @@ bool agx_nir_lower_monolithic_msaa(struct nir_shader *shader,
 bool agx_nir_lower_sample_intrinsics(struct nir_shader *shader,
                                      bool ignore_sample_mask_without_msaa);
 
-bool agx_nir_lower_alpha_to_coverage(struct nir_shader *shader,
-                                     uint8_t nr_samples);
-
-bool agx_nir_lower_alpha_to_one(struct nir_shader *shader);
-
 uint32_t agx_tilebuffer_total_size(struct agx_tilebuffer_layout *tib);
 
 enum pipe_format
diff --git a/src/asahi/lib/meson.build b/src/asahi/lib/meson.build
index 4649dcf3395..dfff7e9945b 100644
--- a/src/asahi/lib/meson.build
+++ b/src/asahi/lib/meson.build
@@ -11,7 +11,6 @@ libasahi_lib_files = files(
   'agx_linker.c',
   'agx_bg_eot.c',
   'agx_tilebuffer.c',
-  'agx_nir_lower_alpha.c',
   'agx_nir_lower_gs.c',
   'agx_nir_lower_ia.c',
   'agx_nir_lower_msaa.c',
diff --git a/src/asahi/libagx/geometry.cl b/src/asahi/libagx/geometry.cl
index f788955b838..ac7eb0fe0ec 100644
--- a/src/asahi/libagx/geometry.cl
+++ b/src/asahi/libagx/geometry.cl
@@ -443,9 +443,8 @@ first_true_thread_in_workgroup(bool cond, local uint *scratch)
  * sets up most of the new draw descriptor.
  */
 static global void *
-setup_unroll_for_draw(global struct agx_geometry_state *heap,
-                      constant uint *in_draw, global uint *out,
-                      enum mesa_prim mode, uint index_size_B)
+setup_unroll_for_draw(global struct agx_heap *heap, constant uint *in_draw,
+                      global uint *out, enum mesa_prim mode, uint index_size_B)
 {
    /* Determine an upper bound on the memory required for the index buffer.
     * Restarts only decrease the unrolled index buffer size, so the maximum size
@@ -469,16 +468,15 @@ setup_unroll_for_draw(global struct agx_geometry_state *heap,
    out[4] = in_draw[4];                       /* base instance */
 
    /* Return the index buffer we allocated */
-   return (global uchar *)heap->heap + old_heap_bottom_B;
+   return (global uchar *)heap->base + old_heap_bottom_B;
 }
 
 KERNEL(1024)
-libagx_unroll_restart(global struct agx_geometry_state *heap,
-                      uint64_t index_buffer, constant uint *in_draw,
-                      global uint32_t *out_draw, uint32_t max_draws,
-                      uint32_t restart_index, uint32_t index_buffer_size_el,
-                      uint32_t index_size_log2, uint32_t flatshade_first,
-                      uint mode__11)
+libagx_unroll_restart(global struct agx_heap *heap, uint64_t index_buffer,
+                      constant uint *in_draw, global uint32_t *out_draw,
+                      uint32_t max_draws, uint32_t restart_index,
+                      uint32_t index_buffer_size_el, uint32_t index_size_log2,
+                      uint32_t flatshade_first, uint mode__11)
 {
    uint32_t index_size_B = 1 << index_size_log2;
    enum mesa_prim mode = libagx_uncompact_prim(mode__11);
@@ -555,43 +553,13 @@ libagx_setup_xfb_buffer(global struct agx_geometry_params *p, uint i)
    return off;
 }
 
-/*
- * Translate EndPrimitive for LINE_STRIP or TRIANGLE_STRIP output prims into
- * writes into the 32-bit output index buffer. We write the sequence (b, b + 1,
- * b + 2, ..., b + n - 1, -1), where b (base) is the first vertex in the prim, n
- * (count) is the number of verts in the prims, and -1 is the prim restart index
- * used to signal the end of the prim.
- *
- * For points, we write index buffers without restart, just as a sideband to
- * pass data into the vertex shader.
- */
 void
-libagx_end_primitive(global int *index_buffer, uint total_verts,
+libagx_end_primitive(global uint32_t *index_buffer, uint total_verts,
                      uint verts_in_prim, uint total_prims, uint index_offs,
                      uint geometry_base, bool restart)
 {
-   /* Previous verts/prims are from previous invocations plus earlier
-    * prims in this invocation. For the intra-invocation counts, we
-    * subtract the count for this prim from the inclusive sum NIR gives us.
-    */
-   uint previous_verts_in_invoc = (total_verts - verts_in_prim);
-   uint previous_verts = previous_verts_in_invoc;
-   uint previous_prims = restart ? (total_prims - 1) : 0;
-
-   /* The indices are encoded as: (unrolled ID * output vertices) + vertex. */
-   uint index_base = geometry_base + previous_verts_in_invoc;
-
-   /* Index buffer contains 1 index for each vertex and 1 for each prim */
-   global int *out =
-      &index_buffer[index_offs + previous_verts + previous_prims];
-
-   /* Write out indices for the strip */
-   for (uint i = 0; i < verts_in_prim; ++i) {
-      out[i] = index_base + i;
-   }
-
-   if (restart)
-      out[verts_in_prim] = -1;
+   _libagx_end_primitive(index_buffer, total_verts, verts_in_prim, total_prims,
+                         index_offs, geometry_base, restart);
 }
 
 void
@@ -609,11 +577,12 @@ libagx_gs_setup_indirect(
    global uintptr_t *vertex_buffer /* output */,
    global struct agx_ia_state *ia /* output */,
    global struct agx_geometry_params *p /* output */,
+   global struct agx_heap *heap,
    uint64_t vs_outputs /* Vertex (TES) output mask */,
    uint32_t index_size_B /* 0 if no index bffer */,
    uint32_t index_buffer_range_el,
    uint32_t prim /* Input primitive type, enum mesa_prim */,
-   int is_prefix_summing, uint indices_per_in_prim)
+   int is_prefix_summing, uint max_indices, enum agx_gs_shape shape)
 {
    /* Determine the (primitives, instances) grid size. */
    uint vertex_count = draw[0];
@@ -648,35 +617,37 @@ libagx_gs_setup_indirect(
    }
 
    /* We need to allocate VS and GS count buffers, do so now */
-   global struct agx_geometry_state *state = p->state;
-
    uint vertex_buffer_size =
       libagx_tcs_in_size(vertex_count * instance_count, vs_outputs);
 
    if (is_prefix_summing) {
       p->count_buffer = agx_heap_alloc_nonatomic(
-         state, p->input_primitives * p->count_buffer_stride);
+         heap, p->input_primitives * p->count_buffer_stride);
    }
 
    p->input_buffer =
-      (uintptr_t)agx_heap_alloc_nonatomic(state, vertex_buffer_size);
+      (uintptr_t)agx_heap_alloc_nonatomic(heap, vertex_buffer_size);
    *vertex_buffer = p->input_buffer;
 
    p->input_mask = vs_outputs;
 
    /* Allocate the index buffer and write the draw consuming it */
    global VkDrawIndexedIndirectCommand *cmd = (global void *)p->indirect_desc;
-   uint count = p->input_primitives * indices_per_in_prim;
-   uint index_buffer_offset_B = agx_heap_alloc_nonatomic_offs(state, count * 4);
 
    *cmd = (VkDrawIndexedIndirectCommand){
-      .indexCount = count,
-      .instanceCount = 1,
-      .firstIndex = index_buffer_offset_B / 4,
+      .indexCount = agx_gs_rast_vertices(shape, max_indices, prim_per_instance,
+                                         instance_count),
+      .instanceCount = agx_gs_rast_instances(shape, max_indices,
+                                             prim_per_instance, instance_count),
    };
 
-   p->output_index_buffer =
-      (global uint *)(state->heap + index_buffer_offset_B);
+   if (shape == AGX_GS_SHAPE_DYNAMIC_INDEXED) {
+      cmd->firstIndex =
+         agx_heap_alloc_nonatomic_offs(heap, cmd->indexCount * 4) / 4;
+
+      p->output_index_buffer =
+         (global uint *)(heap->base + (cmd->firstIndex * 4));
+   }
 }
 
 /*
@@ -777,7 +748,7 @@ libagx_prefix_sum_tess(global struct libagx_tess_args *p, global uint *c_prims,
    uint32_t elsize_B = sizeof(uint32_t);
    uint32_t size_B = total * elsize_B;
    uint alloc_B = agx_heap_alloc_nonatomic_offs(p->heap, size_B);
-   p->index_buffer = (global uint32_t *)(((uintptr_t)p->heap->heap) + alloc_B);
+   p->index_buffer = (global uint32_t *)(((uintptr_t)p->heap->base) + alloc_B);
 
    /* ...and now we can generate the API indexed draw */
    global uint32_t *desc = p->out_draws;
diff --git a/src/asahi/libagx/geometry.h b/src/asahi/libagx/geometry.h
index 70bfcf6c29e..54ef991396b 100644
--- a/src/asahi/libagx/geometry.h
+++ b/src/asahi/libagx/geometry.h
@@ -11,41 +11,125 @@
 #include "util/bitscan.h"
 #include "util/u_math.h"
 
-#ifndef __OPENCL_VERSION__
-#define libagx_popcount(x)   util_bitcount64(x)
-#define libagx_sub_sat(x, y) ((x >= y) ? (x - y) : 0)
-#else
-#define libagx_popcount(x)   popcount(x)
-#define libagx_sub_sat(x, y) sub_sat(x, y)
-#endif
-
-#ifndef LIBAGX_GEOMETRY_H
-#define LIBAGX_GEOMETRY_H
+#pragma once
 
 #define MAX_SO_BUFFERS     4
 #define MAX_VERTEX_STREAMS 4
 
-/* Packed geometry state buffer */
-struct agx_geometry_state {
-   /* Heap to allocate from. */
-   DEVICE(uchar) heap;
-   uint32_t heap_bottom, heap_size;
+enum agx_gs_shape {
+   /* Indexed, where indices are encoded as:
+    *
+    *    round_to_pot(max_indices) * round_to_pot(input_primitives) *
+    *                              * instance_count
+    *
+    * invoked for max_indices * input_primitives * instance_count indices.
+    *
+    * This is used with any dynamic topology. No hardware instancing used.
+    */
+   AGX_GS_SHAPE_DYNAMIC_INDEXED,
+
+   /* Indexed with a static index buffer. Indices ranges up to max_indices.
+    * Hardware instance count = input_primitives * software instance count.
+    */
+   AGX_GS_SHAPE_STATIC_INDEXED,
+
+   /* Non-indexed. Dispatched as:
+    *
+    *    (max_indices, input_primitives * instance count).
+    */
+   AGX_GS_SHAPE_STATIC_PER_PRIM,
+
+   /* Non-indexed. Dispatched as:
+    *
+    *    (max_indices * input_primitives, instance count).
+    */
+   AGX_GS_SHAPE_STATIC_PER_INSTANCE,
+};
+
+static inline unsigned
+agx_gs_rast_vertices(enum agx_gs_shape shape, unsigned max_indices,
+                     unsigned input_primitives, unsigned instance_count)
+{
+   switch (shape) {
+   case AGX_GS_SHAPE_DYNAMIC_INDEXED:
+      return max_indices * input_primitives * instance_count;
+
+   case AGX_GS_SHAPE_STATIC_INDEXED:
+   case AGX_GS_SHAPE_STATIC_PER_PRIM:
+      return max_indices;
+
+   case AGX_GS_SHAPE_STATIC_PER_INSTANCE:
+      return max_indices * input_primitives;
+   }
+
+   unreachable("invalid shape");
+}
+
+static inline unsigned
+agx_gs_rast_instances(enum agx_gs_shape shape, unsigned max_indices,
+                      unsigned input_primitives, unsigned instance_count)
+{
+   switch (shape) {
+   case AGX_GS_SHAPE_DYNAMIC_INDEXED:
+      return 1;
+
+   case AGX_GS_SHAPE_STATIC_INDEXED:
+   case AGX_GS_SHAPE_STATIC_PER_PRIM:
+      return input_primitives * instance_count;
+
+   case AGX_GS_SHAPE_STATIC_PER_INSTANCE:
+      return instance_count;
+   }
+
+   unreachable("invalid shape");
+}
+
+static inline bool
+agx_gs_indexed(enum agx_gs_shape shape)
+{
+   return shape == AGX_GS_SHAPE_DYNAMIC_INDEXED ||
+          shape == AGX_GS_SHAPE_STATIC_INDEXED;
+}
+
+static inline unsigned
+agx_gs_index_size(enum agx_gs_shape shape)
+{
+   switch (shape) {
+   case AGX_GS_SHAPE_DYNAMIC_INDEXED:
+      return 4;
+   case AGX_GS_SHAPE_STATIC_INDEXED:
+      return 1;
+   default:
+      return 0;
+   }
+}
+
+/* Heap to allocate from. */
+struct agx_heap {
+   DEVICE(uchar) base;
+   uint32_t bottom, size;
 } PACKED;
-static_assert(sizeof(struct agx_geometry_state) == 4 * 4);
+static_assert(sizeof(struct agx_heap) == 4 * 4);
 
 #ifdef __OPENCL_VERSION__
 static inline uint
-agx_heap_alloc_nonatomic_offs(global struct agx_geometry_state *heap,
-                              uint size_B)
+_agx_heap_alloc_offs(global struct agx_heap *heap, uint size_B, bool atomic)
 {
-   uint offs = heap->heap_bottom;
-   heap->heap_bottom += align(size_B, 16);
+   size_B = align(size_B, 16);
+
+   uint offs;
+   if (atomic) {
+      offs = atomic_fetch_add((volatile atomic_uint *)(&heap->bottom), size_B);
+   } else {
+      offs = heap->bottom;
+      heap->bottom = offs + size_B;
+   }
 
-   // Use printf+abort because assert is stripped from release builds.
-   if (heap->heap_bottom >= heap->heap_size) {
+   /* Use printf+abort because assert is stripped from release builds. */
+   if (heap->bottom >= heap->size) {
       printf(
          "FATAL: GPU heap overflow, allocating size %u, at offset %u, heap size %u!",
-         size_B, offs, heap->heap_size);
+         size_B, offs, heap->size);
 
       abort();
    }
@@ -53,10 +137,22 @@ agx_heap_alloc_nonatomic_offs(global struct agx_geometry_state *heap,
    return offs;
 }
 
+static inline uint
+agx_heap_alloc_nonatomic_offs(global struct agx_heap *heap, uint size_B)
+{
+   return _agx_heap_alloc_offs(heap, size_B, false);
+}
+
+static inline uint
+agx_heap_alloc_atomic_offs(global struct agx_heap *heap, uint size_B)
+{
+   return _agx_heap_alloc_offs(heap, size_B, true);
+}
+
 static inline global void *
-agx_heap_alloc_nonatomic(global struct agx_geometry_state *heap, uint size_B)
+agx_heap_alloc_nonatomic(global struct agx_heap *heap, uint size_B)
 {
-   return heap->heap + agx_heap_alloc_nonatomic_offs(heap, size_B);
+   return heap->base + agx_heap_alloc_nonatomic_offs(heap, size_B);
 }
 #endif
 
@@ -87,13 +183,10 @@ libagx_index_buffer(uint64_t index_buffer, uint size_el, uint offset_el,
 static inline uint
 libagx_index_buffer_range_el(uint size_el, uint offset_el)
 {
-   return libagx_sub_sat(size_el, offset_el);
+   return offset_el < size_el ? (size_el - offset_el) : 0;
 }
 
 struct agx_geometry_params {
-   /* Persistent (cross-draw) geometry state */
-   DEVICE(struct agx_geometry_state) state;
-
    /* Address of associated indirect draw buffer */
    DEVICE(uint) indirect_desc;
 
@@ -140,10 +233,13 @@ struct agx_geometry_params {
    uint32_t xfb_prims[MAX_VERTEX_STREAMS];
 
    /* Within an indirect GS draw, the grids used to dispatch the VS/GS written
-    * out by the GS indirect setup kernel or the CPU for a direct draw.
+    * out by the GS indirect setup kernel or the CPU for a direct draw. This is
+    * the "indirect local" format: first 3 is in threads, second 3 is in grid
+    * blocks. This lets us use nontrivial workgroups with indirect draws without
+    * needing any predication.
     */
-   uint32_t vs_grid[3];
-   uint32_t gs_grid[3];
+   uint32_t vs_grid[6];
+   uint32_t gs_grid[6];
 
    /* Number of input primitives across all instances, calculated by the CPU for
     * a direct draw or the GS indirect setup kernel for an indirect draw.
@@ -167,7 +263,7 @@ struct agx_geometry_params {
     */
    uint32_t input_topology;
 } PACKED;
-static_assert(sizeof(struct agx_geometry_params) == 82 * 4);
+static_assert(sizeof(struct agx_geometry_params) == 86 * 4);
 
 /* TCS shared memory layout:
  *
@@ -179,8 +275,8 @@ static inline uint
 libagx_tcs_in_offs_el(uint vtx, gl_varying_slot location,
                       uint64_t crosslane_vs_out_mask)
 {
-   uint base = vtx * libagx_popcount(crosslane_vs_out_mask);
-   uint offs = libagx_popcount(crosslane_vs_out_mask &
+   uint base = vtx * util_bitcount64(crosslane_vs_out_mask);
+   uint offs = util_bitcount64(crosslane_vs_out_mask &
                                (((uint64_t)(1) << location) - 1));
 
    return base + offs;
@@ -196,7 +292,7 @@ libagx_tcs_in_offs(uint vtx, gl_varying_slot location,
 static inline uint
 libagx_tcs_in_size(uint32_t vertices_in_patch, uint64_t crosslane_vs_out_mask)
 {
-   return vertices_in_patch * libagx_popcount(crosslane_vs_out_mask) * 16;
+   return vertices_in_patch * util_bitcount64(crosslane_vs_out_mask) * 16;
 }
 
 /*
@@ -230,9 +326,9 @@ libagx_tcs_out_offs_el(uint vtx_id, gl_varying_slot location, uint nr_patch_out,
 
    /* Anything else is a per-vtx output */
    off += 4 * nr_patch_out;
-   off += 4 * vtx_id * libagx_popcount(vtx_out_mask);
+   off += 4 * vtx_id * util_bitcount64(vtx_out_mask);
 
-   uint idx = libagx_popcount(vtx_out_mask & (((uint64_t)(1) << location) - 1));
+   uint idx = util_bitcount64(vtx_out_mask & (((uint64_t)(1) << location) - 1));
    return off + (4 * idx);
 }
 
@@ -284,4 +380,41 @@ libagx_uncompact_prim(uint packed)
    return (packed >= MESA_PRIM_QUADS) ? (packed + 3) : packed;
 }
 
-#endif
+/*
+ * Translate EndPrimitive for LINE_STRIP or TRIANGLE_STRIP output prims into
+ * writes into the 32-bit output index buffer. We write the sequence (b, b + 1,
+ * b + 2, ..., b + n - 1, -1), where b (base) is the first vertex in the prim, n
+ * (count) is the number of verts in the prims, and -1 is the prim restart index
+ * used to signal the end of the prim.
+ *
+ * For points, we write index buffers without restart, just as a sideband to
+ * pass data into the vertex shader.
+ */
+static inline void
+_libagx_end_primitive(GLOBAL uint32_t *index_buffer, uint32_t total_verts,
+                      uint32_t verts_in_prim, uint32_t total_prims,
+                      uint32_t index_offs, uint32_t geometry_base, bool restart)
+{
+   /* Previous verts/prims are from previous invocations plus earlier
+    * prims in this invocation. For the intra-invocation counts, we
+    * subtract the count for this prim from the inclusive sum NIR gives us.
+    */
+   uint32_t previous_verts_in_invoc = (total_verts - verts_in_prim);
+   uint32_t previous_verts = previous_verts_in_invoc;
+   uint32_t previous_prims = restart ? (total_prims - 1) : 0;
+
+   /* The indices are encoded as: (unrolled ID * output vertices) + vertex. */
+   uint32_t index_base = geometry_base + previous_verts_in_invoc;
+
+   /* Index buffer contains 1 index for each vertex and 1 for each prim */
+   GLOBAL uint32_t *out =
+      &index_buffer[index_offs + previous_verts + previous_prims];
+
+   /* Write out indices for the strip */
+   for (uint32_t i = 0; i < verts_in_prim; ++i) {
+      out[i] = index_base + i;
+   }
+
+   if (restart)
+      out[verts_in_prim] = -1;
+}
diff --git a/src/asahi/libagx/tessellator.cl b/src/asahi/libagx/tessellator.cl
index bfbe862d7b1..957230e422d 100644
--- a/src/asahi/libagx/tessellator.cl
+++ b/src/asahi/libagx/tessellator.cl
@@ -117,14 +117,6 @@ tess_factors(constant struct libagx_tess_args *p, uint patch)
    return p->tcs_buffer + (patch * p->tcs_stride_el);
 }
 
-static inline uint
-libagx_heap_alloc(global struct agx_geometry_state *heap, uint size_B)
-{
-   // TODO: drop align to 4 I think
-   return atomic_fetch_add((volatile atomic_uint *)(&heap->heap_bottom),
-                           align(size_B, 8));
-}
-
 /*
  * Generate an indexed draw for a patch with the computed number of indices.
  * This allocates heap memory for the index buffer, returning the allocated
@@ -196,11 +188,11 @@ libagx_heap_alloc_points(constant struct libagx_tess_args *p, uint patch,
    }
 
    uint32_t elsize_B = sizeof(struct libagx_tess_point);
-   uint32_t alloc_B = libagx_heap_alloc(p->heap, elsize_B * count);
+   uint32_t alloc_B = agx_heap_alloc_atomic_offs(p->heap, elsize_B * count);
    uint32_t alloc_el = alloc_B / elsize_B;
 
    p->coord_allocs[patch] = alloc_el;
-   return (global struct libagx_tess_point *)(((uintptr_t)p->heap->heap) +
+   return (global struct libagx_tess_point *)(((uintptr_t)p->heap->base) +
                                               alloc_B);
 }
 
diff --git a/src/asahi/libagx/tessellator.h b/src/asahi/libagx/tessellator.h
index ced21ad563e..5841d5578f1 100644
--- a/src/asahi/libagx/tessellator.h
+++ b/src/asahi/libagx/tessellator.h
@@ -29,7 +29,7 @@ static_assert(sizeof(struct libagx_tess_point) == 8);
 
 struct libagx_tess_args {
    /* Heap to allocate tessellator outputs in */
-   DEVICE(struct agx_geometry_state) heap;
+   DEVICE(struct agx_heap) heap;
 
    /* Patch coordinate buffer, indexed as:
     *
diff --git a/src/asahi/meson.build b/src/asahi/meson.build
index aaa7da43ccd..c1ff8c62c01 100644
--- a/src/asahi/meson.build
+++ b/src/asahi/meson.build
@@ -9,15 +9,12 @@ inc_asahi = include_directories([
    '.', 'layout', 'lib', 'genxml', 'compiler'
 ])
 
-if with_gallium_asahi or with_asahi_vk or with_tools.contains('asahi')
+if with_gallium_asahi or with_asahi_vk
    subdir('genxml')
    subdir('libagx')
+   subdir('layout')
    subdir('compiler')
    subdir('clc')
-endif
-
-if with_gallium_asahi or with_asahi_vk
-   subdir('layout')
    subdir('lib')
 elif dep_iokit.found()
    # Just build enough for libwrap.dylib
diff --git a/src/asahi/vulkan/hk_cmd_buffer.h b/src/asahi/vulkan/hk_cmd_buffer.h
index c9c3bf3b178..1a491742e83 100644
--- a/src/asahi/vulkan/hk_cmd_buffer.h
+++ b/src/asahi/vulkan/hk_cmd_buffer.h
@@ -462,6 +462,7 @@ struct hk_cmd_buffer {
    uint64_t geom_indirect;
    uint64_t geom_index_buffer;
    uint32_t geom_index_count;
+   uint32_t geom_instance_count;
 
    /* Does the command buffer use the geometry heap? */
    bool uses_heap;
@@ -793,6 +794,9 @@ hk_dispatch_with_local_size(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
                             struct hk_shader *s, struct agx_grid grid,
                             struct agx_workgroup local_size)
 {
+   if (agx_is_shader_empty(&s->b))
+      return;
+
    struct hk_device *dev = hk_cmd_buffer_device(cmd);
    uint32_t usc = hk_upload_usc_words(cmd, s, s->only_linked);
 
diff --git a/src/asahi/vulkan/hk_cmd_dispatch.c b/src/asahi/vulkan/hk_cmd_dispatch.c
index 0fe522aaa70..615ba970d7f 100644
--- a/src/asahi/vulkan/hk_cmd_dispatch.c
+++ b/src/asahi/vulkan/hk_cmd_dispatch.c
@@ -87,6 +87,9 @@ static void
 dispatch(struct hk_cmd_buffer *cmd, struct agx_grid grid)
 {
    struct hk_shader *s = hk_only_variant(cmd->state.cs.shader);
+   if (agx_is_shader_empty(&s->b))
+      return;
+
    struct hk_cs *cs = hk_cmd_buffer_get_cs(cmd, true /* compute */);
    if (!cs)
       return;
diff --git a/src/asahi/vulkan/hk_cmd_draw.c b/src/asahi/vulkan/hk_cmd_draw.c
index 2d71f49fd73..1c83dd90f72 100644
--- a/src/asahi/vulkan/hk_cmd_draw.c
+++ b/src/asahi/vulkan/hk_cmd_draw.c
@@ -521,59 +521,41 @@ hk_merge_render_iview(struct hk_rendering_state *render,
 static void
 hk_pack_zls_control(struct agx_zls_control_packed *packed,
                     struct ail_layout *z_layout, struct ail_layout *s_layout,
-                    const VkRenderingAttachmentInfo *attach_z,
-                    const VkRenderingAttachmentInfo *attach_s,
+                    const VkRenderingAttachmentInfo *z,
+                    const VkRenderingAttachmentInfo *s,
                     bool incomplete_render_area, bool partial_render)
 {
-   agx_pack(packed, ZLS_CONTROL, zls_control) {
-      if (z_layout) {
-         /* XXX: Dropping Z stores is wrong if the render pass gets split into
-          * multiple control streams (can that ever happen?) We need more ZLS
-          * variants. Force || true for now.
-          */
-         zls_control.z_store_enable =
-            attach_z->storeOp == VK_ATTACHMENT_STORE_OP_STORE ||
-            attach_z->resolveMode != VK_RESOLVE_MODE_NONE || partial_render ||
-            true;
-
-         zls_control.z_load_enable =
-            attach_z->loadOp == VK_ATTACHMENT_LOAD_OP_LOAD || partial_render ||
-            incomplete_render_area;
-
-         if (z_layout->compressed) {
-            zls_control.z_compress_1 = true;
-            zls_control.z_compress_2 = true;
-         }
+   struct agx_zls zls = {0};
 
-         if (z_layout->format == PIPE_FORMAT_Z16_UNORM) {
-            zls_control.z_format = AGX_ZLS_FORMAT_16;
-         } else {
-            zls_control.z_format = AGX_ZLS_FORMAT_32F;
-         }
-      }
+   if (z) {
+      /* XXX: Dropping Z stores is wrong if the render pass gets split into
+       * multiple control streams (can that ever happen?) We need more ZLS
+       * variants. Force || true for now.
+       */
+      zls.z_store = z->storeOp == VK_ATTACHMENT_STORE_OP_STORE ||
+                    z->resolveMode != VK_RESOLVE_MODE_NONE || partial_render ||
+                    true;
 
-      if (s_layout) {
-         /* TODO:
-          * Fail
-          * dEQP-VK.renderpass.dedicated_allocation.formats.d32_sfloat_s8_uint.input.dont_care.store.self_dep_clear_draw_use_input_aspect
-          * without the force
-          * .. maybe a VkRenderPass emulation bug.
-          */
-         zls_control.s_store_enable =
-            attach_s->storeOp == VK_ATTACHMENT_STORE_OP_STORE ||
-            attach_s->resolveMode != VK_RESOLVE_MODE_NONE || partial_render ||
-            true;
-
-         zls_control.s_load_enable =
-            attach_s->loadOp == VK_ATTACHMENT_LOAD_OP_LOAD || partial_render ||
-            incomplete_render_area;
-
-         if (s_layout->compressed) {
-            zls_control.s_compress_1 = true;
-            zls_control.s_compress_2 = true;
-         }
-      }
+      zls.z_load = z->loadOp == VK_ATTACHMENT_LOAD_OP_LOAD || partial_render ||
+                   incomplete_render_area;
+   }
+
+   if (s) {
+      /* TODO:
+       * Fail
+       * dEQP-VK.renderpass.dedicated_allocation.formats.d32_sfloat_s8_uint.input.dont_care.store.self_dep_clear_draw_use_input_aspect
+       * without the force
+       * .. maybe a VkRenderPass emulation bug.
+       */
+      zls.s_store = s->storeOp == VK_ATTACHMENT_STORE_OP_STORE ||
+                    s->resolveMode != VK_RESOLVE_MODE_NONE || partial_render ||
+                    true;
+
+      zls.s_load = s->loadOp == VK_ATTACHMENT_LOAD_OP_LOAD || partial_render ||
+                   incomplete_render_area;
    }
+
+   agx_pack_zls_control(packed, z_layout, s_layout, &zls);
 }
 
 VKAPI_ATTR void VKAPI_CALL
@@ -1012,11 +994,10 @@ hk_CmdEndRendering(VkCommandBuffer commandBuffer)
 }
 
 static uint64_t
-hk_geometry_state(struct hk_cmd_buffer *cmd)
+hk_heap(struct hk_cmd_buffer *cmd)
 {
    struct hk_device *dev = hk_cmd_buffer_device(cmd);
 
-   /* We tie heap allocation to geometry state allocation, so allocate now. */
    if (unlikely(!dev->heap)) {
       perf_debug(cmd, "Allocating heap");
 
@@ -1026,29 +1007,28 @@ hk_geometry_state(struct hk_cmd_buffer *cmd)
       /* The geometry state buffer is initialized here and then is treated by
        * the CPU as rodata, even though the GPU uses it for scratch internally.
        */
-      off_t off = dev->rodata.geometry_state - dev->rodata.bo->va->addr;
-      struct agx_geometry_state *map = agx_bo_map(dev->rodata.bo) + off;
+      off_t off = dev->rodata.heap - dev->rodata.bo->va->addr;
+      struct agx_heap *map = agx_bo_map(dev->rodata.bo) + off;
 
-      *map = (struct agx_geometry_state){
-         .heap = dev->heap->va->addr,
-         .heap_size = size,
+      *map = (struct agx_heap){
+         .base = dev->heap->va->addr,
+         .size = size,
       };
    }
 
    /* We need to free all allocations after each command buffer execution */
    if (!cmd->uses_heap) {
       perf_debug(cmd, "Freeing heap");
-      uint64_t addr = dev->rodata.geometry_state;
+      uint64_t addr = dev->rodata.heap;
 
       /* Zeroing the allocated index frees everything */
-      hk_queue_write(cmd,
-                     addr + offsetof(struct agx_geometry_state, heap_bottom), 0,
+      hk_queue_write(cmd, addr + offsetof(struct agx_heap, bottom), 0,
                      true /* after gfx */);
 
       cmd->uses_heap = true;
    }
 
-   return dev->rodata.geometry_state;
+   return dev->rodata.heap;
 }
 
 static uint64_t
@@ -1110,6 +1090,7 @@ hk_rast_prim(struct hk_cmd_buffer *cmd)
 static uint64_t
 hk_upload_geometry_params(struct hk_cmd_buffer *cmd, struct agx_draw draw)
 {
+   struct hk_device *dev = hk_cmd_buffer_device(cmd);
    struct hk_descriptor_state *desc = &cmd->state.gfx.descriptors;
    struct vk_dynamic_graphics_state *dyn = &cmd->vk.dynamic_graphics_state;
    struct hk_graphics_state *gfx = &cmd->state.gfx;
@@ -1129,8 +1110,7 @@ hk_upload_geometry_params(struct hk_cmd_buffer *cmd, struct agx_draw draw)
    }
 
    struct agx_geometry_params params = {
-      .state = hk_geometry_state(cmd),
-      .flat_outputs = fs ? fs->info.fs.interp.flat : 0,
+      .flat_outputs = fs->info.fs.interp.flat,
       .input_topology = mode,
 
       /* Overriden by the indirect setup kernel. As tess->GS is always indirect,
@@ -1168,12 +1148,24 @@ hk_upload_geometry_params(struct hk_cmd_buffer *cmd, struct agx_draw draw)
       params.count_buffer = T.gpu;
    }
 
+   /* Workgroup size */
+   params.vs_grid[3] = params.gs_grid[3] = 64;
+   params.vs_grid[4] = params.gs_grid[4] = 1;
+   params.vs_grid[5] = params.gs_grid[5] = 1;
+
+   struct agx_gs_info *gsi = &count->info.gs;
+
    if (indirect) {
       /* TODO: size */
       cmd->geom_indirect = hk_pool_alloc(cmd, 64, 4).gpu;
 
       params.indirect_desc = cmd->geom_indirect;
       params.vs_grid[2] = params.gs_grid[2] = 1;
+
+      if (gsi->shape == AGX_GS_SHAPE_DYNAMIC_INDEXED) {
+         cmd->geom_index_buffer = dev->heap->va->addr;
+         cmd->geom_index_count = dev->heap->size;
+      }
    } else {
       uint32_t verts = draw.b.count[0], instances = draw.b.count[1];
 
@@ -1188,13 +1180,23 @@ hk_upload_geometry_params(struct hk_cmd_buffer *cmd, struct agx_draw draw)
          params.count_buffer = hk_pool_alloc(cmd, size, 4).gpu;
       }
 
-      cmd->geom_index_count =
-         params.input_primitives * count->info.gs.max_indices;
+      cmd->geom_index_count = agx_gs_rast_vertices(
+         gsi->shape, gsi->max_indices, params.gs_grid[0], instances);
+
+      cmd->geom_instance_count = agx_gs_rast_instances(
+         gsi->shape, gsi->max_indices, params.gs_grid[0], instances);
 
-      params.output_index_buffer =
-         hk_pool_alloc(cmd, cmd->geom_index_count * 4, 4).gpu;
+      if (gsi->shape == AGX_GS_SHAPE_DYNAMIC_INDEXED) {
+         params.output_index_buffer =
+            hk_pool_alloc(cmd, cmd->geom_index_count * 4, 4).gpu;
 
-      cmd->geom_index_buffer = params.output_index_buffer;
+         cmd->geom_index_buffer = params.output_index_buffer;
+      }
+   }
+
+   if (gsi->shape == AGX_GS_SHAPE_STATIC_INDEXED) {
+      cmd->geom_index_buffer =
+         hk_pool_upload(cmd, count->info.gs.topology, gsi->max_indices * 4, 4);
    }
 
    desc->root_dirty = true;
@@ -1218,7 +1220,7 @@ hk_upload_tess_params(struct hk_cmd_buffer *cmd, struct libagx_tess_args *out,
          : LIBAGX_TESS_PARTITIONING_FRACTIONAL_EVEN;
 
    struct libagx_tess_args args = {
-      .heap = hk_geometry_state(cmd),
+      .heap = hk_heap(cmd),
       .tcs_stride_el = tcs->info.tess.tcs_output_stride / 4,
       .statistic = hk_pipeline_stat_addr(
          cmd,
@@ -1242,7 +1244,7 @@ hk_upload_tess_params(struct hk_cmd_buffer *cmd, struct libagx_tess_args *out,
    uint32_t draw_stride_el = 5;
    size_t draw_stride_B = draw_stride_el * sizeof(uint32_t);
 
-   /* heap is allocated by hk_geometry_state */
+   /* heap is allocated by hk_heap */
    args.patch_coord_buffer = dev->heap->va->addr;
 
    if (!agx_is_indirect(draw.b)) {
@@ -1385,7 +1387,7 @@ hk_draw_without_restart(struct hk_cmd_buffer *cmd, struct agx_draw draw,
    assert(draw_count == 1 && "TODO: multidraw");
 
    struct libagx_unroll_restart_args ia = {
-      .heap = hk_geometry_state(cmd),
+      .heap = hk_heap(cmd),
       .index_buffer = draw.index_buffer,
       .in_draw = draw.b.ptr,
       .out_draw = hk_pool_alloc(cmd, 5 * sizeof(uint32_t) * draw_count, 4).gpu,
@@ -1426,6 +1428,7 @@ hk_launch_gs_prerast(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
 
    uint64_t geometry_params = desc->root.draw.geometry_params;
    unsigned count_words = count->info.gs.count_words;
+   struct agx_workgroup wg = agx_workgroup(64, 1, 1);
 
    if (false /* TODO */)
       perf_debug(cmd, "Transform feedbck");
@@ -1444,6 +1447,7 @@ hk_launch_gs_prerast(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
    /* Setup grids */
    if (agx_is_indirect(draw.b)) {
       struct libagx_gs_setup_indirect_args gsi = {
+         .heap = hk_heap(cmd),
          .index_buffer = draw.index_buffer,
          .draw = draw.b.ptr,
          .ia = desc->root.draw.input_assembly,
@@ -1451,7 +1455,8 @@ hk_launch_gs_prerast(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
          .vs_outputs = vs->b.info.outputs,
          .prim = mode,
          .is_prefix_summing = count->info.gs.prefix_sum,
-         .indices_per_in_prim = count->info.gs.max_indices,
+         .max_indices = count->info.gs.max_indices,
+         .shape = count->info.gs.shape,
       };
 
       if (cmd->state.gfx.shaders[MESA_SHADER_TESS_EVAL]) {
@@ -1471,10 +1476,10 @@ hk_launch_gs_prerast(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
       libagx_gs_setup_indirect_struct(cmd, agx_1d(1),
                                       AGX_BARRIER_ALL | AGX_PREGFX, gsi);
 
-      grid_vs = agx_grid_indirect(
+      grid_vs = agx_grid_indirect_local(
          geometry_params + offsetof(struct agx_geometry_params, vs_grid));
 
-      grid_gs = agx_grid_indirect(
+      grid_gs = agx_grid_indirect_local(
          geometry_params + offsetof(struct agx_geometry_params, gs_grid));
    } else {
       grid_vs = grid_gs = draw.b;
@@ -1488,7 +1493,7 @@ hk_launch_gs_prerast(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
                                             vs->info.stage == MESA_SHADER_VERTEX
                                                ? gfx->linked[MESA_SHADER_VERTEX]
                                                : vs->only_linked),
-                        grid_vs, agx_workgroup(1, 1, 1));
+                        grid_vs, wg);
 
    /* Transform feedback and various queries require extra dispatching,
     * determine if we need that here.
@@ -1507,8 +1512,7 @@ hk_launch_gs_prerast(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
       /* If we need counts, launch the count shader and prefix sum the results. */
       if (count_words) {
          perf_debug(dev, "Geometry shader count");
-         hk_dispatch_with_local_size(cmd, cs, count, grid_gs,
-                                     agx_workgroup(1, 1, 1));
+         hk_dispatch_with_local_size(cmd, cs, count, grid_gs, wg);
       }
 
       if (count->info.gs.prefix_sum) {
@@ -1524,16 +1528,30 @@ hk_launch_gs_prerast(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
    }
 
    /* Pre-rast geometry shader */
-   hk_dispatch_with_local_size(cmd, cs, main, grid_gs, agx_workgroup(1, 1, 1));
+   hk_dispatch_with_local_size(cmd, cs, main, grid_gs, wg);
 
-   if (agx_is_indirect(draw.b)) {
-      return agx_draw_indexed_indirect(cmd->geom_indirect, dev->heap->va->addr,
-                                       dev->heap->size, AGX_INDEX_SIZE_U32,
-                                       true);
+   if (agx_gs_indexed(count->info.gs.shape)) {
+      enum agx_index_size index_size =
+         agx_translate_index_size(agx_gs_index_size(count->info.gs.shape));
+
+      if (agx_is_indirect(draw.b)) {
+         return agx_draw_indexed_indirect(
+            cmd->geom_indirect, cmd->geom_index_buffer, cmd->geom_index_count,
+            index_size, true);
+      } else {
+         return agx_draw_indexed(cmd->geom_index_count,
+                                 cmd->geom_instance_count, 0, 0, 0,
+                                 cmd->geom_index_buffer,
+                                 cmd->geom_index_count * 4, index_size, true);
+      }
    } else {
-      return agx_draw_indexed(cmd->geom_index_count, 1, 0, 0, 0,
-                              cmd->geom_index_buffer, cmd->geom_index_count * 4,
-                              AGX_INDEX_SIZE_U32, true);
+      if (agx_is_indirect(draw.b)) {
+         return agx_draw_indirect(cmd->geom_indirect);
+      } else {
+         return (struct agx_draw){
+            .b = agx_3d(cmd->geom_index_count, cmd->geom_instance_count, 1),
+         };
+      }
    }
 }
 
@@ -1685,8 +1703,8 @@ hk_flush_shaders(struct hk_cmd_buffer *cmd)
     * shaders.
     */
    agx_assign_uvs(&gfx->linked_varyings, &hw_vs->info.uvs,
-                  fs ? hk_only_variant(fs)->info.fs.interp.flat : 0,
-                  fs ? hk_only_variant(fs)->info.fs.interp.linear : 0);
+                  hk_only_variant(fs)->info.fs.interp.flat,
+                  hk_only_variant(fs)->info.fs.interp.linear);
 
    for (unsigned i = 0; i < VARYING_SLOT_MAX; ++i) {
       desc->root.draw.uvs_index[i] = gfx->linked_varyings.slots[i];
@@ -2157,9 +2175,13 @@ translate_ppp_vertex(unsigned vtx)
 static void
 hk_flush_index(struct hk_cmd_buffer *cmd, struct hk_cs *cs)
 {
-   uint32_t index = cmd->state.gfx.shaders[MESA_SHADER_GEOMETRY]
-                       ? BITFIELD_MASK(32)
-                       : cmd->state.gfx.index.restart;
+   struct hk_api_shader *gs = cmd->state.gfx.shaders[MESA_SHADER_GEOMETRY];
+   uint32_t index = cmd->state.gfx.index.restart;
+
+   if (gs) {
+      enum agx_gs_shape shape = gs->variants[HK_GS_VARIANT_COUNT].info.gs.shape;
+      index = BITFIELD_MASK(8 * agx_gs_index_size(shape));
+   }
 
    /* VDM State updates are relatively expensive, so only emit them when the
     * restart index changes. This is simpler than accurate dirty tracking.
@@ -2278,11 +2300,8 @@ hk_flush_ppp_state(struct hk_cmd_buffer *cmd, struct hk_cs *cs, uint8_t **out)
               IS_SHADER_DIRTY(TESS_EVAL) || IS_DIRTY(TS_DOMAIN_ORIGIN),
       .cull_2 = varyings_dirty,
 
-      /* With a null FS, the fragment shader PPP word is ignored and doesn't
-       * need to be present.
-       */
-      .fragment_shader = fs && (fs_dirty || linked_fs_dirty || varyings_dirty ||
-                                gfx->descriptors.root_dirty),
+      .fragment_shader = fs_dirty || linked_fs_dirty || varyings_dirty ||
+                         gfx->descriptors.root_dirty,
 
       .occlusion_query = gfx->dirty & HK_DIRTY_OCCLUSION,
       .output_size = hw_vs_dirty,
@@ -2328,24 +2347,14 @@ hk_flush_ppp_state(struct hk_cmd_buffer *cmd, struct hk_cs *cs, uint8_t **out)
    }
 
    if (dirty.fragment_control_2) {
-      if (linked_fs) {
-         /* Annoying, rasterizer_discard seems to be ignored (sometimes?) in the
-          * main fragment control word and has to be combined into the secondary
-          * word for reliable behaviour.
-          */
-         agx_ppp_push_merged(&ppp, FRAGMENT_CONTROL, cfg,
-                             linked_fs->b.fragment_control) {
+      /* Annoying, rasterizer_discard seems to be ignored (sometimes?) in the
+       * main fragment control word and has to be combined into the secondary
+       * word for reliable behaviour.
+       */
+      agx_ppp_push_merged(&ppp, FRAGMENT_CONTROL, cfg,
+                          linked_fs->b.fragment_control) {
 
-            cfg.tag_write_disable = dyn->rs.rasterizer_discard_enable;
-         }
-      } else {
-         /* If there is no fragment shader, we must disable tag writes to avoid
-          * executing the missing shader. This optimizes depth-only passes.
-          */
-         agx_ppp_push(&ppp, FRAGMENT_CONTROL, cfg) {
-            cfg.tag_write_disable = true;
-            cfg.pass_type = AGX_PASS_TYPE_OPAQUE;
-         }
+         cfg.tag_write_disable = dyn->rs.rasterizer_discard_enable;
       }
    }
 
@@ -2373,16 +2382,12 @@ hk_flush_ppp_state(struct hk_cmd_buffer *cmd, struct hk_cs *cs, uint8_t **out)
    }
 
    if (dirty.fragment_front_face_2) {
-      if (fs) {
-         agx_pack(&fragment_face_2, FRAGMENT_FACE_2, cfg) {
-            cfg.object_type = gfx->object_type;
-         }
-
-         agx_merge(fragment_face_2, fs->frag_face, FRAGMENT_FACE_2);
-         agx_ppp_push_packed(&ppp, &fragment_face_2, FRAGMENT_FACE_2);
-      } else {
-         agx_ppp_fragment_face_2(&ppp, gfx->object_type, NULL);
+      agx_pack(&fragment_face_2, FRAGMENT_FACE_2, cfg) {
+         cfg.object_type = gfx->object_type;
       }
+
+      agx_merge(fragment_face_2, fs->frag_face, FRAGMENT_FACE_2);
+      agx_ppp_push_packed(&ppp, &fragment_face_2, FRAGMENT_FACE_2);
    }
 
    if (dirty.fragment_front_stencil) {
@@ -2412,12 +2417,8 @@ hk_flush_ppp_state(struct hk_cmd_buffer *cmd, struct hk_cs *cs, uint8_t **out)
    if (dirty.output_select) {
       struct agx_output_select_packed osel = hw_vs->info.uvs.osel;
 
-      if (linked_fs) {
-         agx_ppp_push_merged_blobs(&ppp, AGX_OUTPUT_SELECT_LENGTH, &osel,
-                                   &linked_fs->b.osel);
-      } else {
-         agx_ppp_push_packed(&ppp, &osel, OUTPUT_SELECT);
-      }
+      agx_ppp_push_merged_blobs(&ppp, AGX_OUTPUT_SELECT_LENGTH, &osel,
+                                &linked_fs->b.osel);
    }
 
    assert(dirty.varying_counts_32 == dirty.varying_counts_16);
@@ -2694,135 +2695,123 @@ hk_flush_dynamic_state(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
       bool has_sample_mask = api_sample_mask != tib_sample_mask;
 
       if (hw_vs->info.cull_distance_array_size) {
-         perf_debug(cmd, "Emulating cull distance (size %u, %s a frag shader)",
-                    hw_vs->info.cull_distance_array_size,
-                    fs ? "with" : "without");
+         perf_debug(cmd, "Emulating cull distance (size %u)",
+                    hw_vs->info.cull_distance_array_size);
       }
 
       if (has_sample_mask) {
-         perf_debug(cmd, "Emulating sample mask (%s a frag shader)",
-                    fs ? "with" : "without");
+         perf_debug(cmd, "Emulating sample mask");
       }
 
-      if (fs) {
-         unsigned samples_shaded = 0;
-         if (fs->info.fs.epilog_key.sample_shading)
-            samples_shaded = dyn->ms.rasterization_samples;
+      unsigned samples_shaded = 0;
+      if (fs->info.fs.epilog_key.sample_shading)
+         samples_shaded = dyn->ms.rasterization_samples;
 
-         struct hk_fast_link_key_fs key = {
-            .prolog.statistics = hk_pipeline_stat_addr(
-               cmd,
-               VK_QUERY_PIPELINE_STATISTIC_FRAGMENT_SHADER_INVOCATIONS_BIT),
+      struct hk_fast_link_key_fs key = {
+         .prolog.statistics = hk_pipeline_stat_addr(
+            cmd, VK_QUERY_PIPELINE_STATISTIC_FRAGMENT_SHADER_INVOCATIONS_BIT),
 
-            .prolog.cull_distance_size = hw_vs->info.cull_distance_array_size,
-            .prolog.api_sample_mask = has_sample_mask ? api_sample_mask : 0xff,
-            .nr_samples_shaded = samples_shaded,
-         };
+         .prolog.cull_distance_size = hw_vs->info.cull_distance_array_size,
+         .prolog.api_sample_mask = has_sample_mask ? api_sample_mask : 0xff,
+         .nr_samples_shaded = samples_shaded,
+      };
 
-         bool prolog_discards =
-            has_sample_mask || key.prolog.cull_distance_size;
-
-         bool needs_prolog = key.prolog.statistics || prolog_discards;
-
-         if (needs_prolog) {
-            /* With late main shader tests, the prolog runs tests if neither the
-             * main shader nor epilog will.
-             *
-             * With (nontrivial) early main shader tests, the prolog does not
-             * run tests, the tests will run at the start of the main shader.
-             * This ensures tests are after API sample mask and cull distance
-             * discards.
-             */
-            key.prolog.run_zs_tests = !nontrivial_force_early &&
-                                      !fs->b.info.writes_sample_mask &&
-                                      !epilog_discards && prolog_discards;
-
-            if (key.prolog.cull_distance_size) {
-               key.prolog.cf_base = fs->b.info.varyings.fs.nr_cf;
-            }
-         }
+      bool prolog_discards = has_sample_mask || key.prolog.cull_distance_size;
 
-         key.epilog = (struct agx_fs_epilog_key){
-            .link = fs->info.fs.epilog_key,
-            .nr_samples = MAX2(dyn->ms.rasterization_samples, 1),
-            .blend.alpha_to_coverage = dyn->ms.alpha_to_coverage_enable,
-            .blend.alpha_to_one = dyn->ms.alpha_to_one_enable,
-            .blend.logicop_enable = dyn->cb.logic_op_enable,
-            .blend.logicop_func = vk_logic_op_to_pipe(dyn->cb.logic_op),
-         };
+      bool needs_prolog = key.prolog.statistics || prolog_discards;
 
-         for (unsigned rt = 0; rt < ARRAY_SIZE(dyn->cal.color_map); ++rt) {
-            int map = dyn->cal.color_map[rt];
-            key.epilog.remap[rt] = map == MESA_VK_ATTACHMENT_UNUSED ? -1 : map;
+      if (needs_prolog) {
+         /* With late main shader tests, the prolog runs tests if neither the
+          * main shader nor epilog will.
+          *
+          * With (nontrivial) early main shader tests, the prolog does not
+          * run tests, the tests will run at the start of the main shader.
+          * This ensures tests are after API sample mask and cull distance
+          * discards.
+          */
+         key.prolog.run_zs_tests = !nontrivial_force_early &&
+                                   !fs->b.info.writes_sample_mask &&
+                                   !epilog_discards && prolog_discards;
+
+         if (key.prolog.cull_distance_size) {
+            key.prolog.cf_base = fs->b.info.varyings.fs.nr_cf;
          }
+      }
 
-         if (dyn->ms.alpha_to_one_enable || dyn->ms.alpha_to_coverage_enable ||
-             dyn->cb.logic_op_enable) {
+      key.epilog = (struct agx_fs_epilog_key){
+         .link = fs->info.fs.epilog_key,
+         .nr_samples = MAX2(dyn->ms.rasterization_samples, 1),
+         .blend.alpha_to_coverage = dyn->ms.alpha_to_coverage_enable,
+         .blend.alpha_to_one = dyn->ms.alpha_to_one_enable,
+         .blend.logicop_enable = dyn->cb.logic_op_enable,
+         .blend.logicop_func = vk_logic_op_to_pipe(dyn->cb.logic_op),
+      };
 
-            perf_debug(
-               cmd, "Epilog with%s%s%s",
-               dyn->ms.alpha_to_one_enable ? " alpha-to-one" : "",
-               dyn->ms.alpha_to_coverage_enable ? " alpha-to-coverage" : "",
-               dyn->cb.logic_op_enable ? " logic-op" : "");
-         }
+      for (unsigned rt = 0; rt < ARRAY_SIZE(dyn->cal.color_map); ++rt) {
+         int map = dyn->cal.color_map[rt];
+         key.epilog.remap[rt] = map == MESA_VK_ATTACHMENT_UNUSED ? -1 : map;
+      }
 
-         key.epilog.link.already_ran_zs |= nontrivial_force_early;
+      if (dyn->ms.alpha_to_one_enable || dyn->ms.alpha_to_coverage_enable ||
+          dyn->cb.logic_op_enable) {
 
-         struct hk_rendering_state *render = &cmd->state.gfx.render;
-         for (uint32_t i = 0; i < render->color_att_count; i++) {
-            key.epilog.rt_formats[i] =
-               hk_format_to_pipe_format(render->color_att[i].vk_format);
-
-            const struct vk_color_blend_attachment_state *cb =
-               &dyn->cb.attachments[i];
-
-            bool write_enable = dyn->cb.color_write_enables & BITFIELD_BIT(i);
-            unsigned write_mask = write_enable ? cb->write_mask : 0;
-
-            /* nir_lower_blend always blends, so use a default blend state when
-             * blending is disabled at an API level.
-             */
-            if (!dyn->cb.attachments[i].blend_enable) {
-               key.epilog.blend.rt[i] = (struct agx_blend_rt_key){
-                  .colormask = write_mask,
-                  .rgb_func = PIPE_BLEND_ADD,
-                  .alpha_func = PIPE_BLEND_ADD,
-                  .rgb_src_factor = PIPE_BLENDFACTOR_ONE,
-                  .alpha_src_factor = PIPE_BLENDFACTOR_ONE,
-                  .rgb_dst_factor = PIPE_BLENDFACTOR_ZERO,
-                  .alpha_dst_factor = PIPE_BLENDFACTOR_ZERO,
-               };
-            } else {
-               key.epilog.blend.rt[i] = (struct agx_blend_rt_key){
-                  .colormask = write_mask,
+         perf_debug(
+            cmd, "Epilog with%s%s%s",
+            dyn->ms.alpha_to_one_enable ? " alpha-to-one" : "",
+            dyn->ms.alpha_to_coverage_enable ? " alpha-to-coverage" : "",
+            dyn->cb.logic_op_enable ? " logic-op" : "");
+      }
 
-                  .rgb_src_factor =
-                     vk_blend_factor_to_pipe(cb->src_color_blend_factor),
+      key.epilog.link.already_ran_zs |= nontrivial_force_early;
 
-                  .rgb_dst_factor =
-                     vk_blend_factor_to_pipe(cb->dst_color_blend_factor),
+      struct hk_rendering_state *render = &cmd->state.gfx.render;
+      for (uint32_t i = 0; i < render->color_att_count; i++) {
+         key.epilog.rt_formats[i] =
+            hk_format_to_pipe_format(render->color_att[i].vk_format);
 
-                  .rgb_func = vk_blend_op_to_pipe(cb->color_blend_op),
+         const struct vk_color_blend_attachment_state *cb =
+            &dyn->cb.attachments[i];
 
-                  .alpha_src_factor =
-                     vk_blend_factor_to_pipe(cb->src_alpha_blend_factor),
+         bool write_enable = dyn->cb.color_write_enables & BITFIELD_BIT(i);
+         unsigned write_mask = write_enable ? cb->write_mask : 0;
 
-                  .alpha_dst_factor =
-                     vk_blend_factor_to_pipe(cb->dst_alpha_blend_factor),
+         /* nir_lower_blend always blends, so use a default blend state when
+          * blending is disabled at an API level.
+          */
+         if (!dyn->cb.attachments[i].blend_enable) {
+            key.epilog.blend.rt[i] = (struct agx_blend_rt_key){
+               .colormask = write_mask,
+               .rgb_func = PIPE_BLEND_ADD,
+               .alpha_func = PIPE_BLEND_ADD,
+               .rgb_src_factor = PIPE_BLENDFACTOR_ONE,
+               .alpha_src_factor = PIPE_BLENDFACTOR_ONE,
+               .rgb_dst_factor = PIPE_BLENDFACTOR_ZERO,
+               .alpha_dst_factor = PIPE_BLENDFACTOR_ZERO,
+            };
+         } else {
+            key.epilog.blend.rt[i] = (struct agx_blend_rt_key){
+               .colormask = write_mask,
 
-                  .alpha_func = vk_blend_op_to_pipe(cb->alpha_blend_op),
-               };
-            }
-         }
+               .rgb_src_factor =
+                  vk_blend_factor_to_pipe(cb->src_color_blend_factor),
 
-         hk_update_fast_linked(cmd, fs, &key);
-      } else {
-         /* TODO: prolog without fs needs to work too... */
-         if (cmd->state.gfx.linked[MESA_SHADER_FRAGMENT] != NULL) {
-            cmd->state.gfx.linked_dirty |= BITFIELD_BIT(MESA_SHADER_FRAGMENT);
-            cmd->state.gfx.linked[MESA_SHADER_FRAGMENT] = NULL;
+               .rgb_dst_factor =
+                  vk_blend_factor_to_pipe(cb->dst_color_blend_factor),
+
+               .rgb_func = vk_blend_op_to_pipe(cb->color_blend_op),
+
+               .alpha_src_factor =
+                  vk_blend_factor_to_pipe(cb->src_alpha_blend_factor),
+
+               .alpha_dst_factor =
+                  vk_blend_factor_to_pipe(cb->dst_alpha_blend_factor),
+
+               .alpha_func = vk_blend_op_to_pipe(cb->alpha_blend_op),
+            };
          }
       }
+
+      hk_update_fast_linked(cmd, fs, &key);
    }
 
    /* If the vertex shader uses draw parameters, vertex uniforms are dirty every
@@ -2937,7 +2926,7 @@ hk_flush_dynamic_state(struct hk_cmd_buffer *cmd, struct hk_cs *cs,
    bool linked_fs_dirty = IS_LINKED_DIRTY(FRAGMENT);
 
    if ((gfx->dirty & HK_DIRTY_PROVOKING) || vgt_dirty || linked_fs_dirty) {
-      unsigned bindings = linked_fs ? linked_fs->b.cf.nr_bindings : 0;
+      unsigned bindings = linked_fs->b.cf.nr_bindings;
       if (bindings) {
          size_t linkage_size =
             AGX_CF_BINDING_HEADER_LENGTH + (bindings * AGX_CF_BINDING_LENGTH);
@@ -3543,7 +3532,7 @@ hk_draw(struct hk_cmd_buffer *cmd, uint16_t draw_id, struct agx_draw draw_)
          uint64_t target = hk_cs_alloc_for_indirect(cs, size_B);
 
          libagx_draw_robust_index(cmd, agx_1d(32), AGX_BARRIER_ALL | AGX_PREGFX,
-                                  target, hk_geometry_state(cmd), draw.b.ptr,
+                                  target, hk_heap(cmd), draw.b.ptr,
                                   draw.index_buffer, draw.index_buffer_range_B,
                                   draw.restart, topology, draw.index_size);
       } else {
diff --git a/src/asahi/vulkan/hk_device.c b/src/asahi/vulkan/hk_device.c
index 2b9e27383cf..3245adfe7a4 100644
--- a/src/asahi/vulkan/hk_device.c
+++ b/src/asahi/vulkan/hk_device.c
@@ -65,6 +65,11 @@ hk_upload_rodata(struct hk_device *dev)
    if (!dev->rodata.bo || !dev->sparse.write)
       return VK_ERROR_OUT_OF_HOST_MEMORY;
 
+   /* The contents of sparse.write are undefined, but making them nonzero helps
+    * fuzz for bugs where we incorrectly read from the write section.
+    */
+   memset(agx_bo_map(dev->sparse.write), 0xCA, AIL_PAGESIZE);
+
    uint8_t *map = agx_bo_map(dev->rodata.bo);
    uint32_t offs = 0;
 
@@ -96,7 +101,7 @@ hk_upload_rodata(struct hk_device *dev)
    *image_heap_ptr = dev->images.bo->va->addr;
    offs += sizeof(uint64_t);
 
-   /* The geometry state buffer isn't strictly readonly data, but we only have a
+   /* The heap descriptor isn't strictly readonly data, but we only have a
     * single instance of it device-wide and -- after initializing at heap
     * allocate time -- it is read-only from the CPU perspective. The GPU uses it
     * for scratch, but is required to reset it after use to ensure resubmitting
@@ -105,8 +110,8 @@ hk_upload_rodata(struct hk_device *dev)
     * So, we allocate it here for convenience.
     */
    offs = align(offs, sizeof(uint64_t));
-   dev->rodata.geometry_state = dev->rodata.bo->va->addr + offs;
-   offs += sizeof(struct agx_geometry_state);
+   dev->rodata.heap = dev->rodata.bo->va->addr + offs;
+   offs += sizeof(struct agx_heap);
 
    /* For null storage descriptors, we need to reserve 16 bytes to catch writes.
     * No particular content is required; we cannot get robustness2 semantics
diff --git a/src/asahi/vulkan/hk_device.h b/src/asahi/vulkan/hk_device.h
index 651e865e2d0..1582793c68e 100644
--- a/src/asahi/vulkan/hk_device.h
+++ b/src/asahi/vulkan/hk_device.h
@@ -85,7 +85,7 @@ struct hk_device {
       struct agx_bo *bo;
       struct agx_usc_uniform_packed image_heap;
       uint64_t null_sink;
-      uint64_t geometry_state;
+      uint64_t heap;
    } rodata;
 
    /* Pages for backing sparse resources */
diff --git a/src/asahi/vulkan/hk_image.c b/src/asahi/vulkan/hk_image.c
index 61d715177cd..b0e9479faef 100644
--- a/src/asahi/vulkan/hk_image.c
+++ b/src/asahi/vulkan/hk_image.c
@@ -1696,8 +1696,15 @@ hk_copy_image_to_image_cpu(struct hk_device *device, struct hk_image *src_image,
          unsigned dst_level = info->dstSubresource.mipLevel;
          uint32_t block_width = src_layout->tilesize_el[src_level].width_el;
          uint32_t block_height = src_layout->tilesize_el[src_level].height_el;
+
+         /* Twiddled images have a single "tile" sized to the entire image, so
+          * break it up so we'll fit.
+          */
+         if (src_layout->tiling == AIL_TILING_TWIDDLED) {
+            block_width = block_height = MIN2(block_width, 32);
+         }
+
          uint32_t temp_pitch = block_width * src_block_B;
-         ;
 
          for (unsigned by = src_offset.y / block_height;
               by * block_height < src_offset.y + extent.height; by++) {
@@ -1714,6 +1721,8 @@ hk_copy_image_to_image_cpu(struct hk_device *device, struct hk_image *src_image,
                   MIN2((bx + 1) * block_width, src_offset.x + extent.width) -
                   src_x_start;
 
+               assert(height * temp_pitch <= ARRAY_SIZE(temp_tile));
+
                ail_detile((void *)src, temp_tile, src_layout, src_level,
                           temp_pitch, src_x_start, src_y_start, width, height);
                ail_tile(dst, temp_tile, dst_layout, dst_level, temp_pitch,
diff --git a/src/asahi/vulkan/hk_image_view.c b/src/asahi/vulkan/hk_image_view.c
index 572c3bae238..7b44a94c8c0 100644
--- a/src/asahi/vulkan/hk_image_view.c
+++ b/src/asahi/vulkan/hk_image_view.c
@@ -501,12 +501,12 @@ pack_pbe(struct hk_device *dev, struct hk_image_view *view, unsigned view_plane,
             cfg.aligned_width_msaa_sw =
                align(u_minify(layout->width_px, level),
                      layout->tilesize_el[level].width_el);
+
+            cfg.sample_count_log2_sw = util_logbase2(image->vk.samples);
          } else {
             cfg.level_offset_sw = ail_get_level_offset_B(layout, cfg.level);
          }
 
-         cfg.sample_count_log2_sw = util_logbase2(image->vk.samples);
-
          if (layout->tiling != AIL_TILING_LINEAR) {
             struct ail_tile tile_size = layout->tilesize_el[level];
             cfg.tile_width_sw = tile_size.width_el;
diff --git a/src/asahi/vulkan/hk_physical_device.c b/src/asahi/vulkan/hk_physical_device.c
index b453efbb3cb..b63d1b8270c 100644
--- a/src/asahi/vulkan/hk_physical_device.c
+++ b/src/asahi/vulkan/hk_physical_device.c
@@ -108,6 +108,7 @@ hk_get_device_extensions(const struct hk_instance *instance,
       .KHR_shader_integer_dot_product = true,
       .KHR_shader_maximal_reconvergence = true,
       .KHR_shader_non_semantic_info = true,
+      .KHR_shader_quad_control = true,
       .KHR_shader_relaxed_extended_instruction = true,
       .KHR_shader_subgroup_extended_types = true,
       .KHR_shader_subgroup_rotate = true,
@@ -414,6 +415,9 @@ hk_get_device_features(
       /* VK_KHR_shader_maximal_reconvergence */
       .shaderMaximalReconvergence = true,
 
+      /* VK_KHR_shader_quad_control */
+      .shaderQuadControl = true,
+
       /* VK_KHR_shader_subgroup_rotate */
       .shaderSubgroupRotate = true,
       .shaderSubgroupRotateClustered = true,
diff --git a/src/asahi/vulkan/hk_shader.c b/src/asahi/vulkan/hk_shader.c
index f624126ce27..bf5602c9519 100644
--- a/src/asahi/vulkan/hk_shader.c
+++ b/src/asahi/vulkan/hk_shader.c
@@ -750,16 +750,10 @@ hk_lower_nir(struct hk_device *dev, nir_shader *nir,
             lower_load_global_constant_offset_instr, nir_metadata_none,
             &soft_fault);
 
-   if (!nir->info.shared_memory_explicit_layout) {
-      /* There may be garbage in shared_size, but it's the job of
-       * nir_lower_vars_to_explicit_types to allocate it. We have to reset to
-       * avoid overallocation.
-       */
-      nir->info.shared_size = 0;
+   assert(nir->info.shared_size == 0);
 
-      NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, nir_var_mem_shared,
-               shared_var_info);
-   }
+   NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, nir_var_mem_shared,
+            shared_var_info);
    NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_shared,
             nir_address_format_32bit_offset);
 
diff --git a/src/broadcom/ci/broadcom-rpi3-fails.txt b/src/broadcom/ci/broadcom-rpi3-fails.txt
index 7293006b222..de09d6c29e1 100644
--- a/src/broadcom/ci/broadcom-rpi3-fails.txt
+++ b/src/broadcom/ci/broadcom-rpi3-fails.txt
@@ -1222,14 +1222,25 @@ arm32-dEQP-GLES2.functional.uniform_api.random.79,Fail
 
 # These are known failures
 asan-KHR-GLES2.core.internalformat.texture2d.depth_component_unsigned_int_depth_component16,Fail
+asan-dEQP-GLES2.functional.clipping.line.wide_line_clip_viewport_center,Fail
 asan-dEQP-GLES2.functional.texture.mipmap.2d.basic.nearest_linear_clamp_non_square,Fail
 asan-dEQP-GLES2.functional.texture.wrap.clamp_clamp_nearest_npot_etc1,Fail
 
 # Already known failures
 ubsan-KHR-GLES2.core.internalformat.texture2d.depth_component_unsigned_int_depth_component16,Fail
+ubsan-KHR-GLES2.core.internalformat.texture2d.depth_component_unsigned_short_depth_component16,Fail
+ubsan-dEQP-GLES2.functional.clipping.line.wide_line_clip_viewport_center,Fail
 ubsan-dEQP-GLES2.functional.clipping.line.wide_line_clip_viewport_corner,Fail
+ubsan-dEQP-GLES2.functional.depth_stencil_clear.depth_stencil_masked,Fail
+ubsan-dEQP-GLES2.functional.texture.filtering.2d.nearest_mipmap_linear_linear_mirror_rgba8888,Fail
+ubsan-dEQP-GLES2.functional.texture.filtering.2d.nearest_mipmap_nearest_linear_mirror_rgba8888,Fail
+ubsan-dEQP-GLES2.functional.texture.mipmap.2d.basic.linear_linear_mirror_non_square,Fail
+ubsan-dEQP-GLES2.functional.texture.mipmap.2d.basic.linear_linear_repeat_non_square,Fail
 ubsan-dEQP-GLES2.functional.texture.mipmap.2d.basic.nearest_linear_clamp_non_square,Fail
+ubsan-dEQP-GLES2.functional.texture.mipmap.2d.basic.nearest_linear_mirror_non_square,Fail
+ubsan-dEQP-GLES2.functional.texture.mipmap.2d.basic.nearest_linear_repeat_non_square,Fail
 ubsan-dEQP-GLES2.functional.texture.wrap.clamp_clamp_nearest_npot_etc1,Fail
+ubsan-dEQP-GLES2.functional.uniform_api.random.79,Fail
 
 asan-dEQP-GLES2.functional.clipping.line.wide_line_clip_viewport_corner,Fail
 arm32-dEQP-GLES2.functional.texture.mipmap.2d.basic.linear_linear_mirror_non_square,Fail
diff --git a/src/broadcom/ci/broadcom-rpi3-skips.txt b/src/broadcom/ci/broadcom-rpi3-skips.txt
index 2fb0ba424f8..72d1596d088 100644
--- a/src/broadcom/ci/broadcom-rpi3-skips.txt
+++ b/src/broadcom/ci/broadcom-rpi3-skips.txt
@@ -42,3 +42,6 @@ spec@glsl-1.50.*
 spec@glsl-3.*
 spec@glsl-4.*
 spec@glsl-es-3.*
+
+# ASan issues
+asan-dEQP-GLES2.functional.uniform_api.random.21
diff --git a/src/broadcom/ci/broadcom-rpi4-fails.txt b/src/broadcom/ci/broadcom-rpi4-fails.txt
index 28a3fa8cfdc..c8ec1314b1d 100644
--- a/src/broadcom/ci/broadcom-rpi4-fails.txt
+++ b/src/broadcom/ci/broadcom-rpi4-fails.txt
@@ -582,7 +582,16 @@ arm32-KHR-GL31.transform_feedback3.multiple_streams,Fail
 arm32-KHR-GL31.transform_feedback3.skip_components,Fail
 arm32-KHR-GL31.transform_feedback3.skip_multiple_buffers,Fail
 
+asan-KHR-GL31.transform_feedback3.skip_multiple_buffers,Fail
 ubsan-KHR-GL31.transform_feedback3.multiple_streams,Fail
 
 # This seems to be working with upstream
 program@execute@vector-conversion,Fail
+
+# B10G11R11 Formats have accuracy issues.
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_variable.states.color_dc_ca_rsub_alpha_dc_s1a_rsub-color_cc_da_min_alpha_ca_1ms1a_max-color_1msc_1mdc_max_alpha_cc_sa_rsub-color_da_o_sub_alpha_z_dc_rsub,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_variable.states.color_da_ca_max_alpha_da_1mdc_rsub-color_sa_1msc_sub_alpha_sc_1mca_sub-color_1ms1c_s1c_add_alpha_s1c_dc_rsub-color_da_1mda_add_alpha_s1c_1msa_sub,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_variable.states.color_1ms1a_sa_max_alpha_sas_sas_min-color_1ms1c_1msa_sub_alpha_1msc_o_add-color_sa_sa_rsub_alpha_cc_cc_add-color_da_da_add_alpha_s1c_da_add,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_array.states.color_dc_ca_rsub_alpha_dc_s1a_rsub-color_cc_da_min_alpha_ca_1ms1a_max-color_1msc_1mdc_max_alpha_cc_sa_rsub-color_da_o_sub_alpha_z_dc_rsub,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_array.states.color_da_ca_max_alpha_da_1mdc_rsub-color_sa_1msc_sub_alpha_sc_1mca_sub-color_1ms1c_s1c_add_alpha_s1c_dc_rsub-color_da_1mda_add_alpha_s1c_1msa_sub,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_array.states.color_1ms1a_sa_max_alpha_sas_sas_min-color_1ms1c_1msa_sub_alpha_1msc_o_add-color_sa_sa_rsub_alpha_cc_cc_add-color_da_da_add_alpha_s1c_da_add,Fail
diff --git a/src/broadcom/ci/broadcom-rpi5-fails.txt b/src/broadcom/ci/broadcom-rpi5-fails.txt
index df7ae85b94d..056243e7f5c 100644
--- a/src/broadcom/ci/broadcom-rpi5-fails.txt
+++ b/src/broadcom/ci/broadcom-rpi5-fails.txt
@@ -15,7 +15,6 @@ spec@!opengl 1.0@gl-1.0-edgeflag,Fail
 spec@!opengl 1.0@gl-1.0-edgeflag-quads,Fail
 spec@!opengl 1.0@gl-1.0-no-op-paths,Fail
 spec@!opengl 1.0@gl-1.0-user-clip-all-planes,Fail
-spec@!opengl 1.1@depthstencil-default_fb-drawpixels-24_8 samples=4,Fail
 spec@!opengl 1.1@point-line-no-cull,Fail
 spec@!opengl 1.1@teximage-colors gl_alpha16@Exact upload-download of GL_ALPHA16,Fail
 spec@!opengl 1.1@texwrap formats bordercolor,Fail
@@ -454,3 +453,11 @@ KHR-GL31.transform_feedback3.skip_multiple_buffers,Fail
 
 # This seems to be working with upstream
 program@execute@vector-conversion,Fail
+
+# B10G11R11 Formats have accuracy issues.
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_variable.states.color_dc_ca_rsub_alpha_dc_s1a_rsub-color_cc_da_min_alpha_ca_1ms1a_max-color_1msc_1mdc_max_alpha_cc_sa_rsub-color_da_o_sub_alpha_z_dc_rsub,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_variable.states.color_da_ca_max_alpha_da_1mdc_rsub-color_sa_1msc_sub_alpha_sc_1mca_sub-color_1ms1c_s1c_add_alpha_s1c_dc_rsub-color_da_1mda_add_alpha_s1c_1msa_sub,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_variable.states.color_1ms1a_sa_max_alpha_sas_sas_min-color_1ms1c_1msa_sub_alpha_1msc_o_add-color_sa_sa_rsub_alpha_cc_cc_add-color_da_da_add_alpha_s1c_da_add,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_array.states.color_dc_ca_rsub_alpha_dc_s1a_rsub-color_cc_da_min_alpha_ca_1ms1a_max-color_1msc_1mdc_max_alpha_cc_sa_rsub-color_da_o_sub_alpha_z_dc_rsub,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_array.states.color_da_ca_max_alpha_da_1mdc_rsub-color_sa_1msc_sub_alpha_sc_1mca_sub-color_1ms1c_s1c_add_alpha_s1c_dc_rsub-color_da_1mda_add_alpha_s1c_1msa_sub,Fail
+dEQP-VK.pipeline.monolithic.blend.dual_source.format.b10g11r11_ufloat_pack32.output_array.states.color_1ms1a_sa_max_alpha_sas_sas_min-color_1ms1c_1msa_sub_alpha_1msc_o_add-color_sa_sa_rsub_alpha_cc_cc_add-color_da_da_add_alpha_s1c_da_add,Fail
diff --git a/src/broadcom/ci/broadcom-rpi5-flakes.txt b/src/broadcom/ci/broadcom-rpi5-flakes.txt
index 7967e7c061b..a812ac1569d 100644
--- a/src/broadcom/ci/broadcom-rpi5-flakes.txt
+++ b/src/broadcom/ci/broadcom-rpi5-flakes.txt
@@ -6,6 +6,7 @@ glx@glx-visuals-stencil
 program@execute@builtin@builtin-float-sincos-1.0.generated
 spec@!opengl 1.0@gl-1.0-front-invalidate-back
 spec@!opengl 1.1@depthstencil-default_fb-drawpixels-24_8 samples=2
+spec@!opengl 1.1@depthstencil-default_fb-drawpixels-24_8 samples=4
 spec@!opengl 1.1@depthstencil-default_fb-drawpixels-32f_24_8_rev samples=2
 spec@!opengl 1.1@depthstencil-default_fb-drawpixels-32f_24_8_rev samples=4
 spec@!opengl 1.1@depthstencil-default_fb-drawpixels-float-and-ushort samples=2
diff --git a/src/broadcom/ci/deqp-broadcom-rpi3-arm32.toml b/src/broadcom/ci/deqp-broadcom-rpi3-gl-arm32.toml
similarity index 100%
rename from src/broadcom/ci/deqp-broadcom-rpi3-arm32.toml
rename to src/broadcom/ci/deqp-broadcom-rpi3-gl-arm32.toml
diff --git a/src/broadcom/ci/deqp-broadcom-rpi3-asan.toml b/src/broadcom/ci/deqp-broadcom-rpi3-gl-asan.toml
similarity index 100%
rename from src/broadcom/ci/deqp-broadcom-rpi3-asan.toml
rename to src/broadcom/ci/deqp-broadcom-rpi3-gl-asan.toml
diff --git a/src/broadcom/ci/deqp-broadcom-rpi3-ubsan.toml b/src/broadcom/ci/deqp-broadcom-rpi3-gl-ubsan.toml
similarity index 100%
rename from src/broadcom/ci/deqp-broadcom-rpi3-ubsan.toml
rename to src/broadcom/ci/deqp-broadcom-rpi3-gl-ubsan.toml
diff --git a/src/broadcom/ci/deqp-broadcom-rpi3.toml b/src/broadcom/ci/deqp-broadcom-rpi3-gl.toml
similarity index 100%
rename from src/broadcom/ci/deqp-broadcom-rpi3.toml
rename to src/broadcom/ci/deqp-broadcom-rpi3-gl.toml
diff --git a/src/broadcom/ci/deqp-broadcom-rpi4-arm32.toml b/src/broadcom/ci/deqp-broadcom-rpi4-gl-arm32.toml
similarity index 98%
rename from src/broadcom/ci/deqp-broadcom-rpi4-arm32.toml
rename to src/broadcom/ci/deqp-broadcom-rpi4-gl-arm32.toml
index eb1834daf3c..2473706c605 100644
--- a/src/broadcom/ci/deqp-broadcom-rpi4-arm32.toml
+++ b/src/broadcom/ci/deqp-broadcom-rpi4-gl-arm32.toml
@@ -10,7 +10,7 @@ deqp_args = [
 ]
 version_check = "GL ES 3.1.*git"
 renderer_check = "V3D 4.2.14"
-fraction = 4
+fraction = 2
 prefix = "arm32-"
 
 [[deqp]]
diff --git a/src/broadcom/ci/deqp-broadcom-rpi4-asan.toml b/src/broadcom/ci/deqp-broadcom-rpi4-gl-asan.toml
similarity index 100%
rename from src/broadcom/ci/deqp-broadcom-rpi4-asan.toml
rename to src/broadcom/ci/deqp-broadcom-rpi4-gl-asan.toml
diff --git a/src/broadcom/ci/deqp-broadcom-rpi4-ubsan.toml b/src/broadcom/ci/deqp-broadcom-rpi4-gl-ubsan.toml
similarity index 100%
rename from src/broadcom/ci/deqp-broadcom-rpi4-ubsan.toml
rename to src/broadcom/ci/deqp-broadcom-rpi4-gl-ubsan.toml
diff --git a/src/broadcom/ci/deqp-broadcom-rpi4.toml b/src/broadcom/ci/deqp-broadcom-rpi4-gl.toml
similarity index 100%
rename from src/broadcom/ci/deqp-broadcom-rpi4.toml
rename to src/broadcom/ci/deqp-broadcom-rpi4-gl.toml
diff --git a/src/broadcom/ci/deqp-broadcom-rpi5.toml b/src/broadcom/ci/deqp-broadcom-rpi5-gl.toml
similarity index 100%
rename from src/broadcom/ci/deqp-broadcom-rpi5.toml
rename to src/broadcom/ci/deqp-broadcom-rpi5-gl.toml
diff --git a/src/broadcom/ci/gitlab-ci-inc.yml b/src/broadcom/ci/gitlab-ci-inc.yml
index 00ddcc346f0..15a1a3f2e2f 100644
--- a/src/broadcom/ci/gitlab-ci-inc.yml
+++ b/src/broadcom/ci/gitlab-ci-inc.yml
@@ -43,7 +43,7 @@
       when: on_success
 
 .vc4-manual-rules:
-  stage: broadcom-postmerge
+  stage: broadcom-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -70,7 +70,7 @@
       when: on_success
 
 .v3d-manual-rules:
-  stage: broadcom-postmerge
+  stage: broadcom-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -88,7 +88,7 @@
     - !reference [.rusticl-rules, rules]
 
 .v3d-rusticl-manual-rules:
-  stage: broadcom-postmerge
+  stage: broadcom-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.v3d-manual-rules, rules]
@@ -108,7 +108,7 @@
       when: on_success
 
 .v3dv-manual-rules:
-  stage: broadcom-postmerge
+  stage: broadcom-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -160,32 +160,55 @@
     FARM: igalia
   timeout: 25m
 
-.broadcom-test:arm64:
+.broadcom-test:arm64-gl:
   extends:
     - .broadcom-test
-    - .baremetal-test-arm64
+    - .baremetal-test-arm64-gl
   variables:
     BM_BOOTFS: /boot/raspberrypi_arm64
 
-.broadcom-test-full:arm64:
+.broadcom-test:arm64-vk:
   extends:
-    - .broadcom-test:arm64
+    - .broadcom-test
+    - .baremetal-test-arm64-vk
+  variables:
+    BM_BOOTFS: /boot/raspberrypi_arm64
+
+.broadcom-test-full:arm64-gl:
+  extends:
+    - .broadcom-test:arm64-gl
   variables:
     BM_BOOTFS: /boot/raspberrypi_arm64_full
 
-.broadcom-asan-test:arm64:
+.broadcom-test-full:arm64-vk:
+  extends:
+    - .broadcom-test:arm64-vk
+  variables:
+    BM_BOOTFS: /boot/raspberrypi_arm64_full
+
+.broadcom-asan-test:arm64-gl:
+  extends:
+    - .broadcom-test:arm64-gl
+    - .baremetal-arm64-asan-test-gl
+
+.broadcom-asan-test:arm64-vk:
+  extends:
+    - .broadcom-test:arm64-vk
+    - .baremetal-arm64-asan-test-vk
+
+.broadcom-ubsan-test:arm64-gl:
   extends:
-    - .broadcom-test:arm64
-    - .baremetal-arm64-asan-test
+    - .broadcom-test:arm64-gl
+    - .baremetal-arm64-ubsan-test-gl
 
-.broadcom-ubsan-test:arm64:
+.broadcom-ubsan-test:arm64-vk:
   extends:
-    - .broadcom-test:arm64
-    - .baremetal-arm64-ubsan-test
+    - .broadcom-test:arm64-vk
+    - .baremetal-arm64-ubsan-test-vk
 
-.broadcom-test:arm32:
+.broadcom-test:arm32-gl:
   extends:
     - .broadcom-test
-    - .baremetal-test-arm32
+    - .baremetal-test-arm32-gl
   variables:
     BM_BOOTFS: /boot/raspberrypi_arm32
diff --git a/src/broadcom/ci/gitlab-ci.yml b/src/broadcom/ci/gitlab-ci.yml
index 1a3377ef78a..ef20bb9073a 100644
--- a/src/broadcom/ci/gitlab-ci.yml
+++ b/src/broadcom/ci/gitlab-ci.yml
@@ -4,11 +4,12 @@ include:
 vc4-rpi3-gl:arm64:
   extends:
     - .igalia-bcm2837-rpi-3-b
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-gl
+    - .test-piglit
     - .vc4-rules
-  parallel: 4
+  parallel: 3
   variables:
-    DEQP_SUITE: broadcom-rpi3
+    DEQP_SUITE: broadcom-rpi3-gl
     HWCI_START_WESTON: 1
 
 vc4-rpi3-gl-piglit-full:arm64:
@@ -24,57 +25,57 @@ vc4-rpi3-gl-piglit-full:arm64:
 vc4-rpi3-gl:arm32:
   extends:
     - .igalia-bcm2837-rpi-3-b
-    - .broadcom-test:arm32
+    - .broadcom-test:arm32-gl
     - .vc4-manual-rules
   tags:
     - igalia-rpi3
     - igalia-fullrun
   variables:
-    DEQP_SUITE: broadcom-rpi3-arm32
+    DEQP_SUITE: broadcom-rpi3-gl-arm32
 
 vc4-rpi3-gl-asan:arm64:
   extends:
     - .igalia-bcm2837-rpi-3-b
-    - .broadcom-asan-test:arm64
+    - .broadcom-asan-test:arm64-gl
     - .vc4-manual-rules
   variables:
     FDO_CI_CONCURRENT: 1
     HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
-    DEQP_SUITE: broadcom-rpi3-asan
-    DEQP_FRACTION: 10
+    DEQP_SUITE: broadcom-rpi3-gl-asan
+    DEQP_FRACTION: 5
 
 vc4-rpi3-gl-ubsan:arm64:
   extends:
     - .igalia-bcm2837-rpi-3-b
-    - .broadcom-ubsan-test:arm64
+    - .broadcom-ubsan-test:arm64-gl
     - .vc4-manual-rules
   variables:
     # UBSan is quite slow, so restrict to 1 job
     FDO_CI_CONCURRENT: 1
     HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
-    DEQP_SUITE: broadcom-rpi3-ubsan
-    DEQP_FRACTION: 10
+    DEQP_SUITE: broadcom-rpi3-gl-ubsan
+    DEQP_FRACTION: 2
 
 v3d-rpi4-gl:arm64:
   extends:
     - .igalia-bcm2711-rpi-4
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-gl
+    - .test-piglit
     - .v3d-rules
   parallel: 8
   variables:
     HWCI_START_WESTON: 1
-    DEQP_SUITE: broadcom-rpi4
-    DEQP_FRACTION: 2
+    DEQP_SUITE: broadcom-rpi4-gl
 
 v3d-rpi4-gl-full:arm64:
   extends:
     - v3d-rpi4-gl:arm64
-    - .broadcom-test-full:arm64
+    - .broadcom-test-full:arm64-gl
     - .v3d-manual-rules
   tags:
     - igalia-rpi4
     - igalia-fullrun
-  parallel: 6
+  parallel: 4
   timeout: 45m
   variables:
     DEQP_FRACTION: 1
@@ -82,7 +83,8 @@ v3d-rpi4-gl-full:arm64:
 v3d-rpi4-rusticl:arm64:
   extends:
     - .igalia-bcm2711-rpi-4
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-gl
+    - .test-piglit
     - .v3d-rusticl-manual-rules
   timeout: 40m  # base run time = 25min test, 32min total
   variables:
@@ -92,7 +94,7 @@ v3d-rpi4-traces:arm64:
   extends:
     - .igalia-bcm2711-rpi-4
     - .piglit-traces-test
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-gl
     - .v3d-rules
   variables:
     HWCI_TEST_SCRIPT: "/install/piglit/piglit-traces.sh"
@@ -103,44 +105,45 @@ v3d-rpi4-traces:arm64:
 v3d-rpi4-gl:arm32:
   extends:
     - .igalia-bcm2711-rpi-4
-    - .broadcom-test:arm32
+    - .broadcom-test:arm32-gl
     - .v3d-manual-rules
   tags:
     - igalia-rpi4
     - igalia-fullrun
   timeout: 35m
   variables:
-    DEQP_SUITE: broadcom-rpi4-arm32
+    DEQP_SUITE: broadcom-rpi4-gl-arm32
 
 v3d-rpi4-gl-asan:arm64:
   extends:
     - .igalia-bcm2711-rpi-4
-    - .broadcom-asan-test:arm64
+    - .broadcom-asan-test:arm64-gl
     - .v3d-manual-rules
   variables:
     FDO_CI_CONCURRENT: 1
     HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
-    DEQP_SUITE: broadcom-rpi4-asan
+    DEQP_SUITE: broadcom-rpi4-gl-asan
+    # FIXME: set to 9 once the new failures are investigated
     DEQP_FRACTION: 30
 
 v3d-rpi4-gl-ubsan:arm64:
   extends:
     - .igalia-bcm2711-rpi-4
-    - .broadcom-ubsan-test:arm64
+    - .broadcom-ubsan-test:arm64-gl
     - .v3d-manual-rules
   variables:
     # UBSan is quite slow, so restrict to 1 job
     FDO_CI_CONCURRENT: 1
     HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
-    DEQP_SUITE: broadcom-rpi4-ubsan
-    DEQP_FRACTION: 30
+    DEQP_SUITE: broadcom-rpi4-gl-ubsan
+    DEQP_FRACTION: 6
 
 v3dv-rpi4-vk:arm64:
   extends:
     - .igalia-bcm2711-rpi-4
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-vk
     - .v3dv-rules
-  parallel: 10
+  parallel: 8
   variables:
     HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
     HWCI_START_WESTON: 1
@@ -151,12 +154,12 @@ v3dv-rpi4-vk:arm64:
 v3dv-rpi4-vk-full:arm64:
   extends:
     - v3dv-rpi4-vk:arm64
-    - .broadcom-test-full:arm64
+    - .broadcom-test-full:arm64-vk
     - .v3dv-manual-rules
   tags:
     - igalia-rpi4
     - igalia-fullrun
-  parallel: 6
+  parallel: 8
   timeout: 2h
   variables:
     # Keep 10 minutes for boot + setup + uploading the artifacts at the end
@@ -166,7 +169,7 @@ v3dv-rpi4-vk-full:arm64:
 v3dv-rpi4-vk-asan:arm64:
   extends:
     - .igalia-bcm2711-rpi-4
-    - .broadcom-asan-test:arm64
+    - .broadcom-asan-test:arm64-vk
     - .v3dv-manual-rules
   variables:
     FDO_CI_CONCURRENT: 1
@@ -177,7 +180,7 @@ v3dv-rpi4-vk-asan:arm64:
 v3dv-rpi4-vk-ubsan:arm64:
   extends:
     - .igalia-bcm2711-rpi-4
-    - .broadcom-ubsan-test:arm64
+    - .broadcom-ubsan-test:arm64-vk
     - .v3dv-manual-rules
   variables:
     # UBSan is quite slow, so restrict to 1 job
@@ -189,18 +192,20 @@ v3dv-rpi4-vk-ubsan:arm64:
 v3d-rpi5-gl:arm64:
   extends:
     - .igalia-bcm2712-rpi-5
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-gl
+    - .test-piglit
     - .v3d-rules
   variables:
     HWCI_START_WESTON: 1
-    DEQP_SUITE: broadcom-rpi5
-    DEQP_FRACTION: 3
+    DEQP_SUITE: broadcom-rpi5-gl
+    DEQP_FRACTION: 4
 
 v3d-rpi5-gl-full:arm64:
   extends:
     - v3d-rpi5-gl:arm64
-    - .broadcom-test-full:arm64
+    - .broadcom-test-full:arm64-gl
     - .v3d-manual-rules
+  parallel: 2
   tags:
     - igalia-rpi5
     - igalia-fullrun
@@ -212,7 +217,8 @@ v3d-rpi5-gl-full:arm64:
 v3d-rpi5-rusticl:arm64:
   extends:
     - .igalia-bcm2712-rpi-5
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-gl
+    - .test-piglit
     - .v3d-rusticl-manual-rules
   tags:
     - igalia-rpi5
@@ -225,7 +231,7 @@ v3d-rpi5-traces:arm64:
   extends:
     - .igalia-bcm2712-rpi-5
     - .piglit-traces-test
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-gl
     - .v3d-rules
   variables:
     HWCI_TEST_SCRIPT: "/install/piglit/piglit-traces.sh"
@@ -236,25 +242,25 @@ v3d-rpi5-traces:arm64:
 v3dv-rpi5-vk:arm64:
   extends:
     - .igalia-bcm2712-rpi-5
-    - .broadcom-test:arm64
+    - .broadcom-test:arm64-vk
     - .v3dv-rules
   parallel: 2
   variables:
     HWCI_TEST_SCRIPT: "/install/deqp-runner.sh"
     HWCI_START_WESTON: 1
     DEQP_SUITE: broadcom-rpi5-vk
-    DEQP_FRACTION: 5
+    DEQP_FRACTION: 6
     FLAKES_CHANNEL: "#videocore-ci"
 
 v3dv-rpi5-vk-full:arm64:
   extends:
     - v3dv-rpi5-vk:arm64
-    - .broadcom-test-full:arm64
+    - .broadcom-test-full:arm64-vk
     - .v3dv-manual-rules
   tags:
     - igalia-rpi5
     - igalia-fullrun
-  parallel: null
+  parallel: 4
   timeout: 2h 30m
   variables:
     # Keep 10 minutes for boot + setup + uploading the artifacts at the end
diff --git a/src/broadcom/common/v3d_debug.c b/src/broadcom/common/v3d_debug.c
index b69e56bd984..cf77ec98393 100644
--- a/src/broadcom/common/v3d_debug.c
+++ b/src/broadcom/common/v3d_debug.c
@@ -107,6 +107,7 @@ static const struct debug_named_value debug_control[] = {
           "Disable TFU (v3dv only)" },
         { "sync", V3D_DEBUG_SYNC,
           "Sync wait for each job to complete after submission." },
+        { "soft_blend", V3D_DEBUG_SOFT_BLEND, "Force fallback to software blending" },
         DEBUG_NAMED_VALUE_END
 };
 
diff --git a/src/broadcom/common/v3d_debug.h b/src/broadcom/common/v3d_debug.h
index a01326ba40c..668b1be36bb 100644
--- a/src/broadcom/common/v3d_debug.h
+++ b/src/broadcom/common/v3d_debug.h
@@ -70,6 +70,7 @@ extern uint32_t v3d_mesa_debug;
 #define V3D_DEBUG_OPT_COMPILE_TIME  (1 << 25)
 #define V3D_DEBUG_DISABLE_TFU       (1 << 26)
 #define V3D_DEBUG_SYNC              (1 << 27)
+#define V3D_DEBUG_SOFT_BLEND        (1 << 28)
 
 #define V3D_DEBUG_SHADERS           (V3D_DEBUG_TGSI | V3D_DEBUG_NIR | \
                                      V3D_DEBUG_VIR | V3D_DEBUG_QPU | \
diff --git a/src/broadcom/compiler/meson.build b/src/broadcom/compiler/meson.build
index 2a58a6cad20..13d674796bc 100644
--- a/src/broadcom/compiler/meson.build
+++ b/src/broadcom/compiler/meson.build
@@ -17,6 +17,7 @@ libbroadcom_compiler_files = files(
   'qpu_validate.c',
   'v3d_tex.c',
   'v3d_compiler.h',
+  'v3d_nir_lower_blend.c',
   'v3d_nir_lower_io.c',
   'v3d_nir_lower_image_load_store.c',
   'v3d_nir_lower_line_smooth.c',
diff --git a/src/broadcom/compiler/nir_to_vir.c b/src/broadcom/compiler/nir_to_vir.c
index d40f5d4c089..2499b3d3a4a 100644
--- a/src/broadcom/compiler/nir_to_vir.c
+++ b/src/broadcom/compiler/nir_to_vir.c
@@ -1960,7 +1960,8 @@ emit_frag_end(struct v3d_compile *c)
                         has_any_tlb_color_write = true;
         }
 
-        if (c->fs_key->sample_alpha_to_coverage && c->output_color_var[0]) {
+        if (!c->fs_key->software_blend &&
+            c->fs_key->sample_alpha_to_coverage && c->output_color_var[0]) {
                 struct nir_variable *var = c->output_color_var[0];
                 struct qreg *color = &c->outputs[var->data.driver_location * 4];
 
@@ -2485,6 +2486,15 @@ ntq_setup_outputs(struct v3d_compile *c)
                 case FRAG_RESULT_DATA5:
                 case FRAG_RESULT_DATA6:
                 case FRAG_RESULT_DATA7:
+                        /* Dual source outputs have an index that is != 0.
+                         * If they have not been removed by now they end up
+                         * clobbering `output_color_var` with the wrong
+                         * variable.
+                         */
+                        if (var->data.index != 0 && var->data.index != NIR_VARIABLE_NO_INDEX) {
+                            break;
+                        }
+
                         c->output_color_var[var->data.location -
                                             FRAG_RESULT_DATA0] = var;
                         break;
@@ -3597,6 +3607,15 @@ ntq_emit_intrinsic(struct v3d_compile *c, nir_intrinsic_instr *instr)
                               vir_uniform(c, QUNIFORM_AA_LINE_WIDTH, 0));
                 break;
 
+        case nir_intrinsic_demote_samples: {
+                struct qreg mask =
+                        vir_NOT(c, ntq_get_src(c, instr->src[0], 0));
+
+                vir_SETMSF_dest(c, vir_nop_reg(),
+                                vir_AND(c, mask, vir_MSF(c)));
+                break;
+        }
+
         case nir_intrinsic_load_sample_mask_in:
                 ntq_store_def(c, &instr->def, 0, vir_MSF(c));
                 break;
@@ -4122,6 +4141,34 @@ ntq_emit_intrinsic(struct v3d_compile *c, nir_intrinsic_instr *instr)
                               vir_uniform(c, QUNIFORM_VIEW_INDEX, 0));
                 break;
 
+        /* We only use these when doing software blending. */
+        case nir_intrinsic_load_blend_const_color_r_float:
+                ntq_store_def(c, &instr->def, 0,
+                              vir_uniform(c, QUNIFORM_BLEND_CONSTANT_R, 0));
+                break;
+        case nir_intrinsic_load_blend_const_color_g_float:
+                ntq_store_def(c, &instr->def, 0,
+                              vir_uniform(c, QUNIFORM_BLEND_CONSTANT_G, 0));
+                break;
+        case nir_intrinsic_load_blend_const_color_b_float:
+                ntq_store_def(c, &instr->def, 0,
+                              vir_uniform(c, QUNIFORM_BLEND_CONSTANT_B, 0));
+                break;
+        case nir_intrinsic_load_blend_const_color_a_float:
+                ntq_store_def(c, &instr->def, 0,
+                              vir_uniform(c, QUNIFORM_BLEND_CONSTANT_A, 0));
+                break;
+
+
+        /* We only use this if alpha to coverage is enabled when using
+         * software blending.
+         */
+        case nir_intrinsic_alpha_to_coverage:
+                assert(c->fs_key->msaa);
+                ntq_store_def(c, &instr->def, 0,
+                              vir_FTOC(c, ntq_get_src(c, instr->src[0], 0)));
+                break;
+
         default:
                 fprintf(stderr, "Unknown intrinsic: ");
                 nir_print_instr(&instr->instr, stderr);
diff --git a/src/broadcom/compiler/v3d_compiler.h b/src/broadcom/compiler/v3d_compiler.h
index 753474279f3..ed4efd62055 100644
--- a/src/broadcom/compiler/v3d_compiler.h
+++ b/src/broadcom/compiler/v3d_compiler.h
@@ -360,6 +360,14 @@ enum quniform_contents {
          * Current value of DrawIndex for Multidraw
          */
         QUNIFORM_DRAW_ID,
+
+        /**
+         * Blend constants for software blend.
+         */
+        QUNIFORM_BLEND_CONSTANT_R,
+        QUNIFORM_BLEND_CONSTANT_G,
+        QUNIFORM_BLEND_CONSTANT_B,
+        QUNIFORM_BLEND_CONSTANT_A,
 };
 
 static inline uint32_t v3d_unit_data_create(uint32_t unit, uint32_t value)
@@ -427,6 +435,7 @@ struct v3d_fs_key {
         bool sample_alpha_to_coverage;
         bool sample_alpha_to_one;
         bool can_earlyz_with_discard;
+        bool software_blend;
         /* Mask of which color render targets are present. */
         uint8_t cbufs;
         uint8_t swap_color_rb;
@@ -439,13 +448,26 @@ struct v3d_fs_key {
         uint8_t uint_color_rb;
 
         /* Color format information per render target. Only set when logic
-         * operations are enabled or when fbfetch is in use.
+         * operations are enabled, when fbfetch is in use or when falling back
+         * to software blend.
          */
         struct {
                 enum pipe_format format;
                 uint8_t swizzle[4];
         } color_fmt[V3D_MAX_DRAW_BUFFERS];
 
+        /* Software blend state. Only set when software blend is enabled.
+         * (currently only for handling the dual source case)
+         */
+        struct {
+                enum pipe_blend_func rgb_func;
+                enum pipe_blendfactor rgb_src_factor;
+                enum pipe_blendfactor rgb_dst_factor;
+                enum pipe_blend_func alpha_func;
+                enum pipe_blendfactor alpha_src_factor;
+                enum pipe_blendfactor alpha_dst_factor;
+        } blend[V3D_MAX_DRAW_BUFFERS];
+
         enum pipe_logicop logicop_func;
         uint32_t point_sprite_mask;
 
@@ -1212,6 +1234,7 @@ bool v3d_nir_lower_global_2x32(nir_shader *s);
 bool v3d_nir_lower_load_store_bitsize(nir_shader *s);
 bool v3d_nir_lower_algebraic(struct nir_shader *shader, const struct v3d_compile *c);
 bool v3d_nir_lower_load_output(nir_shader *s, struct v3d_compile *c);
+bool v3d_nir_lower_blend(nir_shader *s, struct v3d_compile *c);
 
 nir_def *v3d_nir_get_tlb_color(nir_builder *b, struct v3d_compile *c, int rt, int sample);
 
diff --git a/src/broadcom/compiler/v3d_nir_lower_blend.c b/src/broadcom/compiler/v3d_nir_lower_blend.c
new file mode 100644
index 00000000000..4cc77f6dc9f
--- /dev/null
+++ b/src/broadcom/compiler/v3d_nir_lower_blend.c
@@ -0,0 +1,54 @@
+/*
+ * Copyright 2025 Raspberry Pi Ltd
+ * SPDX-License-Identifier: MIT
+ */
+
+#include "util/format/u_format.h"
+#include "compiler/nir/nir_builder.h"
+#include "compiler/nir/nir_format_convert.h"
+#include "compiler/nir/nir_lower_blend.h"
+#include "v3d_compiler.h"
+
+bool
+v3d_nir_lower_blend(nir_shader *nir, struct v3d_compile *c)
+{
+   if (!c->fs_key->software_blend)
+      return false;
+
+   nir_lower_blend_options options = {
+      /* logic op is handled elsewhere in the compiler */
+      .logicop_enable = false,
+      .scalar_blend_const = true,
+   };
+
+   bool lower_blend = false;
+   for (unsigned rt = 0; rt < V3D_MAX_DRAW_BUFFERS; rt++) {
+      if (!(c->fs_key->cbufs & (1 << rt))) {
+         static const nir_lower_blend_channel replace = {
+            .func = PIPE_BLEND_ADD,
+            .src_factor = PIPE_BLENDFACTOR_ONE,
+            .dst_factor = PIPE_BLENDFACTOR_ZERO,
+         };
+
+         options.rt[rt].rgb = replace;
+         options.rt[rt].alpha = replace;
+         continue;
+      }
+
+      lower_blend = true;
+
+      /* Colour write mask is handled by the hardware. */
+      options.rt[rt].colormask = 0xf;
+
+      options.format[rt] = c->fs_key->color_fmt[rt].format;
+
+      options.rt[rt].rgb.func = c->fs_key->blend[rt].rgb_func;
+      options.rt[rt].alpha.func = c->fs_key->blend[rt].alpha_func;
+      options.rt[rt].rgb.dst_factor = c->fs_key->blend[rt].rgb_dst_factor;
+      options.rt[rt].alpha.dst_factor = c->fs_key->blend[rt].alpha_dst_factor;
+      options.rt[rt].rgb.src_factor = c->fs_key->blend[rt].rgb_src_factor;
+      options.rt[rt].alpha.src_factor = c->fs_key->blend[rt].alpha_src_factor;
+   }
+
+   return lower_blend && nir_lower_blend(nir, &options);
+}
diff --git a/src/broadcom/compiler/v3d_nir_lower_logic_ops.c b/src/broadcom/compiler/v3d_nir_lower_logic_ops.c
index c2eaa5aad72..bdae6c926e0 100644
--- a/src/broadcom/compiler/v3d_nir_lower_logic_ops.c
+++ b/src/broadcom/compiler/v3d_nir_lower_logic_ops.c
@@ -354,6 +354,9 @@ v3d_nir_lower_logic_ops_block(nir_block *block, struct v3d_compile *c)
                         const int rt = driver_loc;
                         assert(rt < V3D_MAX_DRAW_BUFFERS);
 
+                        if (!(c->fs_key->cbufs & (1 << rt)))
+                                continue;
+
                         const enum pipe_format format =
                                 c->fs_key->color_fmt[rt].format;
                         if (util_format_is_float(format) ||
diff --git a/src/broadcom/compiler/vir.c b/src/broadcom/compiler/vir.c
index 96bcb956ad8..435d84de7a8 100644
--- a/src/broadcom/compiler/vir.c
+++ b/src/broadcom/compiler/vir.c
@@ -1140,15 +1140,29 @@ v3d_nir_lower_fs_early(struct v3d_compile *c)
         if (c->fs_key->int_color_rb || c->fs_key->uint_color_rb)
                 v3d_fixup_fs_output_types(c);
 
-        NIR_PASS(_, c->s, v3d_nir_lower_load_output, c);
-        NIR_PASS(_, c->s, v3d_nir_lower_logic_ops, c);
-
         if (c->fs_key->line_smoothing) {
                 NIR_PASS(_, c->s, v3d_nir_lower_line_smooth);
                 NIR_PASS(_, c->s, nir_lower_global_vars_to_local);
                 /* The lowering pass can introduce new sysval reads */
                 nir_shader_gather_info(c->s, nir_shader_get_entrypoint(c->s));
         }
+
+        if (c->fs_key->software_blend) {
+                if (c->fs_key->sample_alpha_to_coverage) {
+                        assert(c->fs_key->msaa);
+
+                        NIR_PASS(_, c->s, nir_lower_alpha_to_coverage,
+                                 V3D_MAX_SAMPLES, true);
+                }
+
+                if (c->fs_key->sample_alpha_to_one)
+                        NIR_PASS(_, c->s, nir_lower_alpha_to_one);
+
+                NIR_PASS(_, c->s, v3d_nir_lower_blend, c);
+        }
+
+        NIR_PASS(_, c->s, v3d_nir_lower_load_output, c);
+        NIR_PASS(_, c->s, v3d_nir_lower_logic_ops, c);
 }
 
 static void
diff --git a/src/broadcom/vulkan/v3dv_cmd_buffer.c b/src/broadcom/vulkan/v3dv_cmd_buffer.c
index 73bf0c78b35..7ee0d9bc99d 100644
--- a/src/broadcom/vulkan/v3dv_cmd_buffer.c
+++ b/src/broadcom/vulkan/v3dv_cmd_buffer.c
@@ -2400,7 +2400,9 @@ update_gfx_uniform_state(struct v3dv_cmd_buffer *cmd_buffer)
                 V3DV_CMD_DIRTY_DESCRIPTOR_SETS |
                 V3DV_CMD_DIRTY_VIEW_INDEX |
                 V3DV_CMD_DIRTY_DRAW_ID)) ||
-      BITSET_TEST(dyn->dirty, MESA_VK_DYNAMIC_VP_VIEWPORTS);
+      BITSET_TEST(dyn->dirty, MESA_VK_DYNAMIC_VP_VIEWPORTS) ||
+      (pipeline->blend.use_software &&
+       BITSET_TEST(dyn->dirty, MESA_VK_DYNAMIC_CB_BLEND_CONSTANTS));
 
    if (!dirty_uniform_state)
       return false;
@@ -2411,6 +2413,8 @@ update_gfx_uniform_state(struct v3dv_cmd_buffer *cmd_buffer)
    const bool has_new_descriptors = dirty & V3DV_CMD_DIRTY_DESCRIPTOR_SETS;
    const bool has_new_view_index = dirty & V3DV_CMD_DIRTY_VIEW_INDEX;
    const bool has_new_draw_id = dirty & V3DV_CMD_DIRTY_DRAW_ID;
+   const bool has_new_blend_constants = (pipeline->blend.use_software &&
+      BITSET_TEST(dyn->dirty, MESA_VK_DYNAMIC_CB_BLEND_CONSTANTS));
 
    /* VK_SHADER_STAGE_FRAGMENT_BIT */
    const bool has_new_descriptors_fs =
@@ -2424,7 +2428,8 @@ update_gfx_uniform_state(struct v3dv_cmd_buffer *cmd_buffer)
    const bool needs_fs_update = has_new_pipeline ||
                                 has_new_view_index ||
                                 has_new_push_constants_fs ||
-                                has_new_descriptors_fs;
+                                has_new_descriptors_fs ||
+                                has_new_blend_constants;
 
    if (needs_fs_update) {
       struct v3dv_shader_variant *fs_variant =
diff --git a/src/broadcom/vulkan/v3dv_device.c b/src/broadcom/vulkan/v3dv_device.c
index 821aff205fd..7f77c5edfe5 100644
--- a/src/broadcom/vulkan/v3dv_device.c
+++ b/src/broadcom/vulkan/v3dv_device.c
@@ -258,7 +258,7 @@ get_features(const struct v3dv_physical_device *physical_device,
       .geometryShader = true,
       .tessellationShader = false,
       .sampleRateShading = true,
-      .dualSrcBlend = false,
+      .dualSrcBlend = true,
       .logicOp = true,
       .multiDrawIndirect = false,
       .drawIndirectFirstInstance = true,
@@ -967,7 +967,7 @@ get_device_properties(const struct v3dv_physical_device *device,
       /* Fragment limits */
       .maxFragmentInputComponents               = max_varying_components,
       .maxFragmentOutputAttachments             = 4,
-      .maxFragmentDualSrcAttachments            = 0,
+      .maxFragmentDualSrcAttachments            = 1,
       .maxFragmentCombinedOutputResources       = max_rts +
                                                   MAX_STORAGE_BUFFERS +
                                                   MAX_STORAGE_IMAGES,
diff --git a/src/broadcom/vulkan/v3dv_pipeline.c b/src/broadcom/vulkan/v3dv_pipeline.c
index 54767e4e3b4..6ce49f6657a 100644
--- a/src/broadcom/vulkan/v3dv_pipeline.c
+++ b/src/broadcom/vulkan/v3dv_pipeline.c
@@ -29,6 +29,7 @@
 #include "qpu/qpu_disasm.h"
 
 #include "compiler/nir/nir_builder.h"
+#include "compiler/nir/nir_lower_blend.h"
 #include "nir/nir_serialize.h"
 
 #include "util/shader_stats.h"
@@ -39,6 +40,7 @@
 #include "vk_format.h"
 #include "vk_nir_convert_ycbcr.h"
 #include "vk_pipeline.h"
+#include "vk_blend.h"
 
 static VkResult
 compute_vpm_config(struct v3dv_pipeline *pipeline);
@@ -1121,7 +1123,9 @@ v3d_fs_key_set_color_attachment(struct v3d_fs_key *key,
    /* If logic operations are enabled then we might emit color reads and we
     * need to know the color buffer format and swizzle for that
     */
-   if (key->logicop_func != PIPE_LOGICOP_COPY) {
+   if (key->logicop_func != PIPE_LOGICOP_COPY ||
+       p_stage->nir->info.fs.uses_fbfetch_output ||
+       key->software_blend) {
       /* Framebuffer formats should be single plane */
       assert(vk_format_get_plane_count(fb_format) == 1);
       key->color_fmt[index].format = fb_pipe_format;
@@ -1130,6 +1134,27 @@ v3d_fs_key_set_color_attachment(struct v3d_fs_key *key,
              sizeof(key->color_fmt[index].swizzle));
    }
 
+   if (key->software_blend) {
+      struct vk_color_blend_attachment_state *att =
+         &p_stage->pipeline->dynamic_graphics_state.cb.attachments[index];
+
+      if (att->blend_enable) {
+         key->blend[index].rgb_func = vk_blend_op_to_pipe(att->color_blend_op);
+         key->blend[index].alpha_func = vk_blend_op_to_pipe(att->alpha_blend_op);
+         key->blend[index].rgb_dst_factor = vk_blend_factor_to_pipe(att->dst_color_blend_factor);
+         key->blend[index].alpha_dst_factor = vk_blend_factor_to_pipe(att->dst_alpha_blend_factor);
+         key->blend[index].rgb_src_factor = vk_blend_factor_to_pipe(att->src_color_blend_factor);
+         key->blend[index].alpha_src_factor = vk_blend_factor_to_pipe(att->src_alpha_blend_factor);
+      } else {
+         key->blend[index].rgb_func = PIPE_BLEND_ADD;
+         key->blend[index].alpha_func = PIPE_BLEND_ADD;
+         key->blend[index].rgb_dst_factor = PIPE_BLENDFACTOR_ZERO;
+         key->blend[index].alpha_dst_factor = PIPE_BLENDFACTOR_ZERO;
+         key->blend[index].rgb_src_factor = PIPE_BLENDFACTOR_ONE;
+         key->blend[index].alpha_src_factor = PIPE_BLENDFACTOR_ONE;
+      }
+   }
+
    const struct util_format_description *desc =
       vk_format_description(fb_format);
 
@@ -1215,6 +1240,8 @@ pipeline_populate_v3d_fs_key(struct v3d_fs_key *key,
     */
    key->swap_color_rb = 0;
 
+   key->software_blend = p_stage->pipeline->blend.use_software;
+
    for (uint32_t i = 0; i < rendering_info->color_attachment_count; i++) {
       if (rendering_info->color_attachment_formats[i] == VK_FORMAT_UNDEFINED)
          continue;
@@ -1989,6 +2016,8 @@ pipeline_populate_graphics_key(struct v3dv_pipeline *pipeline,
       key->sample_alpha_to_one = ms_info->alphaToOneEnable;
    }
 
+   key->software_blend = pipeline->blend.use_software;
+
    struct vk_render_pass_state *ri = &pipeline->rendering_info;
    for (uint32_t i = 0; i < ri->color_attachment_count; i++) {
       if (ri->color_attachment_formats[i] == VK_FORMAT_UNDEFINED)
@@ -2002,7 +2031,8 @@ pipeline_populate_graphics_key(struct v3dv_pipeline *pipeline,
       /* If logic operations are enabled then we might emit color reads and we
        * need to know the color buffer format and swizzle for that
        */
-      if (key->logicop_func != PIPE_LOGICOP_COPY) {
+      if (key->logicop_func != PIPE_LOGICOP_COPY ||
+          key->software_blend) {
          /* Framebuffer formats should be single plane */
          assert(vk_format_get_plane_count(fb_format) == 1);
          key->color_fmt[i].format = fb_pipe_format;
@@ -2011,6 +2041,27 @@ pipeline_populate_graphics_key(struct v3dv_pipeline *pipeline,
                 sizeof(key->color_fmt[i].swizzle));
       }
 
+      if (key->software_blend) {
+         struct vk_color_blend_attachment_state *att =
+            &pipeline->dynamic_graphics_state.cb.attachments[i];
+
+         if (att->blend_enable) {
+            key->blend[i].rgb_func = vk_blend_op_to_pipe(att->color_blend_op);
+            key->blend[i].alpha_func = vk_blend_op_to_pipe(att->alpha_blend_op);
+            key->blend[i].rgb_dst_factor = vk_blend_factor_to_pipe(att->dst_color_blend_factor);
+            key->blend[i].alpha_dst_factor = vk_blend_factor_to_pipe(att->dst_alpha_blend_factor);
+            key->blend[i].rgb_src_factor = vk_blend_factor_to_pipe(att->src_color_blend_factor);
+            key->blend[i].alpha_src_factor = vk_blend_factor_to_pipe(att->src_alpha_blend_factor);
+         } else {
+            key->blend[i].rgb_func = PIPE_BLEND_ADD;
+            key->blend[i].alpha_func = PIPE_BLEND_ADD;
+            key->blend[i].rgb_dst_factor = PIPE_BLENDFACTOR_ZERO;
+            key->blend[i].alpha_dst_factor = PIPE_BLENDFACTOR_ZERO;
+            key->blend[i].rgb_src_factor = PIPE_BLENDFACTOR_ONE;
+            key->blend[i].alpha_src_factor = PIPE_BLENDFACTOR_ONE;
+         }
+      }
+
       const struct util_format_description *desc =
          vk_format_description(fb_format);
 
@@ -3090,10 +3141,8 @@ shared_type_info(const struct glsl_type *type, unsigned *size, unsigned *align)
 static void
 lower_compute(struct nir_shader *nir)
 {
-   if (!nir->info.shared_memory_explicit_layout) {
-      NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
-               nir_var_mem_shared, shared_type_info);
-   }
+   NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
+            nir_var_mem_shared, shared_type_info);
 
    NIR_PASS(_, nir, nir_lower_explicit_io,
             nir_var_mem_shared, nir_address_format_32bit_offset);
diff --git a/src/broadcom/vulkan/v3dv_private.h b/src/broadcom/vulkan/v3dv_private.h
index 45bc2c989b6..040c1d03665 100644
--- a/src/broadcom/vulkan/v3dv_private.h
+++ b/src/broadcom/vulkan/v3dv_private.h
@@ -321,11 +321,20 @@ struct v3dv_pipeline_key {
    bool msaa;
    bool sample_alpha_to_coverage;
    bool sample_alpha_to_one;
+   bool software_blend;
    uint8_t cbufs;
    struct {
       enum pipe_format format;
       uint8_t swizzle[4];
    } color_fmt[V3D_MAX_DRAW_BUFFERS];
+   struct {
+           enum pipe_blend_func rgb_func;
+           enum pipe_blendfactor rgb_src_factor;
+           enum pipe_blendfactor rgb_dst_factor;
+           enum pipe_blend_func alpha_func;
+           enum pipe_blendfactor alpha_src_factor;
+           enum pipe_blendfactor alpha_dst_factor;
+   } blend[V3D_MAX_DRAW_BUFFERS];
    uint8_t f32_color_rb;
    uint32_t va_swap_rb_mask;
    bool has_multiview;
@@ -2318,7 +2327,12 @@ struct v3dv_pipeline {
 
    /* Blend state */
    struct {
-      /* Per-RT bit mask with blend enables */
+      /* In some cases, such as when dual source blend factors are in use, we
+       * fall back to software blend lowering.
+       */
+      bool use_software;
+
+      /* Per-RT bit mask with blend enables. */
       uint8_t enables;
       /* Per-RT prepacked blend config packets */
       uint8_t cfg[V3D_MAX_DRAW_BUFFERS][V3DV_BLEND_CFG_LENGTH];
diff --git a/src/broadcom/vulkan/v3dv_uniforms.c b/src/broadcom/vulkan/v3dv_uniforms.c
index 83ce86f4587..a8d6bfab1bb 100644
--- a/src/broadcom/vulkan/v3dv_uniforms.c
+++ b/src/broadcom/vulkan/v3dv_uniforms.c
@@ -670,6 +670,19 @@ v3dv_write_uniforms_wg_offsets(struct v3dv_cmd_buffer *cmd_buffer,
                         v3dv_get_aa_line_width(pipeline, job->cmd_buffer));
          break;
 
+      case QUNIFORM_BLEND_CONSTANT_R:
+         cl_aligned_f(&uniforms, job->cmd_buffer->vk.dynamic_graphics_state.cb.blend_constants[0]);
+         break;
+      case QUNIFORM_BLEND_CONSTANT_G:
+         cl_aligned_f(&uniforms, job->cmd_buffer->vk.dynamic_graphics_state.cb.blend_constants[1]);
+         break;
+      case QUNIFORM_BLEND_CONSTANT_B:
+         cl_aligned_f(&uniforms, job->cmd_buffer->vk.dynamic_graphics_state.cb.blend_constants[2]);
+         break;
+      case QUNIFORM_BLEND_CONSTANT_A:
+         cl_aligned_f(&uniforms, job->cmd_buffer->vk.dynamic_graphics_state.cb.blend_constants[3]);
+         break;
+
       default:
          unreachable("unsupported quniform_contents uniform type\n");
       }
diff --git a/src/broadcom/vulkan/v3dvx_cmd_buffer.c b/src/broadcom/vulkan/v3dvx_cmd_buffer.c
index e66a6d242fc..6cde8af89c1 100644
--- a/src/broadcom/vulkan/v3dvx_cmd_buffer.c
+++ b/src/broadcom/vulkan/v3dvx_cmd_buffer.c
@@ -1617,6 +1617,10 @@ v3dX(cmd_buffer_emit_blend)(struct v3dv_cmd_buffer *cmd_buffer)
    struct v3dv_pipeline *pipeline = cmd_buffer->state.gfx.pipeline;
    assert(pipeline);
 
+   /* When using software blend we don't want to enable any blend hardware */
+   if (pipeline->blend.use_software)
+      return;
+
    const struct v3d_device_info *devinfo = &cmd_buffer->device->devinfo;
    const uint32_t max_color_rts = V3D_MAX_RENDER_TARGETS(devinfo->ver);
 
diff --git a/src/broadcom/vulkan/v3dvx_pipeline.c b/src/broadcom/vulkan/v3dvx_pipeline.c
index 7b1fe4a3a2e..693376bf815 100644
--- a/src/broadcom/vulkan/v3dvx_pipeline.c
+++ b/src/broadcom/vulkan/v3dvx_pipeline.c
@@ -27,7 +27,8 @@
 #include "broadcom/compiler/v3d_compiler.h"
 
 static uint8_t
-blend_factor(VkBlendFactor factor, bool dst_alpha_one, bool *needs_constants)
+blend_factor(VkBlendFactor factor, bool dst_alpha_one, bool *needs_constants,
+             bool *needs_dual_src)
 {
    switch (factor) {
    case VK_BLEND_FACTOR_ZERO:
@@ -52,11 +53,17 @@ blend_factor(VkBlendFactor factor, bool dst_alpha_one, bool *needs_constants)
    case VK_BLEND_FACTOR_ONE_MINUS_DST_ALPHA:
       return dst_alpha_one ? V3D_BLEND_FACTOR_ZERO :
                              V3D_BLEND_FACTOR_INV_DST_ALPHA;
+
+   /* For dual source blending we need to fallback to software as the hardware
+    * has no support for it.
+    */
    case VK_BLEND_FACTOR_SRC1_COLOR:
    case VK_BLEND_FACTOR_ONE_MINUS_SRC1_COLOR:
    case VK_BLEND_FACTOR_SRC1_ALPHA:
    case VK_BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA:
-      unreachable("Invalid blend factor: dual source blending not supported.");
+      assert(needs_dual_src);
+      *needs_dual_src = true;
+      return VK_BLEND_FACTOR_ZERO;
    default:
       unreachable("Unknown blend factor.");
    }
@@ -86,6 +93,8 @@ pack_blend(struct v3dv_pipeline *pipeline,
    assert(ri->color_attachment_count == cb_info->attachmentCount);
    pipeline->blend.needs_color_constants = false;
    uint32_t color_write_masks = 0;
+
+   bool needs_dual_src = false;
    for (uint32_t i = 0; i < ri->color_attachment_count; i++) {
       const VkPipelineColorBlendAttachmentState *b_state =
          &cb_info->pAttachments[i];
@@ -116,21 +125,29 @@ pack_blend(struct v3dv_pipeline *pipeline,
          config.color_blend_mode = b_state->colorBlendOp;
          config.color_blend_dst_factor =
             blend_factor(b_state->dstColorBlendFactor, dst_alpha_one,
-                         &pipeline->blend.needs_color_constants);
+                         &pipeline->blend.needs_color_constants,
+                         &needs_dual_src);
          config.color_blend_src_factor =
             blend_factor(b_state->srcColorBlendFactor, dst_alpha_one,
-                         &pipeline->blend.needs_color_constants);
+                         &pipeline->blend.needs_color_constants,
+                         &needs_dual_src);
 
          config.alpha_blend_mode = b_state->alphaBlendOp;
          config.alpha_blend_dst_factor =
             blend_factor(b_state->dstAlphaBlendFactor, dst_alpha_one,
-                         &pipeline->blend.needs_color_constants);
+                         &pipeline->blend.needs_color_constants,
+                         &needs_dual_src);
          config.alpha_blend_src_factor =
             blend_factor(b_state->srcAlphaBlendFactor, dst_alpha_one,
-                         &pipeline->blend.needs_color_constants);
+                         &pipeline->blend.needs_color_constants,
+                         &needs_dual_src);
       }
    }
 
+   /* We may want to fallback to software in other cases in the future such
+    * as for formats not supported by the blend hardware.
+    */
+   pipeline->blend.use_software = V3D_DBG(SOFT_BLEND) || needs_dual_src;
    pipeline->blend.color_write_masks = color_write_masks;
 }
 
@@ -191,7 +208,8 @@ pack_cfg_bits(struct v3dv_pipeline *pipeline,
          config.direct3d_provoking_vertex = true;
       }
 
-      config.blend_enable = pipeline->blend.enables != 0;
+      config.blend_enable = pipeline->blend.enables != 0 &&
+         !pipeline->blend.use_software;
 
 #if V3D_VERSION >= 71
       /* From the Vulkan spec:
diff --git a/src/compiler/builtin_types.py b/src/compiler/builtin_types.py
index a8530e9aeeb..ec48be2bac0 100644
--- a/src/compiler/builtin_types.py
+++ b/src/compiler/builtin_types.py
@@ -26,12 +26,21 @@ def sampler_type(name, gl_type, base_type, dim, shadow, array, sampled_type):
     })
 
 def vector_type(base_name, vec_name, base_type, gl_type, extra_gl_type=None):
+    gl_types = [None, None, None, None]
+
     if extra_gl_type is None:
         extra_gl_type = ""
-    simple_type(base_name, gl_type + extra_gl_type, base_type, 1, 1)
-    simple_type(vec_name + "2", gl_type + "_VEC2" + extra_gl_type, base_type, 2, 1)
-    simple_type(vec_name + "3", gl_type + "_VEC3" + extra_gl_type, base_type, 3, 1)
-    simple_type(vec_name + "4", gl_type + "_VEC4" + extra_gl_type, base_type, 4, 1)
+
+    if gl_type:
+        gl_types = [gl_type + extra_gl_type,
+                    gl_type + "_VEC2" + extra_gl_type,
+                    gl_type + "_VEC3" + extra_gl_type,
+                    gl_type + "_VEC4" + extra_gl_type]
+
+    simple_type(base_name, gl_types[0], base_type, 1, 1)
+    simple_type(vec_name + "2",  gl_types[1], base_type, 2, 1)
+    simple_type(vec_name + "3",  gl_types[2], base_type, 3, 1)
+    simple_type(vec_name + "4",  gl_types[3], base_type, 4, 1)
     simple_type(vec_name + "5", None, base_type, 5, 1)
     simple_type(vec_name + "8", None, base_type, 8, 1)
     simple_type(vec_name + "16", None, base_type, 16, 1)
@@ -52,6 +61,9 @@ vector_type("uint16_t",  "u16vec", "GLSL_TYPE_UINT16",  "GL_UNSIGNED_INT16", "_N
 vector_type("int8_t",    "i8vec",  "GLSL_TYPE_INT8",    "GL_INT8", "_NV")
 vector_type("uint8_t",   "u8vec",  "GLSL_TYPE_UINT8",   "GL_UNSIGNED_INT8", "_NV")
 
+vector_type("bfloat16_t", "bf16vec", "GLSL_TYPE_BFLOAT16", None)
+vector_type("e4m3fn_t", "e4m3fnvec", "GLSL_TYPE_FLOAT_E4M3FN", None)
+
 simple_type("mat2",   "GL_FLOAT_MAT2",   "GLSL_TYPE_FLOAT", 2, 2)
 simple_type("mat3",   "GL_FLOAT_MAT3",   "GLSL_TYPE_FLOAT", 3, 3)
 simple_type("mat4",   "GL_FLOAT_MAT4",   "GLSL_TYPE_FLOAT", 4, 4)
diff --git a/src/compiler/glsl/ast_to_hir.cpp b/src/compiler/glsl/ast_to_hir.cpp
index 263d05267e6..537be820068 100644
--- a/src/compiler/glsl/ast_to_hir.cpp
+++ b/src/compiler/glsl/ast_to_hir.cpp
@@ -1135,6 +1135,7 @@ do_comparison(void *mem_ctx, int operation, ir_rvalue *op0, ir_rvalue *op1)
    switch (op0->type->base_type) {
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_BOOL:
diff --git a/src/compiler/glsl/gl_nir_link_uniform_initializers.c b/src/compiler/glsl/gl_nir_link_uniform_initializers.c
index 7bc671d57fc..425b354cf29 100644
--- a/src/compiler/glsl/gl_nir_link_uniform_initializers.c
+++ b/src/compiler/glsl/gl_nir_link_uniform_initializers.c
@@ -163,6 +163,7 @@ copy_constant_to_storage(union gl_constant_value *storage,
          case GLSL_TYPE_UINT8:
          case GLSL_TYPE_INT8:
          case GLSL_TYPE_FLOAT16:
+         case GLSL_TYPE_BFLOAT16:
             /* All other types should have already been filtered by other
              * paths in the caller.
              */
diff --git a/src/compiler/glsl/ir_clone.cpp b/src/compiler/glsl/ir_clone.cpp
index 059ae579b8a..3c1977b6cc5 100644
--- a/src/compiler/glsl/ir_clone.cpp
+++ b/src/compiler/glsl/ir_clone.cpp
@@ -338,6 +338,7 @@ ir_constant::clone(void *mem_ctx, struct hash_table *ht) const
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_BOOL:
    case GLSL_TYPE_UINT64:
diff --git a/src/compiler/glsl_types.c b/src/compiler/glsl_types.c
index 089660ddea1..280f971f244 100644
--- a/src/compiler/glsl_types.c
+++ b/src/compiler/glsl_types.c
@@ -347,6 +347,10 @@ glsl_get_base_glsl_type(const glsl_type *t)
       return &glsl_type_builtin_float16_t;
    case GLSL_TYPE_DOUBLE:
       return &glsl_type_builtin_double;
+   case GLSL_TYPE_BFLOAT16:
+      return &glsl_type_builtin_bfloat16_t;
+   case GLSL_TYPE_FLOAT_E4M3FN:
+      return &glsl_type_builtin_e4m3fn_t;
    case GLSL_TYPE_BOOL:
       return &glsl_type_builtin_bool;
    case GLSL_TYPE_UINT64:
@@ -384,6 +388,8 @@ glsl_get_bare_type(const glsl_type *t)
    case GLSL_TYPE_UINT16:
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
@@ -593,6 +599,8 @@ glsl_ ## vname ## _type (unsigned components)    \
 
 VECN(components, float, vec)
 VECN(components, float16_t, f16vec)
+VECN(components, bfloat16_t, bf16vec)
+VECN(components, e4m3fn_t, e4m3fnvec)
 VECN(components, double, dvec)
 VECN(components, int, ivec)
 VECN(components, uint, uvec)
@@ -641,6 +649,10 @@ glsl_simple_explicit_type(unsigned base_type, unsigned rows, unsigned columns,
          return glsl_vec_type(rows);
       case GLSL_TYPE_FLOAT16:
          return glsl_f16vec_type(rows);
+      case GLSL_TYPE_BFLOAT16:
+         return glsl_bf16vec_type(rows);
+      case GLSL_TYPE_FLOAT_E4M3FN:
+         return glsl_e4m3fnvec_type(rows);
       case GLSL_TYPE_DOUBLE:
          return glsl_dvec_type(rows);
       case GLSL_TYPE_BOOL:
@@ -1742,6 +1754,8 @@ glsl_get_component_slots(const glsl_type *t)
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_BOOL:
       return glsl_get_components(t);
 
@@ -1794,6 +1808,8 @@ glsl_get_component_slots_aligned(const glsl_type *t, unsigned offset)
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_BOOL:
       return glsl_get_components(t);
 
@@ -2880,6 +2896,8 @@ glsl_count_vec4_slots(const glsl_type *t, bool is_gl_vertex_input, bool is_bindl
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_BOOL:
       return t->matrix_columns;
    case GLSL_TYPE_DOUBLE:
@@ -3084,6 +3102,8 @@ encode_type_to_blob(struct blob *blob, const glsl_type *type)
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_UINT8:
    case GLSL_TYPE_INT8:
@@ -3732,6 +3752,8 @@ glsl_get_natural_size_align_bytes(const glsl_type *type,
    case GLSL_TYPE_UINT16:
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
@@ -3791,6 +3813,8 @@ glsl_get_word_size_align_bytes(const glsl_type *type,
    case GLSL_TYPE_UINT16:
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
@@ -3850,6 +3874,8 @@ glsl_get_vec4_size_align_bytes(const glsl_type *type,
    case GLSL_TYPE_UINT16:
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
@@ -3923,3 +3949,24 @@ glsl_type_get_image_count(const glsl_type *type)
 {
    return glsl_type_count(type, GLSL_TYPE_IMAGE);
 }
+
+enum glsl_base_type
+glsl_apply_signedness_to_base_type(enum glsl_base_type type, bool signedness)
+{
+   switch (type) {
+   case GLSL_TYPE_UINT:
+   case GLSL_TYPE_INT:
+      return signedness ? GLSL_TYPE_INT : GLSL_TYPE_UINT;
+   case GLSL_TYPE_UINT8:
+   case GLSL_TYPE_INT8:
+      return signedness ? GLSL_TYPE_INT8 : GLSL_TYPE_UINT8;
+   case GLSL_TYPE_UINT16:
+   case GLSL_TYPE_INT16:
+      return signedness ? GLSL_TYPE_INT16 : GLSL_TYPE_UINT16;
+   case GLSL_TYPE_UINT64:
+   case GLSL_TYPE_INT64:
+      return signedness ? GLSL_TYPE_INT64 : GLSL_TYPE_UINT64;
+   default:
+      return type;
+   }
+}
diff --git a/src/compiler/glsl_types.h b/src/compiler/glsl_types.h
index f518ae9e394..2defbf3136a 100644
--- a/src/compiler/glsl_types.h
+++ b/src/compiler/glsl_types.h
@@ -63,6 +63,8 @@ enum glsl_base_type {
    GLSL_TYPE_INT,
    GLSL_TYPE_FLOAT,
    GLSL_TYPE_FLOAT16,
+   GLSL_TYPE_BFLOAT16,
+   GLSL_TYPE_FLOAT_E4M3FN,
    GLSL_TYPE_DOUBLE,
    GLSL_TYPE_UINT8,
    GLSL_TYPE_INT8,
@@ -99,12 +101,14 @@ static unsigned glsl_base_type_bit_size(enum glsl_base_type type)
       return 32;
 
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
    case GLSL_TYPE_UINT16:
    case GLSL_TYPE_INT16:
       return 16;
 
    case GLSL_TYPE_UINT8:
    case GLSL_TYPE_INT8:
+   case GLSL_TYPE_FLOAT_E4M3FN:
       return 8;
 
    case GLSL_TYPE_DOUBLE:
@@ -167,12 +171,14 @@ glsl_base_type_get_bit_size(const enum glsl_base_type base_type)
       return 32;
 
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
    case GLSL_TYPE_UINT16:
    case GLSL_TYPE_INT16:
       return 16;
 
    case GLSL_TYPE_UINT8:
    case GLSL_TYPE_INT8:
+   case GLSL_TYPE_FLOAT_E4M3FN:
       return 8;
 
    case GLSL_TYPE_DOUBLE:
@@ -232,6 +238,12 @@ glsl_signed_base_type_of(enum glsl_base_type type)
    }
 }
 
+/* Change integer types to be signed or unsigned.  Other types remain
+ * unchanged.
+ */
+enum glsl_base_type
+glsl_apply_signedness_to_base_type(enum glsl_base_type type, bool signedness);
+
 int
 glsl_get_sampler_dim_coordinate_components(enum glsl_sampler_dim dim);
 
@@ -615,6 +627,18 @@ glsl_type_is_float_16_32_64(const glsl_type *t)
    return t->base_type == GLSL_TYPE_FLOAT16 || glsl_type_is_float(t) || glsl_type_is_double(t);
 }
 
+static inline bool
+glsl_type_is_bfloat_16(const glsl_type *t)
+{
+   return t->base_type == GLSL_TYPE_BFLOAT16;
+}
+
+static inline bool
+glsl_type_is_e4m3fn(const glsl_type *t)
+{
+   return t->base_type == GLSL_TYPE_FLOAT_E4M3FN;
+}
+
 static inline bool
 glsl_type_is_int_16_32_64(const glsl_type *t)
 {
@@ -931,6 +955,8 @@ static inline const glsl_type *glsl_int8_t_type(void) { return &glsl_type_builti
 static inline const glsl_type *glsl_uint8_t_type(void) { return &glsl_type_builtin_uint8_t; }
 static inline const glsl_type *glsl_bool_type(void) { return &glsl_type_builtin_bool; }
 static inline const glsl_type *glsl_atomic_uint_type(void) { return &glsl_type_builtin_atomic_uint; }
+static inline const glsl_type *glsl_bfloat16_t_type(void) { return &glsl_type_builtin_bfloat16_t; }
+static inline const glsl_type *glsl_e4m3fn_t_type(void) { return &glsl_type_builtin_e4m3fn_t; }
 
 static inline const glsl_type *
 glsl_floatN_t_type(unsigned bit_size)
@@ -944,6 +970,16 @@ glsl_floatN_t_type(unsigned bit_size)
    }
 }
 
+static inline const glsl_type *
+glsl_bfloatN_t_type(unsigned bit_size)
+{
+   switch (bit_size) {
+   case 16: return &glsl_type_builtin_bfloat16_t;
+   default:
+      unreachable("Unsupported bit size");
+   }
+}
+
 static inline const glsl_type *
 glsl_intN_t_type(unsigned bit_size)
 {
@@ -972,6 +1008,8 @@ glsl_uintN_t_type(unsigned bit_size)
 
 const glsl_type *glsl_vec_type(unsigned components);
 const glsl_type *glsl_f16vec_type(unsigned components);
+const glsl_type *glsl_bf16vec_type(unsigned components);
+const glsl_type *glsl_e4m3fnvec_type(unsigned components);
 const glsl_type *glsl_dvec_type(unsigned components);
 const glsl_type *glsl_ivec_type(unsigned components);
 const glsl_type *glsl_uvec_type(unsigned components);
diff --git a/src/compiler/nir/meson.build b/src/compiler/nir/meson.build
index a4b5110cb62..8e0595cc323 100644
--- a/src/compiler/nir/meson.build
+++ b/src/compiler/nir/meson.build
@@ -99,6 +99,7 @@ files_libnir = files(
   'nir_from_ssa.c',
   'nir_functions.c',
   'nir_gather_info.c',
+  'nir_gather_output_deps.c',
   'nir_gather_tcs_info.c',
   'nir_gather_types.c',
   'nir_gather_xfb_info.c',
@@ -115,6 +116,7 @@ files_libnir = files(
   'nir_loop_analyze.h',
   'nir_lower_alu.c',
   'nir_lower_alu_width.c',
+  'nir_lower_alpha.c',
   'nir_lower_alpha_test.c',
   'nir_lower_amul.c',
   'nir_lower_array_deref_of_vec.c',
diff --git a/src/compiler/nir/nir.c b/src/compiler/nir/nir.c
index 4fa4041ca39..39e95100956 100644
--- a/src/compiler/nir/nir.c
+++ b/src/compiler/nir/nir.c
@@ -2901,6 +2901,8 @@ nir_get_nir_type_for_glsl_base_type(enum glsl_base_type base_type)
    case GLSL_TYPE_INT64:   return nir_type_int64;
    case GLSL_TYPE_FLOAT:   return nir_type_float32;
    case GLSL_TYPE_FLOAT16: return nir_type_float16;
+   case GLSL_TYPE_BFLOAT16: return nir_type_uint16;
+   case GLSL_TYPE_FLOAT_E4M3FN: return nir_type_uint8;
    case GLSL_TYPE_DOUBLE:  return nir_type_float64;
       /* clang-format on */
 
diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index ef4089999e6..f0a4682700f 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -650,6 +650,15 @@ typedef struct nir_variable {
        */
       unsigned per_vertex : 1;
 
+      /**
+       * Whether the shared memory block that this variable represent alias
+       * with other similarly decorated shared memory blocks.  These are Blocks
+       * marked as Aliased in SPIR-V.
+       *
+       * See SPV_KHR_workgroup_storage_explicit_layout for details.
+       */
+      unsigned aliased_shared_memory : 1;
+
       /**
        * Layout qualifier for gl_FragDepth. See nir_depth_layout.
        *
@@ -5213,6 +5222,13 @@ bool nir_lower_vec_to_regs(nir_shader *shader, nir_instr_writemask_filter_cb cb,
 bool nir_lower_alpha_test(nir_shader *shader, enum compare_func func,
                           bool alpha_to_one,
                           const gl_state_index16 *alpha_ref_state_tokens);
+
+bool nir_lower_alpha_to_coverage(nir_shader *shader,
+                                 uint8_t nr_samples,
+                                 bool has_intrinsic);
+
+bool nir_lower_alpha_to_one(nir_shader *shader);
+
 bool nir_lower_alu(nir_shader *shader);
 
 bool nir_lower_flrp(nir_shader *shader, unsigned lowering_mask,
@@ -6438,6 +6454,51 @@ void nir_print_use_dominators(nir_use_dominance_state *state,
                               nir_instr **instructions,
                               unsigned num_instructions);
 
+static inline unsigned
+nir_verts_in_output_prim(nir_shader *gs)
+{
+   assert(gs->info.stage == MESA_SHADER_GEOMETRY);
+   return mesa_vertices_per_prim(gs->info.gs.output_primitive);
+}
+
+typedef struct {
+   struct {
+      /* The list of instructions that affect this output including the output
+       * store itself. If NULL, the output isn't stored.
+       */
+      nir_instr **instr_list;
+      unsigned num_instr;
+   } output[NUM_TOTAL_VARYING_SLOTS];
+} nir_output_deps;
+
+void nir_gather_output_dependencies(nir_shader *nir, nir_output_deps *deps);
+void nir_free_output_dependencies(nir_output_deps *deps);
+
+typedef struct {
+   struct {
+      /* Per component mask of input slots. */
+      BITSET_DECLARE(inputs, NUM_TOTAL_VARYING_SLOTS * 8);
+      bool defined;
+      bool uses_ssbo_reads;
+      bool uses_image_reads;
+   } output[NUM_TOTAL_VARYING_SLOTS];
+} nir_input_to_output_deps;
+
+void nir_gather_input_to_output_dependencies(nir_shader *nir,
+                                             nir_input_to_output_deps *out_deps);
+void nir_print_input_to_output_deps(nir_input_to_output_deps *deps,
+                                    nir_shader *nir, FILE *f);
+
+typedef struct {
+   /* 1 bit per 16-bit component. */
+   BITSET_DECLARE(pos_only, NUM_TOTAL_VARYING_SLOTS * 8);
+   BITSET_DECLARE(var_only, NUM_TOTAL_VARYING_SLOTS * 8);
+   BITSET_DECLARE(both, NUM_TOTAL_VARYING_SLOTS * 8);
+} nir_output_clipper_var_groups;
+
+void nir_gather_output_clipper_var_groups(nir_shader *nir,
+                                          nir_output_clipper_var_groups *groups);
+
 #include "nir_inline_helpers.h"
 
 #ifdef __cplusplus
diff --git a/src/compiler/nir/nir_builder.h b/src/compiler/nir/nir_builder.h
index 54d5dad8f98..37044143937 100644
--- a/src/compiler/nir/nir_builder.h
+++ b/src/compiler/nir/nir_builder.h
@@ -761,6 +761,32 @@ nir_fdot(nir_builder *build, nir_def *src0, nir_def *src1)
    return NULL;
 }
 
+static inline nir_def *
+nir_bfdot(nir_builder *build, nir_def *src0, nir_def *src1)
+{
+   assert(src0->num_components == src1->num_components);
+   switch (src0->num_components) {
+   case 1:
+      return nir_bfmul(build, src0, src1);
+   case 2:
+      return nir_bfdot2(build, src0, src1);
+   case 3:
+      return nir_bfdot3(build, src0, src1);
+   case 4:
+      return nir_bfdot4(build, src0, src1);
+   case 5:
+      return nir_bfdot5(build, src0, src1);
+   case 8:
+      return nir_bfdot8(build, src0, src1);
+   case 16:
+      return nir_bfdot16(build, src0, src1);
+   default:
+      unreachable("bad component size");
+   }
+
+   return NULL;
+}
+
 static inline nir_def *
 nir_ball_iequal(nir_builder *b, nir_def *src0, nir_def *src1)
 {
diff --git a/src/compiler/nir/nir_constant_expressions.py b/src/compiler/nir/nir_constant_expressions.py
index 80719f84815..d3c2c729399 100644
--- a/src/compiler/nir/nir_constant_expressions.py
+++ b/src/compiler/nir/nir_constant_expressions.py
@@ -60,6 +60,7 @@ template = """\
 #include "util/half_float.h"
 #include "util/double.h"
 #include "util/softfloat.h"
+#include "util/bfloat.h"
 #include "util/bigmath.h"
 #include "util/format/format_utils.h"
 #include "util/format_r11g11b10f.h"
diff --git a/src/compiler/nir/nir_divergence_analysis.c b/src/compiler/nir/nir_divergence_analysis.c
index 8c45b4a758c..abafd2d5aa3 100644
--- a/src/compiler/nir/nir_divergence_analysis.c
+++ b/src/compiler/nir/nir_divergence_analysis.c
@@ -693,6 +693,7 @@ visit_intrinsic(nir_intrinsic_instr *instr, struct divergence_state *state)
    case nir_intrinsic_is_sparse_resident_zink:
    case nir_intrinsic_sparse_residency_code_and:
    case nir_intrinsic_bvh64_intersect_ray_amd:
+   case nir_intrinsic_bvh8_intersect_ray_amd:
    case nir_intrinsic_image_deref_load_param_intel:
    case nir_intrinsic_image_load_raw_intel:
    case nir_intrinsic_get_ubo_size:
@@ -816,6 +817,7 @@ visit_intrinsic(nir_intrinsic_instr *instr, struct divergence_state *state)
    case nir_intrinsic_task_payload_atomic_swap:
    case nir_intrinsic_global_atomic:
    case nir_intrinsic_global_atomic_swap:
+   case nir_intrinsic_alpha_to_coverage:
    case nir_intrinsic_global_atomic_amd:
    case nir_intrinsic_global_atomic_agx:
    case nir_intrinsic_global_atomic_swap_amd:
diff --git a/src/compiler/nir/nir_gather_info.c b/src/compiler/nir/nir_gather_info.c
index 13ad829d237..888ac6b908e 100644
--- a/src/compiler/nir/nir_gather_info.c
+++ b/src/compiler/nir/nir_gather_info.c
@@ -806,7 +806,7 @@ gather_intrinsic_info(nir_intrinsic_instr *instr, nir_shader *shader,
       shader->info.outputs_written |= BITFIELD64_BIT(FRAG_RESULT_SAMPLE_MASK);
       break;
 
-   case nir_intrinsic_discard_agx:
+   case nir_intrinsic_demote_samples:
       shader->info.fs.uses_discard = true;
       break;
 
diff --git a/src/compiler/nir/nir_gather_output_deps.c b/src/compiler/nir/nir_gather_output_deps.c
new file mode 100644
index 00000000000..c3681844015
--- /dev/null
+++ b/src/compiler/nir/nir_gather_output_deps.c
@@ -0,0 +1,499 @@
+/*
+ * Copyright Â© 2024 Advanced Micro Devices, Inc.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+/* For each output slot, gather which input components are used to compute it.
+ * Component-wise ALU instructions must be scalar.
+ */
+
+#include "nir_builder.h"
+#include "util/hash_table.h"
+#include "util/u_dynarray.h"
+#include "util/u_memory.h"
+
+static void
+accum_deps(BITSET_WORD *dst, BITSET_WORD *src, unsigned num_bitset_words)
+{
+   __bitset_or(dst, dst, src, num_bitset_words);
+}
+
+typedef struct {
+   BITSET_WORD **instr_deps;
+   BITSET_WORD *tmp;
+   unsigned num_bitset_words;
+} foreach_src_data;
+
+static bool
+accum_src_deps(nir_src *src, void *opaque)
+{
+   foreach_src_data *data = (foreach_src_data *)opaque;
+   nir_instr *src_instr = src->ssa->parent_instr;
+
+   if (src_instr->type == nir_instr_type_load_const ||
+       src_instr->type == nir_instr_type_undef)
+      return true;
+
+   nir_instr *dst_instr = nir_src_parent_instr(src);
+   accum_deps(data->instr_deps[dst_instr->index],
+              data->instr_deps[src_instr->index], data->num_bitset_words);
+   return true;
+}
+
+typedef struct {
+   nir_block *start_block; /* the first block of the loop */
+   nir_block *exit_block;  /* the first block after the loop */
+   bool header_phi_changed;
+} loop_entry;
+
+static loop_entry *
+get_current_loop(struct util_dynarray *loop_stack)
+{
+   assert(util_dynarray_num_elements(loop_stack, loop_entry));
+   return util_dynarray_last_ptr(loop_stack, loop_entry);
+}
+
+/* For each output slot, gather which instructions are used to compute it.
+ * The result is that each output slot will have the list of all instructions
+ * that must execute to compute that output.
+ *
+ * If there are memory operations that affect other memory operations, those
+ * dependencies are not gathered.
+ *
+ * Required:
+ * - The shader must be in LCSSA form.
+ *
+ * Recommended:
+ * - IO intrinsics and component-wise ALU instructions should be scalar, and
+ *   vecN opcodes should have their components copy-propagated. If not,
+ *   the results will have false dependencies.
+ *
+ * Algorithm:
+ * - For each instruction, compute a bitset of instruction indices whose
+ *   results are needed to compute the result of the instruction. The final
+ *   bitset is the instruction index OR'd with bitsets of all its sources and
+ *   also all if-conditions used to enter the block, recursively.
+ * - Since every instruction inherits instruction bitsets from its sources,
+ *   every instruction contains the list of all instructions that must execute
+ *   before the instruction can execute.
+ * - At the end, output stores contain the list of instructions that must
+ *   execute to compute their results. This may be any subset of instructions
+ *   from the shader, including all instructions.
+ *
+ * Control flow notes:
+ * - There is a stack of "if" conditions for entered ifs.
+ * - The dependencies of instructions are the union of dependencies of all
+ *   their sources and all if conditions on the if-condition stack.
+ * - For each continue, all loop-header phis receive the dependencies of all
+ *   if-conditions on the if-condition stack at the continue.
+ * - For each break, all loop-exit phis receive the dependencies of all
+ *   if-conditions on the if-condition stack at the break.
+ * - If there is any change to loop-header phis while iterating over a loop,
+ *   we iterate over the loop again after the current iteration is finished.
+ */
+void
+nir_gather_output_dependencies(nir_shader *nir, nir_output_deps *deps)
+{
+   nir_function_impl *impl = nir_shader_get_entrypoint(nir);
+   nir_metadata_require(impl, nir_metadata_instr_index);
+   unsigned num_instr = nir_impl_last_block(impl)->end_ip;
+
+   /* Allocate bitsets of instruction->instruction dependencies. */
+   unsigned num_bitset_words = BITSET_WORDS(num_instr);
+   BITSET_WORD **instr_deps = rzalloc_array(NULL, BITSET_WORD*, num_instr);
+   void *mem_ctx = instr_deps;
+   for (unsigned i = 0; i < num_instr; i++)
+      instr_deps[i] = rzalloc_array(mem_ctx, BITSET_WORD, num_bitset_words);
+
+   /* Allocate bitsets of instruction->output dependencies. */
+   BITSET_WORD **out_deps = rzalloc_array(mem_ctx, BITSET_WORD*,
+                                          NUM_TOTAL_VARYING_SLOTS);
+
+   /* Allocate stacks. */
+   struct util_dynarray loop_stack, if_cond_stack;
+   util_dynarray_init(&loop_stack, mem_ctx);
+   util_dynarray_init(&if_cond_stack, mem_ctx);
+
+   /* Gather dependencies of every instruction.
+    * Dependencies of each instruction are OR'd dependencies of its sources and
+    * control flow conditions.
+    */
+   nir_foreach_block(block, impl) {
+      nir_cf_node *parent_cf = block->cf_node.parent;
+      bool is_loop_first_block = parent_cf->type == nir_cf_node_loop &&
+                                 block == nir_cf_node_cf_tree_first(parent_cf);
+      if (is_loop_first_block) {
+         loop_entry loop = {
+            .start_block = block,
+            .exit_block = nir_cf_node_cf_tree_next(parent_cf),
+         };
+         util_dynarray_append(&loop_stack, loop_entry, loop);
+      }
+
+      if (parent_cf->type == nir_cf_node_if &&
+          block == nir_if_first_then_block(nir_cf_node_as_if(parent_cf))) {
+         util_dynarray_append(&if_cond_stack, nir_def *,
+                              nir_cf_node_as_if(parent_cf)->condition.ssa);
+      }
+
+   loop_again:
+      nir_foreach_instr(instr, block) {
+         /* Add self as a dependency. */
+         BITSET_WORD *this_instr_deps = instr_deps[instr->index];
+         BITSET_SET(this_instr_deps, instr->index);
+
+         /* Add sources as dependencies. */
+         nir_foreach_src(instr, accum_src_deps,
+                         &(foreach_src_data){instr_deps, NULL, num_bitset_words});
+
+         /* Add parent if-conditions as dependencies.
+          *
+          * Note that phis with sources inside conditional blocks don't need
+          * this because the phi sources already contain if-conditions.
+          */
+         util_dynarray_foreach(&if_cond_stack, nir_def *, cond) {
+            accum_deps(this_instr_deps,
+                       instr_deps[(*cond)->parent_instr->index],
+                       num_bitset_words);
+         }
+
+         /* Gather the current instruction. */
+         switch (instr->type) {
+         case nir_instr_type_jump:
+            switch (nir_instr_as_jump(instr)->type) {
+            case nir_jump_continue:
+            case nir_jump_break: {
+               loop_entry *loop = get_current_loop(&loop_stack);
+               /* Iterate over all loop-header phis (for continue) or all
+                * loop-exit phis (for break).
+                *
+                * Assumption: Only the loop-start block can have loop-header
+                * phis.
+                */
+               bool is_continue =
+                  nir_instr_as_jump(instr)->type == nir_jump_continue;
+               nir_block *iter_block =
+                  is_continue ? loop->start_block : loop->exit_block;
+               assert(iter_block);
+
+               nir_foreach_phi(phi, iter_block) {
+                  /* We need to track whether any header phi of the current
+                   * loop has changed because we need to walk such loops
+                   * again. Use the bitset bitcount to determine whether
+                   * any instruction has been added to header phis as
+                   * a dependency.
+                   */
+                  unsigned old_count = 0;
+                  if (is_continue) {
+                     old_count = __bitset_count(instr_deps[phi->instr.index],
+                                                num_bitset_words);
+                  }
+
+                  /* Add dependencies of all if-conditions affecting the
+                   * jump statement to phis at the loop header / exit.
+                   */
+                  util_dynarray_foreach(&if_cond_stack, nir_def *, cond) {
+                     accum_deps(instr_deps[phi->instr.index],
+                                instr_deps[(*cond)->parent_instr->index],
+                                num_bitset_words);
+                  }
+
+                  if (is_continue &&
+                      old_count != __bitset_count(instr_deps[phi->instr.index],
+                                     num_bitset_words))
+                     loop->header_phi_changed = true;
+               }
+               break;
+            }
+            default:
+               unreachable("unexpected jump type");
+            }
+            break;
+
+         case nir_instr_type_intrinsic: {
+            nir_intrinsic_instr *intr = nir_instr_as_intrinsic(instr);
+
+            switch (intr->intrinsic) {
+            case nir_intrinsic_store_output:
+            case nir_intrinsic_store_per_vertex_output:
+            case nir_intrinsic_store_per_primitive_output:
+            case nir_intrinsic_store_per_view_output: {
+               /* The write mask must be contiguous starting from x. */
+               ASSERTED unsigned writemask = nir_intrinsic_write_mask(intr);
+               assert(writemask == BITFIELD_MASK(util_bitcount(writemask)));
+
+               nir_io_semantics sem = nir_intrinsic_io_semantics(intr);
+               assert(sem.num_slots >= 1);
+
+               for (unsigned i = 0; i < sem.num_slots; i++) {
+                  unsigned slot = sem.location + i;
+                  if (!out_deps[slot]) {
+                     out_deps[slot] = rzalloc_array(mem_ctx, BITSET_WORD,
+                                                    num_bitset_words);
+                  }
+                  accum_deps(out_deps[slot], this_instr_deps, num_bitset_words);
+               }
+               break;
+            }
+
+            default:
+               break;
+            }
+            break;
+         }
+
+         default:
+            break;
+         }
+      }
+
+      if (parent_cf->type == nir_cf_node_if &&
+          block == nir_if_last_else_block(nir_cf_node_as_if(parent_cf))) {
+         /* Add the current if stack to the phis after the if node because
+          * this can happen:
+          *
+          *    a = load_const true
+          *    b = load_const false
+          *    if (cond) {
+          *    } else {
+          *    }
+          *    c = phi a, b
+          *
+          * c depends on cond, but doesn't use any defs from then/else blocks.
+          */
+         nir_foreach_phi(phi, nir_cf_node_cf_tree_next(parent_cf)) {
+            util_dynarray_foreach(&if_cond_stack, nir_def *, cond) {
+               accum_deps(instr_deps[phi->instr.index],
+                          instr_deps[(*cond)->parent_instr->index],
+                          num_bitset_words);
+            }
+         }
+
+         assert(util_dynarray_num_elements(&if_cond_stack, nir_def *));
+         (void)util_dynarray_pop_ptr(&if_cond_stack, nir_def *);
+      }
+
+      if (parent_cf->type == nir_cf_node_loop &&
+          block == nir_cf_node_cf_tree_last(parent_cf)) {
+         assert(util_dynarray_num_elements(&loop_stack, loop_entry));
+         loop_entry *loop = get_current_loop(&loop_stack);
+
+         /* Check if any loop header phis would be changed by iterating over
+          * the loop again.
+          */
+         nir_foreach_phi(phi, loop->start_block) {
+            unsigned old_count = __bitset_count(instr_deps[phi->instr.index],
+                                                num_bitset_words);
+            nir_foreach_src(&phi->instr, accum_src_deps,
+                            &(foreach_src_data){instr_deps, NULL, num_bitset_words});
+            if (old_count != __bitset_count(instr_deps[phi->instr.index],
+                                            num_bitset_words)) {
+               loop->header_phi_changed = true;
+               break;
+            }
+         }
+
+         if (loop->header_phi_changed) {
+            loop->header_phi_changed = false;
+            /* Iterate over the loop again: */
+            is_loop_first_block = true;
+            block = loop->start_block;
+            assert(block);
+            goto loop_again;
+         }
+
+         (void)util_dynarray_pop_ptr(&loop_stack, loop_entry);
+      }
+   }
+
+   /* Gather instructions that affect each output from bitsets. */
+   memset(deps, 0, sizeof(*deps));
+
+   for (unsigned i = 0; i < NUM_TOTAL_VARYING_SLOTS; i++) {
+      if (!out_deps[i])
+         continue;
+
+      unsigned total = __bitset_count(out_deps[i], num_bitset_words);
+      unsigned added = 0;
+      deps->output[i].num_instr = total;
+      deps->output[i].instr_list = malloc(total * sizeof(nir_instr*));
+
+      nir_foreach_block(block, impl) {
+         nir_foreach_instr(instr, block) {
+            if (BITSET_TEST(out_deps[i], instr->index)) {
+               assert(added < total);
+               deps->output[i].instr_list[added++] = instr;
+            }
+         }
+      }
+      assert(added == total);
+   }
+
+   ralloc_free(mem_ctx);
+}
+
+void
+nir_free_output_dependencies(nir_output_deps *deps)
+{
+   for (unsigned i = 0; i < ARRAY_SIZE(deps->output); i++) {
+      assert(!!deps->output[i].instr_list == !!deps->output[i].num_instr);
+      if (deps->output[i].instr_list)
+         free(deps->output[i].instr_list);
+   }
+}
+
+static unsigned
+get_slot_index(nir_intrinsic_instr *intr, unsigned slot_offset)
+{
+   nir_io_semantics sem = nir_intrinsic_io_semantics(intr);
+   return (sem.location + slot_offset) * 8 + nir_intrinsic_component(intr) * 2 +
+          sem.high_16bits;
+}
+
+/* For each output slot, gather which inputs are used to compute it.
+ * The shader must be in LCSSA form.
+ *
+ * If there are memory operations that affect other memory operations, those
+ * dependencies are not gathered.
+ */
+void
+nir_gather_input_to_output_dependencies(nir_shader *nir,
+                                        nir_input_to_output_deps *out_deps)
+{
+   nir_output_deps deps;
+   nir_gather_output_dependencies(nir, &deps);
+
+   memset(out_deps, 0, sizeof(*out_deps));
+
+   for (unsigned out = 0; out < ARRAY_SIZE(deps.output); out++) {
+      unsigned num_instr = deps.output[out].num_instr;
+
+      if (!num_instr)
+         continue;
+
+      out_deps->output[out].defined = true;
+
+      for (unsigned i = 0; i < num_instr; i++) {
+         nir_instr *instr = deps.output[out].instr_list[i];
+         if (instr->type != nir_instr_type_intrinsic)
+            continue;
+
+         nir_intrinsic_instr *intr = nir_instr_as_intrinsic(instr);
+         switch (intr->intrinsic) {
+         case nir_intrinsic_load_input:
+         case nir_intrinsic_load_input_vertex:
+         case nir_intrinsic_load_per_vertex_input:
+         case nir_intrinsic_load_per_primitive_input:
+         case nir_intrinsic_load_interpolated_input: {
+            nir_io_semantics sem = nir_intrinsic_io_semantics(intr);
+            assert(intr->def.num_components == 1);
+            assert(sem.num_slots >= 1);
+
+            for (unsigned index = 0; index < sem.num_slots; index++) {
+               unsigned slot = get_slot_index(intr, index);
+               BITSET_SET(out_deps->output[out].inputs, slot);
+            }
+            break;
+         }
+         case nir_instr_type_tex:
+            if (!nir_tex_instr_is_query(nir_instr_as_tex(instr)))
+               out_deps->output[out].uses_image_reads = true;
+            break;
+         default: {
+            const char *name = nir_intrinsic_infos[intr->intrinsic].name;
+
+            if (strstr(name, "load_ssbo") || strstr(name, "ssbo_atomic"))
+               out_deps->output[out].uses_ssbo_reads = true;
+
+            if (strstr(name, "image") &&
+                (strstr(name, "load") || strstr(name, "atomic")))
+               out_deps->output[out].uses_image_reads = true;
+            break;
+         }
+         }
+      }
+   }
+
+   nir_free_output_dependencies(&deps);
+}
+
+void
+nir_print_input_to_output_deps(nir_input_to_output_deps *deps,
+                               nir_shader *nir, FILE *f)
+{
+   for (unsigned i = 0; i < NUM_TOTAL_VARYING_SLOTS; i++) {
+      if (!deps->output[i].defined)
+         continue;
+
+      fprintf(f, "%s(->%s): %s =",
+              _mesa_shader_stage_to_abbrev(nir->info.stage),
+              nir->info.next_stage != MESA_SHADER_NONE ?
+                 _mesa_shader_stage_to_abbrev(nir->info.next_stage) :
+                 "NONE",
+              gl_varying_slot_name_for_stage(i, nir->info.stage));
+
+      unsigned in;
+      BITSET_FOREACH_SET(in, deps->output[i].inputs, NUM_TOTAL_VARYING_SLOTS * 8) {
+         fprintf(f, " %u.%c%s", in / 8, "xyzw"[(in % 8) / 2], in % 2 ? ".hi" : "");
+      }
+      fprintf(f, "%s%s",
+              deps->output[i].uses_ssbo_reads ? " (ssbo read)" : "",
+              deps->output[i].uses_image_reads ? " (image read)" : "");
+      fprintf(f, "\n");
+   }
+}
+
+/* Gather 3 disjoint sets:
+ * - the set of input components only used to compute outputs for the clipper
+ *   (those that are only used to compute the position and clip outputs)
+ * - the set of input components only used to compute all other outputs
+ * - the set of input components that are used to compute BOTH outputs for
+ *   the clipper and all other outputs
+ *
+ * If there are memory operations that affect other memory operations, those
+ * dependencies are not gathered.
+ *
+ * The shader must be in LCSSA form.
+ *
+ * Patch outputs are not gathered because shaders feeding the clipper don't
+ * have patch outputs.
+ */
+void
+nir_gather_output_clipper_var_groups(nir_shader *nir,
+                                     nir_output_clipper_var_groups *groups)
+{
+   nir_input_to_output_deps *deps = calloc(1, sizeof(*deps));
+   nir_gather_input_to_output_dependencies(nir, deps);
+
+   uint32_t clipper_outputs = VARYING_BIT_POS |
+                              VARYING_BIT_CLIP_VERTEX |
+                              VARYING_BIT_CLIP_DIST0 |
+                              VARYING_BIT_CLIP_DIST1 |
+                              VARYING_BIT_CULL_DIST0 |
+                              VARYING_BIT_CULL_DIST1;
+
+   /* OR-reduce the per-output sets. */
+   memset(groups, 0, sizeof(*groups));
+
+   u_foreach_bit(i, clipper_outputs) {
+      if (deps->output[i].defined) {
+         BITSET_OR(groups->pos_only, groups->pos_only,
+                   deps->output[i].inputs);
+      }
+   }
+
+   for (unsigned i = 0; i < NUM_TOTAL_VARYING_SLOTS; i++) {
+      if (deps->output[i].defined &&
+          (i >= 32 || !(clipper_outputs & BITFIELD_BIT(i)))) {
+         BITSET_OR(groups->var_only, groups->var_only,
+                   deps->output[i].inputs);
+      }
+   }
+
+   /* Compute the intersection of the above and make them disjoint. */
+   BITSET_AND(groups->both, groups->pos_only, groups->var_only);
+   BITSET_ANDNOT(groups->pos_only, groups->pos_only, groups->both);
+   BITSET_ANDNOT(groups->var_only, groups->var_only, groups->both);
+   free(deps);
+}
diff --git a/src/compiler/nir/nir_intrinsics.py b/src/compiler/nir/nir_intrinsics.py
index b0769ebf8e1..189ade3b000 100644
--- a/src/compiler/nir/nir_intrinsics.py
+++ b/src/compiler/nir/nir_intrinsics.py
@@ -223,6 +223,12 @@ index("nir_alu_type", "src_type")
 # The nir_alu_type of the data output from a load or conversion
 index("nir_alu_type", "dest_type")
 
+# Source and destination data types for dpas_intel.  Needed here to
+# represent types that won't have a nir_alu_type.
+index("enum glsl_base_type", "src_base_type")
+index("enum glsl_base_type", "src_base_type2")
+index("enum glsl_base_type", "dest_base_type")
+
 # The swizzle mask for quad_swizzle_amd & masked_swizzle_amd
 index("unsigned", "swizzle_mask")
 
@@ -322,6 +328,8 @@ index("struct glsl_cmat_description", "cmat_desc")
 index("enum glsl_matrix_layout", "matrix_layout")
 index("nir_cmat_signed", "cmat_signed_mask")
 index("nir_op", "alu_op")
+index("unsigned", "neg_lo_amd")
+index("unsigned", "neg_hi_amd")
 
 # For Intel DPAS instrinsic.
 index("unsigned", "systolic_depth")
@@ -1118,6 +1126,14 @@ barycentric("coord_at_offset", 3, [2])
 intrinsic("load_sample_pos_from_id", src_comp=[1], dest_comp=2,
           flags=[CAN_ELIMINATE, CAN_REORDER])
 
+# Demote a subset of samples given by a specified sample mask. This acts like a
+# per-sample demote, or an inverted accumulating gl_SampleMask write.
+intrinsic("demote_samples", src_comp=[1])
+
+# Convert float value to coverage mask.
+intrinsic("alpha_to_coverage", src_comp=[1], dest_comp=1, indices=[],
+          flags=[CAN_ELIMINATE, CAN_REORDER], bit_sizes=[16])
+
 intrinsic("load_persp_center_rhw_ir3", dest_comp=1,
           flags=[CAN_ELIMINATE, CAN_REORDER])
 
@@ -1336,6 +1352,7 @@ intrinsic("cmat_load", src_comp=[-1, -1, 1], indices=[MATRIX_LAYOUT])
 intrinsic("cmat_store", src_comp=[-1, -1, 1], indices=[MATRIX_LAYOUT])
 intrinsic("cmat_length", src_comp=[], dest_comp=1, indices=[CMAT_DESC], bit_sizes=[32])
 intrinsic("cmat_muladd", src_comp=[-1, -1, -1, -1], indices=[SATURATE, CMAT_SIGNED_MASK])
+intrinsic("cmat_convert", src_comp=[-1, -1], indices=[CMAT_SIGNED_MASK])
 intrinsic("cmat_unary_op", src_comp=[-1, -1], indices=[ALU_OP])
 intrinsic("cmat_binary_op", src_comp=[-1, -1, -1], indices=[ALU_OP])
 intrinsic("cmat_scalar_op", src_comp=[-1, -1, -1], indices=[ALU_OP])
@@ -1776,6 +1793,32 @@ system_value("sbt_base_amd", 1, bit_sizes=[64])
 # 6. inverse ray direction (componentwise 1.0/ray direction)
 intrinsic("bvh64_intersect_ray_amd", [4, 2, 1, 3, 3, 3], 4, flags=[CAN_ELIMINATE, CAN_REORDER])
 
+# 1. HW descriptor
+# 2. BVH base
+# 3. instance cull mask
+# 4. ray extent
+# 5. ray origin
+# 6. ray direction
+# 7. node ID
+#
+# dst:
+# | component | box node    | instance node        | triangle node                     | procedural node                   |
+# |-----------|-------------|----------------------|-----------------------------------|-----------------------------------|
+# | 0         | child_id[0] |                      | t[0]                              |                                   |
+# | 1         | child_id[1] |                      | u[0]                              |                                   |
+# | 2         | child_id[2] | blas_addr_lo         | v[0]                              |                                   |
+# | 3         | child_id[3] | blas_addr_hi         | primitive_index_hit_kind[0]       | primitive_index                   |
+# | 4         | child_id[4] |                      | t[1]                              |                                   |
+# | 5         | child_id[5] |                      | u[1]                              |                                   |
+# | 6         | child_id[6] | user_data            | v[1]                              |                                   |
+# | 7         | child_id[7] | next_node_ids        | primitive_index_hit_kind[1]       |                                   |
+# | 8         |             |                      | geometry_index_navigation_bits[0] | geometry_index_navigation_bits[0] |
+# | 9         |             |                      | geometry_index_navigation_bits[1] | geometry_index_navigation_bits[1] |
+# | [10,12]   |             | object_ray_origin    |                                   |                                   |
+# | [13,15]   |             | object_ray_direction |                                   |                                   |
+#
+intrinsic("bvh8_intersect_ray_amd", [4, 2, 1, 1, 3, 3, 1], 16, flags=[CAN_ELIMINATE, CAN_REORDER])
+
 # Return of a callable in raytracing pipelines
 intrinsic("rt_return_amd")
 
@@ -1940,7 +1983,7 @@ intrinsic("strict_wqm_coord_amd", src_comp=[0], dest_comp=0, bit_sizes=[32], ind
           flags=[CAN_ELIMINATE])
 
 intrinsic("cmat_muladd_amd", src_comp=[-1, -1, 0], dest_comp=0, bit_sizes=src2,
-          indices=[SATURATE, CMAT_SIGNED_MASK], flags=[CAN_ELIMINATE])
+          indices=[SATURATE, NEG_LO_AMD, NEG_HI_AMD, SRC_BASE_TYPE, SRC_BASE_TYPE2], flags=[CAN_ELIMINATE])
 
 # Get the debug log buffer descriptor.
 intrinsic("load_debug_log_desc_amd", bit_sizes=[32], dest_comp=4, flags=[CAN_ELIMINATE, CAN_REORDER])
@@ -2144,12 +2187,6 @@ load("sysval_agx", [], [DESC_SET, BINDING, FLAGS], [CAN_REORDER, CAN_ELIMINATE])
 # documented elsewhere as they are too complicated for this comment.
 intrinsic("sample_mask_agx", src_comp=[1, 1])
 
-# Discard a subset of samples given by a specified sample mask. This acts like a
-# per-sample discard, or an inverted accumulating gl_SampleMask write. The
-# compiler will lower to sample_mask_agx, but that lowering is nontrivial as
-# sample_mask_agx also triggers depth/stencil testing.
-intrinsic("discard_agx", src_comp=[1])
-
 # For a given row of the polygon stipple given as an integer source in [0, 31],
 # load the 32-bit stipple pattern for that row.
 intrinsic("load_polygon_stipple_agx", src_comp=[1], dest_comp=1, bit_sizes=[32],
@@ -2390,7 +2427,7 @@ system_value("ray_query_global_intel", 1, bit_sizes=[64])
 # its value. Some supported configurations will have the component count of
 # that matrix different than the others.
 intrinsic("dpas_intel", dest_comp=0, src_comp=[0, -1, 0],
-          indices=[DEST_TYPE, SRC_TYPE, SATURATE, SYSTOLIC_DEPTH, REPEAT_COUNT],
+          indices=[DEST_BASE_TYPE, SRC_BASE_TYPE, SATURATE, SYSTOLIC_DEPTH, REPEAT_COUNT],
           flags=[CAN_ELIMINATE])
 
 # NVIDIA-specific intrinsics
diff --git a/src/asahi/lib/agx_nir_lower_alpha.c b/src/compiler/nir/nir_lower_alpha.c
similarity index 87%
rename from src/asahi/lib/agx_nir_lower_alpha.c
rename to src/compiler/nir/nir_lower_alpha.c
index 6b039c00552..006c4395182 100644
--- a/src/asahi/lib/agx_nir_lower_alpha.c
+++ b/src/compiler/nir/nir_lower_alpha.c
@@ -4,16 +4,31 @@
  * SPDX-License-Identifier: MIT
  */
 
-#include "agx_tilebuffer.h"
 #include "nir.h"
 #include "nir_builder.h"
 
+static nir_def *
+alpha_to_coverage(nir_builder *b, nir_def *alpha, uint8_t nr_samples, bool has_intrinsic)
+{
+   if (has_intrinsic)
+      return nir_alpha_to_coverage(b, alpha);
+
+   /* Calculate a coverage mask (alpha * nr_samples) bits set. The way we do
+    * this isn't particularly clever:
+    *
+    *    # of bits = (unsigned int) (alpha * nr_samples)
+    *    mask = (1 << (# of bits)) - 1
+    */
+   nir_def *bits = nir_f2u32(b, nir_fmul_imm(b, alpha, nr_samples));
+   return nir_iadd_imm(b, nir_ishl(b, nir_imm_intN_t(b, 1, 16), bits), -1);
+}
+
 /*
  * Lower alpha-to-coverage to sample_mask and some math. May run on either a
  * monolithic pixel shader or a fragment epilogue.
  */
 bool
-agx_nir_lower_alpha_to_coverage(nir_shader *shader, uint8_t nr_samples)
+nir_lower_alpha_to_coverage(nir_shader *shader, uint8_t nr_samples, bool has_intrinsic)
 {
    /* nir_lower_io_to_temporaries ensures that stores are in the last block */
    nir_function_impl *impl = nir_shader_get_entrypoint(shader);
@@ -53,19 +68,11 @@ agx_nir_lower_alpha_to_coverage(nir_shader *shader, uint8_t nr_samples)
    nir_builder _b = nir_builder_at(nir_before_instr(&store->instr));
    nir_builder *b = &_b;
 
-   /* Calculate a coverage mask (alpha * nr_samples) bits set. The way we do
-    * this isn't particularly clever:
-    *
-    *    # of bits = (unsigned int) (alpha * nr_samples)
-    *    mask = (1 << (# of bits)) - 1
-    */
    nir_def *alpha = nir_channel(b, rgba, 3);
-   nir_def *bits = nir_f2u32(b, nir_fmul_imm(b, alpha, nr_samples));
-   nir_def *mask =
-      nir_iadd_imm(b, nir_ishl(b, nir_imm_intN_t(b, 1, 16), bits), -1);
+   nir_def *mask = alpha_to_coverage(b, alpha, nr_samples, has_intrinsic);
 
    /* Discard samples that aren't covered */
-   nir_discard_agx(b, nir_inot(b, mask));
+   nir_demote_samples(b, nir_inot(b, mask));
    shader->info.fs.uses_discard = true;
    return nir_progress(true, impl, nir_metadata_control_flow);
 }
@@ -76,7 +83,7 @@ agx_nir_lower_alpha_to_coverage(nir_shader *shader, uint8_t nr_samples)
  * fragment epilogue.
  */
 bool
-agx_nir_lower_alpha_to_one(nir_shader *shader)
+nir_lower_alpha_to_one(nir_shader *shader)
 {
    bool progress = false;
 
diff --git a/src/compiler/nir/nir_lower_alu_width.c b/src/compiler/nir/nir_lower_alu_width.c
index cf1e6dfdefc..85c3f17c191 100644
--- a/src/compiler/nir/nir_lower_alu_width.c
+++ b/src/compiler/nir/nir_lower_alu_width.c
@@ -140,9 +140,51 @@ will_lower_ffma(nir_shader *shader, unsigned bit_size)
    unreachable("bad bit size");
 }
 
+static nir_def *
+lower_bfdot_to_bfdot2_bfadd(nir_builder *b, nir_alu_instr *alu)
+{
+   unsigned num_components = nir_op_infos[alu->op].input_sizes[0];
+
+   nir_def *acc = nir_imm_intN_t(b, 0x8000, 16); /* -0.0 BF16`*/
+   for (int i = 0; i < num_components; i += 2) {
+      nir_alu_instr *instr = nir_alu_instr_create(b->shader, nir_op_bfdot2_bfadd);
+      nir_alu_ssa_dest_init(instr, 1, 16);
+
+      for (unsigned j = 0; j < 2; j++) {
+         if (num_components - i == 1) {
+            /* Pad with mix of -0.0 and +0.0 to get -0.0 for the mul. */
+            nir_def *zero = nir_imm_intN_t(b, j ? 0x8000 : 0, 16);
+            nir_def *src = nir_vec2(b, nir_channel(b, alu->src[j].src.ssa, i), zero);
+            instr->src[j].src = nir_src_for_ssa(src);
+         } else {
+            nir_alu_src_copy(&instr->src[j], &alu->src[j]);
+            instr->src[j].swizzle[0] = alu->src[j].swizzle[i];
+            instr->src[j].swizzle[1] = alu->src[j].swizzle[i + 1];
+         }
+      }
+      instr->src[2].src = nir_src_for_ssa(acc);
+      instr->exact = b->exact;
+      instr->fp_fast_math = b->fp_fast_math;
+
+      nir_builder_instr_insert(b, &instr->instr);
+      acc = &instr->def;
+   }
+
+   return acc;
+}
+
 static nir_def *
 lower_fdot(nir_alu_instr *alu, nir_builder *builder)
 {
+   const bool is_bfloat16 = alu->op == nir_op_bfdot2 ||
+                            alu->op == nir_op_bfdot3 ||
+                            alu->op == nir_op_bfdot4 ||
+                            alu->op == nir_op_bfdot8 ||
+                            alu->op == nir_op_bfdot16;
+
+   if (is_bfloat16 && builder->shader->options->has_bfdot2_bfadd)
+      return lower_bfdot_to_bfdot2_bfadd(builder, alu);
+
    /* Reversed order can result in lower instruction count because it
     * creates more MAD/FMA in the case of fdot(a, vec4(b, 1.0)).
     * Some games expect xyzw order, so only reverse the order for imprecise fdot.
@@ -152,16 +194,19 @@ lower_fdot(nir_alu_instr *alu, nir_builder *builder)
    /* If we don't want to lower ffma, create several ffma instead of fmul+fadd
     * and fusing later because fusing is not possible for exact fdot instructions.
     */
-   if (will_lower_ffma(builder->shader, alu->def.bit_size))
+   if (!is_bfloat16 && will_lower_ffma(builder->shader, alu->def.bit_size))
       return lower_reduction(alu, nir_op_fmul, nir_op_fadd, builder, reverse_order);
 
    unsigned num_components = nir_op_infos[alu->op].input_sizes[0];
 
+   const nir_op fma_op = is_bfloat16 ? nir_op_bffma : nir_op_ffma;
+   const nir_op mul_op = is_bfloat16 ? nir_op_bfmul : nir_op_fmul;
+
    nir_def *prev = NULL;
    for (int i = 0; i < num_components; i++) {
       int channel = reverse_order ? num_components - 1 - i : i;
       nir_alu_instr *instr = nir_alu_instr_create(
-         builder->shader, prev ? nir_op_ffma : nir_op_fmul);
+         builder->shader, prev ? fma_op : mul_op);
       nir_alu_ssa_dest_init(instr, 1, alu->def.bit_size);
       for (unsigned j = 0; j < 2; j++) {
          nir_alu_src_copy(&instr->src[j], &alu->src[j]);
@@ -344,6 +389,11 @@ lower_alu_instr_width(nir_builder *b, nir_instr *instr, void *_data)
    case nir_op_fdot4:
    case nir_op_fdot8:
    case nir_op_fdot16:
+   case nir_op_bfdot2:
+   case nir_op_bfdot3:
+   case nir_op_bfdot4:
+   case nir_op_bfdot8:
+   case nir_op_bfdot16:
       return lower_fdot(alu, b);
 
       LOWER_REDUCTION(nir_op_ball_fequal, nir_op_feq, nir_op_iand);
diff --git a/src/compiler/nir/nir_lower_gs_intrinsics.c b/src/compiler/nir/nir_lower_gs_intrinsics.c
index d37833b7066..b6dc21d2992 100644
--- a/src/compiler/nir/nir_lower_gs_intrinsics.c
+++ b/src/compiler/nir/nir_lower_gs_intrinsics.c
@@ -142,8 +142,7 @@ rewrite_emit_vertex(nir_intrinsic_instr *intrin, struct state *state)
       /* We form a new primitive for every vertex emitted after the first
        * complete primitive (since we're outputting strips).
        */
-      unsigned min_verts =
-         mesa_vertices_per_prim(b->shader->info.gs.output_primitive);
+      unsigned min_verts = nir_verts_in_output_prim(b->shader);
       nir_def *new_prim = nir_uge_imm(b, vtx_per_prim_cnt, min_verts);
 
       /* Increment the decomposed primitive count by 1 if we formed a complete
@@ -185,8 +184,6 @@ overwrite_incomplete_primitives(struct state *state, unsigned stream)
    assert(state->count_vtx_per_prim);
 
    nir_builder *b = state->builder;
-   unsigned outprim_min_vertices =
-      mesa_vertices_per_prim(b->shader->info.gs.output_primitive);
 
    /* Total count of vertices emitted so far. */
    nir_def *vtxcnt_total =
@@ -198,7 +195,7 @@ overwrite_incomplete_primitives(struct state *state, unsigned stream)
 
    /* See if the current primitive is a incomplete */
    nir_def *is_inc_prim =
-      nir_ilt_imm(b, vtxcnt_per_primitive, outprim_min_vertices);
+      nir_ilt_imm(b, vtxcnt_per_primitive, nir_verts_in_output_prim(b->shader));
 
    /* Number of vertices in the incomplete primitive */
    nir_def *num_inc_vtx =
diff --git a/src/compiler/nir/nir_lower_io.c b/src/compiler/nir/nir_lower_io.c
index 7ab2c63330e..109327e07d2 100644
--- a/src/compiler/nir/nir_lower_io.c
+++ b/src/compiler/nir/nir_lower_io.c
@@ -2663,6 +2663,65 @@ lower_vars_to_explicit(nir_shader *shader,
    return progress;
 }
 
+static unsigned
+nir_calculate_alignment_from_explicit_layout(const glsl_type *type,
+                                             glsl_type_size_align_func type_info)
+{
+   unsigned size, alignment;
+   glsl_get_explicit_type_for_size_align(type, type_info,
+                                         &size, &alignment);
+   return alignment;
+}
+
+static void
+nir_assign_shared_var_locations(nir_shader *shader, glsl_type_size_align_func type_info)
+{
+   assert(shader->info.shared_memory_explicit_layout);
+
+   /* Calculate region for Aliased shared memory at the beginning. */
+   unsigned aliased_size = 0;
+   unsigned aliased_alignment = 0;
+   nir_foreach_variable_with_modes(var, shader, nir_var_mem_shared) {
+      /* Per SPV_KHR_workgroup_storage_explicit_layout, if one shared variable is
+       * a Block, all of them will be and Blocks are explicitly laid out.
+       */
+      assert(glsl_type_is_interface(var->type));
+
+      if (var->data.aliased_shared_memory) {
+         const bool align_to_stride = false;
+         aliased_size = MAX2(aliased_size, glsl_get_explicit_size(var->type, align_to_stride));
+         aliased_alignment = MAX2(aliased_alignment,
+                                  nir_calculate_alignment_from_explicit_layout(var->type, type_info));
+      }
+   }
+
+   unsigned offset = shader->info.shared_size;
+
+   unsigned aliased_location = UINT_MAX;
+   if (aliased_size) {
+      aliased_location = align(offset, aliased_alignment);
+      offset = aliased_location + aliased_size;
+   }
+
+   /* Allocate Blocks either at the Aliased region or after it. */
+   nir_foreach_variable_with_modes(var, shader, nir_var_mem_shared) {
+      if (var->data.aliased_shared_memory) {
+         assert(aliased_location != UINT_MAX);
+         var->data.driver_location = aliased_location;
+      } else {
+         const bool align_to_stride = false;
+         const unsigned size = glsl_get_explicit_size(var->type, align_to_stride);
+         const unsigned alignment =
+            MAX2(nir_calculate_alignment_from_explicit_layout(var->type, type_info),
+                 var->data.alignment);
+         var->data.driver_location = align(offset, alignment);
+         offset = var->data.driver_location + size;
+      }
+   }
+
+   shader->info.shared_size = offset;
+}
+
 /* If nir_lower_vars_to_explicit_types is called on any shader that contains
  * generic pointers, it must either be used on all of the generic modes or
  * none.
@@ -2693,8 +2752,13 @@ nir_lower_vars_to_explicit_types(nir_shader *shader,
       progress |= lower_vars_to_explicit(shader, &shader->variables, nir_var_mem_global, type_info);
 
    if (modes & nir_var_mem_shared) {
-      assert(!shader->info.shared_memory_explicit_layout);
-      progress |= lower_vars_to_explicit(shader, &shader->variables, nir_var_mem_shared, type_info);
+      if (shader->info.shared_memory_explicit_layout) {
+         nir_assign_shared_var_locations(shader, type_info);
+         /* Types don't change, so no further lowering is needed. */
+         modes &= ~nir_var_mem_shared;
+      } else {
+         progress |= lower_vars_to_explicit(shader, &shader->variables, nir_var_mem_shared, type_info);
+      }
    }
 
    if (modes & nir_var_shader_temp)
@@ -2712,11 +2776,13 @@ nir_lower_vars_to_explicit_types(nir_shader *shader,
    if (modes & nir_var_mem_node_payload_in)
       progress |= lower_vars_to_explicit(shader, &shader->variables, nir_var_mem_node_payload_in, type_info);
 
-   nir_foreach_function_impl(impl, shader) {
-      if (modes & nir_var_function_temp)
-         progress |= lower_vars_to_explicit(shader, &impl->locals, nir_var_function_temp, type_info);
+   if (modes) {
+      nir_foreach_function_impl(impl, shader) {
+         if (modes & nir_var_function_temp)
+            progress |= lower_vars_to_explicit(shader, &impl->locals, nir_var_function_temp, type_info);
 
-      progress |= nir_lower_vars_to_explicit_types_impl(impl, modes, type_info);
+         progress |= nir_lower_vars_to_explicit_types_impl(impl, modes, type_info);
+      }
    }
 
    return progress;
diff --git a/src/compiler/nir/nir_opcodes.py b/src/compiler/nir/nir_opcodes.py
index 4a00b173a0d..def4b6f284c 100644
--- a/src/compiler/nir/nir_opcodes.py
+++ b/src/compiler/nir/nir_opcodes.py
@@ -1727,3 +1727,45 @@ opcode("udot_2x16_uadd_sat", 0, tint32, [0, 0, 0], [tuint32, tuint32, tint32],
 
    dst = tmp >= UINT32_MAX ? UINT32_MAX : tmp;
 """)
+
+# Bfloat16 operations.
+
+unop_numeric_convert("bf2f", tfloat32, tuint16, "_mesa_bfloat16_bits_to_float(src0)")
+unop_numeric_convert("f2bf", tuint16, tfloat32, "_mesa_float_to_bfloat16_bits_rte(src0)")
+
+binop("bfmul", tuint16, _2src_commutative + associative, """
+   const float a = _mesa_bfloat16_bits_to_float(src0);
+   const float b = _mesa_bfloat16_bits_to_float(src1);
+   dst = _mesa_float_to_bfloat16_bits_rte(a * b);
+""")
+
+triop("bffma", tuint16, _2src_commutative, """
+    const float a = _mesa_bfloat16_bits_to_float(src0);
+    const float b = _mesa_bfloat16_bits_to_float(src1);
+    const float c = _mesa_bfloat16_bits_to_float(src2);
+    dst = _mesa_float_to_bfloat16_bits_rte(fmaf(a, b, c));
+""")
+
+binop_reduce("bfdot", 1, tuint16, tuint16,
+             "_mesa_bfloat16_bits_to_float({src0}) * _mesa_bfloat16_bits_to_float({src1})",
+             "_mesa_bfloat16_bits_to_float({src0}) + _mesa_bfloat16_bits_to_float({src1})",
+             "_mesa_float_to_bfloat16_bits_rte({src})")
+
+# Like bfdot2 but with accumulator
+opcode("bfdot2_bfadd", 1, tint16, [2, 2, 1], [tint16, tint16, tint16],
+       False, _2src_commutative, """
+   const float a0 = _mesa_bfloat16_bits_to_float(src0.x);
+   const float a1 = _mesa_bfloat16_bits_to_float(src0.y);
+   const float b0 = _mesa_bfloat16_bits_to_float(src1.x);
+   const float b1 = _mesa_bfloat16_bits_to_float(src1.y);
+
+   float acc = _mesa_bfloat16_bits_to_float(src2.x);
+   acc = fmaf(a0, b0, acc);
+   acc = fmaf(a1, b1, acc);
+
+   dst.x = _mesa_float_to_bfloat16_bits_rte(acc);
+""")
+
+
+unop_numeric_convert("e4m3fn2f", tfloat32, tuint8, "0") # TODO constant fold
+unop_numeric_convert("f2e4m3fn", tuint8, tfloat32, "0") # TODO constant fold
diff --git a/src/compiler/nir/nir_opt_algebraic.py b/src/compiler/nir/nir_opt_algebraic.py
index 215aae4ba89..a618ce82415 100644
--- a/src/compiler/nir/nir_opt_algebraic.py
+++ b/src/compiler/nir/nir_opt_algebraic.py
@@ -1024,14 +1024,20 @@ optimizations.extend([
    (('fmax', ('fneg', ('fmin', b, a)), b), ('fmax', ('fabs', b), ('fneg', a))),
    (('fmin', ('fneg', ('fmax', b, a)), b), ('fmin', ('fneg', ('fabs', b)), ('fneg', a))),
 
-   # If a in [0,b] then b-a is also in [0,b].  Since b in [0,1], max(b-a, 0) =
-   # fsat(b-a).
+   # If a in [-b,0] then a+b is in [0,b].  Since b in [0,1], max(a+b, 0) =
+   # fsat(a+b).
    #
-   # If a > b, then b-a < 0 and max(b-a, 0) = fsat(b-a) = 0
+   # If a < -b, then a+b < 0 and max(a+b, 0) = fsat(a+b) = 0
    #
    # This should be NaN safe since max(NaN, 0) = fsat(NaN) = 0.
-   (('fmax', ('fadd(is_used_once)', ('fneg', 'a(is_not_negative)'), '#b(is_zero_to_one)'), 0.0),
-    ('fsat', ('fadd', ('fneg',  a), b)), '!options->lower_fsat'),
+   (('fmax', ('fadd(is_used_once)', 'a(is_not_positive)', '#b(is_zero_to_one)'), 0.0),
+    ('fsat', ('fadd', a, b)), '!options->lower_fsat'),
+
+   # ffma variants of the pattern above.
+   (('fmax', ('ffma(is_used_once)', 'a(is_not_positive)', 'b(is_not_negative)', '#c(is_zero_to_one)'), 0.0),
+    ('fsat', ('ffma', a, b, c)), '!options->lower_fsat'),
+   (('fmax', ('ffma(is_used_once)', 'a', ('fneg', a), '#b(is_zero_to_one)'), 0.0),
+    ('fsat', ('ffma', a, ('fneg', a), b)), '!options->lower_fsat'),
 
    (('extract_u8', ('imin', ('imax', a, 0), 0xff), 0), ('imin', ('imax', a, 0), 0xff)),
 
@@ -1450,6 +1456,11 @@ optimizations.extend([
    (('fany_nequal4', a, b), ('fsat', ('fdot4', ('sne', a, b), ('sne', a, b))), 'options->lower_vector_cmp'),
    (('fany_nequal8', a, b), ('fsat', ('fdot8', ('sne', a, b), ('sne', a, b))), 'options->lower_vector_cmp'),
    (('fany_nequal16', a, b), ('fsat', ('fdot16', ('sne', a, b), ('sne', a, b))), 'options->lower_vector_cmp'),
+
+   # Vulkan allows us to use any rounding mode, so choose rtz because it's simple.
+   # Avoid some NaNs being converted to Inf if the lsb are cut off.
+   (('f2bf', a), ('bcsel', ('!fneu', a, a), -1, ('unpack_32_2x16_split_y', a)), 'options->lower_bfloat16_conversions'),
+   (('bf2f', a), ('pack_32_2x16', ('vec2', 0, a)), 'options->lower_bfloat16_conversions'),
 ])
 
 def vector_cmp(reduce_op, cmp_op, comps):
@@ -1870,6 +1881,7 @@ optimizations.extend([
    (('fsat', 'a(is_not_positive)'), 0.0),
 
    (('~fmin', 'a(is_not_negative)', 1.0), ('fsat', a), '!options->lower_fsat'),
+   (('fmin', 'a(is_a_number_not_negative)', 1.0), ('fsat', a), '!options->lower_fsat'),
 
    # The result of the multiply must be in [-1, 0], so the result of the ffma
    # must be in [0, 1].
diff --git a/src/compiler/nir/nir_opt_shrink_vectors.c b/src/compiler/nir/nir_opt_shrink_vectors.c
index 651fe0b81ab..84f8600a101 100644
--- a/src/compiler/nir/nir_opt_shrink_vectors.c
+++ b/src/compiler/nir/nir_opt_shrink_vectors.c
@@ -320,6 +320,7 @@ opt_shrink_vectors_intrinsic(nir_builder *b, nir_intrinsic_instr *instr,
    switch (instr->intrinsic) {
    case nir_intrinsic_load_uniform:
    case nir_intrinsic_load_ubo:
+   case nir_intrinsic_load_ubo_vec4:
    case nir_intrinsic_load_input:
    case nir_intrinsic_load_per_primitive_input:
    case nir_intrinsic_load_input_vertex:
diff --git a/src/compiler/nir/nir_opt_varyings.c b/src/compiler/nir/nir_opt_varyings.c
index 89cc67b6e03..edbadc164b7 100644
--- a/src/compiler/nir/nir_opt_varyings.c
+++ b/src/compiler/nir/nir_opt_varyings.c
@@ -657,6 +657,7 @@ struct linkage_info {
    bool can_mix_convergent_flat_with_interpolated;
    bool has_flexible_interp;
    bool always_interpolate_convergent_fs_inputs;
+   bool group_tes_inputs_into_pos_var_groups;
 
    gl_shader_stage producer_stage;
    gl_shader_stage consumer_stage;
@@ -4973,9 +4974,62 @@ compact_varyings(struct linkage_info *linkage,
    if (linkage->consumer_stage == MESA_SHADER_TESS_EVAL) {
       unsigned patch_slot_index = VARYING_SLOT_PATCH0 * 8;
 
-      vs_tcs_tes_gs_assign_slots_2sets(linkage, linkage->flat32_mask,
-                                       linkage->flat16_mask, &slot_index,
-                                       &patch_slot_index, progress);
+      if (linkage->group_tes_inputs_into_pos_var_groups) {
+         /* TES inputs are divided into 3 groups:
+          * - those that only determine POS and CLIP outputs of TES
+          * - those that determine both POS/CLIP outputs and other outputs of TES
+          * - those that only determine all other outputs of TES
+          *
+          * TES inputs from each group are grouped together.
+          * This should be gathered after inter-shader code motion.
+          */
+         nir_output_clipper_var_groups tes_masks32, tes_masks16;
+
+         /* Required by nir_gather_output_clipper_var_groups: */
+         NIR_PASS(_, linkage->consumer_builder.shader, nir_convert_to_lcssa, true, true);
+         nir_gather_output_clipper_var_groups(linkage->consumer_builder.shader,
+                                              &tes_masks32);
+         memcpy(&tes_masks16, &tes_masks32, sizeof(tes_masks16));
+
+         /* Reduce the masks to only contain 32-bit or 16-bit inputs. */
+         BITSET_AND(tes_masks32.pos_only, tes_masks32.pos_only, linkage->flat32_mask);
+         BITSET_AND(tes_masks32.both, tes_masks32.both, linkage->flat32_mask);
+         BITSET_AND(tes_masks32.var_only, tes_masks32.var_only, linkage->flat32_mask);
+
+         BITSET_AND(tes_masks16.pos_only, tes_masks16.pos_only, linkage->flat16_mask);
+         BITSET_AND(tes_masks16.both, tes_masks16.both, linkage->flat16_mask);
+         BITSET_AND(tes_masks16.var_only, tes_masks16.var_only, linkage->flat16_mask);
+
+         /* Reduce flat masks to only contain inputs not used by any outputs.
+          * Such inputs can only be used by memory stores. Then add the flat
+          * masks to var_only.
+          */
+         BITSET_ANDNOT(linkage->flat32_mask, linkage->flat32_mask, tes_masks32.pos_only);
+         BITSET_ANDNOT(linkage->flat32_mask, linkage->flat32_mask, tes_masks32.both);
+         BITSET_ANDNOT(linkage->flat32_mask, linkage->flat32_mask, tes_masks32.var_only);
+
+         BITSET_ANDNOT(linkage->flat16_mask, linkage->flat16_mask, tes_masks16.pos_only);
+         BITSET_ANDNOT(linkage->flat16_mask, linkage->flat16_mask, tes_masks16.both);
+         BITSET_ANDNOT(linkage->flat16_mask, linkage->flat16_mask, tes_masks16.var_only);
+
+         BITSET_OR(tes_masks32.var_only, tes_masks32.var_only, linkage->flat32_mask);
+         BITSET_OR(tes_masks16.var_only, tes_masks16.var_only, linkage->flat16_mask);
+
+         /* The "both" group should be between the other two. */
+         vs_tcs_tes_gs_assign_slots_2sets(linkage, tes_masks32.pos_only,
+                                          tes_masks16.pos_only, &slot_index,
+                                          &patch_slot_index, progress);
+         vs_tcs_tes_gs_assign_slots_2sets(linkage, tes_masks32.both,
+                                          tes_masks16.both, &slot_index,
+                                          &patch_slot_index, progress);
+         vs_tcs_tes_gs_assign_slots_2sets(linkage, tes_masks32.var_only,
+                                          tes_masks16.var_only, &slot_index,
+                                          &patch_slot_index, progress);
+      } else {
+         vs_tcs_tes_gs_assign_slots_2sets(linkage, linkage->flat32_mask,
+                                          linkage->flat16_mask, &slot_index,
+                                          &patch_slot_index, progress);
+      }
 
       /* Put no-varying slots last. These are TCS outputs read by TCS but
        * not TES.
@@ -5150,6 +5204,10 @@ init_linkage(nir_shader *producer, nir_shader *consumer, bool spirv,
          consumer->info.stage == MESA_SHADER_FRAGMENT &&
          consumer->options->io_options &
             nir_io_always_interpolate_convergent_fs_inputs,
+      .group_tes_inputs_into_pos_var_groups =
+         consumer->info.stage == MESA_SHADER_TESS_EVAL &&
+         consumer->options->io_options &
+         nir_io_compaction_groups_tes_inputs_into_pos_and_var_groups,
       .producer_stage = producer->info.stage,
       .consumer_stage = consumer->info.stage,
       .producer_builder =
diff --git a/src/compiler/nir/nir_range_analysis.c b/src/compiler/nir/nir_range_analysis.c
index 4761e493b02..c1e3e1bcd80 100644
--- a/src/compiler/nir/nir_range_analysis.c
+++ b/src/compiler/nir/nir_range_analysis.c
@@ -527,6 +527,43 @@ get_fp_key(struct analysis_query *q)
    return ptr | type_encoding;
 }
 
+static inline bool
+fmul_is_a_number(const struct ssa_result_range left, const struct ssa_result_range right, bool mulz)
+{
+   if (mulz) {
+      /* nir_op_fmulz: unlike nir_op_fmul, 0 * Â±Inf is a number. */
+      return left.is_a_number && right.is_a_number;
+   } else {
+      /* Mulitpliation produces NaN for X * NaN and for 0 * Â±Inf.  If both
+       * operands are numbers and either both are finite or one is finite and
+       * the other cannot be zero, then the result must be a number.
+       */
+      return  (left.is_a_number && right.is_a_number) &&
+               ((left.is_finite && right.is_finite) ||
+                (!is_not_zero(left.range) && right.is_finite) ||
+                (left.is_finite && !is_not_zero(right.range)));
+   }
+}
+
+static inline bool
+fadd_is_a_number(const struct ssa_result_range left, const struct ssa_result_range right)
+{
+   /* X + Y is NaN if either operand is NaN or if one operand is +Inf and
+    * the other is -Inf.  If neither operand is NaN and at least one of the
+    * operands is finite, then the result cannot be NaN.
+    * If the combined range doesn't contain both postive and negative values
+    * (including Infs) then the result cannot be NaN either.
+    */
+   enum ssa_ranges combined_range = union_ranges(left.range, right.range);
+   return left.is_a_number && right.is_a_number &&
+          (left.is_finite || right.is_finite ||
+           combined_range == eq_zero ||
+           combined_range == gt_zero ||
+           combined_range == ge_zero ||
+           combined_range == lt_zero ||
+           combined_range == le_zero);
+}
+
 /**
  * Analyze an expression to determine the range of its result
  *
@@ -625,6 +662,7 @@ process_fp_query(struct analysis_state *state, struct analysis_query *aq, uint32
          push_fp_query(state, alu, 1, nir_type_invalid);
          return;
       case nir_op_ffma:
+      case nir_op_ffmaz:
       case nir_op_flrp:
          push_fp_query(state, alu, 0, nir_type_invalid);
          push_fp_query(state, alu, 1, nir_type_invalid);
@@ -813,13 +851,7 @@ process_fp_query(struct analysis_state *state, struct analysis_query *aq, uint32
 
       r.is_integral = left.is_integral && right.is_integral;
       r.range = fadd_table[left.range][right.range];
-
-      /* X + Y is NaN if either operand is NaN or if one operand is +Inf and
-       * the other is -Inf.  If neither operand is NaN and at least one of the
-       * operands is finite, then the result cannot be NaN.
-       */
-      r.is_a_number = left.is_a_number && right.is_a_number &&
-                      (left.is_finite || right.is_finite);
+      r.is_a_number = fadd_is_a_number(left, right);
       break;
    }
 
@@ -1031,23 +1063,12 @@ process_fp_query(struct analysis_state *state, struct analysis_query *aq, uint32
       } else if (left.range != eq_zero && nir_alu_srcs_negative_equal(alu, alu, 0, 1)) {
          /* -x * x => le_zero. */
          r.range = le_zero;
-      } else
-         r.range = fmul_table[left.range][right.range];
-
-      if (alu->op == nir_op_fmul) {
-         /* Mulitpliation produces NaN for X * NaN and for 0 * Â±Inf.  If both
-          * operands are numbers and either both are finite or one is finite and
-          * the other cannot be zero, then the result must be a number.
-          */
-         r.is_a_number = (left.is_a_number && right.is_a_number) &&
-                         ((left.is_finite && right.is_finite) ||
-                          (!is_not_zero(left.range) && right.is_finite) ||
-                          (left.is_finite && !is_not_zero(right.range)));
       } else {
-         /* nir_op_fmulz: unlike nir_op_fmul, 0 * Â±Inf is a number. */
-         r.is_a_number = left.is_a_number && right.is_a_number;
+         r.range = fmul_table[left.range][right.range];
       }
 
+      r.is_a_number = fmul_is_a_number(left, right, alu->op == nir_op_fmulz);
+
       break;
    }
 
@@ -1352,31 +1373,31 @@ process_fp_query(struct analysis_state *state, struct analysis_query *aq, uint32
       break;
    }
 
-   case nir_op_ffma: {
+   case nir_op_ffma:
+   case nir_op_ffmaz: {
       const struct ssa_result_range first = unpack_data(src_res[0]);
       const struct ssa_result_range second = unpack_data(src_res[1]);
       const struct ssa_result_range third = unpack_data(src_res[2]);
 
-      r.is_integral = first.is_integral && second.is_integral &&
-                      third.is_integral;
-
-      /* Various cases can result in NaN, so assume the worst. */
-      r.is_a_number = false;
-
-      enum ssa_ranges fmul_range;
+      struct ssa_result_range fmul_result;
+      fmul_result.is_integral = first.is_integral && second.is_integral;
+      fmul_result.is_finite = false;
+      fmul_result.is_a_number = fmul_is_a_number(first, third, alu->op == nir_op_ffmaz);
 
       if (first.range != eq_zero && nir_alu_srcs_equal(alu, alu, 0, 1)) {
          /* See handling of nir_op_fmul for explanation of why ge_zero is the
           * range.
           */
-         fmul_range = ge_zero;
+         fmul_result.range = ge_zero;
       } else if (first.range != eq_zero && nir_alu_srcs_negative_equal(alu, alu, 0, 1)) {
          /* -x * x => le_zero */
-         fmul_range = le_zero;
+         fmul_result.range = le_zero;
       } else
-         fmul_range = fmul_table[first.range][second.range];
+         fmul_result.range = fmul_table[first.range][second.range];
 
-      r.range = fadd_table[fmul_range][third.range];
+      r.range = fadd_table[fmul_result.range][third.range];
+      r.is_integral = fmul_result.is_integral && third.is_integral;
+      r.is_a_number = fadd_is_a_number(fmul_result, third);
       break;
    }
 
diff --git a/src/compiler/nir/nir_shader_compiler_options.h b/src/compiler/nir/nir_shader_compiler_options.h
index 483031ee6ca..d35969982b9 100644
--- a/src/compiler/nir/nir_shader_compiler_options.h
+++ b/src/compiler/nir/nir_shader_compiler_options.h
@@ -170,6 +170,14 @@ typedef enum {
     */
    nir_io_compaction_rotates_color_channels = BITFIELD_BIT(8),
 
+   /**
+    * Whether to group TES inputs as follows:
+    * - inputs used to compute only POS/CLIP outputs are first
+    * - inputs used to compute both POS/CLIP outputs and other outputs are next
+    * - inputs used to compute only other outputs are last
+    */
+   nir_io_compaction_groups_tes_inputs_into_pos_and_var_groups = BITFIELD_BIT(9),
+
    /* Options affecting the GLSL compiler or Gallium are below. */
 
    /**
@@ -451,6 +459,11 @@ typedef struct nir_shader_compiler_options {
     */
    bool lower_mul_32x16;
 
+   /**
+    * Set if bf2f and f2bf should be lowered to arithmetic
+    */
+   bool lower_bfloat16_conversions;
+
    bool vectorize_tess_levels;
    bool lower_to_scalar;
    nir_instr_filter_cb lower_to_scalar_filter;
@@ -573,6 +586,9 @@ typedef struct nir_shader_compiler_options {
    /** Backend supports sdot_2x16 and udot_2x16 opcodes. */
    bool has_dot_2x16;
 
+   /** Backend supports bfdot2_bfadd opcode. */
+   bool has_bfdot2_bfadd;
+
    /** Backend supports fmulz (and ffmaz if lower_ffma32=false) */
    bool has_fmulz;
 
diff --git a/src/compiler/spirv/spirv_to_nir.c b/src/compiler/spirv/spirv_to_nir.c
index 31e74339c2c..a8da4ba9683 100644
--- a/src/compiler/spirv/spirv_to_nir.c
+++ b/src/compiler/spirv/spirv_to_nir.c
@@ -40,6 +40,7 @@
 #include "util/u_debug.h"
 #include "util/u_printf.h"
 #include "util/mesa-blake3.h"
+#include "util/bfloat.h"
 
 #include <stdio.h>
 
@@ -58,6 +59,9 @@ static const struct spirv_capabilities implemented_capabilities = {
    .AtomicFloat32MinMaxEXT = true,
    .AtomicFloat64MinMaxEXT = true,
    .AtomicStorage = true,
+   .BFloat16CooperativeMatrixKHR = true,
+   .BFloat16DotProductKHR = true,
+   .BFloat16TypeKHR = true,
    .ClipDistance = true,
    .ComputeDerivativeGroupLinearKHR = true,
    .ComputeDerivativeGroupQuadsKHR = true,
@@ -1886,10 +1890,30 @@ vtn_handle_type(struct vtn_builder *b, SpvOp opcode,
    case SpvOpTypeFloat: {
       int bit_size = w[2];
       val->type->base_type = vtn_base_type_scalar;
-      vtn_fail_if(bit_size != 16 && bit_size != 32 && bit_size != 64,
-                  "Invalid float bit size: %u", bit_size);
-      val->type->type = glsl_floatN_t_type(bit_size);
       val->type->length = 1;
+
+      int32_t encoding = count > 3 ? w[3] : -1;
+      switch (encoding) {
+      case -1:
+         if (bit_size == 8) {
+           val->type->type = glsl_e4m3fn_t_type();
+         } else {
+            /* No encoding specified, it is a regular FP. */
+            vtn_fail_if(bit_size != 16 && bit_size != 32 && bit_size != 64,
+                     "Invalid float bit size: %u", bit_size);
+            val->type->type = glsl_floatN_t_type(bit_size);
+         }
+         break;
+
+      case SpvFPEncodingBFloat16KHR:
+         vtn_fail_if(bit_size != 16,
+                     "Invalid Bfloat16 bit size: %u", bit_size);
+         val->type->type = glsl_bfloatN_t_type(bit_size);
+         break;
+
+      default:
+         vtn_fail("Unsupported OpTypeFloat encoding: %d", encoding);
+      }
       break;
    }
 
@@ -2677,8 +2701,16 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
 
       default: {
          bool swap;
-         nir_alu_type dst_alu_type = nir_get_nir_type_for_glsl_type(val->type->type);
-         nir_alu_type src_alu_type = dst_alu_type;
+
+         const glsl_type *dst_type = val->type->type;
+         const glsl_type *src_type = dst_type;
+
+         const bool bfloat_dst = glsl_type_is_bfloat_16(dst_type);
+         bool bfloat_src = bfloat_dst;
+
+         if (bfloat_dst)
+            dst_type = glsl_float_type();
+
          unsigned num_components = glsl_get_vector_elements(val->type->type);
 
          vtn_assert(count <= 7);
@@ -2686,26 +2718,28 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
          switch (opcode) {
          case SpvOpSConvert:
          case SpvOpFConvert:
-         case SpvOpUConvert:
+         case SpvOpUConvert: {
             /* We have a different source type in a conversion. */
-            src_alu_type =
-               nir_get_nir_type_for_glsl_type(vtn_get_value_type(b, w[4])->type);
+            src_type = vtn_get_value_type(b, w[4])->type;
+            bfloat_src = glsl_type_is_bfloat_16(src_type);
+            if (bfloat_src)
+               src_type = glsl_float_type();
             break;
+         }
          default:
             break;
          };
 
          bool exact;
          nir_op op = vtn_nir_alu_op_for_spirv_opcode(b, opcode, &swap, &exact,
-                                                     nir_alu_type_get_type_size(src_alu_type),
-                                                     nir_alu_type_get_type_size(dst_alu_type));
+                                                     src_type, dst_type);
 
          /* No SPIR-V opcodes handled through this path should set exact.
           * Since it is ignored, assert on it.
           */
          assert(!exact);
 
-         unsigned bit_size = glsl_get_bit_size(val->type->type);
+         unsigned bit_size = glsl_get_bit_size(src_type);
          nir_const_value src[3][NIR_MAX_VEC_COMPONENTS];
 
          for (unsigned i = 0; i < count - 4; i++) {
@@ -2723,8 +2757,11 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
                                  num_components;
 
             unsigned j = swap ? 1 - i : i;
-            for (unsigned c = 0; c < src_comps; c++)
+            for (unsigned c = 0; c < src_comps; c++) {
                src[j][c] = src_val->constant->values[c];
+               if (bfloat_src)
+                  src[j][c].f32 = _mesa_bfloat16_bits_to_float(src[j][c].u16);
+            }
          }
 
          /* fix up fixed size sources */
@@ -2753,6 +2790,16 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
          nir_eval_const_opcode(op, val->constant->values,
                                num_components, bit_size, srcs,
                                b->shader->info.float_controls_execution_mode);
+
+         if (bfloat_dst) {
+            for (int i = 0; i < num_components; i++) {
+               /* Ensure the pad bits are zeroed by fully assigning the value. */
+               const uint16_t b =
+                  _mesa_float_to_bfloat16_bits_rte(val->constant->values[i].f32);
+               val->constant->values[i] = (nir_const_value){ .u16 = b };
+            }
+         }
+
          break;
       } /* default */
       }
@@ -7189,26 +7236,6 @@ spirv_to_nir(const uint32_t *words, size_t word_count,
     */
    nir_opt_dce(b->shader);
 
-   /* Per SPV_KHR_workgroup_storage_explicit_layout, if one shared variable is
-    * a Block, all of them will be and Blocks are explicitly laid out.
-    */
-   nir_foreach_variable_with_modes(var, b->shader, nir_var_mem_shared) {
-      if (glsl_type_is_interface(var->type)) {
-         assert(b->supported_capabilities.WorkgroupMemoryExplicitLayoutKHR);
-         b->shader->info.shared_memory_explicit_layout = true;
-         break;
-      }
-   }
-   if (b->shader->info.shared_memory_explicit_layout) {
-      unsigned size = 0;
-      nir_foreach_variable_with_modes(var, b->shader, nir_var_mem_shared) {
-         assert(glsl_type_is_interface(var->type));
-         const bool align_to_stride = false;
-         size = MAX2(size, glsl_get_explicit_size(var->type, align_to_stride));
-      }
-      b->shader->info.shared_size = size;
-   }
-
    if (stage == MESA_SHADER_FRAGMENT) {
       /* From the Vulkan 1.2.199 spec:
        *
diff --git a/src/compiler/spirv/vtn_alu.c b/src/compiler/spirv/vtn_alu.c
index 94c41c710ca..a89d9b2ad9e 100644
--- a/src/compiler/spirv/vtn_alu.c
+++ b/src/compiler/spirv/vtn_alu.c
@@ -235,8 +235,8 @@ vtn_handle_matrix_alu(struct vtn_builder *b, SpvOp opcode,
    }
 }
 
-static nir_alu_type
-convert_op_src_type(SpvOp opcode)
+nir_alu_type
+vtn_convert_op_src_type(SpvOp opcode)
 {
    switch (opcode) {
    case SpvOpFConvert:
@@ -256,8 +256,8 @@ convert_op_src_type(SpvOp opcode)
    }
 }
 
-static nir_alu_type
-convert_op_dst_type(SpvOp opcode)
+nir_alu_type
+vtn_convert_op_dst_type(SpvOp opcode)
 {
    switch (opcode) {
    case SpvOpFConvert:
@@ -280,8 +280,12 @@ convert_op_dst_type(SpvOp opcode)
 nir_op
 vtn_nir_alu_op_for_spirv_opcode(struct vtn_builder *b,
                                 SpvOp opcode, bool *swap, bool *exact,
-                                unsigned src_bit_size, unsigned dst_bit_size)
+                                const glsl_type *src_type,
+                                const glsl_type *dst_type)
 {
+   const unsigned src_bit_size = glsl_get_bit_size(src_type);
+   const unsigned dst_bit_size = glsl_get_bit_size(dst_type);
+
    /* Indicates that the first two arguments should be swapped.  This is
     * used for implementing greater-than and less-than-or-equal.
     */
@@ -378,8 +382,8 @@ vtn_nir_alu_op_for_spirv_opcode(struct vtn_builder *b,
    case SpvOpConvertUToF:
    case SpvOpSConvert:
    case SpvOpFConvert: {
-      nir_alu_type src_type = convert_op_src_type(opcode) | src_bit_size;
-      nir_alu_type dst_type = convert_op_dst_type(opcode) | dst_bit_size;
+      nir_alu_type src_type = vtn_convert_op_src_type(opcode) | src_bit_size;
+      nir_alu_type dst_type = vtn_convert_op_dst_type(opcode) | dst_bit_size;
       return nir_type_conversion_op(src_type, dst_type, nir_rounding_mode_undef);
    }
 
@@ -660,6 +664,96 @@ vtn_handle_deriv(struct vtn_builder *b, SpvOp opcode, nir_def *src)
    }
 }
 
+static nir_def *
+vtn_handle_convert(struct vtn_builder *b, SpvOp opcode,
+                   struct vtn_value *dest_val,
+                   const struct glsl_type *glsl_dest_type,
+                   const struct glsl_type *glsl_src_type,
+                   nir_def *src)
+{
+   /* From SPV_KHR_bfloat16 extension:
+    *
+    *     Conversions to or from floating-point values with the `BFloat16KHR`
+    *     encoding first convert the source value to IEEE754 binary32, and then
+    *     from IEEE754 binary32 to the target format.
+    *
+    * For now we are limiting exposure of bfloat16 in NIR, so apply the
+    * extra conversions directly here.
+    */
+   if (glsl_type_is_bfloat_16(glsl_src_type)) {
+      nir_def *src_as_float = nir_bf2f(&b->nb, src);
+      if (glsl_type_is_float(glsl_dest_type))
+         return src_as_float;
+      return vtn_handle_convert(b, opcode, dest_val, glsl_dest_type,
+                                glsl_float_type(), src_as_float);
+
+   } else if (glsl_type_is_bfloat_16(glsl_dest_type)) {
+      nir_def *src_as_float;
+      if (glsl_type_is_float(glsl_src_type))
+         src_as_float = src;
+      else
+         src_as_float = vtn_handle_convert(b, opcode, dest_val, glsl_float_type(),
+                                           glsl_src_type, src);
+      return nir_f2bf(&b->nb, src_as_float);
+   }
+
+   if (glsl_type_is_e4m3fn(glsl_src_type)) {
+      nir_def *src_as_float = nir_e4m3fn2f(&b->nb, src);
+      if (glsl_type_is_float(glsl_dest_type))
+         return src_as_float;
+      return vtn_handle_convert(b, opcode, dest_val, glsl_dest_type,
+                                glsl_float_type(), src_as_float);
+
+   } else if (glsl_type_is_e4m3fn(glsl_dest_type)) {
+      nir_def *src_as_float;
+      if (glsl_type_is_float(glsl_src_type))
+         src_as_float = src;
+      else
+         src_as_float = vtn_handle_convert(b, opcode, dest_val, glsl_float_type(),
+                                           glsl_src_type, src);
+      return nir_f2e4m3fn(&b->nb, src_as_float);
+   }
+
+   /* Use bit_size from NIR source instead of from the original src type,
+    * to account for mediump_16bit.  See vtn_handle_alu() for details.
+    */
+   unsigned src_bit_size = src->bit_size;
+   unsigned dst_bit_size = glsl_get_bit_size(glsl_dest_type);
+   nir_alu_type src_type = vtn_convert_op_src_type(opcode) | src_bit_size;
+   nir_alu_type dst_type = vtn_convert_op_dst_type(opcode) | dst_bit_size;
+
+   struct conversion_opts opts = {
+      .rounding_mode = nir_rounding_mode_undef,
+      .saturate = false,
+   };
+   vtn_foreach_decoration(b, dest_val, handle_conversion_opts, &opts);
+
+   if (opcode == SpvOpSatConvertSToU || opcode == SpvOpSatConvertUToS)
+      opts.saturate = true;
+
+   nir_def *result;
+
+   if (b->shader->info.stage == MESA_SHADER_KERNEL) {
+      if (opts.rounding_mode == nir_rounding_mode_undef && !opts.saturate) {
+         result = nir_type_convert(&b->nb, src, src_type, dst_type,
+                                   nir_rounding_mode_undef);
+      } else {
+         result = nir_convert_alu_types(&b->nb, dst_bit_size, src,
+                                        src_type, dst_type,
+                                        opts.rounding_mode, opts.saturate);
+      }
+   } else {
+      vtn_fail_if(opts.rounding_mode != nir_rounding_mode_undef &&
+                  dst_type != nir_type_float16,
+                  "Rounding modes are only allowed on conversions to "
+                  "16-bit float types");
+      result = nir_type_convert(&b->nb, src, src_type, dst_type,
+                                opts.rounding_mode);
+   }
+
+   return result;
+}
+
 void
 vtn_handle_alu(struct vtn_builder *b, SpvOp opcode,
                const uint32_t *w, unsigned count)
@@ -722,7 +816,9 @@ vtn_handle_alu(struct vtn_builder *b, SpvOp opcode,
    }
 
    case SpvOpDot:
-      dest->def = nir_fdot(&b->nb, src[0], src[1]);
+      dest->def = glsl_type_is_bfloat_16(dest_type) ?
+         nir_bfdot(&b->nb, src[0], src[1]) :
+         nir_fdot(&b->nb, src[0], src[1]);
       break;
 
    case SpvOpIAddCarry:
@@ -844,11 +940,9 @@ vtn_handle_alu(struct vtn_builder *b, SpvOp opcode,
    case SpvOpFUnordGreaterThanEqual: {
       bool swap;
       bool unused_exact;
-      unsigned src_bit_size = glsl_get_bit_size(vtn_src[0]->type);
-      unsigned dst_bit_size = glsl_get_bit_size(dest_type);
       nir_op op = vtn_nir_alu_op_for_spirv_opcode(b, opcode, &swap,
                                                   &unused_exact,
-                                                  src_bit_size, dst_bit_size);
+                                                  vtn_src[0]->type, dest_type);
 
       if (swap) {
          nir_def *tmp = src[0];
@@ -911,40 +1005,10 @@ vtn_handle_alu(struct vtn_builder *b, SpvOp opcode,
    case SpvOpSConvert:
    case SpvOpFConvert:
    case SpvOpSatConvertSToU:
-   case SpvOpSatConvertUToS: {
-      unsigned src_bit_size = src[0]->bit_size;
-      unsigned dst_bit_size = glsl_get_bit_size(dest_type);
-      nir_alu_type src_type = convert_op_src_type(opcode) | src_bit_size;
-      nir_alu_type dst_type = convert_op_dst_type(opcode) | dst_bit_size;
-
-      struct conversion_opts opts = {
-         .rounding_mode = nir_rounding_mode_undef,
-         .saturate = false,
-      };
-      vtn_foreach_decoration(b, dest_val, handle_conversion_opts, &opts);
-
-      if (opcode == SpvOpSatConvertSToU || opcode == SpvOpSatConvertUToS)
-         opts.saturate = true;
-
-      if (b->shader->info.stage == MESA_SHADER_KERNEL) {
-         if (opts.rounding_mode == nir_rounding_mode_undef && !opts.saturate) {
-            dest->def = nir_type_convert(&b->nb, src[0], src_type, dst_type,
-                                         nir_rounding_mode_undef);
-         } else {
-            dest->def = nir_convert_alu_types(&b->nb, dst_bit_size, src[0],
-                                              src_type, dst_type,
-                                              opts.rounding_mode, opts.saturate);
-         }
-      } else {
-         vtn_fail_if(opts.rounding_mode != nir_rounding_mode_undef &&
-                     dst_type != nir_type_float16,
-                     "Rounding modes are only allowed on conversions to "
-                     "16-bit float types");
-         dest->def = nir_type_convert(&b->nb, src[0], src_type, dst_type,
-                                      opts.rounding_mode);
-      }
+   case SpvOpSatConvertUToS:
+      dest->def = vtn_handle_convert(b, opcode, dest_val, dest_type,
+                                     vtn_src[0]->type, src[0]);
       break;
-   }
 
    case SpvOpBitFieldInsert:
    case SpvOpBitFieldSExtract:
@@ -954,10 +1018,8 @@ vtn_handle_alu(struct vtn_builder *b, SpvOp opcode,
    case SpvOpShiftRightLogical: {
       bool swap;
       bool exact;
-      unsigned src0_bit_size = glsl_get_bit_size(vtn_src[0]->type);
-      unsigned dst_bit_size = glsl_get_bit_size(dest_type);
       nir_op op = vtn_nir_alu_op_for_spirv_opcode(b, opcode, &swap, &exact,
-                                                  src0_bit_size, dst_bit_size);
+                                                  vtn_src[0]->type, dest_type);
 
       assert(!exact);
 
@@ -1014,11 +1076,9 @@ vtn_handle_alu(struct vtn_builder *b, SpvOp opcode,
    default: {
       bool swap;
       bool exact;
-      unsigned src_bit_size = glsl_get_bit_size(vtn_src[0]->type);
-      unsigned dst_bit_size = glsl_get_bit_size(dest_type);
       nir_op op = vtn_nir_alu_op_for_spirv_opcode(b, opcode, &swap,
                                                   &exact,
-                                                  src_bit_size, dst_bit_size);
+                                                  vtn_src[0]->type, dest_type);
 
       if (swap) {
          nir_def *tmp = src[0];
diff --git a/src/compiler/spirv/vtn_cmat.c b/src/compiler/spirv/vtn_cmat.c
index e9744d0313a..746c58e2eea 100644
--- a/src/compiler/spirv/vtn_cmat.c
+++ b/src/compiler/spirv/vtn_cmat.c
@@ -198,18 +198,35 @@ vtn_handle_cooperative_alu(struct vtn_builder *b, struct vtn_value *dest_val,
       case SpvOpConvertUToF:
       case SpvOpUConvert:
       case SpvOpSConvert:
-      case SpvOpFConvert:
+      case SpvOpFConvert: {
+         struct vtn_type *dst_type = vtn_get_type(b, w[1]);
+         nir_deref_instr *src = vtn_get_cmat_deref(b, w[3]);
+
+         /* The Convert operations define whether integers are interpreted
+          * as signed or unsigned regardless of their original type.  So take
+          * note of that in the intrinsic.  Reuse nir_cmat_signed for that.
+          */
+         const unsigned signed_mask =
+            (vtn_convert_op_src_type(opcode) == nir_type_int ? NIR_CMAT_A_SIGNED : 0) |
+            (vtn_convert_op_dst_type(opcode) == nir_type_int ? NIR_CMAT_RESULT_SIGNED : 0);
+
+
+         nir_deref_instr *dst = vtn_create_cmat_temporary(b, dst_type->type, "cmat_convert");
+         nir_cmat_convert(&b->nb, &dst->def, &src->def, .cmat_signed_mask = signed_mask);
+         vtn_push_var_ssa(b, w[2], dst->var);
+
+         break;
+      }
+
       case SpvOpFNegate:
       case SpvOpSNegate: {
          struct vtn_type *dst_type = vtn_get_type(b, w[1]);
          nir_deref_instr *src = vtn_get_cmat_deref(b, w[3]);
 
-         unsigned src_bit_size = glsl_get_bit_size(glsl_get_cmat_element(src->type));
-         unsigned dst_bit_size = glsl_get_bit_size(glsl_get_cmat_element(dst_type->type));
-
          bool ignored = false;
          nir_op op = vtn_nir_alu_op_for_spirv_opcode(b, opcode, &ignored, &ignored,
-                                                     src_bit_size, dst_bit_size);
+                                                     glsl_get_cmat_element(src->type),
+                                                     glsl_get_cmat_element(dst_type->type));
 
          nir_deref_instr *dst = vtn_create_cmat_temporary(b, dst_type->type, "cmat_unary");
          nir_cmat_unary_op(&b->nb, &dst->def, &src->def,
@@ -228,12 +245,15 @@ vtn_handle_cooperative_alu(struct vtn_builder *b, struct vtn_value *dest_val,
       case SpvOpSDiv:
       case SpvOpUDiv: {
          bool ignored = false;
-         nir_op op = vtn_nir_alu_op_for_spirv_opcode(b, opcode, &ignored, &ignored, 0, 0);
 
          struct vtn_type *dst_type = vtn_get_type(b, w[1]);
          nir_deref_instr *mat_a = vtn_get_cmat_deref(b, w[3]);
          nir_deref_instr *mat_b = vtn_get_cmat_deref(b, w[4]);
 
+         nir_op op = vtn_nir_alu_op_for_spirv_opcode(b, opcode, &ignored, &ignored,
+                                                     glsl_get_cmat_element(mat_a->type),
+                                                     glsl_get_cmat_element(dst_type->type));
+
          nir_deref_instr *dst = vtn_create_cmat_temporary(b, dst_type->type, "cmat_binary");
          nir_cmat_binary_op(&b->nb, &dst->def, &mat_a->def, &mat_b->def,
                             .alu_op = op);
diff --git a/src/compiler/spirv/vtn_private.h b/src/compiler/spirv/vtn_private.h
index 7a0c5013759..3b83618778c 100644
--- a/src/compiler/spirv/vtn_private.h
+++ b/src/compiler/spirv/vtn_private.h
@@ -954,9 +954,13 @@ typedef void (*vtn_execution_mode_foreach_cb)(struct vtn_builder *,
 void vtn_foreach_execution_mode(struct vtn_builder *b, struct vtn_value *value,
                                 vtn_execution_mode_foreach_cb cb, void *data);
 
+nir_alu_type vtn_convert_op_src_type(SpvOp opcode);
+nir_alu_type vtn_convert_op_dst_type(SpvOp opcode);
+
 nir_op vtn_nir_alu_op_for_spirv_opcode(struct vtn_builder *b,
                                        SpvOp opcode, bool *swap, bool *exact,
-                                       unsigned src_bit_size, unsigned dst_bit_size);
+                                       const glsl_type *src_type,
+                                       const glsl_type *dst_type);
 
 void vtn_handle_alu(struct vtn_builder *b, SpvOp opcode,
                     const uint32_t *w, unsigned count);
diff --git a/src/compiler/spirv/vtn_variables.c b/src/compiler/spirv/vtn_variables.c
index 372942cc895..c474ea9a81c 100644
--- a/src/compiler/spirv/vtn_variables.c
+++ b/src/compiler/spirv/vtn_variables.c
@@ -716,6 +716,8 @@ _vtn_variable_load_store(struct vtn_builder *b, bool load,
    case GLSL_TYPE_INT64:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_BFLOAT16:
    case GLSL_TYPE_BOOL:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_COOPERATIVE_MATRIX:
@@ -809,6 +811,8 @@ _vtn_variable_copy(struct vtn_builder *b, struct vtn_pointer *dest,
    case GLSL_TYPE_INT64:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_BOOL:
       /* At this point, we have a scalar, vector, or matrix so we know that
@@ -1599,6 +1603,11 @@ var_decoration_cb(struct vtn_builder *b, struct vtn_value *val, int member,
    case SpvDecorationPatch:
       vtn_var->var->data.patch = true;
       break;
+   case SpvDecorationAliased:
+      if (vtn_var->mode == vtn_variable_mode_workgroup &&
+          glsl_type_is_interface(vtn_var->var->type))
+         vtn_var->var->data.aliased_shared_memory = true;
+      break;
    case SpvDecorationOffset:
       vtn_var->offset = dec->operands[0];
       break;
@@ -2216,6 +2225,9 @@ vtn_create_variable(struct vtn_builder *b, struct vtn_value *val,
       var->var->name = ralloc_strdup(var->var, val->name);
       var->var->type = vtn_type_get_nir_type(b, var->type, var->mode);
       var->var->data.mode = nir_mode;
+      if (var->mode == vtn_variable_mode_workgroup &&
+          glsl_type_is_interface(var->var->type))
+         b->shader->info.shared_memory_explicit_layout = true;
       break;
 
    case vtn_variable_mode_input:
diff --git a/src/egl/drivers/dri2/platform_device.c b/src/egl/drivers/dri2/platform_device.c
index aa36d63a5b2..0dd6a561301 100644
--- a/src/egl/drivers/dri2/platform_device.c
+++ b/src/egl/drivers/dri2/platform_device.c
@@ -282,21 +282,16 @@ device_probe_device(_EGLDisplay *disp)
    if (!dri2_dpy->driver_name)
       goto err_name;
 
-   /* this is software fallback */
-   if (disp->Options.ForceSoftware && !request_software) {
-      /* When doing software rendering, some times user still want to explicitly
-      * choose the render node device since cross node import doesn't work between
-      * vgem/virtio_gpu yet. It would be nice to have a new EXTENSION for this.
-      * For now, just fallback to kms_swrast. */
-      if (strcmp(dri2_dpy->driver_name, "vgem") == 0 ||
-          strcmp(dri2_dpy->driver_name, "virtio_gpu") == 0) {
-         free(dri2_dpy->driver_name);
-         _eglLog(_EGL_WARNING, "NEEDS EXTENSION: falling back to kms_swrast");
-         dri2_dpy->driver_name = strdup("kms_swrast");
-      } else if (strcmp(dri2_dpy->driver_name, "vmwgfx")) {
-         /* this is software fallback; deny progress since a hardware device was requested */
-         return false;
-      }
+   /* When doing software rendering, some times user still want to explicitly
+    * choose the render node device since cross node import doesn't work between
+    * vgem/virtio_gpu yet. It would be nice to have a new EXTENSION for this.
+    * For now, just fallback to kms_swrast. */
+   if (disp->Options.ForceSoftware && !request_software &&
+       (strcmp(dri2_dpy->driver_name, "vgem") == 0 ||
+        strcmp(dri2_dpy->driver_name, "virtio_gpu") == 0)) {
+      free(dri2_dpy->driver_name);
+      _eglLog(_EGL_WARNING, "NEEDS EXTENSION: falling back to kms_swrast");
+      dri2_dpy->driver_name = strdup("kms_swrast");
    }
 
    if (!dri2_load_driver(disp))
diff --git a/src/etnaviv/ci/etnaviv-vipnano-si-plus-fails.txt b/src/etnaviv/ci/etnaviv-vipnano-si-plus-fails.txt
index ae777e39c2a..14e778f8efe 100644
--- a/src/etnaviv/ci/etnaviv-vipnano-si-plus-fails.txt
+++ b/src/etnaviv/ci/etnaviv-vipnano-si-plus-fails.txt
@@ -8,7 +8,9 @@ Add.Op/input_size_5_weight_size_5_input_channels_32_output_channels_256_stride_2
 Add.Op/input_size_80_weight_size_3_input_channels_32_output_channels_120_stride_1_padding_same_1_is_signed_0,Fail
 Add.Op/input_size_80_weight_size_5_input_channels_32_output_channels_256_stride_1_padding_same_1_is_signed_0,Fail
 
-MobileDetParam.Op/mobiledet082,Fail
-MobileDet.Whole,Fail
+# Something seems to have changed in TensorFlow Lite and it doesn't pass any more.
+# Probably the implementation of TFLite_Detection_PostProcess is producing results in a different order.
+# The model actually detects correctly.
+Models.Op/mobiledet_ssdlite_mobiledet_coco_qat_postprocess,Fail
 
-YoloX.Whole,Fail
+Models.Op/yolox_yolox,Fail
diff --git a/src/etnaviv/ci/etnaviv-vipnano-si-plus-skips.txt b/src/etnaviv/ci/etnaviv-vipnano-si-plus-skips.txt
index 14fa8b1140a..62a3c3e852b 100644
--- a/src/etnaviv/ci/etnaviv-vipnano-si-plus-skips.txt
+++ b/src/etnaviv/ci/etnaviv-vipnano-si-plus-skips.txt
@@ -3,26 +3,40 @@ Add.Op/input_size_8_weight_size_3_input_channels_32_output_channels_120_stride_1
 Add.Op/input_size_8_weight_size_5_input_channels_32_output_channels_256_stride_1_padding_same_1_is_signed_0
 
 # These tests below (adds) aren't well constructed and thus fail in TF
-MobileDetParam.Op/mobiledet008
-MobileDetParam.Op/mobiledet011
-MobileDetParam.Op/mobiledet014
-MobileDetParam.Op/mobiledet019
-MobileDetParam.Op/mobiledet022
-MobileDetParam.Op/mobiledet025
-MobileDetParam.Op/mobiledet032
-MobileDetParam.Op/mobiledet035
-MobileDetParam.Op/mobiledet038
-MobileDetParam.Op/mobiledet045
-MobileDetParam.Op/mobiledet049
-MobileDetParam.Op/mobiledet053
-MobileDetParam.Op/mobiledet060
-MobileDetParam.Op/mobiledet064
-MobileDetParam.Op/mobiledet068
-YoloXParam.Op/yolox011
-YoloXParam.Op/yolox020
-YoloXParam.Op/yolox023
-YoloXParam.Op/yolox026
-YoloXParam.Op/yolox035
-YoloXParam.Op/yolox038
-YoloXParam.Op/yolox041
+Models.Op/mobiledet_008
+Models.Op/mobiledet_011
+Models.Op/mobiledet_014
+Models.Op/mobiledet_019
+Models.Op/mobiledet_022
+Models.Op/mobiledet_025
+Models.Op/mobiledet_032
+Models.Op/mobiledet_035
+Models.Op/mobiledet_038
+Models.Op/mobiledet_045
+Models.Op/mobiledet_049
+Models.Op/mobiledet_053
+Models.Op/mobiledet_060
+Models.Op/mobiledet_064
+Models.Op/mobiledet_068
+Models.Op/yolox_011
+Models.Op/yolox_020
+Models.Op/yolox_023
+Models.Op/yolox_026
+Models.Op/yolox_035
+Models.Op/yolox_038
+Models.Op/yolox_041
 
+# These tests below (splits) aren't well constructed and thus fail in TF
+Models.Op/detect_003
+Models.Op/detect_012
+Models.Op/detect_020
+Models.Op/detect_029
+Models.Op/detect_037
+Models.Op/detect_046
+Models.Op/detect_054
+Models.Op/detect_062
+Models.Op/detect_070
+Models.Op/detect_078
+Models.Op/detect_086
+Models.Op/detect_095
+Models.Op/detect_103
diff --git a/src/etnaviv/ci/etnaviv-vipnano-skips.txt b/src/etnaviv/ci/etnaviv-vipnano-skips.txt
index 0971c7851b1..8f6df5aaf44 100644
--- a/src/etnaviv/ci/etnaviv-vipnano-skips.txt
+++ b/src/etnaviv/ci/etnaviv-vipnano-skips.txt
@@ -11,30 +11,30 @@ Add.Op/input_size_8_weight_size_5_input_channels_1_output_channels_256_stride_2_
 
 # No idea why this one is failing, needs investigation.
 # It takes a long time, so better skip for now.
-MobileDet.Whole
+Models.Op/mobiledet_ssdlite_mobiledet_coco_qat_postprocess
 
 # These tests below (adds) aren't well constructed and thus fail in TF
-MobileDetParam.Op/mobiledet008
-MobileDetParam.Op/mobiledet011
-MobileDetParam.Op/mobiledet014
-MobileDetParam.Op/mobiledet019
-MobileDetParam.Op/mobiledet022
-MobileDetParam.Op/mobiledet025
-MobileDetParam.Op/mobiledet032
-MobileDetParam.Op/mobiledet035
-MobileDetParam.Op/mobiledet038
-MobileDetParam.Op/mobiledet045
-MobileDetParam.Op/mobiledet049
-MobileDetParam.Op/mobiledet053
-MobileDetParam.Op/mobiledet060
-MobileDetParam.Op/mobiledet064
-MobileDetParam.Op/mobiledet068
-YoloXParam.Op/yolox011
-YoloXParam.Op/yolox020
-YoloXParam.Op/yolox023
-YoloXParam.Op/yolox026
-YoloXParam.Op/yolox035
-YoloXParam.Op/yolox038
-YoloXParam.Op/yolox041
+Models.Op/mobiledet_008
+Models.Op/mobiledet_011
+Models.Op/mobiledet_014
+Models.Op/mobiledet_019
+Models.Op/mobiledet_022
+Models.Op/mobiledet_025
+Models.Op/mobiledet_032
+Models.Op/mobiledet_035
+Models.Op/mobiledet_038
+Models.Op/mobiledet_045
+Models.Op/mobiledet_049
+Models.Op/mobiledet_053
+Models.Op/mobiledet_060
+Models.Op/mobiledet_064
+Models.Op/mobiledet_068
+Models.Op/yolox_011
+Models.Op/yolox_020
+Models.Op/yolox_023
+Models.Op/yolox_026
+Models.Op/yolox_035
+Models.Op/yolox_038
+Models.Op/yolox_041
 
 FullyConnected.Op/*
\ No newline at end of file
diff --git a/src/etnaviv/ci/gitlab-ci.yml b/src/etnaviv/ci/gitlab-ci.yml
index 38f6f1416e4..c69ccdba9a7 100644
--- a/src/etnaviv/ci/gitlab-ci.yml
+++ b/src/etnaviv/ci/gitlab-ci.yml
@@ -21,7 +21,7 @@
       when: on_success
 
 .etnaviv-manual-rules:
-  stage: etnaviv-postmerge
+  stage: etnaviv-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -133,6 +133,7 @@ gc2000-gles2:
 gc2000-piglit:
   extends:
     - gc2000-gles2
+    - .test-piglit
   variables:
     DEQP_SUITE: etnaviv-gc2000-piglit
     B2C_TIMEOUT_OVERALL_MINUTES: 25
@@ -165,7 +166,7 @@ gc7000-imx8mq-gles2:
 
 gc7000-imx8mp-gles2:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .pengutronix-imx8mp-mba8mpxl:arm64
     - .etnaviv-manual-rules
   variables:
diff --git a/src/etnaviv/hwdb/nxp/gc_feature_database.h b/src/etnaviv/hwdb/nxp/gc_feature_database.h
index cbff46972f6..ea1a049810d 100644
--- a/src/etnaviv/hwdb/nxp/gc_feature_database.h
+++ b/src/etnaviv/hwdb/nxp/gc_feature_database.h
@@ -53,7 +53,7 @@
 *****************************************************************************/
 
 
-/*Auto created on 2023-10-24 16:06*/
+/*Auto created on 2024-06-19 13:57*/
 #ifndef _gc_feature_database_h_
 #define _gc_feature_database_h_
 
@@ -167,6 +167,9 @@ typedef struct
     gctUINT32 SP_VECTOR_DEPTH;
     gctUINT32 VIPSRAM_CLK_DOMAIN_RATIO_PERCENT;
     gctUINT32 VIP_VERSION;
+    gctUINT32 NN_COMMAND_BUFFER_SIZE;
+    gctUINT32 DECOMP_VZ_GROUP_BITS;
+    gctUINT32 NN_LOOP1_DP_NUMBER;
     gctUINT32 REG_FastClear:1;
     gctUINT32 REG_SpecialAntiAliasing:1;
     gctUINT32 REG_Pipe3D:1;
@@ -596,6 +599,14 @@ typedef struct
     gctUINT32 MMU_40BIT_VA_FIX:1;
     gctUINT32 MMU_40BIT_VA_GRAPHICS:1;
     gctUINT32 ONE_OUTPUT_COMPOENT_FOR_MFU:1;
+    gctUINT32 SH_64BIT_VA_ENHANCEMENT:1;
+    gctUINT32 DX11_SH_RCP_SQRT_PRECISSION:1;
+    gctUINT32 TILED_RESOURCE:1;
+    gctUINT32 SH_FP64:1;
+    gctUINT32 SH_SM6:1;
+    gctUINT32 VGPU:1;
+    gctUINT32 DEC_NANO:1;
+    gctUINT32 SH_64BIT_ROBUST_CHECK:1;
     gctUINT32 G2D_RGB_PLANAR:1;
     gctUINT32 G2D_RGB_PLANAR_SOURCE:1;
     gctUINT32 G2D_DEC400EX:1;
@@ -663,7 +674,6 @@ typedef struct
     gctUINT32 NN_ZDP3:1;
     gctUINT32 NN_ZDP6:1;
     gctUINT32 NN_ZDP9:1;
-    gctUINT32 NN_ZDP18:1;
     gctUINT32 NN_XYDP9:1;
     gctUINT32 NN_FIRST_PIXEL_POOLING:1;
     gctUINT32 NN_XYDP6:1;
@@ -775,12 +785,11 @@ typedef struct
     gctUINT32 NN_INT16_TENSOR_ADD:1;
     gctUINT32 NN_TENSOR_ADD_DOUBLE_PIPELINE:1;
     gctUINT32 TENSOR_DMA:1;
-    gctUINT32 DPP_SUPPORT_REF_OUTPUT_CROPING:1;
-    gctUINT32 RGB_TO_RAW:1;
     gctUINT32 NN_SPLIT_X_AMONG_CLUSTER:1;
     gctUINT32 NN_SUPPORT_ZDP_LOOP6:1;
     gctUINT32 NN_FP8_PHASE1:1;
     gctUINT32 NN_SUPPORT_FUSA:1;
+    gctUINT32 NN_OUTPUT_OVERFLOW_MODE:1;
     gctUINT32 NN_DEPTHWISE_ENHANCEMENT:1;
     gctUINT32 NN_CONV_1X1_ENHANCEMENT:1;
     gctUINT32 SUPPORT_DYNAMIC_SHAPE:1;
@@ -788,7 +797,15 @@ typedef struct
     gctUINT32 NN_SUPPORT_GEMM_PHASE2:1;
     gctUINT32 SRAM_PARITY:1;
     gctUINT32 NNCMD_AXIID_OFFSET:1;
-    gctUINT32 SHADER_TRIGGER_NN:1;
+    gctUINT32 TC_SHADER_TRIGGER_NN:1;
+    gctUINT32 TC_PROBE_COUNTER:1;
+    gctUINT32 NN_TILE_BRICK_MODE:1;
+    gctUINT32 NN_4BIT_COEF_PACKED_MODE:1;
+    gctUINT32 NN_BF16_I4_I8_QUANTIZATION:1;
+    gctUINT32 NN_HIGH_PERF_DECODE_SPLIT_STAGE:1;
+    gctUINT32 NN_POST_PROCESSOR_FL32:1;
+    gctUINT32 NN_HIGH_PERF_DECODER:1;
+    gctUINT32 NN_GROUP_QUANT_PHASE1:1;
     gctUINT32 NN_PER3DTILE_BUBBLE_FIX:1;
     gctUINT32 NN_CACHELINE_MODE_PERF_FIX:1;
     gctUINT32 NN_CONV1x1_PERF_FIX:1;
@@ -849,10 +866,10 @@ typedef struct
     gctUINT32 TP_NOT_FULL_USE_CACHE_LINE_FIX:1;
     gctUINT32 SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX:1;
     gctUINT32 BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX:1;
+    gctUINT32 SH_CONFORMANCE_BRUTEFORCE_FIX:1;
     gctUINT32 TP_ASSYM_INT8_FIX:1;
     gctUINT32 NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX:1;
     gctUINT32 NN_2ND_IMG_BASE_ADDR_FIX:1;
-    gctUINT32 NN_TP_SYSTEM_FIX:1;
     gctUINT32 NN_INTILE_YSIZE_128_LIMIT_FIX:1;
     gctUINT32 SH_CLOCK_GATOR_IDLE_CONDITON_FIX:1;
     gctUINT32 NN_BURST_COLLECTER_LAST_FLAG_FIX:1;
@@ -887,16 +904,22 @@ typedef struct
     gctUINT32 NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX:1;
     gctUINT32 NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX:1;
     gctUINT32 NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX:1;
+    gctUINT32 WRSPLIT_NOT_SUPPORT_PROBE_FIX:1;
     gctUINT32 TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX:1;
     gctUINT32 TP_SPECIAL_LIST_PARSER_FIX:1;
     gctUINT32 DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX:1;
     gctUINT32 DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX:1;
+    gctUINT32 TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX:1;
     gctUINT32 SECONDIMG_TILE_SIDEBANFIFO_FIX:1;
     gctUINT32 TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX:1;
+    gctUINT32 WRITE_STRIDE2_DUMMY_FIX:1;
+    gctUINT32 TRSP2_WORDSIZE_BIGGER_FIX:1;
     gctUINT32 BURSTCOLLECTOR_ADDR_UPDATE_FIX:1;
+    gctUINT32 TRSB2_SMALL_BATCH_UPDATE_FIX:1;
     gctUINT32 NN_NT_SMALLBATCH_TRNSFER_INIT_FIX:1;
     gctUINT32 IMGRD_FIRST_ROW_SMALL_SLICE_FIX:1;
     gctUINT32 KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX:1;
+    gctUINT32 MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX:1;
     gctUINT32 MULTI_AXI_ID_IMG_KERNEL_SAME_FIX:1;
     gctUINT32 TRSP2_CONV_SMALLBATCH_FIX:1;
     gctUINT32 DEPTHTOSPACE_SAME_XY_FIX:1;
@@ -908,6 +931,13 @@ typedef struct
     gctUINT32 PERF_KERNEL_DESCRIPTOR_SOURCE_FIX:1;
     gctUINT32 SP_NOIN_IMGRD_DUMMY_FIX:1;
     gctUINT32 NN_4BIT_PERF_EVEN_TILEXSIZE_FIX:1;
+    gctUINT32 STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX:1;
+    gctUINT32 MULTI_ID_DIRECTMODE_CHANGE_FIX:1;
+    gctUINT32 PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX:1;
+    gctUINT32 FIRST_SECOND_IMG_SAME_ID_FIX:1;
+    gctUINT32 TILESIZE_LIMITATION_CORE_BYPASS_FIX:1;
+    gctUINT32 SH_BARRIER_EXECUTION_FIX:1;
+    gctUINT32 FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX:1;
     gctUINT32 NN_INTERLEVE8:1;
     gctUINT32 NN_FP16_ALU:1;
     gctUINT32 NN_INT16_ALU:1;
@@ -923,8 +953,8 @@ typedef struct
     gctUINT32 IMAGE_PARTIAL_CACHE:1;
 } gcsFEATURE_DATABASE;
 
-#define FEATURE_BIT_START 116
-#define FEATURE_BIT_END 869
+#define FEATURE_BIT_START 119
+#define FEATURE_BIT_END 899
 static gcsFEATURE_DATABASE gChipInfo[] = {
     /* gc320_5007 */
     {
@@ -1035,6 +1065,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x1, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x0, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -1464,6 +1497,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -1531,7 +1572,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -1643,12 +1683,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -1656,7 +1695,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -1717,10 +1764,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -1755,16 +1802,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -1776,6 +1829,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -1899,6 +1959,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x1, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x0, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -2328,6 +2391,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -2395,7 +2466,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -2507,12 +2577,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -2520,7 +2589,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -2581,10 +2658,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -2619,16 +2696,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -2640,6 +2723,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -2763,6 +2853,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x1, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x0, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -3192,6 +3285,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -3259,7 +3360,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -3371,12 +3471,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -3384,7 +3483,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -3445,10 +3552,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -3483,16 +3590,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -3504,6 +3617,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -3627,6 +3747,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x0, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -4056,6 +4179,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -4123,7 +4254,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -4235,12 +4365,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -4248,7 +4377,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -4309,10 +4446,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -4347,16 +4484,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -4368,6 +4511,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -4491,6 +4641,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -4920,6 +5073,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -4987,7 +5148,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -5099,12 +5259,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -5112,7 +5271,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -5173,10 +5340,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -5211,16 +5378,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -5232,6 +5405,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -5355,6 +5535,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x1, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x0, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -5784,6 +5967,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -5851,7 +6042,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -5963,12 +6153,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -5976,7 +6165,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -6037,10 +6234,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -6075,16 +6272,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -6096,6 +6299,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -6219,6 +6429,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x1, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x0, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -6648,6 +6861,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -6715,7 +6936,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -6827,12 +7047,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -6840,7 +7059,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -6901,10 +7128,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -6939,16 +7166,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -6960,6 +7193,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -7083,6 +7323,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -7512,6 +7755,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -7579,7 +7830,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -7691,12 +7941,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -7704,7 +7953,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -7765,10 +8022,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -7803,16 +8060,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -7824,6 +8087,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -7947,6 +8217,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -8376,6 +8649,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -8443,7 +8724,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -8555,12 +8835,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -8568,7 +8847,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -8629,10 +8916,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -8667,16 +8954,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -8688,6 +8981,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -8811,6 +9111,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -9240,6 +9543,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -9307,7 +9618,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -9419,12 +9729,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -9432,7 +9741,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -9493,10 +9810,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -9531,16 +9848,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -9552,6 +9875,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -9675,6 +10005,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -10104,6 +10437,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -10171,7 +10512,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -10283,12 +10623,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -10296,7 +10635,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -10357,10 +10704,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -10395,16 +10742,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -10416,6 +10769,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -10539,6 +10899,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -10968,6 +11331,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -11035,7 +11406,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -11147,12 +11517,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -11160,7 +11529,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -11221,10 +11598,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -11259,16 +11636,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -11280,6 +11663,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -11403,6 +11793,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -11832,6 +12225,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -11899,7 +12300,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -12011,12 +12411,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -12024,7 +12423,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -12085,10 +12492,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -12123,16 +12530,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -12144,6 +12557,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -12267,6 +12687,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -12696,6 +13119,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -12763,7 +13194,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -12875,12 +13305,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -12888,7 +13317,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -12949,10 +13386,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -12987,16 +13424,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -13008,6 +13451,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -13131,6 +13581,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -13560,6 +14013,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -13627,7 +14088,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -13739,12 +14199,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -13752,7 +14211,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -13813,10 +14280,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -13851,16 +14318,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -13872,6 +14345,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -13995,6 +14475,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -14424,6 +14907,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -14491,7 +14982,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -14603,12 +15093,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -14616,7 +15105,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -14677,10 +15174,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -14715,16 +15212,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -14736,6 +15239,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -14859,6 +15369,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -15288,6 +15801,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -15355,7 +15876,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -15467,12 +15987,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -15480,7 +15999,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -15541,10 +16068,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -15579,16 +16106,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -15600,6 +16133,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -15723,6 +16263,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -16152,6 +16695,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -16219,7 +16770,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -16331,12 +16881,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -16344,7 +16893,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -16405,10 +16962,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -16443,16 +17000,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -16464,6 +17027,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -16587,6 +17157,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -17016,6 +17589,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -17083,7 +17664,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -17195,12 +17775,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -17208,7 +17787,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -17269,10 +17856,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -17307,16 +17894,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -17328,6 +17921,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -17451,6 +18051,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -17880,6 +18483,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -17947,7 +18558,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -18059,12 +18669,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -18072,7 +18681,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -18133,10 +18750,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -18171,16 +18788,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -18192,6 +18815,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -18315,6 +18945,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -18744,6 +19377,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -18811,7 +19452,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -18923,12 +19563,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -18936,7 +19575,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -18997,10 +19644,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -19035,16 +19682,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -19056,6 +19709,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -19179,6 +19839,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -19608,6 +20271,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -19675,7 +20346,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -19787,12 +20457,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -19800,7 +20469,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -19861,10 +20538,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -19899,16 +20576,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -19920,6 +20603,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -20043,6 +20733,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -20472,6 +21165,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -20539,7 +21240,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -20651,12 +21351,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -20664,7 +21363,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -20725,10 +21432,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -20763,16 +21470,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -20784,6 +21497,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -20907,6 +21627,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -21336,6 +22059,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -21403,7 +22134,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -21515,12 +22245,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -21528,7 +22257,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -21589,10 +22326,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -21627,16 +22364,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -21648,6 +22391,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -21771,6 +22521,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -22200,6 +22953,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -22267,7 +23028,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -22379,12 +23139,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -22392,7 +23151,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -22453,10 +23220,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -22491,16 +23258,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -22512,6 +23285,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -22635,6 +23415,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x32, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x10, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x3, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -23064,6 +23847,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -23131,7 +23922,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x1, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -23243,12 +24033,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -23256,7 +24045,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x1, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x1, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x1, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -23317,10 +24114,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x0, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x0, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x1, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x1, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x1, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x1, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x1, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -23355,16 +24152,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x1, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x1, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x1, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x1, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x1, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x1, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x1, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x1, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x1, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x1, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x1, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x1, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -23376,6 +24179,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x1, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x1, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x1, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x1, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x1, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x1, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -23499,6 +24309,9 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
         0x32, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
         0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x10, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x3, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -23928,6 +24741,14 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
         0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
         0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -23995,7 +24816,6 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
         0x0, /* gcFEATURE_BIT_NN_ZDP9 */
-        0x0, /* gcFEATURE_BIT_NN_ZDP18 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x1, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
@@ -24107,12 +24927,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
-        0x0, /* gcFEATURE_BIT_DPP_SUPPORT_REF_OUTPUT_CROPING */
-        0x0, /* gcFEATURE_BIT_RGB_TO_RAW */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
         0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
@@ -24120,7 +24939,15 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
         0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
-        0x0, /* gcFEATURE_BIT_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
         0x1, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x1, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x1, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -24181,10 +25008,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x0, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x0, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x1, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x1, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x1, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x1, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x1, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -24219,16 +25046,22 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x1, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x1, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x1, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x1, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x1, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x1, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
         0x1, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x1, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x1, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x1, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x1, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x1, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
@@ -24240,6 +25073,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
         0x1, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
         0x1, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x1, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x1, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x1, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x1, /* gcFEATURE_BIT_NN_INT16_ALU */
diff --git a/src/etnaviv/hwdb/st/gc_feature_database.h b/src/etnaviv/hwdb/st/gc_feature_database.h
index 6bac2cd3b6c..fc2f75d0972 100644
--- a/src/etnaviv/hwdb/st/gc_feature_database.h
+++ b/src/etnaviv/hwdb/st/gc_feature_database.h
@@ -2,7 +2,7 @@
 *
 *    The MIT License (MIT)
 *
-*    Copyright (c) 2014 - 2020 Vivante Corporation
+*    Copyright (c) 2014 - 2024 Vivante Corporation
 *
 *    Permission is hereby granted, free of charge, to any person obtaining a
 *    copy of this software and associated documentation files (the "Software"),
@@ -26,7 +26,7 @@
 *
 *    The GPL License (GPL)
 *
-*    Copyright (C) 2014 - 2020 Vivante Corporation
+*    Copyright (C) 2014 - 2024 Vivante Corporation
 *
 *    This program is free software; you can redistribute it and/or
 *    modify it under the terms of the GNU General Public License
@@ -53,7 +53,7 @@
 *****************************************************************************/
 
 
-/*Auto created on 2022-12-29 11:13*/
+/*Auto created on 2024-07-26 17:55*/
 #ifndef _gc_feature_database_h_
 #define _gc_feature_database_h_
 
@@ -120,7 +120,7 @@ typedef struct
     gctUINT32 TPEngine_PwlLUTCount;
     gctUINT32 TPEngine_PwlLUTSize;
     gctUINT32 VIP_SRAM_SIZE;
-    gctUINT32 VIP_SRAM_SIZE_ARRAY;
+    gctUINT32 VIP_SRAM_SIZE_ARRAY[9];
     gctUINT32 TPEngine_CoreCount;
     gctUINT32 AXI_SRAM_SIZE;
     gctUINT32 NN_INIMAGE_OFFSET_BITS;
@@ -137,6 +137,7 @@ typedef struct
     gctUINT32 EQUIVALENT_VIP_SRAM_WIDTH_INBYTE;
     gctUINT32 TP_ZRL_BITS;
     gctUINT32 NN_ZRL_BITS;
+    gctUINT32 NN_ZRL_VALID_ZERO_NUMBER;
     gctUINT32 LATENCY_HIDING_AT_FULL_AXI_BW;
     gctUINT32 AXI_BUS_WIDTH;
     gctUINT32 NN_KERNEL_X_SIZE;
@@ -165,6 +166,11 @@ typedef struct
     gctUINT32 NN_SMALL_ACCUM_BITS;
     gctUINT32 NN_COEF_DECOMPRESS_PERF_X;
     gctUINT32 SP_VECTOR_DEPTH;
+    gctUINT32 VIPSRAM_CLK_DOMAIN_RATIO_PERCENT;
+    gctUINT32 VIP_VERSION;
+    gctUINT32 NN_COMMAND_BUFFER_SIZE;
+    gctUINT32 DECOMP_VZ_GROUP_BITS;
+    gctUINT32 NN_LOOP1_DP_NUMBER;
     gctUINT32 REG_FastClear:1;
     gctUINT32 REG_SpecialAntiAliasing:1;
     gctUINT32 REG_Pipe3D:1;
@@ -573,18 +579,35 @@ typedef struct
     gctUINT32 HIGHP_VEC2:1;
     gctUINT32 MMU_PD_42_BIT_ADDRESS:1;
     gctUINT32 BLT_ROBUSTNESS_FIX:1;
+    gctUINT32 BLT_OUT_OF_BOUND_FIX:1;
     gctUINT32 TFB_PERF_FIX:1;
     gctUINT32 SH_SUPERSCALAR_ARCH:1;
     gctUINT32 PA_ZEROAREA_LINE_FIX:1;
+    gctUINT32 RS_TILER_YUV420_FIX:1;
     gctUINT32 ATTR_IN_GLOBAL_MEMORY:1;
     gctUINT32 SIMPLIFIED_CHECKERBOARD:1;
     gctUINT32 ADDR_REMAP:1;
     gctUINT32 ADDR_40BIT_OVERFLOW_FIX:1;
     gctUINT32 CLIP_DISTANCE_SUPPORT:1;
     gctUINT32 SEPARATED_TEXTURE_SAMPLER:1;
+    gctUINT32 TS_INFO_IN_TX_DESCRIPTOR:1;
     gctUINT32 PER_STAGE_LOCAL_STORAGE:1;
     gctUINT32 DX11_FORMAT_SUPPORT:1;
     gctUINT32 OCCLUSION_SAMPLE_COUNTER:1;
+    gctUINT32 FRONT_FACE_UINT:1;
+    gctUINT32 DYNAMIC_TEXTURE_INDEXING:1;
+    gctUINT32 D3D11_SUPPORT:1;
+    gctUINT32 MMU_40BIT_VA_FIX:1;
+    gctUINT32 MMU_40BIT_VA_GRAPHICS:1;
+    gctUINT32 ONE_OUTPUT_COMPOENT_FOR_MFU:1;
+    gctUINT32 SH_64BIT_VA_ENHANCEMENT:1;
+    gctUINT32 DX11_SH_RCP_SQRT_PRECISSION:1;
+    gctUINT32 TILED_RESOURCE:1;
+    gctUINT32 SH_FP64:1;
+    gctUINT32 SH_SM6:1;
+    gctUINT32 VGPU:1;
+    gctUINT32 DEC_NANO:1;
+    gctUINT32 SH_64BIT_ROBUST_CHECK:1;
     gctUINT32 G2D_RGB_PLANAR:1;
     gctUINT32 G2D_RGB_PLANAR_SOURCE:1;
     gctUINT32 G2D_DEC400EX:1;
@@ -649,10 +672,11 @@ typedef struct
     gctUINT32 NN_REMOVE_POOLING:1;
     gctUINT32 NN_40BIT_BIAS:1;
     gctUINT32 TP_REMOVE_USC:1;
+    gctUINT32 NN_ZDP3:1;
     gctUINT32 NN_ZDP6:1;
+    gctUINT32 NN_ZDP9:1;
     gctUINT32 NN_XYDP9:1;
     gctUINT32 NN_FIRST_PIXEL_POOLING:1;
-    gctUINT32 NN_ZDP3:1;
     gctUINT32 NN_XYDP6:1;
     gctUINT32 SWTILING_PHASE3:1;
     gctUINT32 MCFE:1;
@@ -758,16 +782,38 @@ typedef struct
     gctUINT32 NN_SUPPORT_CLAMP_BORDER_MODE:1;
     gctUINT32 NN_ELEMENTWISE_BROADCAST_STRIDE_X_0:1;
     gctUINT32 NN_2ND_IMAGE_DATA_TYPE:1;
+    gctUINT32 FP_INIMAGE_POST_SCALE:1;
     gctUINT32 NN_INT16_TENSOR_ADD:1;
+    gctUINT32 NN_TENSOR_ADD_DOUBLE_PIPELINE:1;
     gctUINT32 TENSOR_DMA:1;
     gctUINT32 NN_SPLIT_X_AMONG_CLUSTER:1;
-    gctUINT32 NN_FP8:1;
+    gctUINT32 NN_SUPPORT_ZDP_LOOP6:1;
+    gctUINT32 NN_FP8_PHASE1:1;
+    gctUINT32 NN_SUPPORT_FUSA:1;
+    gctUINT32 NN_OUTPUT_OVERFLOW_MODE:1;
     gctUINT32 NN_DEPTHWISE_ENHANCEMENT:1;
     gctUINT32 NN_CONV_1X1_ENHANCEMENT:1;
     gctUINT32 SUPPORT_DYNAMIC_SHAPE:1;
     gctUINT32 SUPPORT_BATCH_ALIGNMENT:1;
     gctUINT32 NN_SUPPORT_GEMM_PHASE2:1;
     gctUINT32 SRAM_PARITY:1;
+    gctUINT32 NNCMD_AXIID_OFFSET:1;
+    gctUINT32 TC_SHADER_TRIGGER_NN:1;
+    gctUINT32 TC_PROBE_COUNTER:1;
+    gctUINT32 NN_TILE_BRICK_MODE:1;
+    gctUINT32 NN_4BIT_COEF_PACKED_MODE:1;
+    gctUINT32 NN_BF16_I4_I8_QUANTIZATION:1;
+    gctUINT32 NN_HIGH_PERF_DECODE_SPLIT_STAGE:1;
+    gctUINT32 NN_POST_PROCESSOR_FL32:1;
+    gctUINT32 NN_HIGH_PERF_DECODER:1;
+    gctUINT32 NN_GROUP_QUANT_PHASE1:1;
+    gctUINT32 NN_SH_IN_PARALLEL:1;
+    gctUINT32 NN_ASYNC_DMA:1;
+    gctUINT32 NN_STRIDE2_FAST_XDP3:1;
+    gctUINT32 NN_2V4_STRUCTURED_SPARSITY:1;
+    gctUINT32 NN_SP_ENHANCEMENT:1;
+    gctUINT32 NN_SUPPORT_SEPARATE_STREAMBUF_ADDR:1;
+    gctUINT32 NN_TF32_MAC:1;
     gctUINT32 NN_PER3DTILE_BUBBLE_FIX:1;
     gctUINT32 NN_CACHELINE_MODE_PERF_FIX:1;
     gctUINT32 NN_CONV1x1_PERF_FIX:1;
@@ -828,10 +874,10 @@ typedef struct
     gctUINT32 TP_NOT_FULL_USE_CACHE_LINE_FIX:1;
     gctUINT32 SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX:1;
     gctUINT32 BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX:1;
+    gctUINT32 SH_CONFORMANCE_BRUTEFORCE_FIX:1;
     gctUINT32 TP_ASSYM_INT8_FIX:1;
     gctUINT32 NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX:1;
     gctUINT32 NN_2ND_IMG_BASE_ADDR_FIX:1;
-    gctUINT32 NN_TP_SYSTEM_FIX:1;
     gctUINT32 NN_INTILE_YSIZE_128_LIMIT_FIX:1;
     gctUINT32 SH_CLOCK_GATOR_IDLE_CONDITON_FIX:1;
     gctUINT32 NN_BURST_COLLECTER_LAST_FLAG_FIX:1;
@@ -866,20 +912,46 @@ typedef struct
     gctUINT32 NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX:1;
     gctUINT32 NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX:1;
     gctUINT32 NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX:1;
+    gctUINT32 WRSPLIT_NOT_SUPPORT_PROBE_FIX:1;
     gctUINT32 TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX:1;
     gctUINT32 TP_SPECIAL_LIST_PARSER_FIX:1;
     gctUINT32 DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX:1;
     gctUINT32 DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX:1;
+    gctUINT32 TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX:1;
     gctUINT32 SECONDIMG_TILE_SIDEBANFIFO_FIX:1;
     gctUINT32 TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX:1;
+    gctUINT32 WRITE_STRIDE2_DUMMY_FIX:1;
+    gctUINT32 TRSP2_WORDSIZE_BIGGER_FIX:1;
+    gctUINT32 BURSTCOLLECTOR_ADDR_UPDATE_FIX:1;
+    gctUINT32 TRSB2_SMALL_BATCH_UPDATE_FIX:1;
     gctUINT32 NN_NT_SMALLBATCH_TRNSFER_INIT_FIX:1;
     gctUINT32 IMGRD_FIRST_ROW_SMALL_SLICE_FIX:1;
     gctUINT32 KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX:1;
+    gctUINT32 MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX:1;
     gctUINT32 MULTI_AXI_ID_IMG_KERNEL_SAME_FIX:1;
     gctUINT32 TRSP2_CONV_SMALLBATCH_FIX:1;
     gctUINT32 DEPTHTOSPACE_SAME_XY_FIX:1;
     gctUINT32 VZ_GROUP_START_Z_OVERFLOW_FIX:1;
     gctUINT32 V82_STREAMMODE_VIPSRAM_ADDRESS_FIX:1;
+    gctUINT32 GEMM_NO_SUPPORT_SMALLBATCH_FIX:1;
+    gctUINT32 SBP1_KHEAD_CMDSIZE_FIX:1;
+    gctUINT32 PERF_BURSTCOLLECTOR_MAXSIZE_FIX:1;
+    gctUINT32 PERF_KERNEL_DESCRIPTOR_SOURCE_FIX:1;
+    gctUINT32 SP_NOIN_IMGRD_DUMMY_FIX:1;
+    gctUINT32 NN_4BIT_PERF_EVEN_TILEXSIZE_FIX:1;
+    gctUINT32 STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX:1;
+    gctUINT32 MULTI_ID_DIRECTMODE_CHANGE_FIX:1;
+    gctUINT32 PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX:1;
+    gctUINT32 FIRST_SECOND_IMG_SAME_ID_FIX:1;
+    gctUINT32 TILESIZE_LIMITATION_CORE_BYPASS_FIX:1;
+    gctUINT32 SH_BARRIER_EXECUTION_FIX:1;
+    gctUINT32 FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX:1;
+    gctUINT32 FIX_PRE_CORE_LOTS_ZEROSKIP_KERNEL_FIX:1;
+    gctUINT32 FIX_MATRIX_A_TRSP1_CHNUM_FIX:1;
+    gctUINT32 FIX_4BIT_SBP2_BLOCKCTRL2_FIX:1;
+    gctUINT32 B2B_RETRUN_NN_CMD_DONE_FIX:1;
+    gctUINT32 MULTI_AXI_ID_VLW_3D_TILE_INFO_FIX:1;
+    gctUINT32 TRSP2_SPECIAL_WORDSIZE_FIX:1;
     gctUINT32 NN_INTERLEVE8:1;
     gctUINT32 NN_FP16_ALU:1;
     gctUINT32 NN_INT16_ALU:1;
@@ -895,6 +967,8 @@ typedef struct
     gctUINT32 IMAGE_PARTIAL_CACHE:1;
 } gcsFEATURE_DATABASE;
 
+#define FEATURE_BIT_START 120
+#define FEATURE_BIT_END 913
 static gcsFEATURE_DATABASE gChipInfo[] = {
     /* gc7000nano_0x4652 */
     {
@@ -958,7 +1032,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_TPEngine_PwlLUTCount */
         0x0, /* gcFEATURE_VALUE_TPEngine_PwlLUTSize */
         0x0, /* gcFEATURE_VALUE_VIP_SRAM_SIZE */
-        0x0, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
+        {0x0, }, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
         0x0, /* gcFEATURE_VALUE_TPEngine_CoreCount */
         0x0, /* gcFEATURE_VALUE_AXI_SRAM_SIZE */
         0x0, /* gcFEATURE_VALUE_NN_INIMAGE_OFFSET_BITS */
@@ -975,6 +1049,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_EQUIVALENT_VIP_SRAM_WIDTH_INBYTE */
         0x0, /* gcFEATURE_VALUE_TP_ZRL_BITS */
         0x0, /* gcFEATURE_VALUE_NN_ZRL_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_ZRL_VALID_ZERO_NUMBER */
         0x0, /* gcFEATURE_VALUE_LATENCY_HIDING_AT_FULL_AXI_BW */
         0x0, /* gcFEATURE_VALUE_AXI_BUS_WIDTH */
         0x0, /* gcFEATURE_VALUE_NN_KERNEL_X_SIZE */
@@ -1003,6 +1078,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_NN_SMALL_ACCUM_BITS */
         0x0, /* gcFEATURE_VALUE_NN_COEF_DECOMPRESS_PERF_X */
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
+        0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
+        0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -1411,18 +1491,35 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_HIGHP_VEC2 */
         0x0, /* gcFEATURE_BIT_MMU_PD_42_BIT_ADDRESS */
         0x0, /* gcFEATURE_BIT_BLT_ROBUSTNESS_FIX */
+        0x0, /* gcFEATURE_BIT_BLT_OUT_OF_BOUND_FIX */
         0x0, /* gcFEATURE_BIT_TFB_PERF_FIX */
         0x0, /* gcFEATURE_BIT_SH_SUPERSCALAR_ARCH */
         0x0, /* gcFEATURE_BIT_PA_ZEROAREA_LINE_FIX */
+        0x0, /* gcFEATURE_BIT_RS_TILER_YUV420_FIX */
         0x0, /* gcFEATURE_BIT_ATTR_IN_GLOBAL_MEMORY */
         0x0, /* gcFEATURE_BIT_SIMPLIFIED_CHECKERBOARD */
         0x0, /* gcFEATURE_BIT_ADDR_REMAP */
         0x0, /* gcFEATURE_BIT_ADDR_40BIT_OVERFLOW_FIX */
         0x0, /* gcFEATURE_BIT_CLIP_DISTANCE_SUPPORT */
         0x0, /* gcFEATURE_BIT_SEPARATED_TEXTURE_SAMPLER */
+        0x0, /* gcFEATURE_BIT_TS_INFO_IN_TX_DESCRIPTOR */
         0x0, /* gcFEATURE_BIT_PER_STAGE_LOCAL_STORAGE */
         0x0, /* gcFEATURE_BIT_DX11_FORMAT_SUPPORT */
         0x0, /* gcFEATURE_BIT_OCCLUSION_SAMPLE_COUNTER */
+        0x0, /* gcFEATURE_BIT_FRONT_FACE_UINT */
+        0x0, /* gcFEATURE_BIT_DYNAMIC_TEXTURE_INDEXING */
+        0x0, /* gcFEATURE_BIT_D3D11_SUPPORT */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
+        0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -1487,10 +1584,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_REMOVE_POOLING */
         0x0, /* gcFEATURE_BIT_NN_40BIT_BIAS */
         0x0, /* gcFEATURE_BIT_TP_REMOVE_USC */
+        0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
+        0x0, /* gcFEATURE_BIT_NN_ZDP9 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
-        0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
         0x0, /* gcFEATURE_BIT_SWTILING_PHASE3 */
         0x0, /* gcFEATURE_BIT_MCFE */
@@ -1596,16 +1694,38 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_CLAMP_BORDER_MODE */
         0x0, /* gcFEATURE_BIT_NN_ELEMENTWISE_BROADCAST_STRIDE_X_0 */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMAGE_DATA_TYPE */
+        0x0, /* gcFEATURE_BIT_FP_INIMAGE_POST_SCALE */
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
-        0x0, /* gcFEATURE_BIT_NN_FP8 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
+        0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
         0x0, /* gcFEATURE_BIT_SUPPORT_BATCH_ALIGNMENT */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
+        0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SH_IN_PARALLEL */
+        0x0, /* gcFEATURE_BIT_NN_ASYNC_DMA */
+        0x0, /* gcFEATURE_BIT_NN_STRIDE2_FAST_XDP3 */
+        0x0, /* gcFEATURE_BIT_NN_2V4_STRUCTURED_SPARSITY */
+        0x0, /* gcFEATURE_BIT_NN_SP_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_SEPARATE_STREAMBUF_ADDR */
+        0x0, /* gcFEATURE_BIT_NN_TF32_MAC */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -1666,10 +1786,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -1704,20 +1824,46 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
+        0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
         0x0, /* gcFEATURE_BIT_VZ_GROUP_START_Z_OVERFLOW_FIX */
         0x0, /* gcFEATURE_BIT_V82_STREAMMODE_VIPSRAM_ADDRESS_FIX */
+        0x0, /* gcFEATURE_BIT_GEMM_NO_SUPPORT_SMALLBATCH_FIX */
+        0x0, /* gcFEATURE_BIT_SBP1_KHEAD_CMDSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_BURSTCOLLECTOR_MAXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
+        0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_PRE_CORE_LOTS_ZEROSKIP_KERNEL_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_MATRIX_A_TRSP1_CHNUM_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_4BIT_SBP2_BLOCKCTRL2_FIX */
+        0x0, /* gcFEATURE_BIT_B2B_RETRUN_NN_CMD_DONE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_VLW_3D_TILE_INFO_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_SPECIAL_WORDSIZE_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -1794,7 +1940,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_TPEngine_PwlLUTCount */
         0x0, /* gcFEATURE_VALUE_TPEngine_PwlLUTSize */
         0x0, /* gcFEATURE_VALUE_VIP_SRAM_SIZE */
-        0x0, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
+        {0x0, }, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
         0x0, /* gcFEATURE_VALUE_TPEngine_CoreCount */
         0x0, /* gcFEATURE_VALUE_AXI_SRAM_SIZE */
         0x0, /* gcFEATURE_VALUE_NN_INIMAGE_OFFSET_BITS */
@@ -1811,6 +1957,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_EQUIVALENT_VIP_SRAM_WIDTH_INBYTE */
         0x0, /* gcFEATURE_VALUE_TP_ZRL_BITS */
         0x0, /* gcFEATURE_VALUE_NN_ZRL_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_ZRL_VALID_ZERO_NUMBER */
         0x0, /* gcFEATURE_VALUE_LATENCY_HIDING_AT_FULL_AXI_BW */
         0x0, /* gcFEATURE_VALUE_AXI_BUS_WIDTH */
         0x0, /* gcFEATURE_VALUE_NN_KERNEL_X_SIZE */
@@ -1839,6 +1986,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_NN_SMALL_ACCUM_BITS */
         0x0, /* gcFEATURE_VALUE_NN_COEF_DECOMPRESS_PERF_X */
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
+        0x0, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
+        0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x0, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -2247,18 +2399,35 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_HIGHP_VEC2 */
         0x0, /* gcFEATURE_BIT_MMU_PD_42_BIT_ADDRESS */
         0x0, /* gcFEATURE_BIT_BLT_ROBUSTNESS_FIX */
+        0x0, /* gcFEATURE_BIT_BLT_OUT_OF_BOUND_FIX */
         0x0, /* gcFEATURE_BIT_TFB_PERF_FIX */
         0x0, /* gcFEATURE_BIT_SH_SUPERSCALAR_ARCH */
         0x0, /* gcFEATURE_BIT_PA_ZEROAREA_LINE_FIX */
+        0x0, /* gcFEATURE_BIT_RS_TILER_YUV420_FIX */
         0x0, /* gcFEATURE_BIT_ATTR_IN_GLOBAL_MEMORY */
         0x0, /* gcFEATURE_BIT_SIMPLIFIED_CHECKERBOARD */
         0x0, /* gcFEATURE_BIT_ADDR_REMAP */
         0x0, /* gcFEATURE_BIT_ADDR_40BIT_OVERFLOW_FIX */
         0x0, /* gcFEATURE_BIT_CLIP_DISTANCE_SUPPORT */
         0x0, /* gcFEATURE_BIT_SEPARATED_TEXTURE_SAMPLER */
+        0x0, /* gcFEATURE_BIT_TS_INFO_IN_TX_DESCRIPTOR */
         0x0, /* gcFEATURE_BIT_PER_STAGE_LOCAL_STORAGE */
         0x0, /* gcFEATURE_BIT_DX11_FORMAT_SUPPORT */
         0x0, /* gcFEATURE_BIT_OCCLUSION_SAMPLE_COUNTER */
+        0x0, /* gcFEATURE_BIT_FRONT_FACE_UINT */
+        0x0, /* gcFEATURE_BIT_DYNAMIC_TEXTURE_INDEXING */
+        0x0, /* gcFEATURE_BIT_D3D11_SUPPORT */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
+        0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -2323,10 +2492,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_REMOVE_POOLING */
         0x0, /* gcFEATURE_BIT_NN_40BIT_BIAS */
         0x0, /* gcFEATURE_BIT_TP_REMOVE_USC */
+        0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
+        0x0, /* gcFEATURE_BIT_NN_ZDP9 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x0, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
-        0x0, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_XYDP6 */
         0x0, /* gcFEATURE_BIT_SWTILING_PHASE3 */
         0x0, /* gcFEATURE_BIT_MCFE */
@@ -2432,16 +2602,38 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_CLAMP_BORDER_MODE */
         0x0, /* gcFEATURE_BIT_NN_ELEMENTWISE_BROADCAST_STRIDE_X_0 */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMAGE_DATA_TYPE */
+        0x0, /* gcFEATURE_BIT_FP_INIMAGE_POST_SCALE */
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
-        0x0, /* gcFEATURE_BIT_NN_FP8 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
+        0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
         0x0, /* gcFEATURE_BIT_SUPPORT_BATCH_ALIGNMENT */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
+        0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SH_IN_PARALLEL */
+        0x0, /* gcFEATURE_BIT_NN_ASYNC_DMA */
+        0x0, /* gcFEATURE_BIT_NN_STRIDE2_FAST_XDP3 */
+        0x0, /* gcFEATURE_BIT_NN_2V4_STRUCTURED_SPARSITY */
+        0x0, /* gcFEATURE_BIT_NN_SP_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_SEPARATE_STREAMBUF_ADDR */
+        0x0, /* gcFEATURE_BIT_NN_TF32_MAC */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -2502,10 +2694,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x1, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x0, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x0, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x0, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -2540,20 +2732,46 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x0, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x0, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x0, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x0, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
+        0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x0, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x0, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x0, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
         0x0, /* gcFEATURE_BIT_VZ_GROUP_START_Z_OVERFLOW_FIX */
         0x0, /* gcFEATURE_BIT_V82_STREAMMODE_VIPSRAM_ADDRESS_FIX */
+        0x0, /* gcFEATURE_BIT_GEMM_NO_SUPPORT_SMALLBATCH_FIX */
+        0x0, /* gcFEATURE_BIT_SBP1_KHEAD_CMDSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_BURSTCOLLECTOR_MAXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
+        0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_PRE_CORE_LOTS_ZEROSKIP_KERNEL_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_MATRIX_A_TRSP1_CHNUM_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_4BIT_SBP2_BLOCKCTRL2_FIX */
+        0x0, /* gcFEATURE_BIT_B2B_RETRUN_NN_CMD_DONE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_VLW_3D_TILE_INFO_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_SPECIAL_WORDSIZE_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
@@ -2568,23 +2786,23 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_NONZERO_MIRROR_BORDER */
         0x0, /* gcFEATURE_BIT_IMAGE_PARTIAL_CACHE */
     },
-    /* GCNANOULTRA31_VIP2 */
+    /* GC8000NANOULTRA31_vip1 */
     {
-        0x7000, /* ChipID */
-        0x6204, /* ChipRevision */
-        0x70007, /* ProductID */
+        0x8000, /* ChipID */
+        0x6207, /* ChipRevision */
+        0xa080007, /* ProductID */
         0x0, /* EcoID */
-        0x13, /* CustomerID */
+        0x19, /* CustomerID */
         0x0, /* PatchVersion */
-        "GCNANOULTRA31_VIP2", /* ProductName */
+        "GC8000NANOULTRA31_vip1", /* ProductName */
         0x0, /* FormalRelease */
         0x40, /* gcFEATURE_VALUE_TempRegisters */
         0x200, /* gcFEATURE_VALUE_ThreadCount */
-        0x2, /* gcFEATURE_VALUE_NumShaderCores */
+        0x1, /* gcFEATURE_VALUE_NumShaderCores */
         0x200, /* gcFEATURE_VALUE_InstructionCount */
         0x140, /* gcFEATURE_VALUE_NumberOfConstants */
         0x1, /* gcFEATURE_VALUE_CoreCount */
-        0x10, /* gcFEATURE_VALUE_LocalStorageSize */
+        0x8, /* gcFEATURE_VALUE_LocalStorageSize */
         0x0, /* gcFEATURE_VALUE_LocalStorageSize_1 */
         0x0, /* gcFEATURE_VALUE_LocalStorageSize_2 */
         0x8, /* gcFEATURE_VALUE_L1CacheSize */
@@ -2592,19 +2810,19 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_L1CacheSize_2 */
         0x200, /* gcFEATURE_VALUE_InstructionMemorySize */
         0x14, /* gcFEATURE_VALUE_ShaderPCLength */
-        0x10, /* gcFEATURE_VALUE_USC_MAX_PAGES */
+        0x8, /* gcFEATURE_VALUE_USC_MAX_PAGES */
         0x0, /* gcFEATURE_VALUE_USC_MAX_PAGES_1 */
         0x0, /* gcFEATURE_VALUE_USC_MAX_PAGES_2 */
         0x1, /* gcFEATURE_VALUE_NumPixelPipes */
-        0x2, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS */
+        0x1, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS */
         0x0, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS_1 */
         0x0, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS_2 */
-        0x2, /* gcFEATURE_VALUE_USC_BANKS */
+        0x1, /* gcFEATURE_VALUE_USC_BANKS */
         0x0, /* gcFEATURE_VALUE_USC_BANKS_1 */
         0x0, /* gcFEATURE_VALUE_USC_BANKS_2 */
         0x20, /* gcFEATURE_VALUE_VIRTUAL_ADDRESS_BITS */
         0x0, /* gcFEATURE_VALUE_PHYSICAL_ADDRESS_BITS */
-        0x10, /* gcFEATURE_VALUE_Streams */
+        0x8, /* gcFEATURE_VALUE_Streams */
         0x10, /* gcFEATURE_VALUE_VaryingCount */
         0x400, /* gcFEATURE_VALUE_VertexOutputBufferSize */
         0x0, /* gcFEATURE_VALUE_BufferSize */
@@ -2621,44 +2839,45 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x2, /* gcFEATURE_VALUE_NNCoreCount */
         0x2, /* gcFEATURE_VALUE_NN_ACTIVE_CORE_COUNT */
         0x2, /* gcFEATURE_VALUE_NNCoreCount_INT8 */
-        0x0, /* gcFEATURE_VALUE_NNCoreCount_INT16 */
+        0x2, /* gcFEATURE_VALUE_NNCoreCount_INT16 */
         0x0, /* gcFEATURE_VALUE_NNCoreCount_UINT16 */
         0x0, /* gcFEATURE_VALUE_NNCoreCount_FLOAT16 */
         0x0, /* gcFEATURE_VALUE_NNCoreCount_BFLOAT */
-        0x6, /* gcFEATURE_VALUE_NNInputBufferDepth */
-        0x40, /* gcFEATURE_VALUE_NNAccumBufferDepth */
+        0x9, /* gcFEATURE_VALUE_NNInputBufferDepth */
+        0x20, /* gcFEATURE_VALUE_NNAccumBufferDepth */
         0x400, /* gcFEATURE_VALUE_TPEngine_PwlLUTCount */
         0x10, /* gcFEATURE_VALUE_TPEngine_PwlLUTSize */
-        0x200, /* gcFEATURE_VALUE_VIP_SRAM_SIZE */
-        0x0, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
-        0x1, /* gcFEATURE_VALUE_TPEngine_CoreCount */
+        0x20000, /* gcFEATURE_VALUE_VIP_SRAM_SIZE */
+        {0x0, }, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
+        0x0, /* gcFEATURE_VALUE_TPEngine_CoreCount */
         0x0, /* gcFEATURE_VALUE_AXI_SRAM_SIZE */
-        0x4, /* gcFEATURE_VALUE_NN_INIMAGE_OFFSET_BITS */
-        0x180, /* gcFEATURE_VALUE_TP_REORDER_INIMAGE_SIZE */
-        0x7, /* gcFEATURE_VALUE_TPLite_CoreCount */
-        0x0, /* gcFEATURE_VALUE_NN_PREPROCESSOR_MAX_SEGMENT_PER_CYCLE */
-        0x1, /* gcFEATURE_VALUE_NNFP16_XYDP_X */
-        0x1, /* gcFEATURE_VALUE_NNFP16_XYDP_Y */
-        0x1, /* gcFEATURE_VALUE_NNFP16_ZDP */
-        0x8, /* gcFEATURE_VALUE_NN_LANES_PER_OUT_CYCLE */
-        0x0, /* gcFEATURE_VALUE_LUT_ACT_LANES */
-        0x20, /* gcFEATURE_VALUE_MAX_OT_NUMBER */
-        0x20, /* gcFEATURE_VALUE_PHYSICAL_VIP_SRAM_WIDTH_IN_BYTE */
-        0x20, /* gcFEATURE_VALUE_EQUIVALENT_VIP_SRAM_WIDTH_INBYTE */
+        0x5, /* gcFEATURE_VALUE_NN_INIMAGE_OFFSET_BITS */
+        0x200, /* gcFEATURE_VALUE_TP_REORDER_INIMAGE_SIZE */
+        0x0, /* gcFEATURE_VALUE_TPLite_CoreCount */
+        0x4, /* gcFEATURE_VALUE_NN_PREPROCESSOR_MAX_SEGMENT_PER_CYCLE */
+        0x0, /* gcFEATURE_VALUE_NNFP16_XYDP_X */
+        0x0, /* gcFEATURE_VALUE_NNFP16_XYDP_Y */
+        0x0, /* gcFEATURE_VALUE_NNFP16_ZDP */
+        0x10, /* gcFEATURE_VALUE_NN_LANES_PER_OUT_CYCLE */
+        0x4, /* gcFEATURE_VALUE_LUT_ACT_LANES */
+        0x40, /* gcFEATURE_VALUE_MAX_OT_NUMBER */
+        0x40, /* gcFEATURE_VALUE_PHYSICAL_VIP_SRAM_WIDTH_IN_BYTE */
+        0x10, /* gcFEATURE_VALUE_EQUIVALENT_VIP_SRAM_WIDTH_INBYTE */
         0x8, /* gcFEATURE_VALUE_TP_ZRL_BITS */
         0x8, /* gcFEATURE_VALUE_NN_ZRL_BITS */
-        0x0, /* gcFEATURE_VALUE_LATENCY_HIDING_AT_FULL_AXI_BW */
-        0x0, /* gcFEATURE_VALUE_AXI_BUS_WIDTH */
-        0xb, /* gcFEATURE_VALUE_NN_KERNEL_X_SIZE */
-        0xb, /* gcFEATURE_VALUE_NN_KERNEL_Y_SIZE */
+        0x0, /* gcFEATURE_VALUE_NN_ZRL_VALID_ZERO_NUMBER */
+        0x80, /* gcFEATURE_VALUE_LATENCY_HIDING_AT_FULL_AXI_BW */
+        0x10, /* gcFEATURE_VALUE_AXI_BUS_WIDTH */
+        0xf, /* gcFEATURE_VALUE_NN_KERNEL_X_SIZE */
+        0xf, /* gcFEATURE_VALUE_NN_KERNEL_Y_SIZE */
         0xf, /* gcFEATURE_VALUE_NN_FC_KERNEL_Y_SIZE */
         0xfffff, /* gcFEATURE_VALUE_NN_KERNEL_Z_SIZE */
-        0xf, /* gcFEATURE_VALUE_NN_X_OFFSET */
-        0xf, /* gcFEATURE_VALUE_NN_Y_OFFSET */
-        0x40, /* gcFEATURE_VALUE_DDR_KERNEL_BURST_SIZE */
-        0x40, /* gcFEATURE_VALUE_MIN_AXI_BURST_SIZE */
+        0x1f, /* gcFEATURE_VALUE_NN_X_OFFSET */
+        0x1f, /* gcFEATURE_VALUE_NN_Y_OFFSET */
+        0x100, /* gcFEATURE_VALUE_DDR_KERNEL_BURST_SIZE */
+        0x100, /* gcFEATURE_VALUE_MIN_AXI_BURST_SIZE */
         0x10, /* gcFEATURE_VALUE_OUTIMAGE_X_STRIDE_BITS */
-        0x0, /* gcFEATURE_VALUE_OUTIMAGE_Y_STRIDE_BITS */
+        0x10, /* gcFEATURE_VALUE_OUTIMAGE_Y_STRIDE_BITS */
         0x0, /* gcFEATURE_VALUE_OUTIMAGE_SLICE_BITS */
         0xd, /* gcFEATURE_VALUE_OUTIMAGE_X_SIZE_BITS */
         0xd, /* gcFEATURE_VALUE_OUTIMAGE_Y_SIZE_BITS */
@@ -2668,13 +2887,18 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_VALUE_INIMAGE_SLICE_BITS */
         0xd, /* gcFEATURE_VALUE_INIMAGE_X_SIZE_BITS */
         0xd, /* gcFEATURE_VALUE_INIMAGE_Y_SIZE_BITS */
-        0x40, /* gcFEATURE_VALUE_MAX_TILE_X_SIZE */
+        0x80, /* gcFEATURE_VALUE_MAX_TILE_X_SIZE */
         0x1, /* gcFEATURE_VALUE_NN_CLUSTER_NUM_FOR_POWER_CONTROL */
-        0x0, /* gcFEATURE_VALUE_NN_IN_LINES_PER_CYCLE */
+        0x3, /* gcFEATURE_VALUE_NN_IN_LINES_PER_CYCLE */
         0x0, /* gcFEATURE_VALUE_NN_MP_INTER_CONNECT_RING_COUNT */
         0x20, /* gcFEATURE_VALUE_NN_SMALL_ACCUM_BITS */
-        0x1, /* gcFEATURE_VALUE_NN_COEF_DECOMPRESS_PERF_X */
+        0x2, /* gcFEATURE_VALUE_NN_COEF_DECOMPRESS_PERF_X */
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
+        0x32, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
+        0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x0, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x0, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -3045,7 +3269,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_PA_LINECLIP_FIX */
         0x1, /* gcFEATURE_BIT_TX_8bit_UVFrac_ROUNDING_FIX */
         0x0, /* gcFEATURE_BIT_MP_ARCH */
-        0x0, /* gcFEATURE_BIT_TX_NO_FIXED_FILTER */
+        0x1, /* gcFEATURE_BIT_TX_NO_FIXED_FILTER */
         0x0, /* gcFEATURE_BIT_SHARE_Z */
         0x0, /* gcFEATURE_BIT_DE_2D_FAST_CLEAR */
         0x0, /* gcFEATURE_BIT_DE_TILESTATUS_ROTATION_FIX */
@@ -3058,7 +3282,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_AXIFE */
         0x0, /* gcFEATURE_BIT_SH_VX2_FLOATING_MAD_FIX */
         0x0, /* gcFEATURE_BIT_TS_FC_VULKAN_SUPPORT */
-        0x1, /* gcFEATURE_BIT_MSAA_FLOAT_64BIT */
+        0x0, /* gcFEATURE_BIT_MSAA_FLOAT_64BIT */
         0x0, /* gcFEATURE_BIT_INDIRECT_COMPUTE_ZERODIM_FIX */
         0x0, /* gcFEATURE_BIT_Q_CHANNEL_SUPPORT */
         0x0, /* gcFEATURE_BIT_MMU_PAGE_DESCRIPTOR */
@@ -3075,7 +3299,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_GPU_INSPECTOR_COUNTERS */
         0x0, /* gcFEATURE_BIT_FP32_TO_FP16_CONV_FIX */
         0x0, /* gcFEATURE_BIT_IMGLD_COMP_COUNT_FIX */
-        0x1, /* gcFEATURE_BIT_IMGLD_WIDTH_LT16_FIX */
+        0x0, /* gcFEATURE_BIT_IMGLD_WIDTH_LT16_FIX */
         0x0, /* gcFEATURE_BIT_TX_FILTER_ROUND_FIX */
         0x0, /* gcFEATURE_BIT_SH_FP32_FMA_SUPPORT */
         0x0, /* gcFEATURE_BIT_PE_64BPP_LINEAR_FORMAT */
@@ -3083,18 +3307,35 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_HIGHP_VEC2 */
         0x0, /* gcFEATURE_BIT_MMU_PD_42_BIT_ADDRESS */
         0x0, /* gcFEATURE_BIT_BLT_ROBUSTNESS_FIX */
+        0x0, /* gcFEATURE_BIT_BLT_OUT_OF_BOUND_FIX */
         0x0, /* gcFEATURE_BIT_TFB_PERF_FIX */
         0x0, /* gcFEATURE_BIT_SH_SUPERSCALAR_ARCH */
         0x0, /* gcFEATURE_BIT_PA_ZEROAREA_LINE_FIX */
+        0x0, /* gcFEATURE_BIT_RS_TILER_YUV420_FIX */
         0x0, /* gcFEATURE_BIT_ATTR_IN_GLOBAL_MEMORY */
         0x0, /* gcFEATURE_BIT_SIMPLIFIED_CHECKERBOARD */
         0x0, /* gcFEATURE_BIT_ADDR_REMAP */
         0x0, /* gcFEATURE_BIT_ADDR_40BIT_OVERFLOW_FIX */
         0x0, /* gcFEATURE_BIT_CLIP_DISTANCE_SUPPORT */
         0x0, /* gcFEATURE_BIT_SEPARATED_TEXTURE_SAMPLER */
+        0x0, /* gcFEATURE_BIT_TS_INFO_IN_TX_DESCRIPTOR */
         0x0, /* gcFEATURE_BIT_PER_STAGE_LOCAL_STORAGE */
         0x0, /* gcFEATURE_BIT_DX11_FORMAT_SUPPORT */
         0x0, /* gcFEATURE_BIT_OCCLUSION_SAMPLE_COUNTER */
+        0x0, /* gcFEATURE_BIT_FRONT_FACE_UINT */
+        0x0, /* gcFEATURE_BIT_DYNAMIC_TEXTURE_INDEXING */
+        0x0, /* gcFEATURE_BIT_D3D11_SUPPORT */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
+        0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -3124,8 +3365,8 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_VIP_HW_FINAL_RELEASE */
         0x1, /* gcFEATURE_BIT_NN_SINGLEPORT_ACCUMBUFFER */
         0x1, /* gcFEATURE_BIT_NN_STRIDE_SUPPORT */
-        0x0, /* gcFEATURE_BIT_SWTILING_PHASE1 */
-        0x0, /* gcFEATURE_BIT_SWTILING_PHASE2 */
+        0x1, /* gcFEATURE_BIT_SWTILING_PHASE1 */
+        0x1, /* gcFEATURE_BIT_SWTILING_PHASE2 */
         0x0, /* gcFEATURE_BIT_TP_SIMPLE_INT16 */
         0x1, /* gcFEATURE_BIT_TP_REAL_INT16 */
         0x1, /* gcFEATURE_BIT_TP_ROI_POOLING */
@@ -3133,7 +3374,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_TP_LRN */
         0x1, /* gcFEATURE_BIT_TP_REORDER */
         0x1, /* gcFEATURE_BIT_TF_QUANTIZATION */
-        0x0, /* gcFEATURE_BIT_NN_NONZERO_BORDER */
+        0x1, /* gcFEATURE_BIT_NN_NONZERO_BORDER */
         0x0, /* gcFEATURE_BIT_NN_MIRROR_BORDER */
         0x1, /* gcFEATURE_BIT_AI_GPU */
         0x0, /* gcFEATURE_BIT_EVIS_NO_ABSDIFF */
@@ -3159,99 +3400,100 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_REMOVE_POOLING */
         0x0, /* gcFEATURE_BIT_NN_40BIT_BIAS */
         0x0, /* gcFEATURE_BIT_TP_REMOVE_USC */
+        0x1, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
+        0x0, /* gcFEATURE_BIT_NN_ZDP9 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x1, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
-        0x1, /* gcFEATURE_BIT_NN_ZDP3 */
-        0x1, /* gcFEATURE_BIT_NN_XYDP6 */
-        0x0, /* gcFEATURE_BIT_SWTILING_PHASE3 */
+        0x0, /* gcFEATURE_BIT_NN_XYDP6 */
+        0x1, /* gcFEATURE_BIT_SWTILING_PHASE3 */
         0x0, /* gcFEATURE_BIT_MCFE */
         0x0, /* gcFEATURE_BIT_USC_STAY_LRU */
         0x1, /* gcFEATURE_BIT_COEF_COMPRESSION_ENHANCEMENT */
-        0x0, /* gcFEATURE_BIT_TP_COEF_COMPRESSION_ENHANCEMENT */
-        0x0, /* gcFEATURE_BIT_NN_COEF_DECOMPRESS_PERF2X */
-        0x0, /* gcFEATURE_BIT_TP_SMALLBATCH_PHASE1 */
+        0x1, /* gcFEATURE_BIT_TP_COEF_COMPRESSION_ENHANCEMENT */
+        0x1, /* gcFEATURE_BIT_NN_COEF_DECOMPRESS_PERF2X */
+        0x1, /* gcFEATURE_BIT_TP_SMALLBATCH_PHASE1 */
         0x1, /* gcFEATURE_BIT_OCB_COUNTER */
         0x0, /* gcFEATURE_BIT_SCALER */
         0x0, /* gcFEATURE_BIT_SCALER_4K */
         0x0, /* gcFEATURE_BIT_INPUT_4BIT */
-        0x0, /* gcFEATURE_BIT_NN_NO_Z_LOCATION_OFFSET */
-        0x0, /* gcFEATURE_BIT_OCB_REMAP_PHYSICAL_ADDRESS */
-        0x0, /* gcFEATURE_BIT_NN_SLOW_OUTPUT */
+        0x1, /* gcFEATURE_BIT_NN_NO_Z_LOCATION_OFFSET */
+        0x1, /* gcFEATURE_BIT_OCB_REMAP_PHYSICAL_ADDRESS */
+        0x1, /* gcFEATURE_BIT_NN_SLOW_OUTPUT */
         0x1, /* gcFEATURE_BIT_NO_NARROW_POST_PROCESS_PIPE */
-        0x0, /* gcFEATURE_BIT_TP_NN_PROBE */
-        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_SUPPORT */
-        0x0, /* gcFEATURE_BIT_NN_XYDP0 */
-        0x0, /* gcFEATURE_BIT_NN_WRITE_WITHOUT_USC */
-        0x0, /* gcFEATURE_BIT_NN_HW_LIMITATION_NATIVE_KER_1x2_2x1 */
-        0x0, /* gcFEATURE_BIT_NN_SMALLBATCH_PHASE1 */
-        0x0, /* gcFEATURE_BIT_NN_SLICE_PADDING_TO_64BYTE_ALIGN */
+        0x1, /* gcFEATURE_BIT_TP_NN_PROBE */
+        0x1, /* gcFEATURE_BIT_NN_DEPTHWISE_SUPPORT */
+        0x1, /* gcFEATURE_BIT_NN_XYDP0 */
+        0x1, /* gcFEATURE_BIT_NN_WRITE_WITHOUT_USC */
+        0x1, /* gcFEATURE_BIT_NN_HW_LIMITATION_NATIVE_KER_1x2_2x1 */
+        0x1, /* gcFEATURE_BIT_NN_SMALLBATCH_PHASE1 */
+        0x1, /* gcFEATURE_BIT_NN_SLICE_PADDING_TO_64BYTE_ALIGN */
         0x0, /* gcFEATURE_BIT_NN_DW_1x1_CONV_MERGE */
-        0x0, /* gcFEATURE_BIT_TP_BFLOAT16 */
+        0x1, /* gcFEATURE_BIT_TP_BFLOAT16 */
         0x0, /* gcFEATURE_BIT_TP_23BITS_POST_MULTIPLIER */
-        0x0, /* gcFEATURE_BIT_NN_TRANSPOSE */
+        0x1, /* gcFEATURE_BIT_NN_TRANSPOSE */
         0x0, /* gcFEATURE_BIT_NN_ZDP_TRANSPOSE_CH9_ONLY */
-        0x0, /* gcFEATURE_BIT_USE_SINGLE_PORT_VIPSRAM */
-        0x0, /* gcFEATURE_BIT_NN_LEAKY_RELU */
-        0x0, /* gcFEATURE_BIT_NN_PRELU */
-        0x0, /* gcFEATURE_BIT_NN_PER_CHANNEL_QUANT */
-        0x0, /* gcFEATURE_BIT_NN_PER_CHANNEL_QUANT_ASYM */
-        0x0, /* gcFEATURE_BIT_NN_ASYMMETRIC_INT8 */
-        0x0, /* gcFEATURE_BIT_NN_FLOAT_POST_MULT */
-        0x0, /* gcFEATURE_BIT_PRELU_LEAKLY_RELU_CLAMP */
-        0x0, /* gcFEATURE_BIT_TPLITE_BFLOAT16 */
-        0x0, /* gcFEATURE_BIT_PREPROCESS_IMG_BUF_640BYTE_LIMIT */
-        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_FP16 */
+        0x1, /* gcFEATURE_BIT_USE_SINGLE_PORT_VIPSRAM */
+        0x1, /* gcFEATURE_BIT_NN_LEAKY_RELU */
+        0x1, /* gcFEATURE_BIT_NN_PRELU */
+        0x1, /* gcFEATURE_BIT_NN_PER_CHANNEL_QUANT */
+        0x1, /* gcFEATURE_BIT_NN_PER_CHANNEL_QUANT_ASYM */
+        0x1, /* gcFEATURE_BIT_NN_ASYMMETRIC_INT8 */
+        0x1, /* gcFEATURE_BIT_NN_FLOAT_POST_MULT */
+        0x1, /* gcFEATURE_BIT_PRELU_LEAKLY_RELU_CLAMP */
+        0x1, /* gcFEATURE_BIT_TPLITE_BFLOAT16 */
+        0x1, /* gcFEATURE_BIT_PREPROCESS_IMG_BUF_640BYTE_LIMIT */
+        0x1, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_FP16 */
         0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_BF16 */
         0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_FP32 */
-        0x0, /* gcFEATURE_BIT_TP_KERNEL_1BYTE_ALGIN */
+        0x1, /* gcFEATURE_BIT_TP_KERNEL_1BYTE_ALGIN */
         0x0, /* gcFEATURE_BIT_BFLOAT_COEF_COMPRESSION_ZERO_COEFBIT14_INVERSE */
-        0x0, /* gcFEATURE_BIT_NN_COMPRESSION_BYPASSS */
+        0x1, /* gcFEATURE_BIT_NN_COMPRESSION_BYPASSS */
         0x0, /* gcFEATURE_BIT_TP_3_USC */
-        0x0, /* gcFEATURE_BIT_BFP_COEF_AUTO_PAD_INCOMPLETE_ZERO_IN_KZ_PLANE */
-        0x0, /* gcFEATURE_BIT_HW_V83 */
-        0x0, /* gcFEATURE_BIT_NN_NATIVE_STRIDE_TWO */
-        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD */
+        0x1, /* gcFEATURE_BIT_BFP_COEF_AUTO_PAD_INCOMPLETE_ZERO_IN_KZ_PLANE */
+        0x1, /* gcFEATURE_BIT_HW_V83 */
+        0x1, /* gcFEATURE_BIT_NN_NATIVE_STRIDE_TWO */
+        0x1, /* gcFEATURE_BIT_NN_TENSOR_ADD */
         0x0, /* gcFEATURE_BIT_NN_FLOAT32_IO */
-        0x0, /* gcFEATURE_BIT_TP_FLOAT32_IO */
-        0x0, /* gcFEATURE_BIT_NN_SMALL_BATCH_PHASE2 */
-        0x0, /* gcFEATURE_BIT_TILE_ACCESS_CAPABILITY */
-        0x0, /* gcFEATURE_BIT_FAST_DP3_PREPROCESSOR */
-        0x0, /* gcFEATURE_BIT_DEPTHWISE_SUPPORT_16BIT_FORMAT */
-        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ALU */
-        0x0, /* gcFEATURE_BIT_NN_ENHANCED_MAX_POOLING */
-        0x0, /* gcFEATURE_BIT_NN_TRANSPOSE_PHASE2 */
-        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_FIELD_MOVE_TO_EXT_CMD */
-        0x0, /* gcFEATURE_BIT_NN_CMD_SUPPORT_SLICE */
-        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_RELU */
+        0x1, /* gcFEATURE_BIT_TP_FLOAT32_IO */
+        0x1, /* gcFEATURE_BIT_NN_SMALL_BATCH_PHASE2 */
+        0x1, /* gcFEATURE_BIT_TILE_ACCESS_CAPABILITY */
+        0x1, /* gcFEATURE_BIT_FAST_DP3_PREPROCESSOR */
+        0x1, /* gcFEATURE_BIT_DEPTHWISE_SUPPORT_16BIT_FORMAT */
+        0x1, /* gcFEATURE_BIT_NN_SUPPORT_ALU */
+        0x1, /* gcFEATURE_BIT_NN_ENHANCED_MAX_POOLING */
+        0x1, /* gcFEATURE_BIT_NN_TRANSPOSE_PHASE2 */
+        0x1, /* gcFEATURE_BIT_NN_TENSOR_ADD_FIELD_MOVE_TO_EXT_CMD */
+        0x1, /* gcFEATURE_BIT_NN_CMD_SUPPORT_SLICE */
+        0x1, /* gcFEATURE_BIT_NN_TENSOR_ADD_RELU */
         0x0, /* gcFEATURE_BIT_TPLITE_SUPPORT_TP_DATA_TRANSPOSE */
-        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONV_1D */
-        0x0, /* gcFEATURE_BIT_USE_VIPSRAM_FOR_KERNEL_STREAMING */
-        0x0, /* gcFEATURE_BIT_NN_SUPPORT_DUMMY_TILE */
+        0x1, /* gcFEATURE_BIT_NN_SUPPORT_CONV_1D */
+        0x1, /* gcFEATURE_BIT_USE_VIPSRAM_FOR_KERNEL_STREAMING */
+        0x1, /* gcFEATURE_BIT_NN_SUPPORT_DUMMY_TILE */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_KERNEL_1BYTE_ALIGN */
-        0x0, /* gcFEATURE_BIT_NN_1x1_NON_POOLING_PACKING */
+        0x1, /* gcFEATURE_BIT_NN_1x1_NON_POOLING_PACKING */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_BOTH_CONV_NATIVE_STRIDE2_AND_POOLING */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONV1x1_AND_NATIVE_CONV_STRIDE2 */
         0x0, /* gcFEATURE_BIT_TP_REMOVE_FC */
         0x0, /* gcFEATURE_BIT_VIP_REMOVE_MMU */
-        0x0, /* gcFEATURE_BIT_NN_RD_IMG_NEED_EXTRA_SPACE */
-        0x0, /* gcFEATURE_BIT_VIP_INDIV_CLK_NN */
-        0x0, /* gcFEATURE_BIT_VIP_EXPORT_CLK_DIV2 */
+        0x1, /* gcFEATURE_BIT_NN_RD_IMG_NEED_EXTRA_SPACE */
+        0x1, /* gcFEATURE_BIT_VIP_INDIV_CLK_NN */
+        0x1, /* gcFEATURE_BIT_VIP_EXPORT_CLK_DIV2 */
         0x0, /* gcFEATURE_BIT_NN_2D_AVERAGE_OUTPUT */
-        0x0, /* gcFEATURE_BIT_NN_JOB_CANCELATION */
+        0x1, /* gcFEATURE_BIT_NN_JOB_CANCELATION */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_INLINE_NWHC_AND_MATRIX_TRANSPOSE */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_BATCH */
         0x0, /* gcFEATURE_BIT_VIP_SUPPORT_DEC */
-        0x0, /* gcFEATURE_BIT_NN_SUPPORT_MULTI_AXI_ID */
+        0x1, /* gcFEATURE_BIT_NN_SUPPORT_MULTI_AXI_ID */
         0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_INT32 */
         0x0, /* gcFEATURE_BIT_NN_DISTRIBUTED_VIPSRAM */
         0x0, /* gcFEATURE_BIT_NN_FC_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_4BIT_PHASE1 */
         0x0, /* gcFEATURE_BIT_VIP_DEC400 */
         0x0, /* gcFEATURE_BIT_NN_POST_MULT_SUPPORT_FP_CONV */
-        0x0, /* gcFEATURE_BIT_NN_SUPPORT_16_8_QUANTIZATION */
+        0x1, /* gcFEATURE_BIT_NN_SUPPORT_16_8_QUANTIZATION */
         0x0, /* gcFEATURE_BIT_SPECIAL_8BIT_SIGN_ABS_CONV */
-        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONFIGURABLE_FASTXDP3 */
+        0x1, /* gcFEATURE_BIT_NN_SUPPORT_CONFIGURABLE_FASTXDP3 */
         0x0, /* gcFEATURE_BIT_NN_USE_CORE_SHARING_IMGBUF_AND_SEQ_NO_ZEROSKIPPING */
         0x0, /* gcFEATURE_BIT_SUPPORT_DECONVNxN_S_LESS_THAN_16 */
         0x0, /* gcFEATURE_BIT_NN_PICOCORE_DEPTHWISE */
@@ -3268,80 +3510,102 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_CLAMP_BORDER_MODE */
         0x0, /* gcFEATURE_BIT_NN_ELEMENTWISE_BROADCAST_STRIDE_X_0 */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMAGE_DATA_TYPE */
+        0x0, /* gcFEATURE_BIT_FP_INIMAGE_POST_SCALE */
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
-        0x0, /* gcFEATURE_BIT_NN_FP8 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
+        0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
         0x0, /* gcFEATURE_BIT_SUPPORT_BATCH_ALIGNMENT */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
-        0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
-        0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
+        0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SH_IN_PARALLEL */
+        0x0, /* gcFEATURE_BIT_NN_ASYNC_DMA */
+        0x0, /* gcFEATURE_BIT_NN_STRIDE2_FAST_XDP3 */
+        0x0, /* gcFEATURE_BIT_NN_2V4_STRUCTURED_SPARSITY */
+        0x0, /* gcFEATURE_BIT_NN_SP_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_SEPARATE_STREAMBUF_ADDR */
+        0x0, /* gcFEATURE_BIT_NN_TF32_MAC */
+        0x1, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x1, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
         0x1, /* gcFEATURE_BIT_TP_REORDER_FIX */
         0x1, /* gcFEATURE_BIT_NN_CONVOUT_FIFO_DEPTH_FIX */
-        0x0, /* gcFEATURE_BIT_NN_ZXDP3_KERNEL_READ_CONFLICT_FIX */
+        0x1, /* gcFEATURE_BIT_NN_ZXDP3_KERNEL_READ_CONFLICT_FIX */
         0x1, /* gcFEATURE_BIT_NN_ZDP3_NO_COMPRESS_FIX */
         0x1, /* gcFEATURE_BIT_NN_ASYNC_COPY_PERF_FIX */
         0x1, /* gcFEATURE_BIT_HI_REORDER_FIX */
-        0x1, /* gcFEATURE_BIT_INCORRECT_WR_REQ_TO_USC_BETWEEN_REORDER_AND_NORMAL_LAYER_FIX */
-        0x0, /* gcFEATURE_BIT_TP_REORDER_LAYER_SUSPEND_FIX */
+        0x0, /* gcFEATURE_BIT_INCORRECT_WR_REQ_TO_USC_BETWEEN_REORDER_AND_NORMAL_LAYER_FIX */
+        0x1, /* gcFEATURE_BIT_TP_REORDER_LAYER_SUSPEND_FIX */
         0x1, /* gcFEATURE_BIT_NN_ASYNC_COPY_MERGE_FIX */
-        0x0, /* gcFEATURE_BIT_USC_INVALIDATE_CACHE_LINE_FIX */
-        0x0, /* gcFEATURE_BIT_NN_REQ_SLOWARBITRATION_FIX */
+        0x1, /* gcFEATURE_BIT_USC_INVALIDATE_CACHE_LINE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_REQ_SLOWARBITRATION_FIX */
         0x0, /* gcFEATURE_BIT_IMAGE_PARTIAL_CACHE_FIX */
-        0x0, /* gcFEATURE_BIT_FULLCACHE_KERNELHEAD_FIX */
-        0x0, /* gcFEATURE_BIT_NN_ZDP_INIMAGE_SIZE_FIX */
-        0x0, /* gcFEATURE_BIT_IDLE_BEFORE_FLUSH_COMPLETE_FIX */
-        0x0, /* gcFEATURE_BIT_NO_FLUSH_USC_FIX */
-        0x0, /* gcFEATURE_BIT_SMALL_BATCH_FLOPS_RESET_FIX */
-        0x1, /* gcFEATURE_BIT_SMALL_BATCH_DISBLE_FIX */
+        0x1, /* gcFEATURE_BIT_FULLCACHE_KERNELHEAD_FIX */
+        0x1, /* gcFEATURE_BIT_NN_ZDP_INIMAGE_SIZE_FIX */
+        0x1, /* gcFEATURE_BIT_IDLE_BEFORE_FLUSH_COMPLETE_FIX */
+        0x1, /* gcFEATURE_BIT_NO_FLUSH_USC_FIX */
+        0x1, /* gcFEATURE_BIT_SMALL_BATCH_FLOPS_RESET_FIX */
+        0x0, /* gcFEATURE_BIT_SMALL_BATCH_DISBLE_FIX */
         0x1, /* gcFEATURE_BIT_OUTPUT_CONVERT_UINT8_INT8_TO_UINT16_INT16_FIX */
-        0x0, /* gcFEATURE_BIT_IMAGE_NOT_PACKED_IN_SRAM_FIX */
-        0x0, /* gcFEATURE_BIT_COEF_DELTA_CORD_OVERFLOW_ZRL_8BIT_FIX */
-        0x0, /* gcFEATURE_BIT_USC_INDIVIDUAL_PORT_WRT_EARLY_EVICT_DATA_CORRUPT_FIX */
-        0x0, /* gcFEATURE_BIT_LOW_EFFICIENCY_OF_ID_WRITE_IMGBUF_FIX */
-        0x0, /* gcFEATURE_BIT_KERNEL_VIP_SRAM_READ_BW_LIMITATION_FIX */
-        0x0, /* gcFEATURE_BIT_USC_BOTTLENECK_FIX */
+        0x1, /* gcFEATURE_BIT_IMAGE_NOT_PACKED_IN_SRAM_FIX */
+        0x1, /* gcFEATURE_BIT_COEF_DELTA_CORD_OVERFLOW_ZRL_8BIT_FIX */
+        0x1, /* gcFEATURE_BIT_USC_INDIVIDUAL_PORT_WRT_EARLY_EVICT_DATA_CORRUPT_FIX */
+        0x1, /* gcFEATURE_BIT_LOW_EFFICIENCY_OF_ID_WRITE_IMGBUF_FIX */
+        0x1, /* gcFEATURE_BIT_KERNEL_VIP_SRAM_READ_BW_LIMITATION_FIX */
+        0x1, /* gcFEATURE_BIT_USC_BOTTLENECK_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_PER_CORE_LESS_THAN_THIRD_COEF_BUFF_DEPTH_FIX */
         0x1, /* gcFEATURE_BIT_NN_TILE_NUM_BIGGER_THAN_1024_FIX */
-        0x0, /* gcFEATURE_BIT_KERNEL_SIZE_WASTE_IN_PARTIAL_MODE_FIX */
-        0x0, /* gcFEATURE_BIT_NN_COMMAND_KERNEL_REQUEST_CONFICT_FIX */
-        0x0, /* gcFEATURE_BIT_TP_REORDER_INTILE_X_SIZE_512_FIX */
-        0x0, /* gcFEATURE_BIT_IMG_POP_PIPELINE_PAUSE_FIX */
-        0x0, /* gcFEATURE_BIT_FULLCACHE_KERNEL_INTERLEAVE_FIX */
+        0x1, /* gcFEATURE_BIT_KERNEL_SIZE_WASTE_IN_PARTIAL_MODE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_COMMAND_KERNEL_REQUEST_CONFICT_FIX */
+        0x1, /* gcFEATURE_BIT_TP_REORDER_INTILE_X_SIZE_512_FIX */
+        0x1, /* gcFEATURE_BIT_IMG_POP_PIPELINE_PAUSE_FIX */
+        0x1, /* gcFEATURE_BIT_FULLCACHE_KERNEL_INTERLEAVE_FIX */
         0x1, /* gcFEATURE_BIT_V8_SINGLE_PORT_ACCUMULATION_BUFFER_RW_CONFICT_ZERO_SKIP_PERF_FIX */
-        0x0, /* gcFEATURE_BIT_V8_ACCUMLATION_READ_OUT_HAS_BUBBLES_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_V8_ACCUMLATION_READ_OUT_HAS_BUBBLES_PERF_FIX */
         0x1, /* gcFEATURE_BIT_DEPTHWISE_NEIGHBOR_IMG_DATA_TRANSFER_NOT_EFFICIENT_FIX */
-        0x0, /* gcFEATURE_BIT_DR_JD_DIFF_CONDITION_FOR_CACHELINE_MODE_PRE_FIX */
-        0x0, /* gcFEATURE_BIT_TP_ACCESS_VIPSRAM_OT_IS_ONE_FIX */
-        0x0, /* gcFEATURE_BIT_EVIS2_FLOP_RESET_FIX */
-        0x0, /* gcFEATURE_BIT_OUTIMAGE_X_BITWIDTH_LIMIT_FOR_NN_TRANSPOSE_FIX */
-        0x0, /* gcFEATURE_BIT_USC_ASYNC_CP_RTN_FLOP_RESET_FIX */
-        0x0, /* gcFEATURE_BIT_IMG_ADDR_NOT_WRAP_IF_OVER_OCB_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NEGATIVE_POST_SHIFT_FIX */
-        0x0, /* gcFEATURE_BIT_INIMAGE_2DTILE_NOT_LESS_160PIXEL_FIX */
+        0x1, /* gcFEATURE_BIT_DR_JD_DIFF_CONDITION_FOR_CACHELINE_MODE_PRE_FIX */
+        0x1, /* gcFEATURE_BIT_TP_ACCESS_VIPSRAM_OT_IS_ONE_FIX */
+        0x1, /* gcFEATURE_BIT_EVIS2_FLOP_RESET_FIX */
+        0x1, /* gcFEATURE_BIT_OUTIMAGE_X_BITWIDTH_LIMIT_FOR_NN_TRANSPOSE_FIX */
+        0x1, /* gcFEATURE_BIT_USC_ASYNC_CP_RTN_FLOP_RESET_FIX */
+        0x1, /* gcFEATURE_BIT_IMG_ADDR_NOT_WRAP_IF_OVER_OCB_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_NEGATIVE_POST_SHIFT_FIX */
+        0x1, /* gcFEATURE_BIT_INIMAGE_2DTILE_NOT_LESS_160PIXEL_FIX */
         0x1, /* gcFEATURE_BIT_IMG_CAHCE_MODE_MUST_0_IN_IMG_DIRECT_MODE_FIX */
-        0x0, /* gcFEATURE_BIT_BURST_COLLECT_DUMMY_DATA_WASTE_CYCLES_FIX */
+        0x1, /* gcFEATURE_BIT_BURST_COLLECT_DUMMY_DATA_WASTE_CYCLES_FIX */
         0x1, /* gcFEATURE_BIT_INIMG_NOT_64BYTE_ALIGN_CACHELINE_MODE_FIX */
         0x1, /* gcFEATURE_BIT_TP_FC_FLOAT_LAST_PIXEL_NEGATIVE_0_FIX */
         0x1, /* gcFEATURE_BIT_NN_WASTE_COEF_READ_WRITE_BANDWIDTH_128BYTE_VIPSRAM_IN_FULL_PATIAL_CACHE_MODE_FIX */
         0x1, /* gcFEATURE_BIT_NN_IN_TILE_DATA_IS_ALL_PAD_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_INSTR_COMPLETE_IN_SAME_CYCLE_WITH_WAIT_EVENT_FIX */
-        0x1, /* gcFEATURE_BIT_CORE_IMAGE_TRANSER_NOT_EFFICIENT_BETWEEN_PARTITION_FIX */
+        0x1, /* gcFEATURE_BIT_NN_TP_INSTR_COMPLETE_IN_SAME_CYCLE_WITH_WAIT_EVENT_FIX */
+        0x0, /* gcFEATURE_BIT_CORE_IMAGE_TRANSER_NOT_EFFICIENT_BETWEEN_PARTITION_FIX */
         0x1, /* gcFEATURE_BIT_TP_FC_KERNEL_STREAM_MUST_LESS_THAN_OR_EQUAL_TO_64BYTE_WHEN_1BYTE_ALGINE_FIX */
-        0x0, /* gcFEATURE_BIT_NN_KERNEL_1x1_NO_PAD_FIX */
+        0x1, /* gcFEATURE_BIT_NN_KERNEL_1x1_NO_PAD_FIX */
         0x1, /* gcFEATURE_BIT_NN_DEPTHWISE_AFTER_16BIT_LAYER_LIMIT_FIX */
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x0, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
-        0x0, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x1, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x1, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x1, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x1, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x1, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x1, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x1, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -3349,68 +3613,94 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_NN_2ND_IMG_SMALL_3D_TILE_FIX */
         0x1, /* gcFEATURE_BIT_NN_TILE_YSIZE_127_LIMITATION_FIX */
         0x1, /* gcFEATURE_BIT_NN_CONV_1D_16BIT_FORMAT_INTILE_SIZE_LIMITATION_FIX */
-        0x1, /* gcFEATURE_BIT_NN_VIPSRAM_DOUBLE_BUFFER_FIX */
-        0x0, /* gcFEATURE_BIT_NN_JD_DIRECT_MODE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_VIPSRAM_DOUBLE_BUFFER_FIX */
+        0x1, /* gcFEATURE_BIT_NN_JD_DIRECT_MODE_FIX */
         0x1, /* gcFEATURE_BIT_NN_KERNEL_DIRECT_WRONG_PUSH_FIX */
         0x1, /* gcFEATURE_BIT_HI_DEFAULT_ENABLE_REORDER_FIX */
         0x1, /* gcFEATURE_BIT_V8_DIRECT_MODE_START_ADDR_BIAS_FOR_NEGATIVE_OFFSET_FIX */
         0x1, /* gcFEATURE_BIT_V83_INTILESIZE_1X1_10BITS_FIX */
-        0x0, /* gcFEATURE_BIT_FASTXDP3_ONLY_IN_DEPTHWISE_FIX */
+        0x1, /* gcFEATURE_BIT_FASTXDP3_ONLY_IN_DEPTHWISE_FIX */
         0x1, /* gcFEATURE_BIT_US_SRAM_READ_INTF_FIFO_OVERFLOW_FIX */
-        0x0, /* gcFEATURE_BIT_USC_PAUSE_TP_WR_REQ_MORE_THAN_256_CYCLES_FIX */
+        0x1, /* gcFEATURE_BIT_USC_PAUSE_TP_WR_REQ_MORE_THAN_256_CYCLES_FIX */
         0x1, /* gcFEATURE_BIT_DEPTHWISE_FLOAT_FIX */
-        0x0, /* gcFEATURE_BIT_TP_CIRCULAR_BUF_WRAP_ADDRESS_OVERFLOW_FIX */
-        0x0, /* gcFEATURE_BIT_NN_CIRCULAR_BUF_WRAP_ADDRESS_OVERFLOW_FIX */
+        0x1, /* gcFEATURE_BIT_TP_CIRCULAR_BUF_WRAP_ADDRESS_OVERFLOW_FIX */
+        0x1, /* gcFEATURE_BIT_NN_CIRCULAR_BUF_WRAP_ADDRESS_OVERFLOW_FIX */
         0x1, /* gcFEATURE_BIT_CLOCK_DIV2_FREQ_CHANGE_FIX */
         0x1, /* gcFEATURE_BIT_SMALL_TILE_TENSOR_ADD_FIX */
         0x1, /* gcFEATURE_BIT_DECOMPRESSOR_DEPTHWISE_FLOAT_FIX */
-        0x0, /* gcFEATURE_BIT_TP_CIRCULAR_BUF_WRAP_ADDRESS_LESS_FIX */
+        0x1, /* gcFEATURE_BIT_TP_CIRCULAR_BUF_WRAP_ADDRESS_LESS_FIX */
         0x1, /* gcFEATURE_BIT_V83_NUMOFPENDINGTILES_FOR_2NDIMAGE_FIX */
         0x1, /* gcFEATURE_BIT_V83_1ST_CACHE_MODE_VIPSRAM_RD_UPDATE_FIX */
         0x1, /* gcFEATURE_BIT_V83_1ST_KERNEL_STREAM_BUFFER_UPDATE_FIX */
         0x0, /* gcFEATURE_BIT_USC_RW_SAME_CACHELINE_UPDATE_FIX */
         0x1, /* gcFEATURE_BIT_NN_KERNEL_MSS_SBP2_DIRECT_STEAM_STEAM_FIX */
         0x1, /* gcFEATURE_BIT_CORE_NUM_OF_KID_FOR_MULTI_LAYER_FIX */
-        0x0, /* gcFEATURE_BIT_KERNEL_XSIZE_YSIZE_NUM_FIX */
+        0x1, /* gcFEATURE_BIT_KERNEL_XSIZE_YSIZE_NUM_FIX */
         0x1, /* gcFEATURE_BIT_IMGRD_ROW_NUMBER_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x0, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x1, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
-        0x1, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
+        0x0, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x1, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
-        0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x1, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x1, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x1, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
+        0x0, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x1, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x1, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x1, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x1, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x1, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
         0x1, /* gcFEATURE_BIT_VZ_GROUP_START_Z_OVERFLOW_FIX */
         0x1, /* gcFEATURE_BIT_V82_STREAMMODE_VIPSRAM_ADDRESS_FIX */
+        0x1, /* gcFEATURE_BIT_GEMM_NO_SUPPORT_SMALLBATCH_FIX */
+        0x0, /* gcFEATURE_BIT_SBP1_KHEAD_CMDSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_BURSTCOLLECTOR_MAXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
+        0x0, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x0, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x0, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_PRE_CORE_LOTS_ZEROSKIP_KERNEL_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_MATRIX_A_TRSP1_CHNUM_FIX */
+        0x0, /* gcFEATURE_BIT_FIX_4BIT_SBP2_BLOCKCTRL2_FIX */
+        0x0, /* gcFEATURE_BIT_B2B_RETRUN_NN_CMD_DONE_FIX */
+        0x0, /* gcFEATURE_BIT_MULTI_AXI_ID_VLW_3D_TILE_INFO_FIX */
+        0x0, /* gcFEATURE_BIT_TRSP2_SPECIAL_WORDSIZE_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
-        0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
-        0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
-        0x1, /* gcFEATURE_BIT_NN_INT8_SCALE */
-        0x1, /* gcFEATURE_BIT_NN_POWER_ISOLATION */
-        0x1, /* gcFEATURE_BIT_ZRL_7BIT */
+        0x1, /* gcFEATURE_BIT_NN_FP16_ALU */
+        0x1, /* gcFEATURE_BIT_NN_INT16_ALU */
+        0x0, /* gcFEATURE_BIT_NN_INT8_SCALE */
+        0x0, /* gcFEATURE_BIT_NN_POWER_ISOLATION */
+        0x0, /* gcFEATURE_BIT_ZRL_7BIT */
         0x0, /* gcFEATURE_BIT_NN_SMALLBATCH */
-        0x0, /* gcFEATURE_BIT_TP_SMALLBATCH */
-        0x1, /* gcFEATURE_BIT_ZRL_8BIT */
+        0x1, /* gcFEATURE_BIT_TP_SMALLBATCH */
+        0x0, /* gcFEATURE_BIT_ZRL_8BIT */
         0x0, /* gcFEATURE_BIT_DDR_BURST_LEN_256B */
         0x0, /* gcFEATURE_BIT_XY_OFFSET_LIMITATION_FIX */
-        0x0, /* gcFEATURE_BIT_NN_NONZERO_MIRROR_BORDER */
-        0x0, /* gcFEATURE_BIT_IMAGE_PARTIAL_CACHE */
+        0x1, /* gcFEATURE_BIT_NN_NONZERO_MIRROR_BORDER */
+        0x1, /* gcFEATURE_BIT_IMAGE_PARTIAL_CACHE */
     },
     /* GCNANOULTRA31_VIP2 */
     {
-        0x8000, /* ChipID */
-        0x6205, /* ChipRevision */
-        0x80003, /* ProductID */
+        0x7000, /* ChipID */
+        0x6204, /* ChipRevision */
+        0x70007, /* ProductID */
         0x0, /* EcoID */
-        0x15, /* CustomerID */
+        0x13, /* CustomerID */
         0x0, /* PatchVersion */
         "GCNANOULTRA31_VIP2", /* ProductName */
         0x0, /* FormalRelease */
@@ -3457,7 +3747,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x2, /* gcFEATURE_VALUE_NNCoreCount */
         0x2, /* gcFEATURE_VALUE_NN_ACTIVE_CORE_COUNT */
         0x2, /* gcFEATURE_VALUE_NNCoreCount_INT8 */
-        0x2, /* gcFEATURE_VALUE_NNCoreCount_INT16 */
+        0x0, /* gcFEATURE_VALUE_NNCoreCount_INT16 */
         0x0, /* gcFEATURE_VALUE_NNCoreCount_UINT16 */
         0x0, /* gcFEATURE_VALUE_NNCoreCount_FLOAT16 */
         0x0, /* gcFEATURE_VALUE_NNCoreCount_BFLOAT */
@@ -3465,8 +3755,8 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x40, /* gcFEATURE_VALUE_NNAccumBufferDepth */
         0x400, /* gcFEATURE_VALUE_TPEngine_PwlLUTCount */
         0x10, /* gcFEATURE_VALUE_TPEngine_PwlLUTSize */
-        0x20000, /* gcFEATURE_VALUE_VIP_SRAM_SIZE */
-        0x0, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
+        0x200, /* gcFEATURE_VALUE_VIP_SRAM_SIZE */
+        {0x0, }, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
         0x1, /* gcFEATURE_VALUE_TPEngine_CoreCount */
         0x0, /* gcFEATURE_VALUE_AXI_SRAM_SIZE */
         0x4, /* gcFEATURE_VALUE_NN_INIMAGE_OFFSET_BITS */
@@ -3479,12 +3769,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x8, /* gcFEATURE_VALUE_NN_LANES_PER_OUT_CYCLE */
         0x0, /* gcFEATURE_VALUE_LUT_ACT_LANES */
         0x20, /* gcFEATURE_VALUE_MAX_OT_NUMBER */
-        0x40, /* gcFEATURE_VALUE_PHYSICAL_VIP_SRAM_WIDTH_IN_BYTE */
+        0x20, /* gcFEATURE_VALUE_PHYSICAL_VIP_SRAM_WIDTH_IN_BYTE */
         0x20, /* gcFEATURE_VALUE_EQUIVALENT_VIP_SRAM_WIDTH_INBYTE */
         0x8, /* gcFEATURE_VALUE_TP_ZRL_BITS */
         0x8, /* gcFEATURE_VALUE_NN_ZRL_BITS */
-        0x80, /* gcFEATURE_VALUE_LATENCY_HIDING_AT_FULL_AXI_BW */
-        0x10, /* gcFEATURE_VALUE_AXI_BUS_WIDTH */
+        0x100, /* gcFEATURE_VALUE_NN_ZRL_VALID_ZERO_NUMBER */
+        0x0, /* gcFEATURE_VALUE_LATENCY_HIDING_AT_FULL_AXI_BW */
+        0x0, /* gcFEATURE_VALUE_AXI_BUS_WIDTH */
         0xb, /* gcFEATURE_VALUE_NN_KERNEL_X_SIZE */
         0xb, /* gcFEATURE_VALUE_NN_KERNEL_Y_SIZE */
         0xf, /* gcFEATURE_VALUE_NN_FC_KERNEL_Y_SIZE */
@@ -3511,6 +3802,11 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x20, /* gcFEATURE_VALUE_NN_SMALL_ACCUM_BITS */
         0x1, /* gcFEATURE_VALUE_NN_COEF_DECOMPRESS_PERF_X */
         0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
+        0x64, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
+        0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x10, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x3, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
         0x1, /* gcFEATURE_BIT_REG_FastClear */
         0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
         0x1, /* gcFEATURE_BIT_REG_Pipe3D */
@@ -3892,7 +4188,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_FORMAT_P010LSB_I010 */
         0x0, /* gcFEATURE_BIT_ENDIAN_CONTROL */
         0x0, /* gcFEATURE_BIT_AXIFE */
-        0x1, /* gcFEATURE_BIT_SH_VX2_FLOATING_MAD_FIX */
+        0x0, /* gcFEATURE_BIT_SH_VX2_FLOATING_MAD_FIX */
         0x0, /* gcFEATURE_BIT_TS_FC_VULKAN_SUPPORT */
         0x1, /* gcFEATURE_BIT_MSAA_FLOAT_64BIT */
         0x0, /* gcFEATURE_BIT_INDIRECT_COMPUTE_ZERODIM_FIX */
@@ -3919,18 +4215,35 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_HIGHP_VEC2 */
         0x0, /* gcFEATURE_BIT_MMU_PD_42_BIT_ADDRESS */
         0x0, /* gcFEATURE_BIT_BLT_ROBUSTNESS_FIX */
+        0x0, /* gcFEATURE_BIT_BLT_OUT_OF_BOUND_FIX */
         0x0, /* gcFEATURE_BIT_TFB_PERF_FIX */
         0x0, /* gcFEATURE_BIT_SH_SUPERSCALAR_ARCH */
         0x0, /* gcFEATURE_BIT_PA_ZEROAREA_LINE_FIX */
+        0x0, /* gcFEATURE_BIT_RS_TILER_YUV420_FIX */
         0x0, /* gcFEATURE_BIT_ATTR_IN_GLOBAL_MEMORY */
         0x0, /* gcFEATURE_BIT_SIMPLIFIED_CHECKERBOARD */
         0x0, /* gcFEATURE_BIT_ADDR_REMAP */
         0x0, /* gcFEATURE_BIT_ADDR_40BIT_OVERFLOW_FIX */
         0x0, /* gcFEATURE_BIT_CLIP_DISTANCE_SUPPORT */
         0x0, /* gcFEATURE_BIT_SEPARATED_TEXTURE_SAMPLER */
+        0x0, /* gcFEATURE_BIT_TS_INFO_IN_TX_DESCRIPTOR */
         0x0, /* gcFEATURE_BIT_PER_STAGE_LOCAL_STORAGE */
         0x0, /* gcFEATURE_BIT_DX11_FORMAT_SUPPORT */
         0x0, /* gcFEATURE_BIT_OCCLUSION_SAMPLE_COUNTER */
+        0x0, /* gcFEATURE_BIT_FRONT_FACE_UINT */
+        0x0, /* gcFEATURE_BIT_DYNAMIC_TEXTURE_INDEXING */
+        0x0, /* gcFEATURE_BIT_D3D11_SUPPORT */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
+        0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
         0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
         0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
@@ -3960,7 +4273,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_VIP_HW_FINAL_RELEASE */
         0x1, /* gcFEATURE_BIT_NN_SINGLEPORT_ACCUMBUFFER */
         0x1, /* gcFEATURE_BIT_NN_STRIDE_SUPPORT */
-        0x1, /* gcFEATURE_BIT_SWTILING_PHASE1 */
+        0x0, /* gcFEATURE_BIT_SWTILING_PHASE1 */
         0x0, /* gcFEATURE_BIT_SWTILING_PHASE2 */
         0x0, /* gcFEATURE_BIT_TP_SIMPLE_INT16 */
         0x1, /* gcFEATURE_BIT_TP_REAL_INT16 */
@@ -3969,7 +4282,7 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_TP_LRN */
         0x1, /* gcFEATURE_BIT_TP_REORDER */
         0x1, /* gcFEATURE_BIT_TF_QUANTIZATION */
-        0x0, /* gcFEATURE_BIT_NN_NONZERO_BORDER */
+        0x1, /* gcFEATURE_BIT_NN_NONZERO_BORDER */
         0x0, /* gcFEATURE_BIT_NN_MIRROR_BORDER */
         0x1, /* gcFEATURE_BIT_AI_GPU */
         0x0, /* gcFEATURE_BIT_EVIS_NO_ABSDIFF */
@@ -3995,12 +4308,13 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_REMOVE_POOLING */
         0x0, /* gcFEATURE_BIT_NN_40BIT_BIAS */
         0x0, /* gcFEATURE_BIT_TP_REMOVE_USC */
+        0x1, /* gcFEATURE_BIT_NN_ZDP3 */
         0x0, /* gcFEATURE_BIT_NN_ZDP6 */
+        0x0, /* gcFEATURE_BIT_NN_ZDP9 */
         0x0, /* gcFEATURE_BIT_NN_XYDP9 */
         0x1, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
-        0x1, /* gcFEATURE_BIT_NN_ZDP3 */
         0x1, /* gcFEATURE_BIT_NN_XYDP6 */
-        0x1, /* gcFEATURE_BIT_SWTILING_PHASE3 */
+        0x0, /* gcFEATURE_BIT_SWTILING_PHASE3 */
         0x0, /* gcFEATURE_BIT_MCFE */
         0x0, /* gcFEATURE_BIT_USC_STAY_LRU */
         0x1, /* gcFEATURE_BIT_COEF_COMPRESSION_ENHANCEMENT */
@@ -4104,16 +4418,38 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_CLAMP_BORDER_MODE */
         0x0, /* gcFEATURE_BIT_NN_ELEMENTWISE_BROADCAST_STRIDE_X_0 */
         0x0, /* gcFEATURE_BIT_NN_2ND_IMAGE_DATA_TYPE */
+        0x0, /* gcFEATURE_BIT_FP_INIMAGE_POST_SCALE */
         0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
         0x0, /* gcFEATURE_BIT_TENSOR_DMA */
         0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
-        0x0, /* gcFEATURE_BIT_NN_FP8 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
+        0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
         0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
         0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
         0x0, /* gcFEATURE_BIT_SUPPORT_BATCH_ALIGNMENT */
         0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
         0x0, /* gcFEATURE_BIT_SRAM_PARITY */
+        0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SH_IN_PARALLEL */
+        0x0, /* gcFEATURE_BIT_NN_ASYNC_DMA */
+        0x0, /* gcFEATURE_BIT_NN_STRIDE2_FAST_XDP3 */
+        0x0, /* gcFEATURE_BIT_NN_2V4_STRUCTURED_SPARSITY */
+        0x0, /* gcFEATURE_BIT_NN_SP_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_SEPARATE_STREAMBUF_ADDR */
+        0x0, /* gcFEATURE_BIT_NN_TF32_MAC */
         0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
         0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
         0x1, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
@@ -4142,7 +4478,1823 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_LOW_EFFICIENCY_OF_ID_WRITE_IMGBUF_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_VIP_SRAM_READ_BW_LIMITATION_FIX */
         0x0, /* gcFEATURE_BIT_USC_BOTTLENECK_FIX */
-        0x0, /* gcFEATURE_BIT_KERNEL_PER_CORE_LESS_THAN_THIRD_COEF_BUFF_DEPTH_FIX */
+        0x1, /* gcFEATURE_BIT_KERNEL_PER_CORE_LESS_THAN_THIRD_COEF_BUFF_DEPTH_FIX */
+        0x1, /* gcFEATURE_BIT_NN_TILE_NUM_BIGGER_THAN_1024_FIX */
+        0x0, /* gcFEATURE_BIT_KERNEL_SIZE_WASTE_IN_PARTIAL_MODE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_COMMAND_KERNEL_REQUEST_CONFICT_FIX */
+        0x0, /* gcFEATURE_BIT_TP_REORDER_INTILE_X_SIZE_512_FIX */
+        0x0, /* gcFEATURE_BIT_IMG_POP_PIPELINE_PAUSE_FIX */
+        0x0, /* gcFEATURE_BIT_FULLCACHE_KERNEL_INTERLEAVE_FIX */
+        0x1, /* gcFEATURE_BIT_V8_SINGLE_PORT_ACCUMULATION_BUFFER_RW_CONFICT_ZERO_SKIP_PERF_FIX */
+        0x0, /* gcFEATURE_BIT_V8_ACCUMLATION_READ_OUT_HAS_BUBBLES_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_DEPTHWISE_NEIGHBOR_IMG_DATA_TRANSFER_NOT_EFFICIENT_FIX */
+        0x0, /* gcFEATURE_BIT_DR_JD_DIFF_CONDITION_FOR_CACHELINE_MODE_PRE_FIX */
+        0x0, /* gcFEATURE_BIT_TP_ACCESS_VIPSRAM_OT_IS_ONE_FIX */
+        0x0, /* gcFEATURE_BIT_EVIS2_FLOP_RESET_FIX */
+        0x0, /* gcFEATURE_BIT_OUTIMAGE_X_BITWIDTH_LIMIT_FOR_NN_TRANSPOSE_FIX */
+        0x0, /* gcFEATURE_BIT_USC_ASYNC_CP_RTN_FLOP_RESET_FIX */
+        0x0, /* gcFEATURE_BIT_IMG_ADDR_NOT_WRAP_IF_OVER_OCB_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_NEGATIVE_POST_SHIFT_FIX */
+        0x0, /* gcFEATURE_BIT_INIMAGE_2DTILE_NOT_LESS_160PIXEL_FIX */
+        0x1, /* gcFEATURE_BIT_IMG_CAHCE_MODE_MUST_0_IN_IMG_DIRECT_MODE_FIX */
+        0x0, /* gcFEATURE_BIT_BURST_COLLECT_DUMMY_DATA_WASTE_CYCLES_FIX */
+        0x1, /* gcFEATURE_BIT_INIMG_NOT_64BYTE_ALIGN_CACHELINE_MODE_FIX */
+        0x1, /* gcFEATURE_BIT_TP_FC_FLOAT_LAST_PIXEL_NEGATIVE_0_FIX */
+        0x1, /* gcFEATURE_BIT_NN_WASTE_COEF_READ_WRITE_BANDWIDTH_128BYTE_VIPSRAM_IN_FULL_PATIAL_CACHE_MODE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_IN_TILE_DATA_IS_ALL_PAD_FIX */
+        0x0, /* gcFEATURE_BIT_NN_TP_INSTR_COMPLETE_IN_SAME_CYCLE_WITH_WAIT_EVENT_FIX */
+        0x1, /* gcFEATURE_BIT_CORE_IMAGE_TRANSER_NOT_EFFICIENT_BETWEEN_PARTITION_FIX */
+        0x1, /* gcFEATURE_BIT_TP_FC_KERNEL_STREAM_MUST_LESS_THAN_OR_EQUAL_TO_64BYTE_WHEN_1BYTE_ALGINE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_KERNEL_1x1_NO_PAD_FIX */
+        0x1, /* gcFEATURE_BIT_NN_DEPTHWISE_AFTER_16BIT_LAYER_LIMIT_FIX */
+        0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
+        0x0, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
+        0x1, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
+        0x1, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
+        0x1, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
+        0x1, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
+        0x1, /* gcFEATURE_BIT_V83_CONVERTER_FOR_NEG_0_FIX */
+        0x1, /* gcFEATURE_BIT_NN_2ND_IMG_SMALL_3D_TILE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_TILE_YSIZE_127_LIMITATION_FIX */
+        0x1, /* gcFEATURE_BIT_NN_CONV_1D_16BIT_FORMAT_INTILE_SIZE_LIMITATION_FIX */
+        0x1, /* gcFEATURE_BIT_NN_VIPSRAM_DOUBLE_BUFFER_FIX */
+        0x0, /* gcFEATURE_BIT_NN_JD_DIRECT_MODE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_KERNEL_DIRECT_WRONG_PUSH_FIX */
+        0x1, /* gcFEATURE_BIT_HI_DEFAULT_ENABLE_REORDER_FIX */
+        0x1, /* gcFEATURE_BIT_V8_DIRECT_MODE_START_ADDR_BIAS_FOR_NEGATIVE_OFFSET_FIX */
+        0x1, /* gcFEATURE_BIT_V83_INTILESIZE_1X1_10BITS_FIX */
+        0x0, /* gcFEATURE_BIT_FASTXDP3_ONLY_IN_DEPTHWISE_FIX */
+        0x1, /* gcFEATURE_BIT_US_SRAM_READ_INTF_FIFO_OVERFLOW_FIX */
+        0x0, /* gcFEATURE_BIT_USC_PAUSE_TP_WR_REQ_MORE_THAN_256_CYCLES_FIX */
+        0x1, /* gcFEATURE_BIT_DEPTHWISE_FLOAT_FIX */
+        0x0, /* gcFEATURE_BIT_TP_CIRCULAR_BUF_WRAP_ADDRESS_OVERFLOW_FIX */
+        0x0, /* gcFEATURE_BIT_NN_CIRCULAR_BUF_WRAP_ADDRESS_OVERFLOW_FIX */
+        0x1, /* gcFEATURE_BIT_CLOCK_DIV2_FREQ_CHANGE_FIX */
+        0x1, /* gcFEATURE_BIT_SMALL_TILE_TENSOR_ADD_FIX */
+        0x1, /* gcFEATURE_BIT_DECOMPRESSOR_DEPTHWISE_FLOAT_FIX */
+        0x0, /* gcFEATURE_BIT_TP_CIRCULAR_BUF_WRAP_ADDRESS_LESS_FIX */
+        0x1, /* gcFEATURE_BIT_V83_NUMOFPENDINGTILES_FOR_2NDIMAGE_FIX */
+        0x1, /* gcFEATURE_BIT_V83_1ST_CACHE_MODE_VIPSRAM_RD_UPDATE_FIX */
+        0x1, /* gcFEATURE_BIT_V83_1ST_KERNEL_STREAM_BUFFER_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_USC_RW_SAME_CACHELINE_UPDATE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_KERNEL_MSS_SBP2_DIRECT_STEAM_STEAM_FIX */
+        0x1, /* gcFEATURE_BIT_CORE_NUM_OF_KID_FOR_MULTI_LAYER_FIX */
+        0x0, /* gcFEATURE_BIT_KERNEL_XSIZE_YSIZE_NUM_FIX */
+        0x1, /* gcFEATURE_BIT_IMGRD_ROW_NUMBER_FIX */
+        0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
+        0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
+        0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x1, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
+        0x1, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
+        0x1, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
+        0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
+        0x1, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
+        0x1, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
+        0x1, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
+        0x1, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
+        0x1, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
+        0x1, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
+        0x1, /* gcFEATURE_BIT_VZ_GROUP_START_Z_OVERFLOW_FIX */
+        0x1, /* gcFEATURE_BIT_V82_STREAMMODE_VIPSRAM_ADDRESS_FIX */
+        0x1, /* gcFEATURE_BIT_GEMM_NO_SUPPORT_SMALLBATCH_FIX */
+        0x1, /* gcFEATURE_BIT_SBP1_KHEAD_CMDSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_BURSTCOLLECTOR_MAXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
+        0x1, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
+        0x1, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x1, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x1, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x1, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_PRE_CORE_LOTS_ZEROSKIP_KERNEL_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_MATRIX_A_TRSP1_CHNUM_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_4BIT_SBP2_BLOCKCTRL2_FIX */
+        0x1, /* gcFEATURE_BIT_B2B_RETRUN_NN_CMD_DONE_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_VLW_3D_TILE_INFO_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_SPECIAL_WORDSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
+        0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
+        0x0, /* gcFEATURE_BIT_NN_INT16_ALU */
+        0x1, /* gcFEATURE_BIT_NN_INT8_SCALE */
+        0x1, /* gcFEATURE_BIT_NN_POWER_ISOLATION */
+        0x1, /* gcFEATURE_BIT_ZRL_7BIT */
+        0x0, /* gcFEATURE_BIT_NN_SMALLBATCH */
+        0x0, /* gcFEATURE_BIT_TP_SMALLBATCH */
+        0x1, /* gcFEATURE_BIT_ZRL_8BIT */
+        0x0, /* gcFEATURE_BIT_DDR_BURST_LEN_256B */
+        0x0, /* gcFEATURE_BIT_XY_OFFSET_LIMITATION_FIX */
+        0x0, /* gcFEATURE_BIT_NN_NONZERO_MIRROR_BORDER */
+        0x0, /* gcFEATURE_BIT_IMAGE_PARTIAL_CACHE */
+    },
+    /* GCNANOULTRA31_VIP2 */
+    {
+        0x8000, /* ChipID */
+        0x6205, /* ChipRevision */
+        0x80003, /* ProductID */
+        0x0, /* EcoID */
+        0x15, /* CustomerID */
+        0x0, /* PatchVersion */
+        "GCNANOULTRA31_VIP2", /* ProductName */
+        0x0, /* FormalRelease */
+        0x40, /* gcFEATURE_VALUE_TempRegisters */
+        0x200, /* gcFEATURE_VALUE_ThreadCount */
+        0x2, /* gcFEATURE_VALUE_NumShaderCores */
+        0x200, /* gcFEATURE_VALUE_InstructionCount */
+        0x140, /* gcFEATURE_VALUE_NumberOfConstants */
+        0x1, /* gcFEATURE_VALUE_CoreCount */
+        0x10, /* gcFEATURE_VALUE_LocalStorageSize */
+        0x0, /* gcFEATURE_VALUE_LocalStorageSize_1 */
+        0x0, /* gcFEATURE_VALUE_LocalStorageSize_2 */
+        0x8, /* gcFEATURE_VALUE_L1CacheSize */
+        0x0, /* gcFEATURE_VALUE_L1CacheSize_1 */
+        0x0, /* gcFEATURE_VALUE_L1CacheSize_2 */
+        0x200, /* gcFEATURE_VALUE_InstructionMemorySize */
+        0x14, /* gcFEATURE_VALUE_ShaderPCLength */
+        0x10, /* gcFEATURE_VALUE_USC_MAX_PAGES */
+        0x0, /* gcFEATURE_VALUE_USC_MAX_PAGES_1 */
+        0x0, /* gcFEATURE_VALUE_USC_MAX_PAGES_2 */
+        0x1, /* gcFEATURE_VALUE_NumPixelPipes */
+        0x2, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS */
+        0x0, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS_1 */
+        0x0, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS_2 */
+        0x2, /* gcFEATURE_VALUE_USC_BANKS */
+        0x0, /* gcFEATURE_VALUE_USC_BANKS_1 */
+        0x0, /* gcFEATURE_VALUE_USC_BANKS_2 */
+        0x20, /* gcFEATURE_VALUE_VIRTUAL_ADDRESS_BITS */
+        0x0, /* gcFEATURE_VALUE_PHYSICAL_ADDRESS_BITS */
+        0x10, /* gcFEATURE_VALUE_Streams */
+        0x10, /* gcFEATURE_VALUE_VaryingCount */
+        0x400, /* gcFEATURE_VALUE_VertexOutputBufferSize */
+        0x0, /* gcFEATURE_VALUE_BufferSize */
+        0x10, /* gcFEATURE_VALUE_VertexCacheSize */
+        0x1, /* gcFEATURE_VALUE_NumResolvePipes */
+        0x10, /* gcFEATURE_VALUE_RESULT_WINDOW_MAX_SIZE */
+        0x0, /* gcFEATURE_VALUE_ClusterAliveMask */
+        0x0, /* gcFEATURE_VALUE_G2D_DEC400_MINOR */
+        0x0, /* gcFEATURE_VALUE_G2D_TILING_MINOR */
+        0x0, /* gcFEATURE_VALUE_PS_INSTRUCTION_COUNT */
+        0x0, /* gcFEATURE_VALUE_PS_INPUT_COMPONENTS */
+        0x0, /* gcFEATURE_VALUE_AIGM_MAX_SIZE */
+        0x40, /* gcFEATURE_VALUE_NNMadPerCore */
+        0x2, /* gcFEATURE_VALUE_NNCoreCount */
+        0x2, /* gcFEATURE_VALUE_NN_ACTIVE_CORE_COUNT */
+        0x2, /* gcFEATURE_VALUE_NNCoreCount_INT8 */
+        0x2, /* gcFEATURE_VALUE_NNCoreCount_INT16 */
+        0x0, /* gcFEATURE_VALUE_NNCoreCount_UINT16 */
+        0x0, /* gcFEATURE_VALUE_NNCoreCount_FLOAT16 */
+        0x0, /* gcFEATURE_VALUE_NNCoreCount_BFLOAT */
+        0x6, /* gcFEATURE_VALUE_NNInputBufferDepth */
+        0x40, /* gcFEATURE_VALUE_NNAccumBufferDepth */
+        0x400, /* gcFEATURE_VALUE_TPEngine_PwlLUTCount */
+        0x10, /* gcFEATURE_VALUE_TPEngine_PwlLUTSize */
+        0x20000, /* gcFEATURE_VALUE_VIP_SRAM_SIZE */
+        {0x0, }, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
+        0x1, /* gcFEATURE_VALUE_TPEngine_CoreCount */
+        0x0, /* gcFEATURE_VALUE_AXI_SRAM_SIZE */
+        0x4, /* gcFEATURE_VALUE_NN_INIMAGE_OFFSET_BITS */
+        0x180, /* gcFEATURE_VALUE_TP_REORDER_INIMAGE_SIZE */
+        0x7, /* gcFEATURE_VALUE_TPLite_CoreCount */
+        0x0, /* gcFEATURE_VALUE_NN_PREPROCESSOR_MAX_SEGMENT_PER_CYCLE */
+        0x1, /* gcFEATURE_VALUE_NNFP16_XYDP_X */
+        0x1, /* gcFEATURE_VALUE_NNFP16_XYDP_Y */
+        0x1, /* gcFEATURE_VALUE_NNFP16_ZDP */
+        0x8, /* gcFEATURE_VALUE_NN_LANES_PER_OUT_CYCLE */
+        0x0, /* gcFEATURE_VALUE_LUT_ACT_LANES */
+        0x20, /* gcFEATURE_VALUE_MAX_OT_NUMBER */
+        0x40, /* gcFEATURE_VALUE_PHYSICAL_VIP_SRAM_WIDTH_IN_BYTE */
+        0x20, /* gcFEATURE_VALUE_EQUIVALENT_VIP_SRAM_WIDTH_INBYTE */
+        0x8, /* gcFEATURE_VALUE_TP_ZRL_BITS */
+        0x8, /* gcFEATURE_VALUE_NN_ZRL_BITS */
+        0x100, /* gcFEATURE_VALUE_NN_ZRL_VALID_ZERO_NUMBER */
+        0x80, /* gcFEATURE_VALUE_LATENCY_HIDING_AT_FULL_AXI_BW */
+        0x10, /* gcFEATURE_VALUE_AXI_BUS_WIDTH */
+        0xb, /* gcFEATURE_VALUE_NN_KERNEL_X_SIZE */
+        0xb, /* gcFEATURE_VALUE_NN_KERNEL_Y_SIZE */
+        0xf, /* gcFEATURE_VALUE_NN_FC_KERNEL_Y_SIZE */
+        0xfffff, /* gcFEATURE_VALUE_NN_KERNEL_Z_SIZE */
+        0xf, /* gcFEATURE_VALUE_NN_X_OFFSET */
+        0xf, /* gcFEATURE_VALUE_NN_Y_OFFSET */
+        0x40, /* gcFEATURE_VALUE_DDR_KERNEL_BURST_SIZE */
+        0x40, /* gcFEATURE_VALUE_MIN_AXI_BURST_SIZE */
+        0x10, /* gcFEATURE_VALUE_OUTIMAGE_X_STRIDE_BITS */
+        0x0, /* gcFEATURE_VALUE_OUTIMAGE_Y_STRIDE_BITS */
+        0x0, /* gcFEATURE_VALUE_OUTIMAGE_SLICE_BITS */
+        0xd, /* gcFEATURE_VALUE_OUTIMAGE_X_SIZE_BITS */
+        0xd, /* gcFEATURE_VALUE_OUTIMAGE_Y_SIZE_BITS */
+        0xe, /* gcFEATURE_VALUE_OUTIMAGE_Z_SIZE_BITS */
+        0x10, /* gcFEATURE_VALUE_INIMAGE_X_STRIDE_BITS */
+        0x10, /* gcFEATURE_VALUE_IMIMAGE_Y_STRIDE_BITS */
+        0x0, /* gcFEATURE_VALUE_INIMAGE_SLICE_BITS */
+        0xd, /* gcFEATURE_VALUE_INIMAGE_X_SIZE_BITS */
+        0xd, /* gcFEATURE_VALUE_INIMAGE_Y_SIZE_BITS */
+        0x40, /* gcFEATURE_VALUE_MAX_TILE_X_SIZE */
+        0x1, /* gcFEATURE_VALUE_NN_CLUSTER_NUM_FOR_POWER_CONTROL */
+        0x0, /* gcFEATURE_VALUE_NN_IN_LINES_PER_CYCLE */
+        0x0, /* gcFEATURE_VALUE_NN_MP_INTER_CONNECT_RING_COUNT */
+        0x20, /* gcFEATURE_VALUE_NN_SMALL_ACCUM_BITS */
+        0x1, /* gcFEATURE_VALUE_NN_COEF_DECOMPRESS_PERF_X */
+        0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
+        0x32, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
+        0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x10, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x3, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
+        0x1, /* gcFEATURE_BIT_REG_FastClear */
+        0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
+        0x1, /* gcFEATURE_BIT_REG_Pipe3D */
+        0x1, /* gcFEATURE_BIT_REG_DXTTextureCompression */
+        0x0, /* gcFEATURE_BIT_REG_DebugMode */
+        0x0, /* gcFEATURE_BIT_REG_ZCompression */
+        0x0, /* gcFEATURE_BIT_REG_YUV420Filter */
+        0x1, /* gcFEATURE_BIT_REG_MSAA */
+        0x0, /* gcFEATURE_BIT_REG_DC */
+        0x0, /* gcFEATURE_BIT_REG_Pipe2D */
+        0x1, /* gcFEATURE_BIT_REG_ETC1TextureCompression */
+        0x1, /* gcFEATURE_BIT_REG_FastScaler */
+        0x1, /* gcFEATURE_BIT_REG_HighDynamicRange */
+        0x1, /* gcFEATURE_BIT_REG_YUV420Tiler */
+        0x1, /* gcFEATURE_BIT_REG_ModuleCG */
+        0x0, /* gcFEATURE_BIT_REG_MinArea */
+        0x0, /* gcFEATURE_BIT_REG_NoEZ */
+        0x0, /* gcFEATURE_BIT_REG_No422Texture */
+        0x0, /* gcFEATURE_BIT_REG_BufferInterleaving */
+        0x1, /* gcFEATURE_BIT_REG_ByteWrite2D */
+        0x0, /* gcFEATURE_BIT_REG_NoScaler */
+        0x1, /* gcFEATURE_BIT_REG_YUY2Averaging */
+        0x0, /* gcFEATURE_BIT_REG_HalfPECache */
+        0x0, /* gcFEATURE_BIT_REG_HalfTXCache */
+        0x0, /* gcFEATURE_BIT_REG_YUY2RenderTarget */
+        0x0, /* gcFEATURE_BIT_REG_Mem32BitSupport */
+        0x0, /* gcFEATURE_BIT_REG_PipeVG */
+        0x0, /* gcFEATURE_BIT_REG_VGTS */
+        0x0, /* gcFEATURE_BIT_REG_FE20 */
+        0x1, /* gcFEATURE_BIT_REG_ByteWrite3D */
+        0x1, /* gcFEATURE_BIT_REG_RsYuvTarget */
+        0x1, /* gcFEATURE_BIT_REG_FE20BitIndex */
+        0x1, /* gcFEATURE_BIT_REG_FlipY */
+        0x1, /* gcFEATURE_BIT_REG_DualReturnBus */
+        0x1, /* gcFEATURE_BIT_REG_EndiannessConfig */
+        0x1, /* gcFEATURE_BIT_REG_Texture8K */
+        0x1, /* gcFEATURE_BIT_REG_CorrectTextureConverter */
+        0x1, /* gcFEATURE_BIT_REG_SpecialMsaaLod */
+        0x1, /* gcFEATURE_BIT_REG_FastClearFlush */
+        0x1, /* gcFEATURE_BIT_REG_2DPE20 */
+        0x0, /* gcFEATURE_BIT_REG_CorrectAutoDisable */
+        0x1, /* gcFEATURE_BIT_REG_Render8K */
+        0x1, /* gcFEATURE_BIT_REG_TileStatus2Bits */
+        0x1, /* gcFEATURE_BIT_REG_SeparateTileStatusWhenInterleaved */
+        0x1, /* gcFEATURE_BIT_REG_SuperTiled32x32 */
+        0x0, /* gcFEATURE_BIT_REG_VG20 */
+        0x0, /* gcFEATURE_BIT_REG_TSExtendedCommands */
+        0x1, /* gcFEATURE_BIT_REG_CompressionFifoFixed */
+        0x1, /* gcFEATURE_BIT_REG_ExtraShaderInstructions0 */
+        0x0, /* gcFEATURE_BIT_REG_VGFilter */
+        0x0, /* gcFEATURE_BIT_REG_VG21 */
+        0x1, /* gcFEATURE_BIT_REG_ShaderGetsW */
+        0x1, /* gcFEATURE_BIT_REG_ExtraShaderInstructions1 */
+        0x1, /* gcFEATURE_BIT_REG_DefaultReg0 */
+        0x1, /* gcFEATURE_BIT_REG_MC20 */
+        0x0, /* gcFEATURE_BIT_REG_ShaderMSAASideband */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes0 */
+        0x0, /* gcFEATURE_BIT_REG_VAA */
+        0x0, /* gcFEATURE_BIT_REG_BypassInMSAA */
+        0x0, /* gcFEATURE_BIT_REG_HierarchicalZ */
+        0x0, /* gcFEATURE_BIT_REG_NewTexture */
+        0x0, /* gcFEATURE_BIT_REG_A8TargetSupport */
+        0x1, /* gcFEATURE_BIT_REG_CorrectStencil */
+        0x1, /* gcFEATURE_BIT_REG_EnhanceVR */
+        0x1, /* gcFEATURE_BIT_REG_RSUVSwizzle */
+        0x0, /* gcFEATURE_BIT_REG_V2Compression */
+        0x0, /* gcFEATURE_BIT_REG_VGDoubleBuffer */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes1 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes2 */
+        0x0, /* gcFEATURE_BIT_REG_TextureStride */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes3 */
+        0x1, /* gcFEATURE_BIT_REG_CorrectAutoDisable1 */
+        0x0, /* gcFEATURE_BIT_REG_AutoRestartTS */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes4 */
+        0x0, /* gcFEATURE_BIT_REG_L2Windowing */
+        0x1, /* gcFEATURE_BIT_REG_HalfFloatPipe */
+        0x1, /* gcFEATURE_BIT_REG_PixelDither */
+        0x1, /* gcFEATURE_BIT_REG_TwoStencilReference */
+        0x1, /* gcFEATURE_BIT_REG_ExtendedPixelFormat */
+        0x1, /* gcFEATURE_BIT_REG_CorrectMinMaxDepth */
+        0x1, /* gcFEATURE_BIT_REG_DitherAndFilterPlusAlpha2D */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes5 */
+        0x0, /* gcFEATURE_BIT_REG_New2D */
+        0x1, /* gcFEATURE_BIT_REG_NewFloatingPointArithmetic */
+        0x1, /* gcFEATURE_BIT_REG_TextureHorizontalAlignmentSelect */
+        0x1, /* gcFEATURE_BIT_REG_NonPowerOfTwo */
+        0x1, /* gcFEATURE_BIT_REG_LinearTextureSupport */
+        0x1, /* gcFEATURE_BIT_REG_Halti0 */
+        0x0, /* gcFEATURE_BIT_REG_CorrectOverflowVG */
+        0x1, /* gcFEATURE_BIT_REG_NegativeLogFix */
+        0x1, /* gcFEATURE_BIT_REG_ResolveOffset */
+        0x1, /* gcFEATURE_BIT_REG_OkToGateAxiClock */
+        0x1, /* gcFEATURE_BIT_REG_MMU */
+        0x1, /* gcFEATURE_BIT_REG_WideLine */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes6 */
+        0x1, /* gcFEATURE_BIT_REG_FcFlushStall */
+        0x1, /* gcFEATURE_BIT_REG_LineLoop */
+        0x1, /* gcFEATURE_BIT_REG_LogicOp */
+        0x1, /* gcFEATURE_BIT_REG_SeamlessCubeMap */
+        0x1, /* gcFEATURE_BIT_REG_SuperTiledTexture */
+        0x1, /* gcFEATURE_BIT_REG_LinearPE */
+        0x1, /* gcFEATURE_BIT_REG_RectPrimitive */
+        0x0, /* gcFEATURE_BIT_REG_Composition */
+        0x1, /* gcFEATURE_BIT_REG_CorrectAutoDisableCountWidth */
+        0x1, /* gcFEATURE_BIT_REG_PESwizzle */
+        0x1, /* gcFEATURE_BIT_REG_EndEvent */
+        0x1, /* gcFEATURE_BIT_REG_S1S8 */
+        0x1, /* gcFEATURE_BIT_REG_Halti1 */
+        0x0, /* gcFEATURE_BIT_REG_RGB888 */
+        0x0, /* gcFEATURE_BIT_REG_TX_YUVAssembler */
+        0x1, /* gcFEATURE_BIT_REG_DynamicFrequencyScaling */
+        0x0, /* gcFEATURE_BIT_REG_TXFilter */
+        0x1, /* gcFEATURE_BIT_REG_FullDirectFB */
+        0x0, /* gcFEATURE_BIT_REG_OnePass2DFilter */
+        0x1, /* gcFEATURE_BIT_REG_ThreadWalkerInPS */
+        0x1, /* gcFEATURE_BIT_REG_TileFiller */
+        0x1, /* gcFEATURE_BIT_REG_YUVStandard */
+        0x0, /* gcFEATURE_BIT_REG_MultiSourceBlt */
+        0x0, /* gcFEATURE_BIT_REG_YUVConversion */
+        0x1, /* gcFEATURE_BIT_REG_FlushFixed2D */
+        0x1, /* gcFEATURE_BIT_REG_Interleaver */
+        0x1, /* gcFEATURE_BIT_REG_MixedStreams */
+        0x0, /* gcFEATURE_BIT_REG_L2CacheFor2D420 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes7 */
+        0x0, /* gcFEATURE_BIT_REG_NoIndexPattern */
+        0x1, /* gcFEATURE_BIT_REG_TextureTileStatus */
+        0x1, /* gcFEATURE_BIT_REG_DecompressZ16 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes8 */
+        0x1, /* gcFEATURE_BIT_REG_DERotationStallFix */
+        0x0, /* gcFEATURE_BIT_REG_OclOnly */
+        0x1, /* gcFEATURE_BIT_REG_NewFeatures0 */
+        0x1, /* gcFEATURE_BIT_REG_InstructionCache */
+        0x0, /* gcFEATURE_BIT_REG_GeometryShader */
+        0x1, /* gcFEATURE_BIT_REG_TexCompressionSupertiled */
+        0x1, /* gcFEATURE_BIT_REG_Generics */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes9 */
+        0x0, /* gcFEATURE_BIT_REG_FastMSAA */
+        0x0, /* gcFEATURE_BIT_REG_WClip */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes10 */
+        0x1, /* gcFEATURE_BIT_REG_UnifiedSamplers */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes11 */
+        0x1, /* gcFEATURE_BIT_REG_PerformanceCounters */
+        0x1, /* gcFEATURE_BIT_REG_ExtraShaderInstructions2 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes12 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes13 */
+        0x1, /* gcFEATURE_BIT_REG_DEEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_ACE */
+        0x1, /* gcFEATURE_BIT_REG_TXEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_PEEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_DEEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes14 */
+        0x0, /* gcFEATURE_BIT_REG_PowerOptimizations0 */
+        0x1, /* gcFEATURE_BIT_REG_NewHZ */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes15 */
+        0x0, /* gcFEATURE_BIT_REG_DEEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements4 */
+        0x1, /* gcFEATURE_BIT_REG_TXEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_FEEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_PEEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_PAEnhancements1 */
+        0x0, /* gcFEATURE_BIT_REG_DENoGamma */
+        0x0, /* gcFEATURE_BIT_REG_PAEnhancements2 */
+        0x0, /* gcFEATURE_BIT_REG_DEEnhancements4 */
+        0x1, /* gcFEATURE_BIT_REG_PEEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_HIEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_TXEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements5 */
+        0x1, /* gcFEATURE_BIT_REG_FEEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes16 */
+        0x0, /* gcFEATURE_BIT_REG_DEEnhancements5 */
+        0x1, /* gcFEATURE_BIT_REG_TXEnhancements4 */
+        0x0, /* gcFEATURE_BIT_REG_PEEnhancements4 */
+        0x1, /* gcFEATURE_BIT_REG_MCEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_Halti2 */
+        0x0, /* gcFEATURE_BIT_REG_DEMirrorRotate */
+        0x1, /* gcFEATURE_BIT_REG_SmallMSAA */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes17 */
+        0x0, /* gcFEATURE_BIT_REG_Rasterizer2 */
+        0x0, /* gcFEATURE_BIT_REG_DualPipeOPF */
+        0x0, /* gcFEATURE_BIT_REG_MultiSrcV2 */
+        0x0, /* gcFEATURE_BIT_REG_CSCV2 */
+        0x1, /* gcFEATURE_BIT_REG_PAEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes18 */
+        0x0, /* gcFEATURE_BIT_REG_Compression2D */
+        0x1, /* gcFEATURE_BIT_REG_Probe */
+        0x1, /* gcFEATURE_BIT_REG_MediumPrecision */
+        0x0, /* gcFEATURE_BIT_REG_DESupertile */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes19 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements6 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements7 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes20 */
+        0x0, /* gcFEATURE_BIT_REG_DEAddress40 */
+        0x0, /* gcFEATURE_BIT_REG_MiniMMUFix */
+        0x1, /* gcFEATURE_BIT_REG_EEZ */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes21 */
+        0x0, /* gcFEATURE_BIT_REG_ExtraVgCaps */
+        0x0, /* gcFEATURE_BIT_REG_MultiSrcV15 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes22 */
+        0x1, /* gcFEATURE_BIT_REG_Halti3 */
+        0x0, /* gcFEATURE_BIT_REG_TessellationShaders */
+        0x0, /* gcFEATURE_BIT_REG_OPF9Tap */
+        0x0, /* gcFEATURE_BIT_REG_MultiSrcV2StrQuad */
+        0x0, /* gcFEATURE_BIT_REG_SeperateSRCAndDstCache */
+        0x1, /* gcFEATURE_BIT_REG_Halti4 */
+        0x1, /* gcFEATURE_BIT_REG_RAWriteDepth */
+        0x0, /* gcFEATURE_BIT_REG_AndroidOnly */
+        0x1, /* gcFEATURE_BIT_REG_HasChipProductReg */
+        0x0, /* gcFEATURE_BIT_REG_TXSupportDEC */
+        0x1, /* gcFEATURE_BIT_REG_S8MSAACompression */
+        0x1, /* gcFEATURE_BIT_REG_BugFixesIn544 */
+        0x0, /* gcFEATURE_BIT_REG_L2CacheRemove */
+        0x1, /* gcFEATURE_BIT_REG_FEAllowRndVtxCnt */
+        0x0, /* gcFEATURE_BIT_REG_CubeMapFL28 */
+        0x1, /* gcFEATURE_BIT_REG_TX6bitFrac */
+        0x1, /* gcFEATURE_BIT_REG_FEAllowStallPrefetchEng */
+        0x0, /* gcFEATURE_BIT_REG_ThirdPartyCompression */
+        0x1, /* gcFEATURE_BIT_REG_RSS8 */
+        0x1, /* gcFEATURE_BIT_REG_MSAACoherencyCheck */
+        0x1, /* gcFEATURE_BIT_REG_Halti5 */
+        0x1, /* gcFEATURE_BIT_REG_Evis */
+        0x0, /* gcFEATURE_BIT_REG_BltEngine */
+        0x0, /* gcFEATURE_BIT_REG_BugFixes23 */
+        0x0, /* gcFEATURE_BIT_REG_BugFixes24 */
+        0x0, /* gcFEATURE_BIT_REG_DEC */
+        0x0, /* gcFEATURE_BIT_REG_VSTileNV12 */
+        0x0, /* gcFEATURE_BIT_REG_VSTileNV12_10BIT */
+        0x0, /* gcFEATURE_BIT_REG_DisableVIP */
+        0x0, /* gcFEATURE_BIT_RenderTarget8 */
+        0x0, /* gcFEATURE_BIT_TxLodFlowCorrection */
+        0x0, /* gcFEATURE_BIT_FaceLod */
+        0x0, /* gcFEATURE_BIT_MultiCoreSemaphoreStallV2 */
+        0x0, /* gcFEATURE_BIT_VMSAA */
+        0x0, /* gcFEATURE_BIT_ChipEnableLink */
+        0x0, /* gcFEATURE_BIT_MULTI_SRC_BLT_1_5_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_MULTI_SRC_BLT_BILINEAR_FILTER */
+        0x1, /* gcFEATURE_BIT_RA_HZEZ_CLOCK_CONTROL */
+        0x1, /* gcFEATURE_BIT_CACHE128B256BPERLINE */
+        0x0, /* gcFEATURE_BIT_V4Compression */
+        0x0, /* gcFEATURE_BIT_DE2D_MAJOR_SUPER_TILE */
+        0x0, /* gcFEATURE_BIT_PE2D_MAJOR_SUPER_TILE */
+        0x1, /* gcFEATURE_BIT_PE_32BPC_COLORMASK_FIX */
+        0x1, /* gcFEATURE_BIT_ALPHA_BLENDING_OPT */
+        0x1, /* gcFEATURE_BIT_NEW_GPIPE */
+        0x0, /* gcFEATURE_BIT_PIPELINE_32_ATTRIBUTES */
+        0x0, /* gcFEATURE_BIT_MSAA_SHADING */
+        0x1, /* gcFEATURE_BIT_NO_ANISTRO_FILTER */
+        0x1, /* gcFEATURE_BIT_NO_ASTC */
+        0x0, /* gcFEATURE_BIT_NO_DXT */
+        0x0, /* gcFEATURE_BIT_HWTFB */
+        0x1, /* gcFEATURE_BIT_RA_DEPTH_WRITE_MSAA1X_FIX */
+        0x1, /* gcFEATURE_BIT_EZHZ_CLOCKGATE_FIX */
+        0x1, /* gcFEATURE_BIT_SH_SNAP2PAGE_FIX */
+        0x1, /* gcFEATURE_BIT_SH_HALFDEPENDENCY_FIX */
+        0x1, /* gcFEATURE_BIT_USC_MCFILL_FIX */
+        0x1, /* gcFEATURE_BIT_TPG_TCPERF_FIX */
+        0x1, /* gcFEATURE_BIT_USC_MDFIFO_OVERFLOW_FIX */
+        0x1, /* gcFEATURE_BIT_SH_TEXLD_BARRIER_IN_CS_FIX */
+        0x1, /* gcFEATURE_BIT_RS_NEW_BASEADDR */
+        0x1, /* gcFEATURE_BIT_PE_8bpp_DUALPIPE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_ADVANCED_INSTR */
+        0x1, /* gcFEATURE_BIT_SH_FLAT_INTERPOLATION_DUAL16_FIX */
+        0x1, /* gcFEATURE_BIT_USC_CONTINUOUS_FLUS_FIX */
+        0x0, /* gcFEATURE_BIT_SH_SUPPORT_V4 */
+        0x0, /* gcFEATURE_BIT_SH_SUPPORT_ALPHA_KILL */
+        0x1, /* gcFEATURE_BIT_PE_NO_ALPHA_TEST */
+        0x0, /* gcFEATURE_BIT_TX_LOD_NEAREST_SELECT */
+        0x1, /* gcFEATURE_BIT_SH_FIX_LDEXP */
+        0x1, /* gcFEATURE_BIT_SUPPORT_MOVAI */
+        0x1, /* gcFEATURE_BIT_SH_SNAP2PAGE_MAXPAGES_FIX */
+        0x1, /* gcFEATURE_BIT_PE_RGBA16I_FIX */
+        0x1, /* gcFEATURE_BIT_BLT_8bpp_256TILE_FC_FIX */
+        0x1, /* gcFEATURE_BIT_PE_64bit_FENCE_FIX */
+        0x1, /* gcFEATURE_BIT_USC_FULL_CACHE_FIX */
+        0x0, /* gcFEATURE_BIT_TX_YUV_ASSEMBLER_10BIT */
+        0x1, /* gcFEATURE_BIT_FE_32bit_INDEX_FIX */
+        0x1, /* gcFEATURE_BIT_BLT_64bpp_MASKED_CLEAR_FIX */
+        0x1, /* gcFEATURE_BIT_SECURITY */
+        0x1, /* gcFEATURE_BIT_ROBUSTNESS */
+        0x1, /* gcFEATURE_BIT_USC_ATOMIC_FIX */
+        0x1, /* gcFEATURE_BIT_SH_PSO_MSAA1x_FIX */
+        0x1, /* gcFEATURE_BIT_USC_VX_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_USC_GOS_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_TX_8bit_UVFrac */
+        0x1, /* gcFEATURE_BIT_TX_DESC_CACHE_CLOCKGATE_FIX */
+        0x1, /* gcFEATURE_BIT_RSBLT_MSAA_DECOMPRESSION */
+        0x0, /* gcFEATURE_BIT_TX_INTEGER_COORDINATE */
+        0x1, /* gcFEATURE_BIT_DRAWID */
+        0x1, /* gcFEATURE_BIT_PSIO_SAMPLEMASK_IN_R0ZW_FIX */
+        0x1, /* gcFEATURE_BIT_TX_INTEGER_COORDINATE_V2 */
+        0x0, /* gcFEATURE_BIT_MULTI_CORE_BLOCK_SET_CONFIG */
+        0x1, /* gcFEATURE_BIT_SNAPPAGE_CMD */
+        0x1, /* gcFEATURE_BIT_SH_NO_INDEX_CONST_ON_A0 */
+        0x1, /* gcFEATURE_BIT_SH_NO_ONECONST_LIMIT */
+        0x1, /* gcFEATURE_BIT_SH_IMG_LDST_ON_TEMP */
+        0x0, /* gcFEATURE_BIT_COMPUTE_ONLY */
+        0x1, /* gcFEATURE_BIT_SH_IMG_LDST_CLAMP */
+        0x1, /* gcFEATURE_BIT_SH_ICACHE_ALLOC_COUNT_FIX */
+        0x1, /* gcFEATURE_BIT_SH_ICACHE_PREFETCH */
+        0x0, /* gcFEATURE_BIT_PE2D_SEPARATE_CACHE */
+        0x1, /* gcFEATURE_BIT_PE_MSAA_OQ_FIX */
+        0x1, /* gcFEATURE_BIT_PSIO_MSAA_CL_FIX */
+        0x1, /* gcFEATURE_BIT_USC_DEFER_FILL_FIX */
+        0x1, /* gcFEATURE_BIT_SH_CLOCK_GATE_FIX */
+        0x0, /* gcFEATURE_BIT_FE_NEED_DUMMYDRAW */
+        0x0, /* gcFEATURE_BIT_PE2D_LINEAR_YUV420_OUTPUT */
+        0x0, /* gcFEATURE_BIT_PE2D_LINEAR_YUV420_10BIT */
+        0x0, /* gcFEATURE_BIT_MULTI_CLUSTER */
+        0x1, /* gcFEATURE_BIT_SH_MULTI_WG_PACK */
+        0x1, /* gcFEATURE_BIT_SH_DUAL16_SAMPLEMASK_ZW */
+        0x1, /* gcFEATURE_BIT_TPG_TRIVIAL_MODE_FIX */
+        0x0, /* gcFEATURE_BIT_TX_ASTC_MULTISLICE_FIX */
+        0x0, /* gcFEATURE_BIT_FE_ROBUST_FIX */
+        0x1, /* gcFEATURE_BIT_SH_GPIPE_ACCESS_FULLTEMPS */
+        0x0, /* gcFEATURE_BIT_PSIO_INTERLOCK */
+        0x1, /* gcFEATURE_BIT_PA_WIDELINE_FIX */
+        0x0, /* gcFEATURE_BIT_WIDELINE_HELPER_FIX */
+        0x1, /* gcFEATURE_BIT_TX_FLUSH_L1CACHE */
+        0x1, /* gcFEATURE_BIT_PE_DITHER_FIX2 */
+        0x1, /* gcFEATURE_BIT_SH_TEXLD_U_FIX */
+        0x1, /* gcFEATURE_BIT_MC_FCCACHE_BYTEMASK */
+        0x1, /* gcFEATURE_BIT_SH_MULTI_WG_PACK_FIX */
+        0x1, /* gcFEATURE_BIT_PE_ADVANCE_BLEND_PART0 */
+        0x1, /* gcFEATURE_BIT_FE_PATCHLIST_FETCH_FIX */
+        0x1, /* gcFEATURE_BIT_RA_CG_FIX */
+        0x0, /* gcFEATURE_BIT_DEC400 */
+        0x0, /* gcFEATURE_BIT_LS_SUPPORT_PERCOMP_DEPENDENCY */
+        0x0, /* gcFEATURE_BIT_MULTI_CORE_BLOCK_SET_CONFIG2 */
+        0x0, /* gcFEATURE_BIT_PE_VMSAA_COVERAGE_CACHE_FIX */
+        0x1, /* gcFEATURE_BIT_SECURITY_AHB */
+        0x0, /* gcFEATURE_BIT_MULTICORE_SEMAPHORESTALL_V3 */
+        0x0, /* gcFEATURE_BIT_SMALLBATCH */
+        0x0, /* gcFEATURE_BIT_SH_CMPLX */
+        0x0, /* gcFEATURE_BIT_SH_IDIV0_SWZL_EHS */
+        0x0, /* gcFEATURE_BIT_TX_LERP_LESS_BIT */
+        0x0, /* gcFEATURE_BIT_SH_GM_ENDIAN */
+        0x0, /* gcFEATURE_BIT_SH_GM_USC_UNALLOC */
+        0x0, /* gcFEATURE_BIT_SH_END_OF_BB */
+        0x1, /* gcFEATURE_BIT_TX_BORDER_CLAMP_FIX */
+        0x0, /* gcFEATURE_BIT_SH_IMG_LD_LASTPIXEL_FIX */
+        0x0, /* gcFEATURE_BIT_ASYNC_BLT */
+        0x1, /* gcFEATURE_BIT_ASYNC_FE_FENCE_FIX */
+        0x0, /* gcFEATURE_BIT_PSCS_THROTTLE */
+        0x0, /* gcFEATURE_BIT_SEPARATE_LS */
+        0x1, /* gcFEATURE_BIT_WIDELINE_TRIANGLE_EMU */
+        0x0, /* gcFEATURE_BIT_FENCE_32BIT */
+        0x1, /* gcFEATURE_BIT_FENCE_64BIT */
+        0x1, /* gcFEATURE_BIT_PE_DEPTH_ONLY_OQFIX */
+        0x1, /* gcFEATURE_BIT_TX_SEAMLESS_CUBE */
+        0x1, /* gcFEATURE_BIT_TX_SNORM_SUPPORT */
+        0x0, /* gcFEATURE_BIT_SH_SCATTER_GATHER */
+        0x0, /* gcFEATURE_BIT_HWMANAGED_LS */
+        0x0, /* gcFEATURE_BIT_SH_IMAGE_ENABLE_FIX */
+        0x1, /* gcFEATURE_BIT_MSAA_FRAGMENT_OPERATION */
+        0x1, /* gcFEATURE_BIT_PE_TILE_CACHE_FLUSH_FIX */
+        0x1, /* gcFEATURE_BIT_BLT_YUV_OUTPUT */
+        0x1, /* gcFEATURE_BIT_SH_IO_CG_FIX */
+        0x0, /* gcFEATURE_BIT_PE_SWIZZLE */
+        0x1, /* gcFEATURE_BIT_SH_ROBUSTNESS_FIX */
+        0x1, /* gcFEATURE_BIT_USC_ATOMIC_FIX2 */
+        0x1, /* gcFEATURE_BIT_PE_A8B8G8R8 */
+        0x1, /* gcFEATURE_BIT_MULTIVIEW_RENDER */
+        0x1, /* gcFEATURE_BIT_FE_DRAW_DIRECT */
+        0x1, /* gcFEATURE_BIT_TX_VKBORDER_MODE */
+        0x1, /* gcFEATURE_BIT_TX_UNNORMALIZED_COORD */
+        0x0, /* gcFEATURE_BIT_PA_LINECLIP_FIX */
+        0x1, /* gcFEATURE_BIT_TX_8bit_UVFrac_ROUNDING_FIX */
+        0x0, /* gcFEATURE_BIT_MP_ARCH */
+        0x0, /* gcFEATURE_BIT_TX_NO_FIXED_FILTER */
+        0x0, /* gcFEATURE_BIT_SHARE_Z */
+        0x0, /* gcFEATURE_BIT_DE_2D_FAST_CLEAR */
+        0x0, /* gcFEATURE_BIT_DE_TILESTATUS_ROTATION_FIX */
+        0x0, /* gcFEATURE_BIT_TX_CLEAR_PENDING_FIX */
+        0x0, /* gcFEATURE_BIT_HI1_L2_CACHE */
+        0x0, /* gcFEATURE_BIT_USC_EVICT_CTRL_FIFO_FLOP_RESET_FIX */
+        0x0, /* gcFEATURE_BIT_FORMAT_10BIT_CROSS_4K */
+        0x0, /* gcFEATURE_BIT_FORMAT_P010LSB_I010 */
+        0x0, /* gcFEATURE_BIT_ENDIAN_CONTROL */
+        0x0, /* gcFEATURE_BIT_AXIFE */
+        0x1, /* gcFEATURE_BIT_SH_VX2_FLOATING_MAD_FIX */
+        0x0, /* gcFEATURE_BIT_TS_FC_VULKAN_SUPPORT */
+        0x1, /* gcFEATURE_BIT_MSAA_FLOAT_64BIT */
+        0x0, /* gcFEATURE_BIT_INDIRECT_COMPUTE_ZERODIM_FIX */
+        0x0, /* gcFEATURE_BIT_Q_CHANNEL_SUPPORT */
+        0x0, /* gcFEATURE_BIT_MMU_PAGE_DESCRIPTOR */
+        0x0, /* gcFEATURE_BIT_YUV_LINEAR_TO_TILE_ROTATE */
+        0x0, /* gcFEATURE_BIT_VEC2_IMULIMAD32_SUPPORT */
+        0x0, /* gcFEATURE_BIT_VEC4_IMULIMAD32_SUPPORT */
+        0x0, /* gcFEATURE_BIT_VEC2_IDIVIMOD16_SUPPORT */
+        0x0, /* gcFEATURE_BIT_DST_TEX_I2F_F2I_INST_DEPRECATE */
+        0x0, /* gcFEATURE_BIT_ALU_FP16_INSTRUCTIONS */
+        0x0, /* gcFEATURE_BIT_DUAL16_14BIT_PC_SUPPORT */
+        0x0, /* gcFEATURE_BIT_LDST_CONV_4ROUNDING_MODES */
+        0x0, /* gcFEATURE_BIT_FULL_PACK_MODE_SUPPORT */
+        0x0, /* gcFEATURE_BIT_DEPTH_FLOAT32_SUPPORT */
+        0x0, /* gcFEATURE_BIT_GPU_INSPECTOR_COUNTERS */
+        0x0, /* gcFEATURE_BIT_FP32_TO_FP16_CONV_FIX */
+        0x0, /* gcFEATURE_BIT_IMGLD_COMP_COUNT_FIX */
+        0x1, /* gcFEATURE_BIT_IMGLD_WIDTH_LT16_FIX */
+        0x0, /* gcFEATURE_BIT_TX_FILTER_ROUND_FIX */
+        0x0, /* gcFEATURE_BIT_SH_FP32_FMA_SUPPORT */
+        0x0, /* gcFEATURE_BIT_PE_64BPP_LINEAR_FORMAT */
+        0x0, /* gcFEATURE_BIT_TX_ETC2_COMPRESSION */
+        0x0, /* gcFEATURE_BIT_HIGHP_VEC2 */
+        0x0, /* gcFEATURE_BIT_MMU_PD_42_BIT_ADDRESS */
+        0x0, /* gcFEATURE_BIT_BLT_ROBUSTNESS_FIX */
+        0x0, /* gcFEATURE_BIT_BLT_OUT_OF_BOUND_FIX */
+        0x0, /* gcFEATURE_BIT_TFB_PERF_FIX */
+        0x0, /* gcFEATURE_BIT_SH_SUPERSCALAR_ARCH */
+        0x0, /* gcFEATURE_BIT_PA_ZEROAREA_LINE_FIX */
+        0x1, /* gcFEATURE_BIT_RS_TILER_YUV420_FIX */
+        0x0, /* gcFEATURE_BIT_ATTR_IN_GLOBAL_MEMORY */
+        0x0, /* gcFEATURE_BIT_SIMPLIFIED_CHECKERBOARD */
+        0x0, /* gcFEATURE_BIT_ADDR_REMAP */
+        0x0, /* gcFEATURE_BIT_ADDR_40BIT_OVERFLOW_FIX */
+        0x0, /* gcFEATURE_BIT_CLIP_DISTANCE_SUPPORT */
+        0x0, /* gcFEATURE_BIT_SEPARATED_TEXTURE_SAMPLER */
+        0x0, /* gcFEATURE_BIT_TS_INFO_IN_TX_DESCRIPTOR */
+        0x0, /* gcFEATURE_BIT_PER_STAGE_LOCAL_STORAGE */
+        0x0, /* gcFEATURE_BIT_DX11_FORMAT_SUPPORT */
+        0x0, /* gcFEATURE_BIT_OCCLUSION_SAMPLE_COUNTER */
+        0x0, /* gcFEATURE_BIT_FRONT_FACE_UINT */
+        0x0, /* gcFEATURE_BIT_DYNAMIC_TEXTURE_INDEXING */
+        0x0, /* gcFEATURE_BIT_D3D11_SUPPORT */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
+        0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
+        0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
+        0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
+        0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
+        0x0, /* gcFEATURE_BIT_G2D_FC_IN_DEC400EX */
+        0x0, /* gcFEATURE_BIT_G2D_NO_YUV420_SOURCE */
+        0x0, /* gcFEATURE_BIT_G2D_YUV420_101010 */
+        0x0, /* gcFEATURE_BIT_G2D_MultiSrcBlt_Pipe */
+        0x0, /* gcFEATURE_BIT_G2D_Stretch_MultiSrc_Pipe */
+        0x0, /* gcFEATURE_BIT_G2D_Normalization */
+        0x0, /* gcFEATURE_BIT_G2D_Normalization_Quantization */
+        0x0, /* gcFEATURE_BIT_G2D_FRAME_DONE_INTR */
+        0x0, /* gcFEATURE_BIT_G2D_MASK_AND_COLORKEY */
+        0x0, /* gcFEATURE_BIT_G2D_DEC400 */
+        0x0, /* gcFEATURE_BIT_G2D_3rd_PARTY_COMPRESSION_1_1 */
+        0x0, /* gcFEATURE_BIT_G2D_Histogram */
+        0x0, /* gcFEATURE_BIT_G2D_Brightness_Saturation */
+        0x0, /* gcFEATURE_BIT_VG_MMU */
+        0x0, /* gcFEATURE_BIT_VG_IM_FILTER */
+        0x0, /* gcFEATURE_BIT_VG_IM_YUV_PACKET */
+        0x0, /* gcFEATURE_BIT_VG_IM_YUV_PLANAR */
+        0x0, /* gcFEATURE_BIT_VG_PE_YUV_PACKET */
+        0x0, /* gcFEATURE_BIT_VG_RESOLVE_ENGINE */
+        0x0, /* gcFEATURE_BIT_VG_PE_COLOR_KEY */
+        0x0, /* gcFEATURE_BIT_VG_IM_INDEX_FORMAT */
+        0x0, /* gcFEATURE_BIT_VG_RESOLUTION_8K */
+        0x0, /* gcFEATURE_BIT_VG_IMAGE_16K */
+        0x1, /* gcFEATURE_BIT_VIP_HW_FINAL_RELEASE */
+        0x1, /* gcFEATURE_BIT_NN_SINGLEPORT_ACCUMBUFFER */
+        0x1, /* gcFEATURE_BIT_NN_STRIDE_SUPPORT */
+        0x1, /* gcFEATURE_BIT_SWTILING_PHASE1 */
+        0x0, /* gcFEATURE_BIT_SWTILING_PHASE2 */
+        0x0, /* gcFEATURE_BIT_TP_SIMPLE_INT16 */
+        0x1, /* gcFEATURE_BIT_TP_REAL_INT16 */
+        0x1, /* gcFEATURE_BIT_TP_ROI_POOLING */
+        0x1, /* gcFEATURE_BIT_TP_MAX_POOLING_STRIDE1 */
+        0x1, /* gcFEATURE_BIT_TP_LRN */
+        0x1, /* gcFEATURE_BIT_TP_REORDER */
+        0x1, /* gcFEATURE_BIT_TF_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_NONZERO_BORDER */
+        0x0, /* gcFEATURE_BIT_NN_MIRROR_BORDER */
+        0x1, /* gcFEATURE_BIT_AI_GPU */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_ABSDIFF */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_BITREPLACE */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_BOXFILTER */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_CORDIAC */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_DP32 */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_FILTER */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_IADD */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_SELECTADD */
+        0x0, /* gcFEATURE_BIT_EVIS_LERP_7OUTPUT */
+        0x0, /* gcFEATURE_BIT_EVIS_ACCSQ_8OUTPUT */
+        0x1, /* gcFEATURE_BIT_EVIS_VX2 */
+        0x1, /* gcFEATURE_BIT_TP_ENGINE */
+        0x1, /* gcFEATURE_BIT_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_TP_TENSOR_ADD_MUL */
+        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_INT16XINT8 */
+        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_8BIT_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_TP_SOFTMAX */
+        0x0, /* gcFEATURE_BIT_NN_23BITS_POST_MULTIPLIER_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_TP_23BITS_POST_MULTIPLIER_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_CONV_INT16X8BIT_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_NN_REMOVE_POOLING */
+        0x0, /* gcFEATURE_BIT_NN_40BIT_BIAS */
+        0x0, /* gcFEATURE_BIT_TP_REMOVE_USC */
+        0x1, /* gcFEATURE_BIT_NN_ZDP3 */
+        0x0, /* gcFEATURE_BIT_NN_ZDP6 */
+        0x0, /* gcFEATURE_BIT_NN_ZDP9 */
+        0x0, /* gcFEATURE_BIT_NN_XYDP9 */
+        0x1, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
+        0x1, /* gcFEATURE_BIT_NN_XYDP6 */
+        0x1, /* gcFEATURE_BIT_SWTILING_PHASE3 */
+        0x0, /* gcFEATURE_BIT_MCFE */
+        0x0, /* gcFEATURE_BIT_USC_STAY_LRU */
+        0x1, /* gcFEATURE_BIT_COEF_COMPRESSION_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_TP_COEF_COMPRESSION_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_COEF_DECOMPRESS_PERF2X */
+        0x0, /* gcFEATURE_BIT_TP_SMALLBATCH_PHASE1 */
+        0x1, /* gcFEATURE_BIT_OCB_COUNTER */
+        0x0, /* gcFEATURE_BIT_SCALER */
+        0x0, /* gcFEATURE_BIT_SCALER_4K */
+        0x0, /* gcFEATURE_BIT_INPUT_4BIT */
+        0x0, /* gcFEATURE_BIT_NN_NO_Z_LOCATION_OFFSET */
+        0x0, /* gcFEATURE_BIT_OCB_REMAP_PHYSICAL_ADDRESS */
+        0x0, /* gcFEATURE_BIT_NN_SLOW_OUTPUT */
+        0x1, /* gcFEATURE_BIT_NO_NARROW_POST_PROCESS_PIPE */
+        0x0, /* gcFEATURE_BIT_TP_NN_PROBE */
+        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_SUPPORT */
+        0x0, /* gcFEATURE_BIT_NN_XYDP0 */
+        0x0, /* gcFEATURE_BIT_NN_WRITE_WITHOUT_USC */
+        0x0, /* gcFEATURE_BIT_NN_HW_LIMITATION_NATIVE_KER_1x2_2x1 */
+        0x0, /* gcFEATURE_BIT_NN_SMALLBATCH_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SLICE_PADDING_TO_64BYTE_ALIGN */
+        0x0, /* gcFEATURE_BIT_NN_DW_1x1_CONV_MERGE */
+        0x0, /* gcFEATURE_BIT_TP_BFLOAT16 */
+        0x0, /* gcFEATURE_BIT_TP_23BITS_POST_MULTIPLIER */
+        0x0, /* gcFEATURE_BIT_NN_TRANSPOSE */
+        0x0, /* gcFEATURE_BIT_NN_ZDP_TRANSPOSE_CH9_ONLY */
+        0x0, /* gcFEATURE_BIT_USE_SINGLE_PORT_VIPSRAM */
+        0x0, /* gcFEATURE_BIT_NN_LEAKY_RELU */
+        0x0, /* gcFEATURE_BIT_NN_PRELU */
+        0x0, /* gcFEATURE_BIT_NN_PER_CHANNEL_QUANT */
+        0x0, /* gcFEATURE_BIT_NN_PER_CHANNEL_QUANT_ASYM */
+        0x0, /* gcFEATURE_BIT_NN_ASYMMETRIC_INT8 */
+        0x0, /* gcFEATURE_BIT_NN_FLOAT_POST_MULT */
+        0x0, /* gcFEATURE_BIT_PRELU_LEAKLY_RELU_CLAMP */
+        0x0, /* gcFEATURE_BIT_TPLITE_BFLOAT16 */
+        0x0, /* gcFEATURE_BIT_PREPROCESS_IMG_BUF_640BYTE_LIMIT */
+        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_FP16 */
+        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_BF16 */
+        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_FP32 */
+        0x0, /* gcFEATURE_BIT_TP_KERNEL_1BYTE_ALGIN */
+        0x0, /* gcFEATURE_BIT_BFLOAT_COEF_COMPRESSION_ZERO_COEFBIT14_INVERSE */
+        0x0, /* gcFEATURE_BIT_NN_COMPRESSION_BYPASSS */
+        0x0, /* gcFEATURE_BIT_TP_3_USC */
+        0x0, /* gcFEATURE_BIT_BFP_COEF_AUTO_PAD_INCOMPLETE_ZERO_IN_KZ_PLANE */
+        0x0, /* gcFEATURE_BIT_HW_V83 */
+        0x0, /* gcFEATURE_BIT_NN_NATIVE_STRIDE_TWO */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD */
+        0x0, /* gcFEATURE_BIT_NN_FLOAT32_IO */
+        0x0, /* gcFEATURE_BIT_TP_FLOAT32_IO */
+        0x0, /* gcFEATURE_BIT_NN_SMALL_BATCH_PHASE2 */
+        0x0, /* gcFEATURE_BIT_TILE_ACCESS_CAPABILITY */
+        0x0, /* gcFEATURE_BIT_FAST_DP3_PREPROCESSOR */
+        0x0, /* gcFEATURE_BIT_DEPTHWISE_SUPPORT_16BIT_FORMAT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ALU */
+        0x0, /* gcFEATURE_BIT_NN_ENHANCED_MAX_POOLING */
+        0x0, /* gcFEATURE_BIT_NN_TRANSPOSE_PHASE2 */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_FIELD_MOVE_TO_EXT_CMD */
+        0x0, /* gcFEATURE_BIT_NN_CMD_SUPPORT_SLICE */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_RELU */
+        0x0, /* gcFEATURE_BIT_TPLITE_SUPPORT_TP_DATA_TRANSPOSE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONV_1D */
+        0x0, /* gcFEATURE_BIT_USE_VIPSRAM_FOR_KERNEL_STREAMING */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_DUMMY_TILE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_KERNEL_1BYTE_ALIGN */
+        0x0, /* gcFEATURE_BIT_NN_1x1_NON_POOLING_PACKING */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_BOTH_CONV_NATIVE_STRIDE2_AND_POOLING */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONV1x1_AND_NATIVE_CONV_STRIDE2 */
+        0x0, /* gcFEATURE_BIT_TP_REMOVE_FC */
+        0x0, /* gcFEATURE_BIT_VIP_REMOVE_MMU */
+        0x0, /* gcFEATURE_BIT_NN_RD_IMG_NEED_EXTRA_SPACE */
+        0x0, /* gcFEATURE_BIT_VIP_INDIV_CLK_NN */
+        0x0, /* gcFEATURE_BIT_VIP_EXPORT_CLK_DIV2 */
+        0x0, /* gcFEATURE_BIT_NN_2D_AVERAGE_OUTPUT */
+        0x0, /* gcFEATURE_BIT_NN_JOB_CANCELATION */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_INLINE_NWHC_AND_MATRIX_TRANSPOSE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_BATCH */
+        0x0, /* gcFEATURE_BIT_VIP_SUPPORT_DEC */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_MULTI_AXI_ID */
+        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_INT32 */
+        0x0, /* gcFEATURE_BIT_NN_DISTRIBUTED_VIPSRAM */
+        0x0, /* gcFEATURE_BIT_NN_FC_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_PHASE1 */
+        0x0, /* gcFEATURE_BIT_VIP_DEC400 */
+        0x0, /* gcFEATURE_BIT_NN_POST_MULT_SUPPORT_FP_CONV */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_16_8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_SPECIAL_8BIT_SIGN_ABS_CONV */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONFIGURABLE_FASTXDP3 */
+        0x0, /* gcFEATURE_BIT_NN_USE_CORE_SHARING_IMGBUF_AND_SEQ_NO_ZEROSKIPPING */
+        0x0, /* gcFEATURE_BIT_SUPPORT_DECONVNxN_S_LESS_THAN_16 */
+        0x0, /* gcFEATURE_BIT_NN_PICOCORE_DEPTHWISE */
+        0x0, /* gcFEATURE_BIT_VIP_SUPPORT_TENSOR_TRANSFER */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CMD_LOOP */
+        0x0, /* gcFEATURE_BIT_VIP_SUPPORT_X_FRAME_COMPRESSION */
+        0x0, /* gcFEATURE_BIT_NN_SMALL_ACCUM */
+        0x0, /* gcFEATURE_BIT_NN_SINGLE_POSTMULT_FIELDS_IN_BITSTREAM */
+        0x0, /* gcFEATURE_BIT_POST_MULTIPLIER_LOW_POWER_MODE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_EFUSE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_STREAMPROCESSOR */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_CONV_CORE_BYPASS */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CLAMP_BORDER_MODE */
+        0x0, /* gcFEATURE_BIT_NN_ELEMENTWISE_BROADCAST_STRIDE_X_0 */
+        0x0, /* gcFEATURE_BIT_NN_2ND_IMAGE_DATA_TYPE */
+        0x0, /* gcFEATURE_BIT_FP_INIMAGE_POST_SCALE */
+        0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
+        0x0, /* gcFEATURE_BIT_TENSOR_DMA */
+        0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
+        0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
+        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
+        0x0, /* gcFEATURE_BIT_SUPPORT_BATCH_ALIGNMENT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
+        0x0, /* gcFEATURE_BIT_SRAM_PARITY */
+        0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SH_IN_PARALLEL */
+        0x0, /* gcFEATURE_BIT_NN_ASYNC_DMA */
+        0x0, /* gcFEATURE_BIT_NN_STRIDE2_FAST_XDP3 */
+        0x0, /* gcFEATURE_BIT_NN_2V4_STRUCTURED_SPARSITY */
+        0x0, /* gcFEATURE_BIT_NN_SP_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_SEPARATE_STREAMBUF_ADDR */
+        0x0, /* gcFEATURE_BIT_NN_TF32_MAC */
+        0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_TP_REORDER_FIX */
+        0x1, /* gcFEATURE_BIT_NN_CONVOUT_FIFO_DEPTH_FIX */
+        0x0, /* gcFEATURE_BIT_NN_ZXDP3_KERNEL_READ_CONFLICT_FIX */
+        0x1, /* gcFEATURE_BIT_NN_ZDP3_NO_COMPRESS_FIX */
+        0x1, /* gcFEATURE_BIT_NN_ASYNC_COPY_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_HI_REORDER_FIX */
+        0x1, /* gcFEATURE_BIT_INCORRECT_WR_REQ_TO_USC_BETWEEN_REORDER_AND_NORMAL_LAYER_FIX */
+        0x0, /* gcFEATURE_BIT_TP_REORDER_LAYER_SUSPEND_FIX */
+        0x1, /* gcFEATURE_BIT_NN_ASYNC_COPY_MERGE_FIX */
+        0x0, /* gcFEATURE_BIT_USC_INVALIDATE_CACHE_LINE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_REQ_SLOWARBITRATION_FIX */
+        0x0, /* gcFEATURE_BIT_IMAGE_PARTIAL_CACHE_FIX */
+        0x0, /* gcFEATURE_BIT_FULLCACHE_KERNELHEAD_FIX */
+        0x0, /* gcFEATURE_BIT_NN_ZDP_INIMAGE_SIZE_FIX */
+        0x0, /* gcFEATURE_BIT_IDLE_BEFORE_FLUSH_COMPLETE_FIX */
+        0x0, /* gcFEATURE_BIT_NO_FLUSH_USC_FIX */
+        0x0, /* gcFEATURE_BIT_SMALL_BATCH_FLOPS_RESET_FIX */
+        0x1, /* gcFEATURE_BIT_SMALL_BATCH_DISBLE_FIX */
+        0x1, /* gcFEATURE_BIT_OUTPUT_CONVERT_UINT8_INT8_TO_UINT16_INT16_FIX */
+        0x0, /* gcFEATURE_BIT_IMAGE_NOT_PACKED_IN_SRAM_FIX */
+        0x0, /* gcFEATURE_BIT_COEF_DELTA_CORD_OVERFLOW_ZRL_8BIT_FIX */
+        0x0, /* gcFEATURE_BIT_USC_INDIVIDUAL_PORT_WRT_EARLY_EVICT_DATA_CORRUPT_FIX */
+        0x0, /* gcFEATURE_BIT_LOW_EFFICIENCY_OF_ID_WRITE_IMGBUF_FIX */
+        0x0, /* gcFEATURE_BIT_KERNEL_VIP_SRAM_READ_BW_LIMITATION_FIX */
+        0x0, /* gcFEATURE_BIT_USC_BOTTLENECK_FIX */
+        0x1, /* gcFEATURE_BIT_KERNEL_PER_CORE_LESS_THAN_THIRD_COEF_BUFF_DEPTH_FIX */
+        0x1, /* gcFEATURE_BIT_NN_TILE_NUM_BIGGER_THAN_1024_FIX */
+        0x0, /* gcFEATURE_BIT_KERNEL_SIZE_WASTE_IN_PARTIAL_MODE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_COMMAND_KERNEL_REQUEST_CONFICT_FIX */
+        0x0, /* gcFEATURE_BIT_TP_REORDER_INTILE_X_SIZE_512_FIX */
+        0x0, /* gcFEATURE_BIT_IMG_POP_PIPELINE_PAUSE_FIX */
+        0x0, /* gcFEATURE_BIT_FULLCACHE_KERNEL_INTERLEAVE_FIX */
+        0x1, /* gcFEATURE_BIT_V8_SINGLE_PORT_ACCUMULATION_BUFFER_RW_CONFICT_ZERO_SKIP_PERF_FIX */
+        0x0, /* gcFEATURE_BIT_V8_ACCUMLATION_READ_OUT_HAS_BUBBLES_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_DEPTHWISE_NEIGHBOR_IMG_DATA_TRANSFER_NOT_EFFICIENT_FIX */
+        0x0, /* gcFEATURE_BIT_DR_JD_DIFF_CONDITION_FOR_CACHELINE_MODE_PRE_FIX */
+        0x0, /* gcFEATURE_BIT_TP_ACCESS_VIPSRAM_OT_IS_ONE_FIX */
+        0x0, /* gcFEATURE_BIT_EVIS2_FLOP_RESET_FIX */
+        0x0, /* gcFEATURE_BIT_OUTIMAGE_X_BITWIDTH_LIMIT_FOR_NN_TRANSPOSE_FIX */
+        0x0, /* gcFEATURE_BIT_USC_ASYNC_CP_RTN_FLOP_RESET_FIX */
+        0x0, /* gcFEATURE_BIT_IMG_ADDR_NOT_WRAP_IF_OVER_OCB_ADDR_FIX */
+        0x0, /* gcFEATURE_BIT_NEGATIVE_POST_SHIFT_FIX */
+        0x0, /* gcFEATURE_BIT_INIMAGE_2DTILE_NOT_LESS_160PIXEL_FIX */
+        0x0, /* gcFEATURE_BIT_IMG_CAHCE_MODE_MUST_0_IN_IMG_DIRECT_MODE_FIX */
+        0x0, /* gcFEATURE_BIT_BURST_COLLECT_DUMMY_DATA_WASTE_CYCLES_FIX */
+        0x1, /* gcFEATURE_BIT_INIMG_NOT_64BYTE_ALIGN_CACHELINE_MODE_FIX */
+        0x1, /* gcFEATURE_BIT_TP_FC_FLOAT_LAST_PIXEL_NEGATIVE_0_FIX */
+        0x1, /* gcFEATURE_BIT_NN_WASTE_COEF_READ_WRITE_BANDWIDTH_128BYTE_VIPSRAM_IN_FULL_PATIAL_CACHE_MODE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_IN_TILE_DATA_IS_ALL_PAD_FIX */
+        0x0, /* gcFEATURE_BIT_NN_TP_INSTR_COMPLETE_IN_SAME_CYCLE_WITH_WAIT_EVENT_FIX */
+        0x1, /* gcFEATURE_BIT_CORE_IMAGE_TRANSER_NOT_EFFICIENT_BETWEEN_PARTITION_FIX */
+        0x1, /* gcFEATURE_BIT_TP_FC_KERNEL_STREAM_MUST_LESS_THAN_OR_EQUAL_TO_64BYTE_WHEN_1BYTE_ALGINE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_KERNEL_1x1_NO_PAD_FIX */
+        0x1, /* gcFEATURE_BIT_NN_DEPTHWISE_AFTER_16BIT_LAYER_LIMIT_FIX */
+        0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
+        0x0, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
+        0x1, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
+        0x1, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
+        0x1, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
+        0x1, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
+        0x1, /* gcFEATURE_BIT_V83_CONVERTER_FOR_NEG_0_FIX */
+        0x1, /* gcFEATURE_BIT_NN_2ND_IMG_SMALL_3D_TILE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_TILE_YSIZE_127_LIMITATION_FIX */
+        0x1, /* gcFEATURE_BIT_NN_CONV_1D_16BIT_FORMAT_INTILE_SIZE_LIMITATION_FIX */
+        0x1, /* gcFEATURE_BIT_NN_VIPSRAM_DOUBLE_BUFFER_FIX */
+        0x0, /* gcFEATURE_BIT_NN_JD_DIRECT_MODE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_KERNEL_DIRECT_WRONG_PUSH_FIX */
+        0x1, /* gcFEATURE_BIT_HI_DEFAULT_ENABLE_REORDER_FIX */
+        0x1, /* gcFEATURE_BIT_V8_DIRECT_MODE_START_ADDR_BIAS_FOR_NEGATIVE_OFFSET_FIX */
+        0x1, /* gcFEATURE_BIT_V83_INTILESIZE_1X1_10BITS_FIX */
+        0x0, /* gcFEATURE_BIT_FASTXDP3_ONLY_IN_DEPTHWISE_FIX */
+        0x1, /* gcFEATURE_BIT_US_SRAM_READ_INTF_FIFO_OVERFLOW_FIX */
+        0x0, /* gcFEATURE_BIT_USC_PAUSE_TP_WR_REQ_MORE_THAN_256_CYCLES_FIX */
+        0x1, /* gcFEATURE_BIT_DEPTHWISE_FLOAT_FIX */
+        0x0, /* gcFEATURE_BIT_TP_CIRCULAR_BUF_WRAP_ADDRESS_OVERFLOW_FIX */
+        0x0, /* gcFEATURE_BIT_NN_CIRCULAR_BUF_WRAP_ADDRESS_OVERFLOW_FIX */
+        0x1, /* gcFEATURE_BIT_CLOCK_DIV2_FREQ_CHANGE_FIX */
+        0x1, /* gcFEATURE_BIT_SMALL_TILE_TENSOR_ADD_FIX */
+        0x1, /* gcFEATURE_BIT_DECOMPRESSOR_DEPTHWISE_FLOAT_FIX */
+        0x0, /* gcFEATURE_BIT_TP_CIRCULAR_BUF_WRAP_ADDRESS_LESS_FIX */
+        0x1, /* gcFEATURE_BIT_V83_NUMOFPENDINGTILES_FOR_2NDIMAGE_FIX */
+        0x1, /* gcFEATURE_BIT_V83_1ST_CACHE_MODE_VIPSRAM_RD_UPDATE_FIX */
+        0x1, /* gcFEATURE_BIT_V83_1ST_KERNEL_STREAM_BUFFER_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_USC_RW_SAME_CACHELINE_UPDATE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_KERNEL_MSS_SBP2_DIRECT_STEAM_STEAM_FIX */
+        0x1, /* gcFEATURE_BIT_CORE_NUM_OF_KID_FOR_MULTI_LAYER_FIX */
+        0x0, /* gcFEATURE_BIT_KERNEL_XSIZE_YSIZE_NUM_FIX */
+        0x1, /* gcFEATURE_BIT_IMGRD_ROW_NUMBER_FIX */
+        0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
+        0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
+        0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x1, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
+        0x1, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
+        0x1, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
+        0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
+        0x1, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
+        0x1, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
+        0x1, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
+        0x1, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
+        0x1, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
+        0x1, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
+        0x1, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
+        0x1, /* gcFEATURE_BIT_VZ_GROUP_START_Z_OVERFLOW_FIX */
+        0x1, /* gcFEATURE_BIT_V82_STREAMMODE_VIPSRAM_ADDRESS_FIX */
+        0x1, /* gcFEATURE_BIT_GEMM_NO_SUPPORT_SMALLBATCH_FIX */
+        0x1, /* gcFEATURE_BIT_SBP1_KHEAD_CMDSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_BURSTCOLLECTOR_MAXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
+        0x1, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
+        0x1, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x1, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x1, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x1, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_PRE_CORE_LOTS_ZEROSKIP_KERNEL_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_MATRIX_A_TRSP1_CHNUM_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_4BIT_SBP2_BLOCKCTRL2_FIX */
+        0x1, /* gcFEATURE_BIT_B2B_RETRUN_NN_CMD_DONE_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_VLW_3D_TILE_INFO_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_SPECIAL_WORDSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
+        0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
+        0x1, /* gcFEATURE_BIT_NN_INT16_ALU */
+        0x1, /* gcFEATURE_BIT_NN_INT8_SCALE */
+        0x1, /* gcFEATURE_BIT_NN_POWER_ISOLATION */
+        0x1, /* gcFEATURE_BIT_ZRL_7BIT */
+        0x0, /* gcFEATURE_BIT_NN_SMALLBATCH */
+        0x0, /* gcFEATURE_BIT_TP_SMALLBATCH */
+        0x1, /* gcFEATURE_BIT_ZRL_8BIT */
+        0x0, /* gcFEATURE_BIT_DDR_BURST_LEN_256B */
+        0x0, /* gcFEATURE_BIT_XY_OFFSET_LIMITATION_FIX */
+        0x0, /* gcFEATURE_BIT_NN_NONZERO_MIRROR_BORDER */
+        0x0, /* gcFEATURE_BIT_IMAGE_PARTIAL_CACHE */
+    },
+    /* GCNANOULTRA31_VIP2 */
+    {
+        0x8000, /* ChipID */
+        0x6205, /* ChipRevision */
+        0x80003, /* ProductID */
+        0x1, /* EcoID */
+        0x15, /* CustomerID */
+        0x0, /* PatchVersion */
+        "GCNANOULTRA31_VIP2", /* ProductName */
+        0x0, /* FormalRelease */
+        0x40, /* gcFEATURE_VALUE_TempRegisters */
+        0x200, /* gcFEATURE_VALUE_ThreadCount */
+        0x2, /* gcFEATURE_VALUE_NumShaderCores */
+        0x200, /* gcFEATURE_VALUE_InstructionCount */
+        0x140, /* gcFEATURE_VALUE_NumberOfConstants */
+        0x1, /* gcFEATURE_VALUE_CoreCount */
+        0x10, /* gcFEATURE_VALUE_LocalStorageSize */
+        0x0, /* gcFEATURE_VALUE_LocalStorageSize_1 */
+        0x0, /* gcFEATURE_VALUE_LocalStorageSize_2 */
+        0x8, /* gcFEATURE_VALUE_L1CacheSize */
+        0x0, /* gcFEATURE_VALUE_L1CacheSize_1 */
+        0x0, /* gcFEATURE_VALUE_L1CacheSize_2 */
+        0x200, /* gcFEATURE_VALUE_InstructionMemorySize */
+        0x14, /* gcFEATURE_VALUE_ShaderPCLength */
+        0x10, /* gcFEATURE_VALUE_USC_MAX_PAGES */
+        0x0, /* gcFEATURE_VALUE_USC_MAX_PAGES_1 */
+        0x0, /* gcFEATURE_VALUE_USC_MAX_PAGES_2 */
+        0x1, /* gcFEATURE_VALUE_NumPixelPipes */
+        0x2, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS */
+        0x0, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS_1 */
+        0x0, /* gcFEATURE_VALUE_USC_CACHE_CONTROLLERS_2 */
+        0x2, /* gcFEATURE_VALUE_USC_BANKS */
+        0x0, /* gcFEATURE_VALUE_USC_BANKS_1 */
+        0x0, /* gcFEATURE_VALUE_USC_BANKS_2 */
+        0x20, /* gcFEATURE_VALUE_VIRTUAL_ADDRESS_BITS */
+        0x0, /* gcFEATURE_VALUE_PHYSICAL_ADDRESS_BITS */
+        0x10, /* gcFEATURE_VALUE_Streams */
+        0x10, /* gcFEATURE_VALUE_VaryingCount */
+        0x400, /* gcFEATURE_VALUE_VertexOutputBufferSize */
+        0x0, /* gcFEATURE_VALUE_BufferSize */
+        0x10, /* gcFEATURE_VALUE_VertexCacheSize */
+        0x1, /* gcFEATURE_VALUE_NumResolvePipes */
+        0x10, /* gcFEATURE_VALUE_RESULT_WINDOW_MAX_SIZE */
+        0x0, /* gcFEATURE_VALUE_ClusterAliveMask */
+        0x0, /* gcFEATURE_VALUE_G2D_DEC400_MINOR */
+        0x0, /* gcFEATURE_VALUE_G2D_TILING_MINOR */
+        0x0, /* gcFEATURE_VALUE_PS_INSTRUCTION_COUNT */
+        0x0, /* gcFEATURE_VALUE_PS_INPUT_COMPONENTS */
+        0x0, /* gcFEATURE_VALUE_AIGM_MAX_SIZE */
+        0x40, /* gcFEATURE_VALUE_NNMadPerCore */
+        0x2, /* gcFEATURE_VALUE_NNCoreCount */
+        0x2, /* gcFEATURE_VALUE_NN_ACTIVE_CORE_COUNT */
+        0x2, /* gcFEATURE_VALUE_NNCoreCount_INT8 */
+        0x2, /* gcFEATURE_VALUE_NNCoreCount_INT16 */
+        0x0, /* gcFEATURE_VALUE_NNCoreCount_UINT16 */
+        0x0, /* gcFEATURE_VALUE_NNCoreCount_FLOAT16 */
+        0x0, /* gcFEATURE_VALUE_NNCoreCount_BFLOAT */
+        0x6, /* gcFEATURE_VALUE_NNInputBufferDepth */
+        0x40, /* gcFEATURE_VALUE_NNAccumBufferDepth */
+        0x400, /* gcFEATURE_VALUE_TPEngine_PwlLUTCount */
+        0x10, /* gcFEATURE_VALUE_TPEngine_PwlLUTSize */
+        0x20000, /* gcFEATURE_VALUE_VIP_SRAM_SIZE */
+        {0x0, }, /* gcFEATURE_VALUE_VIP_SRAM_SIZE_ARRAY */
+        0x1, /* gcFEATURE_VALUE_TPEngine_CoreCount */
+        0x0, /* gcFEATURE_VALUE_AXI_SRAM_SIZE */
+        0x4, /* gcFEATURE_VALUE_NN_INIMAGE_OFFSET_BITS */
+        0x180, /* gcFEATURE_VALUE_TP_REORDER_INIMAGE_SIZE */
+        0x7, /* gcFEATURE_VALUE_TPLite_CoreCount */
+        0x0, /* gcFEATURE_VALUE_NN_PREPROCESSOR_MAX_SEGMENT_PER_CYCLE */
+        0x1, /* gcFEATURE_VALUE_NNFP16_XYDP_X */
+        0x1, /* gcFEATURE_VALUE_NNFP16_XYDP_Y */
+        0x1, /* gcFEATURE_VALUE_NNFP16_ZDP */
+        0x8, /* gcFEATURE_VALUE_NN_LANES_PER_OUT_CYCLE */
+        0x0, /* gcFEATURE_VALUE_LUT_ACT_LANES */
+        0x20, /* gcFEATURE_VALUE_MAX_OT_NUMBER */
+        0x40, /* gcFEATURE_VALUE_PHYSICAL_VIP_SRAM_WIDTH_IN_BYTE */
+        0x20, /* gcFEATURE_VALUE_EQUIVALENT_VIP_SRAM_WIDTH_INBYTE */
+        0x8, /* gcFEATURE_VALUE_TP_ZRL_BITS */
+        0x8, /* gcFEATURE_VALUE_NN_ZRL_BITS */
+        0x100, /* gcFEATURE_VALUE_NN_ZRL_VALID_ZERO_NUMBER */
+        0x80, /* gcFEATURE_VALUE_LATENCY_HIDING_AT_FULL_AXI_BW */
+        0x10, /* gcFEATURE_VALUE_AXI_BUS_WIDTH */
+        0xb, /* gcFEATURE_VALUE_NN_KERNEL_X_SIZE */
+        0xb, /* gcFEATURE_VALUE_NN_KERNEL_Y_SIZE */
+        0xf, /* gcFEATURE_VALUE_NN_FC_KERNEL_Y_SIZE */
+        0xfffff, /* gcFEATURE_VALUE_NN_KERNEL_Z_SIZE */
+        0xf, /* gcFEATURE_VALUE_NN_X_OFFSET */
+        0xf, /* gcFEATURE_VALUE_NN_Y_OFFSET */
+        0x40, /* gcFEATURE_VALUE_DDR_KERNEL_BURST_SIZE */
+        0x40, /* gcFEATURE_VALUE_MIN_AXI_BURST_SIZE */
+        0x10, /* gcFEATURE_VALUE_OUTIMAGE_X_STRIDE_BITS */
+        0x0, /* gcFEATURE_VALUE_OUTIMAGE_Y_STRIDE_BITS */
+        0x0, /* gcFEATURE_VALUE_OUTIMAGE_SLICE_BITS */
+        0xd, /* gcFEATURE_VALUE_OUTIMAGE_X_SIZE_BITS */
+        0xd, /* gcFEATURE_VALUE_OUTIMAGE_Y_SIZE_BITS */
+        0xe, /* gcFEATURE_VALUE_OUTIMAGE_Z_SIZE_BITS */
+        0x10, /* gcFEATURE_VALUE_INIMAGE_X_STRIDE_BITS */
+        0x10, /* gcFEATURE_VALUE_IMIMAGE_Y_STRIDE_BITS */
+        0x0, /* gcFEATURE_VALUE_INIMAGE_SLICE_BITS */
+        0xd, /* gcFEATURE_VALUE_INIMAGE_X_SIZE_BITS */
+        0xd, /* gcFEATURE_VALUE_INIMAGE_Y_SIZE_BITS */
+        0x40, /* gcFEATURE_VALUE_MAX_TILE_X_SIZE */
+        0x1, /* gcFEATURE_VALUE_NN_CLUSTER_NUM_FOR_POWER_CONTROL */
+        0x0, /* gcFEATURE_VALUE_NN_IN_LINES_PER_CYCLE */
+        0x0, /* gcFEATURE_VALUE_NN_MP_INTER_CONNECT_RING_COUNT */
+        0x20, /* gcFEATURE_VALUE_NN_SMALL_ACCUM_BITS */
+        0x1, /* gcFEATURE_VALUE_NN_COEF_DECOMPRESS_PERF_X */
+        0x0, /* gcFEATURE_VALUE_SP_VECTOR_DEPTH */
+        0x32, /* gcFEATURE_VALUE_VIPSRAM_CLK_DOMAIN_RATIO_PERCENT */
+        0x0, /* gcFEATURE_VALUE_VIP_VERSION */
+        0x0, /* gcFEATURE_VALUE_NN_COMMAND_BUFFER_SIZE */
+        0x10, /* gcFEATURE_VALUE_DECOMP_VZ_GROUP_BITS */
+        0x3, /* gcFEATURE_VALUE_NN_LOOP1_DP_NUMBER */
+        0x1, /* gcFEATURE_BIT_REG_FastClear */
+        0x0, /* gcFEATURE_BIT_REG_SpecialAntiAliasing */
+        0x1, /* gcFEATURE_BIT_REG_Pipe3D */
+        0x1, /* gcFEATURE_BIT_REG_DXTTextureCompression */
+        0x0, /* gcFEATURE_BIT_REG_DebugMode */
+        0x0, /* gcFEATURE_BIT_REG_ZCompression */
+        0x0, /* gcFEATURE_BIT_REG_YUV420Filter */
+        0x1, /* gcFEATURE_BIT_REG_MSAA */
+        0x0, /* gcFEATURE_BIT_REG_DC */
+        0x0, /* gcFEATURE_BIT_REG_Pipe2D */
+        0x1, /* gcFEATURE_BIT_REG_ETC1TextureCompression */
+        0x1, /* gcFEATURE_BIT_REG_FastScaler */
+        0x1, /* gcFEATURE_BIT_REG_HighDynamicRange */
+        0x1, /* gcFEATURE_BIT_REG_YUV420Tiler */
+        0x1, /* gcFEATURE_BIT_REG_ModuleCG */
+        0x0, /* gcFEATURE_BIT_REG_MinArea */
+        0x0, /* gcFEATURE_BIT_REG_NoEZ */
+        0x0, /* gcFEATURE_BIT_REG_No422Texture */
+        0x0, /* gcFEATURE_BIT_REG_BufferInterleaving */
+        0x1, /* gcFEATURE_BIT_REG_ByteWrite2D */
+        0x0, /* gcFEATURE_BIT_REG_NoScaler */
+        0x1, /* gcFEATURE_BIT_REG_YUY2Averaging */
+        0x0, /* gcFEATURE_BIT_REG_HalfPECache */
+        0x0, /* gcFEATURE_BIT_REG_HalfTXCache */
+        0x0, /* gcFEATURE_BIT_REG_YUY2RenderTarget */
+        0x0, /* gcFEATURE_BIT_REG_Mem32BitSupport */
+        0x0, /* gcFEATURE_BIT_REG_PipeVG */
+        0x0, /* gcFEATURE_BIT_REG_VGTS */
+        0x0, /* gcFEATURE_BIT_REG_FE20 */
+        0x1, /* gcFEATURE_BIT_REG_ByteWrite3D */
+        0x1, /* gcFEATURE_BIT_REG_RsYuvTarget */
+        0x1, /* gcFEATURE_BIT_REG_FE20BitIndex */
+        0x1, /* gcFEATURE_BIT_REG_FlipY */
+        0x1, /* gcFEATURE_BIT_REG_DualReturnBus */
+        0x1, /* gcFEATURE_BIT_REG_EndiannessConfig */
+        0x1, /* gcFEATURE_BIT_REG_Texture8K */
+        0x1, /* gcFEATURE_BIT_REG_CorrectTextureConverter */
+        0x1, /* gcFEATURE_BIT_REG_SpecialMsaaLod */
+        0x1, /* gcFEATURE_BIT_REG_FastClearFlush */
+        0x1, /* gcFEATURE_BIT_REG_2DPE20 */
+        0x0, /* gcFEATURE_BIT_REG_CorrectAutoDisable */
+        0x1, /* gcFEATURE_BIT_REG_Render8K */
+        0x1, /* gcFEATURE_BIT_REG_TileStatus2Bits */
+        0x1, /* gcFEATURE_BIT_REG_SeparateTileStatusWhenInterleaved */
+        0x1, /* gcFEATURE_BIT_REG_SuperTiled32x32 */
+        0x0, /* gcFEATURE_BIT_REG_VG20 */
+        0x0, /* gcFEATURE_BIT_REG_TSExtendedCommands */
+        0x1, /* gcFEATURE_BIT_REG_CompressionFifoFixed */
+        0x1, /* gcFEATURE_BIT_REG_ExtraShaderInstructions0 */
+        0x0, /* gcFEATURE_BIT_REG_VGFilter */
+        0x0, /* gcFEATURE_BIT_REG_VG21 */
+        0x1, /* gcFEATURE_BIT_REG_ShaderGetsW */
+        0x1, /* gcFEATURE_BIT_REG_ExtraShaderInstructions1 */
+        0x1, /* gcFEATURE_BIT_REG_DefaultReg0 */
+        0x1, /* gcFEATURE_BIT_REG_MC20 */
+        0x0, /* gcFEATURE_BIT_REG_ShaderMSAASideband */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes0 */
+        0x0, /* gcFEATURE_BIT_REG_VAA */
+        0x0, /* gcFEATURE_BIT_REG_BypassInMSAA */
+        0x0, /* gcFEATURE_BIT_REG_HierarchicalZ */
+        0x0, /* gcFEATURE_BIT_REG_NewTexture */
+        0x0, /* gcFEATURE_BIT_REG_A8TargetSupport */
+        0x1, /* gcFEATURE_BIT_REG_CorrectStencil */
+        0x1, /* gcFEATURE_BIT_REG_EnhanceVR */
+        0x1, /* gcFEATURE_BIT_REG_RSUVSwizzle */
+        0x0, /* gcFEATURE_BIT_REG_V2Compression */
+        0x0, /* gcFEATURE_BIT_REG_VGDoubleBuffer */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes1 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes2 */
+        0x0, /* gcFEATURE_BIT_REG_TextureStride */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes3 */
+        0x1, /* gcFEATURE_BIT_REG_CorrectAutoDisable1 */
+        0x0, /* gcFEATURE_BIT_REG_AutoRestartTS */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes4 */
+        0x0, /* gcFEATURE_BIT_REG_L2Windowing */
+        0x1, /* gcFEATURE_BIT_REG_HalfFloatPipe */
+        0x1, /* gcFEATURE_BIT_REG_PixelDither */
+        0x1, /* gcFEATURE_BIT_REG_TwoStencilReference */
+        0x1, /* gcFEATURE_BIT_REG_ExtendedPixelFormat */
+        0x1, /* gcFEATURE_BIT_REG_CorrectMinMaxDepth */
+        0x1, /* gcFEATURE_BIT_REG_DitherAndFilterPlusAlpha2D */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes5 */
+        0x0, /* gcFEATURE_BIT_REG_New2D */
+        0x1, /* gcFEATURE_BIT_REG_NewFloatingPointArithmetic */
+        0x1, /* gcFEATURE_BIT_REG_TextureHorizontalAlignmentSelect */
+        0x1, /* gcFEATURE_BIT_REG_NonPowerOfTwo */
+        0x1, /* gcFEATURE_BIT_REG_LinearTextureSupport */
+        0x1, /* gcFEATURE_BIT_REG_Halti0 */
+        0x0, /* gcFEATURE_BIT_REG_CorrectOverflowVG */
+        0x1, /* gcFEATURE_BIT_REG_NegativeLogFix */
+        0x1, /* gcFEATURE_BIT_REG_ResolveOffset */
+        0x1, /* gcFEATURE_BIT_REG_OkToGateAxiClock */
+        0x1, /* gcFEATURE_BIT_REG_MMU */
+        0x1, /* gcFEATURE_BIT_REG_WideLine */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes6 */
+        0x1, /* gcFEATURE_BIT_REG_FcFlushStall */
+        0x1, /* gcFEATURE_BIT_REG_LineLoop */
+        0x1, /* gcFEATURE_BIT_REG_LogicOp */
+        0x1, /* gcFEATURE_BIT_REG_SeamlessCubeMap */
+        0x1, /* gcFEATURE_BIT_REG_SuperTiledTexture */
+        0x1, /* gcFEATURE_BIT_REG_LinearPE */
+        0x1, /* gcFEATURE_BIT_REG_RectPrimitive */
+        0x0, /* gcFEATURE_BIT_REG_Composition */
+        0x1, /* gcFEATURE_BIT_REG_CorrectAutoDisableCountWidth */
+        0x1, /* gcFEATURE_BIT_REG_PESwizzle */
+        0x1, /* gcFEATURE_BIT_REG_EndEvent */
+        0x1, /* gcFEATURE_BIT_REG_S1S8 */
+        0x1, /* gcFEATURE_BIT_REG_Halti1 */
+        0x0, /* gcFEATURE_BIT_REG_RGB888 */
+        0x0, /* gcFEATURE_BIT_REG_TX_YUVAssembler */
+        0x1, /* gcFEATURE_BIT_REG_DynamicFrequencyScaling */
+        0x0, /* gcFEATURE_BIT_REG_TXFilter */
+        0x1, /* gcFEATURE_BIT_REG_FullDirectFB */
+        0x0, /* gcFEATURE_BIT_REG_OnePass2DFilter */
+        0x1, /* gcFEATURE_BIT_REG_ThreadWalkerInPS */
+        0x1, /* gcFEATURE_BIT_REG_TileFiller */
+        0x1, /* gcFEATURE_BIT_REG_YUVStandard */
+        0x0, /* gcFEATURE_BIT_REG_MultiSourceBlt */
+        0x0, /* gcFEATURE_BIT_REG_YUVConversion */
+        0x1, /* gcFEATURE_BIT_REG_FlushFixed2D */
+        0x1, /* gcFEATURE_BIT_REG_Interleaver */
+        0x1, /* gcFEATURE_BIT_REG_MixedStreams */
+        0x0, /* gcFEATURE_BIT_REG_L2CacheFor2D420 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes7 */
+        0x0, /* gcFEATURE_BIT_REG_NoIndexPattern */
+        0x1, /* gcFEATURE_BIT_REG_TextureTileStatus */
+        0x1, /* gcFEATURE_BIT_REG_DecompressZ16 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes8 */
+        0x1, /* gcFEATURE_BIT_REG_DERotationStallFix */
+        0x0, /* gcFEATURE_BIT_REG_OclOnly */
+        0x1, /* gcFEATURE_BIT_REG_NewFeatures0 */
+        0x1, /* gcFEATURE_BIT_REG_InstructionCache */
+        0x0, /* gcFEATURE_BIT_REG_GeometryShader */
+        0x1, /* gcFEATURE_BIT_REG_TexCompressionSupertiled */
+        0x1, /* gcFEATURE_BIT_REG_Generics */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes9 */
+        0x0, /* gcFEATURE_BIT_REG_FastMSAA */
+        0x0, /* gcFEATURE_BIT_REG_WClip */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes10 */
+        0x1, /* gcFEATURE_BIT_REG_UnifiedSamplers */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes11 */
+        0x1, /* gcFEATURE_BIT_REG_PerformanceCounters */
+        0x1, /* gcFEATURE_BIT_REG_ExtraShaderInstructions2 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes12 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes13 */
+        0x1, /* gcFEATURE_BIT_REG_DEEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_ACE */
+        0x1, /* gcFEATURE_BIT_REG_TXEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_PEEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_DEEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes14 */
+        0x0, /* gcFEATURE_BIT_REG_PowerOptimizations0 */
+        0x1, /* gcFEATURE_BIT_REG_NewHZ */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes15 */
+        0x0, /* gcFEATURE_BIT_REG_DEEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements4 */
+        0x1, /* gcFEATURE_BIT_REG_TXEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_FEEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_PEEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_PAEnhancements1 */
+        0x0, /* gcFEATURE_BIT_REG_DENoGamma */
+        0x0, /* gcFEATURE_BIT_REG_PAEnhancements2 */
+        0x0, /* gcFEATURE_BIT_REG_DEEnhancements4 */
+        0x1, /* gcFEATURE_BIT_REG_PEEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_HIEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_TXEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements5 */
+        0x1, /* gcFEATURE_BIT_REG_FEEnhancements2 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes16 */
+        0x0, /* gcFEATURE_BIT_REG_DEEnhancements5 */
+        0x1, /* gcFEATURE_BIT_REG_TXEnhancements4 */
+        0x0, /* gcFEATURE_BIT_REG_PEEnhancements4 */
+        0x1, /* gcFEATURE_BIT_REG_MCEnhancements1 */
+        0x1, /* gcFEATURE_BIT_REG_Halti2 */
+        0x0, /* gcFEATURE_BIT_REG_DEMirrorRotate */
+        0x1, /* gcFEATURE_BIT_REG_SmallMSAA */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes17 */
+        0x0, /* gcFEATURE_BIT_REG_Rasterizer2 */
+        0x0, /* gcFEATURE_BIT_REG_DualPipeOPF */
+        0x0, /* gcFEATURE_BIT_REG_MultiSrcV2 */
+        0x0, /* gcFEATURE_BIT_REG_CSCV2 */
+        0x1, /* gcFEATURE_BIT_REG_PAEnhancements3 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes18 */
+        0x0, /* gcFEATURE_BIT_REG_Compression2D */
+        0x1, /* gcFEATURE_BIT_REG_Probe */
+        0x1, /* gcFEATURE_BIT_REG_MediumPrecision */
+        0x0, /* gcFEATURE_BIT_REG_DESupertile */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes19 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements6 */
+        0x1, /* gcFEATURE_BIT_REG_SHEnhancements7 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes20 */
+        0x0, /* gcFEATURE_BIT_REG_DEAddress40 */
+        0x0, /* gcFEATURE_BIT_REG_MiniMMUFix */
+        0x1, /* gcFEATURE_BIT_REG_EEZ */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes21 */
+        0x0, /* gcFEATURE_BIT_REG_ExtraVgCaps */
+        0x0, /* gcFEATURE_BIT_REG_MultiSrcV15 */
+        0x1, /* gcFEATURE_BIT_REG_BugFixes22 */
+        0x1, /* gcFEATURE_BIT_REG_Halti3 */
+        0x0, /* gcFEATURE_BIT_REG_TessellationShaders */
+        0x0, /* gcFEATURE_BIT_REG_OPF9Tap */
+        0x0, /* gcFEATURE_BIT_REG_MultiSrcV2StrQuad */
+        0x0, /* gcFEATURE_BIT_REG_SeperateSRCAndDstCache */
+        0x1, /* gcFEATURE_BIT_REG_Halti4 */
+        0x1, /* gcFEATURE_BIT_REG_RAWriteDepth */
+        0x0, /* gcFEATURE_BIT_REG_AndroidOnly */
+        0x1, /* gcFEATURE_BIT_REG_HasChipProductReg */
+        0x0, /* gcFEATURE_BIT_REG_TXSupportDEC */
+        0x1, /* gcFEATURE_BIT_REG_S8MSAACompression */
+        0x1, /* gcFEATURE_BIT_REG_BugFixesIn544 */
+        0x0, /* gcFEATURE_BIT_REG_L2CacheRemove */
+        0x1, /* gcFEATURE_BIT_REG_FEAllowRndVtxCnt */
+        0x0, /* gcFEATURE_BIT_REG_CubeMapFL28 */
+        0x1, /* gcFEATURE_BIT_REG_TX6bitFrac */
+        0x1, /* gcFEATURE_BIT_REG_FEAllowStallPrefetchEng */
+        0x0, /* gcFEATURE_BIT_REG_ThirdPartyCompression */
+        0x1, /* gcFEATURE_BIT_REG_RSS8 */
+        0x1, /* gcFEATURE_BIT_REG_MSAACoherencyCheck */
+        0x1, /* gcFEATURE_BIT_REG_Halti5 */
+        0x1, /* gcFEATURE_BIT_REG_Evis */
+        0x0, /* gcFEATURE_BIT_REG_BltEngine */
+        0x0, /* gcFEATURE_BIT_REG_BugFixes23 */
+        0x0, /* gcFEATURE_BIT_REG_BugFixes24 */
+        0x0, /* gcFEATURE_BIT_REG_DEC */
+        0x0, /* gcFEATURE_BIT_REG_VSTileNV12 */
+        0x0, /* gcFEATURE_BIT_REG_VSTileNV12_10BIT */
+        0x0, /* gcFEATURE_BIT_REG_DisableVIP */
+        0x0, /* gcFEATURE_BIT_RenderTarget8 */
+        0x0, /* gcFEATURE_BIT_TxLodFlowCorrection */
+        0x0, /* gcFEATURE_BIT_FaceLod */
+        0x0, /* gcFEATURE_BIT_MultiCoreSemaphoreStallV2 */
+        0x0, /* gcFEATURE_BIT_VMSAA */
+        0x0, /* gcFEATURE_BIT_ChipEnableLink */
+        0x0, /* gcFEATURE_BIT_MULTI_SRC_BLT_1_5_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_MULTI_SRC_BLT_BILINEAR_FILTER */
+        0x1, /* gcFEATURE_BIT_RA_HZEZ_CLOCK_CONTROL */
+        0x1, /* gcFEATURE_BIT_CACHE128B256BPERLINE */
+        0x0, /* gcFEATURE_BIT_V4Compression */
+        0x0, /* gcFEATURE_BIT_DE2D_MAJOR_SUPER_TILE */
+        0x0, /* gcFEATURE_BIT_PE2D_MAJOR_SUPER_TILE */
+        0x1, /* gcFEATURE_BIT_PE_32BPC_COLORMASK_FIX */
+        0x1, /* gcFEATURE_BIT_ALPHA_BLENDING_OPT */
+        0x1, /* gcFEATURE_BIT_NEW_GPIPE */
+        0x0, /* gcFEATURE_BIT_PIPELINE_32_ATTRIBUTES */
+        0x0, /* gcFEATURE_BIT_MSAA_SHADING */
+        0x1, /* gcFEATURE_BIT_NO_ANISTRO_FILTER */
+        0x1, /* gcFEATURE_BIT_NO_ASTC */
+        0x0, /* gcFEATURE_BIT_NO_DXT */
+        0x0, /* gcFEATURE_BIT_HWTFB */
+        0x1, /* gcFEATURE_BIT_RA_DEPTH_WRITE_MSAA1X_FIX */
+        0x1, /* gcFEATURE_BIT_EZHZ_CLOCKGATE_FIX */
+        0x1, /* gcFEATURE_BIT_SH_SNAP2PAGE_FIX */
+        0x1, /* gcFEATURE_BIT_SH_HALFDEPENDENCY_FIX */
+        0x1, /* gcFEATURE_BIT_USC_MCFILL_FIX */
+        0x1, /* gcFEATURE_BIT_TPG_TCPERF_FIX */
+        0x1, /* gcFEATURE_BIT_USC_MDFIFO_OVERFLOW_FIX */
+        0x1, /* gcFEATURE_BIT_SH_TEXLD_BARRIER_IN_CS_FIX */
+        0x1, /* gcFEATURE_BIT_RS_NEW_BASEADDR */
+        0x1, /* gcFEATURE_BIT_PE_8bpp_DUALPIPE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_ADVANCED_INSTR */
+        0x1, /* gcFEATURE_BIT_SH_FLAT_INTERPOLATION_DUAL16_FIX */
+        0x1, /* gcFEATURE_BIT_USC_CONTINUOUS_FLUS_FIX */
+        0x0, /* gcFEATURE_BIT_SH_SUPPORT_V4 */
+        0x0, /* gcFEATURE_BIT_SH_SUPPORT_ALPHA_KILL */
+        0x1, /* gcFEATURE_BIT_PE_NO_ALPHA_TEST */
+        0x0, /* gcFEATURE_BIT_TX_LOD_NEAREST_SELECT */
+        0x1, /* gcFEATURE_BIT_SH_FIX_LDEXP */
+        0x1, /* gcFEATURE_BIT_SUPPORT_MOVAI */
+        0x1, /* gcFEATURE_BIT_SH_SNAP2PAGE_MAXPAGES_FIX */
+        0x1, /* gcFEATURE_BIT_PE_RGBA16I_FIX */
+        0x1, /* gcFEATURE_BIT_BLT_8bpp_256TILE_FC_FIX */
+        0x1, /* gcFEATURE_BIT_PE_64bit_FENCE_FIX */
+        0x1, /* gcFEATURE_BIT_USC_FULL_CACHE_FIX */
+        0x0, /* gcFEATURE_BIT_TX_YUV_ASSEMBLER_10BIT */
+        0x1, /* gcFEATURE_BIT_FE_32bit_INDEX_FIX */
+        0x1, /* gcFEATURE_BIT_BLT_64bpp_MASKED_CLEAR_FIX */
+        0x1, /* gcFEATURE_BIT_SECURITY */
+        0x1, /* gcFEATURE_BIT_ROBUSTNESS */
+        0x1, /* gcFEATURE_BIT_USC_ATOMIC_FIX */
+        0x1, /* gcFEATURE_BIT_SH_PSO_MSAA1x_FIX */
+        0x1, /* gcFEATURE_BIT_USC_VX_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_USC_GOS_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_TX_8bit_UVFrac */
+        0x1, /* gcFEATURE_BIT_TX_DESC_CACHE_CLOCKGATE_FIX */
+        0x1, /* gcFEATURE_BIT_RSBLT_MSAA_DECOMPRESSION */
+        0x0, /* gcFEATURE_BIT_TX_INTEGER_COORDINATE */
+        0x1, /* gcFEATURE_BIT_DRAWID */
+        0x1, /* gcFEATURE_BIT_PSIO_SAMPLEMASK_IN_R0ZW_FIX */
+        0x1, /* gcFEATURE_BIT_TX_INTEGER_COORDINATE_V2 */
+        0x0, /* gcFEATURE_BIT_MULTI_CORE_BLOCK_SET_CONFIG */
+        0x1, /* gcFEATURE_BIT_SNAPPAGE_CMD */
+        0x1, /* gcFEATURE_BIT_SH_NO_INDEX_CONST_ON_A0 */
+        0x1, /* gcFEATURE_BIT_SH_NO_ONECONST_LIMIT */
+        0x1, /* gcFEATURE_BIT_SH_IMG_LDST_ON_TEMP */
+        0x0, /* gcFEATURE_BIT_COMPUTE_ONLY */
+        0x1, /* gcFEATURE_BIT_SH_IMG_LDST_CLAMP */
+        0x1, /* gcFEATURE_BIT_SH_ICACHE_ALLOC_COUNT_FIX */
+        0x1, /* gcFEATURE_BIT_SH_ICACHE_PREFETCH */
+        0x0, /* gcFEATURE_BIT_PE2D_SEPARATE_CACHE */
+        0x1, /* gcFEATURE_BIT_PE_MSAA_OQ_FIX */
+        0x1, /* gcFEATURE_BIT_PSIO_MSAA_CL_FIX */
+        0x1, /* gcFEATURE_BIT_USC_DEFER_FILL_FIX */
+        0x1, /* gcFEATURE_BIT_SH_CLOCK_GATE_FIX */
+        0x0, /* gcFEATURE_BIT_FE_NEED_DUMMYDRAW */
+        0x0, /* gcFEATURE_BIT_PE2D_LINEAR_YUV420_OUTPUT */
+        0x0, /* gcFEATURE_BIT_PE2D_LINEAR_YUV420_10BIT */
+        0x0, /* gcFEATURE_BIT_MULTI_CLUSTER */
+        0x1, /* gcFEATURE_BIT_SH_MULTI_WG_PACK */
+        0x1, /* gcFEATURE_BIT_SH_DUAL16_SAMPLEMASK_ZW */
+        0x1, /* gcFEATURE_BIT_TPG_TRIVIAL_MODE_FIX */
+        0x0, /* gcFEATURE_BIT_TX_ASTC_MULTISLICE_FIX */
+        0x0, /* gcFEATURE_BIT_FE_ROBUST_FIX */
+        0x1, /* gcFEATURE_BIT_SH_GPIPE_ACCESS_FULLTEMPS */
+        0x0, /* gcFEATURE_BIT_PSIO_INTERLOCK */
+        0x1, /* gcFEATURE_BIT_PA_WIDELINE_FIX */
+        0x0, /* gcFEATURE_BIT_WIDELINE_HELPER_FIX */
+        0x1, /* gcFEATURE_BIT_TX_FLUSH_L1CACHE */
+        0x1, /* gcFEATURE_BIT_PE_DITHER_FIX2 */
+        0x1, /* gcFEATURE_BIT_SH_TEXLD_U_FIX */
+        0x1, /* gcFEATURE_BIT_MC_FCCACHE_BYTEMASK */
+        0x1, /* gcFEATURE_BIT_SH_MULTI_WG_PACK_FIX */
+        0x1, /* gcFEATURE_BIT_PE_ADVANCE_BLEND_PART0 */
+        0x1, /* gcFEATURE_BIT_FE_PATCHLIST_FETCH_FIX */
+        0x1, /* gcFEATURE_BIT_RA_CG_FIX */
+        0x0, /* gcFEATURE_BIT_DEC400 */
+        0x0, /* gcFEATURE_BIT_LS_SUPPORT_PERCOMP_DEPENDENCY */
+        0x0, /* gcFEATURE_BIT_MULTI_CORE_BLOCK_SET_CONFIG2 */
+        0x0, /* gcFEATURE_BIT_PE_VMSAA_COVERAGE_CACHE_FIX */
+        0x1, /* gcFEATURE_BIT_SECURITY_AHB */
+        0x0, /* gcFEATURE_BIT_MULTICORE_SEMAPHORESTALL_V3 */
+        0x0, /* gcFEATURE_BIT_SMALLBATCH */
+        0x0, /* gcFEATURE_BIT_SH_CMPLX */
+        0x0, /* gcFEATURE_BIT_SH_IDIV0_SWZL_EHS */
+        0x0, /* gcFEATURE_BIT_TX_LERP_LESS_BIT */
+        0x0, /* gcFEATURE_BIT_SH_GM_ENDIAN */
+        0x0, /* gcFEATURE_BIT_SH_GM_USC_UNALLOC */
+        0x0, /* gcFEATURE_BIT_SH_END_OF_BB */
+        0x1, /* gcFEATURE_BIT_TX_BORDER_CLAMP_FIX */
+        0x0, /* gcFEATURE_BIT_SH_IMG_LD_LASTPIXEL_FIX */
+        0x0, /* gcFEATURE_BIT_ASYNC_BLT */
+        0x1, /* gcFEATURE_BIT_ASYNC_FE_FENCE_FIX */
+        0x0, /* gcFEATURE_BIT_PSCS_THROTTLE */
+        0x0, /* gcFEATURE_BIT_SEPARATE_LS */
+        0x1, /* gcFEATURE_BIT_WIDELINE_TRIANGLE_EMU */
+        0x0, /* gcFEATURE_BIT_FENCE_32BIT */
+        0x1, /* gcFEATURE_BIT_FENCE_64BIT */
+        0x1, /* gcFEATURE_BIT_PE_DEPTH_ONLY_OQFIX */
+        0x1, /* gcFEATURE_BIT_TX_SEAMLESS_CUBE */
+        0x1, /* gcFEATURE_BIT_TX_SNORM_SUPPORT */
+        0x0, /* gcFEATURE_BIT_SH_SCATTER_GATHER */
+        0x0, /* gcFEATURE_BIT_HWMANAGED_LS */
+        0x0, /* gcFEATURE_BIT_SH_IMAGE_ENABLE_FIX */
+        0x1, /* gcFEATURE_BIT_MSAA_FRAGMENT_OPERATION */
+        0x1, /* gcFEATURE_BIT_PE_TILE_CACHE_FLUSH_FIX */
+        0x1, /* gcFEATURE_BIT_BLT_YUV_OUTPUT */
+        0x1, /* gcFEATURE_BIT_SH_IO_CG_FIX */
+        0x0, /* gcFEATURE_BIT_PE_SWIZZLE */
+        0x1, /* gcFEATURE_BIT_SH_ROBUSTNESS_FIX */
+        0x1, /* gcFEATURE_BIT_USC_ATOMIC_FIX2 */
+        0x1, /* gcFEATURE_BIT_PE_A8B8G8R8 */
+        0x1, /* gcFEATURE_BIT_MULTIVIEW_RENDER */
+        0x1, /* gcFEATURE_BIT_FE_DRAW_DIRECT */
+        0x1, /* gcFEATURE_BIT_TX_VKBORDER_MODE */
+        0x1, /* gcFEATURE_BIT_TX_UNNORMALIZED_COORD */
+        0x0, /* gcFEATURE_BIT_PA_LINECLIP_FIX */
+        0x1, /* gcFEATURE_BIT_TX_8bit_UVFrac_ROUNDING_FIX */
+        0x0, /* gcFEATURE_BIT_MP_ARCH */
+        0x0, /* gcFEATURE_BIT_TX_NO_FIXED_FILTER */
+        0x0, /* gcFEATURE_BIT_SHARE_Z */
+        0x0, /* gcFEATURE_BIT_DE_2D_FAST_CLEAR */
+        0x0, /* gcFEATURE_BIT_DE_TILESTATUS_ROTATION_FIX */
+        0x0, /* gcFEATURE_BIT_TX_CLEAR_PENDING_FIX */
+        0x0, /* gcFEATURE_BIT_HI1_L2_CACHE */
+        0x0, /* gcFEATURE_BIT_USC_EVICT_CTRL_FIFO_FLOP_RESET_FIX */
+        0x0, /* gcFEATURE_BIT_FORMAT_10BIT_CROSS_4K */
+        0x0, /* gcFEATURE_BIT_FORMAT_P010LSB_I010 */
+        0x0, /* gcFEATURE_BIT_ENDIAN_CONTROL */
+        0x0, /* gcFEATURE_BIT_AXIFE */
+        0x1, /* gcFEATURE_BIT_SH_VX2_FLOATING_MAD_FIX */
+        0x0, /* gcFEATURE_BIT_TS_FC_VULKAN_SUPPORT */
+        0x1, /* gcFEATURE_BIT_MSAA_FLOAT_64BIT */
+        0x0, /* gcFEATURE_BIT_INDIRECT_COMPUTE_ZERODIM_FIX */
+        0x0, /* gcFEATURE_BIT_Q_CHANNEL_SUPPORT */
+        0x0, /* gcFEATURE_BIT_MMU_PAGE_DESCRIPTOR */
+        0x0, /* gcFEATURE_BIT_YUV_LINEAR_TO_TILE_ROTATE */
+        0x0, /* gcFEATURE_BIT_VEC2_IMULIMAD32_SUPPORT */
+        0x0, /* gcFEATURE_BIT_VEC4_IMULIMAD32_SUPPORT */
+        0x0, /* gcFEATURE_BIT_VEC2_IDIVIMOD16_SUPPORT */
+        0x0, /* gcFEATURE_BIT_DST_TEX_I2F_F2I_INST_DEPRECATE */
+        0x0, /* gcFEATURE_BIT_ALU_FP16_INSTRUCTIONS */
+        0x0, /* gcFEATURE_BIT_DUAL16_14BIT_PC_SUPPORT */
+        0x0, /* gcFEATURE_BIT_LDST_CONV_4ROUNDING_MODES */
+        0x0, /* gcFEATURE_BIT_FULL_PACK_MODE_SUPPORT */
+        0x0, /* gcFEATURE_BIT_DEPTH_FLOAT32_SUPPORT */
+        0x0, /* gcFEATURE_BIT_GPU_INSPECTOR_COUNTERS */
+        0x0, /* gcFEATURE_BIT_FP32_TO_FP16_CONV_FIX */
+        0x0, /* gcFEATURE_BIT_IMGLD_COMP_COUNT_FIX */
+        0x1, /* gcFEATURE_BIT_IMGLD_WIDTH_LT16_FIX */
+        0x0, /* gcFEATURE_BIT_TX_FILTER_ROUND_FIX */
+        0x0, /* gcFEATURE_BIT_SH_FP32_FMA_SUPPORT */
+        0x0, /* gcFEATURE_BIT_PE_64BPP_LINEAR_FORMAT */
+        0x0, /* gcFEATURE_BIT_TX_ETC2_COMPRESSION */
+        0x0, /* gcFEATURE_BIT_HIGHP_VEC2 */
+        0x0, /* gcFEATURE_BIT_MMU_PD_42_BIT_ADDRESS */
+        0x0, /* gcFEATURE_BIT_BLT_ROBUSTNESS_FIX */
+        0x0, /* gcFEATURE_BIT_BLT_OUT_OF_BOUND_FIX */
+        0x0, /* gcFEATURE_BIT_TFB_PERF_FIX */
+        0x0, /* gcFEATURE_BIT_SH_SUPERSCALAR_ARCH */
+        0x0, /* gcFEATURE_BIT_PA_ZEROAREA_LINE_FIX */
+        0x1, /* gcFEATURE_BIT_RS_TILER_YUV420_FIX */
+        0x0, /* gcFEATURE_BIT_ATTR_IN_GLOBAL_MEMORY */
+        0x0, /* gcFEATURE_BIT_SIMPLIFIED_CHECKERBOARD */
+        0x0, /* gcFEATURE_BIT_ADDR_REMAP */
+        0x0, /* gcFEATURE_BIT_ADDR_40BIT_OVERFLOW_FIX */
+        0x0, /* gcFEATURE_BIT_CLIP_DISTANCE_SUPPORT */
+        0x0, /* gcFEATURE_BIT_SEPARATED_TEXTURE_SAMPLER */
+        0x0, /* gcFEATURE_BIT_TS_INFO_IN_TX_DESCRIPTOR */
+        0x0, /* gcFEATURE_BIT_PER_STAGE_LOCAL_STORAGE */
+        0x0, /* gcFEATURE_BIT_DX11_FORMAT_SUPPORT */
+        0x0, /* gcFEATURE_BIT_OCCLUSION_SAMPLE_COUNTER */
+        0x0, /* gcFEATURE_BIT_FRONT_FACE_UINT */
+        0x0, /* gcFEATURE_BIT_DYNAMIC_TEXTURE_INDEXING */
+        0x0, /* gcFEATURE_BIT_D3D11_SUPPORT */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_FIX */
+        0x0, /* gcFEATURE_BIT_MMU_40BIT_VA_GRAPHICS */
+        0x0, /* gcFEATURE_BIT_ONE_OUTPUT_COMPOENT_FOR_MFU */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_VA_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_DX11_SH_RCP_SQRT_PRECISSION */
+        0x0, /* gcFEATURE_BIT_TILED_RESOURCE */
+        0x0, /* gcFEATURE_BIT_SH_FP64 */
+        0x0, /* gcFEATURE_BIT_SH_SM6 */
+        0x0, /* gcFEATURE_BIT_VGPU */
+        0x0, /* gcFEATURE_BIT_DEC_NANO */
+        0x0, /* gcFEATURE_BIT_SH_64BIT_ROBUST_CHECK */
+        0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR */
+        0x0, /* gcFEATURE_BIT_G2D_RGB_PLANAR_SOURCE */
+        0x0, /* gcFEATURE_BIT_G2D_DEC400EX */
+        0x0, /* gcFEATURE_BIT_G2D_FC_IN_DEC400EX */
+        0x0, /* gcFEATURE_BIT_G2D_NO_YUV420_SOURCE */
+        0x0, /* gcFEATURE_BIT_G2D_YUV420_101010 */
+        0x0, /* gcFEATURE_BIT_G2D_MultiSrcBlt_Pipe */
+        0x0, /* gcFEATURE_BIT_G2D_Stretch_MultiSrc_Pipe */
+        0x0, /* gcFEATURE_BIT_G2D_Normalization */
+        0x0, /* gcFEATURE_BIT_G2D_Normalization_Quantization */
+        0x0, /* gcFEATURE_BIT_G2D_FRAME_DONE_INTR */
+        0x0, /* gcFEATURE_BIT_G2D_MASK_AND_COLORKEY */
+        0x0, /* gcFEATURE_BIT_G2D_DEC400 */
+        0x0, /* gcFEATURE_BIT_G2D_3rd_PARTY_COMPRESSION_1_1 */
+        0x0, /* gcFEATURE_BIT_G2D_Histogram */
+        0x0, /* gcFEATURE_BIT_G2D_Brightness_Saturation */
+        0x0, /* gcFEATURE_BIT_VG_MMU */
+        0x0, /* gcFEATURE_BIT_VG_IM_FILTER */
+        0x0, /* gcFEATURE_BIT_VG_IM_YUV_PACKET */
+        0x0, /* gcFEATURE_BIT_VG_IM_YUV_PLANAR */
+        0x0, /* gcFEATURE_BIT_VG_PE_YUV_PACKET */
+        0x0, /* gcFEATURE_BIT_VG_RESOLVE_ENGINE */
+        0x0, /* gcFEATURE_BIT_VG_PE_COLOR_KEY */
+        0x0, /* gcFEATURE_BIT_VG_IM_INDEX_FORMAT */
+        0x0, /* gcFEATURE_BIT_VG_RESOLUTION_8K */
+        0x0, /* gcFEATURE_BIT_VG_IMAGE_16K */
+        0x1, /* gcFEATURE_BIT_VIP_HW_FINAL_RELEASE */
+        0x1, /* gcFEATURE_BIT_NN_SINGLEPORT_ACCUMBUFFER */
+        0x1, /* gcFEATURE_BIT_NN_STRIDE_SUPPORT */
+        0x1, /* gcFEATURE_BIT_SWTILING_PHASE1 */
+        0x0, /* gcFEATURE_BIT_SWTILING_PHASE2 */
+        0x0, /* gcFEATURE_BIT_TP_SIMPLE_INT16 */
+        0x1, /* gcFEATURE_BIT_TP_REAL_INT16 */
+        0x1, /* gcFEATURE_BIT_TP_ROI_POOLING */
+        0x1, /* gcFEATURE_BIT_TP_MAX_POOLING_STRIDE1 */
+        0x1, /* gcFEATURE_BIT_TP_LRN */
+        0x1, /* gcFEATURE_BIT_TP_REORDER */
+        0x1, /* gcFEATURE_BIT_TF_QUANTIZATION */
+        0x1, /* gcFEATURE_BIT_NN_NONZERO_BORDER */
+        0x0, /* gcFEATURE_BIT_NN_MIRROR_BORDER */
+        0x1, /* gcFEATURE_BIT_AI_GPU */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_ABSDIFF */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_BITREPLACE */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_BOXFILTER */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_CORDIAC */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_DP32 */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_FILTER */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_IADD */
+        0x0, /* gcFEATURE_BIT_EVIS_NO_SELECTADD */
+        0x0, /* gcFEATURE_BIT_EVIS_LERP_7OUTPUT */
+        0x0, /* gcFEATURE_BIT_EVIS_ACCSQ_8OUTPUT */
+        0x1, /* gcFEATURE_BIT_EVIS_VX2 */
+        0x1, /* gcFEATURE_BIT_TP_ENGINE */
+        0x1, /* gcFEATURE_BIT_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_TP_TENSOR_ADD_MUL */
+        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_INT16XINT8 */
+        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_8BIT_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_TP_SOFTMAX */
+        0x0, /* gcFEATURE_BIT_NN_23BITS_POST_MULTIPLIER_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_TP_23BITS_POST_MULTIPLIER_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_CONV_INT16X8BIT_VIP_V7 */
+        0x0, /* gcFEATURE_BIT_NN_REMOVE_POOLING */
+        0x0, /* gcFEATURE_BIT_NN_40BIT_BIAS */
+        0x0, /* gcFEATURE_BIT_TP_REMOVE_USC */
+        0x1, /* gcFEATURE_BIT_NN_ZDP3 */
+        0x0, /* gcFEATURE_BIT_NN_ZDP6 */
+        0x0, /* gcFEATURE_BIT_NN_ZDP9 */
+        0x0, /* gcFEATURE_BIT_NN_XYDP9 */
+        0x1, /* gcFEATURE_BIT_NN_FIRST_PIXEL_POOLING */
+        0x1, /* gcFEATURE_BIT_NN_XYDP6 */
+        0x1, /* gcFEATURE_BIT_SWTILING_PHASE3 */
+        0x0, /* gcFEATURE_BIT_MCFE */
+        0x0, /* gcFEATURE_BIT_USC_STAY_LRU */
+        0x1, /* gcFEATURE_BIT_COEF_COMPRESSION_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_TP_COEF_COMPRESSION_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_COEF_DECOMPRESS_PERF2X */
+        0x0, /* gcFEATURE_BIT_TP_SMALLBATCH_PHASE1 */
+        0x1, /* gcFEATURE_BIT_OCB_COUNTER */
+        0x0, /* gcFEATURE_BIT_SCALER */
+        0x0, /* gcFEATURE_BIT_SCALER_4K */
+        0x0, /* gcFEATURE_BIT_INPUT_4BIT */
+        0x0, /* gcFEATURE_BIT_NN_NO_Z_LOCATION_OFFSET */
+        0x0, /* gcFEATURE_BIT_OCB_REMAP_PHYSICAL_ADDRESS */
+        0x0, /* gcFEATURE_BIT_NN_SLOW_OUTPUT */
+        0x1, /* gcFEATURE_BIT_NO_NARROW_POST_PROCESS_PIPE */
+        0x0, /* gcFEATURE_BIT_TP_NN_PROBE */
+        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_SUPPORT */
+        0x0, /* gcFEATURE_BIT_NN_XYDP0 */
+        0x0, /* gcFEATURE_BIT_NN_WRITE_WITHOUT_USC */
+        0x0, /* gcFEATURE_BIT_NN_HW_LIMITATION_NATIVE_KER_1x2_2x1 */
+        0x0, /* gcFEATURE_BIT_NN_SMALLBATCH_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SLICE_PADDING_TO_64BYTE_ALIGN */
+        0x0, /* gcFEATURE_BIT_NN_DW_1x1_CONV_MERGE */
+        0x0, /* gcFEATURE_BIT_TP_BFLOAT16 */
+        0x0, /* gcFEATURE_BIT_TP_23BITS_POST_MULTIPLIER */
+        0x0, /* gcFEATURE_BIT_NN_TRANSPOSE */
+        0x0, /* gcFEATURE_BIT_NN_ZDP_TRANSPOSE_CH9_ONLY */
+        0x0, /* gcFEATURE_BIT_USE_SINGLE_PORT_VIPSRAM */
+        0x0, /* gcFEATURE_BIT_NN_LEAKY_RELU */
+        0x0, /* gcFEATURE_BIT_NN_PRELU */
+        0x0, /* gcFEATURE_BIT_NN_PER_CHANNEL_QUANT */
+        0x0, /* gcFEATURE_BIT_NN_PER_CHANNEL_QUANT_ASYM */
+        0x0, /* gcFEATURE_BIT_NN_ASYMMETRIC_INT8 */
+        0x0, /* gcFEATURE_BIT_NN_FLOAT_POST_MULT */
+        0x0, /* gcFEATURE_BIT_PRELU_LEAKLY_RELU_CLAMP */
+        0x0, /* gcFEATURE_BIT_TPLITE_BFLOAT16 */
+        0x0, /* gcFEATURE_BIT_PREPROCESS_IMG_BUF_640BYTE_LIMIT */
+        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_FP16 */
+        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_BF16 */
+        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_FP32 */
+        0x0, /* gcFEATURE_BIT_TP_KERNEL_1BYTE_ALGIN */
+        0x0, /* gcFEATURE_BIT_BFLOAT_COEF_COMPRESSION_ZERO_COEFBIT14_INVERSE */
+        0x0, /* gcFEATURE_BIT_NN_COMPRESSION_BYPASSS */
+        0x0, /* gcFEATURE_BIT_TP_3_USC */
+        0x0, /* gcFEATURE_BIT_BFP_COEF_AUTO_PAD_INCOMPLETE_ZERO_IN_KZ_PLANE */
+        0x0, /* gcFEATURE_BIT_HW_V83 */
+        0x0, /* gcFEATURE_BIT_NN_NATIVE_STRIDE_TWO */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD */
+        0x0, /* gcFEATURE_BIT_NN_FLOAT32_IO */
+        0x0, /* gcFEATURE_BIT_TP_FLOAT32_IO */
+        0x0, /* gcFEATURE_BIT_NN_SMALL_BATCH_PHASE2 */
+        0x0, /* gcFEATURE_BIT_TILE_ACCESS_CAPABILITY */
+        0x0, /* gcFEATURE_BIT_FAST_DP3_PREPROCESSOR */
+        0x0, /* gcFEATURE_BIT_DEPTHWISE_SUPPORT_16BIT_FORMAT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ALU */
+        0x0, /* gcFEATURE_BIT_NN_ENHANCED_MAX_POOLING */
+        0x0, /* gcFEATURE_BIT_NN_TRANSPOSE_PHASE2 */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_FIELD_MOVE_TO_EXT_CMD */
+        0x0, /* gcFEATURE_BIT_NN_CMD_SUPPORT_SLICE */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_RELU */
+        0x0, /* gcFEATURE_BIT_TPLITE_SUPPORT_TP_DATA_TRANSPOSE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONV_1D */
+        0x0, /* gcFEATURE_BIT_USE_VIPSRAM_FOR_KERNEL_STREAMING */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_DUMMY_TILE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_KERNEL_1BYTE_ALIGN */
+        0x0, /* gcFEATURE_BIT_NN_1x1_NON_POOLING_PACKING */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_BOTH_CONV_NATIVE_STRIDE2_AND_POOLING */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONV1x1_AND_NATIVE_CONV_STRIDE2 */
+        0x0, /* gcFEATURE_BIT_TP_REMOVE_FC */
+        0x0, /* gcFEATURE_BIT_VIP_REMOVE_MMU */
+        0x0, /* gcFEATURE_BIT_NN_RD_IMG_NEED_EXTRA_SPACE */
+        0x0, /* gcFEATURE_BIT_VIP_INDIV_CLK_NN */
+        0x0, /* gcFEATURE_BIT_VIP_EXPORT_CLK_DIV2 */
+        0x0, /* gcFEATURE_BIT_NN_2D_AVERAGE_OUTPUT */
+        0x0, /* gcFEATURE_BIT_NN_JOB_CANCELATION */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_INLINE_NWHC_AND_MATRIX_TRANSPOSE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_BATCH */
+        0x0, /* gcFEATURE_BIT_VIP_SUPPORT_DEC */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_MULTI_AXI_ID */
+        0x0, /* gcFEATURE_BIT_NN_POST_OUT_SUPPORT_INT32 */
+        0x0, /* gcFEATURE_BIT_NN_DISTRIBUTED_VIPSRAM */
+        0x0, /* gcFEATURE_BIT_NN_FC_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_PHASE1 */
+        0x0, /* gcFEATURE_BIT_VIP_DEC400 */
+        0x0, /* gcFEATURE_BIT_NN_POST_MULT_SUPPORT_FP_CONV */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_16_8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_SPECIAL_8BIT_SIGN_ABS_CONV */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CONFIGURABLE_FASTXDP3 */
+        0x0, /* gcFEATURE_BIT_NN_USE_CORE_SHARING_IMGBUF_AND_SEQ_NO_ZEROSKIPPING */
+        0x0, /* gcFEATURE_BIT_SUPPORT_DECONVNxN_S_LESS_THAN_16 */
+        0x0, /* gcFEATURE_BIT_NN_PICOCORE_DEPTHWISE */
+        0x0, /* gcFEATURE_BIT_VIP_SUPPORT_TENSOR_TRANSFER */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CMD_LOOP */
+        0x0, /* gcFEATURE_BIT_VIP_SUPPORT_X_FRAME_COMPRESSION */
+        0x0, /* gcFEATURE_BIT_NN_SMALL_ACCUM */
+        0x0, /* gcFEATURE_BIT_NN_SINGLE_POSTMULT_FIELDS_IN_BITSTREAM */
+        0x0, /* gcFEATURE_BIT_POST_MULTIPLIER_LOW_POWER_MODE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_EFUSE */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_STREAMPROCESSOR */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_CONV_CORE_BYPASS */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_CLAMP_BORDER_MODE */
+        0x0, /* gcFEATURE_BIT_NN_ELEMENTWISE_BROADCAST_STRIDE_X_0 */
+        0x0, /* gcFEATURE_BIT_NN_2ND_IMAGE_DATA_TYPE */
+        0x0, /* gcFEATURE_BIT_FP_INIMAGE_POST_SCALE */
+        0x0, /* gcFEATURE_BIT_NN_INT16_TENSOR_ADD */
+        0x0, /* gcFEATURE_BIT_NN_TENSOR_ADD_DOUBLE_PIPELINE */
+        0x0, /* gcFEATURE_BIT_TENSOR_DMA */
+        0x0, /* gcFEATURE_BIT_NN_SPLIT_X_AMONG_CLUSTER */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_ZDP_LOOP6 */
+        0x0, /* gcFEATURE_BIT_NN_FP8_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_FUSA */
+        0x0, /* gcFEATURE_BIT_NN_OUTPUT_OVERFLOW_MODE */
+        0x0, /* gcFEATURE_BIT_NN_DEPTHWISE_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_CONV_1X1_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_SUPPORT_DYNAMIC_SHAPE */
+        0x0, /* gcFEATURE_BIT_SUPPORT_BATCH_ALIGNMENT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_GEMM_PHASE2 */
+        0x0, /* gcFEATURE_BIT_SRAM_PARITY */
+        0x0, /* gcFEATURE_BIT_NNCMD_AXIID_OFFSET */
+        0x0, /* gcFEATURE_BIT_TC_SHADER_TRIGGER_NN */
+        0x0, /* gcFEATURE_BIT_TC_PROBE_COUNTER */
+        0x0, /* gcFEATURE_BIT_NN_TILE_BRICK_MODE */
+        0x0, /* gcFEATURE_BIT_NN_4BIT_COEF_PACKED_MODE */
+        0x0, /* gcFEATURE_BIT_NN_BF16_I4_I8_QUANTIZATION */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODE_SPLIT_STAGE */
+        0x0, /* gcFEATURE_BIT_NN_POST_PROCESSOR_FL32 */
+        0x0, /* gcFEATURE_BIT_NN_HIGH_PERF_DECODER */
+        0x0, /* gcFEATURE_BIT_NN_GROUP_QUANT_PHASE1 */
+        0x0, /* gcFEATURE_BIT_NN_SH_IN_PARALLEL */
+        0x0, /* gcFEATURE_BIT_NN_ASYNC_DMA */
+        0x0, /* gcFEATURE_BIT_NN_STRIDE2_FAST_XDP3 */
+        0x0, /* gcFEATURE_BIT_NN_2V4_STRUCTURED_SPARSITY */
+        0x0, /* gcFEATURE_BIT_NN_SP_ENHANCEMENT */
+        0x0, /* gcFEATURE_BIT_NN_SUPPORT_SEPARATE_STREAMBUF_ADDR */
+        0x0, /* gcFEATURE_BIT_NN_TF32_MAC */
+        0x0, /* gcFEATURE_BIT_NN_PER3DTILE_BUBBLE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_CACHELINE_MODE_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_NN_CONV1x1_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_TP_REORDER_FIX */
+        0x1, /* gcFEATURE_BIT_NN_CONVOUT_FIFO_DEPTH_FIX */
+        0x0, /* gcFEATURE_BIT_NN_ZXDP3_KERNEL_READ_CONFLICT_FIX */
+        0x1, /* gcFEATURE_BIT_NN_ZDP3_NO_COMPRESS_FIX */
+        0x1, /* gcFEATURE_BIT_NN_ASYNC_COPY_PERF_FIX */
+        0x1, /* gcFEATURE_BIT_HI_REORDER_FIX */
+        0x1, /* gcFEATURE_BIT_INCORRECT_WR_REQ_TO_USC_BETWEEN_REORDER_AND_NORMAL_LAYER_FIX */
+        0x0, /* gcFEATURE_BIT_TP_REORDER_LAYER_SUSPEND_FIX */
+        0x1, /* gcFEATURE_BIT_NN_ASYNC_COPY_MERGE_FIX */
+        0x0, /* gcFEATURE_BIT_USC_INVALIDATE_CACHE_LINE_FIX */
+        0x0, /* gcFEATURE_BIT_NN_REQ_SLOWARBITRATION_FIX */
+        0x0, /* gcFEATURE_BIT_IMAGE_PARTIAL_CACHE_FIX */
+        0x0, /* gcFEATURE_BIT_FULLCACHE_KERNELHEAD_FIX */
+        0x0, /* gcFEATURE_BIT_NN_ZDP_INIMAGE_SIZE_FIX */
+        0x0, /* gcFEATURE_BIT_IDLE_BEFORE_FLUSH_COMPLETE_FIX */
+        0x0, /* gcFEATURE_BIT_NO_FLUSH_USC_FIX */
+        0x0, /* gcFEATURE_BIT_SMALL_BATCH_FLOPS_RESET_FIX */
+        0x1, /* gcFEATURE_BIT_SMALL_BATCH_DISBLE_FIX */
+        0x1, /* gcFEATURE_BIT_OUTPUT_CONVERT_UINT8_INT8_TO_UINT16_INT16_FIX */
+        0x0, /* gcFEATURE_BIT_IMAGE_NOT_PACKED_IN_SRAM_FIX */
+        0x0, /* gcFEATURE_BIT_COEF_DELTA_CORD_OVERFLOW_ZRL_8BIT_FIX */
+        0x0, /* gcFEATURE_BIT_USC_INDIVIDUAL_PORT_WRT_EARLY_EVICT_DATA_CORRUPT_FIX */
+        0x0, /* gcFEATURE_BIT_LOW_EFFICIENCY_OF_ID_WRITE_IMGBUF_FIX */
+        0x0, /* gcFEATURE_BIT_KERNEL_VIP_SRAM_READ_BW_LIMITATION_FIX */
+        0x0, /* gcFEATURE_BIT_USC_BOTTLENECK_FIX */
+        0x1, /* gcFEATURE_BIT_KERNEL_PER_CORE_LESS_THAN_THIRD_COEF_BUFF_DEPTH_FIX */
         0x1, /* gcFEATURE_BIT_NN_TILE_NUM_BIGGER_THAN_1024_FIX */
         0x0, /* gcFEATURE_BIT_KERNEL_SIZE_WASTE_IN_PARTIAL_MODE_FIX */
         0x0, /* gcFEATURE_BIT_NN_COMMAND_KERNEL_REQUEST_CONFICT_FIX */
@@ -4174,10 +6326,10 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x0, /* gcFEATURE_BIT_TP_NOT_FULL_USE_CACHE_LINE_FIX */
         0x0, /* gcFEATURE_BIT_SH_MOVAI_MOVAR_UNUSED_COMPONENTS_WRITE_DIRTY_DATA_FIX */
         0x0, /* gcFEATURE_BIT_BURST_COLLECT_CONSUMES_MC_DATA_WIDTH_PER_CYCLE_FIX */
+        0x0, /* gcFEATURE_BIT_SH_CONFORMANCE_BRUTEFORCE_FIX */
         0x1, /* gcFEATURE_BIT_TP_ASSYM_INT8_FIX */
         0x1, /* gcFEATURE_BIT_NN_PAD_SLICE_ERROR_WHEN_TRANSPSE_FIX */
         0x1, /* gcFEATURE_BIT_NN_2ND_IMG_BASE_ADDR_FIX */
-        0x0, /* gcFEATURE_BIT_NN_TP_SYSTEM_FIX */
         0x1, /* gcFEATURE_BIT_NN_INTILE_YSIZE_128_LIMIT_FIX */
         0x1, /* gcFEATURE_BIT_SH_CLOCK_GATOR_IDLE_CONDITON_FIX */
         0x1, /* gcFEATURE_BIT_NN_BURST_COLLECTER_LAST_FLAG_FIX */
@@ -4212,20 +6364,46 @@ static gcsFEATURE_DATABASE gChipInfo[] = {
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE1_FIX */
         0x1, /* gcFEATURE_BIT_NN_1ST_AND_2ND_INIMAGE_RAISE_VIPSRAM_RD_UPDATE_AT_SAME_TIME_PHASE2_FIX */
+        0x1, /* gcFEATURE_BIT_WRSPLIT_NOT_SUPPORT_PROBE_FIX */
         0x1, /* gcFEATURE_BIT_TRSP2_NOT_SUPPORT_VIPSRAM_IN_XSTRIDE_IT_FETCH_XSIZE_FIX */
         0x1, /* gcFEATURE_BIT_TP_SPECIAL_LIST_PARSER_FIX */
         0x1, /* gcFEATURE_BIT_DECOMPRESSOR_TREATS_TOTAL_CORES_AS_ACTIVE_CORES_FIX */
         0x0, /* gcFEATURE_BIT_DIRECT_INIMAGE_XSTIDE_LE_13BIT_FIX */
+        0x0, /* gcFEATURE_BIT_TILEXSIZE_LESS_THAN_1_4_AXIBUS_FIX */
         0x1, /* gcFEATURE_BIT_SECONDIMG_TILE_SIDEBANFIFO_FIX */
         0x1, /* gcFEATURE_BIT_TRSPB2_ENDADDR_EQUAL_SRAMEND_FIX */
+        0x0, /* gcFEATURE_BIT_WRITE_STRIDE2_DUMMY_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_WORDSIZE_BIGGER_FIX */
+        0x1, /* gcFEATURE_BIT_BURSTCOLLECTOR_ADDR_UPDATE_FIX */
+        0x0, /* gcFEATURE_BIT_TRSB2_SMALL_BATCH_UPDATE_FIX */
         0x1, /* gcFEATURE_BIT_NN_NT_SMALLBATCH_TRNSFER_INIT_FIX */
         0x1, /* gcFEATURE_BIT_IMGRD_FIRST_ROW_SMALL_SLICE_FIX */
         0x1, /* gcFEATURE_BIT_KERNEL_WR_RD_LUTLOAD_DIRECTMODE_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_KERNEL_FULLCACHE_PERF_FIX */
         0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_IMG_KERNEL_SAME_FIX */
         0x1, /* gcFEATURE_BIT_TRSP2_CONV_SMALLBATCH_FIX */
         0x1, /* gcFEATURE_BIT_DEPTHTOSPACE_SAME_XY_FIX */
         0x1, /* gcFEATURE_BIT_VZ_GROUP_START_Z_OVERFLOW_FIX */
         0x1, /* gcFEATURE_BIT_V82_STREAMMODE_VIPSRAM_ADDRESS_FIX */
+        0x1, /* gcFEATURE_BIT_GEMM_NO_SUPPORT_SMALLBATCH_FIX */
+        0x1, /* gcFEATURE_BIT_SBP1_KHEAD_CMDSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_BURSTCOLLECTOR_MAXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_PERF_KERNEL_DESCRIPTOR_SOURCE_FIX */
+        0x1, /* gcFEATURE_BIT_SP_NOIN_IMGRD_DUMMY_FIX */
+        0x1, /* gcFEATURE_BIT_NN_4BIT_PERF_EVEN_TILEXSIZE_FIX */
+        0x0, /* gcFEATURE_BIT_STREAMMODE_ONE_NNCMD_ONE_2DTILE_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_ID_DIRECTMODE_CHANGE_FIX */
+        0x1, /* gcFEATURE_BIT_PERF_4BITS_DONT_SUPPORT_TRSP1_2_FIX */
+        0x1, /* gcFEATURE_BIT_FIRST_SECOND_IMG_SAME_ID_FIX */
+        0x1, /* gcFEATURE_BIT_TILESIZE_LIMITATION_CORE_BYPASS_FIX */
+        0x1, /* gcFEATURE_BIT_SH_BARRIER_EXECUTION_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_11PK_NO_POOLING_NEWIMGRD_ADDR_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_PRE_CORE_LOTS_ZEROSKIP_KERNEL_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_MATRIX_A_TRSP1_CHNUM_FIX */
+        0x1, /* gcFEATURE_BIT_FIX_4BIT_SBP2_BLOCKCTRL2_FIX */
+        0x1, /* gcFEATURE_BIT_B2B_RETRUN_NN_CMD_DONE_FIX */
+        0x1, /* gcFEATURE_BIT_MULTI_AXI_ID_VLW_3D_TILE_INFO_FIX */
+        0x1, /* gcFEATURE_BIT_TRSP2_SPECIAL_WORDSIZE_FIX */
         0x0, /* gcFEATURE_BIT_NN_INTERLEVE8 */
         0x0, /* gcFEATURE_BIT_NN_FP16_ALU */
         0x1, /* gcFEATURE_BIT_NN_INT16_ALU */
diff --git a/src/etnaviv/isa/etnaviv.xml b/src/etnaviv/isa/etnaviv.xml
index a337c1e9d07..42f551238bf 100644
--- a/src/etnaviv/isa/etnaviv.xml
+++ b/src/etnaviv/isa/etnaviv.xml
@@ -1359,6 +1359,11 @@ SPDX-License-Identifier: MIT
 	<pattern pos="80">1</pattern> <!-- OPCODE_BIT6 -->
 </bitset>
 
+<bitset name="txf" extends="#instruction-tex-src0-src1-src2">
+	<pattern low="0" high="5">001001</pattern> <!-- OPC -->
+	<pattern pos="80">1</pattern> <!-- OPCODE_BIT6 -->
+</bitset>
+
 <bitset name="imadlo0" extends="#instruction-alu-src0-src1-src2">
 	<pattern low="0" high="5">001100</pattern> <!-- OPC -->
 	<pattern pos="80">1</pattern> <!-- OPCODE_BIT6 -->
diff --git a/src/etnaviv/isa/tests/disasm.cpp b/src/etnaviv/isa/tests/disasm.cpp
index aa027618aa4..3d4ebec8a49 100644
--- a/src/etnaviv/isa/tests/disasm.cpp
+++ b/src/etnaviv/isa/tests/disasm.cpp
@@ -166,6 +166,7 @@ INSTANTIATE_TEST_SUITE_P(Opcodes, DisasmTest,
       disasm_state{ {0x00801036, 0x15400804, 0x01540050, 0x00000002}, "clamp0_max        t0.x___, u0.yyyy, u0.zzzz, void\n"},
       disasm_state{ {0x0080103b, 0x00001804, 0x40000000, 0x00400028}, "iaddsat.s32       t0.x___, t1.xxxx, void, -t2.xxxx\n"},
       disasm_state{ {0x01001008, 0x15400804, 0xd00100c0, 0x00000007}, "imod.u16          t0._y__, t0.yyyy, 1, void\n"},
+      disasm_state{ {0x07811009, 0x15001f20, 0x01ff00c0, 0x78021008}, "txf               t1, tex0.xyzw, t1.xyyy, t1.wwww, 4352\n", FLAG_FAILING_ASM},
       disasm_state{ {0x0080103c, 0x00001804, 0x40000140, 0x00000000}, "imullo0.s32       t0.x___, t1.xxxx, t2.xxxx, void\n"},
       disasm_state{ {0x00801000, 0x00001804, 0x40010140, 0x00000000}, "imulhi0.s32       t0.x___, t1.xxxx, t2.xxxx, void\n"},
       disasm_state{ {0x00801004, 0x00201804, 0x40010040, 0x00000000}, "idiv0.s16         t0.x___, t1.xxxx, t0.xxxx, void\n"},
diff --git a/src/freedreno/.gitlab-ci/reference/crash.log b/src/freedreno/.gitlab-ci/reference/crash.log
index 43540bf3e3e..ca46f5a534f 100644
--- a/src/freedreno/.gitlab-ci/reference/crash.log
+++ b/src/freedreno/.gitlab-ci/reference/crash.log
@@ -7184,7 +7184,7 @@ WARNING: 64b discontinuity (no _LO dword for 890d)
 	00000080	SP_FS_TEX_COUNT: 128
 	0000f000	SP_UNKNOWN_A9A8: 0xf000
 	00421800	SP_CS_CTRL_REG0: { THREADSIZE = THREAD64 | UNK22 | THREADMODE = MULTI | HALFREGFOOTPRINT = 0 | FULLREGFOOTPRINT = 48 | BRANCHSTACK = 8 }
-	0000001f	SP_CS_CTRL_REG1: { SHARED_SIZE = 31 | CONSTANTRAMMODE = CONSTLEN_128 }
+	0000001f	SP_CS_UNKNOWN_A9B1: { SHARED_SIZE = 31 }
 	00000000	SP_CS_BRANCH_COND: 0
 	00000000	SP_CS_OBJ_FIRST_EXEC_OFFSET: 0
 	8c415420	SP_CS_OBJ_START: 0x8c415420
@@ -7252,7 +7252,7 @@ WARNING: 64b discontinuity (no _LO dword for 890d)
 	00000080	SP_FS_TEX_COUNT: 128
 	0000f000	SP_UNKNOWN_A9A8: 0xf000
 	00421800	SP_CS_CTRL_REG0: { THREADSIZE = THREAD64 | UNK22 | THREADMODE = MULTI | HALFREGFOOTPRINT = 0 | FULLREGFOOTPRINT = 48 | BRANCHSTACK = 8 }
-	0000001f	SP_CS_CTRL_REG1: { SHARED_SIZE = 31 | CONSTANTRAMMODE = CONSTLEN_128 }
+	0000001f	SP_CS_UNKNOWN_A9B1: { SHARED_SIZE = 31 }
 	00000000	SP_CS_BRANCH_COND: 0
 	00000000	SP_CS_OBJ_FIRST_EXEC_OFFSET: 0
 	8c415420	SP_CS_OBJ_START: 0x8c415420
diff --git a/src/freedreno/.gitlab-ci/reference/crash_prefetch.log b/src/freedreno/.gitlab-ci/reference/crash_prefetch.log
index 91eec96bce4..47fe4d7adc5 100644
--- a/src/freedreno/.gitlab-ci/reference/crash_prefetch.log
+++ b/src/freedreno/.gitlab-ci/reference/crash_prefetch.log
@@ -18960,7 +18960,7 @@ WARNING: 64b discontinuity (no _LO dword for 890d)
 	00000080	SP_FS_TEX_COUNT: 128
 	00000000	SP_UNKNOWN_A9A8: 0
 	00100000	SP_CS_CTRL_REG0: { THREADSIZE = THREAD128 | THREADMODE = MULTI | HALFREGFOOTPRINT = 0 | FULLREGFOOTPRINT = 0 | BRANCHSTACK = 0 }
-	00000000	SP_CS_CTRL_REG1: { SHARED_SIZE = 0 | CONSTANTRAMMODE = CONSTLEN_128 }
+	00000000	SP_CS_UNKNOWN_A9B1: { SHARED_SIZE = 0 }
 	00000000	SP_CS_BRANCH_COND: 0
 	00000000	SP_CS_OBJ_FIRST_EXEC_OFFSET: 0
 	10019a300	SP_CS_OBJ_START: 0x10019a300
@@ -19028,7 +19028,7 @@ WARNING: 64b discontinuity (no _LO dword for 890d)
 	00000080	SP_FS_TEX_COUNT: 128
 	00000000	SP_UNKNOWN_A9A8: 0
 	00100000	SP_CS_CTRL_REG0: { THREADSIZE = THREAD128 | THREADMODE = MULTI | HALFREGFOOTPRINT = 0 | FULLREGFOOTPRINT = 0 | BRANCHSTACK = 0 }
-	00000000	SP_CS_CTRL_REG1: { SHARED_SIZE = 0 | CONSTANTRAMMODE = CONSTLEN_128 }
+	00000000	SP_CS_UNKNOWN_A9B1: { SHARED_SIZE = 0 }
 	00000000	SP_CS_BRANCH_COND: 0
 	00000000	SP_CS_OBJ_FIRST_EXEC_OFFSET: 0
 	10019a300	SP_CS_OBJ_START: 0x10019a300
diff --git a/src/freedreno/.gitlab-ci/reference/prefetch-test.log b/src/freedreno/.gitlab-ci/reference/prefetch-test.log
index 5f59a0bca96..bb840b2e64b 100644
--- a/src/freedreno/.gitlab-ci/reference/prefetch-test.log
+++ b/src/freedreno/.gitlab-ci/reference/prefetch-test.log
@@ -152955,7 +152955,7 @@ WARNING: 64b discontinuity (no _LO dword for 890d)
 	00000001	SP_FS_TEX_COUNT: 1
 	00000000	SP_UNKNOWN_A9A8: 0
 	00100000	SP_CS_CTRL_REG0: { THREADSIZE = THREAD128 | THREADMODE = MULTI | HALFREGFOOTPRINT = 0 | FULLREGFOOTPRINT = 0 | BRANCHSTACK = 0 }
-	00000000	SP_CS_CTRL_REG1: { SHARED_SIZE = 0 | CONSTANTRAMMODE = CONSTLEN_128 }
+	00000000	SP_CS_UNKNOWN_A9B1: { SHARED_SIZE = 0 }
 	00000000	SP_CS_BRANCH_COND: 0
 	00000000	SP_CS_OBJ_FIRST_EXEC_OFFSET: 0
 	17e0995019d62	SP_CS_OBJ_START: 0x17e0995019d62
@@ -153023,7 +153023,7 @@ WARNING: 64b discontinuity (no _LO dword for 890d)
 	00000001	SP_FS_TEX_COUNT: 1
 	00000000	SP_UNKNOWN_A9A8: 0
 	00100000	SP_CS_CTRL_REG0: { THREADSIZE = THREAD128 | THREADMODE = MULTI | HALFREGFOOTPRINT = 0 | FULLREGFOOTPRINT = 0 | BRANCHSTACK = 0 }
-	00000000	SP_CS_CTRL_REG1: { SHARED_SIZE = 0 | CONSTANTRAMMODE = CONSTLEN_128 }
+	00000000	SP_CS_UNKNOWN_A9B1: { SHARED_SIZE = 0 }
 	00000000	SP_CS_BRANCH_COND: 0
 	00000000	SP_CS_OBJ_FIRST_EXEC_OFFSET: 0
 	17e0995019d62	SP_CS_OBJ_START: 0x17e0995019d62
diff --git a/src/freedreno/ci/freedreno-a618-fails.txt b/src/freedreno/ci/freedreno-a618-fails.txt
index c3a51fd1519..1bac8205848 100644
--- a/src/freedreno/ci/freedreno-a618-fails.txt
+++ b/src/freedreno/ci/freedreno-a618-fails.txt
@@ -220,6 +220,8 @@ spec@glsl-4.00@execution@built-in-functions@fs-op-div-dmat4-dmat4,Fail
 # uprev Piglit in Mesa
 glx@glx-swap-pixmap-bad,Fail
 spec@arb_occlusion_query@occlusion_query_order,Fail
+spec@arb_shader_clock@execution@clock,Fail
+spec@arb_shader_clock@execution@clock2x32,Fail
 spec@glsl-1.30@execution@fs-uint-to-float-of-extract-int16,Fail
 spec@glsl-1.30@execution@fs-uint-to-float-of-extract-int8,Fail
 spec@khr_texture_compression_astc@miptree-gles srgb-fp,Fail
diff --git a/src/freedreno/ci/freedreno-a660-flakes.txt b/src/freedreno/ci/freedreno-a660-flakes.txt
index 41286b28e2c..785a1f474a7 100644
--- a/src/freedreno/ci/freedreno-a660-flakes.txt
+++ b/src/freedreno/ci/freedreno-a660-flakes.txt
@@ -94,3 +94,5 @@ angle-dEQP-GLES31.functional.tessellation.user_defined_io.per_patch.vertex_io_ar
 angle-dEQP-GLES31.functional.tessellation.user_defined_io.per_patch.vertex_io_array_size_implicit.isolines
 angle-dEQP-GLES31.functional.tessellation.user_defined_io.per_patch.vertex_io_array_size_shader_builtin.isolines
 angle-dEQP-GLES31.functional.tessellation.user_defined_io.per_vertex.vertex_io_array_size_shader_builtin.triangles_explicit_tcs_out_size
+angle-dEQP-GLES31.functional.tessellation.invariance.outer_edge_symmetry.isolines_fractional_odd_spacing_cw_point_mode
+
diff --git a/src/freedreno/ci/freedreno-a750-vkd3d-fails.txt b/src/freedreno/ci/freedreno-a750-vkd3d-fails.txt
index 31e860a42d8..1e6a7da575c 100644
--- a/src/freedreno/ci/freedreno-a750-vkd3d-fails.txt
+++ b/src/freedreno/ci/freedreno-a750-vkd3d-fails.txt
@@ -1,7 +1,4 @@
-test_multisample_resolve_strongly_typed,Fail
-test_sampler_rounding,Fail
 test_shader_instructions,Fail
-test_suballocate_small_textures_size,Fail
 
 # msm_dpu ae01000.display-controller: [drm:hangcheck_handler] *ERROR* 67.5.20.1: hangcheck detected gpu lockup rb 0!
 test_fence_wait_robustness,Crash
diff --git a/src/freedreno/ci/freedreno-a750-vkd3d-skips.txt b/src/freedreno/ci/freedreno-a750-vkd3d-skips.txt
deleted file mode 100644
index 53003097c32..00000000000
--- a/src/freedreno/ci/freedreno-a750-vkd3d-skips.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-# These vkd3d-proton tests are skipped because they trigger GPU hangs.
-test_vrs_depth_write_dxbc
diff --git a/src/freedreno/ci/gitlab-ci-inc.yml b/src/freedreno/ci/gitlab-ci-inc.yml
index 188daa6fafb..d2ebdab7f7e 100644
--- a/src/freedreno/ci/gitlab-ci-inc.yml
+++ b/src/freedreno/ci/gitlab-ci-inc.yml
@@ -80,7 +80,7 @@
     - !reference [.freedreno-rules, rules]
 
 .google-freedreno-manual-rules:
-  stage: freedreno-postmerge
+  stage: freedreno-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -88,7 +88,7 @@
     - !reference [.freedreno-manual-rules, rules]
 
 .collabora-freedreno-manual-rules:
-  stage: freedreno-postmerge
+  stage: freedreno-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -111,7 +111,7 @@
     - !reference [.turnip-rules, rules]
 
 .google-turnip-manual-rules:
-  stage: freedreno-postmerge
+  stage: freedreno-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -119,7 +119,7 @@
     - !reference [.turnip-manual-rules, rules]
 
 .collabora-turnip-manual-rules:
-  stage: freedreno-postmerge
+  stage: freedreno-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -135,7 +135,7 @@
     - !reference [.google-turnip-rules, rules]
 
 .google-freedreno-turnip-manual-rules:
-  stage: freedreno-postmerge
+  stage: freedreno-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -150,7 +150,7 @@
     - !reference [.collabora-turnip-rules, rules]
 
 .collabora-freedreno-turnip-manual-rules:
-  stage: freedreno-postmerge
+  stage: freedreno-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -158,7 +158,7 @@
     - !reference [.collabora-turnip-manual-rules, rules]
 
 .valve-freedreno-manual-rules:
-  stage: freedreno-postmerge
+  stage: freedreno-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -166,7 +166,7 @@
     - !reference [.freedreno-manual-rules, rules]
 
 .valve-turnip-manual-rules:
-  stage: freedreno-postmerge
+  stage: freedreno-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -199,7 +199,7 @@
     # Ensure that we are using the release build artifact
     S3_ARTIFACT_NAME: mesa-arm64-default-release
   needs:
-    - debian/baremetal_arm64_test
+    - debian/baremetal_arm64_test-gl
     - debian-arm64-release
   dependencies: null
 
@@ -272,9 +272,22 @@
     VK_DRIVER: freedreno
 
 
-.google-freedreno-test:
+.google-freedreno-test-gl:
   extends:
-    - .baremetal-test-arm64
+    - .baremetal-test-arm64-gl
+    - .google-freedreno-rules
+  variables:
+    VK_DRIVER: freedreno
+    FLAKES_CHANNEL: "#freedreno-ci"
+    PIGLIT_PLATFORM: mixed_glx_egl
+    BM_CMDLINE: "ip=dhcp console=ttyMSM0,115200n8 $BM_KERNEL_EXTRA_ARGS root=/dev/nfs rw nfsrootdebug nfsroot=,tcp,nfsvers=4.2 init=/init $BM_KERNELARGS"
+    FARM: google
+  script:
+    - ./install/bare-metal/fastboot.sh
+
+.google-freedreno-test-vk:
+  extends:
+    - .baremetal-test-arm64-vk
     - .google-freedreno-rules
   variables:
     VK_DRIVER: freedreno
@@ -297,7 +310,7 @@
 
 .a306-test:
   extends:
-    - .google-freedreno-test
+    - .google-freedreno-test-gl
   variables:
     BM_KERNEL: Image.gz
     BM_DTB: apq8016-sbc-usb-host
@@ -310,7 +323,7 @@
 # 8 devices (2023-04-15)
 .a530-test:
   extends:
-    - .google-freedreno-test
+    - .google-freedreno-test-gl
   variables:
     BM_KERNEL: Image.gz
     BM_DTB: apq8096-db820c
@@ -322,8 +335,6 @@
 
 # 6 devices (2023-07-06)
 .a630-test:
-  extends:
-    - .google-freedreno-test
   variables:
     FDO_CI_CONCURRENT: 10
     BM_KERNEL: cheza-kernel
diff --git a/src/freedreno/ci/gitlab-ci.yml b/src/freedreno/ci/gitlab-ci.yml
index 859e30ef885..3ca1e72d281 100644
--- a/src/freedreno/ci/gitlab-ci.yml
+++ b/src/freedreno/ci/gitlab-ci.yml
@@ -14,6 +14,7 @@ a306-piglit:
   extends:
     - .baremetal-deqp-test
     - .a306-test
+    - .test-piglit
     - .google-freedreno-manual-rules
   timeout: 40m
   variables:
@@ -27,6 +28,7 @@ a306-piglit:
   extends:
     - .baremetal-deqp-test
     - .a306-test
+    - .test-piglit
     - .google-freedreno-manual-rules
   variables:
     BM_KERNEL_EXTRA_ARGS: "msm.num_hw_submissions=1"
@@ -38,6 +40,7 @@ a306-piglit-shader:
   extends:
     - .baremetal-deqp-test
     - .a306-test
+    - .test-piglit
     - .google-freedreno-manual-rules
   variables:
     DEQP_SUITE: freedreno-a306-piglit-quick-shader
@@ -57,6 +60,7 @@ a306-traces:
 a530-gl:
   extends:
     - .baremetal-deqp-test
+    - .test-piglit
     - .a530-test
   variables:
     DEQP_SUITE: freedreno-a530
@@ -77,6 +81,7 @@ a530-piglit:
   extends:
     - .baremetal-deqp-test
     - .a530-test
+    - .test-piglit
     - .google-freedreno-manual-rules
   parallel: 2
   variables:
@@ -85,7 +90,7 @@ a530-piglit:
 
 a618-angle:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sc7180-trogdor-kingoftown:arm64
     - .collabora-turnip-manual-rules
     - .test-angle
@@ -94,7 +99,7 @@ a618-angle:
 
 a618-vk:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-vk
     - .lava-sc7180-trogdor-kingoftown:arm64
     - .collabora-turnip-rules
   parallel: 9
@@ -120,7 +125,7 @@ a618-vk-full:
 
 .a618-gl:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sc7180-trogdor-lazor-limozeen:arm64
     - .collabora-freedreno-rules
   variables:
@@ -140,7 +145,7 @@ a618-gl-full:
 # X11 takes over the screen, wayland is run headless.
 .a618-egl:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sc7180-trogdor-lazor-limozeen:arm64
     - .collabora-freedreno-rules
   variables:
@@ -151,7 +156,7 @@ a618-gl-full:
 
 a618-skqp:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sc7180-trogdor-kingoftown:arm64
     - .collabora-freedreno-rules
     # SKQP tests both the GL and VK drivers.
@@ -163,8 +168,9 @@ a618-skqp:
 
 .a618-piglit:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sc7180-trogdor-lazor-limozeen:arm64
+    - .test-piglit
     # Note that piglit has GL+VK integration testing.
     - .collabora-freedreno-turnip-rules
   variables:
@@ -175,8 +181,9 @@ a618-skqp:
 
 a618-piglit-full:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sc7180-trogdor-kingoftown:arm64
+    - .test-piglit
     # Note that piglit has GL+VK integration testing.
     - .collabora-freedreno-turnip-manual-rules
   timeout: 60m
@@ -187,8 +194,9 @@ a618-piglit-full:
 
 a618-piglit-cl:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sc7180-trogdor-lazor-limozeen:arm64
+    - .test-piglit
     - .collabora-freedreno-rules
   rules:
     - !reference [.collabora-freedreno-rules, rules]
@@ -200,7 +208,7 @@ a618-piglit-cl:
 
 a618-traces:
   extends:
-    - .lava-piglit-traces:arm64
+    - .lava-arm64-piglit-traces
     - .lava-sc7180-trogdor-kingoftown:arm64
     - .collabora-freedreno-rules
   variables:
@@ -231,7 +239,7 @@ a618-traces-performance:
 
 a660-angle:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sm8350-hdk:arm64
     - .collabora-turnip-manual-rules
     - .test-angle
@@ -240,8 +248,9 @@ a660-angle:
 
 a660-piglit-cl:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lava-sm8350-hdk:arm64
+    - .test-piglit
     - .collabora-freedreno-rules
   rules:
     - !reference [.collabora-freedreno-rules, rules]
@@ -252,7 +261,7 @@ a660-piglit-cl:
 
 a660-gl:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .collabora-freedreno-rules
     - .lava-sm8350-hdk:arm64
   parallel: 2
@@ -270,7 +279,7 @@ a660-gl-full:
 
 a660-vk:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-vk
     - .collabora-turnip-rules
     - .lava-sm8350-hdk:arm64
   parallel: 5
@@ -292,6 +301,7 @@ a660-vk-full:
 a630-gl:
   extends:
     - .baremetal-deqp-test
+    - .google-freedreno-test-gl
     - .a630-test
   parallel: 3
   variables:
@@ -302,8 +312,9 @@ a630-gl:
 a630-gles-asan:
   extends:
     - .baremetal-deqp-test
+    - .google-freedreno-test-gl
     - .a630-test
-    - .baremetal-arm64-asan-test
+    - .baremetal-arm64-asan-test-gl
   variables:
     DEQP_SUITE: freedreno-a630-gles-asan
     FDO_CI_CONCURRENT: 2 # We get OOMkills if we go too wide with asan enabled
@@ -323,6 +334,7 @@ a630-gles-asan-full:
 
 .a630-vk:
   extends:
+    - .google-freedreno-test-vk
     - .a630-test
     - .baremetal-deqp-test
     - .google-turnip-rules
@@ -346,9 +358,10 @@ a630-vk-full:
 
 a630-vk-asan:
   extends:
+    - .google-freedreno-test-vk
     - .a630-test
     - .baremetal-deqp-test
-    - .baremetal-arm64-asan-test
+    - .baremetal-arm64-asan-test-vk
     - .google-turnip-rules
   variables:
     DEQP_SUITE: freedreno-a630-vk-asan
@@ -356,8 +369,10 @@ a630-vk-asan:
 
 a630-piglit:
   extends:
+    - .google-freedreno-test-gl
     - .baremetal-deqp-test
     - .a630-test
+    - .test-piglit
     # Note that piglit has GL+VK integration testing.
     - .google-freedreno-turnip-rules
   variables:
@@ -367,7 +382,9 @@ a630-piglit:
 a630-piglit-full:
   extends:
     - .baremetal-deqp-test
+    - .google-freedreno-test-gl
     - .a630-test
+    - .test-piglit
     # Note that piglit has GL+VK integration testing.
     - .google-freedreno-turnip-manual-rules
   timeout: 60m
@@ -379,6 +396,7 @@ a630-piglit-full:
 a630-traces:
   extends:
     - .google-freedreno-test-traces
+    - .google-freedreno-test-gl
     - .a630-test
   rules:
     - when: never # Google nginx needs updating
@@ -450,6 +468,7 @@ a750-gl:
 a750-piglit-cl:
   extends:
     - .b2c-arm64-test-gl
+    - .test-piglit
     - .a750-mupuf
     - .valve-freedreno-manual-rules
   rules:
diff --git a/src/freedreno/ci/traces-freedreno.yml b/src/freedreno/ci/traces-freedreno.yml
index 7b6d79e0526..aa19da2c903 100644
--- a/src/freedreno/ci/traces-freedreno.yml
+++ b/src/freedreno/ci/traces-freedreno.yml
@@ -51,10 +51,10 @@ traces:
     freedreno-a630:
       checksum: e0e18dcc50ab2e23cead650d64469178
     zink-a618:
-      checksum: b589b5d9ddd3026cbde08f0abe840ea7
+      checksum: b7e0cdb0db74ea9a31fb7a75ae0d76fc
     zink-a630:
       label: [skip, flakes]
-      checksum: b589b5d9ddd3026cbde08f0abe840ea7
+      checksum: b7e0cdb0db74ea9a31fb7a75ae0d76fc
       text: seems to trigger oomkilling recently
 
   valve/counterstrike-source-v2.trace:
diff --git a/src/freedreno/common/freedreno_dev_info.h b/src/freedreno/common/freedreno_dev_info.h
index 6b20f84506c..a067a38db4f 100644
--- a/src/freedreno/common/freedreno_dev_info.h
+++ b/src/freedreno/common/freedreno_dev_info.h
@@ -51,18 +51,6 @@ struct fd_dev_info {
 
    uint32_t max_waves;
 
-   /* Local Memory (i.e. shared memory in GL/Vulkan) and compute shader
-    * const registers, as well as other things not relevant here, share the
-    * same storage space, called the Local Buffer or LB. This is the size of
-    * the part of the LB used for consts and LM. Consts are duplicated
-    * wavesize_granularity times, and the size of duplicated consts + local
-    * memory must not exceed it. If it is left 0, assume that it is
-    * compute constlen + wavesize_granularity * cs_shared_mem_size, which is
-    * enough to hold both the maximum possible compute consts and local
-    * memory at the same time.
-    */
-   uint32_t compute_lb_size;
-
    /* number of CCU is always equal to the number of SP */
    union {
       uint32_t num_sp_cores;
diff --git a/src/freedreno/common/freedreno_devices.py b/src/freedreno/common/freedreno_devices.py
index 6b41d22574d..b8321245ae7 100644
--- a/src/freedreno/common/freedreno_devices.py
+++ b/src/freedreno/common/freedreno_devices.py
@@ -103,7 +103,7 @@ class GPUInfo(Struct):
                  tile_max_w, tile_max_h, num_vsc_pipes,
                  cs_shared_mem_size, num_sp_cores, wave_granularity, fibers_per_sp,
                  highest_bank_bit = 0, ubwc_swizzle = 0x7, macrotile_mode = 0,
-                 threadsize_base = 64, max_waves = 16, compute_lb_size = 0):
+                 threadsize_base = 64, max_waves = 16):
         self.chip          = chip.value
         self.gmem_align_w  = gmem_align_w
         self.gmem_align_h  = gmem_align_h
@@ -139,13 +139,9 @@ class A6xxGPUInfo(GPUInfo):
         if chip == CHIP.A6XX:
             tile_max_w   = 1024 # max_bitfield_val(5, 0, 5)
             tile_max_h   = max_bitfield_val(14, 8, 4) # 1008
-            compute_lb_size = 0
         else:
             tile_max_w   = 1728
             tile_max_h   = 1728
-            # on a7xx the compute_lb_size is 40KB for all known parts for now.
-            # We have a parameter for it in case some low-end parts cut it down.
-            compute_lb_size = 40 * 1024
 
         super().__init__(chip, gmem_align_w = 16, gmem_align_h = 4,
                          tile_align_w = tile_align_w,
@@ -161,8 +157,7 @@ class A6xxGPUInfo(GPUInfo):
                          ubwc_swizzle = ubwc_swizzle,
                          macrotile_mode = macrotile_mode,
                          threadsize_base    = threadsize_base,
-                         max_waves    = max_waves,
-                         compute_lb_size = compute_lb_size)
+                         max_waves    = max_waves)
 
         self.num_ccu = num_ccu
 
diff --git a/src/freedreno/computerator/a6xx.cc b/src/freedreno/computerator/a6xx.cc
index e0adbfd4c31..c07474c3620 100644
--- a/src/freedreno/computerator/a6xx.cc
+++ b/src/freedreno/computerator/a6xx.cc
@@ -180,18 +180,14 @@ cs_program_emit(struct fd_ringbuffer *ring, struct kernel *kernel)
    }
 
    uint32_t shared_size = MAX2(((int)v->shared_size - 1) / 1024, 1);
-   enum a6xx_const_ram_mode mode =
-      v->constlen > 256 ? CONSTLEN_512 :
-      (v->constlen > 192 ? CONSTLEN_256 :
-      (v->constlen > 128 ? CONSTLEN_192 : CONSTLEN_128));
-   OUT_PKT4(ring, REG_A6XX_SP_CS_CTRL_REG1, 1);
-   OUT_RING(ring, A6XX_SP_CS_CTRL_REG1_SHARED_SIZE(shared_size) |
-                  A6XX_SP_CS_CTRL_REG1_CONSTANTRAMMODE(mode));
+   OUT_PKT4(ring, REG_A6XX_SP_CS_UNKNOWN_A9B1, 1);
+   OUT_RING(ring, A6XX_SP_CS_UNKNOWN_A9B1_SHARED_SIZE(shared_size) |
+                  A6XX_SP_CS_UNKNOWN_A9B1_UNK6);
 
    if (CHIP == A6XX && a6xx_backend->info->a6xx.has_lpac) {
-      OUT_PKT4(ring, REG_A6XX_HLSQ_CS_CTRL_REG1, 1);
-      OUT_RING(ring, A6XX_HLSQ_CS_CTRL_REG1_SHARED_SIZE(1) |
-                     A6XX_HLSQ_CS_CTRL_REG1_CONSTANTRAMMODE(mode));
+      OUT_PKT4(ring, REG_A6XX_HLSQ_CS_UNKNOWN_B9D0, 1);
+      OUT_RING(ring, A6XX_HLSQ_CS_UNKNOWN_B9D0_SHARED_SIZE(1) |
+                        A6XX_HLSQ_CS_UNKNOWN_B9D0_UNK6);
    }
 
    uint32_t local_invocation_id, work_group_id;
diff --git a/src/freedreno/ir3/ir3_compiler.c b/src/freedreno/ir3/ir3_compiler.c
index ee9a101acff..24a8e9ebf6b 100644
--- a/src/freedreno/ir3/ir3_compiler.c
+++ b/src/freedreno/ir3/ir3_compiler.c
@@ -263,14 +263,6 @@ ir3_compiler_create(struct fd_device *dev, const struct fd_dev_id *dev_id,
       compiler->has_early_preamble = false;
    }
 
-   if (dev_info->compute_lb_size) {
-      compiler->compute_lb_size = dev_info->compute_lb_size;
-   } else {
-      compiler->compute_lb_size =
-         compiler->max_const_compute * 16 /* bytes/vec4 */ *
-         compiler->wave_granularity + compiler->local_mem_size;
-   }
-
    /* This is just a guess for a4xx. */
    compiler->pvtmem_per_fiber_align = compiler->gen >= 4 ? 512 : 128;
    /* TODO: implement private memory on earlier gen's */
diff --git a/src/freedreno/ir3/ir3_compiler.h b/src/freedreno/ir3/ir3_compiler.h
index cbf4a253b5b..6a6d31968eb 100644
--- a/src/freedreno/ir3/ir3_compiler.h
+++ b/src/freedreno/ir3/ir3_compiler.h
@@ -129,9 +129,6 @@ struct ir3_compiler {
    /* The maximum number of constants, in vec4's, for compute shaders. */
    uint16_t max_const_compute;
 
-   /* See freedreno_dev_info::compute_lb_size. */
-   uint32_t compute_lb_size;
-
    /* Number of instructions that the shader's base address and length
     * (instrlen divides instruction count by this) must be aligned to.
     */
diff --git a/src/freedreno/ir3/ir3_compiler_nir.c b/src/freedreno/ir3/ir3_compiler_nir.c
index 1e54e0629b1..f5b38eb91be 100644
--- a/src/freedreno/ir3/ir3_compiler_nir.c
+++ b/src/freedreno/ir3/ir3_compiler_nir.c
@@ -2216,47 +2216,11 @@ get_barycentric(struct ir3_context *ctx, enum ir3_bary bary)
    return ctx->ij[bary];
 }
 
-/* TODO: make this a common NIR helper?
- * there is a nir_system_value_from_intrinsic but it takes nir_intrinsic_op so
- * it can't be extended to work with this
- */
-static gl_system_value
-nir_intrinsic_barycentric_sysval(nir_intrinsic_instr *intr)
-{
-   enum glsl_interp_mode interp_mode = nir_intrinsic_interp_mode(intr);
-   gl_system_value sysval;
-
-   switch (intr->intrinsic) {
-   case nir_intrinsic_load_barycentric_pixel:
-      if (interp_mode == INTERP_MODE_NOPERSPECTIVE)
-         sysval = SYSTEM_VALUE_BARYCENTRIC_LINEAR_PIXEL;
-      else
-         sysval = SYSTEM_VALUE_BARYCENTRIC_PERSP_PIXEL;
-      break;
-   case nir_intrinsic_load_barycentric_centroid:
-      if (interp_mode == INTERP_MODE_NOPERSPECTIVE)
-         sysval = SYSTEM_VALUE_BARYCENTRIC_LINEAR_CENTROID;
-      else
-         sysval = SYSTEM_VALUE_BARYCENTRIC_PERSP_CENTROID;
-      break;
-   case nir_intrinsic_load_barycentric_sample:
-      if (interp_mode == INTERP_MODE_NOPERSPECTIVE)
-         sysval = SYSTEM_VALUE_BARYCENTRIC_LINEAR_SAMPLE;
-      else
-         sysval = SYSTEM_VALUE_BARYCENTRIC_PERSP_SAMPLE;
-      break;
-   default:
-      unreachable("invalid barycentric intrinsic");
-   }
-
-   return sysval;
-}
-
 static void
 emit_intrinsic_barycentric(struct ir3_context *ctx, nir_intrinsic_instr *intr,
                            struct ir3_instruction **dst)
 {
-   gl_system_value sysval = nir_intrinsic_barycentric_sysval(intr);
+   gl_system_value sysval = ir3_nir_intrinsic_barycentric_sysval(intr);
 
    if (!ctx->so->key.msaa && ctx->compiler->gen < 6) {
       switch (sysval) {
@@ -3890,7 +3854,7 @@ emit_tex(struct ir3_context *ctx, nir_tex_instr *tex)
          ir3_builder_at(ir3_before_terminator(ctx->in_block));
       sam = ir3_SAM(&build, opc, type, MASK(ncomp), 0, NULL,
                     get_barycentric(ctx, IJ_PERSP_PIXEL), 0);
-      sam->prefetch.input_offset = ir3_nir_coord_offset(tex->src[idx].src.ssa);
+      sam->prefetch.input_offset = ir3_nir_coord_offset(tex->src[idx].src.ssa, NULL);
       /* make sure not to add irrelevant flags like S2EN */
       sam->flags = flags | (info.flags & IR3_INSTR_B);
       sam->prefetch.tex = info.tex_idx;
@@ -5806,24 +5770,7 @@ ir3_compile_shader_nir(struct ir3_compiler *compiler,
 
    ir3_debug_print(ir, "AFTER: ir3_sched");
 
-   /* Pre-assign VS inputs on a6xx+ binning pass shader, to align
-    * with draw pass VS, so binning and draw pass can both use the
-    * same VBO state.
-    *
-    * Note that VS inputs are expected to be full precision.
-    */
-   bool pre_assign_inputs = (ir->compiler->gen >= 6) &&
-                            (ir->type == MESA_SHADER_VERTEX) &&
-                            so->binning_pass;
-
-   if (pre_assign_inputs) {
-      foreach_input (in, ir) {
-         assert(in->opc == OPC_META_INPUT);
-         unsigned inidx = in->input.inidx;
-
-         in->dsts[0]->num = so->nonbinning->inputs[inidx].regid;
-      }
-   } else if (ctx->tcs_header) {
+   if (ctx->tcs_header) {
       /* We need to have these values in the same registers between VS and TCS
        * since the VS chains to TCS and doesn't get the sysvals redelivered.
        */
@@ -5846,7 +5793,8 @@ ir3_compile_shader_nir(struct ir3_compiler *compiler,
       int idx = 0;
 
       foreach_input (instr, ir) {
-         if (instr->input.sysval != SYSTEM_VALUE_BARYCENTRIC_PERSP_PIXEL)
+         if (instr->input.sysval !=
+             (SYSTEM_VALUE_BARYCENTRIC_PERSP_PIXEL + so->prefetch_bary_type))
             continue;
 
          assert(idx < 2);
@@ -5904,20 +5852,8 @@ ir3_compile_shader_nir(struct ir3_compiler *compiler,
    foreach_input (in, ir) {
       assert(in->opc == OPC_META_INPUT);
       unsigned inidx = in->input.inidx;
-
-      if (pre_assign_inputs && !so->inputs[inidx].sysval) {
-         if (VALIDREG(so->nonbinning->inputs[inidx].regid)) {
-            compile_assert(
-               ctx, in->dsts[0]->num == so->nonbinning->inputs[inidx].regid);
-            compile_assert(ctx, !!(in->dsts[0]->flags & IR3_REG_HALF) ==
-                                   so->nonbinning->inputs[inidx].half);
-         }
-         so->inputs[inidx].regid = so->nonbinning->inputs[inidx].regid;
-         so->inputs[inidx].half = so->nonbinning->inputs[inidx].half;
-      } else {
-         so->inputs[inidx].regid = in->dsts[0]->num;
-         so->inputs[inidx].half = !!(in->dsts[0]->flags & IR3_REG_HALF);
-      }
+      so->inputs[inidx].regid = in->dsts[0]->num;
+      so->inputs[inidx].half = !!(in->dsts[0]->flags & IR3_REG_HALF);
    }
 
    uint8_t clip_cull_mask = ctx->so->clip_mask | ctx->so->cull_mask;
diff --git a/src/freedreno/ir3/ir3_context.c b/src/freedreno/ir3/ir3_context.c
index a590749a8a6..da406b5e7ac 100644
--- a/src/freedreno/ir3/ir3_context.c
+++ b/src/freedreno/ir3/ir3_context.c
@@ -109,8 +109,9 @@ ir3_context_init(struct ir3_compiler *compiler, struct ir3_shader *shader,
    /* Enable the texture pre-fetch feature only a4xx onwards.  But
     * only enable it on generations that have been tested:
     */
-   if ((so->type == MESA_SHADER_FRAGMENT) && compiler->has_fs_tex_prefetch)
-      NIR_PASS(_, ctx->s, ir3_nir_lower_tex_prefetch);
+   if ((so->type == MESA_SHADER_FRAGMENT) && compiler->has_fs_tex_prefetch) {
+      NIR_PASS(_, ctx->s, ir3_nir_lower_tex_prefetch, &so->prefetch_bary_type);
+   }
 
    bool vectorized = false;
    NIR_PASS(vectorized, ctx->s, nir_opt_vectorize, ir3_nir_vectorize_filter,
diff --git a/src/freedreno/ir3/ir3_nir.c b/src/freedreno/ir3/ir3_nir.c
index 1fba359e591..851138a8f51 100644
--- a/src/freedreno/ir3/ir3_nir.c
+++ b/src/freedreno/ir3/ir3_nir.c
@@ -363,6 +363,9 @@ ir3_optimize_loop(struct ir3_compiler *compiler,
       progress |= OPT(s, nir_lower_bit_size, ir3_lower_bit_size, NULL);
       progress |= OPT(s, nir_opt_constant_folding);
 
+      /* Remove unused components from IO loads. */
+      progress |= OPT(s, nir_opt_shrink_vectors, true);
+
       const nir_opt_offsets_options offset_options = {
          /* How large an offset we can encode in the instr's immediate field.
           */
@@ -1594,3 +1597,36 @@ ir3_const_state_get_free_space(const struct ir3_shader_variant *v,
    free_space_vec4 = ROUND_DOWN_TO(free_space_vec4, align_vec4);
    return free_space_vec4;
 }
+
+gl_system_value
+ir3_nir_intrinsic_barycentric_sysval(nir_intrinsic_instr *intr)
+{
+   enum glsl_interp_mode interp_mode =
+      (enum glsl_interp_mode)nir_intrinsic_interp_mode(intr);
+   gl_system_value sysval;
+
+   switch (intr->intrinsic) {
+   case nir_intrinsic_load_barycentric_pixel:
+      if (interp_mode == INTERP_MODE_NOPERSPECTIVE)
+         sysval = SYSTEM_VALUE_BARYCENTRIC_LINEAR_PIXEL;
+      else
+         sysval = SYSTEM_VALUE_BARYCENTRIC_PERSP_PIXEL;
+      break;
+   case nir_intrinsic_load_barycentric_centroid:
+      if (interp_mode == INTERP_MODE_NOPERSPECTIVE)
+         sysval = SYSTEM_VALUE_BARYCENTRIC_LINEAR_CENTROID;
+      else
+         sysval = SYSTEM_VALUE_BARYCENTRIC_PERSP_CENTROID;
+      break;
+   case nir_intrinsic_load_barycentric_sample:
+      if (interp_mode == INTERP_MODE_NOPERSPECTIVE)
+         sysval = SYSTEM_VALUE_BARYCENTRIC_LINEAR_SAMPLE;
+      else
+         sysval = SYSTEM_VALUE_BARYCENTRIC_PERSP_SAMPLE;
+      break;
+   default:
+      unreachable("invalid barycentric intrinsic");
+   }
+
+   return sysval;
+}
diff --git a/src/freedreno/ir3/ir3_nir.h b/src/freedreno/ir3/ir3_nir.h
index 1c7e507e277..27c82d37777 100644
--- a/src/freedreno/ir3/ir3_nir.h
+++ b/src/freedreno/ir3/ir3_nir.h
@@ -27,8 +27,9 @@ bool ir3_nir_lower_push_consts_to_preamble(nir_shader *nir,
 bool ir3_nir_lower_driver_params_to_ubo(nir_shader *nir,
                                         struct ir3_shader_variant *v);
 bool ir3_nir_move_varying_inputs(nir_shader *shader);
-int ir3_nir_coord_offset(nir_def *ssa);
-bool ir3_nir_lower_tex_prefetch(nir_shader *shader);
+int ir3_nir_coord_offset(nir_def *ssa, gl_system_value *bary_type);
+bool ir3_nir_lower_tex_prefetch(nir_shader *shader,
+                                enum ir3_bary *prefetch_bary_type);
 bool ir3_nir_lower_layer_id(nir_shader *shader);
 bool ir3_nir_lower_frag_shading_rate(nir_shader *shader);
 bool ir3_nir_lower_primitive_shading_rate(nir_shader *shader);
@@ -196,6 +197,13 @@ is_intrinsic_load(nir_intrinsic_op op)
 
 uint32_t ir3_nir_max_imm_offset(nir_intrinsic_instr *intrin, const void *data);
 
+/* TODO: make this a common NIR helper?
+ * there is a nir_system_value_from_intrinsic but it takes nir_intrinsic_op so
+ * it can't be extended to work with this
+ */
+gl_system_value
+ir3_nir_intrinsic_barycentric_sysval(nir_intrinsic_instr *intr);
+
 ENDC;
 
 #endif /* IR3_NIR_H_ */
diff --git a/src/freedreno/ir3/ir3_nir_lower_tex_prefetch.c b/src/freedreno/ir3/ir3_nir_lower_tex_prefetch.c
index af9830788e2..a29313bc8f1 100644
--- a/src/freedreno/ir3/ir3_nir_lower_tex_prefetch.c
+++ b/src/freedreno/ir3/ir3_nir_lower_tex_prefetch.c
@@ -5,13 +5,25 @@
 
 #include "ir3_nir.h"
 
+#include "util/u_vector.h"
+
 /**
  * A pass which detects tex instructions which are candidate to be executed
  * prior to FS shader start, and change them to nir_texop_tex_prefetch.
  */
 
+typedef struct {
+   nir_tex_instr *tex;
+   enum ir3_bary bary;
+} tex_prefetch_candidate;
+
+typedef struct {
+   struct u_vector candidates;
+   uint32_t per_bary_candidates[IJ_COUNT];
+} ir3_prefetch_state;
+
 static int
-coord_offset(nir_def *ssa)
+coord_offset(nir_def *ssa, gl_system_value *bary_type)
 {
    nir_instr *parent_instr = ssa->parent_instr;
 
@@ -27,7 +39,7 @@ coord_offset(nir_def *ssa)
       if (alu->op != nir_op_vec2)
          return -1;
 
-      int base_src_offset = coord_offset(alu->src[0].src.ssa);
+      int base_src_offset = coord_offset(alu->src[0].src.ssa, bary_type);
       if (base_src_offset < 0)
          return -1;
 
@@ -35,7 +47,7 @@ coord_offset(nir_def *ssa)
 
       /* NOTE it might be possible to support more than 2D? */
       for (int i = 1; i < 2; i++) {
-         int nth_src_offset = coord_offset(alu->src[i].src.ssa);
+         int nth_src_offset = coord_offset(alu->src[i].src.ssa, bary_type);
          if (nth_src_offset < 0)
             return -1;
          int nth_offset = nth_src_offset + alu->src[i].swizzle[0];
@@ -62,20 +74,26 @@ coord_offset(nir_def *ssa)
    nir_intrinsic_instr *interp =
       nir_instr_as_intrinsic(input->src[0].ssa->parent_instr);
 
-   if (interp->intrinsic != nir_intrinsic_load_barycentric_pixel)
+   if (interp->intrinsic != nir_intrinsic_load_barycentric_pixel &&
+       interp->intrinsic != nir_intrinsic_load_barycentric_sample &&
+       interp->intrinsic != nir_intrinsic_load_barycentric_centroid)
       return -1;
 
-   /* interpolation modes such as noperspective aren't covered by the other
+   /* interpolation modes such as flat aren't covered by the other
     * test, we need to explicitly check for them here.
     */
    unsigned interp_mode = nir_intrinsic_interp_mode(interp);
-   if (interp_mode != INTERP_MODE_NONE && interp_mode != INTERP_MODE_SMOOTH)
+   if (interp_mode != INTERP_MODE_NONE && interp_mode != INTERP_MODE_SMOOTH &&
+       interp_mode != INTERP_MODE_NOPERSPECTIVE)
       return -1;
 
    /* we also need a const input offset: */
    if (!nir_src_is_const(input->src[1]))
       return -1;
 
+   if (bary_type)
+      *bary_type = ir3_nir_intrinsic_barycentric_sysval(interp);
+
    unsigned base = nir_src_as_uint(input->src[1]) + nir_intrinsic_base(input);
    unsigned comp = nir_intrinsic_component(input);
 
@@ -83,11 +101,13 @@ coord_offset(nir_def *ssa)
 }
 
 int
-ir3_nir_coord_offset(nir_def *ssa)
+ir3_nir_coord_offset(nir_def *ssa, gl_system_value *bary_type)
 {
 
    assert(ssa->num_components == 2);
-   return coord_offset(ssa);
+   if (bary_type)
+      *bary_type = SYSTEM_VALUE_MAX;
+   return coord_offset(ssa, bary_type);
 }
 
 static bool
@@ -136,7 +156,7 @@ ok_tex_samp(nir_tex_instr *tex)
 }
 
 static bool
-lower_tex_prefetch_block(nir_block *block)
+lower_tex_prefetch_block(nir_block *block, ir3_prefetch_state *state)
 {
    bool progress = false;
 
@@ -168,8 +188,14 @@ lower_tex_prefetch_block(nir_block *block)
       /* First source should be the sampling coordinate. */
       nir_tex_src *coord = &tex->src[idx];
 
-      if (ir3_nir_coord_offset(coord->src.ssa) >= 0) {
-         tex->op = nir_texop_tex_prefetch;
+      gl_system_value bary_type;
+      if (ir3_nir_coord_offset(coord->src.ssa, &bary_type) >= 0) {
+         enum ir3_bary bary = bary_type - SYSTEM_VALUE_BARYCENTRIC_PERSP_PIXEL;
+         state->per_bary_candidates[bary]++;
+
+         tex_prefetch_candidate *candidate = u_vector_add(&state->candidates);
+         candidate->tex = tex;
+         candidate->bary = bary;
 
          progress |= true;
       }
@@ -179,7 +205,7 @@ lower_tex_prefetch_block(nir_block *block)
 }
 
 static bool
-lower_tex_prefetch_func(nir_function_impl *impl)
+lower_tex_prefetch_func(nir_function_impl *impl, ir3_prefetch_state *state)
 {
    /* Only instructions in the the outer-most block are considered eligible for
     * pre-dispatch, because they need to be move-able to the beginning of the
@@ -201,18 +227,22 @@ lower_tex_prefetch_func(nir_function_impl *impl)
       }
    }
 
-   bool progress = lower_tex_prefetch_block(block);
+   bool progress = lower_tex_prefetch_block(block, state);
 
    return nir_progress(progress, impl, nir_metadata_control_flow);
 }
 
 bool
-ir3_nir_lower_tex_prefetch(nir_shader *shader)
+ir3_nir_lower_tex_prefetch(nir_shader *shader,
+                           enum ir3_bary *prefetch_bary_type)
 {
    bool progress = false;
 
    assert(shader->info.stage == MESA_SHADER_FRAGMENT);
 
+   ir3_prefetch_state state = {};
+   u_vector_init(&state.candidates, 4, sizeof(tex_prefetch_candidate));
+
    nir_foreach_function (function, shader) {
       /* Only texture sampling instructions inside the main function
        * are eligible for pre-dispatch.
@@ -220,8 +250,36 @@ ir3_nir_lower_tex_prefetch(nir_shader *shader)
       if (!function->impl || !function->is_entrypoint)
          continue;
 
-      progress |= lower_tex_prefetch_func(function->impl);
+      progress |= lower_tex_prefetch_func(function->impl, &state);
    }
 
+   if (progress) {
+      /* We cannot prefetch tex ops that use different interpolation modes,
+       * so we have to choose a single mode to prefetch. We select the
+       * interpolation mode that would allow us to prefetch the most tex ops.
+       */
+      uint32_t max_tex_with_bary = 0;
+      uint32_t chosen_bary = 0;
+      for (int i = 0; i < IJ_COUNT; i++) {
+         if (state.per_bary_candidates[i] > max_tex_with_bary) {
+            max_tex_with_bary = state.per_bary_candidates[i];
+            chosen_bary = i;
+         }
+      }
+
+      tex_prefetch_candidate *candidate;
+      u_vector_foreach(candidate, &state.candidates) {
+         if (candidate->bary == chosen_bary) {
+            candidate->tex->op = nir_texop_tex_prefetch;
+         }
+      }
+
+      *prefetch_bary_type = chosen_bary;
+   } else {
+      *prefetch_bary_type = IJ_COUNT;
+   }
+
+   u_vector_finish(&state.candidates);
+
    return progress;
 }
diff --git a/src/freedreno/ir3/ir3_shader.h b/src/freedreno/ir3/ir3_shader.h
index 2e28ffbd5fb..5b73403d8c1 100644
--- a/src/freedreno/ir3/ir3_shader.h
+++ b/src/freedreno/ir3/ir3_shader.h
@@ -879,6 +879,7 @@ struct ir3_shader_variant {
    /* texture sampler pre-dispatches */
    uint32_t num_sampler_prefetch;
    struct ir3_sampler_prefetch sampler_prefetch[IR3_MAX_SAMPLER_PREFETCH];
+   enum ir3_bary prefetch_bary_type;
 
    /* If true, the last use of helper invocations is the texture prefetch and
     * they should be disabled for the actual shader. Equivalent to adding
@@ -1051,41 +1052,6 @@ ir3_const_state_mut(const struct ir3_shader_variant *v)
    return v->const_state;
 }
 
-static inline unsigned
-ir3_max_const_compute(const struct ir3_shader_variant *v,
-                      const struct ir3_compiler *compiler)
-{
-   unsigned lm_size = v->local_size_variable ? compiler->local_mem_size :
-      v->cs.req_local_mem;
-
-   /* The LB is divided between consts and local memory. LB is split into
-    * wave_granularity banks, to make it possible for different ALUs to access
-    * it at the same time, and consts are duplicated into each bank so that they
-    * always take constant time to access while LM is spread across the banks.
-    *
-    * We cannot arbitrarily divide LB. Instead only certain configurations, as
-    * defined by the CONSTANTRAMMODE register field, are allowed. Not sticking
-    * with the right configuration can result in hangs when multiple compute
-    * shaders are in flight. We have to limit the constlen so that we can pick a
-    * configuration where there is enough space for LM.
-    */
-   unsigned lb_const_size =
-      ((compiler->compute_lb_size - lm_size) / compiler->wave_granularity) /
-      16 /* bytes per vec4 */;
-   if (lb_const_size < compiler->max_const_compute) {
-      const uint32_t lb_const_sizes[] = { 128, 192, 256, 512 };
-
-      assert(lb_const_size >= lb_const_sizes[0]);
-      for (unsigned i = 0; i < ARRAY_SIZE(lb_const_sizes) - 1; i++) {
-         if (lb_const_size < lb_const_sizes[i + 1])
-            return lb_const_sizes[i];
-      }
-      return lb_const_sizes[ARRAY_SIZE(lb_const_sizes) - 1];
-   } else {
-      return compiler->max_const_compute;
-   }
-}
-
 static inline unsigned
 _ir3_max_const(const struct ir3_shader_variant *v, bool safe_constlen)
 {
@@ -1113,7 +1079,7 @@ _ir3_max_const(const struct ir3_shader_variant *v, bool safe_constlen)
 
    if ((v->type == MESA_SHADER_COMPUTE) ||
        (v->type == MESA_SHADER_KERNEL)) {
-      return ir3_max_const_compute(v, compiler) - shared_consts_size;
+      return compiler->max_const_compute - shared_consts_size;
    } else if (safe_constlen) {
       return compiler->max_const_safe - safe_shared_consts_size;
    } else if (v->type == MESA_SHADER_FRAGMENT) {
diff --git a/src/freedreno/ir3/tests/disasm.c b/src/freedreno/ir3/tests/disasm.c
index a0385ae6d8e..58d83240e9c 100644
--- a/src/freedreno/ir3/tests/disasm.c
+++ b/src/freedreno/ir3/tests/disasm.c
@@ -97,7 +97,9 @@ static const struct test {
    INSTR_6XX(40104002_0c210001, "add.f hr0.z, r0.y, c<a0.x + 33>"),
    INSTR_6XX(40b80804_10408004, "(nop3) cmps.f.lt r1.x, (abs)r1.x, c16.x"),
    INSTR_6XX(47308a02_00002000, "(rpt2)bary.f (ei)r0.z, (r)0, r0.x"),
+   INSTR_6XX(47308802_00002000, "(nop1) bary.f (ei)r0.z, 0, r0.x"),
    INSTR_6XX(47348000_00002000, "flat.b (ei)r0.x, 0, r0.x"),
+   INSTR_6XX(473c8000_00002000, "(nop2) flat.b (ei)r0.x, 0, r0.x"),
    INSTR_6XX(43480801_00008001, "(nop3) absneg.s hr0.y, (abs)hr0.y"),
    INSTR_6XX(42280807_27ff0000, "(nop3) add.s hr1.w, hr0.x, h(-1)"),
    INSTR_6XX(40a500f8_2c000004, "cmps.f.ne p0.x, hr1.x, h(0.0)"),
diff --git a/src/freedreno/isa/ir3-cat2.xml b/src/freedreno/isa/ir3-cat2.xml
index ed7ac69d5ca..e1901cc8e53 100644
--- a/src/freedreno/isa/ir3-cat2.xml
+++ b/src/freedreno/isa/ir3-cat2.xml
@@ -158,6 +158,20 @@ SOFTWARE.
 
 
 <bitset name="#instruction-cat2-2src-input" extends="#instruction-cat2">
+	<override expr="#cat2-cat3-nop-encoding">
+		<display>
+			{SY}{SS}{JP}{SAT}(nop{NOP}) {UL}{NAME} {EI}{DST_HALF}{DST}, {SRC1}, {SRC2}
+		</display>
+		<derived name="NOP" expr="#cat2-cat3-nop-value" type="uint"/>
+		<field name="SRC1" low="0" high="15" type="#multisrc">
+			<param name="ZERO" as="SRC_R"/>
+			<param name="FULL"/>
+		</field>
+		<field name="SRC2" low="16" high="31" type="#multisrc">
+			<param name="ZERO" as="SRC_R"/>
+			<param name="FULL"/>
+		</field>
+	</override>
 	<display>
 		{SY}{SS}{JP}{SAT}{REPEAT}{UL}{NAME} {EI}{DST_HALF}{DST}, {SRC1}, {SRC2}
 	</display>
diff --git a/src/freedreno/registers/adreno/a6xx.xml b/src/freedreno/registers/adreno/a6xx.xml
index 17d26f49260..f47e844215c 100644
--- a/src/freedreno/registers/adreno/a6xx.xml
+++ b/src/freedreno/registers/adreno/a6xx.xml
@@ -5121,15 +5121,8 @@ to upconvert to 32b float internally?
 		<bitfield name="MERGEDREGS" pos="31" type="boolean"/>
 	</reg32>
 
-	<enum name="a6xx_const_ram_mode">
-		<value value="0x0" name="CONSTLEN_128"/>
-		<value value="0x1" name="CONSTLEN_192"/>
-		<value value="0x2" name="CONSTLEN_256"/>
-		<value value="0x3" name="CONSTLEN_512"/> <!-- a7xx only -->
-	</enum>
-
 	<!-- set for compute shaders -->
-	<reg32 offset="0xa9b1" name="SP_CS_CTRL_REG1" usage="cmd">
+	<reg32 offset="0xa9b1" name="SP_CS_UNKNOWN_A9B1" usage="cmd">
 		<bitfield name="SHARED_SIZE" low="0" high="4" type="uint">
 			<doc>
 				If 0 - all 32k of shared storage is enabled, otherwise
@@ -5140,13 +5133,9 @@ to upconvert to 32b float internally?
 				always return 0)
 			</doc>
 		</bitfield>
-		<bitfield name="CONSTANTRAMMODE" low="5" high="6" type="a6xx_const_ram_mode">
-			<doc>
-				This defines the split between consts and local
-				memory in the Local Buffer. The programmed value
-				must be at least the actual CONSTLEN.
-			</doc>
-		</bitfield>
+		<bitfield name="UNK5" pos="5" type="boolean"/>
+		<!-- always 1 ? -->
+		<bitfield name="UNK6" pos="6" type="boolean"/>
 	</reg32>
 	<reg32 offset="0xa9b2" name="SP_CS_BRANCH_COND" type="hex" usage="cmd"/>
 	<reg32 offset="0xa9b3" name="SP_CS_OBJ_FIRST_EXEC_OFFSET" type="uint" usage="cmd"/>
@@ -5769,10 +5758,12 @@ to upconvert to 32b float internally?
 		</reg64>
 	</array>
 
-	<!-- new in a6xx gen4, mirror of SP_CS_CTRL_REG1? -->
-	<reg32 offset="0xb9d0" name="HLSQ_CS_CTRL_REG1" variants="A6XX" usage="cmd">
+	<!-- new in a6xx gen4, mirror of SP_CS_UNKNOWN_A9B1? -->
+	<reg32 offset="0xb9d0" name="HLSQ_CS_UNKNOWN_B9D0" variants="A6XX" usage="cmd">
 		<bitfield name="SHARED_SIZE" low="0" high="4" type="uint"/>
-		<bitfield name="CONSTANTRAMMODE" low="5" high="6" type="a6xx_const_ram_mode"/>
+		<bitfield name="UNK5" pos="5" type="boolean"/>
+		<!-- always 1 ? -->
+		<bitfield name="UNK6" pos="6" type="boolean"/>
 	</reg32>
 
 	<reg32 offset="0xbb00" name="HLSQ_DRAW_CMD" variants="A6XX">
diff --git a/src/freedreno/vulkan/tu_acceleration_structure.cc b/src/freedreno/vulkan/tu_acceleration_structure.cc
index 644a31d9c57..1061341f7e6 100644
--- a/src/freedreno/vulkan/tu_acceleration_structure.cc
+++ b/src/freedreno/vulkan/tu_acceleration_structure.cc
@@ -154,7 +154,7 @@ VkDeviceSize get_bvh_size(VkDevice device,
 }
 
 static uint32_t
-encode_key(VkAccelerationStructureTypeKHR type,
+encode_key(struct vk_device *device, VkAccelerationStructureTypeKHR type,
            VkBuildAccelerationStructureFlagBitsKHR flags)
 {
    return 0;
@@ -233,7 +233,7 @@ enum tu_header_key {
 };
 
 static uint32_t
-header_key(VkAccelerationStructureTypeKHR type,
+header_key(struct vk_device *device, VkAccelerationStructureTypeKHR type,
            VkBuildAccelerationStructureFlagBitsKHR flags)
 {
    return (flags & VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_COMPACTION_BIT_KHR) ?
diff --git a/src/freedreno/vulkan/tu_device.cc b/src/freedreno/vulkan/tu_device.cc
index dd79caf6927..50b9b322ad4 100644
--- a/src/freedreno/vulkan/tu_device.cc
+++ b/src/freedreno/vulkan/tu_device.cc
@@ -2374,7 +2374,7 @@ tu_init_cmdbuf_start_a725_quirk(struct tu_device *device)
             .threadmode = MULTI,
             .threadsize = THREAD128,
             .mergedregs = true));
-   tu_cs_emit_regs(&sub_cs, A6XX_SP_CS_CTRL_REG1(.shared_size = 1));
+   tu_cs_emit_regs(&sub_cs, A6XX_SP_CS_UNKNOWN_A9B1(.shared_size = 1));
    tu_cs_emit_regs(&sub_cs, HLSQ_CS_KERNEL_GROUP_X(A7XX, 1),
                      HLSQ_CS_KERNEL_GROUP_Y(A7XX, 1),
                      HLSQ_CS_KERNEL_GROUP_Z(A7XX, 1));
diff --git a/src/freedreno/vulkan/tu_knl_kgsl.cc b/src/freedreno/vulkan/tu_knl_kgsl.cc
index aab25da7f64..4ba29cebf21 100644
--- a/src/freedreno/vulkan/tu_knl_kgsl.cc
+++ b/src/freedreno/vulkan/tu_knl_kgsl.cc
@@ -1328,7 +1328,7 @@ kgsl_queue_submit(struct tu_queue *queue, void *_submit,
    }
 
 fail_submit:
-   if (result != VK_SUCCESS && u_trace_submission_data) {
+   if (result != VK_SUCCESS) {
       mtx_lock(&queue->device->kgsl_profiling_mutex);
       tu_suballoc_bo_free(&queue->device->kgsl_profiling_suballoc,
                           &u_trace_submission_data->kgsl_timestamp_bo);
diff --git a/src/freedreno/vulkan/tu_pipeline.cc b/src/freedreno/vulkan/tu_pipeline.cc
index 9b4a63e6279..ca5a061c99b 100644
--- a/src/freedreno/vulkan/tu_pipeline.cc
+++ b/src/freedreno/vulkan/tu_pipeline.cc
@@ -3955,7 +3955,7 @@ tu_emit_draw_state(struct tu_cmd_buffer *cmd)
 
    if (!cmd->state.pipeline_disable_fs &&
        (EMIT_STATE(disable_fs) ||
-        (cmd->state.dirty & (TU_CMD_DIRTY_SUBPASS | TU_CMD_DIRTY_FS)))) {
+        (cmd->state.dirty & TU_CMD_DIRTY_SUBPASS))) {
       bool disable_fs = tu_calc_disable_fs(
          &cmd->vk.dynamic_graphics_state.cb, &cmd->state.vk_rp,
          cmd->vk.dynamic_graphics_state.ms.alpha_to_coverage_enable,
diff --git a/src/freedreno/vulkan/tu_shader.cc b/src/freedreno/vulkan/tu_shader.cc
index e7f5a11f543..b588cdf2236 100644
--- a/src/freedreno/vulkan/tu_shader.cc
+++ b/src/freedreno/vulkan/tu_shader.cc
@@ -743,7 +743,7 @@ lower_inline_ubo(nir_builder *b, nir_intrinsic_instr *intrin, void *cb_data)
       val = nir_load_global_ir3(b, intrin->num_components,
                                 intrin->def.bit_size,
                                 base_addr, nir_ishr_imm(b, offset, 2),
-                                .access = 
+                                .access =
                                  (enum gl_access_qualifier)(
                                     (enum gl_access_qualifier)(ACCESS_NON_WRITEABLE | ACCESS_CAN_REORDER) |
                                     ACCESS_CAN_SPECULATE),
@@ -1530,18 +1530,14 @@ tu6_emit_cs_config(struct tu_cs *cs,
    tu6_emit_xs(cs, MESA_SHADER_COMPUTE, v, pvtmem, binary_iova);
 
    uint32_t shared_size = MAX2(((int)v->shared_size - 1) / 1024, 1);
-   enum a6xx_const_ram_mode mode =
-      v->constlen > 256 ? CONSTLEN_512 :
-      (v->constlen > 192 ? CONSTLEN_256 :
-      (v->constlen > 128 ? CONSTLEN_192 : CONSTLEN_128));
-   tu_cs_emit_pkt4(cs, REG_A6XX_SP_CS_CTRL_REG1, 1);
-   tu_cs_emit(cs, A6XX_SP_CS_CTRL_REG1_SHARED_SIZE(shared_size) |
-                  A6XX_SP_CS_CTRL_REG1_CONSTANTRAMMODE(mode));
+   tu_cs_emit_pkt4(cs, REG_A6XX_SP_CS_UNKNOWN_A9B1, 1);
+   tu_cs_emit(cs, A6XX_SP_CS_UNKNOWN_A9B1_SHARED_SIZE(shared_size) |
+                  A6XX_SP_CS_UNKNOWN_A9B1_UNK6);
 
    if (CHIP == A6XX && cs->device->physical_device->info->a6xx.has_lpac) {
-      tu_cs_emit_pkt4(cs, REG_A6XX_HLSQ_CS_CTRL_REG1, 1);
-      tu_cs_emit(cs, A6XX_HLSQ_CS_CTRL_REG1_SHARED_SIZE(shared_size) |
-                     A6XX_HLSQ_CS_CTRL_REG1_CONSTANTRAMMODE(mode));
+      tu_cs_emit_pkt4(cs, REG_A6XX_HLSQ_CS_UNKNOWN_B9D0, 1);
+      tu_cs_emit(cs, A6XX_HLSQ_CS_UNKNOWN_B9D0_SHARED_SIZE(shared_size) |
+                     A6XX_HLSQ_CS_UNKNOWN_B9D0_UNK6);
    }
 
    uint32_t local_invocation_id =
@@ -1589,7 +1585,7 @@ tu6_emit_cs_config(struct tu_cs *cs,
       tu_cs_emit_regs(
          cs, HLSQ_CS_CNTL_1(CHIP,
                    .linearlocalidregid = regid(63, 0), .threadsize = thrsz_cs,
-                   .workgrouprastorderzfirsten = true, 
+                   .workgrouprastorderzfirsten = true,
                    .wgtilewidth = 4, .wgtileheight = tile_height));
 
       tu_cs_emit_regs(cs, HLSQ_FS_CNTL_0(CHIP, .threadsize = THREAD64));
@@ -1689,9 +1685,9 @@ tu6_emit_fs_inputs(struct tu_cs *cs, const struct ir3_shader_variant *fs)
       ij_regid[i] = ir3_find_sysval_regid(fs, SYSTEM_VALUE_BARYCENTRIC_PERSP_PIXEL + i);
 
    if (fs->num_sampler_prefetch > 0) {
-      /* It seems like ij_pix is *required* to be r0.x */
-      assert(!VALIDREG(ij_regid[IJ_PERSP_PIXEL]) ||
-             ij_regid[IJ_PERSP_PIXEL] == regid(0, 0));
+      /* FS prefetch reads coordinates from r0.x */
+      assert(!VALIDREG(ij_regid[fs->prefetch_bary_type]) ||
+             ij_regid[fs->prefetch_bary_type] == regid(0, 0));
    }
 
    tu_cs_emit_pkt4(cs, REG_A6XX_SP_FS_PREFETCH_CNTL, 1 + fs->num_sampler_prefetch);
@@ -2591,10 +2587,8 @@ tu_shader_create(struct tu_device *dev,
             nir_address_format_64bit_global);
 
    if (nir->info.stage == MESA_SHADER_COMPUTE) {
-      if (!nir->info.shared_memory_explicit_layout) {
-         NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
-                  nir_var_mem_shared, shared_type_info);
-      }
+      NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
+               nir_var_mem_shared, shared_type_info);
       NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_shared,
                nir_address_format_32bit_offset);
 
diff --git a/src/gallium/auxiliary/pipe-loader/driinfo_gallium.h b/src/gallium/auxiliary/pipe-loader/driinfo_gallium.h
index 23b565bc989..1175995e6c1 100644
--- a/src/gallium/auxiliary/pipe-loader/driinfo_gallium.h
+++ b/src/gallium/auxiliary/pipe-loader/driinfo_gallium.h
@@ -43,7 +43,6 @@ DRI_CONF_SECTION_DEBUG
    DRI_CONF_FORCE_COMPAT_SHADERS(false)
    DRI_CONF_FORCE_GL_NAMES_REUSE()
    DRI_CONF_FORCE_GL_MAP_BUFFER_SYNCHRONIZED(false)
-   DRI_CONF_FORCE_GL_DEPTH_COMPONENT_TYPE_INT(false)
    DRI_CONF_TRANSCODE_ETC(false)
    DRI_CONF_TRANSCODE_ASTC(false)
    DRI_CONF_ALLOW_COMPRESSED_FALLBACK(true)
diff --git a/src/gallium/auxiliary/util/u_driconf.c b/src/gallium/auxiliary/util/u_driconf.c
index 085b196b52d..ef6ae1c2ed8 100644
--- a/src/gallium/auxiliary/util/u_driconf.c
+++ b/src/gallium/auxiliary/util/u_driconf.c
@@ -69,7 +69,6 @@ u_driconf_fill_st_options(struct st_config_options *options,
    query_bool_option(ignore_discard_framebuffer);
    query_int_option(reuse_gl_names);
    query_bool_option(force_gl_map_buffer_synchronized);
-   query_bool_option(force_gl_depth_component_type_int);
    query_bool_option(transcode_etc);
    query_bool_option(transcode_astc);
    query_bool_option(allow_compressed_fallback);
diff --git a/src/gallium/drivers/asahi/agx_batch.c b/src/gallium/drivers/asahi/agx_batch.c
index 6d61c85470d..20274478b47 100644
--- a/src/gallium/drivers/asahi/agx_batch.c
+++ b/src/gallium/drivers/asahi/agx_batch.c
@@ -133,7 +133,7 @@ agx_batch_init(struct agx_context *ctx,
    batch->clear_depth = 0;
    batch->clear_stencil = 0;
    batch->varyings = 0;
-   batch->geometry_state = 0;
+   batch->heap = 0;
    batch->initialized = false;
    batch->draws = 0;
    batch->incoherent_writes = false;
diff --git a/src/gallium/drivers/asahi/agx_pipe.c b/src/gallium/drivers/asahi/agx_pipe.c
index 76d0c9f79ba..c1aedfbd7a1 100644
--- a/src/gallium/drivers/asahi/agx_pipe.c
+++ b/src/gallium/drivers/asahi/agx_pipe.c
@@ -503,7 +503,7 @@ agx_resource_create_with_modifiers(struct pipe_screen *screen,
     * inferring the shader image flag. Do so to avoid reallocation in case the
     * resource is later used as an image.
     */
-   if (nresource->modifier != DRM_FORMAT_MOD_APPLE_GPU_TILED_COMPRESSED &&
+   if (!ail_is_drm_modifier_compressed(nresource->modifier) &&
        templ->depth0 == 1) {
 
       nresource->base.bind |= PIPE_BIND_SHADER_IMAGE;
@@ -1241,6 +1241,7 @@ agx_cmdbuf(struct agx_device *dev, struct drm_asahi_cmd_render *c,
    c->isp_bgobjvals = 0x300;
 
    struct agx_resource *zres = NULL, *sres = NULL;
+   struct pipe_surface *zsbuf = framebuffer->zsbuf;
 
    if (framebuffer->zsbuf) {
       agx_pack(&c->isp_zls_pixels, CR_ISP_ZLS_PIXELS, cfg) {
@@ -1249,123 +1250,108 @@ agx_cmdbuf(struct agx_device *dev, struct drm_asahi_cmd_render *c,
       }
    }
 
-   agx_pack(&c->zls_ctrl, ZLS_CONTROL, zls_control) {
-
-      if (framebuffer->zsbuf) {
-         struct pipe_surface *zsbuf = framebuffer->zsbuf;
-         struct agx_resource *zsres = agx_resource(zsbuf->texture);
-
-         unsigned level = zsbuf->u.tex.level;
-         unsigned first_layer = zsbuf->u.tex.first_layer;
-
-         const struct util_format_description *desc = util_format_description(
-            agx_resource(zsbuf->texture)->layout.format);
-
-         assert(desc->format == PIPE_FORMAT_Z32_FLOAT ||
-                desc->format == PIPE_FORMAT_Z16_UNORM ||
-                desc->format == PIPE_FORMAT_Z32_FLOAT_S8X24_UINT ||
-                desc->format == PIPE_FORMAT_S8_UINT);
-
-         if (util_format_has_depth(desc))
-            zres = zsres;
-         else
-            sres = zsres;
-
-         if (zsres->separate_stencil)
-            sres = zsres->separate_stencil;
-
-         if (zres) {
-            bool clear = (batch->clear & PIPE_CLEAR_DEPTH);
-            bool load = (batch->load & PIPE_CLEAR_DEPTH);
-
-            zls_control.z_store_enable = (batch->resolve & PIPE_CLEAR_DEPTH);
-            zls_control.z_load_enable = !clear && load;
-
-            c->depth.base = agx_map_texture_gpu(zres, first_layer) +
-                            ail_get_level_offset_B(&zres->layout, level);
-
-            /* Main stride in pages */
-            assert((zres->layout.depth_px == 1 ||
-                    is_aligned(zres->layout.layer_stride_B, AIL_PAGESIZE)) &&
-                   "Page aligned Z layers");
-
-            unsigned stride_pages = zres->layout.layer_stride_B / AIL_PAGESIZE;
-            c->depth.stride = ((stride_pages - 1) << 14) | 1;
-
-            assert(zres->layout.tiling != AIL_TILING_LINEAR && "must tile");
-
-            if (zres->layout.compressed) {
-               c->depth.comp_base =
-                  agx_map_texture_gpu(zres, 0) +
-                  zres->layout.metadata_offset_B +
-                  (first_layer * zres->layout.compression_layer_stride_B) +
-                  zres->layout.level_offsets_compressed_B[level];
-
-               /* Meta stride in cache lines */
-               assert(is_aligned(zres->layout.compression_layer_stride_B,
-                                 AIL_CACHELINE) &&
-                      "Cacheline aligned Z meta layers");
-               unsigned stride_lines =
-                  zres->layout.compression_layer_stride_B / AIL_CACHELINE;
-               c->depth.comp_stride = (stride_lines - 1) << 14;
-
-               zls_control.z_compress_1 = true;
-               zls_control.z_compress_2 = true;
-            }
-
-            if (zres->base.format == PIPE_FORMAT_Z16_UNORM) {
-               const float scale = 0xffff;
-               c->isp_bgobjdepth =
-                  (uint16_t)(SATURATE(clear_depth) * scale + 0.5f);
-               zls_control.z_format = AGX_ZLS_FORMAT_16;
-               c->flags |= DRM_ASAHI_RENDER_DBIAS_IS_INT;
-            } else {
-               c->isp_bgobjdepth = fui(clear_depth);
-               zls_control.z_format = AGX_ZLS_FORMAT_32F;
-            }
+   if (zsbuf) {
+      struct agx_resource *zsres = agx_resource(zsbuf->texture);
+      const struct util_format_description *desc =
+         util_format_description(zsres->layout.format);
+
+      assert(desc->format == PIPE_FORMAT_Z32_FLOAT ||
+             desc->format == PIPE_FORMAT_Z16_UNORM ||
+             desc->format == PIPE_FORMAT_Z32_FLOAT_S8X24_UINT ||
+             desc->format == PIPE_FORMAT_S8_UINT);
+
+      if (util_format_has_depth(desc))
+         zres = zsres;
+      else
+         sres = zsres;
+
+      if (zsres->separate_stencil)
+         sres = zsres->separate_stencil;
+
+      unsigned level = zsbuf->u.tex.level;
+      unsigned first_layer = zsbuf->u.tex.first_layer;
+
+      if (zres) {
+         c->depth.base = agx_map_texture_gpu(zres, first_layer) +
+                         ail_get_level_offset_B(&zres->layout, level);
+
+         /* Main stride in pages */
+         assert((zres->layout.depth_px == 1 ||
+                 is_aligned(zres->layout.layer_stride_B, AIL_PAGESIZE)) &&
+                "Page aligned Z layers");
+
+         unsigned stride_pages = zres->layout.layer_stride_B / AIL_PAGESIZE;
+         c->depth.stride = ((stride_pages - 1) << 14) | 1;
+
+         if (zres->layout.compressed) {
+            c->depth.comp_base =
+               agx_map_texture_gpu(zres, 0) + zres->layout.metadata_offset_B +
+               (first_layer * zres->layout.compression_layer_stride_B) +
+               zres->layout.level_offsets_compressed_B[level];
+
+            /* Meta stride in cache lines */
+            assert(is_aligned(zres->layout.compression_layer_stride_B,
+                              AIL_CACHELINE) &&
+                   "Cacheline aligned Z meta layers");
+            unsigned stride_lines =
+               zres->layout.compression_layer_stride_B / AIL_CACHELINE;
+            c->depth.comp_stride = (stride_lines - 1) << 14;
+         }
+
+         if (zres->base.format == PIPE_FORMAT_Z16_UNORM) {
+            const float scale = 0xffff;
+            c->isp_bgobjdepth =
+               (uint16_t)(SATURATE(clear_depth) * scale + 0.5f);
+
+            c->flags |= DRM_ASAHI_RENDER_DBIAS_IS_INT;
+         } else {
+            c->isp_bgobjdepth = fui(clear_depth);
          }
+      }
 
-         if (sres) {
-            bool clear = (batch->clear & PIPE_CLEAR_STENCIL);
-            bool load = (batch->load & PIPE_CLEAR_STENCIL);
-
-            zls_control.s_store_enable = (batch->resolve & PIPE_CLEAR_STENCIL);
-            zls_control.s_load_enable = !clear && load;
-
-            c->stencil.base = agx_map_texture_gpu(sres, first_layer) +
-                              ail_get_level_offset_B(&sres->layout, level);
-
-            /* Main stride in pages */
-            assert((sres->layout.depth_px == 1 ||
-                    is_aligned(sres->layout.layer_stride_B, AIL_PAGESIZE)) &&
-                   "Page aligned S layers");
-            unsigned stride_pages = sres->layout.layer_stride_B / AIL_PAGESIZE;
-            c->stencil.stride = ((stride_pages - 1) << 14) | 1;
-
-            if (sres->layout.compressed) {
-               c->stencil.comp_base =
-                  agx_map_texture_gpu(sres, 0) +
-                  sres->layout.metadata_offset_B +
-                  (first_layer * sres->layout.compression_layer_stride_B) +
-                  sres->layout.level_offsets_compressed_B[level];
-
-               /* Meta stride in cache lines */
-               assert(is_aligned(sres->layout.compression_layer_stride_B,
-                                 AIL_CACHELINE) &&
-                      "Cacheline aligned S meta layers");
-               unsigned stride_lines =
-                  sres->layout.compression_layer_stride_B / AIL_CACHELINE;
-               c->stencil.comp_stride = (stride_lines - 1) << 14;
-
-               zls_control.s_compress_1 = true;
-               zls_control.s_compress_2 = true;
-            }
-
-            c->isp_bgobjvals |= clear_stencil;
+      if (sres) {
+         c->stencil.base = agx_map_texture_gpu(sres, first_layer) +
+                           ail_get_level_offset_B(&sres->layout, level);
+
+         /* Main stride in pages */
+         assert((sres->layout.depth_px == 1 ||
+                 is_aligned(sres->layout.layer_stride_B, AIL_PAGESIZE)) &&
+                "Page aligned S layers");
+         unsigned stride_pages = sres->layout.layer_stride_B / AIL_PAGESIZE;
+         c->stencil.stride = ((stride_pages - 1) << 14) | 1;
+
+         if (sres->layout.compressed) {
+            c->stencil.comp_base =
+               agx_map_texture_gpu(sres, 0) + sres->layout.metadata_offset_B +
+               (first_layer * sres->layout.compression_layer_stride_B) +
+               sres->layout.level_offsets_compressed_B[level];
+
+            /* Meta stride in cache lines */
+            assert(is_aligned(sres->layout.compression_layer_stride_B,
+                              AIL_CACHELINE) &&
+                   "Cacheline aligned S meta layers");
+            unsigned stride_lines =
+               sres->layout.compression_layer_stride_B / AIL_CACHELINE;
+            c->stencil.comp_stride = (stride_lines - 1) << 14;
          }
+
+         c->isp_bgobjvals |= clear_stencil;
       }
    }
 
+   unsigned load = batch->load & ~batch->clear;
+
+   struct agx_zls zls = {
+      .z_store = batch->resolve & PIPE_CLEAR_DEPTH,
+      .s_store = batch->resolve & PIPE_CLEAR_STENCIL,
+      .z_load = load & PIPE_CLEAR_DEPTH,
+      .s_load = load & PIPE_CLEAR_STENCIL,
+   };
+
+   agx_pack_zls_control((struct agx_zls_control_packed *)&c->zls_ctrl,
+                        zres ? &zres->layout : NULL,
+                        sres ? &sres->layout : NULL, &zls);
+
    if (dev->debug & AGX_DBG_NOCLUSTER)
       c->flags |= DRM_ASAHI_RENDER_NO_VERTEX_CLUSTERING;
 
diff --git a/src/gallium/drivers/asahi/agx_state.c b/src/gallium/drivers/asahi/agx_state.c
index 39e61873e64..b8e5817173a 100644
--- a/src/gallium/drivers/asahi/agx_state.c
+++ b/src/gallium/drivers/asahi/agx_state.c
@@ -60,6 +60,7 @@
 #include "agx_nir_lower_gs.h"
 #include "agx_nir_lower_vbo.h"
 #include "agx_tilebuffer.h"
+#include "geometry.h"
 #include "libagx.h"
 #include "libagx_dgc.h"
 #include "libagx_shaders.h"
@@ -1303,14 +1304,14 @@ agx_batch_upload_pbe(struct agx_batch *batch, struct agx_pbe_packed *out,
             cfg.aligned_width_msaa_sw =
                align(u_minify(view->resource->width0, level),
                      tex->layout.tilesize_el[level].width_el);
+
+            cfg.sample_count_log2_sw = util_logbase2(tex->base.nr_samples);
          } else {
             cfg.level_offset_sw =
                ail_get_level_offset_B(&tex->layout, cfg.level);
          }
 
-         cfg.sample_count_log2_sw = util_logbase2(tex->base.nr_samples);
-
-         if (tex->layout.tiling == AIL_TILING_GPU || emrt) {
+         if (tex->layout.tiling != AIL_TILING_LINEAR || emrt) {
             struct ail_tile tile_size = tex->layout.tilesize_el[level];
             cfg.tile_width_sw = tile_size.width_el;
             cfg.tile_height_sw = tile_size.height_el;
@@ -3937,11 +3938,11 @@ agx_ia_update(struct agx_batch *batch, const struct pipe_draw_info *info,
 }
 
 static uint64_t
-agx_batch_geometry_state(struct agx_batch *batch)
+agx_batch_heap(struct agx_batch *batch)
 {
    struct agx_context *ctx = batch->ctx;
 
-   if (!batch->geometry_state) {
+   if (!batch->heap) {
       uint32_t size = 128 * 1024 * 1024;
 
       if (!ctx->heap) {
@@ -3949,18 +3950,18 @@ agx_batch_geometry_state(struct agx_batch *batch)
                                         PIPE_USAGE_DEFAULT, size);
       }
 
-      struct agx_geometry_state state = {
-         .heap = agx_resource(ctx->heap)->bo->va->addr,
-         .heap_size = size,
+      struct agx_heap heap = {
+         .base = agx_resource(ctx->heap)->bo->va->addr,
+         .size = size,
       };
 
       agx_batch_writes(batch, agx_resource(ctx->heap), 0);
 
-      batch->geometry_state =
-         agx_pool_upload_aligned(&batch->pool, &state, sizeof(state), 8);
+      batch->heap =
+         agx_pool_upload_aligned(&batch->pool, &heap, sizeof(heap), 8);
    }
 
-   return batch->geometry_state;
+   return batch->heap;
 }
 
 static uint64_t
@@ -3980,7 +3981,6 @@ agx_batch_geometry_params(struct agx_batch *batch, uint64_t input_index_buffer,
       agx_pool_upload_aligned(&batch->pool, &ia, sizeof(ia), 8);
 
    struct agx_geometry_params params = {
-      .state = agx_batch_geometry_state(batch),
       .indirect_desc = batch->geom_indirect,
       .flat_outputs =
          batch->ctx->stage[PIPE_SHADER_FRAGMENT].shader->info.inputs_flat_shaded,
@@ -4039,14 +4039,16 @@ agx_batch_geometry_params(struct agx_batch *batch, uint64_t input_index_buffer,
       params.count_buffer = T.gpu;
    }
 
+   /* Workgroup size */
+   params.vs_grid[3] = params.gs_grid[3] = 64;
+   params.vs_grid[4] = params.gs_grid[4] = 1;
+   params.vs_grid[5] = params.gs_grid[5] = 1;
+
    if (indirect) {
       batch->uniforms.vertex_output_buffer_ptr =
          agx_pool_alloc_aligned(&batch->pool, 8, 8).gpu;
 
       params.vs_grid[2] = params.gs_grid[2] = 1;
-
-      batch->geom_index_bo = agx_resource(batch->ctx->heap)->bo;
-      batch->geom_index = batch->geom_index_bo->va->addr;
    } else {
       params.vs_grid[0] = draw->count;
       params.gs_grid[0] =
@@ -4073,14 +4075,16 @@ agx_batch_geometry_params(struct agx_batch *batch, uint64_t input_index_buffer,
          params.input_buffer = addr;
       }
 
-      unsigned idx_size =
-         params.input_primitives * batch->ctx->gs->gs.max_indices;
+      struct agx_gs_info *gsi = &batch->ctx->gs->gs;
+      if (gsi->shape == AGX_GS_SHAPE_DYNAMIC_INDEXED) {
+         unsigned idx_size = params.input_primitives * gsi->max_indices;
 
-      params.output_index_buffer =
-         agx_pool_alloc_aligned_with_bo(&batch->pool, idx_size * 4, 4,
-                                        &batch->geom_index_bo)
-            .gpu;
-      batch->geom_index = params.output_index_buffer;
+         params.output_index_buffer =
+            agx_pool_alloc_aligned_with_bo(&batch->pool, idx_size * 4, 4,
+                                           &batch->geom_index_bo)
+               .gpu;
+         batch->geom_index = params.output_index_buffer;
+      }
    }
 
    return agx_pool_upload_aligned_with_bo(&batch->pool, &params, sizeof(params),
@@ -4131,7 +4135,7 @@ agx_launch_gs_prerast(struct agx_batch *batch,
 
    uint64_t gp = batch->uniforms.geometry_params;
    struct agx_grid grid_vs, grid_gs;
-   struct agx_workgroup wg;
+   struct agx_workgroup wg = agx_workgroup(64, 1, 1);
 
    /* Setup grids */
    if (indirect) {
@@ -4150,23 +4154,23 @@ agx_launch_gs_prerast(struct agx_batch *batch,
          .vertex_buffer = batch->uniforms.vertex_output_buffer_ptr,
          .ia = batch->uniforms.input_assembly,
          .p = batch->uniforms.geometry_params,
+         .heap = agx_batch_heap(batch),
          .vs_outputs = batch->uniforms.vertex_outputs,
          .index_size_B = info->index_size,
          .prim = info->mode,
          .is_prefix_summing = gs->gs.prefix_sum,
-         .indices_per_in_prim = gs->gs.max_indices,
+         .max_indices = gs->gs.max_indices,
+         .shape = gs->gs.shape,
       };
 
       libagx_gs_setup_indirect_struct(batch, agx_1d(1), AGX_BARRIER_ALL, gsi);
 
-      wg = agx_workgroup(1, 1, 1);
-      grid_vs =
-         agx_grid_indirect(gp + offsetof(struct agx_geometry_params, vs_grid));
+      grid_vs = agx_grid_indirect_local(
+         gp + offsetof(struct agx_geometry_params, vs_grid));
 
-      grid_gs =
-         agx_grid_indirect(gp + offsetof(struct agx_geometry_params, gs_grid));
+      grid_gs = agx_grid_indirect_local(
+         gp + offsetof(struct agx_geometry_params, gs_grid));
    } else {
-      wg = agx_workgroup(64, 1, 1);
       grid_vs = agx_3d(draws->count, info->instance_count, 1);
 
       grid_gs =
@@ -4270,7 +4274,7 @@ agx_draw_without_restart(struct agx_batch *batch,
       &out_draws_rsrc.bo);
 
    struct libagx_unroll_restart_args unroll = {
-      .heap = agx_batch_geometry_state(batch),
+      .heap = agx_batch_heap(batch),
       .index_buffer = ib,
       .out_draw = out_draws.gpu,
       .restart_index = info->restart_index,
@@ -4606,11 +4610,11 @@ agx_draw_patches(struct agx_context *ctx, const struct pipe_draw_info *info,
    agx_upload_draw_params(batch, indirect, draws, info);
 
    /* Setup parameters */
-   uint64_t geom_state = agx_batch_geometry_state(batch);
+   uint64_t heap = agx_batch_heap(batch);
    assert((tcs->tess.output_stride & 3) == 0 && "must be aligned");
 
    struct libagx_tess_args args = {
-      .heap = geom_state,
+      .heap = heap,
       .tcs_stride_el = tcs->tess.output_stride / 4,
       .statistic = agx_get_query_address(
          batch, ctx->pipeline_statistics[PIPE_STAT_QUERY_DS_INVOCATIONS]),
@@ -5135,7 +5139,7 @@ agx_draw_vbo(struct pipe_context *pctx, const struct pipe_draw_info *info,
 
    /* Wrap the pool allocation in a fake resource for meta-Gallium use */
    struct agx_resource indirect_rsrc = {.bo = batch->geom_indirect_bo};
-   struct agx_resource index_rsrc = {.bo = batch->geom_index_bo};
+   struct agx_resource index_rsrc = {};
 
    if (ctx->gs) {
       /* Launch the pre-rasterization parts of the geometry shader */
@@ -5145,11 +5149,12 @@ agx_draw_vbo(struct pipe_context *pctx, const struct pipe_draw_info *info,
          return;
 
       /* Setup to rasterize the GS results */
+      struct agx_gs_info *gsi = &ctx->gs->gs;
       info_gs = (struct pipe_draw_info){
-         .mode = ctx->gs->gs.mode,
-         .index_size = 4,
-         .primitive_restart = true,
-         .restart_index = ~0,
+         .mode = gsi->mode,
+         .index_size = agx_gs_index_size(gsi->shape),
+         .primitive_restart = agx_gs_indexed(gsi->shape),
+         .restart_index = agx_gs_index_size(gsi->shape) == 1 ? 0xFF : ~0,
          .index.resource = &index_rsrc.base,
          .instance_count = 1,
       };
@@ -5162,26 +5167,38 @@ agx_draw_vbo(struct pipe_context *pctx, const struct pipe_draw_info *info,
          };
 
          indirect = &indirect_gs;
+
+         batch->geom_index_bo = agx_resource(batch->ctx->heap)->bo;
+         batch->geom_index = batch->geom_index_bo->va->addr;
       } else {
-         unsigned unrolled_prims =
-            u_decomposed_prims_for_vertices(info->mode, draws->count) *
-            info->instance_count;
+         unsigned prims =
+            u_decomposed_prims_for_vertices(info->mode, draws->count);
 
          draw_gs = (struct pipe_draw_start_count_bias){
-            .count = ctx->gs->gs.max_indices * unrolled_prims,
+            .count = agx_gs_rast_vertices(gsi->shape, gsi->max_indices, prims,
+                                          info->instance_count),
          };
 
+         info_gs.instance_count = agx_gs_rast_instances(
+            gsi->shape, gsi->max_indices, prims, info->instance_count);
+
          draws = &draw_gs;
       }
 
       info = &info_gs;
+      index_rsrc.bo = batch->geom_index_bo;
 
       /* TODO: Deduplicate? */
       batch->reduced_prim = u_reduced_prim(info->mode);
       ctx->dirty |= AGX_DIRTY_PRIM;
 
-      ib = batch->geom_index;
-      ib_extent = index_rsrc.bo->size - (batch->geom_index - ib);
+      if (gsi->shape == AGX_GS_SHAPE_DYNAMIC_INDEXED) {
+         ib = batch->geom_index;
+         ib_extent = index_rsrc.bo->size - (batch->geom_index - ib);
+      } else if (gsi->shape == AGX_GS_SHAPE_STATIC_INDEXED) {
+         ib = agx_pool_upload(&batch->pool, gsi->topology, gsi->max_indices);
+         ib_extent = gsi->max_indices;
+      }
 
       /* We need to reemit geometry descriptors since the txf sampler may change
        * between the GS prepass and the GS rast program.
@@ -5297,6 +5314,8 @@ agx_launch(struct agx_batch *batch, struct agx_grid grid,
            unsigned variable_shared_mem)
 {
    struct agx_context *ctx = batch->ctx;
+   if (!linked && agx_is_shader_empty(&cs->b))
+      return;
 
    /* To implement load_num_workgroups, the number of workgroups needs to be
     * available in GPU memory. This is either the indirect buffer, or just a
diff --git a/src/gallium/drivers/asahi/agx_state.h b/src/gallium/drivers/asahi/agx_state.h
index e6dd33aaf27..5ae930d4af4 100644
--- a/src/gallium/drivers/asahi/agx_state.h
+++ b/src/gallium/drivers/asahi/agx_state.h
@@ -419,8 +419,8 @@ struct agx_batch {
    uint64_t geom_indirect;
    struct agx_bo *geom_indirect_bo;
 
-   /* Geometry state buffer if geometry/etc shaders are used */
-   uint64_t geometry_state;
+   /* Heap descriptor if dynamic allocation is required */
+   uint64_t heap;
 
    /* Uploaded descriptors */
    uint32_t texture_count[PIPE_SHADER_TYPES];
diff --git a/src/gallium/drivers/asahi/meson.build b/src/gallium/drivers/asahi/meson.build
index 61bbc4c5bdf..900c54d0a1e 100644
--- a/src/gallium/drivers/asahi/meson.build
+++ b/src/gallium/drivers/asahi/meson.build
@@ -23,7 +23,7 @@ libasahi = static_library(
   include_directories : [inc_gallium_aux, inc_gallium, inc_include, inc_src, inc_asahi, inc_virtio_gpu, inc_virtio_vdrm],
   c_args : [c_msvc_compat_args, '-Wno-c2x-extensions'],
   gnu_symbol_visibility : 'hidden',
-  dependencies : [idep_nir, idep_mesautil, idep_agx_pack, dep_libdrm, idep_libagx, idep_libagx_shaders_h],
+  dependencies : [idep_nir, idep_mesautil, idep_agx_pack, dep_libdrm, idep_mesaclc, idep_libagx, idep_libagx_shaders_h],
 )
 
 driver_asahi = declare_dependency(
diff --git a/src/gallium/drivers/crocus/ci/gitlab-ci-inc.yml b/src/gallium/drivers/crocus/ci/gitlab-ci-inc.yml
index e3d0dac9a3a..01474f67d68 100644
--- a/src/gallium/drivers/crocus/ci/gitlab-ci-inc.yml
+++ b/src/gallium/drivers/crocus/ci/gitlab-ci-inc.yml
@@ -20,6 +20,7 @@
   extends:
     - .anholt-g41-test
     - .test-gl
+    - .test-piglit
     - .deqp-test
   variables:
     DEQP_SUITE: crocus-g41
diff --git a/src/gallium/drivers/crocus/ci/gitlab-ci.yml b/src/gallium/drivers/crocus/ci/gitlab-ci.yml
index 14850941b97..0f67598b35e 100644
--- a/src/gallium/drivers/crocus/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/crocus/ci/gitlab-ci.yml
@@ -6,6 +6,7 @@ crocus-hsw:
     - .anholt-hsw-test
     - .test-gl
     - .deqp-test
+    - .test-piglit
     - .crocus-manual-rules
   variables:
     GPU_VERSION: crocus-hsw
diff --git a/src/gallium/drivers/crocus/crocus_batch.c b/src/gallium/drivers/crocus/crocus_batch.c
index 5d74101c5df..9a8505e7c4b 100644
--- a/src/gallium/drivers/crocus/crocus_batch.c
+++ b/src/gallium/drivers/crocus/crocus_batch.c
@@ -947,7 +947,9 @@ _crocus_batch_flush(struct crocus_batch *batch, const char *file, int line)
    finish_growing_bos(&batch->state);
    int ret = submit_batch(batch);
 
-   if (INTEL_DEBUG(DEBUG_BATCH | DEBUG_SUBMIT | DEBUG_PIPE_CONTROL)) {
+   if (INTEL_DEBUG(DEBUG_BATCH) ||
+       INTEL_DEBUG(DEBUG_SUBMIT) ||
+       INTEL_DEBUG(DEBUG_PIPE_CONTROL)) {
       int bytes_for_commands = crocus_batch_bytes_used(batch);
       int second_bytes = 0;
       if (batch->command.bo != batch->exec_bos[0]) {
@@ -965,7 +967,7 @@ _crocus_batch_flush(struct crocus_batch *batch, const char *file, int line)
               batch->command.relocs.reloc_count,
               batch->state.relocs.reloc_count);
 
-      if (INTEL_DEBUG(DEBUG_BATCH | DEBUG_SUBMIT)) {
+      if (INTEL_DEBUG(DEBUG_BATCH) || INTEL_DEBUG(DEBUG_SUBMIT)) {
          dump_fence_list(batch);
          dump_validation_list(batch);
       }
diff --git a/src/gallium/drivers/crocus/crocus_state.c b/src/gallium/drivers/crocus/crocus_state.c
index 898fb55f71d..d6c63f6cb7c 100644
--- a/src/gallium/drivers/crocus/crocus_state.c
+++ b/src/gallium/drivers/crocus/crocus_state.c
@@ -771,7 +771,7 @@ crocus_calculate_urb_fence(struct crocus_batch *batch, unsigned csize,
             exit(1);
          }
 
-         if (INTEL_DEBUG(DEBUG_URB|DEBUG_PERF))
+         if (INTEL_DEBUG(DEBUG_URB) || INTEL_DEBUG(DEBUG_PERF))
             fprintf(stderr, "URB CONSTRAINED\n");
       }
 
diff --git a/src/gallium/drivers/d3d12/ci/gitlab-ci.yml b/src/gallium/drivers/d3d12/ci/gitlab-ci.yml
index c4dd60d680a..b8149e588fb 100644
--- a/src/gallium/drivers/d3d12/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/d3d12/ci/gitlab-ci.yml
@@ -19,6 +19,7 @@
 .d3d12-test-piglit:
   extends:
     - .d3d12-test
+    - .test-piglit
   script:
     - . _install/piglit_run.ps1
   # temporarily restrict to GSt runners until we discover why GL testing is
diff --git a/src/gallium/drivers/d3d12/d3d12_context_common.cpp b/src/gallium/drivers/d3d12/d3d12_context_common.cpp
index a4a5523c603..d741a0a7fa3 100644
--- a/src/gallium/drivers/d3d12/d3d12_context_common.cpp
+++ b/src/gallium/drivers/d3d12/d3d12_context_common.cpp
@@ -494,12 +494,16 @@ d3d12_context_create(struct pipe_screen *pscreen, void *priv, unsigned flags)
       ctx->batches[i].ctx_index = i;
    }
 
-   if (flags & PIPE_CONTEXT_PREFER_THREADED)
-      return threaded_context_create(&ctx->base,
+   if (flags & PIPE_CONTEXT_PREFER_THREADED) {
+      struct pipe_context *ret = threaded_context_create(&ctx->base,
          &screen->transfer_pool,
          d3d12_replace_buffer_storage,
          NULL,
          &ctx->threaded_context);
+      ctx->threaded_context->bytes_replaced_limit = 1024 * 1024 * 1024; /* 1GiB */
+      threaded_context_init_bytes_mapped_limit(ctx->threaded_context, 4);
+      return ret;
+   }
 
    return &ctx->base;
 }
diff --git a/src/gallium/drivers/d3d12/d3d12_residency.cpp b/src/gallium/drivers/d3d12/d3d12_residency.cpp
index c00e55e4014..f586522e4c5 100644
--- a/src/gallium/drivers/d3d12/d3d12_residency.cpp
+++ b/src/gallium/drivers/d3d12/d3d12_residency.cpp
@@ -228,10 +228,13 @@ d3d12_process_batch_residency(struct d3d12_screen *screen, struct d3d12_batch *b
                ++screen->residency_fence_value;
          }
 
-         if (SUCCEEDED(hr) && batch_count == residency_batch_size) {
+         if (SUCCEEDED(hr)) {
+            bool batch_full = batch_count == residency_batch_size;
             batch_count = 0;
             size_to_make_resident -= batch_memory_size;
-            continue;
+            batch_memory_size = 0;
+            if (batch_full)
+               continue;
          }
       }
 
diff --git a/src/gallium/drivers/etnaviv/etnaviv_compiler_nir_emit.c b/src/gallium/drivers/etnaviv/etnaviv_compiler_nir_emit.c
index 08a5ab5fb7b..708f0788b58 100644
--- a/src/gallium/drivers/etnaviv/etnaviv_compiler_nir_emit.c
+++ b/src/gallium/drivers/etnaviv/etnaviv_compiler_nir_emit.c
@@ -212,6 +212,10 @@ etna_emit_tex(struct etna_compile *c, nir_texop op, unsigned texid, unsigned dst
    case nir_texop_txb: inst.opcode = ISA_OPC_TEXLDB; break;
    case nir_texop_txd: inst.opcode = ISA_OPC_TEXLDD; break;
    case nir_texop_txl: inst.opcode = ISA_OPC_TEXLDL; break;
+   case nir_texop_txf:
+      inst.opcode = ISA_OPC_TXF;
+      inst.src[2] = etna_immediate_int(0x1100);
+      break;
    default:
       compile_error(c, "Unhandled NIR tex type: %d\n", op);
    }
diff --git a/src/gallium/drivers/etnaviv/etnaviv_ml.c b/src/gallium/drivers/etnaviv/etnaviv_ml.c
index febe0f0d87f..2b79bba3c0b 100644
--- a/src/gallium/drivers/etnaviv/etnaviv_ml.c
+++ b/src/gallium/drivers/etnaviv/etnaviv_ml.c
@@ -16,58 +16,73 @@
 #include "etnaviv_ml_tp.h"
 #include "etnaviv_ml.h"
 
-struct pipe_resource *
+struct etna_ml_tensor *
 etna_ml_get_tensor(struct etna_ml_subgraph *subgraph, unsigned idx)
 {
-   return *util_dynarray_element(&subgraph->tensors, struct pipe_resource *, idx);
+   struct etna_ml_tensor **tensor = util_dynarray_element(&subgraph->tensors, struct etna_ml_tensor*, idx);
+   if (*tensor == NULL)
+      *tensor = calloc(1, sizeof(**tensor));
+   return *tensor;
+}
+
+struct pipe_resource *
+etna_ml_get_resource(struct etna_ml_subgraph *subgraph, unsigned idx)
+{
+   return etna_ml_get_tensor(subgraph, idx)->resource;
 }
 
 unsigned
 etna_ml_get_offset(struct etna_ml_subgraph *subgraph, unsigned idx)
 {
-   return *util_dynarray_element(&subgraph->offsets, unsigned, idx);
+   return etna_ml_get_tensor(subgraph, idx)->offset;
 }
 
 unsigned
 etna_ml_get_size(struct etna_ml_subgraph *subgraph, unsigned idx)
 {
-   return *util_dynarray_element(&subgraph->sizes, unsigned, idx);
+   return etna_ml_get_tensor(subgraph, idx)->size;
+}
+
+static void
+etna_ml_copy_layout(struct etna_ml_subgraph *subgraph, unsigned idx, unsigned src_idx)
+{
+   struct etna_ml_tensor *dst = etna_ml_get_tensor(subgraph, idx);
+   struct etna_ml_tensor *src = etna_ml_get_tensor(subgraph, src_idx);
+   dst->exp_layout = src->exp_layout;
+   dst->act_layout = src->act_layout;
 }
 
 unsigned
 etna_ml_allocate_tensor(struct etna_ml_subgraph *subgraph)
 {
-   struct pipe_resource **tensors = util_dynarray_grow(&subgraph->tensors, struct pipe_resource *, 1);
-   tensors[0] = NULL;
+   struct etna_ml_tensor **tensors = util_dynarray_grow(&subgraph->tensors, struct etna_ml_tensor *, 1);
+   tensors[0] = calloc(1, sizeof(*tensors[0]));
+   tensors[0]->resource = NULL;
+   tensors[0]->offset = 0;
+   tensors[0]->size = 0;
 
-   unsigned *offsets = util_dynarray_grow(&subgraph->offsets, unsigned, 1);
-   offsets[0] = 0;
-
-   unsigned *sizes = util_dynarray_grow(&subgraph->sizes, unsigned, 1);
-   sizes[0] = 0;
-
-   return util_dynarray_num_elements(&subgraph->tensors, struct pipe_resource *) - 1;
+   return util_dynarray_num_elements(&subgraph->tensors, struct etna_ml_tensor *) - 1;
 }
 
-static void
+void
 etna_ml_create_tensor(struct etna_ml_subgraph *subgraph, unsigned idx, unsigned size)
 {
    struct pipe_context *context = subgraph->base.context;
-   struct pipe_resource **tensors = util_dynarray_begin(&subgraph->tensors);
-   unsigned *sizes = util_dynarray_begin(&subgraph->sizes);
+   struct etna_ml_tensor *tensor = etna_ml_get_tensor(subgraph, idx);
 
-   assert(idx < util_dynarray_num_elements(&subgraph->tensors, struct pipe_resource *));
+   assert(idx < util_dynarray_num_elements(&subgraph->tensors, struct etna_ml_tensor *));
+   assert(size > 0);
 
-   struct pipe_resource *res = tensors[idx];
+   struct pipe_resource *res = tensor->resource;
 
    if (res != NULL) {
-      assert(size == sizes[idx]);
+      assert(size == tensor->size);
       return;
    }
 
    res = etna_ml_create_resource(context, size);
-   tensors[idx] = res;
-   sizes[idx] = size;
+   tensor->resource = res;
+   tensor->size = size;
 
    ML_DBG("created resource %p for tensor %d with size %d\n", res, idx, size);
 }
@@ -75,13 +90,11 @@ etna_ml_create_tensor(struct etna_ml_subgraph *subgraph, unsigned idx, unsigned
 static void
 etna_ml_destroy_tensor(struct etna_ml_subgraph *subgraph, unsigned idx)
 {
-   struct pipe_resource **tensors = util_dynarray_begin(&subgraph->tensors);
-   unsigned *offsets = util_dynarray_begin(&subgraph->offsets);
-   unsigned *sizes = util_dynarray_begin(&subgraph->sizes);
+   struct etna_ml_tensor *tensor = etna_ml_get_tensor(subgraph, idx);
 
-   pipe_resource_reference(&tensors[idx], NULL);
-   offsets[idx] = 0;
-   sizes[idx] = 0;
+   pipe_resource_reference(&tensor->resource, NULL);
+   tensor->offset = 0;
+   tensor->size = 0;
 }
 
 struct etna_bo *
@@ -181,41 +194,6 @@ etna_ml_find_consumer(const struct pipe_ml_operation *poperations,
    return NULL;
 }
 
-static bool
-needs_transpose(const struct pipe_ml_operation *poperations,
-                unsigned count,
-                const struct pipe_ml_operation *poperation)
-{
-   const struct pipe_ml_operation *producer;
-
-   if (poperation->input_tensors[0]->dims[3] == 1)
-      return false;
-
-   producer = etna_ml_find_producer(poperations, count, poperation->input_tensors[0]->index);
-   if (!producer)
-      return true;
-
-   return false;
-}
-
-static bool
-needs_detranspose(const struct pipe_ml_operation *poperations,
-                  unsigned count,
-                  const struct pipe_ml_operation *poperation)
-{
-   const struct pipe_ml_operation *consumer;
-
-   if (poperation->output_tensors[0]->dims[3] == 1)
-      return false;
-
-   /* TODO: Support multiple consumers */
-   consumer = etna_ml_find_consumer(poperations, count, poperation->output_tensors[0]->index);
-   if (!consumer)
-      return true;
-
-   return false;
-}
-
 static void
 reference_tensor_with_offset(struct etna_ml_subgraph *subgraph,
                              unsigned src_tensor,
@@ -223,12 +201,47 @@ reference_tensor_with_offset(struct etna_ml_subgraph *subgraph,
                              unsigned offset,
                              unsigned size)
 {
-   struct pipe_resource **tensors = util_dynarray_begin(&subgraph->tensors);
-   unsigned *offsets = util_dynarray_begin(&subgraph->offsets);
-   unsigned *sizes = util_dynarray_begin(&subgraph->sizes);
-   pipe_resource_reference(&tensors[dst_tensor], tensors[src_tensor]);
-   offsets[dst_tensor] = offset;
-   sizes[dst_tensor] = size;
+   struct etna_ml_tensor *src = etna_ml_get_tensor(subgraph, src_tensor);
+   struct etna_ml_tensor *dst = etna_ml_get_tensor(subgraph, dst_tensor);
+   struct pipe_resource *old_res = dst->resource;
+   struct etna_ml_tensor **tensors = util_dynarray_begin(&subgraph->tensors);
+   unsigned num_tensors = util_dynarray_num_elements(&subgraph->tensors, struct etna_ml_tensor *);
+   ML_DBG("src_tensor %d (%x) dst_tensor %d offset %d size %d\n", src_tensor, etna_bo_gpu_va(etna_buffer_resource(src->resource)->bo), dst_tensor, offset, size);
+   pipe_resource_reference(&dst->resource, src->resource);
+   dst->offset = offset;
+   dst->size = size;
+
+   if (old_res) {
+      for (int i = 0; i < num_tensors; i++) {
+         if (etna_ml_get_resource(subgraph, i) == old_res) {
+            pipe_resource_reference(&tensors[i]->resource, src->resource);
+            tensors[i]->size = size;
+            tensors[i]->offset = offset;
+         }
+      }
+   }
+}
+
+static void
+recreate_tensor(struct etna_ml_subgraph *subgraph, unsigned idx, unsigned size)
+{
+   struct pipe_resource *old_res = etna_ml_get_resource(subgraph, idx);
+   struct etna_ml_tensor **tensors = util_dynarray_begin(&subgraph->tensors);
+   unsigned num_tensors = util_dynarray_num_elements(&subgraph->tensors, struct etna_ml_tensor *);
+   struct pipe_resource *new_res;
+
+   etna_ml_destroy_tensor(subgraph, idx);
+   etna_ml_create_tensor(subgraph, idx, size);
+   new_res = etna_ml_get_resource(subgraph, idx);
+
+   if (old_res) {
+      for (int i = 0; i < num_tensors; i++) {
+         if (etna_ml_get_resource(subgraph, i) == old_res) {
+            pipe_resource_reference(&tensors[i]->resource, new_res);
+            tensors[i]->size = size;
+         }
+      }
+   }
 }
 
 static void
@@ -266,6 +279,23 @@ dump_graph(struct list_head *etna_operations)
    ML_DBG("\n");
 }
 
+static bool
+is_3d(struct pipe_tensor *tensor)
+{
+   return tensor->dims[1] > 1 &&
+          tensor->dims[2] > 1 &&
+          tensor->dims[3] > 1;
+}
+
+/** Tensor layout inference:
+  * - Graph inputs are in NHWC order.
+  * - Graph outputs are expected in NHWC order.
+  * - Element-wise operations don't care about the layout.
+  * - Other operations expect the tensors in NCHW order (if input_channels > 1) and their outputs are in NCHW order.
+  * - Implicit transposes and detransposes are the only operations that change channel order.
+  * - Explicit transposes and detransposes are ignored.
+  */
+
 static void
 lower_operations(struct etna_ml_subgraph *subgraph,
                  const struct pipe_ml_operation *poperations,
@@ -274,77 +304,89 @@ lower_operations(struct etna_ml_subgraph *subgraph,
 {
    for (unsigned i = 0; i < count; i++) {
       const struct pipe_ml_operation *poperation = &poperations[i];
+      struct etna_operation *operation = calloc(1, sizeof(*operation));
+      assert(poperation->input_count <= MAX_TENSORS);
+      unsigned input_tensors[MAX_TENSORS] = {};
+
+      for (int i = 0; i < poperation->input_count; i++) {
+         struct etna_ml_tensor *tensor = etna_ml_get_tensor(subgraph, poperation->input_tensors[i]->index);
+         enum etna_ml_tensor_layout operation_layout = ETNA_ML_LAYOUT_ANY;
+
+         if (poperation->type == PIPE_ML_OPERATION_TYPE_CONVOLUTION ||
+             poperation->type == PIPE_ML_OPERATION_TYPE_FULLY_CONNECTED ||
+             poperation->type == PIPE_ML_OPERATION_TYPE_CONCATENATION)
+            operation_layout = ETNA_ML_LAYOUT_NCHW;
+
+         if (!etna_ml_find_producer(poperations, count, poperation->input_tensors[i]->index)) {
+            /* In TensorFlow Lite, graph inputs are in channel-last */
+            tensor->act_layout = ETNA_ML_LAYOUT_NHWC;
+            tensor->exp_layout = ETNA_ML_LAYOUT_NHWC;
+         }
 
-      switch(poperation->type) {
-         case PIPE_ML_OPERATION_TYPE_CONVOLUTION: {
-            unsigned input_tensor = poperation->input_tensors[0]->index;
+         input_tensors[i] = poperation->input_tensors[i]->index;
 
-            if (needs_transpose(poperations, count, poperation)) {
-               ML_DBG("Adding transpose for convolution operation.\n");
-               struct etna_operation *operation = calloc(1, sizeof(*operation));
-               etna_ml_lower_transpose(subgraph, poperation->input_tensors[0], operation, &input_tensor);
-               list_addtail(&operation->link, etna_operations);
-            }
+         if (poperation->input_tensors[i]->resource != NULL)
+            continue;
+
+         if (operation_layout != ETNA_ML_LAYOUT_ANY &&
+             tensor->act_layout != operation_layout) {
+            ML_DBG("Adding transpose.\n");
+            struct etna_operation *transpose = calloc(1, sizeof(*transpose));
+            etna_ml_lower_transpose(subgraph, poperation->input_tensors[i], transpose);
+            transpose->input_tensors[0] = input_tensors[i];
+            transpose->output_tensors[0] = etna_ml_allocate_tensor(subgraph);
+            input_tensors[i] = transpose->output_tensors[0];
+            list_addtail(&transpose->link, etna_operations);
+
+            struct etna_ml_tensor *transposed_tensor = etna_ml_get_tensor(subgraph, input_tensors[i]);
+            transposed_tensor->exp_layout = tensor->exp_layout;
+            transposed_tensor->act_layout = operation_layout;
+         }
+
+         struct etna_ml_tensor *tensor2 = etna_ml_get_tensor(subgraph, input_tensors[i]);
+         ML_DBG("operation %d input tensor %d layouts %d %d.\n", poperation->type, input_tensors[i], tensor2->exp_layout, tensor2->act_layout);
+      }
 
+      switch(poperation->type) {
+         case PIPE_ML_OPERATION_TYPE_CONVOLUTION: {
             if (needs_reshuffle(subgraph, poperation)) {
                ML_DBG("Adding reshuffle for convolution operation.\n");
-               struct etna_operation *operation = calloc(1, sizeof(*operation));
-               unsigned temp = 0;
-               etna_ml_lower_reshuffle(subgraph, poperation, operation, &temp);
-               operation->input_tensors[0] = input_tensor;
-               input_tensor = temp;
-               list_addtail(&operation->link, etna_operations);
+               struct etna_operation *reshuffle = calloc(1, sizeof(*reshuffle));
+               etna_ml_lower_reshuffle(subgraph, poperation, reshuffle);
+               reshuffle->input_tensors[0] = input_tensors[0];
+               reshuffle->output_tensors[0] = etna_ml_allocate_tensor(subgraph);
+               input_tensors[0] = reshuffle->output_tensors[0];
+               list_addtail(&reshuffle->link, etna_operations);
+               etna_ml_copy_layout(subgraph, reshuffle->output_tensors[0], reshuffle->input_tensors[0]);
             }
 
             ML_DBG("Adding convolution.\n");
-            struct etna_operation *operation = calloc(1, sizeof(*operation));
             etna_ml_lower_convolution(subgraph, poperation, operation);
-            operation->input_tensors[0] = input_tensor;
+            operation->input_tensors[0] = input_tensors[0];
+            operation->output_tensors[0] = poperation->output_tensors[0]->index;
+            input_tensors[0] = operation->output_tensors[0];
             list_addtail(&operation->link, etna_operations);
+            etna_ml_copy_layout(subgraph, operation->output_tensors[0], operation->input_tensors[0]);
 
-            if (needs_detranspose(poperations, count, poperation)) {
-               ML_DBG("Adding detranspose for convolution operation.\n");
-               struct etna_operation *detranspose = calloc(1, sizeof(*operation));
-               etna_ml_lower_detranspose(subgraph, operation, detranspose);
-               operation->output_tensors[0] = detranspose->input_tensors[0];
-               list_addtail(&detranspose->link, etna_operations);
-            }
             break;
          }
          case PIPE_ML_OPERATION_TYPE_ADD: {
-            struct etna_operation *operation = calloc(1, sizeof(*operation));
             etna_ml_lower_add(subgraph, poperation, operation);
+            operation->input_tensors[0] = input_tensors[0];
+            operation->input_tensors[1] = input_tensors[1];
+            operation->output_tensors[0] = poperation->output_tensors[0]->index;
             list_addtail(&operation->link, etna_operations);
 
-            if (needs_detranspose(poperations, count, poperation)) {
-               struct etna_operation *detranspose = calloc(1, sizeof(*operation));
-               etna_ml_lower_detranspose(subgraph, operation, detranspose);
-               operation->output_tensors[0] = detranspose->input_tensors[0];
-               list_addtail(&detranspose->link, etna_operations);
-            }
             break;
          }
          case PIPE_ML_OPERATION_TYPE_CONCATENATION: {
-            bool do_transpose = needs_transpose(poperations, count, poperation);
-
-            struct etna_operation *operation = calloc(1, sizeof(*operation));
             operation->type = ETNA_JOB_TYPE_CONCAT;
             assert(poperation->input_count <= MAX_TENSORS);
-            unsigned input_size = 0;
             for (int i = 0; i < poperation->input_count; i++) {
-               unsigned input_tensor = poperation->input_tensors[i]->index;
-
-               if (do_transpose) {
-                  struct etna_operation *operation = calloc(1, sizeof(*operation));
-                  etna_ml_lower_transpose(subgraph, poperation->input_tensors[i], operation, &input_tensor);
-                  list_addtail(&operation->link, etna_operations);
-               }
-
-               operation->input_tensors[i] = input_tensor;
+               operation->input_tensors[i] = input_tensors[i];
                operation->input_tensor_sizes[i] = poperation->input_tensors[i]->dims[1] *
                                                   poperation->input_tensors[i]->dims[2] *
                                                   poperation->input_tensors[i]->dims[3];
-               input_size += input_size;
             }
             operation->input_count = poperation->input_count;
 
@@ -358,17 +400,9 @@ lower_operations(struct etna_ml_subgraph *subgraph,
 
             list_addtail(&operation->link, etna_operations);
 
-            if (needs_detranspose(poperations, count, poperation)) {
-               struct etna_operation *detranspose = calloc(1, sizeof(*operation));
-               etna_ml_lower_detranspose(subgraph, operation, detranspose);
-               operation->output_tensors[0] = detranspose->input_tensors[0];
-               list_addtail(&detranspose->link, etna_operations);
-            }
-
             break;
          }
          case PIPE_ML_OPERATION_TYPE_SPLIT: {
-            struct etna_operation *operation = calloc(1, sizeof(*operation));
             operation->type = ETNA_JOB_TYPE_SPLIT;
 
             operation->input_tensors[0] = poperation->input_tensors[1]->index;
@@ -390,38 +424,45 @@ lower_operations(struct etna_ml_subgraph *subgraph,
             break;
          }
          case PIPE_ML_OPERATION_TYPE_PAD: {
-            unsigned input_tensor = poperation->input_tensors[0]->index;
-
-            if (needs_transpose(poperations, count, poperation)) {
-               struct etna_operation *operation = calloc(1, sizeof(*operation));
-               etna_ml_lower_transpose(subgraph, poperation->input_tensors[0], operation, &input_tensor);
-               list_addtail(&operation->link, etna_operations);
-            }
-
             ML_DBG("Adding pad operation.\n");
-            struct etna_operation *operation = calloc(1, sizeof(*operation));
             etna_ml_lower_pad(subgraph, poperation, operation);
-            operation->input_tensors[0] = input_tensor;
+            operation->input_tensors[0] = input_tensors[0];
+            operation->output_tensors[0] = poperation->output_tensors[0]->index;
             list_addtail(&operation->link, etna_operations);
-
-            if (needs_detranspose(poperations, count, poperation)) {
-               struct etna_operation *detranspose = calloc(1, sizeof(*operation));
-               etna_ml_lower_detranspose(subgraph, operation, detranspose);
-               operation->output_tensors[0] = detranspose->input_tensors[0];
-               list_addtail(&detranspose->link, etna_operations);
-            }
-
             break;
          }
          case PIPE_ML_OPERATION_TYPE_FULLY_CONNECTED: {
-            struct etna_operation *operation = calloc(1, sizeof(*operation));
             etna_ml_lower_fully_connected(subgraph, poperation, operation);
+            operation->input_tensors[0] = input_tensors[0];
+            operation->output_tensors[0] = poperation->output_tensors[0]->index;
             list_addtail(&operation->link, etna_operations);
             break;
          }
          default:
             unreachable("Unsupported ML operation type");
       }
+
+      for (int i = 0; i < poperation->output_count; i++) {
+         struct etna_ml_tensor *tensor = etna_ml_get_tensor(subgraph, poperation->output_tensors[i]->index);
+         if (tensor->exp_layout == ETNA_ML_LAYOUT_ANY &&
+             tensor->act_layout == ETNA_ML_LAYOUT_ANY) {
+            ML_DBG("Copying layout to output tensor %d.\n", poperation->output_tensors[i]->index);
+            etna_ml_copy_layout(subgraph, poperation->output_tensors[i]->index, operation->input_tensors[0]);
+         }
+
+         ML_DBG("type %d i %d tensor %d layout %d == %d\n", poperation->type, i, poperation->output_tensors[i]->index, tensor->exp_layout, tensor->act_layout);
+         if (!etna_ml_find_consumer(poperations, count, poperation->output_tensors[i]->index) &&
+             is_3d(poperation->output_tensors[i]) &&
+             tensor->exp_layout != tensor->act_layout) {
+            ML_DBG("Adding detranspose.\n");
+            struct etna_operation *detranspose = calloc(1, sizeof(*detranspose));
+            etna_ml_lower_detranspose(subgraph, poperation->output_tensors[i], detranspose);
+            operation->output_tensors[i] = etna_ml_allocate_tensor(subgraph);
+            detranspose->input_tensors[0] = operation->output_tensors[i];
+            detranspose->output_tensors[0] = poperation->output_tensors[i]->index;
+            list_addtail(&detranspose->link, etna_operations);
+         }
+      }
    }
 
    list_for_each_entry(struct etna_operation, operation, etna_operations, link) {
@@ -449,17 +490,17 @@ lower_operations(struct etna_ml_subgraph *subgraph,
                                          operation->output_tensor_sizes[i]);
             offset += operation->output_tensor_sizes[i];
          }
-      } else if (operation->type == ETNA_JOB_TYPE_NN && operation->input_count > 1) { /* Add */
-         etna_ml_destroy_tensor(subgraph, operation->input_tensors[0]);
-         etna_ml_create_tensor(subgraph, operation->input_tensors[0], operation->input_tensor_sizes[0] +
-                                                                      operation->input_tensor_sizes[1]);
+      } else if (operation->type == ETNA_JOB_TYPE_NN && operation->input_count > 1) { /* Add or Subtraction */
+         recreate_tensor(subgraph, operation->input_tensors[0], operation->input_tensor_sizes[0] +
+                                                                        operation->input_tensor_sizes[1]);
          reference_tensor_with_offset(subgraph,
                                       operation->input_tensors[0],
                                       operation->input_tensors[1],
                                       operation->input_tensor_sizes[0],
                                       operation->input_tensor_sizes[1]);
       } else {
-         etna_ml_create_tensor(subgraph, operation->input_tensors[0], operation->input_tensor_sizes[0]);
+         for (int i = 0; i < operation->input_count; i++)
+            etna_ml_create_tensor(subgraph, operation->input_tensors[i], operation->input_tensor_sizes[i]);
       }
    }
 
@@ -468,7 +509,7 @@ lower_operations(struct etna_ml_subgraph *subgraph,
     */
    ML_DBG("Ensuring all output tensors have their memory backing.\n");
    list_for_each_entry(struct etna_operation, operation, etna_operations, link) {
-      struct pipe_resource *res = etna_ml_get_tensor(subgraph, operation->output_tensors[0]);
+      struct pipe_resource *res = etna_ml_get_resource(subgraph, operation->output_tensors[0]);
       if (res != NULL)
          continue;
 
@@ -541,20 +582,10 @@ etna_ml_subgraph_create(struct pipe_context *pcontext,
    util_dynarray_init(&subgraph->operations, NULL);
 
    util_dynarray_init(&subgraph->tensors, NULL);
-   if (!util_dynarray_resize(&subgraph->tensors, struct pipe_resource *, tensor_count))
+   if (!util_dynarray_resize(&subgraph->tensors, struct etna_ml_tensor*, tensor_count))
       return NULL;
    memset(util_dynarray_begin(&subgraph->tensors), 0, subgraph->tensors.size);
 
-   util_dynarray_init(&subgraph->offsets, NULL);
-   if (!util_dynarray_resize(&subgraph->offsets, unsigned, tensor_count))
-      return NULL;
-   memset(util_dynarray_begin(&subgraph->offsets), 0, subgraph->offsets.size);
-
-   util_dynarray_init(&subgraph->sizes, NULL);
-   if (!util_dynarray_resize(&subgraph->sizes, unsigned, tensor_count))
-      return NULL;
-   memset(util_dynarray_begin(&subgraph->sizes), 0, subgraph->sizes.size);
-
    lower_operations(subgraph, poperations, count, &operations);
 
    list_for_each_entry(struct etna_operation, operation, &operations, link) {
@@ -665,8 +696,6 @@ etna_ml_subgraph_invoke(struct pipe_context *pctx, struct pipe_ml_subgraph *psub
    struct etna_context *ctx = etna_context(pctx);
    unsigned tp_core_count = etna_ml_get_core_info(ctx)->tp_core_count;
    struct etna_ml_subgraph *subgraph = (struct etna_ml_subgraph *)(psubgraph);
-   unsigned *offsets = util_dynarray_begin(&subgraph->offsets);
-   unsigned *sizes = util_dynarray_begin(&subgraph->sizes);
    struct etna_cmd_stream *stream = ctx->stream;
    static bool is_initialized = false;
 
@@ -688,26 +717,31 @@ etna_ml_subgraph_invoke(struct pipe_context *pctx, struct pipe_ml_subgraph *psub
    }
 
    for (int i = 0; i < inputs_count; i++) {
-      struct pipe_resource *res = etna_ml_get_tensor(subgraph, input_idxs[i]);
+      struct etna_ml_tensor *tensor = etna_ml_get_tensor(subgraph, input_idxs[i]);
       if (is_signed[i]) {
          struct pipe_transfer *dst_transfer;
          const uint8_t *src = inputs[i];
          uint8_t *dst_map;
-         dst_map = pipe_buffer_map_range(pctx, res, 0, sizes[input_idxs[i]], PIPE_MAP_WRITE, &dst_transfer);
+         dst_map = pipe_buffer_map_range(pctx, tensor->resource, tensor->offset, tensor->size, PIPE_MAP_WRITE, &dst_transfer);
          assert(dst_map);
-         for (unsigned k = 0; k < sizes[input_idxs[i]]; k++) {
+         for (unsigned k = 0; k < tensor->size; k++) {
             dst_map[k] = src[k] + 128;
          }
          pipe_buffer_unmap(pctx, dst_transfer);
       } else {
-         pipe_buffer_write(pctx, res, offsets[input_idxs[i]], sizes[input_idxs[i]], inputs[i]);
+         pipe_buffer_write(pctx, tensor->resource, tensor->offset, tensor->size, inputs[i]);
       }
    }
 
-   unsigned i = 0;
+   static unsigned i = 0;
    util_dynarray_foreach(&subgraph->operations, struct etna_vip_instruction, operation) {
 
       if (DBG_ENABLED(ETNA_DBG_DUMP_SHADERS)) {
+         struct pipe_transfer *transfer = NULL;
+         pipe_buffer_map(pctx, operation->input, PIPE_MAP_READ, &transfer);
+         dump_bo(etna_buffer_resource(operation->input)->bo, "input", i, 0, operation->input_offset, 0);
+         pipe_buffer_unmap(pctx, transfer);
+
          switch (operation->type) {
             case ETNA_JOB_TYPE_TP:
                for (unsigned j = 0; j < tp_core_count && operation->configs[j]; j++) {
@@ -765,10 +799,6 @@ etna_ml_subgraph_invoke(struct pipe_context *pctx, struct pipe_ml_subgraph *psub
          if (DBG_ENABLED(ETNA_DBG_DUMP_SHADERS)) {
             struct pipe_transfer *transfer = NULL;
 
-            pipe_buffer_map(pctx, operation->input, PIPE_MAP_READ, &transfer);
-            dump_bo(etna_buffer_resource(operation->input)->bo, "input", i, 0, operation->input_offset, 0);
-            pipe_buffer_unmap(pctx, transfer);
-
             pipe_buffer_map(pctx, operation->output, PIPE_MAP_READ, &transfer);
             dump_bo(etna_buffer_resource(operation->output)->bo, "output", i, 0, operation->output_offset, 0);
             pipe_buffer_unmap(pctx, transfer);
@@ -796,31 +826,33 @@ etna_ml_subgraph_read_outputs(struct pipe_context *context, struct pipe_ml_subgr
    unsigned operation_count = util_dynarray_num_elements(&subgraph->operations, struct etna_vip_instruction);
    struct etna_vip_instruction *last_operation;
 
-   last_operation = util_dynarray_element(&subgraph->operations,
-                                          struct etna_vip_instruction,
-                                          operation_count - 1);
+   if (operation_count > 0) {
+      last_operation = util_dynarray_element(&subgraph->operations,
+                                             struct etna_vip_instruction,
+                                             operation_count - 1);
 
-   if (DBG_ENABLED(ETNA_DBG_ML_MSGS)) {
-      long start, end;
-      struct timespec time;
+      if (DBG_ENABLED(ETNA_DBG_ML_MSGS)) {
+         long start, end;
+         struct timespec time;
 
-      clock_gettime(CLOCK_MONOTONIC, &time);
-      start = (long)time.tv_sec * 1000 + (long)time.tv_nsec / 1000000;
+         clock_gettime(CLOCK_MONOTONIC, &time);
+         start = (long)time.tv_sec * 1000 + (long)time.tv_nsec / 1000000;
 
-      context->flush(context, NULL, 0);
+         context->flush(context, NULL, 0);
 
-      struct pipe_transfer *transfer = NULL;
-      pipe_buffer_map(context, last_operation->output, PIPE_MAP_READ, &transfer);
-      pipe_buffer_unmap(context, transfer);
+         struct pipe_transfer *transfer = NULL;
+         pipe_buffer_map(context, last_operation->output, PIPE_MAP_READ, &transfer);
+         pipe_buffer_unmap(context, transfer);
 
-      clock_gettime(CLOCK_MONOTONIC, &time);
-      end = (long)time.tv_sec * 1000 + (long)time.tv_nsec / 1000000;
-      ML_DBG("Running the NN job took %ld ms.\n", (end - start));
-   } else
-      context->flush(context, NULL, 0);
+         clock_gettime(CLOCK_MONOTONIC, &time);
+         end = (long)time.tv_sec * 1000 + (long)time.tv_nsec / 1000000;
+         ML_DBG("Running the NN job took %ld ms.\n", (end - start));
+      } else
+         context->flush(context, NULL, 0);
+   }
 
    for (int i = 0; i < outputs_count; i++) {
-      struct pipe_resource *res = etna_ml_get_tensor(subgraph, output_idxs[i]);
+      struct pipe_resource *res = etna_ml_get_resource(subgraph, output_idxs[i]);
       if (is_signed[i]) {
          struct pipe_transfer *src_transfer;
          uint8_t *src_map;
@@ -854,12 +886,13 @@ etna_ml_subgraph_destroy(struct pipe_context *context, struct pipe_ml_subgraph *
    }
    util_dynarray_fini(&subgraph->operations);
 
-   util_dynarray_foreach(&subgraph->tensors, struct pipe_resource *, tensor) {
-      pipe_resource_reference(tensor, NULL);
+   util_dynarray_foreach(&subgraph->tensors, struct etna_ml_tensor*, tensor) {
+      if (!*tensor)
+         continue;
+      pipe_resource_reference(&(*tensor)->resource, NULL);
+      free(*tensor);
    }
    util_dynarray_fini(&subgraph->tensors);
-   util_dynarray_fini(&subgraph->offsets);
-   util_dynarray_fini(&subgraph->sizes);
 
    free(subgraph);
 }
diff --git a/src/gallium/drivers/etnaviv/etnaviv_ml.h b/src/gallium/drivers/etnaviv/etnaviv_ml.h
index 69422990b47..db69371ad90 100644
--- a/src/gallium/drivers/etnaviv/etnaviv_ml.h
+++ b/src/gallium/drivers/etnaviv/etnaviv_ml.h
@@ -36,15 +36,27 @@ enum etna_ml_tp_type {
    ETNA_ML_TP_PAD,
 };
 
+enum etna_ml_tensor_layout {
+   ETNA_ML_LAYOUT_ANY = 0,
+   ETNA_ML_LAYOUT_NHWC,
+   ETNA_ML_LAYOUT_NCHW,
+};
+
+struct etna_ml_tensor {
+   struct pipe_resource *resource;
+   unsigned offset;
+   unsigned size;
+   enum etna_ml_tensor_layout exp_layout; /* expected */
+   enum etna_ml_tensor_layout act_layout; /* actual */
+};
+
 struct etna_ml_subgraph {
    struct pipe_ml_subgraph base;
 
    struct util_dynarray operations;
 
-   /* The three are indexed by tensor index */
-   struct util_dynarray tensors; /* Contains struct pipe_resource* */
-   struct util_dynarray offsets; /* These are integers */
-   struct util_dynarray sizes; /* These are integers */
+   /* Indexed by tensor index */
+   struct util_dynarray tensors; /* Contains struct etna_ml_tensor */
 };
 
 struct etna_vip_instruction {
@@ -110,6 +122,13 @@ struct etna_operation {
    uint8_t addition_offset;
 
    struct pipe_resource *bias_tensor;
+
+   unsigned pad_before_x;
+   unsigned pad_after_x;
+   unsigned pad_before_y;
+   unsigned pad_after_y;
+   unsigned pad_before_z;
+   unsigned pad_after_z;
 };
 
 #define ML_DBG(fmt, ...)                                  \
@@ -119,7 +138,9 @@ struct etna_operation {
    } while (0)
 
 unsigned etna_ml_allocate_tensor(struct etna_ml_subgraph *subgraph);
-struct pipe_resource *etna_ml_get_tensor(struct etna_ml_subgraph *subgraph, unsigned idx);
+void etna_ml_create_tensor(struct etna_ml_subgraph *subgraph, unsigned idx, unsigned size);
+struct etna_ml_tensor *etna_ml_get_tensor(struct etna_ml_subgraph *subgraph, unsigned idx);
+struct pipe_resource *etna_ml_get_resource(struct etna_ml_subgraph *subgraph, unsigned idx);
 unsigned etna_ml_get_offset(struct etna_ml_subgraph *subgraph, unsigned idx);
 unsigned etna_ml_get_size(struct etna_ml_subgraph *subgraph, unsigned idx);
 
diff --git a/src/gallium/drivers/etnaviv/etnaviv_ml_nn.c b/src/gallium/drivers/etnaviv/etnaviv_ml_nn.c
index 67ebd2ee6b7..13afb3c2756 100644
--- a/src/gallium/drivers/etnaviv/etnaviv_ml_nn.c
+++ b/src/gallium/drivers/etnaviv/etnaviv_ml_nn.c
@@ -4,6 +4,7 @@
  */
 
 #include "pipe/p_state.h"
+#include "util/macros.h"
 #include "util/u_inlines.h"
 
 #include "etnaviv_context.h"
@@ -185,6 +186,119 @@ map_resource(struct pipe_resource *resource)
    return etna_bo_map(etna_buffer_resource(resource)->bo);
 }
 
+static void
+calc_quant_params(float min, float max, float *out_scale, uint8_t *out_zero_point)
+{
+   if (max < min)
+      SWAP(max, min);
+
+   float diff = max - MIN2(min, 0.0);
+   *out_scale = diff / 255.0f;
+   *out_zero_point = round(-(min / *out_scale));
+}
+
+static void
+calc_quantization(struct etna_ml_subgraph *subgraph, const struct pipe_ml_operation *poperation,
+                  struct etna_operation *operation, float *out_scale, uint8_t *out_zero_point)
+{
+   const struct pipe_tensor *weight_tensor = poperation->conv.weight_tensor;
+   void *map = map_resource(operation->weight_tensor);
+   unsigned input_channels = operation->input_channels;
+
+   if (poperation->conv.depthwise)
+      input_channels = 1;
+
+   uint8_t (*weights)[operation->weight_width][operation->weight_height][input_channels] = map;
+
+   float max = .0, min = FLT_MAX;
+   for (unsigned oc = 0; oc < operation->output_channels; oc++) {
+      for (unsigned w = 0; w < operation->weight_width; w++) {
+         for (unsigned h = 0; h < operation->weight_height; h++) {
+            for (unsigned ic = 0; ic < input_channels; ic++) {
+               float dequant;
+               if (operation->weight_signed) {
+                  int8_t val = weights[oc][w][h][ic];
+                  dequant = weight_tensor->scales[oc] * (val - weight_tensor->zero_points[oc]);
+               } else {
+                  uint8_t val = weights[oc][w][h][ic];
+                  dequant = weight_tensor->scales[oc] * (val - weight_tensor->zero_points[oc]);
+               }
+               max = MAX2(max, dequant);
+               min = MIN2(min, dequant);
+            }
+         }
+      }
+   }
+
+   calc_quant_params(min, max, out_scale, out_zero_point);
+}
+
+static void
+requantize_weights(struct etna_ml_subgraph *subgraph,
+                   const struct pipe_ml_operation *poperation,
+                   struct etna_operation *operation)
+{
+   const struct pipe_tensor *weight_tensor = poperation->conv.weight_tensor;
+   struct pipe_context *context = subgraph->base.context;
+   void *input = map_resource(operation->weight_tensor);
+   unsigned input_channels = operation->input_channels;
+
+   if (poperation->conv.depthwise)
+      input_channels = 1;
+
+   unsigned new_size = operation->output_channels * operation->weight_width * operation->weight_height * input_channels;
+   struct pipe_resource *output_res = etna_ml_create_resource(context, new_size);
+   void *output = map_resource(output_res);
+   uint8_t (*map_in)[operation->weight_width][operation->weight_height][input_channels] = input;
+   uint8_t (*map_out)[operation->weight_width][operation->weight_height][input_channels] = output;
+
+   for (unsigned oc = 0; oc < operation->output_channels; oc++) {
+      for (unsigned w = 0; w < operation->weight_width; w++) {
+         for (unsigned h = 0; h < operation->weight_height; h++) {
+            for (unsigned ic = 0; ic < input_channels; ic++) {
+               if (operation->weight_signed) {
+                  int8_t val = map_in[oc][w][h][ic];
+                  double dequantized = weight_tensor->scales[oc] * (val - weight_tensor->zero_points[oc]);
+                  int8_t requantized = round(dequantized / operation->weight_scale);
+                  map_out[oc][w][h][ic] = requantized + operation->weight_zero_point - 0x80;
+               } else {
+                  uint8_t val = map_in[oc][w][h][ic];
+                  double dequantized = weight_tensor->scales[oc] * (val - weight_tensor->zero_points[oc]);
+                  uint8_t requantized = round(dequantized / operation->weight_scale);
+                  map_out[oc][w][h][ic] = requantized + operation->weight_zero_point;
+               }
+            }
+         }
+      }
+   }
+
+   pipe_resource_reference(&operation->weight_tensor, NULL);
+   operation->weight_tensor = output_res;
+}
+
+static void
+requantize_bias(struct etna_ml_subgraph *subgraph,
+                const struct pipe_ml_operation *poperation,
+                struct etna_operation *operation)
+{
+   const struct pipe_tensor *bias_tensor = poperation->conv.bias_tensor;
+   struct pipe_context *context = subgraph->base.context;
+   uint32_t *input = map_resource(operation->bias_tensor);
+   unsigned new_size = operation->output_channels * sizeof(*input);
+   struct pipe_resource *output_res = etna_ml_create_resource(context, new_size);
+   uint32_t *output = map_resource(output_res);
+   float bias_scale = operation->weight_scale * operation->input_scale;
+
+   for (unsigned oc = 0; oc < operation->output_channels; oc++) {
+      int32_t quantized = input[oc];
+      double dequantized = bias_tensor->scales[oc] * quantized;
+      int32_t requantized = round(dequantized / bias_scale);
+      output[oc] = requantized;
+   }
+
+   pipe_resource_reference(&operation->bias_tensor, NULL);
+   operation->bias_tensor = output_res;
+}
 
 static void
 pointwise_to_2x2(struct etna_ml_subgraph *subgraph, struct etna_operation *operation)
@@ -467,7 +581,6 @@ etna_ml_lower_convolution(struct etna_ml_subgraph *subgraph,
    operation->padding_same = poperation->conv.padding_same;
    operation->stride = poperation->conv.stride_x;
 
-   operation->input_tensors[0] = poperation->input_tensors[0]->index;
    operation->input_count = 1;
    operation->input_width = poperation->input_tensors[0]->dims[1];
    operation->input_height = poperation->input_tensors[0]->dims[2];
@@ -475,7 +588,7 @@ etna_ml_lower_convolution(struct etna_ml_subgraph *subgraph,
    operation->input_zero_point = etna_tensor_zero_point(poperation->input_tensors[0]);
    operation->input_scale = poperation->input_tensors[0]->scale;
 
-   operation->output_tensors[0] = poperation->output_tensors[0]->index;
+   operation->output_count = 1;
    operation->output_width = poperation->output_tensors[0]->dims[1];
    operation->output_height = poperation->output_tensors[0]->dims[2];
    operation->output_channels = poperation->output_tensors[0]->dims[3];
@@ -495,12 +608,15 @@ etna_ml_lower_convolution(struct etna_ml_subgraph *subgraph,
       pointwise_to_2x2(subgraph, operation);
 
    if (operation->depthwise) {
-      if (nn_core_version < 8 && (operation->output_channels > 1 || operation->stride > 1)) {
-         if (operation->input_width < 8 && operation->input_width > 2)
-            operation->pooling_first_pixel = false;
-         expand_depthwise(subgraph, operation);
-      } else if (operation->output_channels > 1)
+      if (nn_core_version < 8) {
+         if (operation->output_channels > 1 || operation->stride > 1) {
+            if (operation->input_width < 8 && operation->input_width > 2)
+               operation->pooling_first_pixel = false;
+            expand_depthwise(subgraph, operation);
+         }
+      } else if (operation->output_channels > 1) {
          reorder_for_hw_depthwise(subgraph, operation);
+      }
    }
 
    if (operation->stride > 1 && !operation->pooling_first_pixel)
@@ -511,11 +627,31 @@ etna_ml_lower_convolution(struct etna_ml_subgraph *subgraph,
    operation->input_tensor_sizes[0] = operation->input_width *
                                       operation->input_height *
                                       operation->input_channels;
-   ML_DBG("%dx%dx%d\n", operation->input_width, operation->input_height, operation->input_channels);
 
    operation->output_tensor_sizes[0] = operation->output_width *
                                        operation->output_height *
                                        operation->output_channels;
+
+   if (poperation->conv.weight_tensor->scales) {
+      float scale;
+      uint8_t zero_point;
+
+      assert(poperation->conv.weight_tensor->zero_points);
+
+      ML_DBG("\nWARNING: The weights in this model are quantized using a per-channel scheme.\n"
+             "The hardware doesn't support it natively, so it will be workarounded by requantizing\n"
+             "on the fly, with a loss of accuracy. It is recommended to quantize the model with the\n"
+             "per-tensor scheme. See https://ai.google.dev/edge/litert/models/quantization_spec.\n\n");
+
+      calc_quantization(subgraph, poperation, operation, &scale, &zero_point);
+      operation->weight_scale = scale;
+      operation->weight_zero_point = zero_point;
+      requantize_weights(subgraph, poperation, operation);
+      requantize_bias(subgraph, poperation, operation);
+
+      if (nn_core_version >= 8 && poperation->conv.depthwise)
+         operation->input_channels = 1;
+   }
 }
 
 static float
@@ -555,14 +691,13 @@ compute_bias_add(float input1_scale, float input2_scale, uint8_t input1_zp, uint
    return (int) (round(bias) - round(addition_offset) * input2_zp);
 }
 
-void
-etna_ml_lower_add(struct etna_ml_subgraph *subgraph,
-                  const struct pipe_ml_operation *poperation,
-                  struct etna_operation *operation)
+
+static void
+etna_ml_lower_add_v7(struct etna_ml_subgraph *subgraph,
+                     const struct pipe_ml_operation *poperation,
+                     struct etna_operation *operation)
 {
    struct pipe_context *context = subgraph->base.context;
-   struct etna_context *ctx = etna_context(context);
-   unsigned nn_core_version = ctx->screen->specs.nn_core_version;
 
    assert(poperation->type == PIPE_ML_OPERATION_TYPE_ADD);
 
@@ -574,23 +709,21 @@ etna_ml_lower_add(struct etna_ml_subgraph *subgraph,
    operation->padding_same = false;
    operation->stride = 1;
 
+   operation->input_count = 2;
    operation->input_width = poperation->input_tensors[0]->dims[1];
    operation->input_height = poperation->input_tensors[0]->dims[2];
    operation->input_channels = poperation->input_tensors[0]->dims[3];
    operation->input_zero_point = etna_tensor_zero_point(poperation->input_tensors[0]);
    operation->input_scale = poperation->input_tensors[0]->scale;
 
-   operation->input_tensors[0] = poperation->input_tensors[0]->index;
    operation->input_tensor_sizes[0] = operation->input_width *
                                       operation->input_height *
                                       operation->input_channels;
-   operation->input_tensors[1] = poperation->input_tensors[1]->index;
    operation->input_tensor_sizes[1] = operation->input_width *
                                       operation->input_height *
                                       operation->input_channels;
-   operation->input_count = 2;
 
-   operation->output_tensors[0] = poperation->output_tensors[0]->index;
+   operation->output_count = 1;
    operation->output_width = poperation->output_tensors[0]->dims[1];
    operation->output_height = poperation->output_tensors[0]->dims[2];
    operation->output_channels = poperation->output_tensors[0]->dims[3];
@@ -601,59 +734,151 @@ etna_ml_lower_add(struct etna_ml_subgraph *subgraph,
                                        operation->output_height *
                                        operation->output_channels;
 
-   if (nn_core_version < 8) {
-      operation->weight_tensor = etna_ml_create_resource(context, 8);
-      operation->weight_width = 2;
-      operation->weight_height = 2;
-      operation->weight_zero_point = 0x0;
-      operation->weight_scale = compute_weight_scale_add(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale);
-      operation->weight_signed = false;
-      operation->addition_offset = compute_addition_offset(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale, operation->weight_scale);
-
-      uint8_t *weight_map = map_resource(operation->weight_tensor);
-      weight_map[0] = compute_weight_add(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale, operation->weight_scale);
-
-      operation->bias_tensor = etna_ml_create_resource(context, 4);
-      int32_t *bias_map = map_resource(operation->bias_tensor);
-      bias_map[0] = compute_bias_add(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale,
-                                    poperation->input_tensors[1]->zero_point, poperation->input_tensors[0]->zero_point,
-                                    operation->weight_scale);
+   operation->weight_tensor = etna_ml_create_resource(context, 8);
+   operation->weight_width = 2;
+   operation->weight_height = 2;
+   operation->weight_zero_point = 0x0;
+   operation->weight_scale = compute_weight_scale_add(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale);
+   operation->weight_signed = false;
+   operation->addition_offset = compute_addition_offset(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale, operation->weight_scale);
+
+   uint8_t *weight_map = map_resource(operation->weight_tensor);
+   weight_map[0] = compute_weight_add(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale, operation->weight_scale);
+
+   operation->bias_tensor = etna_ml_create_resource(context, 4);
+   int32_t *bias_map = map_resource(operation->bias_tensor);
+   bias_map[0] = compute_bias_add(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale,
+                                  poperation->input_tensors[1]->zero_point, poperation->input_tensors[0]->zero_point,
+                                  operation->weight_scale);
+}
+
+static void
+etna_ml_lower_add_v8(struct etna_ml_subgraph *subgraph,
+                     const struct pipe_ml_operation *poperation,
+                     struct etna_operation *operation)
+{
+   struct pipe_context *context = subgraph->base.context;
+   unsigned max_input_dim = (1 << 13) - 1;  /* in_image_x_size is 13 bits long */
+
+   assert(poperation->type == PIPE_ML_OPERATION_TYPE_ADD);
+
+   operation->type = ETNA_JOB_TYPE_NN;
+   operation->addition = false;
+   operation->depthwise = false;
+   operation->pointwise = false;
+   operation->pooling_first_pixel = false;
+   operation->padding_same = false;
+   operation->stride = 1;
+
+   unsigned input_width = poperation->input_tensors[0]->dims[1];
+   unsigned input_height = poperation->input_tensors[0]->dims[2];
+   unsigned input_channels = poperation->input_tensors[0]->dims[3];
+
+   operation->input_count = 2;
+   if (input_width % 2 == 0 &&
+       input_height * input_channels <= max_input_dim) {
+      operation->input_width = 4;
+      operation->input_height = input_height * input_channels;
+      operation->input_channels = (input_width * 2) / 4;
+
+      operation->output_width = 1;
+      operation->output_height = poperation->output_tensors[0]->dims[2] * poperation->output_tensors[0]->dims[3];
+      operation->output_channels = poperation->output_tensors[0]->dims[1];
+
+      operation->weight_width = 1;
+      operation->weight_height = operation->input_width;
+   } else if (input_channels % 3 == 0 &&
+              input_height * input_width <= max_input_dim) {
+      operation->input_width = 3;
+      operation->input_height = input_height * input_width;
+      operation->input_channels = (input_channels * 2) / 3;
+
+      operation->output_width = 1;
+      operation->output_height = poperation->output_tensors[0]->dims[1] * poperation->output_tensors[0]->dims[2];
+      operation->output_channels = poperation->output_tensors[0]->dims[3];
+
+      operation->weight_width = 1;
+      operation->weight_height = operation->input_width;
    } else {
-      operation->input_channels = 2 * operation->output_channels;
+      operation->input_width = input_width;
+      operation->input_height = input_height;
+      operation->input_channels = (input_channels * 2) / 1;
+
+      operation->output_width = input_width;
+      operation->output_height = input_height;
+      operation->output_channels = input_channels;
 
-      operation->weight_tensor = etna_ml_create_resource(context, operation->input_channels * operation->output_channels);
       operation->weight_width = 1;
       operation->weight_height = 1;
-      operation->weight_zero_point = 0x0;
-      operation->weight_scale = compute_weight_scale_add(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale);
-      operation->weight_signed = false;
-      operation->addition_offset = compute_addition_offset(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale, operation->weight_scale);
-
-      uint8_t (*weight_map)[operation->input_channels] = map_resource(operation->weight_tensor);
-      memset(weight_map, 0, pipe_buffer_size(operation->weight_tensor));
-
-      uint8_t first_weight = compute_weight_add(poperation->input_tensors[1]->scale, poperation->input_tensors[0]->scale, operation->weight_scale);
-      uint8_t second_weight = round((poperation->input_tensors[1]->scale / poperation->input_tensors[0]->scale) / operation->weight_scale);
-
-      for(unsigned oc = 0; oc < operation->output_channels; oc++) {
-         for(unsigned ic = 0; ic < operation->input_channels; ic++) {
-            if (ic == oc) {
-               weight_map[oc][ic] = first_weight;
-            } else if(ic == operation->output_channels + oc) {
-               weight_map[oc][ic] = second_weight;
-            }
-         }
-      }
+   }
+
+   operation->input_zero_point = etna_tensor_zero_point(poperation->input_tensors[0]);
+   operation->input_scale = poperation->input_tensors[0]->scale;
+
+   operation->input_tensor_sizes[0] = operation->input_width *
+                                       operation->input_height *
+                                       operation->input_channels /
+                                       2;
+
+   operation->input_tensor_sizes[1] = operation->input_width *
+                                       operation->input_height *
+                                       operation->input_channels /
+                                       2;
+
+   operation->output_count = 1;
+   operation->output_zero_point = etna_tensor_zero_point(poperation->output_tensors[0]);
+   operation->output_scale = poperation->output_tensors[0]->scale;
 
-      operation->bias_tensor = etna_ml_create_resource(context, 4 * operation->output_channels);
-      uint32_t *bias_map = map_resource(operation->bias_tensor);
+   operation->output_tensor_sizes[0] = operation->output_width *
+                                       operation->output_height *
+                                       operation->output_channels;
+
+   float min = 1.0 * (poperation->input_tensors[1]->scale / poperation->input_tensors[0]->scale);
+   float max = 1.0;
+
+   calc_quant_params(min, max, &operation->weight_scale, &operation->weight_zero_point);
 
-      int zero_point_diff = poperation->input_tensors[0]->zero_point - poperation->input_tensors[1]->zero_point;
-      double bias = zero_point_diff * poperation->input_tensors[1]->scale;
-      bias /= operation->weight_scale * poperation->input_tensors[0]->scale;
-      for(unsigned oc = 0; oc < operation->output_channels; oc++)
-         bias_map[oc] = (int)round(bias);
+   unsigned kernel_size = operation->output_channels * operation->weight_width * operation->weight_height * operation->input_channels;
+   operation->weight_tensor = etna_ml_create_resource(context, kernel_size);
+   uint8_t (*weight_map) = map_resource(operation->weight_tensor);
+
+   uint8_t first_weight = round(max / operation->weight_scale) + operation->weight_zero_point;
+   uint8_t second_weight = round(min / operation->weight_scale);
+   for(unsigned i = 0; i < kernel_size; i++) {
+      if (i % (operation->weight_width * operation->weight_height * operation->input_channels + 1) == 0)
+         weight_map[i] = first_weight;
+      else if (i % (operation->weight_width * operation->weight_height * operation->input_channels + 1) == operation->output_channels)
+         weight_map[i] = second_weight;
+      else
+         weight_map[i] = operation->weight_zero_point;
    }
+
+   operation->bias_tensor = etna_ml_create_resource(context, 4 * operation->output_channels);
+   uint32_t *bias_map = map_resource(operation->bias_tensor);
+   uint8_t input_zero_point_1 = etna_tensor_zero_point(poperation->input_tensors[0]);
+   uint8_t input_zero_point_2 = etna_tensor_zero_point(poperation->input_tensors[1]);
+   int zero_point_diff = input_zero_point_1 - input_zero_point_2;
+   double scale_factor = poperation->input_tensors[0]->scale * operation->weight_scale;
+   double bias_scale = poperation->input_tensors[1]->scale / scale_factor;
+
+   int bias = zero_point_diff * round(bias_scale);
+   for(unsigned oc = 0; oc < operation->output_channels; oc++)
+      bias_map[oc] = bias;
+}
+
+void
+etna_ml_lower_add(struct etna_ml_subgraph *subgraph,
+                  const struct pipe_ml_operation *poperation,
+                  struct etna_operation *operation)
+{
+   struct pipe_context *context = subgraph->base.context;
+   struct etna_context *ctx = etna_context(context);
+   unsigned nn_core_version = ctx->screen->specs.nn_core_version;
+
+   if (nn_core_version < 8)
+      etna_ml_lower_add_v7(subgraph, poperation, operation);
+   else
+      etna_ml_lower_add_v8(subgraph, poperation, operation);
 }
 
 void
@@ -672,32 +897,32 @@ etna_ml_lower_fully_connected(struct etna_ml_subgraph *subgraph,
    operation->padding_same = false;
    operation->stride = 1;
 
-   operation->input_tensors[0] = poperation->input_tensors[0]->index;
    operation->input_count = 1;
-   operation->input_width = poperation->input_tensors[0]->dims[1];
+   operation->input_width = poperation->input_tensors[0]->dims[3];
    operation->input_height = 1;
    operation->input_channels = 1;
-   operation->input_zero_point = poperation->input_tensors[0]->zero_point;
+   operation->input_zero_point = etna_tensor_zero_point(poperation->input_tensors[0]);
    operation->input_scale = poperation->input_tensors[0]->scale;
    operation->input_tensor_sizes[0] = operation->input_width *
                                       operation->input_height *
                                       operation->input_channels;
 
-   operation->output_tensors[0] = poperation->output_tensors[0]->index;
+   operation->output_count = 1;
    operation->output_width = 1;
    operation->output_height = 1;
-   operation->output_channels = poperation->output_tensors[0]->dims[1];
-   operation->output_zero_point = poperation->output_tensors[0]->zero_point;
+   operation->output_channels = poperation->output_tensors[0]->dims[3];
+   operation->output_zero_point = etna_tensor_zero_point(poperation->output_tensors[0]);
    operation->output_scale = poperation->output_tensors[0]->scale;
    operation->output_tensor_sizes[0] = operation->output_width *
-                                      operation->output_height *
-                                      operation->output_channels;
+                                       operation->output_height *
+                                       operation->output_channels;
 
    pipe_resource_reference(&operation->weight_tensor, poperation->conv.weight_tensor->resource);
-   operation->weight_width = poperation->conv.weight_tensor->dims[1];
+   operation->weight_width = poperation->conv.weight_tensor->dims[3];
    operation->weight_height = 1;
-   operation->weight_zero_point = poperation->conv.weight_tensor->zero_point;
+   operation->weight_zero_point = etna_tensor_zero_point(poperation->conv.weight_tensor);
    operation->weight_scale = poperation->conv.weight_tensor->scale;
+   operation->weight_signed = poperation->conv.weight_tensor->is_signed;
 
    pipe_resource_reference(&operation->bias_tensor, poperation->conv.bias_tensor->resource);
 }
@@ -770,11 +995,6 @@ create_nn_config(struct etna_ml_subgraph *subgraph, const struct etna_operation
                                   &output_width, &output_height, &output_channels);
    }
 
-   if (input_height > input_width) {
-      SWAP(input_width, input_height);
-      SWAP(output_width, output_height);
-   }
-
    if (operation->fully_connected) {
       unsigned original_input_width = input_width;
       input_width = 15;
@@ -787,6 +1007,9 @@ create_nn_config(struct etna_ml_subgraph *subgraph, const struct etna_operation
       input_channels = original_input_height / input_height;
       weight_width = input_width;
       weight_height = input_height;
+   } else {
+      SWAP(input_width, input_height);
+      SWAP(output_width, output_height);
    }
 
    etna_bo_cpu_prep(bo, DRM_ETNA_PREP_WRITE);
@@ -833,7 +1056,7 @@ create_nn_config(struct etna_ml_subgraph *subgraph, const struct etna_operation
    map->further7 = 0x0;
    map->further8 = 0x0;
 
-   struct pipe_resource *input = etna_ml_get_tensor(subgraph, operation->input_tensors[0]);
+   struct pipe_resource *input = etna_ml_get_resource(subgraph, operation->input_tensors[0]);
    unsigned offset = etna_ml_get_offset(subgraph, operation->input_tensors[0]);
    map->in_image_address = etna_bo_gpu_va(etna_buffer_resource(input)->bo) + offset;
    map->in_image_x_size = input_width;
@@ -863,7 +1086,9 @@ create_nn_config(struct etna_ml_subgraph *subgraph, const struct etna_operation
          map->unused7_2 = nn_core_version == 8;
          map->unused7_3 = nn_core_version == 8;
 
-      } else if (operation->stride == 2 && weight_width > 2 && (input_width < 5 || (operation->depthwise && (weight_width == 5 || input_width == 5)))) {
+      } else if (operation->stride == 2 &&
+                 weight_width > 2 && weight_width <= input_width &&
+                 (input_width < 5 || (operation->depthwise && (weight_width == 5 || input_width == 5)))) {
 
          if ((input_width <= 5 && weight_width < 5) ||
             (input_width > 5 && weight_width >= 5)) {
@@ -881,7 +1106,7 @@ create_nn_config(struct etna_ml_subgraph *subgraph, const struct etna_operation
       }
    }
 
-   struct pipe_resource *output = etna_ml_get_tensor(subgraph, operation->output_tensors[0]);
+   struct pipe_resource *output = etna_ml_get_resource(subgraph, operation->output_tensors[0]);
    offset = etna_ml_get_offset(subgraph, operation->output_tensors[0]);
    map->out_image_address = etna_bo_gpu_va(etna_buffer_resource(output)->bo) + offset;
    map->out_image_x_size = output_width;
@@ -1053,15 +1278,17 @@ etna_ml_compile_operation_nn(struct etna_ml_subgraph *subgraph, const struct etn
    else
       instruction->coefficients = etna_ml_create_coeffs_v8(subgraph, operation, &coef_cache_size);
 
-   struct pipe_resource *input = etna_ml_get_tensor(subgraph, operation->input_tensors[0]);
+   struct pipe_resource *input = etna_ml_get_resource(subgraph, operation->input_tensors[0]);
    assert(input);
    pipe_resource_reference(&instruction->input, input);
 
-   struct pipe_resource *output = etna_ml_get_tensor(subgraph, operation->output_tensors[0]);
+   struct pipe_resource *output = etna_ml_get_resource(subgraph, operation->output_tensors[0]);
    assert(output);
    pipe_resource_reference(&instruction->output, output);
 
    instruction->configs[0] = create_nn_config(subgraph, operation, instruction->coefficients, coef_cache_size);
+   instruction->input_offset = etna_ml_get_offset(subgraph, operation->input_tensors[0]);
+   instruction->output_offset = etna_ml_get_offset(subgraph, operation->output_tensors[0]);
 }
 
 void
diff --git a/src/gallium/drivers/etnaviv/etnaviv_ml_tp.c b/src/gallium/drivers/etnaviv/etnaviv_ml_tp.c
index c02f63a727e..5ea6e7c4fb0 100644
--- a/src/gallium/drivers/etnaviv/etnaviv_ml_tp.c
+++ b/src/gallium/drivers/etnaviv/etnaviv_ml_tp.c
@@ -12,6 +12,7 @@
 #include "etnaviv_ml.h"
 #include "etnaviv_ml_tp.h"
 
+#define DIMS3(w, h, c) (input_width == w && input_height == h && input_channels == c)
 #define FIELD(field, bits) uint32_t field : bits;
 
 struct etna_tp_params {
@@ -264,11 +265,11 @@ create_transpose_config(struct etna_ml_subgraph *subgraph, const struct etna_ope
    map->in_tile_y_size = operation->input_height;
    map->in_tile_y_inc = operation->input_height;
 
-   struct pipe_resource *input = etna_ml_get_tensor(subgraph, operation->input_tensors[0]);
+   struct pipe_resource *input = etna_ml_get_resource(subgraph, operation->input_tensors[0]);
    unsigned offset = etna_ml_get_offset(subgraph, operation->input_tensors[0]);
    map->in_image_base_address = etna_bo_gpu_va(etna_buffer_resource(input)->bo) + offset;
 
-   struct pipe_resource *output = etna_ml_get_tensor(subgraph, operation->output_tensors[0]);
+   struct pipe_resource *output = etna_ml_get_resource(subgraph, operation->output_tensors[0]);
    offset = etna_ml_get_offset(subgraph, operation->output_tensors[0]);
    map->out_image_base_address = etna_bo_gpu_va(etna_buffer_resource(output)->bo) + offset;
 
@@ -314,11 +315,11 @@ create_detranspose_config(struct etna_ml_subgraph *subgraph, const struct etna_o
    map->in_tile_y_size = 0x1;
    map->in_tile_y_inc = 0x1;
 
-   struct pipe_resource *input = etna_ml_get_tensor(subgraph, operation->input_tensors[0]);
+   struct pipe_resource *input = etna_ml_get_resource(subgraph, operation->input_tensors[0]);
    unsigned offset = etna_ml_get_offset(subgraph, operation->input_tensors[0]);
    map->in_image_base_address = etna_bo_gpu_va(etna_buffer_resource(input)->bo) + offset;
 
-   struct pipe_resource *output = etna_ml_get_tensor(subgraph, operation->output_tensors[0]);
+   struct pipe_resource *output = etna_ml_get_resource(subgraph, operation->output_tensors[0]);
    offset = etna_ml_get_offset(subgraph, operation->output_tensors[0]);
    map->out_image_base_address = etna_bo_gpu_va(etna_buffer_resource(output)->bo) + offset;
 
@@ -349,11 +350,13 @@ split_reshuffle(struct etna_ml_subgraph *subgraph, const struct etna_operation *
    unsigned remaining_out_size, remaining_in_size;
    unsigned dim_to_split = 0;
 
-   if (out_dims[1] >= out_dims[dim_to_split])
-      dim_to_split = 1;
+   if (operation->input_channels >= out_dims[dim_to_split]) {
+      if (out_dims[1] >= out_dims[dim_to_split])
+         dim_to_split = 1;
 
-   if (out_dims[2] >= out_dims[dim_to_split])
-      dim_to_split = 2;
+      if (out_dims[2] >= out_dims[dim_to_split])
+         dim_to_split = 2;
+   }
 
    remaining_in_size = in_dims[dim_to_split];
    remaining_out_size = out_dims[dim_to_split];
@@ -429,10 +432,8 @@ create_reshuffle_config(struct etna_ml_subgraph *subgraph, const struct etna_ope
 
    set_default_tp_config(map);
 
-   if (input_height > input_width) {
-      SWAP(input_width, input_height);
-      SWAP(output_width, output_height);
-   }
+   SWAP(input_width, input_height);
+   SWAP(output_width, output_height);
 
    in_dims[0] = input_width;
    in_dims[1] = input_height;
@@ -466,11 +467,11 @@ create_reshuffle_config(struct etna_ml_subgraph *subgraph, const struct etna_ope
    map->in_tile_y_size = out_dims[1] * 2;
    map->in_tile_y_inc = out_dims[1] * 2;
 
-   struct pipe_resource *input = etna_ml_get_tensor(subgraph, operation->input_tensors[0]);
+   struct pipe_resource *input = etna_ml_get_resource(subgraph, operation->input_tensors[0]);
    unsigned offset = etna_ml_get_offset(subgraph, operation->input_tensors[0]);
    map->in_image_base_address = etna_bo_gpu_va(etna_buffer_resource(input)->bo) + offset;
 
-   struct pipe_resource *output = etna_ml_get_tensor(subgraph, operation->output_tensors[0]);
+   struct pipe_resource *output = etna_ml_get_resource(subgraph, operation->output_tensors[0]);
    offset = etna_ml_get_offset(subgraph, operation->output_tensors[0]);
    map->out_image_base_address = etna_bo_gpu_va(etna_buffer_resource(output)->bo) + offset;
 
@@ -545,21 +546,25 @@ static void
 split_pad(struct etna_ml_subgraph *subgraph, const struct etna_operation *operation,
           unsigned tp_core, unsigned tp_cores_used, unsigned *in_dims, unsigned *out_dims)
 {
-   unsigned remaining_in_size;
+   unsigned remaining_out_size, remaining_in_size;
    unsigned dim_to_split = 2;
 
    remaining_in_size = in_dims[dim_to_split];
+   remaining_out_size = out_dims[dim_to_split];
 
    for (unsigned i = 0; i <= tp_core; i++) {
-      unsigned size = DIV_ROUND_UP(remaining_in_size, (tp_cores_used - i));
+      unsigned in_size = DIV_ROUND_UP(remaining_in_size, (tp_cores_used - i));
+      unsigned out_size = DIV_ROUND_UP(remaining_out_size, (tp_cores_used - i));
 
       if (i < tp_cores_used - 1) {
-         in_dims[dim_to_split] = size;
+         in_dims[dim_to_split] = in_size;
          remaining_in_size -= in_dims[dim_to_split];
       } else
          in_dims[dim_to_split] = remaining_in_size;
 
-      out_dims[dim_to_split] = size;
+      out_dims[dim_to_split] = out_size;
+
+      remaining_out_size -= out_size;
    }
 }
 
@@ -575,11 +580,28 @@ create_pad_config(struct etna_ml_subgraph *subgraph, const struct etna_operation
    unsigned output_width = operation->output_width;
    unsigned output_height = operation->output_height;
    unsigned output_channels = operation->output_channels;
+   unsigned pad_before_x = operation->pad_before_x;
+   unsigned pad_after_x = operation->pad_after_x;
+   unsigned pad_before_y = operation->pad_before_y;
+   unsigned pad_after_y = operation->pad_after_y;
+   unsigned pad_before_z = operation->pad_before_z;
+   unsigned pad_after_z = operation->pad_after_z;
    unsigned in_dims[3];
    unsigned out_dims[3];
+   struct etna_ml_tensor *input = etna_ml_get_tensor(subgraph, operation->input_tensors[0]);
 
-   SWAP(input_width, input_height);
-   SWAP(output_width, output_height);
+   if (input->exp_layout == ETNA_ML_LAYOUT_NHWC &&
+       input->act_layout == ETNA_ML_LAYOUT_NCHW) {
+      SWAP(input_width, input_height);
+      SWAP(output_width, output_height);
+      SWAP(pad_before_x, pad_before_y);
+      SWAP(pad_after_x, pad_after_y);
+   } else {
+      SWAP(input_width, input_channels);
+      SWAP(output_width, output_channels);
+      SWAP(pad_before_x, pad_before_z);
+      SWAP(pad_after_x, pad_after_z);
+   }
 
    etna_bo_cpu_prep(bo, DRM_ETNA_PREP_WRITE);
 
@@ -604,21 +626,28 @@ create_pad_config(struct etna_ml_subgraph *subgraph, const struct etna_operation
    map->in_image_stride = input_width;
    map->in_image_slice = input_width * input_height;
 
-   map->in_window_x_start = 0xffff;
-   map->in_window_y_start = 0xffff;
+   map->in_window_x_start = 0x0 - pad_before_x;
+   map->in_window_y_start = 0x0 - pad_before_y;
+   map->in_window_x_end = input_width - 1 + pad_after_x;
+   map->in_window_y_end = input_height - 1 + pad_after_y;
+
+   if (tp_cores_used > 1) {
+      if (pad_before_z)
+         map->in_window_z_start_overfetch = tp_core == 0;
+
+      if (pad_after_z)
+         map->in_window_z_end_overfetch = tp_core == tp_cores_used - 1;
+   }
 
-   map->in_window_x_end = in_dims[0];
-   map->in_window_y_end = in_dims[1];
    map->in_tile_x_size = out_dims[0];
    map->in_tile_x_inc = out_dims[0];
    map->in_tile_y_size = out_dims[1];
    map->in_tile_y_inc = out_dims[1];
 
-   struct pipe_resource *input = etna_ml_get_tensor(subgraph, operation->input_tensors[0]);
    unsigned offset = etna_ml_get_offset(subgraph, operation->input_tensors[0]);
-   map->in_image_base_address = etna_bo_gpu_va(etna_buffer_resource(input)->bo) + offset;
+   map->in_image_base_address = etna_bo_gpu_va(etna_buffer_resource(input->resource)->bo) + offset;
 
-   struct pipe_resource *output = etna_ml_get_tensor(subgraph, operation->output_tensors[0]);
+   struct pipe_resource *output = etna_ml_get_resource(subgraph, operation->output_tensors[0]);
    offset = etna_ml_get_offset(subgraph, operation->output_tensors[0]);
    map->out_image_base_address = etna_bo_gpu_va(etna_buffer_resource(output)->bo) + offset;
 
@@ -639,8 +668,13 @@ create_pad_config(struct etna_ml_subgraph *subgraph, const struct etna_operation
       split_pad(subgraph, operation, i, tp_cores_used, in_dims, out_dims);
 
       in_offset = map->in_image_slice * in_dims[2];
-      out_offset = out_dims[2];
-      out_offset *= map->in_tile_x_size * map->in_tile_y_size;
+
+      out_offset = map->in_tile_x_size * map->in_tile_y_size;
+
+      if (i == 0)
+         out_offset *= in_dims[2] + pad_before_z;
+      else
+         out_offset *= in_dims[2];
 
       map->in_image_base_address += in_offset;
       map->out_image_base_address += out_offset;
@@ -690,8 +724,7 @@ etna_tensor_zero_point(const struct pipe_tensor *tensor)
 void
 etna_ml_lower_transpose(struct etna_ml_subgraph *subgraph,
                         const struct pipe_tensor *input_tensor,
-                        struct etna_operation *operation,
-                        unsigned *output_tensor)
+                        struct etna_operation *operation)
 {
    operation->type = ETNA_JOB_TYPE_TP;
    operation->tp_type = ETNA_ML_TP_TRANSPOSE;
@@ -707,8 +740,6 @@ etna_ml_lower_transpose(struct etna_ml_subgraph *subgraph,
                                       operation->input_height *
                                       operation->input_channels;
 
-   *output_tensor = etna_ml_allocate_tensor(subgraph);
-   operation->output_tensors[0] = *output_tensor;
    operation->output_width = operation->input_width;
    operation->output_height = operation->input_height;
    operation->output_channels = operation->input_channels;
@@ -721,30 +752,28 @@ etna_ml_lower_transpose(struct etna_ml_subgraph *subgraph,
 
 void
 etna_ml_lower_detranspose(struct etna_ml_subgraph *subgraph,
-                          struct etna_operation *convolution,
+                          const struct pipe_tensor *output_tensor,
                           struct etna_operation *operation)
 {
    operation->type = ETNA_JOB_TYPE_TP;
    operation->tp_type = ETNA_ML_TP_DETRANSPOSE;
 
-   operation->input_tensors[0] = etna_ml_allocate_tensor(subgraph);
+   operation->input_tensors[0] = output_tensor->index;
    operation->input_count = 1;
-   operation->input_width = convolution->output_width;
-   operation->input_height = convolution->output_height;
-   operation->input_channels = convolution->output_channels;
-   operation->input_zero_point = convolution->output_zero_point;
-   operation->input_scale = convolution->output_scale;
+   operation->input_width = output_tensor->dims[1];
+   operation->input_height = output_tensor->dims[2];
+   operation->input_channels = output_tensor->dims[3];
+   operation->input_zero_point = etna_tensor_zero_point(output_tensor);
+   operation->input_scale = output_tensor->scale;
    operation->input_tensor_sizes[0] = operation->input_width *
                                       operation->input_height *
                                       operation->input_channels;
 
-   operation->output_tensors[0] = convolution->output_tensors[0];
-   operation->output_count = 1;
-   operation->output_width = convolution->output_width;
-   operation->output_height = convolution->output_height;
-   operation->output_channels = convolution->output_channels;
-   operation->output_zero_point = convolution->output_zero_point;
-   operation->output_scale = convolution->output_scale;
+   operation->output_width = operation->input_width;
+   operation->output_height = operation->input_height;
+   operation->output_channels = operation->input_channels;
+   operation->output_zero_point = operation->input_zero_point;
+   operation->output_scale = operation->input_scale;
    operation->output_tensor_sizes[0] = operation->output_width *
                                        operation->output_height *
                                        operation->output_channels;
@@ -753,15 +782,13 @@ etna_ml_lower_detranspose(struct etna_ml_subgraph *subgraph,
 void
 etna_ml_lower_reshuffle(struct etna_ml_subgraph *subgraph,
                         const struct pipe_ml_operation *convolution,
-                        struct etna_operation *operation,
-                        unsigned *output_tensor)
+                        struct etna_operation *operation)
 {
    operation->type = ETNA_JOB_TYPE_TP;
    operation->tp_type = ETNA_ML_TP_RESHUFFLE;
    operation->stride = convolution->conv.stride_x;
    operation->padding_same = convolution->conv.padding_same;
 
-   operation->input_tensors[0] = convolution->input_tensors[0]->index;
    operation->input_count = 1;
    operation->input_width = convolution->input_tensors[0]->dims[1];
    operation->input_height = convolution->input_tensors[0]->dims[2];
@@ -772,8 +799,7 @@ etna_ml_lower_reshuffle(struct etna_ml_subgraph *subgraph,
                                       operation->input_height *
                                       operation->input_channels;
 
-   *output_tensor = etna_ml_allocate_tensor(subgraph);
-   operation->output_tensors[0] = *output_tensor;
+   operation->output_count = 1;
    operation->output_width = DIV_ROUND_UP(operation->input_width, operation->stride);
    operation->output_height = DIV_ROUND_UP(operation->input_height, operation->stride);
    operation->output_channels = operation->input_channels * operation->stride * operation->stride;
@@ -809,7 +835,6 @@ etna_ml_lower_pad(struct etna_ml_subgraph *subgraph,
    operation->tp_type = ETNA_ML_TP_PAD;
    operation->stride = 1;
 
-   operation->input_tensors[0] = pad->input_tensors[0]->index;
    operation->input_count = 1;
    operation->input_width = pad->input_tensors[0]->dims[1];
    operation->input_height = pad->input_tensors[0]->dims[2];
@@ -820,7 +845,7 @@ etna_ml_lower_pad(struct etna_ml_subgraph *subgraph,
    operation->input_zero_point = etna_tensor_zero_point(pad->input_tensors[0]);
    operation->input_scale = pad->input_tensors[0]->scale;
 
-   operation->output_tensors[0] = pad->output_tensors[0]->index;
+   operation->output_count = 1;
    operation->output_width = pad->output_tensors[0]->dims[1];
    operation->output_height = pad->output_tensors[0]->dims[2];
    operation->output_channels = pad->output_tensors[0]->dims[3];
@@ -829,6 +854,13 @@ etna_ml_lower_pad(struct etna_ml_subgraph *subgraph,
    operation->output_tensor_sizes[0] = operation->output_width *
                                        operation->output_height *
                                        operation->output_channels;
+
+   operation->pad_before_x = pad->pad.before_x;
+   operation->pad_after_x = pad->pad.after_x;
+   operation->pad_before_y = pad->pad.before_y;
+   operation->pad_after_y = pad->pad.after_y;
+   operation->pad_before_z = pad->pad.before_z;
+   operation->pad_after_z = pad->pad.after_z;
 }
 
 void
@@ -837,11 +869,11 @@ etna_ml_compile_operation_tp(struct etna_ml_subgraph *subgraph,
                              struct etna_vip_instruction *instruction)
 {
    struct etna_context *ctx = etna_context(subgraph->base.context);
-   struct pipe_resource *input = etna_ml_get_tensor(subgraph, operation->input_tensors[0]);
+   struct pipe_resource *input = etna_ml_get_resource(subgraph, operation->input_tensors[0]);
    assert(input);
    pipe_resource_reference(&instruction->input, input);
 
-   struct pipe_resource *output = etna_ml_get_tensor(subgraph, operation->output_tensors[0]);
+   struct pipe_resource *output = etna_ml_get_resource(subgraph, operation->output_tensors[0]);
    assert(output);
    pipe_resource_reference(&instruction->output, output);
 
@@ -875,6 +907,9 @@ etna_ml_compile_operation_tp(struct etna_ml_subgraph *subgraph,
    case ETNA_ML_TP_PAD: {
       unsigned tp_cores_used = etna_ml_get_core_info(ctx)->tp_core_count;
 
+      if (operation->input_width == 1)
+         tp_cores_used = 1;
+
       ML_DBG("pad: input_width %d tp_cores_used %d\n", operation->input_width, tp_cores_used);
       for (unsigned i = 0; i < tp_cores_used; i++) {
          instruction->configs[i] = create_pad_config(subgraph, operation, i, tp_cores_used);
@@ -907,7 +942,8 @@ etna_ml_emit_operation_tp(struct etna_ml_subgraph *subgraph,
       etna_set_state(stream, VIVS_GL_OCB_REMAP_END, 0x0);
       etna_set_state(stream, VIVS_GL_TP_CONFIG, 0x0);
 
-      if (operation->tp_type == ETNA_ML_TP_PAD) {
+      if (more_than_one_tp_job &&
+          operation->tp_type == ETNA_ML_TP_PAD) {
          etna_set_state(stream, VIVS_GL_UNK03950, j < tp_core_count - 1 ? 0x8 : 0x0);
       } else {
          etna_set_state(stream, VIVS_GL_UNK03950, 0x0);
diff --git a/src/gallium/drivers/etnaviv/etnaviv_ml_tp.h b/src/gallium/drivers/etnaviv/etnaviv_ml_tp.h
index 2bbda23252d..532351d79dd 100644
--- a/src/gallium/drivers/etnaviv/etnaviv_ml_tp.h
+++ b/src/gallium/drivers/etnaviv/etnaviv_ml_tp.h
@@ -8,19 +8,17 @@
 void
 etna_ml_lower_transpose(struct etna_ml_subgraph *subgraph,
                         const struct pipe_tensor *input_tensor,
-                        struct etna_operation *operation,
-                        unsigned *output_tensor);
+                        struct etna_operation *operation);
 
 void
 etna_ml_lower_detranspose(struct etna_ml_subgraph *subgraph,
-                          struct etna_operation *convolution,
+                          const struct pipe_tensor *output_tensor,
                           struct etna_operation *operation);
 
 void
 etna_ml_lower_reshuffle(struct etna_ml_subgraph *subgraph,
                         const struct pipe_ml_operation *first_operation,
-                        struct etna_operation *operation,
-                        unsigned *output_tensor);
+                        struct etna_operation *operation);
 
 void
 etna_ml_lower_pad(struct etna_ml_subgraph *subgraph,
diff --git a/src/gallium/drivers/etnaviv/etnaviv_nir_lower_texture.c b/src/gallium/drivers/etnaviv/etnaviv_nir_lower_texture.c
index d0462ead016..45ac922fcb2 100644
--- a/src/gallium/drivers/etnaviv/etnaviv_nir_lower_texture.c
+++ b/src/gallium/drivers/etnaviv/etnaviv_nir_lower_texture.c
@@ -6,17 +6,12 @@
 #include "etnaviv_nir.h"
 
 static bool
-lower_txs(nir_builder *b, nir_instr *instr, UNUSED void *data)
+lower_txs(nir_builder *b, nir_tex_instr *tex, UNUSED void *data)
 {
-   if (instr->type != nir_instr_type_tex)
-      return false;
-
-   nir_tex_instr *tex = nir_instr_as_tex(instr);
-
    if (tex->op != nir_texop_txs)
       return false;
 
-   b->cursor = nir_instr_remove(instr);
+   b->cursor = nir_instr_remove(&tex->instr);
 
    nir_def *idx = nir_imm_int(b, tex->texture_index);
    nir_def *sizes = nir_load_texture_size_etna(b, 32, idx);
@@ -26,6 +21,51 @@ lower_txs(nir_builder *b, nir_instr *instr, UNUSED void *data)
    return true;
 }
 
+static bool
+legalize_txf_lod(nir_builder *b, nir_tex_instr *tex, UNUSED void *data)
+{
+   if (tex->op != nir_texop_txf)
+      return false;
+
+   b->cursor = nir_before_instr(&tex->instr);
+
+   int lod_index = nir_tex_instr_src_index(tex, nir_tex_src_lod);
+   assert(lod_index >= 0);
+   nir_def *lod = tex->src[lod_index].src.ssa;
+
+   nir_src_rewrite(&tex->src[lod_index].src, nir_i2f32(b, lod));
+
+   return true;
+}
+
+static bool
+legalize_txd_derivatives(nir_builder *b, nir_tex_instr *tex, UNUSED void *data)
+{
+   if (tex->op != nir_texop_txd)
+      return false;
+
+   b->cursor = nir_before_instr(&tex->instr);
+
+   int coord_index = nir_tex_instr_src_index(tex, nir_tex_src_coord);
+   int ddx_index = nir_tex_instr_src_index(tex, nir_tex_src_ddx);
+   int ddy_index = nir_tex_instr_src_index(tex, nir_tex_src_ddy);
+
+   assert(coord_index >= 0);
+   assert(ddx_index >= 0);
+   assert(ddy_index >= 0);
+
+   nir_def *coord = tex->src[coord_index].src.ssa;
+   nir_def *ddx = tex->src[ddx_index].src.ssa;
+   nir_def *ddy = tex->src[ddy_index].src.ssa;
+
+   coord = nir_trim_vector(b, coord, ddx->num_components);
+
+   nir_src_rewrite(&tex->src[ddx_index].src, nir_fadd(b, coord, ddx));
+   nir_src_rewrite(&tex->src[ddy_index].src, nir_fadd(b, coord, ddy));
+
+   return true;
+}
+
 bool
 etna_nir_lower_texture(nir_shader *s, struct etna_shader_key *key)
 {
@@ -45,8 +85,14 @@ etna_nir_lower_texture(nir_shader *s, struct etna_shader_key *key)
                                                   key->tex_swizzle,
                                                   true);
 
-   NIR_PASS(progress, s, nir_shader_instructions_pass, lower_txs,
+   NIR_PASS(progress, s, nir_shader_tex_pass, lower_txs,
          nir_metadata_control_flow, NULL);
 
+   NIR_PASS(progress, s, nir_shader_tex_pass, legalize_txf_lod,
+      nir_metadata_control_flow, NULL);
+
+   NIR_PASS(progress, s, nir_shader_tex_pass, legalize_txd_derivatives,
+      nir_metadata_control_flow, NULL);
+
    return progress;
 }
diff --git a/src/gallium/drivers/freedreno/a6xx/fd6_compute.cc b/src/gallium/drivers/freedreno/a6xx/fd6_compute.cc
index a82b1517f18..7cc70667375 100644
--- a/src/gallium/drivers/freedreno/a6xx/fd6_compute.cc
+++ b/src/gallium/drivers/freedreno/a6xx/fd6_compute.cc
@@ -220,18 +220,14 @@ fd6_launch_grid(struct fd_context *ctx, const struct pipe_grid_info *info) in_dt
 
    uint32_t shared_size =
       MAX2(((int)(cs->v->cs.req_local_mem + info->variable_shared_mem) - 1) / 1024, 1);
-   enum a6xx_const_ram_mode mode =
-      cs->v->constlen > 256 ? CONSTLEN_512 :
-      (cs->v->constlen > 192 ? CONSTLEN_256 :
-      (cs->v->constlen > 128 ? CONSTLEN_192 : CONSTLEN_128));
-   OUT_PKT4(ring, REG_A6XX_SP_CS_CTRL_REG1, 1);
-   OUT_RING(ring, A6XX_SP_CS_CTRL_REG1_SHARED_SIZE(shared_size) |
-                     A6XX_SP_CS_CTRL_REG1_CONSTANTRAMMODE(mode));
+   OUT_PKT4(ring, REG_A6XX_SP_CS_UNKNOWN_A9B1, 1);
+   OUT_RING(ring, A6XX_SP_CS_UNKNOWN_A9B1_SHARED_SIZE(shared_size) |
+                     A6XX_SP_CS_UNKNOWN_A9B1_UNK6);
 
    if (CHIP == A6XX && ctx->screen->info->a6xx.has_lpac) {
-      OUT_PKT4(ring, REG_A6XX_HLSQ_CS_CTRL_REG1, 1);
-      OUT_RING(ring, A6XX_HLSQ_CS_CTRL_REG1_SHARED_SIZE(shared_size) |
-                        A6XX_HLSQ_CS_CTRL_REG1_CONSTANTRAMMODE(mode));
+      OUT_PKT4(ring, REG_A6XX_HLSQ_CS_UNKNOWN_B9D0, 1);
+      OUT_RING(ring, A6XX_HLSQ_CS_UNKNOWN_B9D0_SHARED_SIZE(shared_size) |
+                        A6XX_HLSQ_CS_UNKNOWN_B9D0_UNK6);
    }
 
    const unsigned *local_size =
diff --git a/src/gallium/drivers/freedreno/a6xx/fd6_program.cc b/src/gallium/drivers/freedreno/a6xx/fd6_program.cc
index 5798a503403..08439fffbfe 100644
--- a/src/gallium/drivers/freedreno/a6xx/fd6_program.cc
+++ b/src/gallium/drivers/freedreno/a6xx/fd6_program.cc
@@ -939,9 +939,9 @@ emit_fs_inputs(struct fd_ringbuffer *ring, const struct program_builder *b)
       ij_regid[i] = ir3_find_sysval_regid(fs, SYSTEM_VALUE_BARYCENTRIC_PERSP_PIXEL + i);
 
    if (fs->num_sampler_prefetch > 0) {
-      /* It seems like ij_pix is *required* to be r0.x */
-      assert(!VALIDREG(ij_regid[IJ_PERSP_PIXEL]) ||
-             ij_regid[IJ_PERSP_PIXEL] == regid(0, 0));
+      /* FS prefetch reads coordinates from r0.x */
+      assert(!VALIDREG(ij_regid[fs->prefetch_bary_type]) ||
+             ij_regid[fs->prefetch_bary_type] == regid(0, 0));
    }
 
    OUT_PKT4(ring, REG_A6XX_SP_FS_PREFETCH_CNTL, 1 + fs->num_sampler_prefetch);
diff --git a/src/gallium/drivers/i915/ci/gitlab-ci.yml b/src/gallium/drivers/i915/ci/gitlab-ci.yml
index bee8d886110..8d10cbf86d9 100644
--- a/src/gallium/drivers/i915/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/i915/ci/gitlab-ci.yml
@@ -17,7 +17,7 @@ include:
 i915-g33:
   extends:
     - .ondracka-g33-test
-    - .b2c-deqp-test
+    - .test-piglit
   variables:
     DEQP_SUITE: i915g
     PIGLIT_PLATFORM: gbm
diff --git a/src/gallium/drivers/iris/iris_batch.c b/src/gallium/drivers/iris/iris_batch.c
index d2482c23e84..efbb910ec9a 100644
--- a/src/gallium/drivers/iris/iris_batch.c
+++ b/src/gallium/drivers/iris/iris_batch.c
@@ -231,7 +231,7 @@ iris_init_batch(struct iris_context *ice,
          batch->other_batches[batch->num_other_batches++] = other_batch;
    }
 
-   if (INTEL_DEBUG(DEBUG_BATCH | DEBUG_BATCH_STATS)) {
+   if (INTEL_DEBUG(DEBUG_BATCH) || INTEL_DEBUG(DEBUG_BATCH_STATS)) {
       const unsigned decode_flags = INTEL_BATCH_DECODE_DEFAULT_FLAGS |
          (INTEL_DEBUG(DEBUG_COLOR) ? INTEL_BATCH_DECODE_IN_COLOR : 0);
 
@@ -550,7 +550,7 @@ iris_batch_free(const struct iris_context *ice, struct iris_batch *batch)
 
    _mesa_hash_table_destroy(batch->bo_aux_modes, NULL);
 
-   if (INTEL_DEBUG(DEBUG_BATCH | DEBUG_BATCH_STATS))
+   if (INTEL_DEBUG(DEBUG_BATCH) || INTEL_DEBUG(DEBUG_BATCH_STATS))
       intel_batch_decode_ctx_finish(&batch->decoder);
 }
 
@@ -925,7 +925,9 @@ _iris_batch_flush(struct iris_batch *batch, const char *file, int line)
 
    iris_finish_batch(batch);
 
-   if (INTEL_DEBUG(DEBUG_BATCH | DEBUG_SUBMIT | DEBUG_PIPE_CONTROL)) {
+   if (INTEL_DEBUG(DEBUG_BATCH) ||
+       INTEL_DEBUG(DEBUG_SUBMIT) ||
+       INTEL_DEBUG(DEBUG_PIPE_CONTROL)) {
       const char *basefile = strstr(file, "iris/");
       if (basefile)
          file = basefile + 5;
diff --git a/src/gallium/drivers/iris/iris_bufmgr.c b/src/gallium/drivers/iris/iris_bufmgr.c
index 2f4c2765276..4681557c24a 100644
--- a/src/gallium/drivers/iris/iris_bufmgr.c
+++ b/src/gallium/drivers/iris/iris_bufmgr.c
@@ -781,6 +781,8 @@ iris_slab_alloc(void *priv,
       flags |= BO_ALLOC_COMPRESSED;
       break;
    case IRIS_HEAP_SYSTEM_MEMORY_CACHED_COHERENT:
+      flags |= BO_ALLOC_CACHED_COHERENT | BO_ALLOC_SMEM;
+      break;
    case IRIS_HEAP_SYSTEM_MEMORY_UNCACHED:
       flags |= BO_ALLOC_SMEM;
       break;
diff --git a/src/gallium/drivers/iris/iris_state.c b/src/gallium/drivers/iris/iris_state.c
index 072776d1909..1e2bd3cb402 100644
--- a/src/gallium/drivers/iris/iris_state.c
+++ b/src/gallium/drivers/iris/iris_state.c
@@ -9107,16 +9107,14 @@ iris_upload_compute_walker(struct iris_context *ice,
       }
    }
 
-   uint32_t total_shared = shader->total_shared + grid->variable_shared_mem;
    struct GENX(INTERFACE_DESCRIPTOR_DATA) idd = {};
-   idd.KernelStartPointer =
-      KSP(shader) + iris_cs_data_prog_offset(cs_data, dispatch.simd_size);
+   idd.KernelStartPointer = KSP(shader);
    idd.NumberofThreadsinGPGPUThreadGroup = dispatch.threads;
    idd.SharedLocalMemorySize =
-      intel_compute_slm_encode_size(GFX_VER, total_shared);
+      intel_compute_slm_encode_size(GFX_VER, shader->total_shared);
    idd.PreferredSLMAllocationSize =
       intel_compute_preferred_slm_calc_encode_size(devinfo,
-                                                   total_shared,
+                                                   shader->total_shared,
                                                    dispatch.group_size,
                                                    dispatch.simd_size);
    idd.SamplerStatePointer = shs->sampler_table.offset;
@@ -9265,6 +9263,15 @@ iris_upload_gpgpu_walker(struct iris_context *ice,
       }
    }
 
+   for (unsigned i = 0; i < IRIS_MAX_GLOBAL_BINDINGS; i++) {
+      struct pipe_resource *res = ice->state.global_bindings[i];
+      if (!res)
+         break;
+
+      iris_use_pinned_bo(batch, iris_resource_bo(res),
+                         true, IRIS_DOMAIN_NONE);
+   }
+
    if (stage_dirty & (IRIS_STAGE_DIRTY_SAMPLER_STATES_CS |
                       IRIS_STAGE_DIRTY_BINDINGS_CS |
                       IRIS_STAGE_DIRTY_CONSTANTS_CS |
@@ -9319,20 +9326,6 @@ iris_upload_gpgpu_walker(struct iris_context *ice,
 
 #endif /* #if GFX_VERx10 >= 125 */
 
-static void
-iris_use_global_bindings(struct iris_context *ice,
-                         struct iris_batch *batch)
-{
-   for (unsigned i = 0; i < IRIS_MAX_GLOBAL_BINDINGS; i++) {
-      struct pipe_resource *res = ice->state.global_bindings[i];
-      if (!res)
-         break;
-
-      iris_use_pinned_bo(batch, iris_resource_bo(res),
-                        true, IRIS_DOMAIN_NONE);
-   }
-}
-
 static void
 iris_upload_compute_state(struct iris_context *ice,
                           struct iris_batch *batch,
@@ -9374,8 +9367,6 @@ iris_upload_compute_state(struct iris_context *ice,
       iris_use_pinned_bo(batch, border_color_pool->bo, false,
                          IRIS_DOMAIN_NONE);
 
-   iris_use_global_bindings(ice, batch);
-
 #if GFX_VER >= 12
    genX(invalidate_aux_map_state)(batch);
 #endif
diff --git a/src/gallium/drivers/lima/ci/gitlab-ci.yml b/src/gallium/drivers/lima/ci/gitlab-ci.yml
index 2a6a5c28ba5..278530b66c5 100644
--- a/src/gallium/drivers/lima/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/lima/ci/gitlab-ci.yml
@@ -23,7 +23,7 @@
 
 lima-mali450-deqp:arm64:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .lima-rules
     - .lava-meson-gxl-s805x-libretech-ac:arm64
   variables:
@@ -33,7 +33,8 @@ lima-mali450-deqp:arm64:
 
 lima-mali450-piglit:arm64:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
+    - .test-piglit
     - .lima-rules
     - .lava-meson-gxl-s805x-libretech-ac:arm64
   variables:
diff --git a/src/gallium/drivers/llvmpipe/ci/gitlab-ci-inc.yml b/src/gallium/drivers/llvmpipe/ci/gitlab-ci-inc.yml
index 71a6e3c717e..679f353eb24 100644
--- a/src/gallium/drivers/llvmpipe/ci/gitlab-ci-inc.yml
+++ b/src/gallium/drivers/llvmpipe/ci/gitlab-ci-inc.yml
@@ -23,7 +23,7 @@
       when: on_success
 
 .llvmpipe-manual-rules:
-  stage: software-renderer-postmerge
+  stage: software-renderer-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
diff --git a/src/gallium/drivers/llvmpipe/ci/gitlab-ci.yml b/src/gallium/drivers/llvmpipe/ci/gitlab-ci.yml
index 25e61b31216..ace1a5a98c0 100644
--- a/src/gallium/drivers/llvmpipe/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/llvmpipe/ci/gitlab-ci.yml
@@ -5,6 +5,7 @@ llvmpipe-piglit-rusticl:
   extends:
     - .llvmpipe-piglit-cl
     - .llvmpipe-rusticl-rules
+    - .test-piglit
   needs:
     - debian-testing
     - debian/x86_64_test-gl
@@ -28,7 +29,9 @@ llvmpipe:
     DEQP_SUITE: llvmpipe
     XVFB_SCRIPT: "install/deqp-runner.sh"
     DEQP_FRACTION: 4
-  extends: .llvmpipe-deqp-test
+  extends:
+    - .llvmpipe-deqp-test
+    - .test-piglit
   script: |
     . "$SCRIPTS_DIR"/setup-test-env.sh
     export LD_LIBRARY_PATH="$CI_PROJECT_DIR/install/lib"
@@ -57,6 +60,7 @@ llvmpipe-deqp-asan:
     # shared runners
     LP_NUM_THREADS: 0
     DEQP_FORCE_ASAN: 1
+    S3_ARTIFACT_NAME: mesa-x86_64-asan-debugoptimized
   extends: .llvmpipe-deqp-test
   needs:
     - debian/x86_64_test-gl
diff --git a/src/gallium/drivers/nouveau/ci/gitlab-ci-inc.yml b/src/gallium/drivers/nouveau/ci/gitlab-ci-inc.yml
index 392ef7ecea3..753a89165fc 100644
--- a/src/gallium/drivers/nouveau/ci/gitlab-ci-inc.yml
+++ b/src/gallium/drivers/nouveau/ci/gitlab-ci-inc.yml
@@ -24,7 +24,7 @@
       when: on_success
 
 .nouveau-manual-rules:
-  stage: nouveau-postmerge
+  stage: nouveau-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
diff --git a/src/gallium/drivers/nouveau/ci/gitlab-ci.yml b/src/gallium/drivers/nouveau/ci/gitlab-ci.yml
index c8e9bcdae4c..e942749ef0b 100644
--- a/src/gallium/drivers/nouveau/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/nouveau/ci/gitlab-ci.yml
@@ -3,7 +3,7 @@ include:
 
 .gk20a-gles:
   extends:
-    - .baremetal-test-arm32
+    - .baremetal-test-arm32-gl
     - .nouveau-bm-test
     - .anholt-tegra124-jetson-tk1:arm32
   parallel: 4
@@ -15,7 +15,7 @@ include:
 # Single Jetson Nano board at anholt's house.
 .gm20b-gles-full:
   extends:
-    - .baremetal-test-arm64
+    - .baremetal-test-arm64-gl
     - .nouveau-bm-test
     - .google-tegra210-p3450-0000:arm64
     - .nouveau-manual-rules
diff --git a/src/gallium/drivers/panfrost/pan_cmdstream.c b/src/gallium/drivers/panfrost/pan_cmdstream.c
index a9b89f1e99c..bdde1da6397 100644
--- a/src/gallium/drivers/panfrost/pan_cmdstream.c
+++ b/src/gallium/drivers/panfrost/pan_cmdstream.c
@@ -1,4 +1,5 @@
 /*
+ * Copyright (C) 2025 Arm Ltd.
  * Copyright (C) 2023 Amazon.com, Inc. or its affiliates.
  * Copyright (C) 2018 Alyssa Rosenzweig
  * Copyright (C) 2020 Collabora Ltd.
@@ -2875,6 +2876,57 @@ panfrost_update_streamout_offsets(struct panfrost_context *ctx)
    (PAN_DIRTY_ZS | PAN_DIRTY_BLEND | PAN_DIRTY_MSAA | PAN_DIRTY_RASTERIZER |   \
     PAN_DIRTY_OQ)
 
+#if PAN_ARCH >= 9
+static uint64_t
+panfrost_emit_varying_descriptors(struct panfrost_batch *batch)
+{
+   struct panfrost_compiled_shader *vs =
+      batch->ctx->prog[PIPE_SHADER_VERTEX];
+   struct panfrost_compiled_shader *fs =
+      batch->ctx->prog[PIPE_SHADER_FRAGMENT];
+
+   const uint32_t vs_out_mask = vs->info.varyings.fixed_varyings;
+   const uint32_t fs_in_mask = fs->info.varyings.fixed_varyings;
+   const uint32_t fs_in_slots = fs->info.varyings.input_count +
+                                util_bitcount(fs_in_mask);
+
+   struct panfrost_ptr bufs =
+      pan_pool_alloc_desc_array(&batch->pool.base, fs_in_slots, ATTRIBUTE);
+   struct mali_attribute_packed *descs = bufs.cpu;
+
+   batch->nr_varying_attribs[PIPE_SHADER_FRAGMENT] = fs_in_slots;
+
+   const uint32_t varying_size = panfrost_vertex_attribute_stride(vs, fs);
+
+   for (uint32_t i = 0; i < fs_in_slots; i++) {
+      const struct pan_shader_varying *var = &fs->info.varyings.input[i];
+
+      uint32_t index = 0;
+      if (var->location >= VARYING_SLOT_VAR0) {
+         unsigned nr_special = util_bitcount(vs_out_mask);
+         unsigned general_index = (var->location - VARYING_SLOT_VAR0);
+         index = nr_special + general_index;
+      } else {
+         index = util_bitcount(vs_out_mask & BITFIELD_MASK(var->location));
+      }
+
+      pan_pack(&descs[i], ATTRIBUTE, cfg) {
+         cfg.attribute_type = MALI_ATTRIBUTE_TYPE_VERTEX_PACKET;
+         cfg.offset_enable = false;
+         cfg.format = GENX(panfrost_format_from_pipe_format)(var->format)->hw;
+         cfg.table = 61;
+         cfg.frequency = MALI_ATTRIBUTE_FREQUENCY_VERTEX;
+         cfg.offset = 1024 + (index * 16);
+         cfg.buffer_index = 0;
+         cfg.attribute_stride = varying_size;
+         cfg.packet_stride = varying_size + 16;
+      }
+   }
+
+   return bufs.gpu;
+}
+#endif
+
 static inline void
 panfrost_update_shader_state(struct panfrost_batch *batch,
                              enum pipe_shader_type st)
@@ -2904,6 +2956,9 @@ panfrost_update_shader_state(struct panfrost_batch *batch,
    }
 
 #if PAN_ARCH >= 9
+   if ((dirty & PAN_DIRTY_STAGE_SHADER) && frag)
+      batch->attribs[st] = panfrost_emit_varying_descriptors(batch);
+
    if (dirty & PAN_DIRTY_STAGE_IMAGE) {
       batch->images[st] =
          ctx->image_mask[st] ? panfrost_emit_images(batch, st) : 0;
diff --git a/src/gallium/drivers/panfrost/pan_cmdstream.h b/src/gallium/drivers/panfrost/pan_cmdstream.h
index 3623595c0e7..51d655610c7 100644
--- a/src/gallium/drivers/panfrost/pan_cmdstream.h
+++ b/src/gallium/drivers/panfrost/pan_cmdstream.h
@@ -273,7 +273,7 @@ panfrost_vertex_attribute_stride(struct panfrost_compiled_shader *vs,
    unsigned v = vs->info.varyings.output_count;
    unsigned f = fs->info.varyings.input_count;
    unsigned slots = MAX2(v, f);
-   slots += util_bitcount(fs->key.fs.fixed_varying_mask);
+   slots += util_bitcount(vs->info.varyings.fixed_varyings);
 
    /* Assumes 16 byte slots. We could do better. */
    return slots * 16;
@@ -310,7 +310,11 @@ panfrost_emit_resources(struct panfrost_batch *batch,
    panfrost_make_resource_table(T, PAN_TABLE_IMAGE, batch->images[stage],
                                 util_last_bit(ctx->image_mask[stage]));
 
-   if (stage == PIPE_SHADER_VERTEX) {
+   if (stage == PIPE_SHADER_FRAGMENT) {
+      panfrost_make_resource_table(T, PAN_TABLE_ATTRIBUTE,
+                                   batch->attribs[stage],
+                                   batch->nr_varying_attribs[PIPE_SHADER_FRAGMENT]);
+   } else if (stage == PIPE_SHADER_VERTEX) {
       panfrost_make_resource_table(T, PAN_TABLE_ATTRIBUTE,
                                    batch->attribs[stage],
                                    ctx->vertex->num_elements);
diff --git a/src/gallium/drivers/panfrost/pan_context.h b/src/gallium/drivers/panfrost/pan_context.h
index 6835d39de49..516ab77b600 100644
--- a/src/gallium/drivers/panfrost/pan_context.h
+++ b/src/gallium/drivers/panfrost/pan_context.h
@@ -346,9 +346,6 @@ struct panfrost_fs_key {
    /* Number of colour buffers if gl_FragColor is written */
    unsigned nr_cbufs_for_fragcolor;
 
-   /* On Valhall, fixed_varying_mask of the linked vertex shader */
-   uint32_t fixed_varying_mask;
-
    /* Midgard shaders that read the tilebuffer must be keyed for
     * non-blendable formats
     */
@@ -427,12 +424,6 @@ struct panfrost_uncompiled_shader {
    /* Compiled transform feedback program, if one is required */
    struct panfrost_compiled_shader *xfb;
 
-   /* On vertex shaders, bit mask of special desktop-only varyings to link
-    * with the fragment shader. Used on Valhall to implement separable
-    * shaders for desktop GL.
-    */
-   uint32_t fixed_varying_mask;
-
    /* On fragments shaders, bit mask of varyings using noprespective
     * interpolation, starting at VARYING_SLOT_VAR0 */
    uint32_t noperspective_varyings;
diff --git a/src/gallium/drivers/panfrost/pan_job.h b/src/gallium/drivers/panfrost/pan_job.h
index 8ab9bca2147..e089ad85800 100644
--- a/src/gallium/drivers/panfrost/pan_job.h
+++ b/src/gallium/drivers/panfrost/pan_job.h
@@ -133,6 +133,7 @@ struct panfrost_batch {
 
    unsigned nr_push_uniforms[PIPE_SHADER_TYPES];
    unsigned nr_uniform_buffers[PIPE_SHADER_TYPES];
+   unsigned nr_varying_attribs[PIPE_SHADER_TYPES];
 
    /* Varying related pointers */
    struct {
diff --git a/src/gallium/drivers/panfrost/pan_nir_lower_res_indices.c b/src/gallium/drivers/panfrost/pan_nir_lower_res_indices.c
index 1d7ccf83565..52dc3efc64a 100644
--- a/src/gallium/drivers/panfrost/pan_nir_lower_res_indices.c
+++ b/src/gallium/drivers/panfrost/pan_nir_lower_res_indices.c
@@ -77,15 +77,12 @@ static bool
 lower_input_intrin(nir_builder *b, nir_intrinsic_instr *intrin,
                    const struct panfrost_compile_inputs *inputs)
 {
-   /* We always use heap-based varying allocation when IDVS is used on Valhall. */
-   bool malloc_idvs = !inputs->no_idvs;
-
    /* All vertex attributes come from the attribute table.
     * Fragment inputs come from the attribute table too, unless they've
     * been allocated on the heap.
     */
    if (b->shader->info.stage == MESA_SHADER_VERTEX ||
-       (b->shader->info.stage == MESA_SHADER_FRAGMENT && !malloc_idvs)) {
+       b->shader->info.stage == MESA_SHADER_FRAGMENT) {
       nir_intrinsic_set_base(
          intrin,
          pan_res_handle(PAN_TABLE_ATTRIBUTE, nir_intrinsic_base(intrin)));
@@ -131,6 +128,7 @@ lower_intrinsic(nir_builder *b, nir_intrinsic_instr *intrin,
    case nir_intrinsic_image_texel_address:
       return lower_image_intrin(b, intrin);
    case nir_intrinsic_load_input:
+   case nir_intrinsic_load_interpolated_input:
       return lower_input_intrin(b, intrin, inputs);
    case nir_intrinsic_load_ubo:
       return lower_load_ubo_intrin(b, intrin);
diff --git a/src/gallium/drivers/panfrost/pan_screen.c b/src/gallium/drivers/panfrost/pan_screen.c
index dcdcfa6a3af..ed9c01b8ad0 100644
--- a/src/gallium/drivers/panfrost/pan_screen.c
+++ b/src/gallium/drivers/panfrost/pan_screen.c
@@ -364,7 +364,7 @@ panfrost_init_shader_caps(struct panfrost_screen *screen)
       caps->max_tex_indirections = 16384; /* arbitrary */
       caps->max_control_flow_depth = 1024; /* arbitrary */
       /* Used as ABI on Midgard */
-      caps->max_inputs = 16;
+      caps->max_inputs = dev->arch >= 9 ? 32 : 16;
       caps->max_outputs = i == PIPE_SHADER_FRAGMENT ? 8 : PIPE_MAX_ATTRIBS;
       caps->max_temps = 256; /* arbitrary */
       caps->max_const_buffer0_size = 16 * 1024 * sizeof(float);
@@ -638,7 +638,7 @@ panfrost_init_screen_caps(struct panfrost_screen *screen)
 
    caps->shader_buffer_offset_alignment = 4;
 
-   caps->max_varyings = dev->arch >= 9 ? 16 : 32;
+   caps->max_varyings = 32;
 
    /* Removed in v6 (Bifrost) */
    caps->gl_clamp =
diff --git a/src/gallium/drivers/panfrost/pan_shader.c b/src/gallium/drivers/panfrost/pan_shader.c
index 5717de09d22..74416cf8af6 100644
--- a/src/gallium/drivers/panfrost/pan_shader.c
+++ b/src/gallium/drivers/panfrost/pan_shader.c
@@ -1,4 +1,5 @@
 /*
+ * Copyright (C) 2025 Arm Ltd.
  * Copyright (c) 2022 Amazon.com, Inc. or its affiliates.
  * Copyright (C) 2019-2022 Collabora, Ltd.
  * Copyright (C) 2019 Red Hat Inc.
@@ -109,11 +110,18 @@ lower_sample_mask_writes(nir_builder *b, nir_intrinsic_instr *intrin,
    return true;
 }
 
+static bool
+panfrost_use_ld_var_buf(const nir_shader *ir)
+{
+   const uint64_t allowed = VARYING_BIT_POS | VARYING_BIT_PSIZ |
+      BITFIELD64_MASK(16) << VARYING_SLOT_VAR0;
+   return (ir->info.inputs_read & ~allowed) == 0;
+}
+
 static void
 panfrost_shader_compile(struct panfrost_screen *screen, const nir_shader *ir,
                         struct util_debug_callback *dbg,
                         struct panfrost_shader_key *key, unsigned req_local_mem,
-                        unsigned fixed_varying_mask,
                         struct panfrost_shader_binary *out)
 {
    MESA_TRACE_FUNC();
@@ -135,18 +143,15 @@ panfrost_shader_compile(struct panfrost_screen *screen, const nir_shader *ir,
       .gpu_id = panfrost_device_gpu_id(dev),
    };
 
-   if (dev->arch >= 9)
-      /* Use LD_VAR_BUF for varying lookups. */
-      inputs.valhall.use_ld_var_buf = true;
-
    /* Lower this early so the backends don't have to worry about it */
    if (s->info.stage == MESA_SHADER_FRAGMENT) {
-      inputs.fixed_varying_mask = key->fs.fixed_varying_mask;
+      inputs.fixed_varying_mask =
+         panfrost_get_fixed_varying_mask(s->info.inputs_read);
    } else if (s->info.stage == MESA_SHADER_VERTEX) {
-      inputs.fixed_varying_mask = fixed_varying_mask;
-
       /* No IDVS for internal XFB shaders */
       inputs.no_idvs = s->info.has_transform_feedback_varyings;
+      inputs.fixed_varying_mask =
+         panfrost_get_fixed_varying_mask(s->info.outputs_written);
 
       if (s->info.has_transform_feedback_varyings) {
          NIR_PASS(_, s, nir_io_add_const_offset_to_base,
@@ -173,6 +178,8 @@ panfrost_shader_compile(struct panfrost_screen *screen, const nir_shader *ir,
       if (key->fs.clip_plane_enable) {
          NIR_PASS(_, s, nir_lower_clip_fs, key->fs.clip_plane_enable,
                   false, true);
+         inputs.fixed_varying_mask =
+            panfrost_get_fixed_varying_mask(s->info.inputs_read);
       }
 
       if (key->fs.line_smooth) {
@@ -214,6 +221,9 @@ panfrost_shader_compile(struct panfrost_screen *screen, const nir_shader *ir,
    /* Lower resource indices */
    NIR_PASS(_, s, panfrost_nir_lower_res_indices, &inputs);
 
+   if (dev->arch >= 9)
+      inputs.valhall.use_ld_var_buf = panfrost_use_ld_var_buf(s);
+
    screen->vtbl.compile_shader(s, &inputs, &out->binary, &out->info);
 
    panfrost_stats_util_debug(dbg, gl_shader_stage_name(s->info.stage),
@@ -253,8 +263,7 @@ panfrost_shader_get(struct pipe_screen *pscreen,
    if (!panfrost_disk_cache_retrieve(screen->disk_cache, uncompiled,
                                      &state->key, &res)) {
       panfrost_shader_compile(screen, uncompiled->nir, dbg, &state->key,
-                              req_local_mem, uncompiled->fixed_varying_mask,
-                              &res);
+                              req_local_mem, &res);
 
       panfrost_disk_cache_store(screen->disk_cache, uncompiled, &state->key,
                                 &res);
@@ -304,7 +313,6 @@ panfrost_build_fs_key(struct panfrost_context *ctx,
    struct panfrost_device *dev = pan_device(ctx->base.screen);
    struct pipe_framebuffer_state *fb = &ctx->pipe_framebuffer;
    struct pipe_rasterizer_state *rast = (void *)ctx->rasterizer;
-   struct panfrost_uncompiled_shader *vs = ctx->uncompiled[MESA_SHADER_VERTEX];
 
    /* gl_FragColor lowering needs the number of colour buffers */
    if (uncompiled->fragcolor_lowered) {
@@ -337,12 +345,6 @@ panfrost_build_fs_key(struct panfrost_context *ctx,
          key->rt_formats[i] = fmt;
       }
    }
-
-   /* Funny desktop GL varying lowering on Valhall */
-   if (dev->arch >= 9) {
-      assert(vs != NULL && "too early");
-      key->fixed_varying_mask = vs->fixed_varying_mask;
-   }
 }
 
 static void
@@ -482,13 +484,6 @@ panfrost_create_shader_state(struct pipe_context *pctx,
    so->stream_output = cso->stream_output;
    so->nir = nir;
 
-   /* Fix linkage early */
-   if (so->nir->info.stage == MESA_SHADER_VERTEX) {
-      so->fixed_varying_mask =
-         (so->nir->info.outputs_written & BITFIELD_MASK(VARYING_SLOT_VAR0)) &
-         ~VARYING_BIT_POS & ~VARYING_BIT_PSIZ;
-   }
-
    /* gl_FragColor needs to be lowered before lowering I/O, do that now */
    if (nir->info.stage == MESA_SHADER_FRAGMENT &&
        nir->info.outputs_written & BITFIELD_BIT(FRAG_RESULT_COLOR)) {
diff --git a/src/gallium/drivers/r300/ci/gitlab-ci-inc.yml b/src/gallium/drivers/r300/ci/gitlab-ci-inc.yml
index dcb071e42b1..664868fe49a 100644
--- a/src/gallium/drivers/r300/ci/gitlab-ci-inc.yml
+++ b/src/gallium/drivers/r300/ci/gitlab-ci-inc.yml
@@ -17,7 +17,7 @@
       when: on_success
 
 .r300-manual-rules:
-  stage: amd-postmerge
+  stage: amd-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -37,7 +37,7 @@
       when: on_success
 
 .r300-nine-manual-rules:
-  stage: amd-postmerge
+  stage: amd-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
diff --git a/src/gallium/drivers/r300/ci/gitlab-ci.yml b/src/gallium/drivers/r300/ci/gitlab-ci.yml
index d286fce3aa4..225a9da5444 100644
--- a/src/gallium/drivers/r300/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/r300/ci/gitlab-ci.yml
@@ -29,7 +29,6 @@ include:
 r300-rv530-deqp-gles2:
   extends:
     - .ondracka-rv530
-    - .b2c-deqp-test
   variables:
     DEQP_SUITE: r300-rv530
     GPU_VERSION: r300-rv530-nohiz
@@ -52,7 +51,6 @@ r300-rv530-nine:
 r300-rv380-deqp-gles2:
   extends:
     - .ondracka-rv380
-    - .b2c-deqp-test
   variables:
     DEQP_SUITE: r300-rv380
     GPU_VERSION: r300-rv380
@@ -60,7 +58,7 @@ r300-rv380-deqp-gles2:
 r300-rv410-deqp-piglit:
   extends:
     - .ondracka-generic
-    - .b2c-deqp-test
+    - .test-piglit
   variables:
     DEQP_SUITE: r300-rv410
     GPU_VERSION: r300-rv410
@@ -72,7 +70,7 @@ r300-rv410-deqp-piglit:
 r300-rv530-piglit:
   extends:
     - .ondracka-rv530
-    - .b2c-deqp-test
+    - .test-piglit
   variables:
     DEQP_SUITE: r300-piglit
     PIGLIT_PLATFORM: gbm
diff --git a/src/gallium/drivers/r600/meson.build b/src/gallium/drivers/r600/meson.build
index 8468b8ab301..97d88630304 100644
--- a/src/gallium/drivers/r600/meson.build
+++ b/src/gallium/drivers/r600/meson.build
@@ -144,13 +144,6 @@ egd_tables_h = custom_target(
 )
 
 r600_c_args = []
-if with_gallium_clover
-  if dep_elf.found()
-    r600_c_args += '-DHAVE_OPENCL'
-  else
-    warning('r600 requires libelf to support opencl.')
-  endif
-endif
 
 r600_cpp_args = []
 if cpp.has_type('std::pmr::monotonic_buffer_resource',
diff --git a/src/gallium/drivers/r600/r600_buffer_common.c b/src/gallium/drivers/r600/r600_buffer_common.c
index a49b76baf27..5ff88b5afa4 100644
--- a/src/gallium/drivers/r600/r600_buffer_common.c
+++ b/src/gallium/drivers/r600/r600_buffer_common.c
@@ -600,7 +600,8 @@ r600_buffer_from_user_memory(struct pipe_screen *screen,
 	struct radeon_winsys *ws = rscreen->ws;
 	struct r600_resource *rbuffer;
 
-	if (templ->bind & PIPE_BIND_GLOBAL) {
+	if ((templ->bind & PIPE_BIND_GLOBAL) &&
+	    (templ->bind & PIPE_BIND_COMPUTE_RESOURCE)) {
 		rbuffer = r600_resource(r600_compute_global_buffer_create(screen, templ));
 		((struct r600_resource_global *)rbuffer)->chunk->real_buffer = rbuffer;
 	} else {
diff --git a/src/gallium/drivers/radeonsi/ci/radeonsi-run-tests.py b/src/gallium/drivers/radeonsi/ci/radeonsi-run-tests.py
index b396594b982..9d83157f15e 100755
--- a/src/gallium/drivers/radeonsi/ci/radeonsi-run-tests.py
+++ b/src/gallium/drivers/radeonsi/ci/radeonsi-run-tests.py
@@ -441,7 +441,7 @@ if args.piglit:
         "--skips",
         skips_list,
         "--skips",
-        os.path.join(path_above_mesa, "mesa", ".gitlab-ci", "gbm-skips.txt")
+        os.path.join(path_above_mesa, "mesa", ".gitlab-ci", "all-skips.txt")
     ] + filters_args + flakes_args
 
     if os.path.exists(baseline):
diff --git a/src/gallium/drivers/radeonsi/meson.build b/src/gallium/drivers/radeonsi/meson.build
index 0a29c3d0fd1..1cbc6c5ed51 100644
--- a/src/gallium/drivers/radeonsi/meson.build
+++ b/src/gallium/drivers/radeonsi/meson.build
@@ -81,10 +81,8 @@ files_libradeonsi = files(
   'radeon_uvd.h',
   'radeon_uvd_enc.c',
   'radeon_uvd_enc.h',
-  'radeon_uvd_enc_1_1.c',
   'radeon_vce.c',
   'radeon_vce.h',
-  'radeon_vce_52.c',
   'radeon_vcn.h',
   'radeon_vcn.c',
   'radeon_vcn_dec.c',
diff --git a/src/gallium/drivers/radeonsi/radeon_uvd_enc.c b/src/gallium/drivers/radeonsi/radeon_uvd_enc.c
index 3c5b5407e13..13a20095a93 100644
--- a/src/gallium/drivers/radeonsi/radeon_uvd_enc.c
+++ b/src/gallium/drivers/radeonsi/radeon_uvd_enc.c
@@ -10,6 +10,7 @@
 
 #include "pipe/p_video_codec.h"
 #include "radeon_video.h"
+#include "radeon_bitstream.h"
 #include "radeonsi/si_pipe.h"
 #include "util/u_memory.h"
 #include "util/u_video.h"
@@ -17,6 +18,926 @@
 
 #include <stdio.h>
 
+#define RADEON_ENC_CS(value) (enc->cs.current.buf[enc->cs.current.cdw++] = (value))
+#define RADEON_ENC_BEGIN(cmd)                                                                      \
+   {                                                                                               \
+      uint32_t *begin = &enc->cs.current.buf[enc->cs.current.cdw++];                               \
+      RADEON_ENC_CS(cmd)
+#define RADEON_ENC_READ(buf, domain, off)                                                          \
+   radeon_uvd_enc_add_buffer(enc, (buf), RADEON_USAGE_READ, (domain), (off))
+#define RADEON_ENC_WRITE(buf, domain, off)                                                         \
+   radeon_uvd_enc_add_buffer(enc, (buf), RADEON_USAGE_WRITE, (domain), (off))
+#define RADEON_ENC_READWRITE(buf, domain, off)                                                     \
+   radeon_uvd_enc_add_buffer(enc, (buf), RADEON_USAGE_READWRITE, (domain), (off))
+#define RADEON_ENC_END()                                                                           \
+   *begin = (&enc->cs.current.buf[enc->cs.current.cdw] - begin) * 4;                               \
+   enc->total_task_size += *begin;                                                                 \
+   }
+
+static void radeon_uvd_enc_add_buffer(struct radeon_uvd_encoder *enc, struct pb_buffer_lean *buf,
+                                      unsigned usage, enum radeon_bo_domain domain,
+                                      signed offset)
+{
+   enc->ws->cs_add_buffer(&enc->cs, buf, usage | RADEON_USAGE_SYNCHRONIZED, domain);
+   uint64_t addr;
+   addr = enc->ws->buffer_get_virtual_address(buf);
+   addr = addr + offset;
+   RADEON_ENC_CS(addr >> 32);
+   RADEON_ENC_CS(addr);
+}
+
+static void radeon_uvd_enc_session_info(struct radeon_uvd_encoder *enc)
+{
+   unsigned int interface_version =
+      ((RENC_UVD_FW_INTERFACE_MAJOR_VERSION << RENC_UVD_IF_MAJOR_VERSION_SHIFT) |
+       (RENC_UVD_FW_INTERFACE_MINOR_VERSION << RENC_UVD_IF_MINOR_VERSION_SHIFT));
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SESSION_INFO);
+   RADEON_ENC_CS(0x00000000); // reserved
+   RADEON_ENC_CS(interface_version);
+   RADEON_ENC_READWRITE(enc->si->res->buf, enc->si->res->domains, 0x0);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_task_info(struct radeon_uvd_encoder *enc, bool need_feedback)
+{
+   enc->enc_pic.task_info.task_id++;
+
+   if (need_feedback)
+      enc->enc_pic.task_info.allowed_max_num_feedbacks = 1;
+   else
+      enc->enc_pic.task_info.allowed_max_num_feedbacks = 0;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_TASK_INFO);
+   enc->p_task_size = &enc->cs.current.buf[enc->cs.current.cdw++];
+   RADEON_ENC_CS(enc->enc_pic.task_info.task_id);
+   RADEON_ENC_CS(enc->enc_pic.task_info.allowed_max_num_feedbacks);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_session_init_hevc(struct radeon_uvd_encoder *enc)
+{
+   uint32_t padding_width = 0;
+   uint32_t padding_height = 0;
+   uint32_t max_padding_width = 64 - 2;
+   uint32_t max_padding_height = 16 - 2;
+
+   enc->enc_pic.session_init.aligned_picture_width = align(enc->base.width, 64);
+   enc->enc_pic.session_init.aligned_picture_height = align(enc->base.height, 16);
+
+   if (enc->enc_pic.session_init.aligned_picture_width > enc->source->width)
+      padding_width = enc->enc_pic.session_init.aligned_picture_width - enc->source->width;
+   if (enc->enc_pic.session_init.aligned_picture_height > enc->source->height)
+      padding_height = enc->enc_pic.session_init.aligned_picture_height - enc->source->height;
+
+   /* Input surface can be smaller if the difference is within padding bounds. */
+   if (padding_width > max_padding_width || padding_height > max_padding_height)
+      RVID_ERR("Input surface size doesn't match aligned size\n");
+
+   if (enc->enc_pic.desc->seq.conformance_window_flag) {
+      uint32_t pad_w =
+         (enc->enc_pic.desc->seq.conf_win_left_offset + enc->enc_pic.desc->seq.conf_win_right_offset) * 2;
+      uint32_t pad_h =
+         (enc->enc_pic.desc->seq.conf_win_top_offset + enc->enc_pic.desc->seq.conf_win_bottom_offset) * 2;
+      padding_width = CLAMP(pad_w, padding_width, max_padding_width);
+      padding_height = CLAMP(pad_h, padding_height, max_padding_height);
+   }
+
+   enc->enc_pic.session_init.padding_width = padding_width;
+   enc->enc_pic.session_init.padding_height = padding_height;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SESSION_INIT);
+   RADEON_ENC_CS(enc->enc_pic.session_init.aligned_picture_width);
+   RADEON_ENC_CS(enc->enc_pic.session_init.aligned_picture_height);
+   RADEON_ENC_CS(enc->enc_pic.session_init.padding_width);
+   RADEON_ENC_CS(enc->enc_pic.session_init.padding_height);
+   RADEON_ENC_CS(enc->enc_pic.session_init.pre_encode_mode);
+   RADEON_ENC_CS(enc->enc_pic.session_init.pre_encode_chroma_enabled);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_layer_control(struct radeon_uvd_encoder *enc)
+{
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_LAYER_CONTROL);
+   RADEON_ENC_CS(enc->enc_pic.layer_ctrl.max_num_temporal_layers);
+   RADEON_ENC_CS(enc->enc_pic.layer_ctrl.num_temporal_layers);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_layer_select(struct radeon_uvd_encoder *enc)
+{
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_LAYER_SELECT);
+   RADEON_ENC_CS(enc->enc_pic.layer_sel.temporal_layer_index);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_slice_control_hevc(struct radeon_uvd_encoder *enc,
+                                              struct pipe_picture_desc *picture)
+{
+   struct pipe_h265_enc_picture_desc *pic = (struct pipe_h265_enc_picture_desc *)picture;
+   uint32_t num_ctbs_total, num_ctbs_in_slice;
+
+   num_ctbs_total =
+      DIV_ROUND_UP(enc->base.width, 64) * DIV_ROUND_UP(enc->base.height, 64);
+
+   if (pic->num_slice_descriptors <= 1) {
+      num_ctbs_in_slice = num_ctbs_total;
+   } else {
+      bool use_app_config = true;
+      num_ctbs_in_slice = pic->slices_descriptors[0].num_ctu_in_slice;
+
+      /* All slices must have equal size */
+      for (unsigned i = 1; i < pic->num_slice_descriptors - 1; i++) {
+         if (num_ctbs_in_slice != pic->slices_descriptors[i].num_ctu_in_slice)
+            use_app_config = false;
+      }
+      /* Except last one can be smaller */
+      if (pic->slices_descriptors[pic->num_slice_descriptors - 1].num_ctu_in_slice > num_ctbs_in_slice)
+         use_app_config = false;
+
+      if (!use_app_config) {
+         assert(num_ctbs_total >= pic->num_slice_descriptors);
+         num_ctbs_in_slice =
+            (num_ctbs_total + pic->num_slice_descriptors - 1) / pic->num_slice_descriptors;
+      }
+   }
+
+   enc->enc_pic.hevc_slice_ctrl.slice_control_mode = RENC_UVD_SLICE_CONTROL_MODE_FIXED_CTBS;
+   enc->enc_pic.hevc_slice_ctrl.fixed_ctbs_per_slice.num_ctbs_per_slice =
+      num_ctbs_in_slice;
+   enc->enc_pic.hevc_slice_ctrl.fixed_ctbs_per_slice.num_ctbs_per_slice_segment =
+      num_ctbs_in_slice;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SLICE_CONTROL);
+   RADEON_ENC_CS(enc->enc_pic.hevc_slice_ctrl.slice_control_mode);
+   RADEON_ENC_CS(enc->enc_pic.hevc_slice_ctrl.fixed_ctbs_per_slice.num_ctbs_per_slice);
+   RADEON_ENC_CS(enc->enc_pic.hevc_slice_ctrl.fixed_ctbs_per_slice.num_ctbs_per_slice_segment);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_spec_misc_hevc(struct radeon_uvd_encoder *enc,
+                                          struct pipe_picture_desc *picture)
+{
+   struct pipe_h265_enc_picture_desc *pic = (struct pipe_h265_enc_picture_desc *)picture;
+   enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3 =
+      pic->seq.log2_min_luma_coding_block_size_minus3;
+   enc->enc_pic.hevc_spec_misc.amp_disabled = !pic->seq.amp_enabled_flag;
+   enc->enc_pic.hevc_spec_misc.strong_intra_smoothing_enabled =
+      pic->seq.strong_intra_smoothing_enabled_flag;
+   enc->enc_pic.hevc_spec_misc.constrained_intra_pred_flag = pic->pic.constrained_intra_pred_flag;
+   enc->enc_pic.hevc_spec_misc.cabac_init_flag = pic->slice.cabac_init_flag;
+   enc->enc_pic.hevc_spec_misc.half_pel_enabled = 1;
+   enc->enc_pic.hevc_spec_misc.quarter_pel_enabled = 1;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SPEC_MISC);
+   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3);
+   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.amp_disabled);
+   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.strong_intra_smoothing_enabled);
+   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.constrained_intra_pred_flag);
+   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.cabac_init_flag);
+   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.half_pel_enabled);
+   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.quarter_pel_enabled);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_rc_session_init(struct radeon_uvd_encoder *enc,
+                                           struct pipe_picture_desc *picture)
+{
+   struct pipe_h265_enc_picture_desc *pic = (struct pipe_h265_enc_picture_desc *)picture;
+   enc->enc_pic.rc_session_init.vbv_buffer_level = pic->rc[0].vbv_buf_lv;
+   switch (pic->rc[0].rate_ctrl_method) {
+   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_DISABLE:
+      enc->enc_pic.rc_session_init.rate_control_method = RENC_UVD_RATE_CONTROL_METHOD_NONE;
+      break;
+   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_CONSTANT_SKIP:
+   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_CONSTANT:
+      enc->enc_pic.rc_session_init.rate_control_method = RENC_UVD_RATE_CONTROL_METHOD_CBR;
+      break;
+   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_VARIABLE_SKIP:
+   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_VARIABLE:
+      enc->enc_pic.rc_session_init.rate_control_method =
+         RENC_UVD_RATE_CONTROL_METHOD_PEAK_CONSTRAINED_VBR;
+      break;
+   default:
+      enc->enc_pic.rc_session_init.rate_control_method = RENC_UVD_RATE_CONTROL_METHOD_NONE;
+   }
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_RATE_CONTROL_SESSION_INIT);
+   RADEON_ENC_CS(enc->enc_pic.rc_session_init.rate_control_method);
+   RADEON_ENC_CS(enc->enc_pic.rc_session_init.vbv_buffer_level);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_rc_layer_init(struct radeon_uvd_encoder *enc)
+{
+   uint32_t i = enc->enc_pic.layer_sel.temporal_layer_index;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_RATE_CONTROL_LAYER_INIT);
+   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].target_bit_rate);
+   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].peak_bit_rate);
+   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].frame_rate_num);
+   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].frame_rate_den);
+   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].vbv_buffer_size);
+   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].avg_target_bits_per_picture);
+   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].peak_bits_per_picture_integer);
+   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].peak_bits_per_picture_fractional);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_deblocking_filter_hevc(struct radeon_uvd_encoder *enc,
+                                                  struct pipe_picture_desc *picture)
+{
+   struct pipe_h265_enc_picture_desc *pic = (struct pipe_h265_enc_picture_desc *)picture;
+   enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled =
+      pic->pic.pps_loop_filter_across_slices_enabled_flag;
+   enc->enc_pic.hevc_deblock.deblocking_filter_disabled =
+      pic->slice.slice_deblocking_filter_disabled_flag;
+   enc->enc_pic.hevc_deblock.beta_offset_div2 = pic->slice.slice_beta_offset_div2;
+   enc->enc_pic.hevc_deblock.tc_offset_div2 = pic->slice.slice_tc_offset_div2;
+   enc->enc_pic.hevc_deblock.cb_qp_offset = pic->slice.slice_cb_qp_offset;
+   enc->enc_pic.hevc_deblock.cr_qp_offset = pic->slice.slice_cr_qp_offset;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_DEBLOCKING_FILTER);
+   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled);
+   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.deblocking_filter_disabled);
+   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.beta_offset_div2);
+   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.tc_offset_div2);
+   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.cb_qp_offset);
+   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.cr_qp_offset);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_quality_params(struct radeon_uvd_encoder *enc)
+{
+   enc->enc_pic.quality_params.scene_change_sensitivity = 0;
+   enc->enc_pic.quality_params.scene_change_min_idr_interval = 0;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_QUALITY_PARAMS);
+   RADEON_ENC_CS(enc->enc_pic.quality_params.vbaq_mode);
+   RADEON_ENC_CS(enc->enc_pic.quality_params.scene_change_sensitivity);
+   RADEON_ENC_CS(enc->enc_pic.quality_params.scene_change_min_idr_interval);
+   RADEON_ENC_END();
+}
+
+static unsigned int radeon_uvd_enc_write_sps(struct radeon_uvd_encoder *enc, uint8_t *out)
+{
+   struct radeon_bitstream bs;
+   struct pipe_h265_enc_seq_param *sps = &enc->enc_pic.desc->seq;
+   int i;
+
+   radeon_bs_reset(&bs, out, NULL);
+   radeon_bs_set_emulation_prevention(&bs, false);
+   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
+   radeon_bs_code_fixed_bits(&bs, 0x4201, 16);
+   radeon_bs_set_emulation_prevention(&bs, true);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 4); /* sps_video_parameter_set_id */
+   radeon_bs_code_fixed_bits(&bs, sps->sps_max_sub_layers_minus1, 3);
+   radeon_bs_code_fixed_bits(&bs, sps->sps_temporal_id_nesting_flag, 1);
+   radeon_bs_hevc_profile_tier_level(&bs, sps->sps_max_sub_layers_minus1, &sps->profile_tier_level);
+   radeon_bs_code_ue(&bs, 0x0); /* sps_seq_parameter_set_id */
+   radeon_bs_code_ue(&bs, sps->chroma_format_idc);
+   radeon_bs_code_ue(&bs, enc->enc_pic.session_init.aligned_picture_width);
+   radeon_bs_code_ue(&bs, enc->enc_pic.session_init.aligned_picture_height);
+
+   radeon_bs_code_fixed_bits(&bs, sps->conformance_window_flag, 1);
+   if (sps->conformance_window_flag) {
+      radeon_bs_code_ue(&bs, sps->conf_win_left_offset);
+      radeon_bs_code_ue(&bs, sps->conf_win_right_offset);
+      radeon_bs_code_ue(&bs, sps->conf_win_top_offset);
+      radeon_bs_code_ue(&bs, sps->conf_win_bottom_offset);
+   }
+
+   radeon_bs_code_ue(&bs, sps->bit_depth_luma_minus8);
+   radeon_bs_code_ue(&bs, sps->bit_depth_chroma_minus8);
+   radeon_bs_code_ue(&bs, sps->log2_max_pic_order_cnt_lsb_minus4);
+   radeon_bs_code_fixed_bits(&bs, sps->sps_sub_layer_ordering_info_present_flag, 1);
+   i = sps->sps_sub_layer_ordering_info_present_flag ? 0 : sps->sps_max_sub_layers_minus1;
+   for (; i <= sps->sps_max_sub_layers_minus1; i++) {
+      radeon_bs_code_ue(&bs, sps->sps_max_dec_pic_buffering_minus1[i]);
+      radeon_bs_code_ue(&bs, sps->sps_max_num_reorder_pics[i]);
+      radeon_bs_code_ue(&bs, sps->sps_max_latency_increase_plus1[i]);
+   }
+
+   unsigned log2_diff_max_min_luma_coding_block_size =
+      6 - (enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3 + 3);
+   unsigned log2_min_transform_block_size_minus2 =
+      enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3;
+   unsigned log2_diff_max_min_transform_block_size = log2_diff_max_min_luma_coding_block_size;
+   unsigned max_transform_hierarchy_depth_inter = log2_diff_max_min_luma_coding_block_size + 1;
+   unsigned max_transform_hierarchy_depth_intra = max_transform_hierarchy_depth_inter;
+
+   radeon_bs_code_ue(&bs, enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3);
+   radeon_bs_code_ue(&bs, log2_diff_max_min_luma_coding_block_size);
+   radeon_bs_code_ue(&bs, log2_min_transform_block_size_minus2);
+   radeon_bs_code_ue(&bs, log2_diff_max_min_transform_block_size);
+   radeon_bs_code_ue(&bs, max_transform_hierarchy_depth_inter);
+   radeon_bs_code_ue(&bs, max_transform_hierarchy_depth_intra);
+
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* scaling_list_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, !enc->enc_pic.hevc_spec_misc.amp_disabled, 1);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* sample_adaptive_offset_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* pcm_enabled_flag */
+
+   radeon_bs_code_ue(&bs, sps->num_short_term_ref_pic_sets);
+   for (i = 0; i < sps->num_short_term_ref_pic_sets; i++)
+      radeon_bs_hevc_st_ref_pic_set(&bs, i, sps->num_short_term_ref_pic_sets, sps->st_ref_pic_set);
+
+   radeon_bs_code_fixed_bits(&bs, sps->long_term_ref_pics_present_flag, 1);
+   if (sps->long_term_ref_pics_present_flag) {
+      radeon_bs_code_ue(&bs, sps->num_long_term_ref_pics_sps);
+      for (i = 0; i < sps->num_long_term_ref_pics_sps; i++) {
+         radeon_bs_code_fixed_bits(&bs, sps->lt_ref_pic_poc_lsb_sps[i], sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
+         radeon_bs_code_fixed_bits(&bs, sps->used_by_curr_pic_lt_sps_flag[i], 1);
+      }
+   }
+
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* sps_temporal_mvp_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_spec_misc.strong_intra_smoothing_enabled, 1);
+
+   /* VUI parameters present flag */
+   radeon_bs_code_fixed_bits(&bs, (sps->vui_parameters_present_flag), 1);
+   if (sps->vui_parameters_present_flag) {
+      /* aspect ratio present flag */
+      radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.aspect_ratio_info_present_flag), 1);
+      if (sps->vui_flags.aspect_ratio_info_present_flag) {
+         radeon_bs_code_fixed_bits(&bs, (sps->aspect_ratio_idc), 8);
+         if (sps->aspect_ratio_idc == PIPE_H2645_EXTENDED_SAR) {
+            radeon_bs_code_fixed_bits(&bs, (sps->sar_width), 16);
+            radeon_bs_code_fixed_bits(&bs, (sps->sar_height), 16);
+         }
+      }
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.overscan_info_present_flag, 1);
+      if (sps->vui_flags.overscan_info_present_flag)
+         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.overscan_appropriate_flag, 1);
+      /* video signal type present flag  */
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.video_signal_type_present_flag, 1);
+      if (sps->vui_flags.video_signal_type_present_flag) {
+         radeon_bs_code_fixed_bits(&bs, sps->video_format, 3);
+         radeon_bs_code_fixed_bits(&bs, sps->video_full_range_flag, 1);
+         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.colour_description_present_flag, 1);
+         if (sps->vui_flags.colour_description_present_flag) {
+            radeon_bs_code_fixed_bits(&bs, sps->colour_primaries, 8);
+            radeon_bs_code_fixed_bits(&bs, sps->transfer_characteristics, 8);
+            radeon_bs_code_fixed_bits(&bs, sps->matrix_coefficients, 8);
+         }
+      }
+      /* chroma loc info present flag */
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.chroma_loc_info_present_flag, 1);
+      if (sps->vui_flags.chroma_loc_info_present_flag) {
+         radeon_bs_code_ue(&bs, sps->chroma_sample_loc_type_top_field);
+         radeon_bs_code_ue(&bs, sps->chroma_sample_loc_type_bottom_field);
+      }
+      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* neutral chroma indication flag */
+      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* field seq flag */
+      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* frame field info present flag */
+      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* default display windows flag */
+      /* vui timing info present flag */
+      radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.timing_info_present_flag), 1);
+      if (sps->vui_flags.timing_info_present_flag) {
+         radeon_bs_code_fixed_bits(&bs, (sps->num_units_in_tick), 32);
+         radeon_bs_code_fixed_bits(&bs, (sps->time_scale), 32);
+         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.poc_proportional_to_timing_flag, 1);
+         if (sps->vui_flags.poc_proportional_to_timing_flag)
+            radeon_bs_code_ue(&bs, sps->num_ticks_poc_diff_one_minus1);
+         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.hrd_parameters_present_flag, 1);
+         if (sps->vui_flags.hrd_parameters_present_flag)
+            radeon_bs_hevc_hrd_parameters(&bs, 1, sps->sps_max_sub_layers_minus1, &sps->hrd_parameters);
+      }
+      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* bitstream restriction flag */
+   }
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* sps extension present flag */
+
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
+   radeon_bs_byte_align(&bs);
+
+   return bs.bits_output / 8;
+}
+
+static unsigned int radeon_uvd_enc_write_pps(struct radeon_uvd_encoder *enc, uint8_t *out)
+{
+   struct radeon_bitstream bs;
+   struct pipe_h265_enc_pic_param *pps = &enc->enc_pic.desc->pic;
+
+   radeon_bs_reset(&bs, out, NULL);
+   radeon_bs_set_emulation_prevention(&bs, false);
+   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
+   radeon_bs_code_fixed_bits(&bs, 0x4401, 16);
+   radeon_bs_set_emulation_prevention(&bs, true);
+   radeon_bs_code_ue(&bs, 0x0); /* pps_pic_parameter_set_id */
+   radeon_bs_code_ue(&bs, 0x0); /* pps_seq_parameter_set_id */
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* dependent_slice_segments_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, pps->output_flag_present_flag, 1);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 3); /* num_extra_slice_header_bits */
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* sign_data_hiding_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* cabac_init_present_flag */
+   radeon_bs_code_ue(&bs, pps->num_ref_idx_l0_default_active_minus1);
+   radeon_bs_code_ue(&bs, pps->num_ref_idx_l1_default_active_minus1);
+   radeon_bs_code_se(&bs, 0x0); /* init_qp_minus26 */
+   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_spec_misc.constrained_intra_pred_flag, 1);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* transform_skip_enabled */
+   bool cu_qp_delta_enabled_flag =
+      enc->enc_pic.rc_session_init.rate_control_method != RENC_UVD_RATE_CONTROL_METHOD_NONE;
+   radeon_bs_code_fixed_bits(&bs, cu_qp_delta_enabled_flag, 1);
+   if (cu_qp_delta_enabled_flag)
+      radeon_bs_code_ue(&bs, 0x0); /* diff_cu_qp_delta_depth */
+   radeon_bs_code_se(&bs, enc->enc_pic.hevc_deblock.cb_qp_offset);
+   radeon_bs_code_se(&bs, enc->enc_pic.hevc_deblock.cr_qp_offset);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* pps_slice_chroma_qp_offsets_present_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x0, 2); /* weighted_pred_flag + weighted_bipred_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* transquant_bypass_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* tiles_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* entropy_coding_sync_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled, 1);
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* deblocking_filter_control_present_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* deblocking_filter_override_enabled_flag */
+   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_deblock.deblocking_filter_disabled, 1);
+
+   if (!enc->enc_pic.hevc_deblock.deblocking_filter_disabled) {
+      radeon_bs_code_se(&bs, enc->enc_pic.hevc_deblock.beta_offset_div2);
+      radeon_bs_code_se(&bs, enc->enc_pic.hevc_deblock.tc_offset_div2);
+   }
+
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* pps_scaling_list_data_present_flag */
+   radeon_bs_code_fixed_bits(&bs, pps->lists_modification_present_flag, 1);
+   radeon_bs_code_ue(&bs, pps->log2_parallel_merge_level_minus2);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 2);
+
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
+   radeon_bs_byte_align(&bs);
+
+   return bs.bits_output / 8;
+}
+
+static unsigned int radeon_uvd_enc_write_vps(struct radeon_uvd_encoder *enc, uint8_t *out)
+{
+   struct radeon_bitstream bs;
+   struct pipe_h265_enc_vid_param *vps = &enc->enc_pic.desc->vid;
+   int i;
+
+   radeon_bs_reset(&bs, out, NULL);
+   radeon_bs_set_emulation_prevention(&bs, false);
+   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
+   radeon_bs_code_fixed_bits(&bs, 0x4001, 16);
+   radeon_bs_set_emulation_prevention(&bs, true);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 4); /* vps_video_parameter_set_id*/
+   radeon_bs_code_fixed_bits(&bs, vps->vps_base_layer_internal_flag, 1);
+   radeon_bs_code_fixed_bits(&bs, vps->vps_base_layer_available_flag, 1);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 6); /* vps_max_layers_minus1 */
+   radeon_bs_code_fixed_bits(&bs, vps->vps_max_sub_layers_minus1, 3);
+   radeon_bs_code_fixed_bits(&bs, vps->vps_temporal_id_nesting_flag, 1);
+   radeon_bs_code_fixed_bits(&bs, 0xffff, 16); /* vps_reserved_0xffff_16bits */
+   radeon_bs_hevc_profile_tier_level(&bs, vps->vps_max_sub_layers_minus1, &vps->profile_tier_level);
+   radeon_bs_code_fixed_bits(&bs, vps->vps_sub_layer_ordering_info_present_flag, 1);
+   i = vps->vps_sub_layer_ordering_info_present_flag ? 0 : vps->vps_max_sub_layers_minus1;
+   for (; i <= vps->vps_max_sub_layers_minus1; i++) {
+      radeon_bs_code_ue(&bs, vps->vps_max_dec_pic_buffering_minus1[i]);
+      radeon_bs_code_ue(&bs, vps->vps_max_num_reorder_pics[i]);
+      radeon_bs_code_ue(&bs, vps->vps_max_latency_increase_plus1[i]);
+   }
+   radeon_bs_code_fixed_bits(&bs, 0x0, 6); /* vps_max_layer_id */
+   radeon_bs_code_ue(&bs, 0x0); /* vps_num_layer_sets_minus1 */
+   radeon_bs_code_fixed_bits(&bs, vps->vps_timing_info_present_flag, 1);
+   if (vps->vps_timing_info_present_flag) {
+      radeon_bs_code_fixed_bits(&bs, vps->vps_num_units_in_tick, 32);
+      radeon_bs_code_fixed_bits(&bs, vps->vps_time_scale, 32);
+      radeon_bs_code_fixed_bits(&bs, vps->vps_poc_proportional_to_timing_flag, 1);
+      if (vps->vps_poc_proportional_to_timing_flag)
+         radeon_bs_code_ue(&bs, vps->vps_num_ticks_poc_diff_one_minus1);
+      radeon_bs_code_ue(&bs, 0x0); /* vps_num_hrd_parameters */
+   }
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* vps_extension_flag */
+
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
+   radeon_bs_byte_align(&bs);
+
+   return bs.bits_output / 8;
+}
+
+static void radeon_uvd_enc_slice_header_hevc(struct radeon_uvd_encoder *enc)
+{
+   struct radeon_bitstream bs;
+   struct pipe_h265_enc_seq_param *sps = &enc->enc_pic.desc->seq;
+   struct pipe_h265_enc_pic_param *pps = &enc->enc_pic.desc->pic;
+   struct pipe_h265_enc_slice_param *slice = &enc->enc_pic.desc->slice;
+   uint32_t instruction[RENC_UVD_SLICE_HEADER_TEMPLATE_MAX_NUM_INSTRUCTIONS] = {0};
+   uint32_t num_bits[RENC_UVD_SLICE_HEADER_TEMPLATE_MAX_NUM_INSTRUCTIONS] = {0};
+   unsigned int inst_index = 0;
+   unsigned int cdw_start = 0;
+   unsigned int cdw_filled = 0;
+   unsigned int bits_copied = 0;
+   unsigned int num_pic_total_curr = 0;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SLICE_HEADER);
+   radeon_bs_reset(&bs, NULL, &enc->cs);
+   radeon_bs_set_emulation_prevention(&bs, false);
+
+   cdw_start = enc->cs.current.cdw;
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1);
+   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.nal_unit_type, 6);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 6);
+   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.temporal_id + 1, 3);
+
+   radeon_bs_flush_headers(&bs);
+   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_COPY;
+   num_bits[inst_index] = bs.bits_output - bits_copied;
+   bits_copied = bs.bits_output;
+   inst_index++;
+
+   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_FIRST_SLICE;
+   inst_index++;
+
+   if ((enc->enc_pic.nal_unit_type >= 16) && (enc->enc_pic.nal_unit_type <= 23))
+      radeon_bs_code_fixed_bits(&bs, slice->no_output_of_prior_pics_flag, 1);
+
+   radeon_bs_code_ue(&bs, 0x0); /* slice_pic_parameter_set_id */
+
+   radeon_bs_flush_headers(&bs);
+   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_COPY;
+   num_bits[inst_index] = bs.bits_output - bits_copied;
+   bits_copied = bs.bits_output;
+   inst_index++;
+
+   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_SLICE_SEGMENT;
+   inst_index++;
+
+   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_DEPENDENT_SLICE_END;
+   inst_index++;
+
+   switch (enc->enc_pic.picture_type) {
+   case PIPE_H2645_ENC_PICTURE_TYPE_I:
+   case PIPE_H2645_ENC_PICTURE_TYPE_IDR:
+      radeon_bs_code_ue(&bs, 0x2);
+      break;
+   case PIPE_H2645_ENC_PICTURE_TYPE_P:
+   case PIPE_H2645_ENC_PICTURE_TYPE_SKIP:
+   default:
+      radeon_bs_code_ue(&bs, 0x1);
+      break;
+   }
+
+   if (pps->output_flag_present_flag)
+      radeon_bs_code_fixed_bits(&bs, slice->pic_output_flag, 1);
+
+   if ((enc->enc_pic.nal_unit_type != 19) && (enc->enc_pic.nal_unit_type != 20)) {
+      radeon_bs_code_fixed_bits(&bs, slice->slice_pic_order_cnt_lsb, sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
+      radeon_bs_code_fixed_bits(&bs, slice->short_term_ref_pic_set_sps_flag, 1);
+      if (!slice->short_term_ref_pic_set_sps_flag) {
+         num_pic_total_curr =
+            radeon_bs_hevc_st_ref_pic_set(&bs, sps->num_short_term_ref_pic_sets,
+                                          sps->num_short_term_ref_pic_sets, sps->st_ref_pic_set);
+      } else if (sps->num_short_term_ref_pic_sets > 1) {
+         radeon_bs_code_fixed_bits(&bs, slice->short_term_ref_pic_set_idx,
+                                    util_logbase2_ceil(sps->num_short_term_ref_pic_sets));
+      }
+      if (sps->long_term_ref_pics_present_flag) {
+         if (sps->num_long_term_ref_pics_sps > 0)
+            radeon_bs_code_ue(&bs, slice->num_long_term_sps);
+         radeon_bs_code_ue(&bs, slice->num_long_term_pics);
+         for (unsigned i = 0; i < slice->num_long_term_sps + slice->num_long_term_pics; i++) {
+            if (i < slice->num_long_term_sps) {
+               if (sps->num_long_term_ref_pics_sps > 1)
+                  radeon_bs_code_fixed_bits(&bs, slice->lt_idx_sps[i], util_logbase2_ceil(sps->num_long_term_ref_pics_sps));
+            } else {
+               radeon_bs_code_fixed_bits(&bs, slice->poc_lsb_lt[i], sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
+               radeon_bs_code_fixed_bits(&bs, slice->used_by_curr_pic_lt_flag[i], 1);
+               if (slice->used_by_curr_pic_lt_flag[i])
+                  num_pic_total_curr++;
+            }
+            radeon_bs_code_fixed_bits(&bs, slice->delta_poc_msb_present_flag[i], 1);
+            if (slice->delta_poc_msb_present_flag[i])
+               radeon_bs_code_ue(&bs, slice->delta_poc_msb_cycle_lt[i]);
+         }
+      }
+   }
+
+   if (enc->enc_pic.picture_type == PIPE_H2645_ENC_PICTURE_TYPE_P) {
+      radeon_bs_code_fixed_bits(&bs, slice->num_ref_idx_active_override_flag, 1);
+      if (slice->num_ref_idx_active_override_flag)
+         radeon_bs_code_ue(&bs, slice->num_ref_idx_l0_active_minus1);
+      if (pps->lists_modification_present_flag && num_pic_total_curr > 1) {
+         unsigned num_bits = util_logbase2_ceil(num_pic_total_curr);
+         unsigned num_ref_l0_minus1 = slice->num_ref_idx_active_override_flag ?
+            slice->num_ref_idx_l0_active_minus1 : pps->num_ref_idx_l0_default_active_minus1;
+         radeon_bs_code_fixed_bits(&bs, slice->ref_pic_lists_modification.ref_pic_list_modification_flag_l0, 1);
+         for (unsigned i = 0; i <= num_ref_l0_minus1; i++)
+            radeon_bs_code_fixed_bits(&bs, slice->ref_pic_lists_modification.list_entry_l0[i], num_bits);
+      }
+      radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_spec_misc.cabac_init_flag, 1);
+      radeon_bs_code_ue(&bs, 5 - slice->max_num_merge_cand);
+   }
+
+   radeon_bs_flush_headers(&bs);
+   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_COPY;
+   num_bits[inst_index] = bs.bits_output - bits_copied;
+   bits_copied = bs.bits_output;
+   inst_index++;
+
+   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_SLICE_QP_DELTA;
+   inst_index++;
+
+   if ((enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled) &&
+       (!enc->enc_pic.hevc_deblock.deblocking_filter_disabled)) {
+      radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled, 1);
+      radeon_bs_flush_headers(&bs);
+      instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_COPY;
+      num_bits[inst_index] = bs.bits_output - bits_copied;
+      bits_copied = bs.bits_output;
+      inst_index++;
+   }
+
+   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_END;
+
+   cdw_filled = enc->cs.current.cdw - cdw_start;
+   for (int i = 0; i < RENC_UVD_SLICE_HEADER_TEMPLATE_MAX_TEMPLATE_SIZE_IN_DWORDS - cdw_filled; i++)
+      RADEON_ENC_CS(0x00000000);
+
+   for (int j = 0; j < RENC_UVD_SLICE_HEADER_TEMPLATE_MAX_NUM_INSTRUCTIONS; j++) {
+      RADEON_ENC_CS(instruction[j]);
+      RADEON_ENC_CS(num_bits[j]);
+   }
+
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_ctx(struct radeon_uvd_encoder *enc)
+{
+   struct si_screen *sscreen = (struct si_screen *)enc->screen;
+
+   enc->enc_pic.ctx_buf.swizzle_mode = 0;
+   if (sscreen->info.gfx_level < GFX9) {
+      enc->enc_pic.ctx_buf.rec_luma_pitch = (enc->luma->u.legacy.level[0].nblk_x * enc->luma->bpe);
+      enc->enc_pic.ctx_buf.rec_chroma_pitch =
+         (enc->chroma->u.legacy.level[0].nblk_x * enc->chroma->bpe);
+   } else {
+      enc->enc_pic.ctx_buf.rec_luma_pitch = enc->luma->u.gfx9.surf_pitch * enc->luma->bpe;
+      enc->enc_pic.ctx_buf.rec_chroma_pitch = enc->chroma->u.gfx9.surf_pitch * enc->chroma->bpe;
+   }
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_ENCODE_CONTEXT_BUFFER);
+   RADEON_ENC_READWRITE(enc->dpb.res->buf, enc->dpb.res->domains, 0);
+   RADEON_ENC_CS(0x00000000); // reserved
+   RADEON_ENC_CS(enc->enc_pic.ctx_buf.swizzle_mode);
+   RADEON_ENC_CS(enc->enc_pic.ctx_buf.rec_luma_pitch);
+   RADEON_ENC_CS(enc->enc_pic.ctx_buf.rec_chroma_pitch);
+   RADEON_ENC_CS(enc->enc_pic.ctx_buf.num_reconstructed_pictures);
+   for (uint32_t i = 0; i < RENC_UVD_MAX_NUM_RECONSTRUCTED_PICTURES; i++) {
+      RADEON_ENC_CS(enc->enc_pic.ctx_buf.reconstructed_pictures[i].luma_offset);
+      RADEON_ENC_CS(enc->enc_pic.ctx_buf.reconstructed_pictures[i].chroma_offset);
+   }
+   RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_picture_luma_pitch);
+   RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_picture_chroma_pitch);
+   for (uint32_t i = 0; i < RENC_UVD_MAX_NUM_RECONSTRUCTED_PICTURES; i++) {
+      RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_reconstructed_pictures[i].luma_offset);
+      RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_reconstructed_pictures[i].chroma_offset);
+   }
+   RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_input_picture.luma_offset);
+   RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_input_picture.chroma_offset);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_bitstream(struct radeon_uvd_encoder *enc)
+{
+   enc->enc_pic.bit_buf.mode = RENC_UVD_SWIZZLE_MODE_LINEAR;
+   enc->enc_pic.bit_buf.video_bitstream_buffer_size = enc->bs_size;
+   enc->enc_pic.bit_buf.video_bitstream_data_offset = enc->bs_offset;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_VIDEO_BITSTREAM_BUFFER);
+   RADEON_ENC_CS(enc->enc_pic.bit_buf.mode);
+   RADEON_ENC_WRITE(enc->bs_handle, RADEON_DOMAIN_GTT, 0);
+   RADEON_ENC_CS(enc->enc_pic.bit_buf.video_bitstream_buffer_size);
+   RADEON_ENC_CS(enc->enc_pic.bit_buf.video_bitstream_data_offset);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_feedback(struct radeon_uvd_encoder *enc)
+{
+   enc->enc_pic.fb_buf.mode = RENC_UVD_FEEDBACK_BUFFER_MODE_LINEAR;
+   enc->enc_pic.fb_buf.feedback_buffer_size = 16;
+   enc->enc_pic.fb_buf.feedback_data_size = 40;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_FEEDBACK_BUFFER);
+   RADEON_ENC_CS(enc->enc_pic.fb_buf.mode);
+   RADEON_ENC_WRITE(enc->fb->res->buf, enc->fb->res->domains, 0x0);
+   RADEON_ENC_CS(enc->enc_pic.fb_buf.feedback_buffer_size);
+   RADEON_ENC_CS(enc->enc_pic.fb_buf.feedback_data_size);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_intra_refresh(struct radeon_uvd_encoder *enc)
+{
+   switch (enc->enc_pic.desc->intra_refresh.mode) {
+   case INTRA_REFRESH_MODE_UNIT_ROWS:
+      enc->enc_pic.intra_ref.intra_refresh_mode = RENC_UVD_INTRA_REFRESH_MODE_CTB_MB_ROWS;
+      break;
+   case INTRA_REFRESH_MODE_UNIT_COLUMNS:
+      enc->enc_pic.intra_ref.intra_refresh_mode = RENC_UVD_INTRA_REFRESH_MODE_CTB_MB_COLUMNS;
+      break;
+   default:
+      enc->enc_pic.intra_ref.intra_refresh_mode = RENC_UVD_INTRA_REFRESH_MODE_NONE;
+      break;
+   };
+
+   enc->enc_pic.intra_ref.offset = enc->enc_pic.desc->intra_refresh.offset;
+   enc->enc_pic.intra_ref.region_size = enc->enc_pic.desc->intra_refresh.region_size;
+
+   if (!enc->enc_pic.hevc_deblock.deblocking_filter_disabled)
+      enc->enc_pic.intra_ref.region_size++;
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_INTRA_REFRESH);
+   RADEON_ENC_CS(enc->enc_pic.intra_ref.intra_refresh_mode);
+   RADEON_ENC_CS(enc->enc_pic.intra_ref.offset);
+   RADEON_ENC_CS(enc->enc_pic.intra_ref.region_size);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_rc_per_pic(struct radeon_uvd_encoder *enc)
+{
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_RATE_CONTROL_PER_PICTURE);
+   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.qp);
+   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.min_qp_app);
+   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.max_qp_app);
+   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.max_au_size);
+   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.enabled_filler_data);
+   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.skip_frame_enable);
+   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.enforce_hrd);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_encode_params_hevc(struct radeon_uvd_encoder *enc)
+{
+   struct si_screen *sscreen = (struct si_screen *)enc->screen;
+   switch (enc->enc_pic.picture_type) {
+   case PIPE_H2645_ENC_PICTURE_TYPE_I:
+   case PIPE_H2645_ENC_PICTURE_TYPE_IDR:
+      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_I;
+      break;
+   case PIPE_H2645_ENC_PICTURE_TYPE_P:
+      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_P;
+      break;
+   case PIPE_H2645_ENC_PICTURE_TYPE_SKIP:
+      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_P_SKIP;
+      break;
+   case PIPE_H2645_ENC_PICTURE_TYPE_B:
+      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_B;
+      break;
+   default:
+      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_I;
+   }
+
+   enc->enc_pic.enc_params.allowed_max_bitstream_size = enc->bs_size - enc->bs_offset;
+   if (sscreen->info.gfx_level < GFX9) {
+      enc->enc_pic.enc_params.input_pic_luma_pitch =
+         (enc->luma->u.legacy.level[0].nblk_x * enc->luma->bpe);
+      enc->enc_pic.enc_params.input_pic_chroma_pitch =
+         (enc->chroma->u.legacy.level[0].nblk_x * enc->chroma->bpe);
+   } else {
+      enc->enc_pic.enc_params.input_pic_luma_pitch = enc->luma->u.gfx9.surf_pitch * enc->luma->bpe;
+      enc->enc_pic.enc_params.input_pic_chroma_pitch =
+         enc->chroma->u.gfx9.surf_pitch * enc->chroma->bpe;
+      enc->enc_pic.enc_params.input_pic_swizzle_mode = enc->luma->u.gfx9.swizzle_mode;
+   }
+
+   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_ENCODE_PARAMS);
+   RADEON_ENC_CS(enc->enc_pic.enc_params.pic_type);
+   RADEON_ENC_CS(enc->enc_pic.enc_params.allowed_max_bitstream_size);
+
+   if (sscreen->info.gfx_level < GFX9) {
+      RADEON_ENC_READ(enc->handle, RADEON_DOMAIN_VRAM, (uint64_t)enc->luma->u.legacy.level[0].offset_256B * 256);
+      RADEON_ENC_READ(enc->handle, RADEON_DOMAIN_VRAM, (uint64_t)enc->chroma->u.legacy.level[0].offset_256B * 256);
+   } else {
+      RADEON_ENC_READ(enc->handle, RADEON_DOMAIN_VRAM, enc->luma->u.gfx9.surf_offset);
+      RADEON_ENC_READ(enc->handle, RADEON_DOMAIN_VRAM, enc->chroma->u.gfx9.surf_offset);
+   }
+   RADEON_ENC_CS(enc->enc_pic.enc_params.input_pic_luma_pitch);
+   RADEON_ENC_CS(enc->enc_pic.enc_params.input_pic_chroma_pitch);
+   RADEON_ENC_CS(enc->enc_pic.enc_params.input_pic_addr_mode);
+   RADEON_ENC_CS(enc->enc_pic.enc_params.input_pic_swizzle_mode);
+   RADEON_ENC_CS(enc->enc_pic.enc_params.reference_picture_index);
+   RADEON_ENC_CS(enc->enc_pic.enc_params.reconstructed_picture_index);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_op_init(struct radeon_uvd_encoder *enc)
+{
+   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_INITIALIZE);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_op_close(struct radeon_uvd_encoder *enc)
+{
+   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_CLOSE_SESSION);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_op_enc(struct radeon_uvd_encoder *enc)
+{
+   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_ENCODE);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_op_init_rc(struct radeon_uvd_encoder *enc)
+{
+   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_INIT_RC);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_op_init_rc_vbv(struct radeon_uvd_encoder *enc)
+{
+   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_INIT_RC_VBV_BUFFER_LEVEL);
+   RADEON_ENC_END();
+}
+
+static void radeon_uvd_enc_op_preset(struct radeon_uvd_encoder *enc)
+{
+   uint32_t preset_mode;
+
+   switch (enc->enc_pic.desc->quality_modes.preset_mode) {
+   case 0: /* SPEED */
+      preset_mode = RENC_UVD_IB_OP_SET_SPEED_ENCODING_MODE;
+      break;
+   case 1: /* BALANCED */
+      preset_mode = RENC_UVD_IB_OP_SET_BALANCE_ENCODING_MODE;
+      break;
+   case 2: /* QUALITY */
+   default:
+      preset_mode = RENC_UVD_IB_OP_SET_QUALITY_ENCODING_MODE;
+      break;
+   }
+
+   RADEON_ENC_BEGIN(preset_mode);
+   RADEON_ENC_END();
+}
+
+static void begin(struct radeon_uvd_encoder *enc, struct pipe_picture_desc *pic)
+{
+   radeon_uvd_enc_session_info(enc);
+   enc->total_task_size = 0;
+   radeon_uvd_enc_task_info(enc, enc->need_feedback);
+   radeon_uvd_enc_op_init(enc);
+
+   radeon_uvd_enc_session_init_hevc(enc);
+   radeon_uvd_enc_slice_control_hevc(enc, pic);
+   radeon_uvd_enc_spec_misc_hevc(enc, pic);
+   radeon_uvd_enc_deblocking_filter_hevc(enc, pic);
+
+   radeon_uvd_enc_layer_control(enc);
+   radeon_uvd_enc_rc_session_init(enc, pic);
+   radeon_uvd_enc_quality_params(enc);
+
+   for (uint32_t i = 0; i < enc->enc_pic.layer_ctrl.num_temporal_layers; i++) {
+      enc->enc_pic.layer_sel.temporal_layer_index = i;
+      radeon_uvd_enc_layer_select(enc);
+      radeon_uvd_enc_rc_layer_init(enc);
+      radeon_uvd_enc_layer_select(enc);
+      radeon_uvd_enc_rc_per_pic(enc);
+   }
+
+   radeon_uvd_enc_op_init_rc(enc);
+   radeon_uvd_enc_op_init_rc_vbv(enc);
+   *enc->p_task_size = (enc->total_task_size);
+}
+
+static void encode(struct radeon_uvd_encoder *enc)
+{
+   radeon_uvd_enc_session_info(enc);
+   enc->total_task_size = 0;
+   radeon_uvd_enc_task_info(enc, enc->need_feedback);
+
+   if (enc->need_rate_control || enc->need_rc_per_pic) {
+      for (uint32_t i = 0; i < enc->enc_pic.layer_ctrl.num_temporal_layers; i++) {
+         enc->enc_pic.layer_sel.temporal_layer_index = i;
+         radeon_uvd_enc_layer_select(enc);
+         if (enc->need_rate_control)
+            radeon_uvd_enc_rc_layer_init(enc);
+         if (enc->need_rc_per_pic)
+            radeon_uvd_enc_rc_per_pic(enc);
+      }
+   }
+
+   enc->enc_pic.layer_sel.temporal_layer_index = enc->enc_pic.temporal_id;
+   radeon_uvd_enc_layer_select(enc);
+
+   radeon_uvd_enc_slice_header_hevc(enc);
+   radeon_uvd_enc_encode_params_hevc(enc);
+
+   radeon_uvd_enc_ctx(enc);
+   radeon_uvd_enc_bitstream(enc);
+   radeon_uvd_enc_feedback(enc);
+   radeon_uvd_enc_intra_refresh(enc);
+
+   radeon_uvd_enc_op_preset(enc);
+   radeon_uvd_enc_op_enc(enc);
+   *enc->p_task_size = (enc->total_task_size);
+}
+
+static void destroy(struct radeon_uvd_encoder *enc)
+{
+   radeon_uvd_enc_session_info(enc);
+   enc->total_task_size = 0;
+   radeon_uvd_enc_task_info(enc, enc->need_feedback);
+   radeon_uvd_enc_op_close(enc);
+   *enc->p_task_size = (enc->total_task_size);
+}
+
 static void radeon_uvd_enc_get_param(struct radeon_uvd_encoder *enc,
                                      struct pipe_h265_enc_picture_desc *pic)
 {
@@ -174,7 +1095,7 @@ static void radeon_uvd_enc_begin_frame(struct pipe_video_codec *encoder,
       si_vid_create_buffer(enc->screen, enc->si, 128 * 1024, PIPE_USAGE_DEFAULT);
       si_vid_create_buffer(enc->screen, &fb, 4096, PIPE_USAGE_STAGING);
       enc->fb = &fb;
-      enc->begin(enc, picture);
+      begin(enc, picture);
       flush(enc, PIPE_FLUSH_ASYNC, NULL);
       si_vid_destroy_buffer(&fb);
    }
@@ -272,7 +1193,7 @@ static void radeon_uvd_enc_encode_bitstream(struct pipe_video_codec *encoder,
    enc->fb->user_data = radeon_uvd_enc_encode_headers(enc);
 
    enc->need_feedback = true;
-   enc->encode(enc);
+   encode(enc);
 }
 
 static int radeon_uvd_enc_end_frame(struct pipe_video_codec *encoder,
@@ -292,7 +1213,7 @@ static void radeon_uvd_enc_destroy(struct pipe_video_codec *encoder)
       enc->need_feedback = false;
       si_vid_create_buffer(enc->screen, &fb, 512, PIPE_USAGE_STAGING);
       enc->fb = &fb;
-      enc->destroy(enc);
+      destroy(enc);
       flush(enc, PIPE_FLUSH_ASYNC, NULL);
       if (enc->si) {
          si_vid_destroy_buffer(enc->si);
@@ -406,8 +1327,6 @@ struct pipe_video_codec *radeon_uvd_create_encoder(struct pipe_context *context,
       goto error;
    }
 
-   radeon_uvd_enc_1_1_init(enc);
-
    return &enc->base;
 
 error:
diff --git a/src/gallium/drivers/radeonsi/radeon_uvd_enc.h b/src/gallium/drivers/radeonsi/radeon_uvd_enc.h
index a39adbda652..be2a33ba2df 100644
--- a/src/gallium/drivers/radeonsi/radeon_uvd_enc.h
+++ b/src/gallium/drivers/radeonsi/radeon_uvd_enc.h
@@ -338,10 +338,6 @@ struct radeon_uvd_enc_pic {
 struct radeon_uvd_encoder {
    struct pipe_video_codec base;
 
-   void (*begin)(struct radeon_uvd_encoder *enc, struct pipe_picture_desc *pic);
-   void (*encode)(struct radeon_uvd_encoder *enc);
-   void (*destroy)(struct radeon_uvd_encoder *enc);
-
    unsigned stream_handle;
 
    struct pipe_screen *screen;
@@ -387,11 +383,6 @@ struct ruvd_enc_feedback_data {
 
 struct si_screen;
 
-void radeon_uvd_enc_1_1_init(struct radeon_uvd_encoder *enc);
 bool si_radeon_uvd_enc_supported(struct si_screen *sscreen);
 
-unsigned int radeon_uvd_enc_write_vps(struct radeon_uvd_encoder *enc, uint8_t *out);
-unsigned int radeon_uvd_enc_write_sps(struct radeon_uvd_encoder *enc, uint8_t *out);
-unsigned int radeon_uvd_enc_write_pps(struct radeon_uvd_encoder *enc, uint8_t *out);
-
 #endif // _RADEON_UVD_ENC_H
diff --git a/src/gallium/drivers/radeonsi/radeon_uvd_enc_1_1.c b/src/gallium/drivers/radeonsi/radeon_uvd_enc_1_1.c
deleted file mode 100644
index 12921287f5c..00000000000
--- a/src/gallium/drivers/radeonsi/radeon_uvd_enc_1_1.c
+++ /dev/null
@@ -1,945 +0,0 @@
-/**************************************************************************
- *
- * Copyright 2018 Advanced Micro Devices, Inc.
- *
- * SPDX-License-Identifier: MIT
- *
- **************************************************************************/
-
-#include "pipe/p_video_codec.h"
-#include "radeon_uvd_enc.h"
-#include "radeon_video.h"
-#include "radeon_bitstream.h"
-#include "radeonsi/si_pipe.h"
-#include "util/u_memory.h"
-#include "util/u_video.h"
-#include "vl/vl_video_buffer.h"
-
-#include <stdio.h>
-
-#define RADEON_ENC_CS(value) (enc->cs.current.buf[enc->cs.current.cdw++] = (value))
-#define RADEON_ENC_BEGIN(cmd)                                                                      \
-   {                                                                                               \
-      uint32_t *begin = &enc->cs.current.buf[enc->cs.current.cdw++];                             \
-      RADEON_ENC_CS(cmd)
-#define RADEON_ENC_READ(buf, domain, off)                                                          \
-   radeon_uvd_enc_add_buffer(enc, (buf), RADEON_USAGE_READ, (domain), (off))
-#define RADEON_ENC_WRITE(buf, domain, off)                                                         \
-   radeon_uvd_enc_add_buffer(enc, (buf), RADEON_USAGE_WRITE, (domain), (off))
-#define RADEON_ENC_READWRITE(buf, domain, off)                                                     \
-   radeon_uvd_enc_add_buffer(enc, (buf), RADEON_USAGE_READWRITE, (domain), (off))
-#define RADEON_ENC_END()                                                                           \
-   *begin = (&enc->cs.current.buf[enc->cs.current.cdw] - begin) * 4;                             \
-   enc->total_task_size += *begin;                                                                 \
-   }
-
-static void radeon_uvd_enc_add_buffer(struct radeon_uvd_encoder *enc, struct pb_buffer_lean *buf,
-                                      unsigned usage, enum radeon_bo_domain domain,
-                                      signed offset)
-{
-   enc->ws->cs_add_buffer(&enc->cs, buf, usage | RADEON_USAGE_SYNCHRONIZED, domain);
-   uint64_t addr;
-   addr = enc->ws->buffer_get_virtual_address(buf);
-   addr = addr + offset;
-   RADEON_ENC_CS(addr >> 32);
-   RADEON_ENC_CS(addr);
-}
-
-static void radeon_uvd_enc_session_info(struct radeon_uvd_encoder *enc)
-{
-   unsigned int interface_version =
-      ((RENC_UVD_FW_INTERFACE_MAJOR_VERSION << RENC_UVD_IF_MAJOR_VERSION_SHIFT) |
-       (RENC_UVD_FW_INTERFACE_MINOR_VERSION << RENC_UVD_IF_MINOR_VERSION_SHIFT));
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SESSION_INFO);
-   RADEON_ENC_CS(0x00000000); // reserved
-   RADEON_ENC_CS(interface_version);
-   RADEON_ENC_READWRITE(enc->si->res->buf, enc->si->res->domains, 0x0);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_task_info(struct radeon_uvd_encoder *enc, bool need_feedback)
-{
-   enc->enc_pic.task_info.task_id++;
-
-   if (need_feedback)
-      enc->enc_pic.task_info.allowed_max_num_feedbacks = 1;
-   else
-      enc->enc_pic.task_info.allowed_max_num_feedbacks = 0;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_TASK_INFO);
-   enc->p_task_size = &enc->cs.current.buf[enc->cs.current.cdw++];
-   RADEON_ENC_CS(enc->enc_pic.task_info.task_id);
-   RADEON_ENC_CS(enc->enc_pic.task_info.allowed_max_num_feedbacks);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_session_init_hevc(struct radeon_uvd_encoder *enc)
-{
-   uint32_t padding_width = 0;
-   uint32_t padding_height = 0;
-   uint32_t max_padding_width = 64 - 2;
-   uint32_t max_padding_height = 16 - 2;
-
-   enc->enc_pic.session_init.aligned_picture_width = align(enc->base.width, 64);
-   enc->enc_pic.session_init.aligned_picture_height = align(enc->base.height, 16);
-
-   if (enc->enc_pic.session_init.aligned_picture_width > enc->source->width)
-      padding_width = enc->enc_pic.session_init.aligned_picture_width - enc->source->width;
-   if (enc->enc_pic.session_init.aligned_picture_height > enc->source->height)
-      padding_height = enc->enc_pic.session_init.aligned_picture_height - enc->source->height;
-
-   /* Input surface can be smaller if the difference is within padding bounds. */
-   if (padding_width > max_padding_width || padding_height > max_padding_height)
-      RVID_ERR("Input surface size doesn't match aligned size\n");
-
-   if (enc->enc_pic.desc->seq.conformance_window_flag) {
-      uint32_t pad_w =
-         (enc->enc_pic.desc->seq.conf_win_left_offset + enc->enc_pic.desc->seq.conf_win_right_offset) * 2;
-      uint32_t pad_h =
-         (enc->enc_pic.desc->seq.conf_win_top_offset + enc->enc_pic.desc->seq.conf_win_bottom_offset) * 2;
-      padding_width = CLAMP(pad_w, padding_width, max_padding_width);
-      padding_height = CLAMP(pad_h, padding_height, max_padding_height);
-   }
-
-   enc->enc_pic.session_init.padding_width = padding_width;
-   enc->enc_pic.session_init.padding_height = padding_height;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SESSION_INIT);
-   RADEON_ENC_CS(enc->enc_pic.session_init.aligned_picture_width);
-   RADEON_ENC_CS(enc->enc_pic.session_init.aligned_picture_height);
-   RADEON_ENC_CS(enc->enc_pic.session_init.padding_width);
-   RADEON_ENC_CS(enc->enc_pic.session_init.padding_height);
-   RADEON_ENC_CS(enc->enc_pic.session_init.pre_encode_mode);
-   RADEON_ENC_CS(enc->enc_pic.session_init.pre_encode_chroma_enabled);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_layer_control(struct radeon_uvd_encoder *enc)
-{
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_LAYER_CONTROL);
-   RADEON_ENC_CS(enc->enc_pic.layer_ctrl.max_num_temporal_layers);
-   RADEON_ENC_CS(enc->enc_pic.layer_ctrl.num_temporal_layers);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_layer_select(struct radeon_uvd_encoder *enc)
-{
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_LAYER_SELECT);
-   RADEON_ENC_CS(enc->enc_pic.layer_sel.temporal_layer_index);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_slice_control_hevc(struct radeon_uvd_encoder *enc,
-                                              struct pipe_picture_desc *picture)
-{
-   struct pipe_h265_enc_picture_desc *pic = (struct pipe_h265_enc_picture_desc *)picture;
-   uint32_t num_ctbs_total, num_ctbs_in_slice;
-
-   num_ctbs_total =
-      DIV_ROUND_UP(enc->base.width, 64) * DIV_ROUND_UP(enc->base.height, 64);
-
-   if (pic->num_slice_descriptors <= 1) {
-      num_ctbs_in_slice = num_ctbs_total;
-   } else {
-      bool use_app_config = true;
-      num_ctbs_in_slice = pic->slices_descriptors[0].num_ctu_in_slice;
-
-      /* All slices must have equal size */
-      for (unsigned i = 1; i < pic->num_slice_descriptors - 1; i++) {
-         if (num_ctbs_in_slice != pic->slices_descriptors[i].num_ctu_in_slice)
-            use_app_config = false;
-      }
-      /* Except last one can be smaller */
-      if (pic->slices_descriptors[pic->num_slice_descriptors - 1].num_ctu_in_slice > num_ctbs_in_slice)
-         use_app_config = false;
-
-      if (!use_app_config) {
-         assert(num_ctbs_total >= pic->num_slice_descriptors);
-         num_ctbs_in_slice =
-            (num_ctbs_total + pic->num_slice_descriptors - 1) / pic->num_slice_descriptors;
-      }
-   }
-
-   enc->enc_pic.hevc_slice_ctrl.slice_control_mode = RENC_UVD_SLICE_CONTROL_MODE_FIXED_CTBS;
-   enc->enc_pic.hevc_slice_ctrl.fixed_ctbs_per_slice.num_ctbs_per_slice =
-      num_ctbs_in_slice;
-   enc->enc_pic.hevc_slice_ctrl.fixed_ctbs_per_slice.num_ctbs_per_slice_segment =
-      num_ctbs_in_slice;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SLICE_CONTROL);
-   RADEON_ENC_CS(enc->enc_pic.hevc_slice_ctrl.slice_control_mode);
-   RADEON_ENC_CS(enc->enc_pic.hevc_slice_ctrl.fixed_ctbs_per_slice.num_ctbs_per_slice);
-   RADEON_ENC_CS(enc->enc_pic.hevc_slice_ctrl.fixed_ctbs_per_slice.num_ctbs_per_slice_segment);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_spec_misc_hevc(struct radeon_uvd_encoder *enc,
-                                          struct pipe_picture_desc *picture)
-{
-   struct pipe_h265_enc_picture_desc *pic = (struct pipe_h265_enc_picture_desc *)picture;
-   enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3 =
-      pic->seq.log2_min_luma_coding_block_size_minus3;
-   enc->enc_pic.hevc_spec_misc.amp_disabled = !pic->seq.amp_enabled_flag;
-   enc->enc_pic.hevc_spec_misc.strong_intra_smoothing_enabled =
-      pic->seq.strong_intra_smoothing_enabled_flag;
-   enc->enc_pic.hevc_spec_misc.constrained_intra_pred_flag = pic->pic.constrained_intra_pred_flag;
-   enc->enc_pic.hevc_spec_misc.cabac_init_flag = pic->slice.cabac_init_flag;
-   enc->enc_pic.hevc_spec_misc.half_pel_enabled = 1;
-   enc->enc_pic.hevc_spec_misc.quarter_pel_enabled = 1;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SPEC_MISC);
-   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3);
-   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.amp_disabled);
-   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.strong_intra_smoothing_enabled);
-   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.constrained_intra_pred_flag);
-   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.cabac_init_flag);
-   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.half_pel_enabled);
-   RADEON_ENC_CS(enc->enc_pic.hevc_spec_misc.quarter_pel_enabled);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_rc_session_init(struct radeon_uvd_encoder *enc,
-                                           struct pipe_picture_desc *picture)
-{
-   struct pipe_h265_enc_picture_desc *pic = (struct pipe_h265_enc_picture_desc *)picture;
-   enc->enc_pic.rc_session_init.vbv_buffer_level = pic->rc[0].vbv_buf_lv;
-   switch (pic->rc[0].rate_ctrl_method) {
-   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_DISABLE:
-      enc->enc_pic.rc_session_init.rate_control_method = RENC_UVD_RATE_CONTROL_METHOD_NONE;
-      break;
-   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_CONSTANT_SKIP:
-   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_CONSTANT:
-      enc->enc_pic.rc_session_init.rate_control_method = RENC_UVD_RATE_CONTROL_METHOD_CBR;
-      break;
-   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_VARIABLE_SKIP:
-   case PIPE_H2645_ENC_RATE_CONTROL_METHOD_VARIABLE:
-      enc->enc_pic.rc_session_init.rate_control_method =
-         RENC_UVD_RATE_CONTROL_METHOD_PEAK_CONSTRAINED_VBR;
-      break;
-   default:
-      enc->enc_pic.rc_session_init.rate_control_method = RENC_UVD_RATE_CONTROL_METHOD_NONE;
-   }
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_RATE_CONTROL_SESSION_INIT);
-   RADEON_ENC_CS(enc->enc_pic.rc_session_init.rate_control_method);
-   RADEON_ENC_CS(enc->enc_pic.rc_session_init.vbv_buffer_level);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_rc_layer_init(struct radeon_uvd_encoder *enc)
-{
-   uint32_t i = enc->enc_pic.layer_sel.temporal_layer_index;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_RATE_CONTROL_LAYER_INIT);
-   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].target_bit_rate);
-   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].peak_bit_rate);
-   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].frame_rate_num);
-   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].frame_rate_den);
-   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].vbv_buffer_size);
-   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].avg_target_bits_per_picture);
-   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].peak_bits_per_picture_integer);
-   RADEON_ENC_CS(enc->enc_pic.rc_layer_init[i].peak_bits_per_picture_fractional);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_deblocking_filter_hevc(struct radeon_uvd_encoder *enc,
-                                                  struct pipe_picture_desc *picture)
-{
-   struct pipe_h265_enc_picture_desc *pic = (struct pipe_h265_enc_picture_desc *)picture;
-   enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled =
-      pic->pic.pps_loop_filter_across_slices_enabled_flag;
-   enc->enc_pic.hevc_deblock.deblocking_filter_disabled =
-      pic->slice.slice_deblocking_filter_disabled_flag;
-   enc->enc_pic.hevc_deblock.beta_offset_div2 = pic->slice.slice_beta_offset_div2;
-   enc->enc_pic.hevc_deblock.tc_offset_div2 = pic->slice.slice_tc_offset_div2;
-   enc->enc_pic.hevc_deblock.cb_qp_offset = pic->slice.slice_cb_qp_offset;
-   enc->enc_pic.hevc_deblock.cr_qp_offset = pic->slice.slice_cr_qp_offset;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_DEBLOCKING_FILTER);
-   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled);
-   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.deblocking_filter_disabled);
-   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.beta_offset_div2);
-   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.tc_offset_div2);
-   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.cb_qp_offset);
-   RADEON_ENC_CS(enc->enc_pic.hevc_deblock.cr_qp_offset);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_quality_params(struct radeon_uvd_encoder *enc)
-{
-   enc->enc_pic.quality_params.scene_change_sensitivity = 0;
-   enc->enc_pic.quality_params.scene_change_min_idr_interval = 0;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_QUALITY_PARAMS);
-   RADEON_ENC_CS(enc->enc_pic.quality_params.vbaq_mode);
-   RADEON_ENC_CS(enc->enc_pic.quality_params.scene_change_sensitivity);
-   RADEON_ENC_CS(enc->enc_pic.quality_params.scene_change_min_idr_interval);
-   RADEON_ENC_END();
-}
-
-unsigned int radeon_uvd_enc_write_sps(struct radeon_uvd_encoder *enc, uint8_t *out)
-{
-   struct radeon_bitstream bs;
-   struct pipe_h265_enc_seq_param *sps = &enc->enc_pic.desc->seq;
-   int i;
-
-   radeon_bs_reset(&bs, out, NULL);
-   radeon_bs_set_emulation_prevention(&bs, false);
-   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
-   radeon_bs_code_fixed_bits(&bs, 0x4201, 16);
-   radeon_bs_set_emulation_prevention(&bs, true);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 4); /* sps_video_parameter_set_id */
-   radeon_bs_code_fixed_bits(&bs, sps->sps_max_sub_layers_minus1, 3);
-   radeon_bs_code_fixed_bits(&bs, sps->sps_temporal_id_nesting_flag, 1);
-   radeon_bs_hevc_profile_tier_level(&bs, sps->sps_max_sub_layers_minus1, &sps->profile_tier_level);
-   radeon_bs_code_ue(&bs, 0x0); /* sps_seq_parameter_set_id */
-   radeon_bs_code_ue(&bs, sps->chroma_format_idc);
-   radeon_bs_code_ue(&bs, enc->enc_pic.session_init.aligned_picture_width);
-   radeon_bs_code_ue(&bs, enc->enc_pic.session_init.aligned_picture_height);
-
-   radeon_bs_code_fixed_bits(&bs, sps->conformance_window_flag, 1);
-   if (sps->conformance_window_flag) {
-      radeon_bs_code_ue(&bs, sps->conf_win_left_offset);
-      radeon_bs_code_ue(&bs, sps->conf_win_right_offset);
-      radeon_bs_code_ue(&bs, sps->conf_win_top_offset);
-      radeon_bs_code_ue(&bs, sps->conf_win_bottom_offset);
-   }
-
-   radeon_bs_code_ue(&bs, sps->bit_depth_luma_minus8);
-   radeon_bs_code_ue(&bs, sps->bit_depth_chroma_minus8);
-   radeon_bs_code_ue(&bs, sps->log2_max_pic_order_cnt_lsb_minus4);
-   radeon_bs_code_fixed_bits(&bs, sps->sps_sub_layer_ordering_info_present_flag, 1);
-   i = sps->sps_sub_layer_ordering_info_present_flag ? 0 : sps->sps_max_sub_layers_minus1;
-   for (; i <= sps->sps_max_sub_layers_minus1; i++) {
-      radeon_bs_code_ue(&bs, sps->sps_max_dec_pic_buffering_minus1[i]);
-      radeon_bs_code_ue(&bs, sps->sps_max_num_reorder_pics[i]);
-      radeon_bs_code_ue(&bs, sps->sps_max_latency_increase_plus1[i]);
-   }
-
-   unsigned log2_diff_max_min_luma_coding_block_size =
-      6 - (enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3 + 3);
-   unsigned log2_min_transform_block_size_minus2 =
-      enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3;
-   unsigned log2_diff_max_min_transform_block_size = log2_diff_max_min_luma_coding_block_size;
-   unsigned max_transform_hierarchy_depth_inter = log2_diff_max_min_luma_coding_block_size + 1;
-   unsigned max_transform_hierarchy_depth_intra = max_transform_hierarchy_depth_inter;
-
-   radeon_bs_code_ue(&bs, enc->enc_pic.hevc_spec_misc.log2_min_luma_coding_block_size_minus3);
-   radeon_bs_code_ue(&bs, log2_diff_max_min_luma_coding_block_size);
-   radeon_bs_code_ue(&bs, log2_min_transform_block_size_minus2);
-   radeon_bs_code_ue(&bs, log2_diff_max_min_transform_block_size);
-   radeon_bs_code_ue(&bs, max_transform_hierarchy_depth_inter);
-   radeon_bs_code_ue(&bs, max_transform_hierarchy_depth_intra);
-
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* scaling_list_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, !enc->enc_pic.hevc_spec_misc.amp_disabled, 1);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* sample_adaptive_offset_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* pcm_enabled_flag */
-
-   radeon_bs_code_ue(&bs, sps->num_short_term_ref_pic_sets);
-   for (i = 0; i < sps->num_short_term_ref_pic_sets; i++)
-      radeon_bs_hevc_st_ref_pic_set(&bs, i, sps->num_short_term_ref_pic_sets, sps->st_ref_pic_set);
-
-   radeon_bs_code_fixed_bits(&bs, sps->long_term_ref_pics_present_flag, 1);
-   if (sps->long_term_ref_pics_present_flag) {
-      radeon_bs_code_ue(&bs, sps->num_long_term_ref_pics_sps);
-      for (i = 0; i < sps->num_long_term_ref_pics_sps; i++) {
-         radeon_bs_code_fixed_bits(&bs, sps->lt_ref_pic_poc_lsb_sps[i], sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
-         radeon_bs_code_fixed_bits(&bs, sps->used_by_curr_pic_lt_sps_flag[i], 1);
-      }
-   }
-
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* sps_temporal_mvp_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_spec_misc.strong_intra_smoothing_enabled, 1);
-
-   /* VUI parameters present flag */
-   radeon_bs_code_fixed_bits(&bs, (sps->vui_parameters_present_flag), 1);
-   if (sps->vui_parameters_present_flag) {
-      /* aspect ratio present flag */
-      radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.aspect_ratio_info_present_flag), 1);
-      if (sps->vui_flags.aspect_ratio_info_present_flag) {
-         radeon_bs_code_fixed_bits(&bs, (sps->aspect_ratio_idc), 8);
-         if (sps->aspect_ratio_idc == PIPE_H2645_EXTENDED_SAR) {
-            radeon_bs_code_fixed_bits(&bs, (sps->sar_width), 16);
-            radeon_bs_code_fixed_bits(&bs, (sps->sar_height), 16);
-         }
-      }
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.overscan_info_present_flag, 1);
-      if (sps->vui_flags.overscan_info_present_flag)
-         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.overscan_appropriate_flag, 1);
-      /* video signal type present flag  */
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.video_signal_type_present_flag, 1);
-      if (sps->vui_flags.video_signal_type_present_flag) {
-         radeon_bs_code_fixed_bits(&bs, sps->video_format, 3);
-         radeon_bs_code_fixed_bits(&bs, sps->video_full_range_flag, 1);
-         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.colour_description_present_flag, 1);
-         if (sps->vui_flags.colour_description_present_flag) {
-            radeon_bs_code_fixed_bits(&bs, sps->colour_primaries, 8);
-            radeon_bs_code_fixed_bits(&bs, sps->transfer_characteristics, 8);
-            radeon_bs_code_fixed_bits(&bs, sps->matrix_coefficients, 8);
-         }
-      }
-      /* chroma loc info present flag */
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.chroma_loc_info_present_flag, 1);
-      if (sps->vui_flags.chroma_loc_info_present_flag) {
-         radeon_bs_code_ue(&bs, sps->chroma_sample_loc_type_top_field);
-         radeon_bs_code_ue(&bs, sps->chroma_sample_loc_type_bottom_field);
-      }
-      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* neutral chroma indication flag */
-      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* field seq flag */
-      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* frame field info present flag */
-      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* default display windows flag */
-      /* vui timing info present flag */
-      radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.timing_info_present_flag), 1);
-      if (sps->vui_flags.timing_info_present_flag) {
-         radeon_bs_code_fixed_bits(&bs, (sps->num_units_in_tick), 32);
-         radeon_bs_code_fixed_bits(&bs, (sps->time_scale), 32);
-         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.poc_proportional_to_timing_flag, 1);
-         if (sps->vui_flags.poc_proportional_to_timing_flag)
-            radeon_bs_code_ue(&bs, sps->num_ticks_poc_diff_one_minus1);
-         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.hrd_parameters_present_flag, 1);
-         if (sps->vui_flags.hrd_parameters_present_flag)
-            radeon_bs_hevc_hrd_parameters(&bs, 1, sps->sps_max_sub_layers_minus1, &sps->hrd_parameters);
-      }
-      radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* bitstream restriction flag */
-   }
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1);  /* sps extension present flag */
-
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
-   radeon_bs_byte_align(&bs);
-
-   return bs.bits_output / 8;
-}
-
-unsigned int radeon_uvd_enc_write_pps(struct radeon_uvd_encoder *enc, uint8_t *out)
-{
-   struct radeon_bitstream bs;
-   struct pipe_h265_enc_pic_param *pps = &enc->enc_pic.desc->pic;
-
-   radeon_bs_reset(&bs, out, NULL);
-   radeon_bs_set_emulation_prevention(&bs, false);
-   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
-   radeon_bs_code_fixed_bits(&bs, 0x4401, 16);
-   radeon_bs_set_emulation_prevention(&bs, true);
-   radeon_bs_code_ue(&bs, 0x0); /* pps_pic_parameter_set_id */
-   radeon_bs_code_ue(&bs, 0x0); /* pps_seq_parameter_set_id */
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* dependent_slice_segments_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, pps->output_flag_present_flag, 1);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 3); /* num_extra_slice_header_bits */
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* sign_data_hiding_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* cabac_init_present_flag */
-   radeon_bs_code_ue(&bs, pps->num_ref_idx_l0_default_active_minus1);
-   radeon_bs_code_ue(&bs, pps->num_ref_idx_l1_default_active_minus1);
-   radeon_bs_code_se(&bs, 0x0); /* init_qp_minus26 */
-   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_spec_misc.constrained_intra_pred_flag, 1);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* transform_skip_enabled */
-   bool cu_qp_delta_enabled_flag =
-      enc->enc_pic.rc_session_init.rate_control_method != RENC_UVD_RATE_CONTROL_METHOD_NONE;
-   radeon_bs_code_fixed_bits(&bs, cu_qp_delta_enabled_flag, 1);
-   if (cu_qp_delta_enabled_flag)
-      radeon_bs_code_ue(&bs, 0x0); /* diff_cu_qp_delta_depth */
-   radeon_bs_code_se(&bs, enc->enc_pic.hevc_deblock.cb_qp_offset);
-   radeon_bs_code_se(&bs, enc->enc_pic.hevc_deblock.cr_qp_offset);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* pps_slice_chroma_qp_offsets_present_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x0, 2); /* weighted_pred_flag + weighted_bipred_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* transquant_bypass_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* tiles_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* entropy_coding_sync_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled, 1);
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* deblocking_filter_control_present_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* deblocking_filter_override_enabled_flag */
-   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_deblock.deblocking_filter_disabled, 1);
-
-   if (!enc->enc_pic.hevc_deblock.deblocking_filter_disabled) {
-      radeon_bs_code_se(&bs, enc->enc_pic.hevc_deblock.beta_offset_div2);
-      radeon_bs_code_se(&bs, enc->enc_pic.hevc_deblock.tc_offset_div2);
-   }
-
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* pps_scaling_list_data_present_flag */
-   radeon_bs_code_fixed_bits(&bs, pps->lists_modification_present_flag, 1);
-   radeon_bs_code_ue(&bs, pps->log2_parallel_merge_level_minus2);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 2);
-
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
-   radeon_bs_byte_align(&bs);
-
-   return bs.bits_output / 8;
-}
-
-unsigned int radeon_uvd_enc_write_vps(struct radeon_uvd_encoder *enc, uint8_t *out)
-{
-   struct radeon_bitstream bs;
-   struct pipe_h265_enc_vid_param *vps = &enc->enc_pic.desc->vid;
-   int i;
-
-   radeon_bs_reset(&bs, out, NULL);
-   radeon_bs_set_emulation_prevention(&bs, false);
-   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
-   radeon_bs_code_fixed_bits(&bs, 0x4001, 16);
-   radeon_bs_set_emulation_prevention(&bs, true);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 4); /* vps_video_parameter_set_id*/
-   radeon_bs_code_fixed_bits(&bs, vps->vps_base_layer_internal_flag, 1);
-   radeon_bs_code_fixed_bits(&bs, vps->vps_base_layer_available_flag, 1);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 6); /* vps_max_layers_minus1 */
-   radeon_bs_code_fixed_bits(&bs, vps->vps_max_sub_layers_minus1, 3);
-   radeon_bs_code_fixed_bits(&bs, vps->vps_temporal_id_nesting_flag, 1);
-   radeon_bs_code_fixed_bits(&bs, 0xffff, 16); /* vps_reserved_0xffff_16bits */
-   radeon_bs_hevc_profile_tier_level(&bs, vps->vps_max_sub_layers_minus1, &vps->profile_tier_level);
-   radeon_bs_code_fixed_bits(&bs, vps->vps_sub_layer_ordering_info_present_flag, 1);
-   i = vps->vps_sub_layer_ordering_info_present_flag ? 0 : vps->vps_max_sub_layers_minus1;
-   for (; i <= vps->vps_max_sub_layers_minus1; i++) {
-      radeon_bs_code_ue(&bs, vps->vps_max_dec_pic_buffering_minus1[i]);
-      radeon_bs_code_ue(&bs, vps->vps_max_num_reorder_pics[i]);
-      radeon_bs_code_ue(&bs, vps->vps_max_latency_increase_plus1[i]);
-   }
-   radeon_bs_code_fixed_bits(&bs, 0x0, 6); /* vps_max_layer_id */
-   radeon_bs_code_ue(&bs, 0x0); /* vps_num_layer_sets_minus1 */
-   radeon_bs_code_fixed_bits(&bs, vps->vps_timing_info_present_flag, 1);
-   if (vps->vps_timing_info_present_flag) {
-      radeon_bs_code_fixed_bits(&bs, vps->vps_num_units_in_tick, 32);
-      radeon_bs_code_fixed_bits(&bs, vps->vps_time_scale, 32);
-      radeon_bs_code_fixed_bits(&bs, vps->vps_poc_proportional_to_timing_flag, 1);
-      if (vps->vps_poc_proportional_to_timing_flag)
-         radeon_bs_code_ue(&bs, vps->vps_num_ticks_poc_diff_one_minus1);
-      radeon_bs_code_ue(&bs, 0x0); /* vps_num_hrd_parameters */
-   }
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* vps_extension_flag */
-
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
-   radeon_bs_byte_align(&bs);
-
-   return bs.bits_output / 8;
-}
-
-static void radeon_uvd_enc_slice_header_hevc(struct radeon_uvd_encoder *enc)
-{
-   struct radeon_bitstream bs;
-   struct pipe_h265_enc_seq_param *sps = &enc->enc_pic.desc->seq;
-   struct pipe_h265_enc_pic_param *pps = &enc->enc_pic.desc->pic;
-   struct pipe_h265_enc_slice_param *slice = &enc->enc_pic.desc->slice;
-   uint32_t instruction[RENC_UVD_SLICE_HEADER_TEMPLATE_MAX_NUM_INSTRUCTIONS] = {0};
-   uint32_t num_bits[RENC_UVD_SLICE_HEADER_TEMPLATE_MAX_NUM_INSTRUCTIONS] = {0};
-   unsigned int inst_index = 0;
-   unsigned int cdw_start = 0;
-   unsigned int cdw_filled = 0;
-   unsigned int bits_copied = 0;
-   unsigned int num_pic_total_curr = 0;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_SLICE_HEADER);
-   radeon_bs_reset(&bs, NULL, &enc->cs);
-   radeon_bs_set_emulation_prevention(&bs, false);
-
-   cdw_start = enc->cs.current.cdw;
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1);
-   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.nal_unit_type, 6);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 6);
-   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.temporal_id + 1, 3);
-
-   radeon_bs_flush_headers(&bs);
-   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_COPY;
-   num_bits[inst_index] = bs.bits_output - bits_copied;
-   bits_copied = bs.bits_output;
-   inst_index++;
-
-   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_FIRST_SLICE;
-   inst_index++;
-
-   if ((enc->enc_pic.nal_unit_type >= 16) && (enc->enc_pic.nal_unit_type <= 23))
-      radeon_bs_code_fixed_bits(&bs, slice->no_output_of_prior_pics_flag, 1);
-
-   radeon_bs_code_ue(&bs, 0x0); /* slice_pic_parameter_set_id */
-
-   radeon_bs_flush_headers(&bs);
-   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_COPY;
-   num_bits[inst_index] = bs.bits_output - bits_copied;
-   bits_copied = bs.bits_output;
-   inst_index++;
-
-   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_SLICE_SEGMENT;
-   inst_index++;
-
-   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_DEPENDENT_SLICE_END;
-   inst_index++;
-
-   switch (enc->enc_pic.picture_type) {
-   case PIPE_H2645_ENC_PICTURE_TYPE_I:
-   case PIPE_H2645_ENC_PICTURE_TYPE_IDR:
-      radeon_bs_code_ue(&bs, 0x2);
-      break;
-   case PIPE_H2645_ENC_PICTURE_TYPE_P:
-   case PIPE_H2645_ENC_PICTURE_TYPE_SKIP:
-   default:
-      radeon_bs_code_ue(&bs, 0x1);
-      break;
-   }
-
-   if (pps->output_flag_present_flag)
-      radeon_bs_code_fixed_bits(&bs, slice->pic_output_flag, 1);
-
-   if ((enc->enc_pic.nal_unit_type != 19) && (enc->enc_pic.nal_unit_type != 20)) {
-      radeon_bs_code_fixed_bits(&bs, slice->slice_pic_order_cnt_lsb, sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
-      radeon_bs_code_fixed_bits(&bs, slice->short_term_ref_pic_set_sps_flag, 1);
-      if (!slice->short_term_ref_pic_set_sps_flag) {
-         num_pic_total_curr =
-            radeon_bs_hevc_st_ref_pic_set(&bs, sps->num_short_term_ref_pic_sets,
-                                          sps->num_short_term_ref_pic_sets, sps->st_ref_pic_set);
-      } else if (sps->num_short_term_ref_pic_sets > 1) {
-         radeon_bs_code_fixed_bits(&bs, slice->short_term_ref_pic_set_idx,
-                                    util_logbase2_ceil(sps->num_short_term_ref_pic_sets));
-      }
-      if (sps->long_term_ref_pics_present_flag) {
-         if (sps->num_long_term_ref_pics_sps > 0)
-            radeon_bs_code_ue(&bs, slice->num_long_term_sps);
-         radeon_bs_code_ue(&bs, slice->num_long_term_pics);
-         for (unsigned i = 0; i < slice->num_long_term_sps + slice->num_long_term_pics; i++) {
-            if (i < slice->num_long_term_sps) {
-               if (sps->num_long_term_ref_pics_sps > 1)
-                  radeon_bs_code_fixed_bits(&bs, slice->lt_idx_sps[i], util_logbase2_ceil(sps->num_long_term_ref_pics_sps));
-            } else {
-               radeon_bs_code_fixed_bits(&bs, slice->poc_lsb_lt[i], sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
-               radeon_bs_code_fixed_bits(&bs, slice->used_by_curr_pic_lt_flag[i], 1);
-               if (slice->used_by_curr_pic_lt_flag[i])
-                  num_pic_total_curr++;
-            }
-            radeon_bs_code_fixed_bits(&bs, slice->delta_poc_msb_present_flag[i], 1);
-            if (slice->delta_poc_msb_present_flag[i])
-               radeon_bs_code_ue(&bs, slice->delta_poc_msb_cycle_lt[i]);
-         }
-      }
-   }
-
-   if (enc->enc_pic.picture_type == PIPE_H2645_ENC_PICTURE_TYPE_P) {
-      radeon_bs_code_fixed_bits(&bs, slice->num_ref_idx_active_override_flag, 1);
-      if (slice->num_ref_idx_active_override_flag)
-         radeon_bs_code_ue(&bs, slice->num_ref_idx_l0_active_minus1);
-      if (pps->lists_modification_present_flag && num_pic_total_curr > 1) {
-         unsigned num_bits = util_logbase2_ceil(num_pic_total_curr);
-         unsigned num_ref_l0_minus1 = slice->num_ref_idx_active_override_flag ?
-            slice->num_ref_idx_l0_active_minus1 : pps->num_ref_idx_l0_default_active_minus1;
-         radeon_bs_code_fixed_bits(&bs, slice->ref_pic_lists_modification.ref_pic_list_modification_flag_l0, 1);
-         for (unsigned i = 0; i <= num_ref_l0_minus1; i++)
-            radeon_bs_code_fixed_bits(&bs, slice->ref_pic_lists_modification.list_entry_l0[i], num_bits);
-      }
-      radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_spec_misc.cabac_init_flag, 1);
-      radeon_bs_code_ue(&bs, 5 - slice->max_num_merge_cand);
-   }
-
-   radeon_bs_flush_headers(&bs);
-   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_COPY;
-   num_bits[inst_index] = bs.bits_output - bits_copied;
-   bits_copied = bs.bits_output;
-   inst_index++;
-
-   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_SLICE_QP_DELTA;
-   inst_index++;
-
-   if ((enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled) &&
-       (!enc->enc_pic.hevc_deblock.deblocking_filter_disabled)) {
-      radeon_bs_code_fixed_bits(&bs, enc->enc_pic.hevc_deblock.loop_filter_across_slices_enabled, 1);
-      radeon_bs_flush_headers(&bs);
-      instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_COPY;
-      num_bits[inst_index] = bs.bits_output - bits_copied;
-      bits_copied = bs.bits_output;
-      inst_index++;
-   }
-
-   instruction[inst_index] = RENC_UVD_HEADER_INSTRUCTION_END;
-
-   cdw_filled = enc->cs.current.cdw - cdw_start;
-   for (int i = 0; i < RENC_UVD_SLICE_HEADER_TEMPLATE_MAX_TEMPLATE_SIZE_IN_DWORDS - cdw_filled; i++)
-      RADEON_ENC_CS(0x00000000);
-
-   for (int j = 0; j < RENC_UVD_SLICE_HEADER_TEMPLATE_MAX_NUM_INSTRUCTIONS; j++) {
-      RADEON_ENC_CS(instruction[j]);
-      RADEON_ENC_CS(num_bits[j]);
-   }
-
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_ctx(struct radeon_uvd_encoder *enc)
-{
-   struct si_screen *sscreen = (struct si_screen *)enc->screen;
-
-   enc->enc_pic.ctx_buf.swizzle_mode = 0;
-   if (sscreen->info.gfx_level < GFX9) {
-      enc->enc_pic.ctx_buf.rec_luma_pitch = (enc->luma->u.legacy.level[0].nblk_x * enc->luma->bpe);
-      enc->enc_pic.ctx_buf.rec_chroma_pitch =
-         (enc->chroma->u.legacy.level[0].nblk_x * enc->chroma->bpe);
-   } else {
-      enc->enc_pic.ctx_buf.rec_luma_pitch = enc->luma->u.gfx9.surf_pitch * enc->luma->bpe;
-      enc->enc_pic.ctx_buf.rec_chroma_pitch = enc->chroma->u.gfx9.surf_pitch * enc->chroma->bpe;
-   }
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_ENCODE_CONTEXT_BUFFER);
-   RADEON_ENC_READWRITE(enc->dpb.res->buf, enc->dpb.res->domains, 0);
-   RADEON_ENC_CS(0x00000000); // reserved
-   RADEON_ENC_CS(enc->enc_pic.ctx_buf.swizzle_mode);
-   RADEON_ENC_CS(enc->enc_pic.ctx_buf.rec_luma_pitch);
-   RADEON_ENC_CS(enc->enc_pic.ctx_buf.rec_chroma_pitch);
-   RADEON_ENC_CS(enc->enc_pic.ctx_buf.num_reconstructed_pictures);
-   for (uint32_t i = 0; i < RENC_UVD_MAX_NUM_RECONSTRUCTED_PICTURES; i++) {
-      RADEON_ENC_CS(enc->enc_pic.ctx_buf.reconstructed_pictures[i].luma_offset);
-      RADEON_ENC_CS(enc->enc_pic.ctx_buf.reconstructed_pictures[i].chroma_offset);
-   }
-   RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_picture_luma_pitch);
-   RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_picture_chroma_pitch);
-   for (uint32_t i = 0; i < RENC_UVD_MAX_NUM_RECONSTRUCTED_PICTURES; i++) {
-      RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_reconstructed_pictures[i].luma_offset);
-      RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_reconstructed_pictures[i].chroma_offset);
-   }
-   RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_input_picture.luma_offset);
-   RADEON_ENC_CS(enc->enc_pic.ctx_buf.pre_encode_input_picture.chroma_offset);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_bitstream(struct radeon_uvd_encoder *enc)
-{
-   enc->enc_pic.bit_buf.mode = RENC_UVD_SWIZZLE_MODE_LINEAR;
-   enc->enc_pic.bit_buf.video_bitstream_buffer_size = enc->bs_size;
-   enc->enc_pic.bit_buf.video_bitstream_data_offset = enc->bs_offset;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_VIDEO_BITSTREAM_BUFFER);
-   RADEON_ENC_CS(enc->enc_pic.bit_buf.mode);
-   RADEON_ENC_WRITE(enc->bs_handle, RADEON_DOMAIN_GTT, 0);
-   RADEON_ENC_CS(enc->enc_pic.bit_buf.video_bitstream_buffer_size);
-   RADEON_ENC_CS(enc->enc_pic.bit_buf.video_bitstream_data_offset);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_feedback(struct radeon_uvd_encoder *enc)
-{
-   enc->enc_pic.fb_buf.mode = RENC_UVD_FEEDBACK_BUFFER_MODE_LINEAR;
-   enc->enc_pic.fb_buf.feedback_buffer_size = 16;
-   enc->enc_pic.fb_buf.feedback_data_size = 40;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_FEEDBACK_BUFFER);
-   RADEON_ENC_CS(enc->enc_pic.fb_buf.mode);
-   RADEON_ENC_WRITE(enc->fb->res->buf, enc->fb->res->domains, 0x0);
-   RADEON_ENC_CS(enc->enc_pic.fb_buf.feedback_buffer_size);
-   RADEON_ENC_CS(enc->enc_pic.fb_buf.feedback_data_size);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_intra_refresh(struct radeon_uvd_encoder *enc)
-{
-   switch (enc->enc_pic.desc->intra_refresh.mode) {
-   case INTRA_REFRESH_MODE_UNIT_ROWS:
-      enc->enc_pic.intra_ref.intra_refresh_mode = RENC_UVD_INTRA_REFRESH_MODE_CTB_MB_ROWS;
-      break;
-   case INTRA_REFRESH_MODE_UNIT_COLUMNS:
-      enc->enc_pic.intra_ref.intra_refresh_mode = RENC_UVD_INTRA_REFRESH_MODE_CTB_MB_COLUMNS;
-      break;
-   default:
-      enc->enc_pic.intra_ref.intra_refresh_mode = RENC_UVD_INTRA_REFRESH_MODE_NONE;
-      break;
-   };
-
-   enc->enc_pic.intra_ref.offset = enc->enc_pic.desc->intra_refresh.offset;
-   enc->enc_pic.intra_ref.region_size = enc->enc_pic.desc->intra_refresh.region_size;
-
-   if (!enc->enc_pic.hevc_deblock.deblocking_filter_disabled)
-      enc->enc_pic.intra_ref.region_size++;
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_INTRA_REFRESH);
-   RADEON_ENC_CS(enc->enc_pic.intra_ref.intra_refresh_mode);
-   RADEON_ENC_CS(enc->enc_pic.intra_ref.offset);
-   RADEON_ENC_CS(enc->enc_pic.intra_ref.region_size);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_rc_per_pic(struct radeon_uvd_encoder *enc)
-{
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_RATE_CONTROL_PER_PICTURE);
-   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.qp);
-   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.min_qp_app);
-   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.max_qp_app);
-   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.max_au_size);
-   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.enabled_filler_data);
-   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.skip_frame_enable);
-   RADEON_ENC_CS(enc->enc_pic.rc_per_pic.enforce_hrd);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_encode_params_hevc(struct radeon_uvd_encoder *enc)
-{
-   struct si_screen *sscreen = (struct si_screen *)enc->screen;
-   switch (enc->enc_pic.picture_type) {
-   case PIPE_H2645_ENC_PICTURE_TYPE_I:
-   case PIPE_H2645_ENC_PICTURE_TYPE_IDR:
-      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_I;
-      break;
-   case PIPE_H2645_ENC_PICTURE_TYPE_P:
-      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_P;
-      break;
-   case PIPE_H2645_ENC_PICTURE_TYPE_SKIP:
-      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_P_SKIP;
-      break;
-   case PIPE_H2645_ENC_PICTURE_TYPE_B:
-      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_B;
-      break;
-   default:
-      enc->enc_pic.enc_params.pic_type = RENC_UVD_PICTURE_TYPE_I;
-   }
-
-   enc->enc_pic.enc_params.allowed_max_bitstream_size = enc->bs_size - enc->bs_offset;
-   if (sscreen->info.gfx_level < GFX9) {
-      enc->enc_pic.enc_params.input_pic_luma_pitch =
-         (enc->luma->u.legacy.level[0].nblk_x * enc->luma->bpe);
-      enc->enc_pic.enc_params.input_pic_chroma_pitch =
-         (enc->chroma->u.legacy.level[0].nblk_x * enc->chroma->bpe);
-   } else {
-      enc->enc_pic.enc_params.input_pic_luma_pitch = enc->luma->u.gfx9.surf_pitch * enc->luma->bpe;
-      enc->enc_pic.enc_params.input_pic_chroma_pitch =
-         enc->chroma->u.gfx9.surf_pitch * enc->chroma->bpe;
-      enc->enc_pic.enc_params.input_pic_swizzle_mode = enc->luma->u.gfx9.swizzle_mode;
-   }
-
-   RADEON_ENC_BEGIN(RENC_UVD_IB_PARAM_ENCODE_PARAMS);
-   RADEON_ENC_CS(enc->enc_pic.enc_params.pic_type);
-   RADEON_ENC_CS(enc->enc_pic.enc_params.allowed_max_bitstream_size);
-
-   if (sscreen->info.gfx_level < GFX9) {
-      RADEON_ENC_READ(enc->handle, RADEON_DOMAIN_VRAM, (uint64_t)enc->luma->u.legacy.level[0].offset_256B * 256);
-      RADEON_ENC_READ(enc->handle, RADEON_DOMAIN_VRAM, (uint64_t)enc->chroma->u.legacy.level[0].offset_256B * 256);
-   } else {
-      RADEON_ENC_READ(enc->handle, RADEON_DOMAIN_VRAM, enc->luma->u.gfx9.surf_offset);
-      RADEON_ENC_READ(enc->handle, RADEON_DOMAIN_VRAM, enc->chroma->u.gfx9.surf_offset);
-   }
-   RADEON_ENC_CS(enc->enc_pic.enc_params.input_pic_luma_pitch);
-   RADEON_ENC_CS(enc->enc_pic.enc_params.input_pic_chroma_pitch);
-   RADEON_ENC_CS(enc->enc_pic.enc_params.input_pic_addr_mode);
-   RADEON_ENC_CS(enc->enc_pic.enc_params.input_pic_swizzle_mode);
-   RADEON_ENC_CS(enc->enc_pic.enc_params.reference_picture_index);
-   RADEON_ENC_CS(enc->enc_pic.enc_params.reconstructed_picture_index);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_op_init(struct radeon_uvd_encoder *enc)
-{
-   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_INITIALIZE);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_op_close(struct radeon_uvd_encoder *enc)
-{
-   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_CLOSE_SESSION);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_op_enc(struct radeon_uvd_encoder *enc)
-{
-   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_ENCODE);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_op_init_rc(struct radeon_uvd_encoder *enc)
-{
-   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_INIT_RC);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_op_init_rc_vbv(struct radeon_uvd_encoder *enc)
-{
-   RADEON_ENC_BEGIN(RENC_UVD_IB_OP_INIT_RC_VBV_BUFFER_LEVEL);
-   RADEON_ENC_END();
-}
-
-static void radeon_uvd_enc_op_preset(struct radeon_uvd_encoder *enc)
-{
-   uint32_t preset_mode;
-
-   switch (enc->enc_pic.desc->quality_modes.preset_mode) {
-   case 0: /* SPEED */
-      preset_mode = RENC_UVD_IB_OP_SET_SPEED_ENCODING_MODE;
-      break;
-   case 1: /* BALANCED */
-      preset_mode = RENC_UVD_IB_OP_SET_BALANCE_ENCODING_MODE;
-      break;
-   case 2: /* QUALITY */
-   default:
-      preset_mode = RENC_UVD_IB_OP_SET_QUALITY_ENCODING_MODE;
-      break;
-   }
-
-   RADEON_ENC_BEGIN(preset_mode);
-   RADEON_ENC_END();
-}
-
-static void begin(struct radeon_uvd_encoder *enc, struct pipe_picture_desc *pic)
-{
-   radeon_uvd_enc_session_info(enc);
-   enc->total_task_size = 0;
-   radeon_uvd_enc_task_info(enc, enc->need_feedback);
-   radeon_uvd_enc_op_init(enc);
-
-   radeon_uvd_enc_session_init_hevc(enc);
-   radeon_uvd_enc_slice_control_hevc(enc, pic);
-   radeon_uvd_enc_spec_misc_hevc(enc, pic);
-   radeon_uvd_enc_deblocking_filter_hevc(enc, pic);
-
-   radeon_uvd_enc_layer_control(enc);
-   radeon_uvd_enc_rc_session_init(enc, pic);
-   radeon_uvd_enc_quality_params(enc);
-
-   for (uint32_t i = 0; i < enc->enc_pic.layer_ctrl.num_temporal_layers; i++) {
-      enc->enc_pic.layer_sel.temporal_layer_index = i;
-      radeon_uvd_enc_layer_select(enc);
-      radeon_uvd_enc_rc_layer_init(enc);
-      radeon_uvd_enc_layer_select(enc);
-      radeon_uvd_enc_rc_per_pic(enc);
-   }
-
-   radeon_uvd_enc_op_init_rc(enc);
-   radeon_uvd_enc_op_init_rc_vbv(enc);
-   *enc->p_task_size = (enc->total_task_size);
-}
-
-static void encode(struct radeon_uvd_encoder *enc)
-{
-   radeon_uvd_enc_session_info(enc);
-   enc->total_task_size = 0;
-   radeon_uvd_enc_task_info(enc, enc->need_feedback);
-
-   if (enc->need_rate_control || enc->need_rc_per_pic) {
-      for (uint32_t i = 0; i < enc->enc_pic.layer_ctrl.num_temporal_layers; i++) {
-         enc->enc_pic.layer_sel.temporal_layer_index = i;
-         radeon_uvd_enc_layer_select(enc);
-         if (enc->need_rate_control)
-            radeon_uvd_enc_rc_layer_init(enc);
-         if (enc->need_rc_per_pic)
-            radeon_uvd_enc_rc_per_pic(enc);
-      }
-   }
-
-   enc->enc_pic.layer_sel.temporal_layer_index = enc->enc_pic.temporal_id;
-   radeon_uvd_enc_layer_select(enc);
-
-   radeon_uvd_enc_slice_header_hevc(enc);
-   radeon_uvd_enc_encode_params_hevc(enc);
-
-   radeon_uvd_enc_ctx(enc);
-   radeon_uvd_enc_bitstream(enc);
-   radeon_uvd_enc_feedback(enc);
-   radeon_uvd_enc_intra_refresh(enc);
-
-   radeon_uvd_enc_op_preset(enc);
-   radeon_uvd_enc_op_enc(enc);
-   *enc->p_task_size = (enc->total_task_size);
-}
-
-static void destroy(struct radeon_uvd_encoder *enc)
-{
-   radeon_uvd_enc_session_info(enc);
-   enc->total_task_size = 0;
-   radeon_uvd_enc_task_info(enc, enc->need_feedback);
-   radeon_uvd_enc_op_close(enc);
-   *enc->p_task_size = (enc->total_task_size);
-}
-
-void radeon_uvd_enc_1_1_init(struct radeon_uvd_encoder *enc)
-{
-   enc->begin = begin;
-   enc->encode = encode;
-   enc->destroy = destroy;
-}
diff --git a/src/gallium/drivers/radeonsi/radeon_vce.c b/src/gallium/drivers/radeonsi/radeon_vce.c
index ff43a780c52..f9b6ff1712a 100644
--- a/src/gallium/drivers/radeonsi/radeon_vce.c
+++ b/src/gallium/drivers/radeonsi/radeon_vce.c
@@ -10,6 +10,7 @@
 
 #include "pipe/p_video_codec.h"
 #include "radeon_video.h"
+#include "radeon_bitstream.h"
 #include "radeonsi/si_pipe.h"
 #include "util/u_memory.h"
 #include "util/u_video.h"
@@ -17,49 +18,326 @@
 
 #include <stdio.h>
 
-#define FW_52_0_3  ((52 << 24) | (0 << 16) | (3 << 8))
-#define FW_52_4_3  ((52 << 24) | (4 << 16) | (3 << 8))
-#define FW_52_8_3  ((52 << 24) | (8 << 16) | (3 << 8))
-#define FW_53       (53 << 24)
+#define REF_LIST_MODIFICATION_OP_END                  0
+#define REF_LIST_MODIFICATION_OP_SHORT_TERM_SUBTRACT  1
+#define REF_LIST_MODIFICATION_OP_LONG_TERM            2
+#define REF_LIST_MODIFICATION_OP_VIEW_ADD             3
 
-/**
- * flush commands to the hardware
- */
-static void flush(struct rvce_encoder *enc, unsigned flags, struct pipe_fence_handle **fence)
+#define INTRAREFRESH_METHOD_BAR_BASED                 6
+
+static void task_info(struct rvce_encoder *enc, uint32_t op, uint32_t fb_idx)
 {
-   enc->ws->cs_flush(&enc->cs, flags, fence);
+   RVCE_BEGIN(0x00000002); // task info
+   enc->enc_pic.ti.task_operation = op;
+   enc->enc_pic.ti.reference_picture_dependency = 0;
+   enc->enc_pic.ti.feedback_index = fb_idx;
+   enc->enc_pic.ti.video_bitstream_ring_index = 0;
+   RVCE_CS(enc->enc_pic.ti.offset_of_next_task_info);
+   RVCE_CS(enc->enc_pic.ti.task_operation);
+   RVCE_CS(enc->enc_pic.ti.reference_picture_dependency);
+   RVCE_CS(enc->enc_pic.ti.collocate_flag_dependency);
+   RVCE_CS(enc->enc_pic.ti.feedback_index);
+   RVCE_CS(enc->enc_pic.ti.video_bitstream_ring_index);
+   RVCE_END();
+}
+
+static void get_rate_control_param(struct rvce_encoder *enc, struct pipe_h264_enc_picture_desc *pic)
+{
+   enc->enc_pic.rc.rc_method = pic->rate_ctrl[0].rate_ctrl_method;
+   enc->enc_pic.rc.target_bitrate = pic->rate_ctrl[0].target_bitrate;
+   enc->enc_pic.rc.peak_bitrate = pic->rate_ctrl[0].peak_bitrate;
+   enc->enc_pic.rc.quant_i_frames = pic->quant_i_frames;
+   enc->enc_pic.rc.quant_p_frames = pic->quant_p_frames;
+   enc->enc_pic.rc.quant_b_frames = pic->quant_b_frames;
+   enc->enc_pic.rc.gop_size = pic->gop_size;
+   enc->enc_pic.rc.frame_rate_num = pic->rate_ctrl[0].frame_rate_num;
+   enc->enc_pic.rc.frame_rate_den = pic->rate_ctrl[0].frame_rate_den;
+   enc->enc_pic.rc.min_qp = pic->rate_ctrl[0].min_qp;
+   enc->enc_pic.rc.max_qp = pic->rate_ctrl[0].max_qp ? pic->rate_ctrl[0].max_qp : 51;
+   enc->enc_pic.rc.max_au_size = pic->rate_ctrl[0].max_au_size;
+   enc->enc_pic.rc.vbv_buffer_size = pic->rate_ctrl[0].vbv_buffer_size;
+   enc->enc_pic.rc.vbv_buf_lv = pic->rate_ctrl[0].vbv_buf_lv;
+   enc->enc_pic.rc.fill_data_enable = pic->rate_ctrl[0].fill_data_enable;
+   enc->enc_pic.rc.enforce_hrd = pic->rate_ctrl[0].enforce_hrd;
+   enc->enc_pic.rc.target_bits_picture =
+      enc->pic.rate_ctrl[0].target_bitrate *
+      ((float)enc->pic.rate_ctrl[0].frame_rate_den /
+      enc->pic.rate_ctrl[0].frame_rate_num);
+   enc->enc_pic.rc.peak_bits_picture_integer =
+      enc->pic.rate_ctrl[0].peak_bitrate *
+      ((float)enc->pic.rate_ctrl[0].frame_rate_den /
+      enc->pic.rate_ctrl[0].frame_rate_num);
+   enc->enc_pic.rc.peak_bits_picture_fraction =
+      (((enc->pic.rate_ctrl[0].peak_bitrate *
+      (uint64_t)enc->pic.rate_ctrl[0].frame_rate_den) %
+      enc->pic.rate_ctrl[0].frame_rate_num) << 32) /
+      enc->pic.rate_ctrl[0].frame_rate_num;
+}
+
+static void get_motion_estimation_param(struct rvce_encoder *enc,
+                                        struct pipe_h264_enc_picture_desc *pic)
+{
+   enc->enc_pic.me.enc_ime_decimation_search = 1;
+   enc->enc_pic.me.motion_est_half_pixel = 1;
+   enc->enc_pic.me.motion_est_quarter_pixel = 1;
+   enc->enc_pic.me.disable_favor_pmv_point = 0;
+   enc->enc_pic.me.lsmvert = 2;
+   enc->enc_pic.me.disable_16x16_frame1 = 0;
+   enc->enc_pic.me.disable_satd = 0;
+   enc->enc_pic.me.enc_ime_skip_x = 0;
+   enc->enc_pic.me.enc_ime_skip_y = 0;
+   enc->enc_pic.me.enc_ime2_search_range_x = 4;
+   enc->enc_pic.me.enc_ime2_search_range_y = 4;
+   enc->enc_pic.me.parallel_mode_speedup_enable = 0;
+   enc->enc_pic.me.fme0_enc_disable_sub_mode = 0;
+   enc->enc_pic.me.fme1_enc_disable_sub_mode = 0;
+   enc->enc_pic.me.ime_sw_speedup_enable = 0;
+
+   switch (pic->quality_modes.preset_mode) {
+   case 0: /* SPEED */
+      enc->enc_pic.me.force_zero_point_center = 0;
+      enc->enc_pic.me.enc_search_range_x = 16;
+      enc->enc_pic.me.enc_search_range_y = 16;
+      enc->enc_pic.me.enc_search1_range_x = 16;
+      enc->enc_pic.me.enc_search1_range_y = 16;
+      enc->enc_pic.me.enable_amd = 0;
+      enc->enc_pic.me.enc_disable_sub_mode = 126;
+      enc->enc_pic.me.enc_en_ime_overw_dis_subm = 0;
+      enc->enc_pic.me.enc_ime_overw_dis_subm_no = 0;
+      break;
+   case 1: /* BALANCED */
+      enc->enc_pic.me.force_zero_point_center = 0;
+      enc->enc_pic.me.enc_search_range_x = 16;
+      enc->enc_pic.me.enc_search_range_y = 16;
+      enc->enc_pic.me.enc_search1_range_x = 16;
+      enc->enc_pic.me.enc_search1_range_y = 16;
+      enc->enc_pic.me.enable_amd = 0;
+      enc->enc_pic.me.enc_disable_sub_mode = 120;
+      enc->enc_pic.me.enc_en_ime_overw_dis_subm = 1;
+      enc->enc_pic.me.enc_ime_overw_dis_subm_no = 1;
+      break;
+   case 2: /* QUALITY */
+   default:
+      enc->enc_pic.me.force_zero_point_center = 1;
+      enc->enc_pic.me.enc_search_range_x = 36;
+      enc->enc_pic.me.enc_search_range_y = 36;
+      enc->enc_pic.me.enc_search1_range_x = 36;
+      enc->enc_pic.me.enc_search1_range_y = 36;
+      enc->enc_pic.me.enable_amd = 1;
+      enc->enc_pic.me.enc_disable_sub_mode = 0;
+      enc->enc_pic.me.enc_en_ime_overw_dis_subm = 0;
+      enc->enc_pic.me.enc_ime_overw_dis_subm_no = 0;
+      break;
+   }
+}
+
+static void get_pic_control_param(struct rvce_encoder *enc, struct pipe_h264_enc_picture_desc *pic)
+{
+   uint32_t num_mbs_total, num_mbs_in_slice;
+
+   num_mbs_total = DIV_ROUND_UP(enc->base.width, 16) * DIV_ROUND_UP(enc->base.height, 16);
+
+   if (pic->num_slice_descriptors <= 1) {
+      num_mbs_in_slice = num_mbs_total;
+   } else {
+      bool use_app_config = true;
+      num_mbs_in_slice = pic->slices_descriptors[0].num_macroblocks;
+
+      /* All slices must have equal size */
+      for (unsigned i = 1; i < pic->num_slice_descriptors - 1; i++) {
+         if (num_mbs_in_slice != pic->slices_descriptors[i].num_macroblocks)
+            use_app_config = false;
+      }
+      /* Except last one can be smaller */
+      if (pic->slices_descriptors[pic->num_slice_descriptors - 1].num_macroblocks > num_mbs_in_slice)
+         use_app_config = false;
+
+      if (!use_app_config) {
+         assert(num_mbs_total >= pic->num_slice_descriptors);
+         num_mbs_in_slice =
+            (num_mbs_total + pic->num_slice_descriptors - 1) / pic->num_slice_descriptors;
+      }
+   }
+
+   if (pic->seq.enc_frame_cropping_flag) {
+      enc->enc_pic.pc.enc_crop_left_offset = pic->seq.enc_frame_crop_left_offset;
+      enc->enc_pic.pc.enc_crop_right_offset = pic->seq.enc_frame_crop_right_offset;
+      enc->enc_pic.pc.enc_crop_top_offset = pic->seq.enc_frame_crop_top_offset;
+      enc->enc_pic.pc.enc_crop_bottom_offset = pic->seq.enc_frame_crop_bottom_offset;
+   }
+   enc->enc_pic.pc.enc_num_mbs_per_slice = num_mbs_in_slice;
+   enc->enc_pic.pc.enc_number_of_reference_frames = 1;
+   enc->enc_pic.pc.enc_max_num_ref_frames = pic->seq.max_num_ref_frames;
+   enc->enc_pic.pc.enc_num_default_active_ref_l0 = pic->pic_ctrl.num_ref_idx_l0_default_active_minus1 + 1;
+   enc->enc_pic.pc.enc_num_default_active_ref_l1 = pic->pic_ctrl.num_ref_idx_l1_default_active_minus1 + 1;
+   enc->enc_pic.pc.enc_slice_mode = 1;
+   enc->enc_pic.pc.enc_use_constrained_intra_pred = pic->pic_ctrl.constrained_intra_pred_flag;
+   enc->enc_pic.pc.enc_cabac_enable = pic->pic_ctrl.enc_cabac_enable;
+   enc->enc_pic.pc.enc_cabac_idc = pic->pic_ctrl.enc_cabac_init_idc;
+   enc->enc_pic.pc.enc_constraint_set_flags = pic->seq.enc_constraint_set_flags << 2;
+   enc->enc_pic.pc.enc_loop_filter_disable = !!pic->dbk.disable_deblocking_filter_idc;
+   enc->enc_pic.pc.enc_lf_beta_offset = pic->dbk.beta_offset_div2;
+   enc->enc_pic.pc.enc_lf_alpha_c0_offset = pic->dbk.alpha_c0_offset_div2;
+   enc->enc_pic.pc.enc_pic_order_cnt_type = pic->seq.pic_order_cnt_type;
+   enc->enc_pic.pc.log2_max_pic_order_cnt_lsb_minus4 = pic->seq.log2_max_pic_order_cnt_lsb_minus4;
+}
+
+static void get_task_info_param(struct rvce_encoder *enc)
+{
+   enc->enc_pic.ti.offset_of_next_task_info = 0xffffffff;
+}
+
+static void get_feedback_buffer_param(struct rvce_encoder *enc, struct pipe_enc_feedback_metadata* metadata)
+{
+   enc->enc_pic.fb.feedback_ring_size = 0x00000001;
+}
+
+static void get_config_ext_param(struct rvce_encoder *enc)
+{
+   enc->enc_pic.ce.enc_enable_perf_logging = 0x00000003;
+}
+
+static void get_param(struct rvce_encoder *enc, struct pipe_h264_enc_picture_desc *pic)
+{
+   int i;
+
+   get_rate_control_param(enc, pic);
+   get_motion_estimation_param(enc, pic);
+   get_pic_control_param(enc, pic);
+   get_task_info_param(enc);
+   get_feedback_buffer_param(enc, NULL);
+   get_config_ext_param(enc);
+
+   enc->enc_pic.picture_type = pic->picture_type;
+   enc->enc_pic.frame_num = pic->frame_num;
+   enc->enc_pic.frame_num_cnt = pic->frame_num_cnt - 1;
+   enc->enc_pic.p_remain = pic->p_remain;
+   enc->enc_pic.i_remain = pic->i_remain;
+   enc->enc_pic.pic_order_cnt = pic->pic_order_cnt;
+   enc->enc_pic.not_referenced = pic->not_referenced;
+   enc->enc_pic.addrmode_arraymode_disrdo_distwoinstants = enc->fw_version >= 52 ? 0x01000201 : 0;
+   enc->enc_pic.eo.enc_idr_pic_id = pic->idr_pic_id;
+   enc->enc_pic.ec.enc_vbaq_mode =
+      pic->rate_ctrl[0].rate_ctrl_method != PIPE_H2645_ENC_RATE_CONTROL_METHOD_DISABLE &&
+      pic->quality_modes.vbaq_mode;
+   if (pic->intra_refresh.mode != PIPE_VIDEO_ENC_INTRA_REFRESH_NONE) {
+      enc->enc_pic.eo.enable_intra_refresh = 1;
+      enc->enc_pic.pc.enc_force_intra_refresh = INTRAREFRESH_METHOD_BAR_BASED;
+      enc->enc_pic.pc.enc_intra_refresh_num_mbs_per_slot = pic->intra_refresh.region_size;
+   } else {
+      enc->enc_pic.eo.enable_intra_refresh = 0;
+   }
+
+   enc->enc_pic.eo.num_ref_idx_active_override_flag = pic->slice.num_ref_idx_active_override_flag;
+   enc->enc_pic.eo.num_ref_idx_l0_active_minus1 = pic->slice.num_ref_idx_l0_active_minus1;
+   enc->enc_pic.eo.num_ref_idx_l1_active_minus1 = pic->slice.num_ref_idx_l1_active_minus1;
+
+   i = 0;
+   if (pic->slice.ref_pic_list_modification_flag_l0) {
+      for (; i < MIN2(4, pic->slice.num_ref_list0_mod_operations); i++) {
+         struct pipe_h264_ref_list_mod_entry *entry = &pic->slice.ref_list0_mod_operations[i];
+         switch (entry->modification_of_pic_nums_idc) {
+         case 0:
+            enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_SHORT_TERM_SUBTRACT;
+            enc->enc_pic.eo.enc_ref_list_modification_num[i] = entry->abs_diff_pic_num_minus1;
+            break;
+         case 2:
+            enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_LONG_TERM;
+            enc->enc_pic.eo.enc_ref_list_modification_num[i] = entry->long_term_pic_num;
+            break;
+         case 5:
+            enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_VIEW_ADD;
+            enc->enc_pic.eo.enc_ref_list_modification_num[i] = entry->abs_diff_pic_num_minus1;
+            break;
+         default:
+         case 3:
+            enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_END;
+            break;
+         }
+      }
+   }
+   if (i < 4)
+      enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_END;
+
+   i = 0;
+   if (pic->pic_ctrl.nal_unit_type == PIPE_H264_NAL_IDR_SLICE) {
+      enc->enc_pic.eo.enc_decoded_picture_marking_op[i++] = pic->slice.long_term_reference_flag ? 6 : 0;
+   } else if (pic->slice.adaptive_ref_pic_marking_mode_flag) {
+      for (; i < MIN2(4, pic->slice.num_ref_pic_marking_operations); i++) {
+         struct pipe_h264_ref_pic_marking_entry *entry = &pic->slice.ref_pic_marking_operations[i];
+         enc->enc_pic.eo.enc_decoded_picture_marking_op[i] = entry->memory_management_control_operation;
+         switch (entry->memory_management_control_operation) {
+         case 1:
+            enc->enc_pic.eo.enc_decoded_picture_marking_num[i] = entry->difference_of_pic_nums_minus1;
+            break;
+         case 2:
+            enc->enc_pic.eo.enc_decoded_picture_marking_num[i] = entry->long_term_pic_num;
+            break;
+         case 3:
+            enc->enc_pic.eo.enc_decoded_picture_marking_num[i] = entry->difference_of_pic_nums_minus1;
+            enc->enc_pic.eo.enc_decoded_picture_marking_idx[i] = entry->long_term_frame_idx;
+            break;
+         case 4:
+            enc->enc_pic.eo.enc_decoded_picture_marking_idx[i] = entry->max_long_term_frame_idx_plus1;
+            break;
+         case 6:
+            enc->enc_pic.eo.enc_decoded_picture_marking_idx[i] = entry->long_term_frame_idx;
+            break;
+         default:
+            break;
+         }
+      }
+   }
+   if (i < 4)
+      enc->enc_pic.eo.enc_decoded_picture_marking_op[i] = 0;
+
+   enc->enc_pic.eo.cur_dpb_idx = pic->dpb_curr_pic;
+
+   enc->enc_pic.eo.l0_dpb_idx = pic->ref_list0[0];
+
+   enc->enc_pic.eo.l1_dpb_idx = PIPE_H2645_LIST_REF_INVALID_ENTRY;
+   enc->enc_pic.eo.l1_luma_offset = 0xffffffff;
+   enc->enc_pic.eo.l1_chroma_offset = 0xffffffff;
 }
 
-#if 0
-static void dump_feedback(struct rvce_encoder *enc, struct rvid_buffer *fb)
-{
-   uint32_t *ptr = enc->ws->buffer_map(fb->res->buf, &enc->cs, PIPE_MAP_READ_WRITE);
-   unsigned i = 0;
-   fprintf(stderr, "\n");
-   fprintf(stderr, "encStatus:\t\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "encHasBitstream:\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "encHasAudioBitstream:\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "encBitstreamOffset:\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "encBitstreamSize:\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "encAudioBitstreamOffset:\t%08x\n", ptr[i++]);
-   fprintf(stderr, "encAudioBitstreamSize:\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "encExtrabytes:\t\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "encAudioExtrabytes:\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "videoTimeStamp:\t\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "audioTimeStamp:\t\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "videoOutputType:\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "attributeFlags:\t\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "seiPrivatePackageOffset:\t%08x\n", ptr[i++]);
-   fprintf(stderr, "seiPrivatePackageSize:\t\t%08x\n", ptr[i++]);
-   fprintf(stderr, "\n");
-   enc->ws->buffer_unmap(fb->res->buf);
-}
-#endif
+static void create(struct rvce_encoder *enc)
+{
+   struct si_screen *sscreen = (struct si_screen *)enc->screen;
+   task_info(enc, 0x00000000, 0);
+
+   RVCE_BEGIN(0x01000001); // create cmd
+   RVCE_CS(enc->enc_pic.ec.enc_use_circular_buffer);
+   RVCE_CS(enc->pic.seq.profile_idc); // encProfile
+   RVCE_CS(enc->pic.seq.level_idc);                    // encLevel
+   RVCE_CS(enc->enc_pic.ec.enc_pic_struct_restriction);
+   RVCE_CS(align(enc->base.width, 16));  // encImageWidth
+   RVCE_CS(align(enc->base.height, 16)); // encImageHeight
+
+   if (sscreen->info.gfx_level < GFX9) {
+      RVCE_CS(enc->luma->u.legacy.level[0].nblk_x * enc->luma->bpe);     // encRefPicLumaPitch
+      RVCE_CS(enc->chroma->u.legacy.level[0].nblk_x * enc->chroma->bpe); // encRefPicChromaPitch
+      RVCE_CS(align(enc->luma->u.legacy.level[0].nblk_y, 16) / 8);       // encRefYHeightInQw
+   } else {
+      RVCE_CS(enc->luma->u.gfx9.surf_pitch * enc->luma->bpe);     // encRefPicLumaPitch
+      RVCE_CS(enc->chroma->u.gfx9.surf_pitch * enc->chroma->bpe); // encRefPicChromaPitch
+      RVCE_CS(align(enc->luma->u.gfx9.surf_height, 16) / 8);      // encRefYHeightInQw
+   }
+
+   RVCE_CS(enc->enc_pic.addrmode_arraymode_disrdo_distwoinstants);
+
+   if (enc->fw_version >= 52) {
+      RVCE_CS(enc->enc_pic.ec.enc_pre_encode_context_buffer_offset);
+      RVCE_CS(enc->enc_pic.ec.enc_pre_encode_input_luma_buffer_offset);
+      RVCE_CS(enc->enc_pic.ec.enc_pre_encode_input_chroma_buffer_offset);
+      RVCE_CS(enc->enc_pic.ec.enc_pre_encode_mode_chromaflag_vbaqmode_scenechangesensitivity);
+   }
+   RVCE_END();
+}
 
 /**
  * Calculate the offsets into the DPB
  */
-void si_vce_frame_offset(struct rvce_encoder *enc, unsigned slot, signed *luma_offset,
+static void frame_offset(struct rvce_encoder *enc, unsigned slot, signed *luma_offset,
                          signed *chroma_offset)
 {
    struct si_screen *sscreen = (struct si_screen *)enc->screen;
@@ -81,6 +359,477 @@ void si_vce_frame_offset(struct rvce_encoder *enc, unsigned slot, signed *luma_o
    *chroma_offset = *luma_offset + pitch * vpitch;
 }
 
+static void encode(struct rvce_encoder *enc)
+{
+   struct si_screen *sscreen = (struct si_screen *)enc->screen;
+   signed luma_offset, chroma_offset;
+   int i;
+
+   task_info(enc, 0x00000003, 0);
+
+   RVCE_BEGIN(0x05000001);                                      // context buffer
+   RVCE_READWRITE(enc->dpb.res->buf, enc->dpb.res->domains, 0); // encodeContextAddressHi/Lo
+   RVCE_END();
+
+   RVCE_BEGIN(0x05000004);                                   // video bitstream buffer
+   RVCE_WRITE(enc->bs_handle, RADEON_DOMAIN_GTT, enc->bs_offset); // videoBitstreamRingAddressHi/Lo
+   RVCE_CS(enc->bs_size);                                    // videoBitstreamRingSize
+   RVCE_END();
+
+   if (enc->dual_pipe) {
+      unsigned aux_offset = 0;
+      RVCE_BEGIN(0x05000002); // auxiliary buffer
+      for (i = 0; i < 8; ++i) {
+         RVCE_CS(aux_offset);
+         aux_offset += RVCE_MAX_BITSTREAM_OUTPUT_ROW_SIZE;
+      }
+      for (i = 0; i < 8; ++i)
+         RVCE_CS(RVCE_MAX_BITSTREAM_OUTPUT_ROW_SIZE);
+      RVCE_END();
+   }
+
+   RVCE_BEGIN(0x03000001);                       // encode
+   RVCE_CS(enc->enc_pic.eo.insert_headers);
+   RVCE_CS(enc->enc_pic.eo.picture_structure);
+   RVCE_CS(enc->bs_size - enc->bs_offset); // allowedMaxBitstreamSize
+   RVCE_CS(enc->enc_pic.eo.force_refresh_map);
+   RVCE_CS(enc->enc_pic.eo.insert_aud);
+   RVCE_CS(enc->enc_pic.eo.end_of_sequence);
+   RVCE_CS(enc->enc_pic.eo.end_of_stream);
+
+   if (sscreen->info.gfx_level < GFX9) {
+      RVCE_READ(enc->handle, RADEON_DOMAIN_VRAM,
+                (uint64_t)enc->luma->u.legacy.level[0].offset_256B * 256); // inputPictureLumaAddressHi/Lo
+      RVCE_READ(enc->handle, RADEON_DOMAIN_VRAM,
+                (uint64_t)enc->chroma->u.legacy.level[0].offset_256B * 256);        // inputPictureChromaAddressHi/Lo
+      RVCE_CS(align(enc->luma->u.legacy.level[0].nblk_y, 16)); // encInputFrameYPitch
+      RVCE_CS(enc->luma->u.legacy.level[0].nblk_x * enc->luma->bpe);     // encInputPicLumaPitch
+      RVCE_CS(enc->chroma->u.legacy.level[0].nblk_x * enc->chroma->bpe); // encInputPicChromaPitch
+   } else {
+      RVCE_READ(enc->handle, RADEON_DOMAIN_VRAM,
+                enc->luma->u.gfx9.surf_offset); // inputPictureLumaAddressHi/Lo
+      RVCE_READ(enc->handle, RADEON_DOMAIN_VRAM,
+                enc->chroma->u.gfx9.surf_offset);                 // inputPictureChromaAddressHi/Lo
+      RVCE_CS(align(enc->luma->u.gfx9.surf_height, 16));          // encInputFrameYPitch
+      RVCE_CS(enc->luma->u.gfx9.surf_pitch * enc->luma->bpe);     // encInputPicLumaPitch
+      RVCE_CS(enc->chroma->u.gfx9.surf_pitch * enc->chroma->bpe); // encInputPicChromaPitch
+      enc->enc_pic.eo.enc_input_pic_swizzle_mode = enc->luma->u.gfx9.swizzle_mode;
+   }
+
+   enc->enc_pic.eo.enc_disable_two_pipe_mode = enc->fw_version >= 50 ? !enc->dual_pipe : 0;
+   RVCE_CS(enc->enc_pic.eo.enc_input_pic_addr_array_disable2pipe_disablemboffload);
+   RVCE_CS(enc->enc_pic.eo.enc_input_pic_tile_config);
+   RVCE_CS(enc->enc_pic.picture_type);                                    // encPicType
+   RVCE_CS(enc->enc_pic.picture_type == PIPE_H2645_ENC_PICTURE_TYPE_IDR); // encIdrFlag
+   RVCE_CS(enc->enc_pic.eo.enc_idr_pic_id);
+   RVCE_CS(enc->enc_pic.eo.enc_mgs_key_pic);
+   RVCE_CS(!enc->enc_pic.not_referenced);
+   RVCE_CS(enc->enc_pic.eo.enc_temporal_layer_index);
+   RVCE_CS(enc->enc_pic.eo.num_ref_idx_active_override_flag);
+   RVCE_CS(enc->enc_pic.eo.num_ref_idx_l0_active_minus1);
+   RVCE_CS(enc->enc_pic.eo.num_ref_idx_l1_active_minus1);
+
+   for (i = 0; i < 4; ++i) {
+      RVCE_CS(enc->enc_pic.eo.enc_ref_list_modification_op[i]);
+      RVCE_CS(enc->enc_pic.eo.enc_ref_list_modification_num[i]);
+   }
+
+   for (i = 0; i < 4; ++i) {
+      RVCE_CS(enc->enc_pic.eo.enc_decoded_picture_marking_op[i]);
+      RVCE_CS(enc->enc_pic.eo.enc_decoded_picture_marking_num[i]);
+      RVCE_CS(enc->enc_pic.eo.enc_decoded_picture_marking_idx[i]);
+   }
+
+   for (i = 0; i < 4; ++i) {
+      RVCE_CS(enc->enc_pic.eo.enc_decoded_ref_base_picture_marking_op[i]);
+      RVCE_CS(enc->enc_pic.eo.enc_decoded_ref_base_picture_marking_num[i]);
+   }
+
+   // encReferencePictureL0[0]
+   if (enc->enc_pic.eo.l0_dpb_idx != PIPE_H2645_LIST_REF_INVALID_ENTRY) {
+      frame_offset(enc, enc->enc_pic.eo.l0_dpb_idx, &luma_offset, &chroma_offset);
+      enc->enc_pic.eo.l0_luma_offset = luma_offset;
+      enc->enc_pic.eo.l0_chroma_offset = chroma_offset;
+   } else {
+      enc->enc_pic.eo.l0_luma_offset = 0xffffffff;
+      enc->enc_pic.eo.l0_chroma_offset = 0xffffffff;
+   }
+   RVCE_CS(0x00000000); // pictureStructure
+   RVCE_CS(enc->enc_pic.eo.l0_enc_pic_type);
+   RVCE_CS(enc->enc_pic.eo.l0_frame_number);
+   RVCE_CS(enc->enc_pic.eo.l0_picture_order_count);
+   RVCE_CS(enc->enc_pic.eo.l0_luma_offset);
+   RVCE_CS(enc->enc_pic.eo.l0_chroma_offset);
+
+   // encReferencePictureL0[1]
+   enc->enc_pic.eo.l0_picture_structure = 0x00000000;
+   enc->enc_pic.eo.l0_enc_pic_type = 0x00000000;
+   enc->enc_pic.eo.l0_frame_number = 0x00000000;
+   enc->enc_pic.eo.l0_picture_order_count = 0x00000000;
+   enc->enc_pic.eo.l0_luma_offset = 0xffffffff;
+   enc->enc_pic.eo.l0_chroma_offset = 0xffffffff;
+   RVCE_CS(enc->enc_pic.eo.l0_picture_structure);
+   RVCE_CS(enc->enc_pic.eo.l0_enc_pic_type);
+   RVCE_CS(enc->enc_pic.eo.l0_frame_number);
+   RVCE_CS(enc->enc_pic.eo.l0_picture_order_count);
+   RVCE_CS(enc->enc_pic.eo.l0_luma_offset);
+   RVCE_CS(enc->enc_pic.eo.l0_chroma_offset);
+
+   // encReferencePictureL1[0]
+   RVCE_CS(0x00000000); // pictureStructure
+   RVCE_CS(enc->enc_pic.eo.l1_enc_pic_type);
+   RVCE_CS(enc->enc_pic.eo.l1_frame_number);
+   RVCE_CS(enc->enc_pic.eo.l1_picture_order_count);
+   RVCE_CS(enc->enc_pic.eo.l1_luma_offset);
+   RVCE_CS(enc->enc_pic.eo.l1_chroma_offset);
+
+   frame_offset(enc, enc->enc_pic.eo.cur_dpb_idx, &luma_offset, &chroma_offset);
+   RVCE_CS(luma_offset);
+   RVCE_CS(chroma_offset);
+   RVCE_CS(enc->enc_pic.eo.enc_coloc_buffer_offset);
+   RVCE_CS(enc->enc_pic.eo.enc_reconstructed_ref_base_picture_luma_offset);
+   RVCE_CS(enc->enc_pic.eo.enc_reconstructed_ref_base_picture_chroma_offset);
+   RVCE_CS(enc->enc_pic.eo.enc_reference_ref_base_picture_luma_offset);
+   RVCE_CS(enc->enc_pic.eo.enc_reference_ref_base_picture_chroma_offset);
+   RVCE_CS(enc->enc_pic.frame_num_cnt);
+   RVCE_CS(enc->enc_pic.frame_num);
+   RVCE_CS(enc->enc_pic.pic_order_cnt);
+   RVCE_CS(enc->enc_pic.i_remain);
+   RVCE_CS(enc->enc_pic.p_remain);
+   RVCE_CS(enc->enc_pic.eo.num_b_pic_remain_in_rcgop);
+   RVCE_CS(enc->enc_pic.eo.num_ir_pic_remain_in_rcgop);
+   RVCE_CS(enc->enc_pic.eo.enable_intra_refresh);
+
+   if (enc->fw_version >= 52) {
+      RVCE_CS(enc->enc_pic.eo.aq_variance_en);
+      RVCE_CS(enc->enc_pic.eo.aq_block_size);
+      RVCE_CS(enc->enc_pic.eo.aq_mb_variance_sel);
+      RVCE_CS(enc->enc_pic.eo.aq_frame_variance_sel);
+      RVCE_CS(enc->enc_pic.eo.aq_param_a);
+      RVCE_CS(enc->enc_pic.eo.aq_param_b);
+      RVCE_CS(enc->enc_pic.eo.aq_param_c);
+      RVCE_CS(enc->enc_pic.eo.aq_param_d);
+      RVCE_CS(enc->enc_pic.eo.aq_param_e);
+      RVCE_CS(enc->enc_pic.eo.context_in_sfb);
+   }
+   RVCE_END();
+}
+
+static void rate_control(struct rvce_encoder *enc)
+{
+   RVCE_BEGIN(0x04000005); // rate control
+   RVCE_CS(enc->enc_pic.rc.rc_method);
+   RVCE_CS(enc->enc_pic.rc.target_bitrate);
+   RVCE_CS(enc->enc_pic.rc.peak_bitrate);
+   RVCE_CS(enc->enc_pic.rc.frame_rate_num);
+   RVCE_CS(enc->enc_pic.rc.gop_size);
+   RVCE_CS(enc->enc_pic.rc.quant_i_frames);
+   RVCE_CS(enc->enc_pic.rc.quant_p_frames);
+   RVCE_CS(enc->enc_pic.rc.quant_b_frames);
+   RVCE_CS(enc->enc_pic.rc.vbv_buffer_size);
+   RVCE_CS(enc->enc_pic.rc.frame_rate_den);
+   RVCE_CS(enc->enc_pic.rc.vbv_buf_lv);
+   RVCE_CS(enc->enc_pic.rc.max_au_size);
+   RVCE_CS(enc->enc_pic.rc.qp_initial_mode);
+   RVCE_CS(enc->enc_pic.rc.target_bits_picture);
+   RVCE_CS(enc->enc_pic.rc.peak_bits_picture_integer);
+   RVCE_CS(enc->enc_pic.rc.peak_bits_picture_fraction);
+   RVCE_CS(enc->enc_pic.rc.min_qp);
+   RVCE_CS(enc->enc_pic.rc.max_qp);
+   RVCE_CS(enc->enc_pic.rc.skip_frame_enable);
+   RVCE_CS(enc->enc_pic.rc.fill_data_enable);
+   RVCE_CS(enc->enc_pic.rc.enforce_hrd);
+   RVCE_CS(enc->enc_pic.rc.b_pics_delta_qp);
+   RVCE_CS(enc->enc_pic.rc.ref_b_pics_delta_qp);
+   RVCE_CS(enc->enc_pic.rc.rc_reinit_disable);
+   if (enc->fw_version >= 50) {
+      RVCE_CS(enc->enc_pic.rc.enc_lcvbr_init_qp_flag);
+      RVCE_CS(enc->enc_pic.rc.lcvbrsatd_based_nonlinear_bit_budget_flag);
+   }
+   RVCE_END();
+}
+
+static void config_extension(struct rvce_encoder *enc)
+{
+   RVCE_BEGIN(0x04000001); // config extension
+   RVCE_CS(enc->enc_pic.ce.enc_enable_perf_logging);
+   RVCE_END();
+}
+
+static void feedback(struct rvce_encoder *enc)
+{
+   RVCE_BEGIN(0x05000005);                                    // feedback buffer
+   RVCE_WRITE(enc->fb->res->buf, enc->fb->res->domains, 0x0); // feedbackRingAddressHi/Lo
+   RVCE_CS(enc->enc_pic.fb.feedback_ring_size);
+   RVCE_END();
+}
+
+static void destroy(struct rvce_encoder *enc)
+{
+   task_info(enc, 0x00000001, 0);
+
+   feedback(enc);
+
+   RVCE_BEGIN(0x02000001); // destroy
+   RVCE_END();
+}
+
+static void motion_estimation(struct rvce_encoder *enc)
+{
+   RVCE_BEGIN(0x04000007); // motion estimation
+   RVCE_CS(enc->enc_pic.me.enc_ime_decimation_search);
+   RVCE_CS(enc->enc_pic.me.motion_est_half_pixel);
+   RVCE_CS(enc->enc_pic.me.motion_est_quarter_pixel);
+   RVCE_CS(enc->enc_pic.me.disable_favor_pmv_point);
+   RVCE_CS(enc->enc_pic.me.force_zero_point_center);
+   RVCE_CS(enc->enc_pic.me.lsmvert);
+   RVCE_CS(enc->enc_pic.me.enc_search_range_x);
+   RVCE_CS(enc->enc_pic.me.enc_search_range_y);
+   RVCE_CS(enc->enc_pic.me.enc_search1_range_x);
+   RVCE_CS(enc->enc_pic.me.enc_search1_range_y);
+   RVCE_CS(enc->enc_pic.me.disable_16x16_frame1);
+   RVCE_CS(enc->enc_pic.me.disable_satd);
+   RVCE_CS(enc->enc_pic.me.enable_amd);
+   RVCE_CS(enc->enc_pic.me.enc_disable_sub_mode);
+   RVCE_CS(enc->enc_pic.me.enc_ime_skip_x);
+   RVCE_CS(enc->enc_pic.me.enc_ime_skip_y);
+   RVCE_CS(enc->enc_pic.me.enc_en_ime_overw_dis_subm);
+   RVCE_CS(enc->enc_pic.me.enc_ime_overw_dis_subm_no);
+   RVCE_CS(enc->enc_pic.me.enc_ime2_search_range_x);
+   RVCE_CS(enc->enc_pic.me.enc_ime2_search_range_y);
+   RVCE_CS(enc->enc_pic.me.parallel_mode_speedup_enable);
+   RVCE_CS(enc->enc_pic.me.fme0_enc_disable_sub_mode);
+   RVCE_CS(enc->enc_pic.me.fme1_enc_disable_sub_mode);
+   RVCE_CS(enc->enc_pic.me.ime_sw_speedup_enable);
+   RVCE_END();
+}
+
+static void pic_control(struct rvce_encoder *enc)
+{
+   RVCE_BEGIN(0x04000002); // pic control
+   RVCE_CS(enc->enc_pic.pc.enc_use_constrained_intra_pred);
+   RVCE_CS(enc->enc_pic.pc.enc_cabac_enable);
+   RVCE_CS(enc->enc_pic.pc.enc_cabac_idc);
+   RVCE_CS(enc->enc_pic.pc.enc_loop_filter_disable);
+   RVCE_CS(enc->enc_pic.pc.enc_lf_beta_offset);
+   RVCE_CS(enc->enc_pic.pc.enc_lf_alpha_c0_offset);
+   RVCE_CS(enc->enc_pic.pc.enc_crop_left_offset);
+   RVCE_CS(enc->enc_pic.pc.enc_crop_right_offset);
+   RVCE_CS(enc->enc_pic.pc.enc_crop_top_offset);
+   RVCE_CS(enc->enc_pic.pc.enc_crop_bottom_offset);
+   RVCE_CS(enc->enc_pic.pc.enc_num_mbs_per_slice);
+   RVCE_CS(enc->enc_pic.pc.enc_intra_refresh_num_mbs_per_slot);
+   RVCE_CS(enc->enc_pic.pc.enc_force_intra_refresh);
+   RVCE_CS(enc->enc_pic.pc.enc_force_imb_period);
+   RVCE_CS(enc->enc_pic.pc.enc_pic_order_cnt_type);
+   RVCE_CS(enc->enc_pic.pc.log2_max_pic_order_cnt_lsb_minus4);
+   RVCE_CS(enc->enc_pic.pc.enc_sps_id);
+   RVCE_CS(enc->enc_pic.pc.enc_pps_id);
+   RVCE_CS(enc->enc_pic.pc.enc_constraint_set_flags);
+   RVCE_CS(enc->enc_pic.pc.enc_b_pic_pattern);
+   RVCE_CS(enc->enc_pic.pc.weight_pred_mode_b_picture);
+   RVCE_CS(enc->enc_pic.pc.enc_number_of_reference_frames);
+   RVCE_CS(enc->enc_pic.pc.enc_max_num_ref_frames);
+   RVCE_CS(enc->enc_pic.pc.enc_num_default_active_ref_l0);
+   RVCE_CS(enc->enc_pic.pc.enc_num_default_active_ref_l1);
+   RVCE_CS(enc->enc_pic.pc.enc_slice_mode);
+   RVCE_CS(enc->enc_pic.pc.enc_max_slice_size);
+   RVCE_END();
+}
+
+static void rdo(struct rvce_encoder *enc)
+{
+   RVCE_BEGIN(0x04000008); // rdo
+   RVCE_CS(enc->enc_pic.rdo.enc_disable_tbe_pred_i_frame);
+   RVCE_CS(enc->enc_pic.rdo.enc_disable_tbe_pred_p_frame);
+   RVCE_CS(enc->enc_pic.rdo.use_fme_interpol_y);
+   RVCE_CS(enc->enc_pic.rdo.use_fme_interpol_uv);
+   RVCE_CS(enc->enc_pic.rdo.use_fme_intrapol_y);
+   RVCE_CS(enc->enc_pic.rdo.use_fme_intrapol_uv);
+   RVCE_CS(enc->enc_pic.rdo.use_fme_interpol_y_1);
+   RVCE_CS(enc->enc_pic.rdo.use_fme_interpol_uv_1);
+   RVCE_CS(enc->enc_pic.rdo.use_fme_intrapol_y_1);
+   RVCE_CS(enc->enc_pic.rdo.use_fme_intrapol_uv_1);
+   RVCE_CS(enc->enc_pic.rdo.enc_16x16_cost_adj);
+   RVCE_CS(enc->enc_pic.rdo.enc_skip_cost_adj);
+   RVCE_CS(enc->enc_pic.rdo.enc_force_16x16_skip);
+   RVCE_CS(enc->enc_pic.rdo.enc_disable_threshold_calc_a);
+   RVCE_CS(enc->enc_pic.rdo.enc_luma_coeff_cost);
+   RVCE_CS(enc->enc_pic.rdo.enc_luma_mb_coeff_cost);
+   RVCE_CS(enc->enc_pic.rdo.enc_chroma_coeff_cost);
+   RVCE_END();
+}
+
+static void config(struct rvce_encoder *enc)
+{
+   task_info(enc, 0x00000002, 0xffffffff);
+   rate_control(enc);
+   config_extension(enc);
+   motion_estimation(enc);
+   rdo(enc);
+   pic_control(enc);
+}
+
+static void session(struct rvce_encoder *enc)
+{
+   RVCE_BEGIN(0x00000001); // session cmd
+   RVCE_CS(enc->stream_handle);
+   RVCE_END();
+}
+
+static unsigned int write_sps(struct rvce_encoder *enc, uint8_t nal_byte, uint8_t *out)
+{
+   struct pipe_h264_enc_seq_param *sps = &enc->pic.seq;
+   struct radeon_bitstream bs;
+
+   radeon_bs_reset(&bs, out, NULL);
+   radeon_bs_set_emulation_prevention(&bs, false);
+   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
+   radeon_bs_code_fixed_bits(&bs, nal_byte, 8);
+   radeon_bs_set_emulation_prevention(&bs, true);
+   radeon_bs_code_fixed_bits(&bs, sps->profile_idc, 8);
+   radeon_bs_code_fixed_bits(&bs, sps->enc_constraint_set_flags, 6);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 2); /* reserved_zero_2bits */
+   radeon_bs_code_fixed_bits(&bs, sps->level_idc, 8);
+   radeon_bs_code_ue(&bs, 0x0); /* seq_parameter_set_id */
+
+   if (sps->profile_idc == 100 || sps->profile_idc == 110 ||
+       sps->profile_idc == 122 || sps->profile_idc == 244 ||
+       sps->profile_idc == 44  || sps->profile_idc == 83 ||
+       sps->profile_idc == 86  || sps->profile_idc == 118 ||
+       sps->profile_idc == 128 || sps->profile_idc == 138) {
+      radeon_bs_code_ue(&bs, 0x1); /* chroma_format_idc */
+      radeon_bs_code_ue(&bs, 0x0); /* bit_depth_luma_minus8 */
+      radeon_bs_code_ue(&bs, 0x0); /* bit_depth_chroma_minus8 */
+      radeon_bs_code_fixed_bits(&bs, 0x0, 2); /* qpprime_y_zero_transform_bypass_flag + seq_scaling_matrix_present_flag */
+   }
+
+   radeon_bs_code_ue(&bs, 3); /* log2_max_frame_num_minus4 */
+   radeon_bs_code_ue(&bs, sps->pic_order_cnt_type);
+
+   if (sps->pic_order_cnt_type == 0)
+      radeon_bs_code_ue(&bs, sps->log2_max_pic_order_cnt_lsb_minus4);
+
+   radeon_bs_code_ue(&bs, sps->max_num_ref_frames);
+   radeon_bs_code_fixed_bits(&bs, sps->gaps_in_frame_num_value_allowed_flag, 1);
+   radeon_bs_code_ue(&bs, DIV_ROUND_UP(enc->base.width, 16) - 1);
+   radeon_bs_code_ue(&bs, DIV_ROUND_UP(enc->base.height, 16) - 1);
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* frame_mbs_only_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* direct_8x8_inference_flag */
+
+   radeon_bs_code_fixed_bits(&bs, sps->enc_frame_cropping_flag, 1);
+   if (sps->enc_frame_cropping_flag) {
+      radeon_bs_code_ue(&bs, sps->enc_frame_crop_left_offset);
+      radeon_bs_code_ue(&bs, sps->enc_frame_crop_right_offset);
+      radeon_bs_code_ue(&bs, sps->enc_frame_crop_top_offset);
+      radeon_bs_code_ue(&bs, sps->enc_frame_crop_bottom_offset);
+   }
+
+   radeon_bs_code_fixed_bits(&bs, sps->vui_parameters_present_flag, 1);
+   if (sps->vui_parameters_present_flag) {
+      radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.aspect_ratio_info_present_flag), 1);
+      if (sps->vui_flags.aspect_ratio_info_present_flag) {
+         radeon_bs_code_fixed_bits(&bs, (sps->aspect_ratio_idc), 8);
+         if (sps->aspect_ratio_idc == PIPE_H2645_EXTENDED_SAR) {
+            radeon_bs_code_fixed_bits(&bs, (sps->sar_width), 16);
+            radeon_bs_code_fixed_bits(&bs, (sps->sar_height), 16);
+         }
+      }
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.overscan_info_present_flag, 1);
+      if (sps->vui_flags.overscan_info_present_flag)
+         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.overscan_appropriate_flag, 1);
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.video_signal_type_present_flag, 1);
+      if (sps->vui_flags.video_signal_type_present_flag) {
+         radeon_bs_code_fixed_bits(&bs, sps->video_format, 3);
+         radeon_bs_code_fixed_bits(&bs, sps->video_full_range_flag, 1);
+         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.colour_description_present_flag, 1);
+         if (sps->vui_flags.colour_description_present_flag) {
+            radeon_bs_code_fixed_bits(&bs, sps->colour_primaries, 8);
+            radeon_bs_code_fixed_bits(&bs, sps->transfer_characteristics, 8);
+            radeon_bs_code_fixed_bits(&bs, sps->matrix_coefficients, 8);
+         }
+      }
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.chroma_loc_info_present_flag, 1);
+      if (sps->vui_flags.chroma_loc_info_present_flag) {
+         radeon_bs_code_ue(&bs, sps->chroma_sample_loc_type_top_field);
+         radeon_bs_code_ue(&bs, sps->chroma_sample_loc_type_bottom_field);
+      }
+      radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.timing_info_present_flag), 1);
+      if (sps->vui_flags.timing_info_present_flag) {
+         radeon_bs_code_fixed_bits(&bs, (sps->num_units_in_tick), 32);
+         radeon_bs_code_fixed_bits(&bs, (sps->time_scale), 32);
+         radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.fixed_frame_rate_flag), 1);
+      }
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.nal_hrd_parameters_present_flag, 1);
+      if (sps->vui_flags.nal_hrd_parameters_present_flag)
+         radeon_bs_h264_hrd_parameters(&bs, &sps->nal_hrd_parameters);
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.vcl_hrd_parameters_present_flag, 1);
+      if (sps->vui_flags.vcl_hrd_parameters_present_flag)
+         radeon_bs_h264_hrd_parameters(&bs, &sps->vcl_hrd_parameters);
+      if (sps->vui_flags.nal_hrd_parameters_present_flag || sps->vui_flags.vcl_hrd_parameters_present_flag)
+         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.low_delay_hrd_flag, 1);
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.pic_struct_present_flag, 1);
+      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.bitstream_restriction_flag, 1);
+      if (sps->vui_flags.bitstream_restriction_flag) {
+         radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* motion_vectors_over_pic_boundaries_flag */
+         radeon_bs_code_ue(&bs, 0x2); /* max_bytes_per_pic_denom */
+         radeon_bs_code_ue(&bs, 0x1); /* max_bits_per_mb_denom */
+         radeon_bs_code_ue(&bs, 0x10); /* log2_max_mv_length_horizontal */
+         radeon_bs_code_ue(&bs, 0x10); /* log2_max_mv_length_vertical */
+         radeon_bs_code_ue(&bs, sps->max_num_reorder_frames);
+         radeon_bs_code_ue(&bs, sps->max_dec_frame_buffering);
+      }
+   }
+
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
+   radeon_bs_byte_align(&bs);
+
+   return bs.bits_output / 8;
+}
+
+static unsigned int write_pps(struct rvce_encoder *enc, uint8_t nal_byte, uint8_t *out)
+{
+   struct radeon_bitstream bs;
+
+   radeon_bs_reset(&bs, out, NULL);
+   radeon_bs_set_emulation_prevention(&bs, false);
+   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
+   radeon_bs_code_fixed_bits(&bs, nal_byte, 8);
+   radeon_bs_set_emulation_prevention(&bs, true);
+   radeon_bs_code_ue(&bs, 0x0); /* pic_parameter_set_id */
+   radeon_bs_code_ue(&bs, 0x0); /* seq_parameter_set_id */
+   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.pc.enc_cabac_enable, 1);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* bottom_field_pic_order_in_frame_present_flag */
+   radeon_bs_code_ue(&bs, 0x0); /* num_slice_groups_minus_1 */
+   radeon_bs_code_ue(&bs, enc->enc_pic.pc.enc_num_default_active_ref_l0 - 1);
+   radeon_bs_code_ue(&bs, enc->enc_pic.pc.enc_num_default_active_ref_l1 - 1);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* weighted_pred_flag */
+   radeon_bs_code_fixed_bits(&bs, 0x0, 2); /* weighted_bipred_idc */
+   radeon_bs_code_se(&bs, 0x0); /* pic_init_qp_minus26 */
+   radeon_bs_code_se(&bs, 0x0); /* pic_init_qs_minus26 */
+   radeon_bs_code_se(&bs, 0x0); /* chroma_qp_index_offset */
+   bool deblocking_filter_present_flag =
+      enc->enc_pic.pc.enc_loop_filter_disable ||
+      enc->enc_pic.pc.enc_lf_beta_offset ||
+      enc->enc_pic.pc.enc_lf_alpha_c0_offset;
+   radeon_bs_code_fixed_bits(&bs, deblocking_filter_present_flag, 1);
+   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.pc.enc_use_constrained_intra_pred, 1);
+   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* redundant_pic_cnt_present_flag */
+
+   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
+   radeon_bs_byte_align(&bs);
+
+   return bs.bits_output / 8;
+}
+
+/**
+ * flush commands to the hardware
+ */
+static void flush(struct rvce_encoder *enc, unsigned flags, struct pipe_fence_handle **fence)
+{
+   enc->ws->cs_flush(&enc->cs, flags, fence);
+}
+
 /**
  * destroy this video encoder
  */
@@ -91,8 +840,8 @@ static void rvce_destroy(struct pipe_video_codec *encoder)
       struct rvid_buffer fb;
       si_vid_create_buffer(enc->screen, &fb, 512, PIPE_USAGE_STAGING);
       enc->fb = &fb;
-      enc->session(enc);
-      enc->destroy(enc);
+      session(enc);
+      destroy(enc);
       flush(enc, PIPE_FLUSH_ASYNC, NULL);
       si_vid_destroy_buffer(&fb);
    }
@@ -141,7 +890,7 @@ static void rvce_begin_frame(struct pipe_video_codec *encoder, struct pipe_video
       enc->pic.rate_ctrl[0].frame_rate_den != pic->rate_ctrl[0].frame_rate_den;
 
    enc->pic = *pic;
-   enc->si_get_pic_param(enc, pic);
+   get_param(enc, pic);
 
    enc->get_buffer(vid_buf->resources[0], &enc->handle, &enc->luma);
    enc->get_buffer(vid_buf->resources[1], NULL, &enc->chroma);
@@ -168,19 +917,18 @@ static void rvce_begin_frame(struct pipe_video_codec *encoder, struct pipe_video
       enc->stream_handle = si_vid_alloc_stream_handle();
       si_vid_create_buffer(enc->screen, &fb, 512, PIPE_USAGE_STAGING);
       enc->fb = &fb;
-      enc->session(enc);
-      enc->create(enc);
-      enc->config(enc);
-      enc->feedback(enc);
+      session(enc);
+      create(enc);
+      config(enc);
+      feedback(enc);
       flush(enc, PIPE_FLUSH_ASYNC, NULL);
-      // dump_feedback(enc, &fb);
       si_vid_destroy_buffer(&fb);
       need_rate_control = false;
    }
 
    if (need_rate_control) {
-      enc->session(enc);
-      enc->config(enc);
+      session(enc);
+      config(enc);
       flush(enc, PIPE_FLUSH_ASYNC, NULL);
    }
 }
@@ -229,10 +977,10 @@ static void *si_vce_encode_headers(struct rvce_encoder *enc)
 
          switch (header->type) {
          case PIPE_H264_NAL_SPS:
-            size = si_vce_write_sps(enc, nal_byte, ptr + offset);
+            size = write_sps(enc, nal_byte, ptr + offset);
             break;
          case PIPE_H264_NAL_PPS:
-            size = si_vce_write_pps(enc, nal_byte, ptr + offset);
+            size = write_pps(enc, nal_byte, ptr + offset);
             break;
          default:
             assert(header->buffer);
@@ -275,10 +1023,9 @@ static void rvce_encode_bitstream(struct pipe_video_codec *encoder,
 
    enc->fb->user_data = si_vce_encode_headers(enc);
 
-   if (!radeon_emitted(&enc->cs, 0))
-      enc->session(enc);
-   enc->encode(enc);
-   enc->feedback(enc);
+   session(enc);
+   encode(enc);
+   feedback(enc);
 }
 
 static int rvce_end_frame(struct pipe_video_codec *encoder, struct pipe_video_buffer *source,
@@ -332,7 +1079,6 @@ static void rvce_get_feedback(struct pipe_video_codec *encoder, void *feedback,
       metadata->codec_unit_metadata[0].flags = 0;
    }
 
-   // dump_feedback(enc, fb);
    si_vid_destroy_buffer(fb);
    FREE(fb);
 }
@@ -415,7 +1161,6 @@ struct pipe_video_codec *si_vce_create_encoder(struct pipe_context *context,
    }
 
    enc->fw_version = (sscreen->info.vce_fw_version & (0xff << 24)) >> 24;
-   si_vce_52_init(enc);
 
    return &enc->base;
 
diff --git a/src/gallium/drivers/radeonsi/radeon_vce.h b/src/gallium/drivers/radeonsi/radeon_vce.h
index 71961c23ba4..70abb7b3ebb 100644
--- a/src/gallium/drivers/radeonsi/radeon_vce.h
+++ b/src/gallium/drivers/radeonsi/radeon_vce.h
@@ -282,42 +282,21 @@ struct rvce_h264_enc_pic {
    struct rvce_enc_create ec;
    struct rvce_config_ext ce;
 
-   unsigned quant_i_frames;
-   unsigned quant_p_frames;
-   unsigned quant_b_frames;
-
    enum pipe_h2645_enc_picture_type picture_type;
    unsigned frame_num;
    unsigned frame_num_cnt;
    unsigned p_remain;
    unsigned i_remain;
-   unsigned idr_pic_id;
    unsigned pic_order_cnt;
    unsigned addrmode_arraymode_disrdo_distwoinstants;
 
    bool not_referenced;
-   bool is_idr;
 };
 
 /* VCE encoder representation */
 struct rvce_encoder {
    struct pipe_video_codec base;
 
-   /* version specific packets */
-   void (*session)(struct rvce_encoder *enc);
-   void (*create)(struct rvce_encoder *enc);
-   void (*feedback)(struct rvce_encoder *enc);
-   void (*rate_control)(struct rvce_encoder *enc);
-   void (*config_extension)(struct rvce_encoder *enc);
-   void (*pic_control)(struct rvce_encoder *enc);
-   void (*motion_estimation)(struct rvce_encoder *enc);
-   void (*rdo)(struct rvce_encoder *enc);
-   void (*config)(struct rvce_encoder *enc);
-   void (*encode)(struct rvce_encoder *enc);
-   void (*destroy)(struct rvce_encoder *enc);
-   void (*task_info)(struct rvce_encoder *enc, uint32_t op, uint32_t fb_idx);
-   void (*si_get_pic_param)(struct rvce_encoder *enc, struct pipe_h264_enc_picture_desc *pic);
-
    unsigned stream_handle;
 
    struct pipe_screen *screen;
@@ -357,13 +336,6 @@ struct rvce_feedback_data {
    struct rvce_output_unit_segment segments[];
 };
 
-unsigned int si_vce_write_sps(struct rvce_encoder *enc, uint8_t nal_byte, uint8_t *out);
-unsigned int si_vce_write_pps(struct rvce_encoder *enc, uint8_t nal_byte, uint8_t *out);
-
-/* CPB handling functions */
-void si_vce_frame_offset(struct rvce_encoder *enc, unsigned slot, signed *luma_offset,
-                         signed *chroma_offset);
-
 struct pipe_video_codec *si_vce_create_encoder(struct pipe_context *context,
                                                const struct pipe_video_codec *templat,
                                                struct radeon_winsys *ws,
@@ -374,7 +346,4 @@ bool si_vce_is_fw_version_supported(struct si_screen *sscreen);
 void si_vce_add_buffer(struct rvce_encoder *enc, struct pb_buffer_lean *buf, unsigned usage,
                        enum radeon_bo_domain domain, signed offset);
 
-/* init vce fw 52 specific callbacks */
-void si_vce_52_init(struct rvce_encoder *enc);
-
 #endif
diff --git a/src/gallium/drivers/radeonsi/radeon_vce_52.c b/src/gallium/drivers/radeonsi/radeon_vce_52.c
deleted file mode 100644
index 65a11653303..00000000000
--- a/src/gallium/drivers/radeonsi/radeon_vce_52.c
+++ /dev/null
@@ -1,815 +0,0 @@
-/**************************************************************************
- *
- * Copyright 2015 Advanced Micro Devices, Inc.
- *
- * SPDX-License-Identifier: MIT
- *
- **************************************************************************/
-
-#include "pipe/p_video_codec.h"
-#include "radeon_vce.h"
-#include "radeon_video.h"
-#include "radeon_bitstream.h"
-#include "radeonsi/si_pipe.h"
-#include "util/u_memory.h"
-#include "util/u_video.h"
-#include "vl/vl_video_buffer.h"
-
-#include <stdio.h>
-
-#define REF_LIST_MODIFICATION_OP_END                  0
-#define REF_LIST_MODIFICATION_OP_SHORT_TERM_SUBTRACT  1
-#define REF_LIST_MODIFICATION_OP_LONG_TERM            2
-#define REF_LIST_MODIFICATION_OP_VIEW_ADD             3
-
-#define INTRAREFRESH_METHOD_BAR_BASED                 6
-
-static void get_rate_control_param(struct rvce_encoder *enc, struct pipe_h264_enc_picture_desc *pic)
-{
-   enc->enc_pic.rc.rc_method = pic->rate_ctrl[0].rate_ctrl_method;
-   enc->enc_pic.rc.target_bitrate = pic->rate_ctrl[0].target_bitrate;
-   enc->enc_pic.rc.peak_bitrate = pic->rate_ctrl[0].peak_bitrate;
-   enc->enc_pic.rc.quant_i_frames = pic->quant_i_frames;
-   enc->enc_pic.rc.quant_p_frames = pic->quant_p_frames;
-   enc->enc_pic.rc.quant_b_frames = pic->quant_b_frames;
-   enc->enc_pic.rc.gop_size = pic->gop_size;
-   enc->enc_pic.rc.frame_rate_num = pic->rate_ctrl[0].frame_rate_num;
-   enc->enc_pic.rc.frame_rate_den = pic->rate_ctrl[0].frame_rate_den;
-   enc->enc_pic.rc.min_qp = pic->rate_ctrl[0].min_qp;
-   enc->enc_pic.rc.max_qp = pic->rate_ctrl[0].max_qp ? pic->rate_ctrl[0].max_qp : 51;
-   enc->enc_pic.rc.max_au_size = pic->rate_ctrl[0].max_au_size;
-   enc->enc_pic.rc.vbv_buffer_size = pic->rate_ctrl[0].vbv_buffer_size;
-   enc->enc_pic.rc.vbv_buf_lv = pic->rate_ctrl[0].vbv_buf_lv;
-   enc->enc_pic.rc.fill_data_enable = pic->rate_ctrl[0].fill_data_enable;
-   enc->enc_pic.rc.enforce_hrd = pic->rate_ctrl[0].enforce_hrd;
-   enc->enc_pic.rc.target_bits_picture =
-      enc->pic.rate_ctrl[0].target_bitrate *
-      ((float)enc->pic.rate_ctrl[0].frame_rate_den /
-      enc->pic.rate_ctrl[0].frame_rate_num);
-   enc->enc_pic.rc.peak_bits_picture_integer =
-      enc->pic.rate_ctrl[0].peak_bitrate *
-      ((float)enc->pic.rate_ctrl[0].frame_rate_den /
-      enc->pic.rate_ctrl[0].frame_rate_num);
-   enc->enc_pic.rc.peak_bits_picture_fraction =
-      (((enc->pic.rate_ctrl[0].peak_bitrate *
-      (uint64_t)enc->pic.rate_ctrl[0].frame_rate_den) %
-      enc->pic.rate_ctrl[0].frame_rate_num) << 32) /
-      enc->pic.rate_ctrl[0].frame_rate_num;
-}
-
-static void get_motion_estimation_param(struct rvce_encoder *enc,
-                                        struct pipe_h264_enc_picture_desc *pic)
-{
-   enc->enc_pic.me.enc_ime_decimation_search = 1;
-   enc->enc_pic.me.motion_est_half_pixel = 1;
-   enc->enc_pic.me.motion_est_quarter_pixel = 1;
-   enc->enc_pic.me.disable_favor_pmv_point = 0;
-   enc->enc_pic.me.lsmvert = 2;
-   enc->enc_pic.me.disable_16x16_frame1 = 0;
-   enc->enc_pic.me.disable_satd = 0;
-   enc->enc_pic.me.enc_ime_skip_x = 0;
-   enc->enc_pic.me.enc_ime_skip_y = 0;
-   enc->enc_pic.me.enc_ime2_search_range_x = 4;
-   enc->enc_pic.me.enc_ime2_search_range_y = 4;
-   enc->enc_pic.me.parallel_mode_speedup_enable = 0;
-   enc->enc_pic.me.fme0_enc_disable_sub_mode = 0;
-   enc->enc_pic.me.fme1_enc_disable_sub_mode = 0;
-   enc->enc_pic.me.ime_sw_speedup_enable = 0;
-
-   switch (pic->quality_modes.preset_mode) {
-   case 0: /* SPEED */
-      enc->enc_pic.me.force_zero_point_center = 0;
-      enc->enc_pic.me.enc_search_range_x = 16;
-      enc->enc_pic.me.enc_search_range_y = 16;
-      enc->enc_pic.me.enc_search1_range_x = 16;
-      enc->enc_pic.me.enc_search1_range_y = 16;
-      enc->enc_pic.me.enable_amd = 0;
-      enc->enc_pic.me.enc_disable_sub_mode = 126;
-      enc->enc_pic.me.enc_en_ime_overw_dis_subm = 0;
-      enc->enc_pic.me.enc_ime_overw_dis_subm_no = 0;
-      break;
-   case 1: /* BALANCED */
-      enc->enc_pic.me.force_zero_point_center = 0;
-      enc->enc_pic.me.enc_search_range_x = 16;
-      enc->enc_pic.me.enc_search_range_y = 16;
-      enc->enc_pic.me.enc_search1_range_x = 16;
-      enc->enc_pic.me.enc_search1_range_y = 16;
-      enc->enc_pic.me.enable_amd = 0;
-      enc->enc_pic.me.enc_disable_sub_mode = 120;
-      enc->enc_pic.me.enc_en_ime_overw_dis_subm = 1;
-      enc->enc_pic.me.enc_ime_overw_dis_subm_no = 1;
-      break;
-   case 2: /* QUALITY */
-   default:
-      enc->enc_pic.me.force_zero_point_center = 1;
-      enc->enc_pic.me.enc_search_range_x = 36;
-      enc->enc_pic.me.enc_search_range_y = 36;
-      enc->enc_pic.me.enc_search1_range_x = 36;
-      enc->enc_pic.me.enc_search1_range_y = 36;
-      enc->enc_pic.me.enable_amd = 1;
-      enc->enc_pic.me.enc_disable_sub_mode = 0;
-      enc->enc_pic.me.enc_en_ime_overw_dis_subm = 0;
-      enc->enc_pic.me.enc_ime_overw_dis_subm_no = 0;
-      break;
-   }
-}
-
-static void get_pic_control_param(struct rvce_encoder *enc, struct pipe_h264_enc_picture_desc *pic)
-{
-   uint32_t num_mbs_total, num_mbs_in_slice;
-
-   num_mbs_total = DIV_ROUND_UP(enc->base.width, 16) * DIV_ROUND_UP(enc->base.height, 16);
-
-   if (pic->num_slice_descriptors <= 1) {
-      num_mbs_in_slice = num_mbs_total;
-   } else {
-      bool use_app_config = true;
-      num_mbs_in_slice = pic->slices_descriptors[0].num_macroblocks;
-
-      /* All slices must have equal size */
-      for (unsigned i = 1; i < pic->num_slice_descriptors - 1; i++) {
-         if (num_mbs_in_slice != pic->slices_descriptors[i].num_macroblocks)
-            use_app_config = false;
-      }
-      /* Except last one can be smaller */
-      if (pic->slices_descriptors[pic->num_slice_descriptors - 1].num_macroblocks > num_mbs_in_slice)
-         use_app_config = false;
-
-      if (!use_app_config) {
-         assert(num_mbs_total >= pic->num_slice_descriptors);
-         num_mbs_in_slice =
-            (num_mbs_total + pic->num_slice_descriptors - 1) / pic->num_slice_descriptors;
-      }
-   }
-
-   if (pic->seq.enc_frame_cropping_flag) {
-      enc->enc_pic.pc.enc_crop_left_offset = pic->seq.enc_frame_crop_left_offset;
-      enc->enc_pic.pc.enc_crop_right_offset = pic->seq.enc_frame_crop_right_offset;
-      enc->enc_pic.pc.enc_crop_top_offset = pic->seq.enc_frame_crop_top_offset;
-      enc->enc_pic.pc.enc_crop_bottom_offset = pic->seq.enc_frame_crop_bottom_offset;
-   }
-   enc->enc_pic.pc.enc_num_mbs_per_slice = num_mbs_in_slice;
-   enc->enc_pic.pc.enc_number_of_reference_frames = 1;
-   enc->enc_pic.pc.enc_max_num_ref_frames = pic->seq.max_num_ref_frames;
-   enc->enc_pic.pc.enc_num_default_active_ref_l0 = pic->pic_ctrl.num_ref_idx_l0_default_active_minus1 + 1;
-   enc->enc_pic.pc.enc_num_default_active_ref_l1 = pic->pic_ctrl.num_ref_idx_l1_default_active_minus1 + 1;
-   enc->enc_pic.pc.enc_slice_mode = 1;
-   enc->enc_pic.pc.enc_use_constrained_intra_pred = pic->pic_ctrl.constrained_intra_pred_flag;
-   enc->enc_pic.pc.enc_cabac_enable = pic->pic_ctrl.enc_cabac_enable;
-   enc->enc_pic.pc.enc_cabac_idc = pic->pic_ctrl.enc_cabac_init_idc;
-   enc->enc_pic.pc.enc_constraint_set_flags = pic->seq.enc_constraint_set_flags << 2;
-   enc->enc_pic.pc.enc_loop_filter_disable = !!pic->dbk.disable_deblocking_filter_idc;
-   enc->enc_pic.pc.enc_lf_beta_offset = pic->dbk.beta_offset_div2;
-   enc->enc_pic.pc.enc_lf_alpha_c0_offset = pic->dbk.alpha_c0_offset_div2;
-   enc->enc_pic.pc.enc_pic_order_cnt_type = pic->seq.pic_order_cnt_type;
-   enc->enc_pic.pc.log2_max_pic_order_cnt_lsb_minus4 = pic->seq.log2_max_pic_order_cnt_lsb_minus4;
-}
-
-static void get_task_info_param(struct rvce_encoder *enc)
-{
-   enc->enc_pic.ti.offset_of_next_task_info = 0xffffffff;
-}
-
-static void get_feedback_buffer_param(struct rvce_encoder *enc, struct pipe_enc_feedback_metadata* metadata)
-{
-   enc->enc_pic.fb.feedback_ring_size = 0x00000001;
-}
-
-static void get_config_ext_param(struct rvce_encoder *enc)
-{
-   enc->enc_pic.ce.enc_enable_perf_logging = 0x00000003;
-}
-
-static void get_param(struct rvce_encoder *enc, struct pipe_h264_enc_picture_desc *pic)
-{
-   int i;
-
-   get_rate_control_param(enc, pic);
-   get_motion_estimation_param(enc, pic);
-   get_pic_control_param(enc, pic);
-   get_task_info_param(enc);
-   get_feedback_buffer_param(enc, NULL);
-   get_config_ext_param(enc);
-
-   enc->enc_pic.picture_type = pic->picture_type;
-   enc->enc_pic.frame_num = pic->frame_num;
-   enc->enc_pic.frame_num_cnt = pic->frame_num_cnt - 1;
-   enc->enc_pic.p_remain = pic->p_remain;
-   enc->enc_pic.i_remain = pic->i_remain;
-   enc->enc_pic.pic_order_cnt = pic->pic_order_cnt;
-   enc->enc_pic.not_referenced = pic->not_referenced;
-   enc->enc_pic.addrmode_arraymode_disrdo_distwoinstants = enc->fw_version >= 52 ? 0x01000201 : 0;
-   enc->enc_pic.is_idr = (pic->picture_type == PIPE_H2645_ENC_PICTURE_TYPE_IDR);
-   enc->enc_pic.eo.enc_idr_pic_id = pic->idr_pic_id;
-   enc->enc_pic.ec.enc_vbaq_mode =
-      pic->rate_ctrl[0].rate_ctrl_method != PIPE_H2645_ENC_RATE_CONTROL_METHOD_DISABLE &&
-      pic->quality_modes.vbaq_mode;
-   if (pic->intra_refresh.mode != PIPE_VIDEO_ENC_INTRA_REFRESH_NONE) {
-      enc->enc_pic.eo.enable_intra_refresh = 1;
-      enc->enc_pic.pc.enc_force_intra_refresh = INTRAREFRESH_METHOD_BAR_BASED;
-      enc->enc_pic.pc.enc_intra_refresh_num_mbs_per_slot = pic->intra_refresh.region_size;
-   } else {
-      enc->enc_pic.eo.enable_intra_refresh = 0;
-   }
-
-   enc->enc_pic.eo.num_ref_idx_active_override_flag = pic->slice.num_ref_idx_active_override_flag;
-   enc->enc_pic.eo.num_ref_idx_l0_active_minus1 = pic->slice.num_ref_idx_l0_active_minus1;
-   enc->enc_pic.eo.num_ref_idx_l1_active_minus1 = pic->slice.num_ref_idx_l1_active_minus1;
-
-   i = 0;
-   if (pic->slice.ref_pic_list_modification_flag_l0) {
-      for (; i < MIN2(4, pic->slice.num_ref_list0_mod_operations); i++) {
-         struct pipe_h264_ref_list_mod_entry *entry = &pic->slice.ref_list0_mod_operations[i];
-         switch (entry->modification_of_pic_nums_idc) {
-         case 0:
-            enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_SHORT_TERM_SUBTRACT;
-            enc->enc_pic.eo.enc_ref_list_modification_num[i] = entry->abs_diff_pic_num_minus1;
-            break;
-         case 2:
-            enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_LONG_TERM;
-            enc->enc_pic.eo.enc_ref_list_modification_num[i] = entry->long_term_pic_num;
-            break;
-         case 5:
-            enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_VIEW_ADD;
-            enc->enc_pic.eo.enc_ref_list_modification_num[i] = entry->abs_diff_pic_num_minus1;
-            break;
-         default:
-         case 3:
-            enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_END;
-            break;
-         }
-      }
-   }
-   if (i < 4)
-      enc->enc_pic.eo.enc_ref_list_modification_op[i] = REF_LIST_MODIFICATION_OP_END;
-
-   i = 0;
-   if (pic->pic_ctrl.nal_unit_type == PIPE_H264_NAL_IDR_SLICE) {
-      enc->enc_pic.eo.enc_decoded_picture_marking_op[i++] = pic->slice.long_term_reference_flag ? 6 : 0;
-   } else if (pic->slice.adaptive_ref_pic_marking_mode_flag) {
-      for (; i < MIN2(4, pic->slice.num_ref_pic_marking_operations); i++) {
-         struct pipe_h264_ref_pic_marking_entry *entry = &pic->slice.ref_pic_marking_operations[i];
-         enc->enc_pic.eo.enc_decoded_picture_marking_op[i] = entry->memory_management_control_operation;
-         switch (entry->memory_management_control_operation) {
-         case 1:
-            enc->enc_pic.eo.enc_decoded_picture_marking_num[i] = entry->difference_of_pic_nums_minus1;
-            break;
-         case 2:
-            enc->enc_pic.eo.enc_decoded_picture_marking_num[i] = entry->long_term_pic_num;
-            break;
-         case 3:
-            enc->enc_pic.eo.enc_decoded_picture_marking_num[i] = entry->difference_of_pic_nums_minus1;
-            enc->enc_pic.eo.enc_decoded_picture_marking_idx[i] = entry->long_term_frame_idx;
-            break;
-         case 4:
-            enc->enc_pic.eo.enc_decoded_picture_marking_idx[i] = entry->max_long_term_frame_idx_plus1;
-            break;
-         case 6:
-            enc->enc_pic.eo.enc_decoded_picture_marking_idx[i] = entry->long_term_frame_idx;
-            break;
-         default:
-            break;
-         }
-      }
-   }
-   if (i < 4)
-      enc->enc_pic.eo.enc_decoded_picture_marking_op[i] = 0;
-
-   enc->enc_pic.eo.cur_dpb_idx = pic->dpb_curr_pic;
-
-   enc->enc_pic.eo.l0_dpb_idx = pic->ref_list0[0];
-
-   enc->enc_pic.eo.l1_dpb_idx = PIPE_H2645_LIST_REF_INVALID_ENTRY;
-   enc->enc_pic.eo.l1_luma_offset = 0xffffffff;
-   enc->enc_pic.eo.l1_chroma_offset = 0xffffffff;
-}
-
-static void create(struct rvce_encoder *enc)
-{
-   struct si_screen *sscreen = (struct si_screen *)enc->screen;
-   enc->task_info(enc, 0x00000000, 0);
-
-   RVCE_BEGIN(0x01000001); // create cmd
-   RVCE_CS(enc->enc_pic.ec.enc_use_circular_buffer);
-   RVCE_CS(enc->pic.seq.profile_idc); // encProfile
-   RVCE_CS(enc->pic.seq.level_idc);                    // encLevel
-   RVCE_CS(enc->enc_pic.ec.enc_pic_struct_restriction);
-   RVCE_CS(align(enc->base.width, 16));  // encImageWidth
-   RVCE_CS(align(enc->base.height, 16)); // encImageHeight
-
-   if (sscreen->info.gfx_level < GFX9) {
-      RVCE_CS(enc->luma->u.legacy.level[0].nblk_x * enc->luma->bpe);     // encRefPicLumaPitch
-      RVCE_CS(enc->chroma->u.legacy.level[0].nblk_x * enc->chroma->bpe); // encRefPicChromaPitch
-      RVCE_CS(align(enc->luma->u.legacy.level[0].nblk_y, 16) / 8);       // encRefYHeightInQw
-   } else {
-      RVCE_CS(enc->luma->u.gfx9.surf_pitch * enc->luma->bpe);     // encRefPicLumaPitch
-      RVCE_CS(enc->chroma->u.gfx9.surf_pitch * enc->chroma->bpe); // encRefPicChromaPitch
-      RVCE_CS(align(enc->luma->u.gfx9.surf_height, 16) / 8);      // encRefYHeightInQw
-   }
-
-   RVCE_CS(enc->enc_pic.addrmode_arraymode_disrdo_distwoinstants);
-
-   if (enc->fw_version >= 52) {
-      RVCE_CS(enc->enc_pic.ec.enc_pre_encode_context_buffer_offset);
-      RVCE_CS(enc->enc_pic.ec.enc_pre_encode_input_luma_buffer_offset);
-      RVCE_CS(enc->enc_pic.ec.enc_pre_encode_input_chroma_buffer_offset);
-      RVCE_CS(enc->enc_pic.ec.enc_pre_encode_mode_chromaflag_vbaqmode_scenechangesensitivity);
-   }
-   RVCE_END();
-}
-
-static void encode(struct rvce_encoder *enc)
-{
-   struct si_screen *sscreen = (struct si_screen *)enc->screen;
-   signed luma_offset, chroma_offset;
-   int i;
-
-   enc->task_info(enc, 0x00000003, 0);
-
-   RVCE_BEGIN(0x05000001);                                      // context buffer
-   RVCE_READWRITE(enc->dpb.res->buf, enc->dpb.res->domains, 0); // encodeContextAddressHi/Lo
-   RVCE_END();
-
-   RVCE_BEGIN(0x05000004);                                   // video bitstream buffer
-   RVCE_WRITE(enc->bs_handle, RADEON_DOMAIN_GTT, enc->bs_offset); // videoBitstreamRingAddressHi/Lo
-   RVCE_CS(enc->bs_size);                                    // videoBitstreamRingSize
-   RVCE_END();
-
-   if (enc->dual_pipe) {
-      unsigned aux_offset = 0;
-      RVCE_BEGIN(0x05000002); // auxiliary buffer
-      for (i = 0; i < 8; ++i) {
-         RVCE_CS(aux_offset);
-         aux_offset += RVCE_MAX_BITSTREAM_OUTPUT_ROW_SIZE;
-      }
-      for (i = 0; i < 8; ++i)
-         RVCE_CS(RVCE_MAX_BITSTREAM_OUTPUT_ROW_SIZE);
-      RVCE_END();
-   }
-
-   RVCE_BEGIN(0x03000001);                       // encode
-   RVCE_CS(enc->enc_pic.eo.insert_headers);
-   RVCE_CS(enc->enc_pic.eo.picture_structure);
-   RVCE_CS(enc->bs_size - enc->bs_offset); // allowedMaxBitstreamSize
-   RVCE_CS(enc->enc_pic.eo.force_refresh_map);
-   RVCE_CS(enc->enc_pic.eo.insert_aud);
-   RVCE_CS(enc->enc_pic.eo.end_of_sequence);
-   RVCE_CS(enc->enc_pic.eo.end_of_stream);
-
-   if (sscreen->info.gfx_level < GFX9) {
-      RVCE_READ(enc->handle, RADEON_DOMAIN_VRAM,
-                (uint64_t)enc->luma->u.legacy.level[0].offset_256B * 256); // inputPictureLumaAddressHi/Lo
-      RVCE_READ(enc->handle, RADEON_DOMAIN_VRAM,
-                (uint64_t)enc->chroma->u.legacy.level[0].offset_256B * 256);        // inputPictureChromaAddressHi/Lo
-      RVCE_CS(align(enc->luma->u.legacy.level[0].nblk_y, 16)); // encInputFrameYPitch
-      RVCE_CS(enc->luma->u.legacy.level[0].nblk_x * enc->luma->bpe);     // encInputPicLumaPitch
-      RVCE_CS(enc->chroma->u.legacy.level[0].nblk_x * enc->chroma->bpe); // encInputPicChromaPitch
-   } else {
-      RVCE_READ(enc->handle, RADEON_DOMAIN_VRAM,
-                enc->luma->u.gfx9.surf_offset); // inputPictureLumaAddressHi/Lo
-      RVCE_READ(enc->handle, RADEON_DOMAIN_VRAM,
-                enc->chroma->u.gfx9.surf_offset);                 // inputPictureChromaAddressHi/Lo
-      RVCE_CS(align(enc->luma->u.gfx9.surf_height, 16));          // encInputFrameYPitch
-      RVCE_CS(enc->luma->u.gfx9.surf_pitch * enc->luma->bpe);     // encInputPicLumaPitch
-      RVCE_CS(enc->chroma->u.gfx9.surf_pitch * enc->chroma->bpe); // encInputPicChromaPitch
-      enc->enc_pic.eo.enc_input_pic_swizzle_mode = enc->luma->u.gfx9.swizzle_mode;
-   }
-
-   enc->enc_pic.eo.enc_disable_two_pipe_mode = enc->fw_version >= 50 ? !enc->dual_pipe : 0;
-   RVCE_CS(enc->enc_pic.eo.enc_input_pic_addr_array_disable2pipe_disablemboffload);
-   RVCE_CS(enc->enc_pic.eo.enc_input_pic_tile_config);
-   RVCE_CS(enc->enc_pic.picture_type);                                    // encPicType
-   RVCE_CS(enc->enc_pic.picture_type == PIPE_H2645_ENC_PICTURE_TYPE_IDR); // encIdrFlag
-   RVCE_CS(enc->enc_pic.eo.enc_idr_pic_id);
-   RVCE_CS(enc->enc_pic.eo.enc_mgs_key_pic);
-   RVCE_CS(!enc->enc_pic.not_referenced);
-   RVCE_CS(enc->enc_pic.eo.enc_temporal_layer_index);
-   RVCE_CS(enc->enc_pic.eo.num_ref_idx_active_override_flag);
-   RVCE_CS(enc->enc_pic.eo.num_ref_idx_l0_active_minus1);
-   RVCE_CS(enc->enc_pic.eo.num_ref_idx_l1_active_minus1);
-
-   for (i = 0; i < 4; ++i) {
-      RVCE_CS(enc->enc_pic.eo.enc_ref_list_modification_op[i]);
-      RVCE_CS(enc->enc_pic.eo.enc_ref_list_modification_num[i]);
-   }
-
-   for (i = 0; i < 4; ++i) {
-      RVCE_CS(enc->enc_pic.eo.enc_decoded_picture_marking_op[i]);
-      RVCE_CS(enc->enc_pic.eo.enc_decoded_picture_marking_num[i]);
-      RVCE_CS(enc->enc_pic.eo.enc_decoded_picture_marking_idx[i]);
-   }
-
-   for (i = 0; i < 4; ++i) {
-      RVCE_CS(enc->enc_pic.eo.enc_decoded_ref_base_picture_marking_op[i]);
-      RVCE_CS(enc->enc_pic.eo.enc_decoded_ref_base_picture_marking_num[i]);
-   }
-
-   // encReferencePictureL0[0]
-   if (enc->enc_pic.eo.l0_dpb_idx != PIPE_H2645_LIST_REF_INVALID_ENTRY) {
-      si_vce_frame_offset(enc, enc->enc_pic.eo.l0_dpb_idx, &luma_offset, &chroma_offset);
-      enc->enc_pic.eo.l0_luma_offset = luma_offset;
-      enc->enc_pic.eo.l0_chroma_offset = chroma_offset;
-   } else {
-      enc->enc_pic.eo.l0_luma_offset = 0xffffffff;
-      enc->enc_pic.eo.l0_chroma_offset = 0xffffffff;
-   }
-   RVCE_CS(0x00000000); // pictureStructure
-   RVCE_CS(enc->enc_pic.eo.l0_enc_pic_type);
-   RVCE_CS(enc->enc_pic.eo.l0_frame_number);
-   RVCE_CS(enc->enc_pic.eo.l0_picture_order_count);
-   RVCE_CS(enc->enc_pic.eo.l0_luma_offset);
-   RVCE_CS(enc->enc_pic.eo.l0_chroma_offset);
-
-   // encReferencePictureL0[1]
-   enc->enc_pic.eo.l0_picture_structure = 0x00000000;
-   enc->enc_pic.eo.l0_enc_pic_type = 0x00000000;
-   enc->enc_pic.eo.l0_frame_number = 0x00000000;
-   enc->enc_pic.eo.l0_picture_order_count = 0x00000000;
-   enc->enc_pic.eo.l0_luma_offset = 0xffffffff;
-   enc->enc_pic.eo.l0_chroma_offset = 0xffffffff;
-   RVCE_CS(enc->enc_pic.eo.l0_picture_structure);
-   RVCE_CS(enc->enc_pic.eo.l0_enc_pic_type);
-   RVCE_CS(enc->enc_pic.eo.l0_frame_number);
-   RVCE_CS(enc->enc_pic.eo.l0_picture_order_count);
-   RVCE_CS(enc->enc_pic.eo.l0_luma_offset);
-   RVCE_CS(enc->enc_pic.eo.l0_chroma_offset);
-
-   // encReferencePictureL1[0]
-   RVCE_CS(0x00000000); // pictureStructure
-   RVCE_CS(enc->enc_pic.eo.l1_enc_pic_type);
-   RVCE_CS(enc->enc_pic.eo.l1_frame_number);
-   RVCE_CS(enc->enc_pic.eo.l1_picture_order_count);
-   RVCE_CS(enc->enc_pic.eo.l1_luma_offset);
-   RVCE_CS(enc->enc_pic.eo.l1_chroma_offset);
-
-   si_vce_frame_offset(enc, enc->enc_pic.eo.cur_dpb_idx, &luma_offset, &chroma_offset);
-   RVCE_CS(luma_offset);
-   RVCE_CS(chroma_offset);
-   RVCE_CS(enc->enc_pic.eo.enc_coloc_buffer_offset);
-   RVCE_CS(enc->enc_pic.eo.enc_reconstructed_ref_base_picture_luma_offset);
-   RVCE_CS(enc->enc_pic.eo.enc_reconstructed_ref_base_picture_chroma_offset);
-   RVCE_CS(enc->enc_pic.eo.enc_reference_ref_base_picture_luma_offset);
-   RVCE_CS(enc->enc_pic.eo.enc_reference_ref_base_picture_chroma_offset);
-   RVCE_CS(enc->enc_pic.frame_num_cnt);
-   RVCE_CS(enc->enc_pic.frame_num);
-   RVCE_CS(enc->enc_pic.pic_order_cnt);
-   RVCE_CS(enc->enc_pic.i_remain);
-   RVCE_CS(enc->enc_pic.p_remain);
-   RVCE_CS(enc->enc_pic.eo.num_b_pic_remain_in_rcgop);
-   RVCE_CS(enc->enc_pic.eo.num_ir_pic_remain_in_rcgop);
-   RVCE_CS(enc->enc_pic.eo.enable_intra_refresh);
-
-   if (enc->fw_version >= 52) {
-      RVCE_CS(enc->enc_pic.eo.aq_variance_en);
-      RVCE_CS(enc->enc_pic.eo.aq_block_size);
-      RVCE_CS(enc->enc_pic.eo.aq_mb_variance_sel);
-      RVCE_CS(enc->enc_pic.eo.aq_frame_variance_sel);
-      RVCE_CS(enc->enc_pic.eo.aq_param_a);
-      RVCE_CS(enc->enc_pic.eo.aq_param_b);
-      RVCE_CS(enc->enc_pic.eo.aq_param_c);
-      RVCE_CS(enc->enc_pic.eo.aq_param_d);
-      RVCE_CS(enc->enc_pic.eo.aq_param_e);
-      RVCE_CS(enc->enc_pic.eo.context_in_sfb);
-   }
-   RVCE_END();
-}
-
-static void rate_control(struct rvce_encoder *enc)
-{
-   RVCE_BEGIN(0x04000005); // rate control
-   RVCE_CS(enc->enc_pic.rc.rc_method);
-   RVCE_CS(enc->enc_pic.rc.target_bitrate);
-   RVCE_CS(enc->enc_pic.rc.peak_bitrate);
-   RVCE_CS(enc->enc_pic.rc.frame_rate_num);
-   RVCE_CS(enc->enc_pic.rc.gop_size);
-   RVCE_CS(enc->enc_pic.rc.quant_i_frames);
-   RVCE_CS(enc->enc_pic.rc.quant_p_frames);
-   RVCE_CS(enc->enc_pic.rc.quant_b_frames);
-   RVCE_CS(enc->enc_pic.rc.vbv_buffer_size);
-   RVCE_CS(enc->enc_pic.rc.frame_rate_den);
-   RVCE_CS(enc->enc_pic.rc.vbv_buf_lv);
-   RVCE_CS(enc->enc_pic.rc.max_au_size);
-   RVCE_CS(enc->enc_pic.rc.qp_initial_mode);
-   RVCE_CS(enc->enc_pic.rc.target_bits_picture);
-   RVCE_CS(enc->enc_pic.rc.peak_bits_picture_integer);
-   RVCE_CS(enc->enc_pic.rc.peak_bits_picture_fraction);
-   RVCE_CS(enc->enc_pic.rc.min_qp);
-   RVCE_CS(enc->enc_pic.rc.max_qp);
-   RVCE_CS(enc->enc_pic.rc.skip_frame_enable);
-   RVCE_CS(enc->enc_pic.rc.fill_data_enable);
-   RVCE_CS(enc->enc_pic.rc.enforce_hrd);
-   RVCE_CS(enc->enc_pic.rc.b_pics_delta_qp);
-   RVCE_CS(enc->enc_pic.rc.ref_b_pics_delta_qp);
-   RVCE_CS(enc->enc_pic.rc.rc_reinit_disable);
-   if (enc->fw_version >= 50) {
-      RVCE_CS(enc->enc_pic.rc.enc_lcvbr_init_qp_flag);
-      RVCE_CS(enc->enc_pic.rc.lcvbrsatd_based_nonlinear_bit_budget_flag);
-   }
-   RVCE_END();
-}
-
-static void config(struct rvce_encoder *enc)
-{
-   enc->task_info(enc, 0x00000002, 0xffffffff);
-   enc->rate_control(enc);
-   enc->config_extension(enc);
-   enc->motion_estimation(enc);
-   enc->rdo(enc);
-   enc->pic_control(enc);
-}
-
-static void config_extension(struct rvce_encoder *enc)
-{
-   RVCE_BEGIN(0x04000001); // config extension
-   RVCE_CS(enc->enc_pic.ce.enc_enable_perf_logging);
-   RVCE_END();
-}
-
-static void feedback(struct rvce_encoder *enc)
-{
-   RVCE_BEGIN(0x05000005);                                    // feedback buffer
-   RVCE_WRITE(enc->fb->res->buf, enc->fb->res->domains, 0x0); // feedbackRingAddressHi/Lo
-   RVCE_CS(enc->enc_pic.fb.feedback_ring_size);
-   RVCE_END();
-}
-
-static void destroy(struct rvce_encoder *enc)
-{
-   enc->task_info(enc, 0x00000001, 0);
-
-   feedback(enc);
-
-   RVCE_BEGIN(0x02000001); // destroy
-   RVCE_END();
-}
-
-static void motion_estimation(struct rvce_encoder *enc)
-{
-   RVCE_BEGIN(0x04000007); // motion estimation
-   RVCE_CS(enc->enc_pic.me.enc_ime_decimation_search);
-   RVCE_CS(enc->enc_pic.me.motion_est_half_pixel);
-   RVCE_CS(enc->enc_pic.me.motion_est_quarter_pixel);
-   RVCE_CS(enc->enc_pic.me.disable_favor_pmv_point);
-   RVCE_CS(enc->enc_pic.me.force_zero_point_center);
-   RVCE_CS(enc->enc_pic.me.lsmvert);
-   RVCE_CS(enc->enc_pic.me.enc_search_range_x);
-   RVCE_CS(enc->enc_pic.me.enc_search_range_y);
-   RVCE_CS(enc->enc_pic.me.enc_search1_range_x);
-   RVCE_CS(enc->enc_pic.me.enc_search1_range_y);
-   RVCE_CS(enc->enc_pic.me.disable_16x16_frame1);
-   RVCE_CS(enc->enc_pic.me.disable_satd);
-   RVCE_CS(enc->enc_pic.me.enable_amd);
-   RVCE_CS(enc->enc_pic.me.enc_disable_sub_mode);
-   RVCE_CS(enc->enc_pic.me.enc_ime_skip_x);
-   RVCE_CS(enc->enc_pic.me.enc_ime_skip_y);
-   RVCE_CS(enc->enc_pic.me.enc_en_ime_overw_dis_subm);
-   RVCE_CS(enc->enc_pic.me.enc_ime_overw_dis_subm_no);
-   RVCE_CS(enc->enc_pic.me.enc_ime2_search_range_x);
-   RVCE_CS(enc->enc_pic.me.enc_ime2_search_range_y);
-   RVCE_CS(enc->enc_pic.me.parallel_mode_speedup_enable);
-   RVCE_CS(enc->enc_pic.me.fme0_enc_disable_sub_mode);
-   RVCE_CS(enc->enc_pic.me.fme1_enc_disable_sub_mode);
-   RVCE_CS(enc->enc_pic.me.ime_sw_speedup_enable);
-   RVCE_END();
-}
-
-static void pic_control(struct rvce_encoder *enc)
-{
-   RVCE_BEGIN(0x04000002); // pic control
-   RVCE_CS(enc->enc_pic.pc.enc_use_constrained_intra_pred);
-   RVCE_CS(enc->enc_pic.pc.enc_cabac_enable);
-   RVCE_CS(enc->enc_pic.pc.enc_cabac_idc);
-   RVCE_CS(enc->enc_pic.pc.enc_loop_filter_disable);
-   RVCE_CS(enc->enc_pic.pc.enc_lf_beta_offset);
-   RVCE_CS(enc->enc_pic.pc.enc_lf_alpha_c0_offset);
-   RVCE_CS(enc->enc_pic.pc.enc_crop_left_offset);
-   RVCE_CS(enc->enc_pic.pc.enc_crop_right_offset);
-   RVCE_CS(enc->enc_pic.pc.enc_crop_top_offset);
-   RVCE_CS(enc->enc_pic.pc.enc_crop_bottom_offset);
-   RVCE_CS(enc->enc_pic.pc.enc_num_mbs_per_slice);
-   RVCE_CS(enc->enc_pic.pc.enc_intra_refresh_num_mbs_per_slot);
-   RVCE_CS(enc->enc_pic.pc.enc_force_intra_refresh);
-   RVCE_CS(enc->enc_pic.pc.enc_force_imb_period);
-   RVCE_CS(enc->enc_pic.pc.enc_pic_order_cnt_type);
-   RVCE_CS(enc->enc_pic.pc.log2_max_pic_order_cnt_lsb_minus4);
-   RVCE_CS(enc->enc_pic.pc.enc_sps_id);
-   RVCE_CS(enc->enc_pic.pc.enc_pps_id);
-   RVCE_CS(enc->enc_pic.pc.enc_constraint_set_flags);
-   RVCE_CS(enc->enc_pic.pc.enc_b_pic_pattern);
-   RVCE_CS(enc->enc_pic.pc.weight_pred_mode_b_picture);
-   RVCE_CS(enc->enc_pic.pc.enc_number_of_reference_frames);
-   RVCE_CS(enc->enc_pic.pc.enc_max_num_ref_frames);
-   RVCE_CS(enc->enc_pic.pc.enc_num_default_active_ref_l0);
-   RVCE_CS(enc->enc_pic.pc.enc_num_default_active_ref_l1);
-   RVCE_CS(enc->enc_pic.pc.enc_slice_mode);
-   RVCE_CS(enc->enc_pic.pc.enc_max_slice_size);
-   RVCE_END();
-}
-
-static void rdo(struct rvce_encoder *enc)
-{
-   RVCE_BEGIN(0x04000008); // rdo
-   RVCE_CS(enc->enc_pic.rdo.enc_disable_tbe_pred_i_frame);
-   RVCE_CS(enc->enc_pic.rdo.enc_disable_tbe_pred_p_frame);
-   RVCE_CS(enc->enc_pic.rdo.use_fme_interpol_y);
-   RVCE_CS(enc->enc_pic.rdo.use_fme_interpol_uv);
-   RVCE_CS(enc->enc_pic.rdo.use_fme_intrapol_y);
-   RVCE_CS(enc->enc_pic.rdo.use_fme_intrapol_uv);
-   RVCE_CS(enc->enc_pic.rdo.use_fme_interpol_y_1);
-   RVCE_CS(enc->enc_pic.rdo.use_fme_interpol_uv_1);
-   RVCE_CS(enc->enc_pic.rdo.use_fme_intrapol_y_1);
-   RVCE_CS(enc->enc_pic.rdo.use_fme_intrapol_uv_1);
-   RVCE_CS(enc->enc_pic.rdo.enc_16x16_cost_adj);
-   RVCE_CS(enc->enc_pic.rdo.enc_skip_cost_adj);
-   RVCE_CS(enc->enc_pic.rdo.enc_force_16x16_skip);
-   RVCE_CS(enc->enc_pic.rdo.enc_disable_threshold_calc_a);
-   RVCE_CS(enc->enc_pic.rdo.enc_luma_coeff_cost);
-   RVCE_CS(enc->enc_pic.rdo.enc_luma_mb_coeff_cost);
-   RVCE_CS(enc->enc_pic.rdo.enc_chroma_coeff_cost);
-   RVCE_END();
-}
-
-static void session(struct rvce_encoder *enc)
-{
-   RVCE_BEGIN(0x00000001); // session cmd
-   RVCE_CS(enc->stream_handle);
-   RVCE_END();
-}
-
-static void task_info(struct rvce_encoder *enc, uint32_t op, uint32_t fb_idx)
-{
-   RVCE_BEGIN(0x00000002); // task info
-   enc->enc_pic.ti.task_operation = op;
-   enc->enc_pic.ti.reference_picture_dependency = 0;
-   enc->enc_pic.ti.feedback_index = fb_idx;
-   enc->enc_pic.ti.video_bitstream_ring_index = 0;
-   RVCE_CS(enc->enc_pic.ti.offset_of_next_task_info);
-   RVCE_CS(enc->enc_pic.ti.task_operation);
-   RVCE_CS(enc->enc_pic.ti.reference_picture_dependency);
-   RVCE_CS(enc->enc_pic.ti.collocate_flag_dependency);
-   RVCE_CS(enc->enc_pic.ti.feedback_index);
-   RVCE_CS(enc->enc_pic.ti.video_bitstream_ring_index);
-   RVCE_END();
-}
-
-unsigned int si_vce_write_sps(struct rvce_encoder *enc, uint8_t nal_byte, uint8_t *out)
-{
-   struct pipe_h264_enc_seq_param *sps = &enc->pic.seq;
-   struct radeon_bitstream bs;
-
-   radeon_bs_reset(&bs, out, NULL);
-   radeon_bs_set_emulation_prevention(&bs, false);
-   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
-   radeon_bs_code_fixed_bits(&bs, nal_byte, 8);
-   radeon_bs_set_emulation_prevention(&bs, true);
-   radeon_bs_code_fixed_bits(&bs, sps->profile_idc, 8);
-   radeon_bs_code_fixed_bits(&bs, sps->enc_constraint_set_flags, 6);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 2); /* reserved_zero_2bits */
-   radeon_bs_code_fixed_bits(&bs, sps->level_idc, 8);
-   radeon_bs_code_ue(&bs, 0x0); /* seq_parameter_set_id */
-
-   if (sps->profile_idc == 100 || sps->profile_idc == 110 ||
-       sps->profile_idc == 122 || sps->profile_idc == 244 ||
-       sps->profile_idc == 44  || sps->profile_idc == 83 ||
-       sps->profile_idc == 86  || sps->profile_idc == 118 ||
-       sps->profile_idc == 128 || sps->profile_idc == 138) {
-      radeon_bs_code_ue(&bs, 0x1); /* chroma_format_idc */
-      radeon_bs_code_ue(&bs, 0x0); /* bit_depth_luma_minus8 */
-      radeon_bs_code_ue(&bs, 0x0); /* bit_depth_chroma_minus8 */
-      radeon_bs_code_fixed_bits(&bs, 0x0, 2); /* qpprime_y_zero_transform_bypass_flag + seq_scaling_matrix_present_flag */
-   }
-
-   radeon_bs_code_ue(&bs, 3); /* log2_max_frame_num_minus4 */
-   radeon_bs_code_ue(&bs, sps->pic_order_cnt_type);
-
-   if (sps->pic_order_cnt_type == 0)
-      radeon_bs_code_ue(&bs, sps->log2_max_pic_order_cnt_lsb_minus4);
-
-   radeon_bs_code_ue(&bs, sps->max_num_ref_frames);
-   radeon_bs_code_fixed_bits(&bs, sps->gaps_in_frame_num_value_allowed_flag, 1);
-   radeon_bs_code_ue(&bs, DIV_ROUND_UP(enc->base.width, 16) - 1);
-   radeon_bs_code_ue(&bs, DIV_ROUND_UP(enc->base.height, 16) - 1);
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* frame_mbs_only_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* direct_8x8_inference_flag */
-
-   radeon_bs_code_fixed_bits(&bs, sps->enc_frame_cropping_flag, 1);
-   if (sps->enc_frame_cropping_flag) {
-      radeon_bs_code_ue(&bs, sps->enc_frame_crop_left_offset);
-      radeon_bs_code_ue(&bs, sps->enc_frame_crop_right_offset);
-      radeon_bs_code_ue(&bs, sps->enc_frame_crop_top_offset);
-      radeon_bs_code_ue(&bs, sps->enc_frame_crop_bottom_offset);
-   }
-
-   radeon_bs_code_fixed_bits(&bs, sps->vui_parameters_present_flag, 1);
-   if (sps->vui_parameters_present_flag) {
-      radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.aspect_ratio_info_present_flag), 1);
-      if (sps->vui_flags.aspect_ratio_info_present_flag) {
-         radeon_bs_code_fixed_bits(&bs, (sps->aspect_ratio_idc), 8);
-         if (sps->aspect_ratio_idc == PIPE_H2645_EXTENDED_SAR) {
-            radeon_bs_code_fixed_bits(&bs, (sps->sar_width), 16);
-            radeon_bs_code_fixed_bits(&bs, (sps->sar_height), 16);
-         }
-      }
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.overscan_info_present_flag, 1);
-      if (sps->vui_flags.overscan_info_present_flag)
-         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.overscan_appropriate_flag, 1);
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.video_signal_type_present_flag, 1);
-      if (sps->vui_flags.video_signal_type_present_flag) {
-         radeon_bs_code_fixed_bits(&bs, sps->video_format, 3);
-         radeon_bs_code_fixed_bits(&bs, sps->video_full_range_flag, 1);
-         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.colour_description_present_flag, 1);
-         if (sps->vui_flags.colour_description_present_flag) {
-            radeon_bs_code_fixed_bits(&bs, sps->colour_primaries, 8);
-            radeon_bs_code_fixed_bits(&bs, sps->transfer_characteristics, 8);
-            radeon_bs_code_fixed_bits(&bs, sps->matrix_coefficients, 8);
-         }
-      }
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.chroma_loc_info_present_flag, 1);
-      if (sps->vui_flags.chroma_loc_info_present_flag) {
-         radeon_bs_code_ue(&bs, sps->chroma_sample_loc_type_top_field);
-         radeon_bs_code_ue(&bs, sps->chroma_sample_loc_type_bottom_field);
-      }
-      radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.timing_info_present_flag), 1);
-      if (sps->vui_flags.timing_info_present_flag) {
-         radeon_bs_code_fixed_bits(&bs, (sps->num_units_in_tick), 32);
-         radeon_bs_code_fixed_bits(&bs, (sps->time_scale), 32);
-         radeon_bs_code_fixed_bits(&bs, (sps->vui_flags.fixed_frame_rate_flag), 1);
-      }
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.nal_hrd_parameters_present_flag, 1);
-      if (sps->vui_flags.nal_hrd_parameters_present_flag)
-         radeon_bs_h264_hrd_parameters(&bs, &sps->nal_hrd_parameters);
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.vcl_hrd_parameters_present_flag, 1);
-      if (sps->vui_flags.vcl_hrd_parameters_present_flag)
-         radeon_bs_h264_hrd_parameters(&bs, &sps->vcl_hrd_parameters);
-      if (sps->vui_flags.nal_hrd_parameters_present_flag || sps->vui_flags.vcl_hrd_parameters_present_flag)
-         radeon_bs_code_fixed_bits(&bs, sps->vui_flags.low_delay_hrd_flag, 1);
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.pic_struct_present_flag, 1);
-      radeon_bs_code_fixed_bits(&bs, sps->vui_flags.bitstream_restriction_flag, 1);
-      if (sps->vui_flags.bitstream_restriction_flag) {
-         radeon_bs_code_fixed_bits(&bs, 0x1, 1); /* motion_vectors_over_pic_boundaries_flag */
-         radeon_bs_code_ue(&bs, 0x2); /* max_bytes_per_pic_denom */
-         radeon_bs_code_ue(&bs, 0x1); /* max_bits_per_mb_denom */
-         radeon_bs_code_ue(&bs, 0x10); /* log2_max_mv_length_horizontal */
-         radeon_bs_code_ue(&bs, 0x10); /* log2_max_mv_length_vertical */
-         radeon_bs_code_ue(&bs, sps->max_num_reorder_frames);
-         radeon_bs_code_ue(&bs, sps->max_dec_frame_buffering);
-      }
-   }
-
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
-   radeon_bs_byte_align(&bs);
-
-   return bs.bits_output / 8;
-}
-
-unsigned int si_vce_write_pps(struct rvce_encoder *enc, uint8_t nal_byte, uint8_t *out)
-{
-   struct radeon_bitstream bs;
-
-   radeon_bs_reset(&bs, out, NULL);
-   radeon_bs_set_emulation_prevention(&bs, false);
-   radeon_bs_code_fixed_bits(&bs, 0x00000001, 32);
-   radeon_bs_code_fixed_bits(&bs, nal_byte, 8);
-   radeon_bs_set_emulation_prevention(&bs, true);
-   radeon_bs_code_ue(&bs, 0x0); /* pic_parameter_set_id */
-   radeon_bs_code_ue(&bs, 0x0); /* seq_parameter_set_id */
-   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.pc.enc_cabac_enable, 1);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* bottom_field_pic_order_in_frame_present_flag */
-   radeon_bs_code_ue(&bs, 0x0); /* num_slice_groups_minus_1 */
-   radeon_bs_code_ue(&bs, enc->enc_pic.pc.enc_num_default_active_ref_l0 - 1);
-   radeon_bs_code_ue(&bs, enc->enc_pic.pc.enc_num_default_active_ref_l1 - 1);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* weighted_pred_flag */
-   radeon_bs_code_fixed_bits(&bs, 0x0, 2); /* weighted_bipred_idc */
-   radeon_bs_code_se(&bs, 0x0); /* pic_init_qp_minus26 */
-   radeon_bs_code_se(&bs, 0x0); /* pic_init_qs_minus26 */
-   radeon_bs_code_se(&bs, 0x0); /* chroma_qp_index_offset */
-   bool deblocking_filter_present_flag =
-      enc->enc_pic.pc.enc_loop_filter_disable ||
-      enc->enc_pic.pc.enc_lf_beta_offset ||
-      enc->enc_pic.pc.enc_lf_alpha_c0_offset;
-   radeon_bs_code_fixed_bits(&bs, deblocking_filter_present_flag, 1);
-   radeon_bs_code_fixed_bits(&bs, enc->enc_pic.pc.enc_use_constrained_intra_pred, 1);
-   radeon_bs_code_fixed_bits(&bs, 0x0, 1); /* redundant_pic_cnt_present_flag */
-
-   radeon_bs_code_fixed_bits(&bs, 0x1, 1);
-   radeon_bs_byte_align(&bs);
-
-   return bs.bits_output / 8;
-}
-
-void si_vce_52_init(struct rvce_encoder *enc)
-{
-   enc->session = session;
-   enc->task_info = task_info;
-   enc->create = create;
-   enc->feedback = feedback;
-   enc->rate_control = rate_control;
-   enc->config_extension = config_extension;
-   enc->pic_control = pic_control;
-   enc->motion_estimation = motion_estimation;
-   enc->rdo = rdo;
-   enc->config = config;
-   enc->encode = encode;
-   enc->destroy = destroy;
-   enc->si_get_pic_param = get_param;
-}
diff --git a/src/gallium/drivers/radeonsi/si_compute.c b/src/gallium/drivers/radeonsi/si_compute.c
index 892dd89be56..f69f2b4516f 100644
--- a/src/gallium/drivers/radeonsi/si_compute.c
+++ b/src/gallium/drivers/radeonsi/si_compute.c
@@ -380,9 +380,7 @@ static bool si_switch_compute_shader(struct si_context *sctx, struct si_compute
          simple_mtx_lock(&shader->selector->mutex);
 
       /* Update max_seen_compute_scratch_bytes_per_wave and compute_tmpring_size. */
-      ac_get_scratch_tmpring_size(&sctx->screen->info,
-                                  config->scratch_bytes_per_wave,
-                                  &sctx->max_seen_compute_scratch_bytes_per_wave,
+      si_get_scratch_tmpring_size(sctx, config->scratch_bytes_per_wave, true,
                                   &sctx->compute_tmpring_size);
 
       if (!si_setup_compute_scratch_buffer(sctx, shader))
diff --git a/src/gallium/drivers/radeonsi/si_get.c b/src/gallium/drivers/radeonsi/si_get.c
index 98a099ea555..a1e23c8c675 100644
--- a/src/gallium/drivers/radeonsi/si_get.c
+++ b/src/gallium/drivers/radeonsi/si_get.c
@@ -901,7 +901,9 @@ void si_init_screen_get_functions(struct si_screen *sscreen)
     * when execution mode is rtz instead of rtne.
     */
    options->force_f2f16_rtz = true;
-   options->io_options |= (!has_mediump ? nir_io_mediump_is_32bit : 0) | nir_io_has_intrinsics;
+   options->io_options |= (!has_mediump ? nir_io_mediump_is_32bit : 0) | nir_io_has_intrinsics |
+                          (sscreen->use_ngg_culling ?
+                              nir_io_compaction_groups_tes_inputs_into_pos_and_var_groups : 0);
    options->lower_mediump_io = has_mediump ? si_lower_mediump_io : NULL;
    /* HW supports indirect indexing for: | Enabled in driver
     * -------------------------------------------------------
diff --git a/src/gallium/drivers/radeonsi/si_nir_lower_abi.c b/src/gallium/drivers/radeonsi/si_nir_lower_abi.c
index 8af33eba7e2..88353c1800b 100644
--- a/src/gallium/drivers/radeonsi/si_nir_lower_abi.c
+++ b/src/gallium/drivers/radeonsi/si_nir_lower_abi.c
@@ -490,7 +490,7 @@ static bool lower_intrinsic(nir_builder *b, nir_instr *instr, struct lower_abi_s
    case nir_intrinsic_load_ring_tess_factors_amd: {
       assert(s->tess_offchip_ring);
       nir_def *addr = nir_channel(b, s->tess_offchip_ring, 0);
-      addr = nir_iadd_imm(b, addr, sel->screen->hs.tess_offchip_ring_size);
+      addr = nir_iadd_imm(b, addr, sel->screen->info.tess_offchip_ring_size);
       replacement = nir_vector_insert_imm(b, s->tess_offchip_ring, addr, 0);
       break;
    }
diff --git a/src/gallium/drivers/radeonsi/si_pipe.c b/src/gallium/drivers/radeonsi/si_pipe.c
index f9df4da8320..07cddb499e4 100644
--- a/src/gallium/drivers/radeonsi/si_pipe.c
+++ b/src/gallium/drivers/radeonsi/si_pipe.c
@@ -643,6 +643,13 @@ static struct pipe_context *si_create_context(struct pipe_screen *screen, unsign
       }
    }
 
+#if !AMD_LLVM_AVAILABLE
+   sctx->shader.vs.key.ge.use_aco = 1;
+   sctx->shader.gs.key.ge.use_aco = 1;
+   sctx->shader.tcs.key.ge.use_aco = 1;
+   sctx->shader.tes.key.ge.use_aco = 1;
+#endif
+
    sctx->ngg = sscreen->use_ngg;
    si_shader_change_notify(sctx);
 
@@ -889,9 +896,7 @@ static struct pipe_context *si_create_context(struct pipe_screen *screen, unsign
       goto fail;
 
    /* Initialize compute_tmpring_size. */
-   ac_get_scratch_tmpring_size(&sctx->screen->info, 0,
-                               &sctx->max_seen_compute_scratch_bytes_per_wave,
-                               &sctx->compute_tmpring_size);
+   si_get_scratch_tmpring_size(sctx, 0, true, &sctx->compute_tmpring_size);
 
    return &sctx->b;
 fail:
@@ -900,6 +905,27 @@ fail:
    return NULL;
 }
 
+void
+si_get_scratch_tmpring_size(struct si_context *sctx, unsigned bytes_per_wave,
+                            bool is_compute, unsigned *spi_tmpring_size)
+{
+   bytes_per_wave = ac_compute_scratch_wavesize(&sctx->screen->info, bytes_per_wave);
+
+   if (is_compute) {
+      sctx->max_seen_compute_scratch_bytes_per_wave =
+         MAX2(sctx->max_seen_compute_scratch_bytes_per_wave, bytes_per_wave);
+   } else {
+      sctx->max_seen_scratch_bytes_per_wave =
+         MAX2(sctx->max_seen_scratch_bytes_per_wave, bytes_per_wave);
+   }
+
+   /* TODO: We could decrease WAVES to make the whole buffer fit into the infinity cache. */
+   ac_get_scratch_tmpring_size(&sctx->screen->info, sctx->screen->info.max_scratch_waves,
+                               is_compute ? sctx->max_seen_compute_scratch_bytes_per_wave
+                                          : sctx->max_seen_scratch_bytes_per_wave,
+                               spi_tmpring_size);
+}
+
 static bool si_is_resource_busy(struct pipe_screen *screen, struct pipe_resource *resource,
                                 unsigned usage)
 {
@@ -1322,7 +1348,6 @@ static struct pipe_screen *radeonsi_screen_create_impl(struct radeon_winsys *ws,
 
    sscreen->nir_options = CALLOC_STRUCT(nir_shader_compiler_options);
 
-   si_init_screen_get_functions(sscreen);
    si_init_screen_buffer_functions(sscreen);
    si_init_screen_fence_functions(sscreen);
    si_init_screen_state_functions(sscreen);
@@ -1330,6 +1355,20 @@ static struct pipe_screen *radeonsi_screen_create_impl(struct radeon_winsys *ws,
    si_init_screen_query_functions(sscreen);
    si_init_screen_live_shader_cache(sscreen);
 
+   if (sscreen->info.gfx_level >= GFX11) {
+      sscreen->use_ngg = true;
+      sscreen->use_ngg_culling = sscreen->info.max_render_backends >= 2 &&
+                                 !(sscreen->debug_flags & DBG(NO_NGG_CULLING));
+   } else {
+      sscreen->use_ngg = !(sscreen->debug_flags & DBG(NO_NGG)) &&
+                         sscreen->info.gfx_level >= GFX10 &&
+                         (sscreen->info.family != CHIP_NAVI14 ||
+                          sscreen->info.is_pro_graphics);
+      sscreen->use_ngg_culling = sscreen->use_ngg &&
+                                 sscreen->info.max_render_backends >= 2 &&
+                                 !(sscreen->debug_flags & DBG(NO_NGG_CULLING));
+   }
+
    sscreen->has_draw_indirect_multi =
       (sscreen->info.family >= CHIP_POLARIS10) ||
       (sscreen->info.gfx_level == GFX8 && sscreen->info.pfp_fw_version >= 121 &&
@@ -1339,6 +1378,7 @@ static struct pipe_screen *radeonsi_screen_create_impl(struct radeon_winsys *ws,
       (sscreen->info.gfx_level == GFX6 && sscreen->info.pfp_fw_version >= 79 &&
        sscreen->info.me_fw_version >= 142);
 
+   si_init_screen_get_functions(sscreen);
    si_init_shader_caps(sscreen);
    si_init_compute_caps(sscreen);
    si_init_screen_caps(sscreen);
@@ -1442,25 +1482,9 @@ static struct pipe_screen *radeonsi_screen_create_impl(struct radeon_winsys *ws,
    if (!debug_get_bool_option("RADEON_DISABLE_PERFCOUNTERS", false))
       si_init_perfcounters(sscreen);
 
-   ac_get_hs_info(&sscreen->info, &sscreen->hs);
-
    if (sscreen->debug_flags & DBG(NO_OUT_OF_ORDER))
       sscreen->info.has_out_of_order_rast = false;
 
-   if (sscreen->info.gfx_level >= GFX11) {
-      sscreen->use_ngg = true;
-      sscreen->use_ngg_culling = sscreen->info.max_render_backends >= 2 &&
-                                 !(sscreen->debug_flags & DBG(NO_NGG_CULLING));
-   } else {
-      sscreen->use_ngg = !(sscreen->debug_flags & DBG(NO_NGG)) &&
-                         sscreen->info.gfx_level >= GFX10 &&
-                         (sscreen->info.family != CHIP_NAVI14 ||
-                          sscreen->info.is_pro_graphics);
-      sscreen->use_ngg_culling = sscreen->use_ngg &&
-                                 sscreen->info.max_render_backends >= 2 &&
-                                 !(sscreen->debug_flags & DBG(NO_NGG_CULLING));
-   }
-
    /* Only set this for the cases that are known to work, which are:
     * - GFX9 if bpp >= 4 (in bytes)
     */
diff --git a/src/gallium/drivers/radeonsi/si_pipe.h b/src/gallium/drivers/radeonsi/si_pipe.h
index d4534bb9a57..8fe3cf4d170 100644
--- a/src/gallium/drivers/radeonsi/si_pipe.h
+++ b/src/gallium/drivers/radeonsi/si_pipe.h
@@ -519,7 +519,6 @@ struct si_screen {
    unsigned pa_sc_raster_config_1;
    unsigned se_tile_repeat;
    unsigned gs_table_depth;
-   struct ac_hs_info hs;
    unsigned eqaa_force_coverage_samples;
    unsigned eqaa_force_z_samples;
    unsigned eqaa_force_color_samples;
@@ -1622,6 +1621,8 @@ struct ac_llvm_compiler *si_create_llvm_compiler(struct si_screen *sscreen);
 void si_init_aux_async_compute_ctx(struct si_screen *sscreen);
 struct si_context *si_get_aux_context(struct si_aux_context *ctx);
 void si_put_aux_context_flush(struct si_aux_context *ctx);
+void si_get_scratch_tmpring_size(struct si_context *sctx, unsigned bytes_per_wave,
+                                 bool is_compute, unsigned *spi_tmpring_size);
 void si_destroy_screen(struct pipe_screen *pscreen);
 
 /* si_perfcounters.c */
diff --git a/src/gallium/drivers/radeonsi/si_shader.c b/src/gallium/drivers/radeonsi/si_shader.c
index 0cee05e415d..eb9b37e3ec0 100644
--- a/src/gallium/drivers/radeonsi/si_shader.c
+++ b/src/gallium/drivers/radeonsi/si_shader.c
@@ -3013,6 +3013,10 @@ si_nir_generate_gs_copy_shader(struct si_screen *sscreen,
 #endif
       si_aco_compile_shader(shader, &linked, debug);
 
+#if !AMD_LLVM_AVAILABLE
+   assert(gs_nir->info.use_aco_amd);
+#endif
+
    if (ok) {
       assert(!shader->config.scratch_bytes_per_wave);
       ok = si_shader_binary_upload(sscreen, shader, 0) >= 0;
@@ -3115,6 +3119,10 @@ bool si_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *compi
 #endif
       si_aco_compile_shader(shader, &linked, debug);
 
+#if !AMD_LLVM_AVAILABLE
+   assert(nir->info.use_aco_amd);
+#endif
+
    if (!ret)
       goto out;
 
diff --git a/src/gallium/drivers/radeonsi/si_shader_info.c b/src/gallium/drivers/radeonsi/si_shader_info.c
index 2710707f5b6..51bded80de2 100644
--- a/src/gallium/drivers/radeonsi/si_shader_info.c
+++ b/src/gallium/drivers/radeonsi/si_shader_info.c
@@ -484,6 +484,7 @@ static void scan_instruction(const struct nir_shader *nir, struct si_shader_info
 void si_nir_scan_shader(struct si_screen *sscreen, struct nir_shader *nir,
                         struct si_shader_info *info, bool colors_lowered)
 {
+#if AMD_LLVM_AVAILABLE
    bool force_use_aco = sscreen->use_aco_shader_type == nir->info.stage;
    for (unsigned i = 0; i < sscreen->num_use_aco_shader_blakes; i++) {
       if (!memcmp(sscreen->use_aco_shader_blakes[i], nir->info.source_blake3,
@@ -499,6 +500,10 @@ void si_nir_scan_shader(struct si_screen *sscreen, struct nir_shader *nir,
                             /* Use ACO for streamout on gfx12 because it's faster. */
                             (sscreen->info.gfx_level >= GFX12 && nir->xfb_info &&
                              nir->xfb_info->output_count));
+#else
+   assert(aco_is_gpu_supported(&sscreen->info));
+   nir->info.use_aco_amd = true;
+#endif
 
    if (nir->info.stage == MESA_SHADER_FRAGMENT) {
       /* post_depth_coverage implies early_fragment_tests */
diff --git a/src/gallium/drivers/radeonsi/si_state.c b/src/gallium/drivers/radeonsi/si_state.c
index 8061be47aa7..81373d34300 100644
--- a/src/gallium/drivers/radeonsi/si_state.c
+++ b/src/gallium/drivers/radeonsi/si_state.c
@@ -5123,8 +5123,16 @@ static void gfx10_init_gfx_preamble_state(struct si_context *sctx)
          ac_pm4_cmd_add(&pm4->base, EVENT_TYPE(V_028A90_BREAK_BATCH) | EVENT_INDEX(0));
       }
 
-      ac_pm4_cmd_add(&pm4->base, PKT3(PKT3_CLEAR_STATE, 0, 0));
-      ac_pm4_cmd_add(&pm4->base, 0);
+      if (sscreen->info.has_clear_state) {
+         ac_pm4_cmd_add(&pm4->base, PKT3(PKT3_CLEAR_STATE, 0, 0));
+         ac_pm4_cmd_add(&pm4->base, 0);
+      } else {
+         /* PA_SC_TILE_STEERING_OVERRIDE needs to be written else observing corruption in
+          * gfx11 with userq.
+          */
+         ac_pm4_set_reg(&pm4->base, R_02835C_PA_SC_TILE_STEERING_OVERRIDE,
+                        sscreen->info.pa_sc_tile_steering_override);
+      }
    }
 
    si_init_compute_preamble_state(sctx, pm4);
diff --git a/src/gallium/drivers/radeonsi/si_state_shaders.cpp b/src/gallium/drivers/radeonsi/si_state_shaders.cpp
index 9a6bb0fa1fd..174e98c053b 100644
--- a/src/gallium/drivers/radeonsi/si_state_shaders.cpp
+++ b/src/gallium/drivers/radeonsi/si_state_shaders.cpp
@@ -3829,7 +3829,9 @@ static void si_bind_vs_shader(struct pipe_context *ctx, void *state)
 
    sctx->shader.vs.cso = sel;
    sctx->shader.vs.current = (sel && sel->variants_count) ? sel->variants[0] : NULL;
+#if AMD_LLVM_AVAILABLE
    sctx->shader.vs.key.ge.use_aco = sel ? sel->info.base.use_aco_amd : 0;
+#endif
    sctx->num_vs_blit_sgprs = sel ? sel->info.base.vs.blit_sgprs_amd : 0;
    sctx->vs_uses_draw_id = sel ? sel->info.uses_drawid : false;
 
@@ -3921,7 +3923,9 @@ static void si_bind_gs_shader(struct pipe_context *ctx, void *state)
 
    sctx->shader.gs.cso = sel;
    sctx->shader.gs.current = (sel && sel->variants_count) ? sel->variants[0] : NULL;
+#if AMD_LLVM_AVAILABLE
    sctx->shader.gs.key.ge.use_aco = sel ? sel->info.base.use_aco_amd : 0;
+#endif
    sctx->ia_multi_vgt_param_key.u.uses_gs = sel != NULL;
 
    si_update_common_shader_state(sctx, sel, PIPE_SHADER_GEOMETRY);
@@ -3953,7 +3957,9 @@ static void si_bind_tcs_shader(struct pipe_context *ctx, void *state)
 
    sctx->shader.tcs.cso = sel;
    sctx->shader.tcs.current = (sel && sel->variants_count) ? sel->variants[0] : NULL;
+#if AMD_LLVM_AVAILABLE
    sctx->shader.tcs.key.ge.use_aco = sel ? sel->info.base.use_aco_amd : 0;
+#endif
    si_update_tess_uses_prim_id(sctx);
    si_update_tess_in_out_patch_vertices(sctx);
 
@@ -3976,7 +3982,9 @@ static void si_bind_tes_shader(struct pipe_context *ctx, void *state)
 
    sctx->shader.tes.cso = sel;
    sctx->shader.tes.current = (sel && sel->variants_count) ? sel->variants[0] : NULL;
+#if AMD_LLVM_AVAILABLE
    sctx->shader.tes.key.ge.use_aco = sel ? sel->info.base.use_aco_amd : 0;
+#endif
    sctx->ia_multi_vgt_param_key.u.uses_tess = sel != NULL;
    si_update_tess_uses_prim_id(sctx);
 
@@ -4493,8 +4501,7 @@ static bool si_update_scratch_relocs(struct si_context *sctx)
 bool si_update_spi_tmpring_size(struct si_context *sctx, unsigned bytes)
 {
    unsigned spi_tmpring_size;
-   ac_get_scratch_tmpring_size(&sctx->screen->info, bytes,
-                               &sctx->max_seen_scratch_bytes_per_wave, &spi_tmpring_size);
+   si_get_scratch_tmpring_size(sctx, bytes, false, &spi_tmpring_size);
 
    unsigned scratch_needed_size = sctx->max_seen_scratch_bytes_per_wave *
                                   sctx->screen->info.max_scratch_waves;
@@ -4545,8 +4552,7 @@ void si_init_tess_factor_ring(struct si_context *sctx)
                                                        SI_RESOURCE_FLAG_DRIVER_INTERNAL |
                                                        SI_RESOURCE_FLAG_DISCARDABLE,
                                                        PIPE_USAGE_DEFAULT,
-                                                       sscreen->hs.tess_offchip_ring_size +
-                                                       sscreen->hs.tess_factor_ring_size,
+                                                       sscreen->info.total_tess_ring_size,
                                                        2 * 1024 * 1024);
       if (!sscreen->tess_rings) {
          simple_mtx_unlock(&sscreen->tess_ring_lock);
@@ -4561,8 +4567,7 @@ void si_init_tess_factor_ring(struct si_context *sctx)
                                                               SI_RESOURCE_FLAG_DRIVER_INTERNAL |
                                                               SI_RESOURCE_FLAG_DISCARDABLE,
                                                               PIPE_USAGE_DEFAULT,
-                                                              sscreen->hs.tess_offchip_ring_size +
-                                                              sscreen->hs.tess_factor_ring_size,
+                                                              sscreen->info.total_tess_ring_size,
                                                               2 * 1024 * 1024);
       }
    }
@@ -4809,7 +4814,10 @@ void si_update_tess_io_layout_state(struct si_context *sctx)
    unsigned num_patches, lds_size;
 
    /* Compute NUM_PATCHES and LDS_SIZE. */
-   ac_nir_compute_tess_wg_info(&sctx->screen->info, &tcs->info.base, ls_current->wave_size,
+   ac_nir_compute_tess_wg_info(&sctx->screen->info, tcs->info.base.outputs_read,
+                               tcs->info.base.outputs_written, tcs->info.base.patch_outputs_read,
+                               tcs->info.base.patch_outputs_written,
+                               tcs->info.base.tess.tcs_vertices_out, ls_current->wave_size,
                                tess_uses_primid, tcs->info.tessfactors_are_def_in_all_invocs,
                                num_tcs_input_cp, lds_input_vertex_size,
                                num_mem_tcs_outputs, num_mem_tcs_patch_outputs,
@@ -5088,9 +5096,9 @@ static void si_emit_spi_ge_ring_state(struct si_context *sctx, unsigned index)
       struct pipe_resource *tf_ring =
          sctx->ws->cs_is_secure(&sctx->gfx_cs) ? sscreen->tess_rings_tmz : sscreen->tess_rings;
       uint64_t factor_va = si_resource(tf_ring)->gpu_address +
-                           sscreen->hs.tess_offchip_ring_size;
+                           sscreen->info.tess_offchip_ring_size;
 
-      unsigned tf_ring_size_field = sscreen->hs.tess_factor_ring_size / 4;
+      unsigned tf_ring_size_field = sscreen->info.tess_factor_ring_size / 4;
       if (sctx->gfx_level >= GFX11)
          tf_ring_size_field /= sscreen->info.max_se;
 
@@ -5107,7 +5115,7 @@ static void si_emit_spi_ge_ring_state(struct si_context *sctx, unsigned index)
       if (sctx->gfx_level >= GFX7) {
          radeon_set_uconfig_reg_seq(R_030938_VGT_TF_RING_SIZE, 3);
          radeon_emit(S_030938_SIZE(tf_ring_size_field)); /* R_030938_VGT_TF_RING_SIZE */
-         radeon_emit(sscreen->hs.hs_offchip_param);      /* R_03093C_VGT_HS_OFFCHIP_PARAM */
+         radeon_emit(sscreen->info.hs_offchip_param);      /* R_03093C_VGT_HS_OFFCHIP_PARAM */
          radeon_emit(factor_va >> 8);                    /* R_030940_VGT_TF_MEMORY_BASE */
 
          if (sctx->gfx_level >= GFX12)
@@ -5119,7 +5127,7 @@ static void si_emit_spi_ge_ring_state(struct si_context *sctx, unsigned index)
       } else {
          radeon_set_config_reg(R_008988_VGT_TF_RING_SIZE, S_008988_SIZE(tf_ring_size_field));
          radeon_set_config_reg(R_0089B8_VGT_TF_MEMORY_BASE, factor_va >> 8);
-         radeon_set_config_reg(R_0089B0_VGT_HS_OFFCHIP_PARAM, sscreen->hs.hs_offchip_param);
+         radeon_set_config_reg(R_0089B0_VGT_HS_OFFCHIP_PARAM, sscreen->info.hs_offchip_param);
       }
       radeon_end();
    }
diff --git a/src/gallium/drivers/radeonsi/si_test_blit_perf.c b/src/gallium/drivers/radeonsi/si_test_blit_perf.c
index d49a4a3f864..a8175682572 100644
--- a/src/gallium/drivers/radeonsi/si_test_blit_perf.c
+++ b/src/gallium/drivers/radeonsi/si_test_blit_perf.c
@@ -219,6 +219,9 @@ void si_test_blit_perf(struct si_screen *sscreen)
       for (unsigned dim = 1; dim <= 3; dim++) {
          for (unsigned format_index = 0; format_index < ARRAY_SIZE(formats); format_index++) {
             for (unsigned samples = 1; samples <= 8; samples *= 2) {
+               if (!sscreen->info.has_image_opcodes && samples > 1)
+                  break;
+
                for (unsigned layout = 0; layout < NUM_LAYOUTS; layout++) {
                   /* Reject invalid combinations. */
                   if (samples >= 2 && (dim != 2 || layout != LAYOUT_T2T))
@@ -242,6 +245,9 @@ void si_test_blit_perf(struct si_screen *sscreen)
                       util_format_is_pure_integer(formats[format_index]))
                      continue;
 
+                  if (!sscreen->info.has_image_opcodes && layout != LAYOUT_L2L)
+                     continue;
+
                   /* Create textures. */
                   struct pipe_resource *src[2] = {0}, *dst[2] = {0};
                   const struct pipe_resource templ = {
diff --git a/src/gallium/drivers/softpipe/ci/gitlab-ci.yml b/src/gallium/drivers/softpipe/ci/gitlab-ci.yml
index 08f997a823d..ea1558d008b 100644
--- a/src/gallium/drivers/softpipe/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/softpipe/ci/gitlab-ci.yml
@@ -7,7 +7,9 @@ softpipe:
     XVFB_SCRIPT: "install/deqp-runner.sh"
     DEQP_FRACTION: 4
   timeout: 15m
-  extends: .softpipe-deqp-test
+  extends:
+    - .softpipe-deqp-test
+    - .test-piglit
   script: |
     . "$SCRIPTS_DIR"/setup-test-env.sh
     export LD_LIBRARY_PATH=$CI_PROJECT_DIR/install/lib
@@ -20,6 +22,7 @@ softpipe-asan-gles31:
     GPU_VERSION: softpipe-asan
     DEQP_FRACTION: 10
     DEQP_FORCE_ASAN: 1
+    S3_ARTIFACT_NAME: mesa-x86_64-asan-debugoptimized
   timeout: 10m
   extends: .softpipe-deqp-test
   needs:
diff --git a/src/gallium/drivers/svga/ci/gitlab-ci.yml b/src/gallium/drivers/svga/ci/gitlab-ci.yml
index 6d368034f27..a7aa798841d 100644
--- a/src/gallium/drivers/svga/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/svga/ci/gitlab-ci.yml
@@ -4,7 +4,7 @@ include:
 .vmware-qemu-traces:x86_64:
   stage: software-renderer
   extends:
-    - .lava-piglit-traces:x86_64
+    - .lava-x86_64-piglit-traces
     - .vmware-manual-rules
   timeout: 30m
   variables:
@@ -23,7 +23,8 @@ include:
 vmware-vmx-piglit:x86_64:
   stage: layered-backends
   extends:
-    - .lava-test-deqp:x86_64
+    - .lava-x86_64-test-gl
+    - .test-piglit
     - .vmware-rules
   timeout: 30m
   parallel: 2
diff --git a/src/gallium/drivers/svga/ci/svga-fails.txt b/src/gallium/drivers/svga/ci/svga-fails.txt
index e2e799273de..abf619d5e6d 100644
--- a/src/gallium/drivers/svga/ci/svga-fails.txt
+++ b/src/gallium/drivers/svga/ci/svga-fails.txt
@@ -1082,5 +1082,7 @@ spec@arb_framebuffer_object@execution@msaa-alpha-to-coverage_alpha-to-one,Fail
 spec@arb_framebuffer_object@execution@msaa-alpha-to-coverage_alpha-to-one_write-z,Fail
 spec@egl_chromium_sync_control@conformance,Fail
 spec@egl_chromium_sync_control@conformance@eglGetSyncValuesCHROMIUM_msc_and_sbc_test,Fail
+spec@gl-3.1@attributeless-vertexid,Fail
+spec@glsl-1.50@execution@primitive-id-no-gs-first-vertex,Fail
 spec@glsl-1.50@execution@primitive-id-no-gs-line,Fail
 
diff --git a/src/gallium/drivers/svga/svga_pipe_streamout.c b/src/gallium/drivers/svga/svga_pipe_streamout.c
index c1604799b40..f4722b784cb 100644
--- a/src/gallium/drivers/svga/svga_pipe_streamout.c
+++ b/src/gallium/drivers/svga/svga_pipe_streamout.c
@@ -416,8 +416,10 @@ svga_set_stream_output_targets(struct pipe_context *pipe,
     * before mapping.
     */
    for (i = 0; i < svga->num_so_targets; i++) {
-      struct svga_buffer *sbuf = svga_buffer(svga->so_targets[i]->buffer);
-      sbuf->dirty = true;
+      if (svga->so_targets[i]) {
+         struct svga_buffer *sbuf = svga_buffer(svga->so_targets[i]->buffer);
+         sbuf->dirty = true;
+      }
    }
 
    /* Before the currently bound streamout targets are unbound,
@@ -433,36 +435,42 @@ svga_set_stream_output_targets(struct pipe_context *pipe,
    for (i = 0; i < num_targets; i++) {
       struct svga_stream_output_target *sot
          = svga_stream_output_target(targets[i]);
-      struct svga_buffer *sbuf = svga_buffer(sot->base.buffer);
-      unsigned size;
-
-      svga->so_surfaces[i] = svga_buffer_handle(svga, sot->base.buffer,
-                                                PIPE_BIND_STREAM_OUTPUT);
-
-      assert(svga_buffer(sot->base.buffer)->key.flags
-             & SVGA3D_SURFACE_BIND_STREAM_OUTPUT);
-
-      /* Mark the buffer surface as RENDERED */
-      assert(sbuf->bufsurf);
-      sbuf->bufsurf->surface_state = SVGA_SURFACE_STATE_RENDERED;
-
-      svga->so_targets[i] = &sot->base;
-      if (offsets[i] == -1) {
-         soBindings[i].offset = -1;
-
-         /* The streamout is being resumed. There is no need to restart streamout statistics
-          * queries for the draw-auto fallback since those queries are still active.
-          */
-         begin_so_queries = false;
+      if (sot) {
+         struct svga_buffer *sbuf = svga_buffer(sot->base.buffer);
+
+         svga->so_surfaces[i] = svga_buffer_handle(svga, sot->base.buffer,
+                                                   PIPE_BIND_STREAM_OUTPUT);
+
+         assert(svga_buffer(sot->base.buffer)->key.flags
+                & SVGA3D_SURFACE_BIND_STREAM_OUTPUT);
+
+         /* Mark the buffer surface as RENDERED */
+         assert(sbuf->bufsurf);
+         sbuf->bufsurf->surface_state = SVGA_SURFACE_STATE_RENDERED;
+
+         svga->so_targets[i] = &sot->base;
+         if (offsets[i] == -1) {
+            soBindings[i].offset = -1;
+
+            /* The streamout is being resumed. There is no need to restart
+             * streamout statistics queries for the draw-auto fallback since
+             * those queries are still active.
+             */
+            begin_so_queries = false;
+         } else {
+            soBindings[i].offset = sot->base.buffer_offset + offsets[i];
+         }
+
+         /* The size cannot extend beyond the end of the buffer.  Clamp it. */
+         soBindings[i].sizeInBytes =
+            MIN2(sot->base.buffer_size,
+                 sot->base.buffer->width0 - sot->base.buffer_offset);
+      } else {
+         svga->so_surfaces[i] = NULL;
+         svga->so_targets[i] = NULL;
+         soBindings[i].offset = 0;
+         soBindings[i].sizeInBytes = 0;
       }
-      else
-         soBindings[i].offset = sot->base.buffer_offset + offsets[i];
-
-      /* The size cannot extend beyond the end of the buffer.  Clamp it. */
-      size = MIN2(sot->base.buffer_size,
-                  sot->base.buffer->width0 - sot->base.buffer_offset);
-
-      soBindings[i].sizeInBytes = size;
    }
 
    /* unbind any previously bound stream output buffers */
diff --git a/src/gallium/drivers/v3d/v3d_context.h b/src/gallium/drivers/v3d/v3d_context.h
index cb8263f38cd..2f9172e1d57 100644
--- a/src/gallium/drivers/v3d/v3d_context.h
+++ b/src/gallium/drivers/v3d/v3d_context.h
@@ -712,6 +712,8 @@ struct v3d_depth_stencil_alpha_state {
 struct v3d_blend_state {
         struct pipe_blend_state base;
 
+        bool use_software;
+
         /* Per-RT mask of whether blending is enabled. */
         uint8_t blend_enables;
 };
diff --git a/src/gallium/drivers/v3d/v3d_program.c b/src/gallium/drivers/v3d/v3d_program.c
index a0136fffff5..c2a02b745ae 100644
--- a/src/gallium/drivers/v3d/v3d_program.c
+++ b/src/gallium/drivers/v3d/v3d_program.c
@@ -367,6 +367,16 @@ v3d_uncompiled_shader_create(struct pipe_context *pctx,
         if (s->info.stage == MESA_SHADER_KERNEL)
                 s->info.stage = MESA_SHADER_COMPUTE;
 
+        if (s->info.stage == MESA_SHADER_FRAGMENT &&
+            s->info.outputs_written & BITFIELD_BIT(FRAG_RESULT_COLOR)) {
+                /* We only support one attachment when doing dual source blending. */
+                if (s->info.fs.color_is_dual_source)
+                        NIR_PASS(_, s, nir_lower_fragcolor, 1);
+                else if (V3D_DBG(SOFT_BLEND))
+                        NIR_PASS(_, s, nir_lower_fragcolor,
+                                 V3D_MAX_DRAW_BUFFERS);
+        }
+
         if (s->info.stage != MESA_SHADER_VERTEX &&
             s->info.stage != MESA_SHADER_GEOMETRY) {
                 NIR_PASS(_, s, nir_lower_io,
@@ -680,6 +690,8 @@ v3d_update_compiled_fs(struct v3d_context *v3d, uint8_t prim_mode)
                  !v3d->zsa->base.depth_writemask) &&
                 !(v3d->active_queries && v3d->current_oq);
 
+        key->software_blend = v3d->blend->use_software;
+
         for (int i = 0; i < v3d->framebuffer.nr_cbufs; i++) {
                 struct pipe_surface *cbuf = v3d->framebuffer.cbufs[i];
                 if (!cbuf)
@@ -696,7 +708,8 @@ v3d_update_compiled_fs(struct v3d_context *v3d, uint8_t prim_mode)
                  * swizzle.
                  */
                 if (key->logicop_func != PIPE_LOGICOP_COPY ||
-                    s->info.fs.uses_fbfetch_output) {
+                    s->info.fs.uses_fbfetch_output ||
+                    key->software_blend) {
 
                         key->color_fmt[i].format = cbuf->format;
                         memcpy(key->color_fmt[i].swizzle,
@@ -705,6 +718,26 @@ v3d_update_compiled_fs(struct v3d_context *v3d, uint8_t prim_mode)
                                sizeof(key->color_fmt[i].swizzle));
                 }
 
+                if (key->software_blend) {
+                        struct pipe_rt_blend_state *blend = &v3d->blend->base.rt[i];
+
+                        if (blend->blend_enable) {
+                                key->blend[i].rgb_func = blend->rgb_func;
+                                key->blend[i].rgb_src_factor = blend->rgb_src_factor;
+                                key->blend[i].rgb_dst_factor = blend->rgb_dst_factor;
+                                key->blend[i].alpha_func = blend->alpha_func;
+                                key->blend[i].alpha_src_factor = blend->alpha_src_factor;
+                                key->blend[i].alpha_dst_factor = blend->alpha_dst_factor;
+                        } else {
+                                key->blend[i].rgb_func = PIPE_BLEND_ADD;
+                                key->blend[i].rgb_src_factor = PIPE_BLENDFACTOR_ONE;
+                                key->blend[i].rgb_dst_factor = PIPE_BLENDFACTOR_ZERO;
+                                key->blend[i].alpha_func = PIPE_BLEND_ADD;
+                                key->blend[i].alpha_src_factor = PIPE_BLENDFACTOR_ONE;
+                                key->blend[i].alpha_dst_factor = PIPE_BLENDFACTOR_ZERO;
+                        }
+                }
+
                 const struct util_format_description *desc =
                         util_format_description(cbuf->format);
 
diff --git a/src/gallium/drivers/v3d/v3d_screen.c b/src/gallium/drivers/v3d/v3d_screen.c
index c760c3c8675..de0777750f0 100644
--- a/src/gallium/drivers/v3d/v3d_screen.c
+++ b/src/gallium/drivers/v3d/v3d_screen.c
@@ -338,6 +338,7 @@ v3d_init_screen_caps(struct v3d_screen *screen)
         caps->max_render_targets = V3D_MAX_RENDER_TARGETS(screen->devinfo.ver);
         caps->fbfetch = caps->max_render_targets;
         caps->fbfetch_coherent = true;
+        caps->max_dual_source_render_targets = 1;
 
         caps->vendor_id = 0x14E4;
 
diff --git a/src/gallium/drivers/v3d/v3d_uniforms.c b/src/gallium/drivers/v3d/v3d_uniforms.c
index 329d888d49e..fe06237ba6a 100644
--- a/src/gallium/drivers/v3d/v3d_uniforms.c
+++ b/src/gallium/drivers/v3d/v3d_uniforms.c
@@ -393,6 +393,19 @@ v3d_write_uniforms(struct v3d_context *v3d, struct v3d_job *job,
                         cl_aligned_u32(&uniforms, job->num_layers);
                         break;
 
+                case QUNIFORM_BLEND_CONSTANT_R:
+                        cl_aligned_f(&uniforms, v3d->blend_color.f.color[0]);
+                        break;
+                case QUNIFORM_BLEND_CONSTANT_G:
+                        cl_aligned_f(&uniforms, v3d->blend_color.f.color[1]);
+                        break;
+                case QUNIFORM_BLEND_CONSTANT_B:
+                        cl_aligned_f(&uniforms, v3d->blend_color.f.color[2]);
+                        break;
+                case QUNIFORM_BLEND_CONSTANT_A:
+                        cl_aligned_f(&uniforms, v3d->blend_color.f.color[3]);
+                        break;
+
                 default:
                         unreachable("Unknown QUNIFORM");
 
@@ -486,6 +499,13 @@ v3d_set_shader_uniform_dirty_flags(struct v3d_compiled_shader *shader)
                         dirty |= V3D_DIRTY_FRAMEBUFFER;
                         break;
 
+                case QUNIFORM_BLEND_CONSTANT_R:
+                case QUNIFORM_BLEND_CONSTANT_G:
+                case QUNIFORM_BLEND_CONSTANT_B:
+                case QUNIFORM_BLEND_CONSTANT_A:
+                        dirty |= V3D_DIRTY_BLEND_COLOR;
+                        break;
+
                 default:
                         assert(quniform_contents_is_texture_p0(shader->prog_data.base->uniforms.contents[i]));
                         dirty |= V3D_DIRTY_FRAGTEX | V3D_DIRTY_VERTTEX |
diff --git a/src/gallium/drivers/v3d/v3dx_emit.c b/src/gallium/drivers/v3d/v3dx_emit.c
index e8f6d894745..d2d48422b62 100644
--- a/src/gallium/drivers/v3d/v3dx_emit.c
+++ b/src/gallium/drivers/v3d/v3dx_emit.c
@@ -324,7 +324,7 @@ v3dX(emit_state)(struct pipe_context *pctx)
                         config.direct3d_provoking_vertex =
                                 v3d->rasterizer->base.flatshade_first;
 
-                        config.blend_enable = v3d->blend->blend_enables;
+                        config.blend_enable = v3d->blend->blend_enables && !v3d->blend->use_software;
 
                         /* Note: EZ state may update based on the compiled FS,
                          * along with ZSA
@@ -480,7 +480,7 @@ v3dX(emit_state)(struct pipe_context *pctx)
         if (v3d->dirty & V3D_DIRTY_BLEND) {
                 struct v3d_blend_state *blend = v3d->blend;
 
-                if (blend->blend_enables) {
+                if (blend->blend_enables && !blend->use_software) {
                         cl_emit(&job->bcl, BLEND_ENABLES, enables) {
                                 enables.mask = blend->blend_enables;
                         }
@@ -516,6 +516,10 @@ v3dX(emit_state)(struct pipe_context *pctx)
                                               (1 << max_rts) - 1,
                                               v3d->blend_dst_alpha_one);
                         }
+                } else {
+                        cl_emit(&job->bcl, BLEND_ENABLES, enables) {
+                                enables.mask = 0;
+                        }
                 }
         }
 
@@ -535,9 +539,6 @@ v3dX(emit_state)(struct pipe_context *pctx)
                 }
         }
 
-        /* GFXH-1431: On V3D 3.x, writing BLEND_CONFIG resets the constant
-         * color.
-         */
         if (v3d->dirty & V3D_DIRTY_BLEND_COLOR) {
                 cl_emit(&job->bcl, BLEND_CONSTANT_COLOR, color) {
                         color.red_f16 = (v3d->swap_color_rb ?
diff --git a/src/gallium/drivers/v3d/v3dx_state.c b/src/gallium/drivers/v3d/v3dx_state.c
index 92c5f6070b7..4215d746407 100644
--- a/src/gallium/drivers/v3d/v3dx_state.c
+++ b/src/gallium/drivers/v3d/v3dx_state.c
@@ -24,6 +24,7 @@
 
 #include "pipe/p_state.h"
 #include "util/format/u_format.h"
+#include "util/u_dual_blend.h"
 #include "util/u_framebuffer.h"
 #include "util/u_inlines.h"
 #include "util/u_math.h"
@@ -123,6 +124,22 @@ v3d_create_rasterizer_state(struct pipe_context *pctx,
         return so;
 }
 
+/* If the pipe_blend_state contains dual source factors then we need to fall
+ * back to software blend.
+ */
+static bool
+v3d_needs_software_blend(const struct pipe_blend_state *blend)
+{
+        if (V3D_DBG(SOFT_BLEND))
+                return true;
+
+        /* We only support 1 attachment with dual source blend. */
+        if (util_blend_state_is_dual(blend, 0))
+                return true;
+
+        return false;
+}
+
 /* Blend state is baked into shaders. */
 static void *
 v3d_create_blend_state(struct pipe_context *pctx,
@@ -136,6 +153,8 @@ v3d_create_blend_state(struct pipe_context *pctx,
 
         so->base = *cso;
 
+        so->use_software = v3d_needs_software_blend(cso);
+
         uint32_t max_rts = V3D_MAX_RENDER_TARGETS(V3D_VERSION);
         if (cso->independent_blend_enable) {
                 for (int i = 0; i < max_rts; i++) {
diff --git a/src/gallium/drivers/virgl/ci/gitlab-ci-inc.yml b/src/gallium/drivers/virgl/ci/gitlab-ci-inc.yml
index 7e4cbd2ae41..acb8e08836d 100644
--- a/src/gallium/drivers/virgl/ci/gitlab-ci-inc.yml
+++ b/src/gallium/drivers/virgl/ci/gitlab-ci-inc.yml
@@ -41,7 +41,7 @@
     LAVA_S3_ARTIFACT_NAME: mesa-x86_64-default-release
     S3_ARTIFACT_NAME: mesa-python-ci-artifacts
   needs:
-    - kernel+rootfs_x86_64
+    - debian/x86_64_test-gl
     - debian-release
 
 .virpipe-test:
@@ -71,7 +71,7 @@
 
 .virgl-iris-test:
   extends:
-    - .lava-piglit-traces:x86_64
+    - .lava-x86_64-piglit-traces
     - .lava-acer-cp514-2h-1130g7-volteer:x86_64
   variables:
     HWCI_KERNEL_MODULES: vhost_vsock
diff --git a/src/gallium/drivers/virgl/ci/gitlab-ci.yml b/src/gallium/drivers/virgl/ci/gitlab-ci.yml
index f396c954644..84adb399599 100644
--- a/src/gallium/drivers/virgl/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/virgl/ci/gitlab-ci.yml
@@ -4,6 +4,7 @@ include:
 virpipe-on-gl:
   extends:
     - .deqp-test
+    - .test-piglit
     - .virpipe-test
   variables:
     DEQP_SUITE: virpipe-gl
diff --git a/src/gallium/drivers/zink/ci/gitlab-ci-inc.yml b/src/gallium/drivers/zink/ci/gitlab-ci-inc.yml
index d70fd9ec839..bcd6251c75d 100644
--- a/src/gallium/drivers/zink/ci/gitlab-ci-inc.yml
+++ b/src/gallium/drivers/zink/ci/gitlab-ci-inc.yml
@@ -41,7 +41,7 @@
     - !reference [.zink-common-rules, rules]
 
 .zink-venus-lvp-manual-rules:
-  stage: layered-backends-postmerge
+  stage: layered-backends-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -57,7 +57,7 @@
     - !reference [.zink-common-rules, rules]
 
 .zink-anv-manual-rules:
-  stage: layered-backends-postmerge
+  stage: layered-backends-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -80,7 +80,7 @@
     - !reference [.zink-common-rules, rules]
 
 .zink-nvk-manual-rules:
-  stage: layered-backends-postmerge
+  stage: layered-backends-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -97,7 +97,7 @@
     ZINK_DEBUG: optimal_keys
 
 .zink-turnip-collabora-manual-rules:
-  stage: layered-backends-postmerge
+  stage: layered-backends-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -105,7 +105,7 @@
     - !reference [.zink-common-manual-rules, rules]
 
 .zink-turnip-valve-manual-rules:
-  stage: layered-backends-postmerge
+  stage: layered-backends-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -120,7 +120,7 @@
     - !reference [.zink-common-rules, rules]
 
 .zink-radv-manual-rules:
-  stage: layered-backends-postmerge
+  stage: layered-backends-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -184,6 +184,7 @@
 
 .zink-anv-adl-test:
   extends:
+    - .lava-x86_64-test-gl
     - .anv-test
     - .lava-acer-cbv514-1h-34uz-brya:x86_64
     - .zink-anv-rules
@@ -194,7 +195,7 @@
 
 .zink-anv-adl-trace-test:
   extends:
-    - .lava-piglit-traces:x86_64
+    - .lava-x86_64-piglit-traces
     - .anv-test
     - .lava-acer-n20q11-r856ltn-p1s2-nissa:x86_64
     - .zink-anv-rules
@@ -205,6 +206,7 @@
 
 .zink-anv-tgl-test:
   extends:
+    - .lava-x86_64-test-gl
     - .anv-test
     - .lava-acer-cp514-2h-1160g7-volteer:x86_64
     - .zink-anv-rules
@@ -215,7 +217,7 @@
 
 .zink-anv-tgl-trace-test:
   extends:
-    - .lava-piglit-traces:x86_64
+    - .lava-x86_64-piglit-traces
     - .anv-test
     - .lava-acer-cp514-2h-1130g7-volteer:x86_64
     - .zink-anv-rules
@@ -228,6 +230,7 @@
   extends:
     - .b2c-x86_64-test-gl-manual
     - .nvk-vkcts
+    - .test-piglit
     - .zink-test
   variables:
     DEQP_SUITE: zink-nvk
@@ -248,6 +251,7 @@
   timeout: 30m
   extends:
     - .zink-test
+    - .test-piglit
     - .test-radv
     - .b2c-x86_64-test-gl
   variables:
diff --git a/src/gallium/drivers/zink/ci/gitlab-ci.yml b/src/gallium/drivers/zink/ci/gitlab-ci.yml
index 6771f4e3776..9a9e422e284 100644
--- a/src/gallium/drivers/zink/ci/gitlab-ci.yml
+++ b/src/gallium/drivers/zink/ci/gitlab-ci.yml
@@ -4,6 +4,7 @@ include:
 zink-lvp:
   extends:
     - .test-gl
+    - .test-piglit
     - .deqp-test
     - .zink-lvp-test
   tags:
@@ -27,6 +28,7 @@ zink-venus-lvp:
     - .test-gl
     - .deqp-test
     - .zink-venus-lvp-test
+    - .test-piglit
   timeout: 15min  # base run time = 8min, but it's on the shared runners so it can go up
   variables:
     DEQP_SUITE: zink-venus-lvp
@@ -54,6 +56,7 @@ zink-venus-lvp-full:
 zink-anv-adl:
   extends:
     - .zink-anv-adl-test
+    - .test-piglit
   variables:
     DEQP_SUITE: zink-anv-adl
     PIGLIT_NO_WINDOW: 1
@@ -69,6 +72,7 @@ zink-anv-adl-full:
   extends:
     - zink-anv-adl
     - .zink-anv-manual-rules
+    - .test-piglit
   variables:
     DEQP_SUITE: zink-anv-adl-full
   timeout: 2h
@@ -92,6 +96,7 @@ zink-anv-adl-traces-restricted:
 zink-anv-tgl:
   extends:
     - .zink-anv-tgl-test
+    - .test-piglit
   timeout: 30m
   variables:
     DEQP_SUITE: zink-anv-tgl
@@ -109,6 +114,7 @@ zink-anv-tgl-full:
   extends:
     - zink-anv-tgl
     - .zink-anv-manual-rules
+    - .test-piglit
   variables:
     DEQP_SUITE: zink-anv-tgl-full
   timeout: 1h 45m
@@ -131,7 +137,7 @@ zink-anv-tgl-traces-restricted:
 
 zink-tu-a618:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .zink-turnip-collabora-rules
     - .zink-test
     - .lava-sc7180-trogdor-lazor-limozeen:arm64
@@ -181,6 +187,7 @@ zink-tu-a750:
     - .tu-zink-test-valve
     - .a750-mupuf
     - .zink-turnip-valve-manual-rules
+    - .test-piglit
   timeout: 25m  # base runtime 11min total, 9min of testing
   variables:
     B2C_TIMEOUT_BOOT_MINUTES: 18
diff --git a/src/gallium/drivers/zink/zink_compiler.c b/src/gallium/drivers/zink/zink_compiler.c
index bef1cf0a3a4..4d8ecb5ec66 100644
--- a/src/gallium/drivers/zink/zink_compiler.c
+++ b/src/gallium/drivers/zink/zink_compiler.c
@@ -1362,7 +1362,8 @@ zink_screen_init_compiler(struct zink_screen *screen)
        zink_driverid(screen) == VK_DRIVER_ID_AMD_PROPRIETARY)
       screen->nir_options.lower_doubles_options = nir_lower_dmod;
 
-   if (screen->info.have_EXT_shader_demote_to_helper_invocation)
+   if (screen->info.have_EXT_shader_demote_to_helper_invocation &&
+       !screen->driver_compiler_workarounds.broken_demote)
       screen->nir_options.discard_is_demote = true;
 
    screen->nir_options.support_indirect_inputs = (uint8_t)BITFIELD_MASK(PIPE_SHADER_TYPES);
diff --git a/src/gallium/drivers/zink/zink_descriptors.c b/src/gallium/drivers/zink/zink_descriptors.c
index 5a191ea5c27..194cb7fe13e 100644
--- a/src/gallium/drivers/zink/zink_descriptors.c
+++ b/src/gallium/drivers/zink/zink_descriptors.c
@@ -857,15 +857,9 @@ set_pool(struct zink_batch_state *bs, struct zink_program *pg, struct zink_descr
    assert(type != ZINK_DESCRIPTOR_TYPE_UNIFORMS);
    assert(mpool);
    const struct zink_descriptor_pool_key *pool_key = pg->dd.pool_key[type];
-   size_t size = bs->dd.pools[type].capacity;
    /* ensure the pool array is big enough to have an element for this key */
-   if (!util_dynarray_resize(&bs->dd.pools[type], struct zink_descriptor_pool_multi*, pool_key->id + 1))
+   if (!util_dynarray_resize_zero(&bs->dd.pools[type], struct zink_descriptor_pool_multi*, pool_key->id + 1))
       return false;
-   if (size != bs->dd.pools[type].capacity) {
-      /* when resizing, always zero the new data to avoid garbage */
-      uint8_t *data = bs->dd.pools[type].data;
-      memset(data + size, 0, bs->dd.pools[type].capacity - size);
-   }
    /* dynarray can't track sparse array sizing, so the array size must be manually tracked */
    bs->dd.pool_size[type] = MAX2(bs->dd.pool_size[type], pool_key->id + 1);
    struct zink_descriptor_pool_multi **mppool = util_dynarray_element(&bs->dd.pools[type], struct zink_descriptor_pool_multi*, pool_key->id);
diff --git a/src/gallium/drivers/zink/zink_screen.c b/src/gallium/drivers/zink/zink_screen.c
index a7fe1d683eb..26254397268 100644
--- a/src/gallium/drivers/zink/zink_screen.c
+++ b/src/gallium/drivers/zink/zink_screen.c
@@ -859,8 +859,9 @@ zink_init_screen_caps(struct zink_screen *screen)
        screen->info.have_EXT_shader_subgroup_ballot);
 
    caps->demote_to_helper_invocation =
-      screen->spirv_version >= SPIRV_VERSION(1, 6) ||
-      screen->info.have_EXT_shader_demote_to_helper_invocation;
+      (screen->spirv_version >= SPIRV_VERSION(1, 6) ||
+       screen->info.have_EXT_shader_demote_to_helper_invocation) &&
+      !screen->driver_compiler_workarounds.broken_demote;
 
    caps->sample_shading = screen->info.feats.features.sampleRateShading;
 
@@ -2933,6 +2934,16 @@ init_driver_workarounds(struct zink_screen *screen)
       break;
    }
 
+   /* these drivers do not implement demote properly */
+   switch (zink_driverid(screen)) {
+   case VK_DRIVER_ID_IMAGINATION_PROPRIETARY:
+      screen->driver_compiler_workarounds.broken_demote = true;
+      break;
+   default:
+      screen->driver_compiler_workarounds.broken_demote = false;
+      break;
+   }
+
    /* When robust contexts are advertised but robustImageAccess2 is not available */
    screen->driver_compiler_workarounds.lower_robustImageAccess2 =
       !screen->info.rb2_feats.robustImageAccess2 &&
diff --git a/src/gallium/drivers/zink/zink_types.h b/src/gallium/drivers/zink/zink_types.h
index 5430197f099..66a3fc1200f 100644
--- a/src/gallium/drivers/zink/zink_types.h
+++ b/src/gallium/drivers/zink/zink_types.h
@@ -1544,6 +1544,7 @@ struct zink_screen {
       bool needs_sanitised_layer;
       bool io_opt;
       bool broken_const;
+      bool broken_demote;
    } driver_compiler_workarounds;
    struct {
       bool broken_l4a4;
diff --git a/src/gallium/frontends/clover/api/context.cpp b/src/gallium/frontends/clover/api/context.cpp
deleted file mode 100644
index 65464bcde06..00000000000
--- a/src/gallium/frontends/clover/api/context.cpp
+++ /dev/null
@@ -1,162 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/util.hpp"
-#include "core/context.hpp"
-#include "core/platform.hpp"
-
-using namespace clover;
-
-CLOVER_API cl_context
-clCreateContext(const cl_context_properties *d_props, cl_uint num_devs,
-                const cl_device_id *d_devs,
-                void (CL_CALLBACK *pfn_notify)(const char *, const void *,
-                                               size_t, void *),
-                void *user_data, cl_int *r_errcode) try {
-   auto props = obj<property_list_tag>(d_props);
-   auto devs = objs(d_devs, num_devs);
-
-   if (!pfn_notify && user_data)
-      throw error(CL_INVALID_VALUE);
-
-   for (auto &prop : props) {
-      if (prop.first == CL_CONTEXT_PLATFORM)
-         find_platform(prop.second.as<cl_platform_id>());
-      else
-         throw error(CL_INVALID_PROPERTY);
-   }
-
-   const auto notify = (!pfn_notify ? context::notify_action() :
-                        [=](const char *s) {
-                           pfn_notify(s, NULL, 0, user_data);
-                        });
-
-   ret_error(r_errcode, CL_SUCCESS);
-   return desc(new context(props, devs, notify));
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_context
-clCreateContextFromType(const cl_context_properties *d_props,
-                        cl_device_type type,
-                        void (CL_CALLBACK *pfn_notify)(
-                           const char *, const void *, size_t, void *),
-                        void *user_data, cl_int *r_errcode) try {
-   cl_platform_id d_platform;
-   cl_uint num_platforms;
-   cl_int ret;
-   std::vector<cl_device_id> devs;
-   cl_uint num_devices;
-
-   ret = clGetPlatformIDs(1, &d_platform, &num_platforms);
-   if (ret || !num_platforms)
-      throw error(CL_INVALID_PLATFORM);
-
-   ret = clGetDeviceIDs(d_platform, type, 0, NULL, &num_devices);
-   if (ret)
-      throw error(CL_DEVICE_NOT_FOUND);
-   devs.resize(num_devices);
-   ret = clGetDeviceIDs(d_platform, type, num_devices, devs.data(), 0);
-   if (ret)
-      throw error(CL_DEVICE_NOT_FOUND);
-
-   return clCreateContext(d_props, num_devices, devs.data(), pfn_notify,
-                          user_data, r_errcode);
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_int
-clRetainContext(cl_context d_ctx) try {
-   obj(d_ctx).retain();
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clReleaseContext(cl_context d_ctx) try {
-   if (obj(d_ctx).release())
-      delete pobj(d_ctx);
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetContextInfo(cl_context d_ctx, cl_context_info param,
-                 size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &ctx = obj(d_ctx);
-
-   switch (param) {
-   case CL_CONTEXT_REFERENCE_COUNT:
-      buf.as_scalar<cl_uint>() = ctx.ref_count();
-      break;
-
-   case CL_CONTEXT_NUM_DEVICES:
-      buf.as_scalar<cl_uint>() = ctx.devices().size();
-      break;
-
-   case CL_CONTEXT_DEVICES:
-      buf.as_vector<cl_device_id>() = descs(ctx.devices());
-      break;
-
-   case CL_CONTEXT_PROPERTIES:
-      buf.as_vector<cl_context_properties>() = desc(ctx.properties());
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clSetContextDestructorCallback(cl_context d_ctx,
-                               void (CL_CALLBACK *pfn_notify)(cl_context, void *),
-                               void *user_data) try {
-   CLOVER_NOT_SUPPORTED_UNTIL("3.0");
-   auto &ctx = obj(d_ctx);
-
-   if (!pfn_notify)
-      return CL_INVALID_VALUE;
-
-   ctx.destroy_notify([=]{ pfn_notify(d_ctx, user_data); });
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
diff --git a/src/gallium/frontends/clover/api/device.cpp b/src/gallium/frontends/clover/api/device.cpp
deleted file mode 100644
index 2d1066f629b..00000000000
--- a/src/gallium/frontends/clover/api/device.cpp
+++ /dev/null
@@ -1,525 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/util.hpp"
-#include "core/platform.hpp"
-#include "core/device.hpp"
-#include "git_sha1.h"
-
-using namespace clover;
-
-namespace {
-   std::string
-   supported_il_versions_as_string(const device &dev) {
-      std::string il_versions_string;
-
-      for (const auto &il_version : dev.supported_il_versions()) {
-         if (!il_versions_string.empty())
-            il_versions_string += " ";
-
-         il_versions_string += std::string(il_version.name) + "_" +
-            std::to_string(CL_VERSION_MAJOR(il_version.version)) + "." +
-            std::to_string(CL_VERSION_MINOR(il_version.version));
-      }
-      return il_versions_string;
-   }
-}
-
-CLOVER_API cl_int
-clGetDeviceIDs(cl_platform_id d_platform, cl_device_type device_type,
-               cl_uint num_entries, cl_device_id *rd_devices,
-               cl_uint *rnum_devices) try {
-   auto &platform = obj(d_platform);
-   std::vector<cl_device_id> d_devs;
-
-   if ((!num_entries && rd_devices) ||
-       (!rnum_devices && !rd_devices))
-      throw error(CL_INVALID_VALUE);
-
-   // Collect matching devices
-   for (device &dev : platform) {
-      if (((device_type & CL_DEVICE_TYPE_DEFAULT) &&
-           dev == platform.front()) ||
-          (device_type & dev.type()))
-         d_devs.push_back(desc(dev));
-   }
-
-   if (d_devs.empty())
-      throw error(CL_DEVICE_NOT_FOUND);
-
-   // ...and return the requested data.
-   if (rnum_devices)
-      *rnum_devices = d_devs.size();
-   if (rd_devices)
-      copy(range(d_devs.begin(),
-                 std::min((unsigned)d_devs.size(), num_entries)),
-           rd_devices);
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clCreateSubDevices(cl_device_id d_dev,
-                   const cl_device_partition_property *props,
-                   cl_uint num_devs, cl_device_id *rd_devs,
-                   cl_uint *rnum_devs) {
-   // There are no currently supported partitioning schemes.
-   return CL_INVALID_VALUE;
-}
-
-CLOVER_API cl_int
-clRetainDevice(cl_device_id d_dev) try {
-   obj(d_dev);
-
-   // The reference count doesn't change for root devices.
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clReleaseDevice(cl_device_id d_dev) try {
-   obj(d_dev);
-
-   // The reference count doesn't change for root devices.
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetDeviceInfo(cl_device_id d_dev, cl_device_info param,
-                size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &dev = obj(d_dev);
-
-   switch (param) {
-   case CL_DEVICE_TYPE:
-      buf.as_scalar<cl_device_type>() = dev.type();
-      break;
-
-   case CL_DEVICE_VENDOR_ID:
-      buf.as_scalar<cl_uint>() = dev.vendor_id();
-      break;
-
-   case CL_DEVICE_MAX_COMPUTE_UNITS:
-      buf.as_scalar<cl_uint>() = dev.max_compute_units();
-      break;
-
-   case CL_DEVICE_MAX_WORK_ITEM_DIMENSIONS:
-      buf.as_scalar<cl_uint>() = dev.max_block_size().size();
-      break;
-
-   case CL_DEVICE_MAX_WORK_ITEM_SIZES:
-      buf.as_vector<size_t>() = dev.max_block_size();
-      break;
-
-   case CL_DEVICE_MAX_WORK_GROUP_SIZE:
-      buf.as_scalar<size_t>() = dev.max_threads_per_block();
-      break;
-
-   case CL_DEVICE_PREFERRED_VECTOR_WIDTH_CHAR:
-      buf.as_scalar<cl_uint>() = 16;
-      break;
-
-   case CL_DEVICE_PREFERRED_VECTOR_WIDTH_SHORT:
-      buf.as_scalar<cl_uint>() = 8;
-      break;
-
-   case CL_DEVICE_PREFERRED_VECTOR_WIDTH_INT:
-      buf.as_scalar<cl_uint>() = 4;
-      break;
-
-   case CL_DEVICE_PREFERRED_VECTOR_WIDTH_LONG:
-      buf.as_scalar<cl_uint>() = 2;
-      break;
-
-   case CL_DEVICE_PREFERRED_VECTOR_WIDTH_FLOAT:
-      buf.as_scalar<cl_uint>() = 4;
-      break;
-
-   case CL_DEVICE_PREFERRED_VECTOR_WIDTH_DOUBLE:
-      buf.as_scalar<cl_uint>() = dev.has_doubles() ? 2 : 0;
-      break;
-
-   case CL_DEVICE_PREFERRED_VECTOR_WIDTH_HALF:
-      buf.as_scalar<cl_uint>() = dev.has_halves() ? 8 : 0;
-      break;
-
-   case CL_DEVICE_MAX_CLOCK_FREQUENCY:
-      buf.as_scalar<cl_uint>() = dev.max_clock_frequency();
-      break;
-
-   case CL_DEVICE_ADDRESS_BITS:
-      buf.as_scalar<cl_uint>() = dev.address_bits();
-      break;
-
-   case CL_DEVICE_MAX_READ_IMAGE_ARGS:
-      buf.as_scalar<cl_uint>() = dev.max_images_read();
-      break;
-
-   case CL_DEVICE_MAX_WRITE_IMAGE_ARGS:
-      buf.as_scalar<cl_uint>() = dev.max_images_write();
-      break;
-
-   case CL_DEVICE_MAX_MEM_ALLOC_SIZE:
-      buf.as_scalar<cl_ulong>() = dev.max_mem_alloc_size();
-      break;
-
-   case CL_DEVICE_IMAGE2D_MAX_WIDTH:
-   case CL_DEVICE_IMAGE2D_MAX_HEIGHT:
-      buf.as_scalar<size_t>() = dev.max_image_size();
-      break;
-
-   case CL_DEVICE_IMAGE3D_MAX_WIDTH:
-   case CL_DEVICE_IMAGE3D_MAX_HEIGHT:
-   case CL_DEVICE_IMAGE3D_MAX_DEPTH:
-      buf.as_scalar<size_t>() = dev.max_image_size_3d();
-      break;
-
-   case CL_DEVICE_IMAGE_MAX_BUFFER_SIZE:
-      buf.as_scalar<size_t>() = dev.max_image_buffer_size();
-      break;
-
-   case CL_DEVICE_IMAGE_MAX_ARRAY_SIZE:
-      buf.as_scalar<size_t>() = dev.max_image_array_number();
-      break;
-
-   case CL_DEVICE_IMAGE_SUPPORT:
-      buf.as_scalar<cl_bool>() = dev.image_support();
-      break;
-
-   case CL_DEVICE_MAX_PARAMETER_SIZE:
-      buf.as_scalar<size_t>() = dev.max_mem_input();
-      break;
-
-   case CL_DEVICE_MAX_SAMPLERS:
-      buf.as_scalar<cl_uint>() = dev.max_samplers();
-      break;
-
-   case CL_DEVICE_MEM_BASE_ADDR_ALIGN:
-      buf.as_scalar<cl_uint>() = 8 * dev.mem_base_addr_align();
-      break;
-
-   case CL_DEVICE_MIN_DATA_TYPE_ALIGN_SIZE:
-      buf.as_scalar<cl_uint>() = 128;
-      break;
-
-   case CL_DEVICE_HALF_FP_CONFIG:
-      // This is the "mandated minimum half precision floating-point
-      // capability" for OpenCL 1.x.
-      buf.as_scalar<cl_device_fp_config>() =
-         CL_FP_INF_NAN | CL_FP_ROUND_TO_NEAREST;
-      break;
-
-   case CL_DEVICE_SINGLE_FP_CONFIG:
-      // This is the "mandated minimum single precision floating-point
-      // capability" for OpenCL 1.1.  In OpenCL 1.2, nothing is required for
-      // custom devices.
-      buf.as_scalar<cl_device_fp_config>() =
-         CL_FP_INF_NAN | CL_FP_ROUND_TO_NEAREST;
-      break;
-
-   case CL_DEVICE_DOUBLE_FP_CONFIG:
-      if (dev.has_doubles())
-         // This is the "mandated minimum double precision floating-point
-         // capability"
-         buf.as_scalar<cl_device_fp_config>() =
-               CL_FP_FMA
-             | CL_FP_ROUND_TO_NEAREST
-             | CL_FP_ROUND_TO_ZERO
-             | CL_FP_ROUND_TO_INF
-             | CL_FP_INF_NAN
-             | CL_FP_DENORM;
-      else
-         buf.as_scalar<cl_device_fp_config>() = 0;
-      break;
-
-   case CL_DEVICE_GLOBAL_MEM_CACHE_TYPE:
-      buf.as_scalar<cl_device_mem_cache_type>() = CL_NONE;
-      break;
-
-   case CL_DEVICE_GLOBAL_MEM_CACHELINE_SIZE:
-      buf.as_scalar<cl_uint>() = 0;
-      break;
-
-   case CL_DEVICE_GLOBAL_MEM_CACHE_SIZE:
-      buf.as_scalar<cl_ulong>() = 0;
-      break;
-
-   case CL_DEVICE_GLOBAL_MEM_SIZE:
-      buf.as_scalar<cl_ulong>() = dev.max_mem_global();
-      break;
-
-   case CL_DEVICE_MAX_CONSTANT_BUFFER_SIZE:
-      buf.as_scalar<cl_ulong>() = dev.max_const_buffer_size();
-      break;
-
-   case CL_DEVICE_MAX_CONSTANT_ARGS:
-      buf.as_scalar<cl_uint>() = dev.max_const_buffers();
-      break;
-
-   case CL_DEVICE_LOCAL_MEM_TYPE:
-      buf.as_scalar<cl_device_local_mem_type>() = CL_LOCAL;
-      break;
-
-   case CL_DEVICE_LOCAL_MEM_SIZE:
-      buf.as_scalar<cl_ulong>() = dev.max_mem_local();
-      break;
-
-   case CL_DEVICE_ERROR_CORRECTION_SUPPORT:
-      buf.as_scalar<cl_bool>() = CL_FALSE;
-      break;
-
-   case CL_DEVICE_PROFILING_TIMER_RESOLUTION:
-      buf.as_scalar<size_t>() = 0;
-      break;
-
-   case CL_DEVICE_ENDIAN_LITTLE:
-      buf.as_scalar<cl_bool>() = (dev.endianness() == PIPE_ENDIAN_LITTLE);
-      break;
-
-   case CL_DEVICE_AVAILABLE:
-   case CL_DEVICE_COMPILER_AVAILABLE:
-   case CL_DEVICE_LINKER_AVAILABLE:
-      buf.as_scalar<cl_bool>() = CL_TRUE;
-      break;
-
-   case CL_DEVICE_EXECUTION_CAPABILITIES:
-      buf.as_scalar<cl_device_exec_capabilities>() = CL_EXEC_KERNEL;
-      break;
-
-   case CL_DEVICE_QUEUE_PROPERTIES:
-      buf.as_scalar<cl_command_queue_properties>() = CL_QUEUE_PROFILING_ENABLE;
-      break;
-
-   case CL_DEVICE_BUILT_IN_KERNELS:
-      buf.as_string() = "";
-      break;
-
-   case CL_DEVICE_NAME:
-      buf.as_string() = dev.device_name();
-      break;
-
-   case CL_DEVICE_VENDOR:
-      buf.as_string() = dev.vendor_name();
-      break;
-
-   case CL_DRIVER_VERSION:
-      buf.as_string() = PACKAGE_VERSION;
-      break;
-
-   case CL_DEVICE_PROFILE:
-      buf.as_string() = "FULL_PROFILE";
-      break;
-
-   case CL_DEVICE_VERSION:
-      buf.as_string() = "OpenCL " + dev.device_version_as_string() + " Mesa " PACKAGE_VERSION MESA_GIT_SHA1;
-      break;
-
-   case CL_DEVICE_EXTENSIONS:
-      buf.as_string() = dev.supported_extensions_as_string();
-      break;
-
-   case CL_DEVICE_PLATFORM:
-      buf.as_scalar<cl_platform_id>() = desc(dev.platform);
-      break;
-
-   case CL_DEVICE_HOST_UNIFIED_MEMORY:
-      buf.as_scalar<cl_bool>() = dev.has_unified_memory();
-      break;
-
-   case CL_DEVICE_NATIVE_VECTOR_WIDTH_CHAR:
-      buf.as_scalar<cl_uint>() = 16;
-      break;
-
-   case CL_DEVICE_NATIVE_VECTOR_WIDTH_SHORT:
-      buf.as_scalar<cl_uint>() = 8;
-      break;
-
-   case CL_DEVICE_NATIVE_VECTOR_WIDTH_INT:
-      buf.as_scalar<cl_uint>() = 4;
-      break;
-
-   case CL_DEVICE_NATIVE_VECTOR_WIDTH_LONG:
-      buf.as_scalar<cl_uint>() = 2;
-      break;
-
-   case CL_DEVICE_NATIVE_VECTOR_WIDTH_FLOAT:
-      buf.as_scalar<cl_uint>() = 4;
-      break;
-
-   case CL_DEVICE_NATIVE_VECTOR_WIDTH_DOUBLE:
-      buf.as_scalar<cl_uint>() = dev.has_doubles() ? 2 : 0;
-      break;
-
-   case CL_DEVICE_NATIVE_VECTOR_WIDTH_HALF:
-      buf.as_scalar<cl_uint>() = dev.has_halves() ? 8 : 0;
-      break;
-
-   case CL_DEVICE_OPENCL_C_VERSION:
-      buf.as_string() = "OpenCL C " + dev.device_clc_version_as_string() + " ";
-      break;
-
-   case CL_DEVICE_PRINTF_BUFFER_SIZE:
-      buf.as_scalar<size_t>() = dev.max_printf_buffer_size();
-      break;
-
-   case CL_DEVICE_PREFERRED_INTEROP_USER_SYNC:
-      buf.as_scalar<cl_bool>() = CL_TRUE;
-      break;
-
-   case CL_DEVICE_PARENT_DEVICE:
-      buf.as_scalar<cl_device_id>() = NULL;
-      break;
-
-   case CL_DEVICE_PARTITION_MAX_SUB_DEVICES:
-      buf.as_scalar<cl_uint>() = 0;
-      break;
-
-   case CL_DEVICE_PARTITION_PROPERTIES:
-      buf.as_vector<cl_device_partition_property>() =
-         desc(property_list<cl_device_partition_property>());
-      break;
-
-   case CL_DEVICE_PARTITION_AFFINITY_DOMAIN:
-      buf.as_scalar<cl_device_affinity_domain>() = 0;
-      break;
-
-   case CL_DEVICE_PARTITION_TYPE:
-      buf.as_vector<cl_device_partition_property>() =
-         desc(property_list<cl_device_partition_property>());
-      break;
-
-   case CL_DEVICE_REFERENCE_COUNT:
-      buf.as_scalar<cl_uint>() = 1;
-      break;
-
-   case CL_DEVICE_SVM_CAPABILITIES:
-   case CL_DEVICE_SVM_CAPABILITIES_ARM:
-      buf.as_scalar<cl_device_svm_capabilities>() = dev.svm_support();
-      break;
-
-   case CL_DEVICE_NUMERIC_VERSION:
-      buf.as_scalar<cl_version>() = dev.device_version();
-      break;
-
-   case CL_DEVICE_OPENCL_C_NUMERIC_VERSION_KHR:
-      buf.as_scalar<cl_version>() = dev.device_clc_version(true);
-      break;
-
-   case CL_DEVICE_OPENCL_C_ALL_VERSIONS:
-      buf.as_vector<cl_name_version>() = dev.opencl_c_all_versions();
-      break;
-
-   case CL_DEVICE_EXTENSIONS_WITH_VERSION:
-      buf.as_vector<cl_name_version>() = dev.supported_extensions();
-      break;
-
-   case CL_DEVICE_OPENCL_C_FEATURES:
-      buf.as_vector<cl_name_version>() = dev.opencl_c_features();
-      break;
-
-   case CL_DEVICE_IL_VERSION:
-      if (dev.supported_extensions_as_string().find("cl_khr_il_program") == std::string::npos)
-         throw error(CL_INVALID_VALUE);
-      buf.as_string() = supported_il_versions_as_string(dev);
-      break;
-
-   case CL_DEVICE_ILS_WITH_VERSION:
-      buf.as_vector<cl_name_version>() = dev.supported_il_versions();
-      break;
-
-   case CL_DEVICE_BUILT_IN_KERNELS_WITH_VERSION:
-      buf.as_vector<cl_name_version>() = std::vector<cl_name_version>{};
-      break;
-
-   case CL_DEVICE_MAX_READ_WRITE_IMAGE_ARGS:
-   case CL_DEVICE_IMAGE_PITCH_ALIGNMENT:
-   case CL_DEVICE_IMAGE_BASE_ADDRESS_ALIGNMENT:
-   case CL_DEVICE_PREFERRED_PLATFORM_ATOMIC_ALIGNMENT:
-   case CL_DEVICE_PREFERRED_GLOBAL_ATOMIC_ALIGNMENT:
-   case CL_DEVICE_PREFERRED_LOCAL_ATOMIC_ALIGNMENT:
-   case CL_DEVICE_MAX_NUM_SUB_GROUPS:
-   case CL_DEVICE_QUEUE_ON_DEVICE_PREFERRED_SIZE:
-   case CL_DEVICE_QUEUE_ON_DEVICE_MAX_SIZE:
-   case CL_DEVICE_MAX_ON_DEVICE_QUEUES:
-   case CL_DEVICE_MAX_ON_DEVICE_EVENTS:
-   case CL_DEVICE_MAX_PIPE_ARGS:
-   case CL_DEVICE_PIPE_MAX_ACTIVE_RESERVATIONS:
-   case CL_DEVICE_PIPE_MAX_PACKET_SIZE:
-      buf.as_scalar<cl_uint>() = 0;
-      break;
-
-   case CL_DEVICE_MAX_GLOBAL_VARIABLE_SIZE:
-   case CL_DEVICE_GLOBAL_VARIABLE_PREFERRED_TOTAL_SIZE:
-      buf.as_scalar<size_t>() = 0;
-      break;
-
-   case CL_DEVICE_SUB_GROUP_INDEPENDENT_FORWARD_PROGRESS:
-   case CL_DEVICE_NON_UNIFORM_WORK_GROUP_SUPPORT:
-   case CL_DEVICE_WORK_GROUP_COLLECTIVE_FUNCTIONS_SUPPORT:
-   case CL_DEVICE_GENERIC_ADDRESS_SPACE_SUPPORT:
-   case CL_DEVICE_PIPE_SUPPORT:
-      buf.as_scalar<cl_bool>() = CL_FALSE;
-      break;
-
-   case CL_DEVICE_QUEUE_ON_DEVICE_PROPERTIES:
-      buf.as_scalar<cl_command_queue_properties>() = 0;
-      break;
-
-   case CL_DEVICE_ATOMIC_MEMORY_CAPABILITIES:
-      buf.as_scalar<cl_device_atomic_capabilities>() = (CL_DEVICE_ATOMIC_ORDER_RELAXED |
-                                                        CL_DEVICE_ATOMIC_SCOPE_WORK_GROUP);
-      break;
-   case CL_DEVICE_ATOMIC_FENCE_CAPABILITIES:
-      buf.as_scalar<cl_device_atomic_capabilities>() = (CL_DEVICE_ATOMIC_ORDER_RELAXED |
-                                                        CL_DEVICE_ATOMIC_ORDER_ACQ_REL |
-                                                        CL_DEVICE_ATOMIC_SCOPE_WORK_GROUP);
-      break;
-
-   case CL_DEVICE_DEVICE_ENQUEUE_CAPABILITIES:
-      buf.as_scalar<cl_device_device_enqueue_capabilities>() = 0;
-      break;
-
-   case CL_DEVICE_PREFERRED_WORK_GROUP_SIZE_MULTIPLE:
-      buf.as_scalar<size_t>() = 1;
-      break;
-
-   case CL_DEVICE_LATEST_CONFORMANCE_VERSION_PASSED:
-      buf.as_string() = "";
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
diff --git a/src/gallium/frontends/clover/api/dispatch.cpp b/src/gallium/frontends/clover/api/dispatch.cpp
deleted file mode 100644
index e6c54b1d727..00000000000
--- a/src/gallium/frontends/clover/api/dispatch.cpp
+++ /dev/null
@@ -1,204 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/dispatch.hpp"
-
-namespace clover {
-   const cl_icd_dispatch _dispatch = {
-      // OpenCL 1.0
-      clGetPlatformIDs,
-      GetPlatformInfo,
-      clGetDeviceIDs,
-      clGetDeviceInfo,
-      clCreateContext,
-      clCreateContextFromType,
-      clRetainContext,
-      clReleaseContext,
-      clGetContextInfo,
-      clCreateCommandQueue,
-      clRetainCommandQueue,
-      clReleaseCommandQueue,
-      clGetCommandQueueInfo,
-      NULL, // clSetCommandQueueProperty
-      clCreateBuffer,
-      clCreateImage2D,
-      clCreateImage3D,
-      clRetainMemObject,
-      clReleaseMemObject,
-      clGetSupportedImageFormats,
-      clGetMemObjectInfo,
-      clGetImageInfo,
-      clCreateSampler,
-      clRetainSampler,
-      clReleaseSampler,
-      clGetSamplerInfo,
-      clCreateProgramWithSource,
-      clCreateProgramWithBinary,
-      clRetainProgram,
-      clReleaseProgram,
-      clBuildProgram,
-      clUnloadCompiler,
-      clGetProgramInfo,
-      clGetProgramBuildInfo,
-      clCreateKernel,
-      clCreateKernelsInProgram,
-      clRetainKernel,
-      clReleaseKernel,
-      clSetKernelArg,
-      clGetKernelInfo,
-      clGetKernelWorkGroupInfo,
-      clWaitForEvents,
-      clGetEventInfo,
-      clRetainEvent,
-      clReleaseEvent,
-      clGetEventProfilingInfo,
-      clFlush,
-      clFinish,
-      clEnqueueReadBuffer,
-      clEnqueueWriteBuffer,
-      clEnqueueCopyBuffer,
-      clEnqueueReadImage,
-      clEnqueueWriteImage,
-      clEnqueueCopyImage,
-      clEnqueueCopyImageToBuffer,
-      clEnqueueCopyBufferToImage,
-      clEnqueueMapBuffer,
-      clEnqueueMapImage,
-      clEnqueueUnmapMemObject,
-      clEnqueueNDRangeKernel,
-      clEnqueueTask,
-      clEnqueueNativeKernel,
-      clEnqueueMarker,
-      clEnqueueWaitForEvents,
-      clEnqueueBarrier,
-      GetExtensionFunctionAddress,
-      NULL, // clCreateFromGLBuffer
-      NULL, // clCreateFromGLTexture2D
-      NULL, // clCreateFromGLTexture3D
-      NULL, // clCreateFromGLRenderbuffer
-      NULL, // clGetGLObjectInfo
-      NULL, // clGetGLTextureInfo
-      NULL, // clEnqueueAcquireGLObjects
-      NULL, // clEnqueueReleaseGLObjects
-
-      // cl_khr_d3d10_sharing
-      NULL, // clGetGLContextInfoKHR
-      NULL, // clGetDeviceIDsFromD3D10KHR
-      NULL, // clCreateFromD3D10BufferKHR
-      NULL, // clCreateFromD3D10Texture2DKHR
-      NULL, // clCreateFromD3D10Texture3DKHR
-      NULL, // clEnqueueAcquireD3D10ObjectsKHR
-      NULL, // clEnqueueReleaseD3D10ObjectsKHR
-
-      // OpenCL 1.1
-      clSetEventCallback,
-      clCreateSubBuffer,
-      clSetMemObjectDestructorCallback,
-      clCreateUserEvent,
-      clSetUserEventStatus,
-      clEnqueueReadBufferRect,
-      clEnqueueWriteBufferRect,
-      clEnqueueCopyBufferRect,
-
-      // cl_ext_device_fission
-      NULL, // clCreateSubDevicesEXT
-      NULL, // clRetainDeviceEXT
-      NULL, // clReleaseDeviceEXT
-
-      // cl_khr_gl_event
-      NULL, // clCreateEventFromGLsyncKHR
-
-      // OpenCL 1.2
-      clCreateSubDevices,
-      clRetainDevice,
-      clReleaseDevice,
-      clCreateImage,
-      clCreateProgramWithBuiltInKernels,
-      clCompileProgram,
-      clLinkProgram,
-      clUnloadPlatformCompiler,
-      clGetKernelArgInfo,
-      clEnqueueFillBuffer,
-      clEnqueueFillImage,
-      clEnqueueMigrateMemObjects,
-      clEnqueueMarkerWithWaitList,
-      clEnqueueBarrierWithWaitList,
-      GetExtensionFunctionAddressForPlatform,
-      NULL, // clCreateFromGLTexture
-
-      // cl_khr_d3d11_sharing
-      NULL, // clGetDeviceIDsFromD3D11KHR
-      NULL, // clCreateFromD3D11BufferKHR
-      NULL, // clCreateFromD3D11Texture2DKHR
-      NULL, // clCreateFromD3D11Texture3DKHR
-      NULL, // clCreateFromDX9MediaSurfaceKHR
-      NULL, // clEnqueueAcquireD3D11ObjectsKHR
-      NULL, // clEnqueueReleaseD3D11ObjectsKHR
-
-      // cl_khr_dx9_media_sharing
-      NULL, // clGetDeviceIDsFromDX9MediaAdapterKHR
-      NULL, // clEnqueueAcquireDX9MediaSurfacesKHR
-      NULL, // clEnqueueReleaseDX9MediaSurfacesKHR
-
-      // cl_khr_egl_image
-      NULL, // clCreateFromEGLImageKHR
-      NULL, // clEnqueueAcquireEGLObjectsKHR
-      NULL, // clEnqueueReleaseEGLObjectsKHR
-
-      // cl_khr_egl_event
-      NULL, // clCreateEventFromEGLSyncKHR
-
-      // OpenCL 2.0
-      clCreateCommandQueueWithProperties,
-      clCreatePipe,
-      clGetPipeInfo,
-      clSVMAlloc,
-      clSVMFree,
-      clEnqueueSVMFree,
-      clEnqueueSVMMemcpy,
-      clEnqueueSVMMemFill,
-      clEnqueueSVMMap,
-      clEnqueueSVMUnmap,
-      NULL, // clCreateSamplerWithProperties
-      clSetKernelArgSVMPointer,
-      clSetKernelExecInfo,
-
-      // cl_khr_sub_groups
-      NULL, // clGetKernelSubGroupInfoKHR
-
-      // OpenCL 2.1
-      NULL, // clCloneKernel
-      clCreateProgramWithIL,
-      clEnqueueSVMMigrateMem,
-      clGetDeviceAndHostTimer,
-      clGetHostTimer,
-      clGetKernelSubGroupInfo,
-      clSetDefaultDeviceCommandQueue,
-
-      // OpenCL 2.2
-      clSetProgramReleaseCallback,
-      clSetProgramSpecializationConstant,
-      clCreateBufferWithProperties,
-      clCreateImageWithProperties,
-      clSetContextDestructorCallback
-   };
-}
diff --git a/src/gallium/frontends/clover/api/dispatch.hpp b/src/gallium/frontends/clover/api/dispatch.hpp
deleted file mode 100644
index f98f94d0c6d..00000000000
--- a/src/gallium/frontends/clover/api/dispatch.hpp
+++ /dev/null
@@ -1,109 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef API_DISPATCH_HPP
-#define API_DISPATCH_HPP
-
-#include "CL/cl.h"
-#include "CL/cl_ext.h"
-#include "CL/cl_egl.h"
-#include "CL/cl_gl.h"
-#include "CL/cl_icd.h"
-
-namespace clover {
-   extern const cl_icd_dispatch _dispatch;
-
-   cl_int CL_API_CALL
-   GetPlatformInfo(cl_platform_id d_platform, cl_platform_info param,
-                   size_t size, void *r_buf, size_t *r_size);
-
-   void * CL_API_CALL
-   GetExtensionFunctionAddress(const char *p_name);
-
-   void * CL_API_CALL
-   GetExtensionFunctionAddressForPlatform(cl_platform_id d_platform,
-                                          const char *p_name);
-
-   cl_int CL_API_CALL
-   IcdGetPlatformIDsKHR(cl_uint num_entries, cl_platform_id *rd_platforms,
-                        cl_uint *rnum_platforms);
-
-   cl_int CL_API_CALL
-   EnqueueSVMFree(cl_command_queue command_queue,
-                  cl_uint num_svm_pointers,
-                  void *svm_pointers[],
-                  void (CL_CALLBACK *pfn_free_func) (
-                     cl_command_queue queue, cl_uint num_svm_pointers,
-                     void *svm_pointers[], void *user_data),
-                  void *user_data,
-                  cl_uint num_events_in_wait_list,
-                  const cl_event *event_wait_list,
-                  cl_event *event,
-                  cl_int cmd);
-
-   cl_int CL_API_CALL
-   EnqueueSVMMemcpy(cl_command_queue command_queue,
-                    cl_bool blocking_copy,
-                    void *dst_ptr,
-                    const void *src_ptr,
-                    size_t size,
-                    cl_uint num_events_in_wait_list,
-                    const cl_event *event_wait_list,
-                    cl_event *event,
-                    cl_int cmd);
-
-   cl_int CL_API_CALL
-   EnqueueSVMMap(cl_command_queue command_queue,
-                 cl_bool blocking_map,
-                 cl_map_flags map_flags,
-                 void *svm_ptr,
-                 size_t size,
-                 cl_uint num_events_in_wait_list,
-                 const cl_event *event_wait_list,
-                 cl_event *event,
-                 cl_int cmd);
-
-   cl_int CL_API_CALL
-   EnqueueSVMMemFill(cl_command_queue command_queue,
-                     void *svm_ptr,
-                     const void *pattern,
-                     size_t pattern_size,
-                     size_t size,
-                     cl_uint num_events_in_wait_list,
-                     const cl_event *event_wait_list,
-                     cl_event *event,
-                     cl_int cmd);
-
-   cl_int CL_API_CALL
-   EnqueueSVMUnmap(cl_command_queue command_queue,
-                   void *svm_ptr,
-                   cl_uint num_events_in_wait_list,
-                   const cl_event *event_wait_list,
-                   cl_event *event,
-                   cl_int cmd);
-
-   cl_program CL_API_CALL
-   CreateProgramWithILKHR(cl_context d_ctx, const void *il,
-                          size_t length, cl_int *r_errcode);
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/api/event.cpp b/src/gallium/frontends/clover/api/event.cpp
deleted file mode 100644
index 7c3b0812f24..00000000000
--- a/src/gallium/frontends/clover/api/event.cpp
+++ /dev/null
@@ -1,310 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/util.hpp"
-#include "core/event.hpp"
-
-using namespace clover;
-
-CLOVER_API cl_event
-clCreateUserEvent(cl_context d_ctx, cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-
-   ret_error(r_errcode, CL_SUCCESS);
-   return desc(new soft_event(ctx, {}, false));
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_int
-clSetUserEventStatus(cl_event d_ev, cl_int status) try {
-   auto &sev = obj<soft_event>(d_ev);
-
-   if (status > 0)
-      return CL_INVALID_VALUE;
-
-   if (sev.status() <= 0)
-      return CL_INVALID_OPERATION;
-
-   if (status)
-      sev.abort(status);
-   else
-      sev.trigger();
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clWaitForEvents(cl_uint num_evs, const cl_event *d_evs) try {
-   auto evs = objs(d_evs, num_evs);
-
-   for (auto &ev : evs) {
-      if (ev.context() != evs.front().context())
-         throw error(CL_INVALID_CONTEXT);
-
-      if (ev.status() < 0)
-         throw error(CL_EXEC_STATUS_ERROR_FOR_EVENTS_IN_WAIT_LIST);
-   }
-
-   // Create a temporary soft event that depends on all the events in
-   // the wait list
-   auto sev = create<soft_event>(evs.front().context(), evs, true);
-
-   // ...and wait on it.
-   sev().wait();
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetEventInfo(cl_event d_ev, cl_event_info param,
-               size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &ev = obj(d_ev);
-
-   switch (param) {
-   case CL_EVENT_COMMAND_QUEUE:
-      buf.as_scalar<cl_command_queue>() = desc(ev.queue());
-      break;
-
-   case CL_EVENT_CONTEXT:
-      buf.as_scalar<cl_context>() = desc(ev.context());
-      break;
-
-   case CL_EVENT_COMMAND_TYPE:
-      buf.as_scalar<cl_command_type>() = ev.command();
-      break;
-
-   case CL_EVENT_COMMAND_EXECUTION_STATUS:
-      buf.as_scalar<cl_int>() = ev.status();
-      break;
-
-   case CL_EVENT_REFERENCE_COUNT:
-      buf.as_scalar<cl_uint>() = ev.ref_count();
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clSetEventCallback(cl_event d_ev, cl_int type,
-                   void (CL_CALLBACK *pfn_notify)(cl_event, cl_int, void *),
-                   void *user_data) try {
-   auto &ev = obj(d_ev);
-
-   if (!pfn_notify ||
-       (type != CL_COMPLETE && type != CL_SUBMITTED && type != CL_RUNNING))
-      throw error(CL_INVALID_VALUE);
-
-   // Create a temporary soft event that depends on ev, with
-   // pfn_notify as completion action.
-   create<soft_event>(ev.context(), ref_vector<event> { ev }, true,
-                      [=, &ev](event &) {
-                         ev.wait();
-                         pfn_notify(desc(ev), ev.status(), user_data);
-                      });
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clRetainEvent(cl_event d_ev) try {
-   obj(d_ev).retain();
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clReleaseEvent(cl_event d_ev) try {
-   if (obj(d_ev).release())
-      delete pobj(d_ev);
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueMarker(cl_command_queue d_q, cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-
-   if (!rd_ev)
-      throw error(CL_INVALID_VALUE);
-
-   *rd_ev = desc(new hard_event(q, CL_COMMAND_MARKER, {}));
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueMarkerWithWaitList(cl_command_queue d_q, cl_uint num_deps,
-                            const cl_event *d_deps, cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-
-   for (auto &ev : deps) {
-      if (ev.context() != q.context())
-         throw error(CL_INVALID_CONTEXT);
-   }
-
-   // Create a hard event that depends on the events in the wait list:
-   // previous commands in the same queue are implicitly serialized
-   // with respect to it -- hard events always are.
-   auto hev = create<hard_event>(q, CL_COMMAND_MARKER, deps);
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueBarrier(cl_command_queue d_q) try {
-   obj(d_q);
-
-   // No need to do anything, q preserves data ordering strictly.
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueBarrierWithWaitList(cl_command_queue d_q, cl_uint num_deps,
-                             const cl_event *d_deps, cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-
-   for (auto &ev : deps) {
-      if (ev.context() != q.context())
-         throw error(CL_INVALID_CONTEXT);
-   }
-
-   // Create a hard event that depends on the events in the wait list:
-   // subsequent commands in the same queue will be implicitly
-   // serialized with respect to it -- hard events always are.
-   auto hev = create<hard_event>(q, CL_COMMAND_BARRIER, deps);
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueWaitForEvents(cl_command_queue d_q, cl_uint num_evs,
-                       const cl_event *d_evs) try {
-   // The wait list is mandatory for clEnqueueWaitForEvents().
-   objs(d_evs, num_evs);
-
-   return clEnqueueBarrierWithWaitList(d_q, num_evs, d_evs, NULL);
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetEventProfilingInfo(cl_event d_ev, cl_profiling_info param,
-                        size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   hard_event &hev = dynamic_cast<hard_event &>(obj(d_ev));
-
-   if (hev.status() != CL_COMPLETE)
-      throw error(CL_PROFILING_INFO_NOT_AVAILABLE);
-
-   switch (param) {
-   case CL_PROFILING_COMMAND_QUEUED:
-      buf.as_scalar<cl_ulong>() = hev.time_queued();
-      break;
-
-   case CL_PROFILING_COMMAND_SUBMIT:
-      buf.as_scalar<cl_ulong>() = hev.time_submit();
-      break;
-
-   case CL_PROFILING_COMMAND_START:
-      buf.as_scalar<cl_ulong>() = hev.time_start();
-      break;
-
-   case CL_PROFILING_COMMAND_END:
-   case CL_PROFILING_COMMAND_COMPLETE:
-      buf.as_scalar<cl_ulong>() = hev.time_end();
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (std::bad_cast &) {
-   return CL_PROFILING_INFO_NOT_AVAILABLE;
-
-} catch (lazy<cl_ulong>::undefined_error &) {
-   return CL_PROFILING_INFO_NOT_AVAILABLE;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clFinish(cl_command_queue d_q) try {
-   auto &q = obj(d_q);
-
-   // Create a temporary hard event -- it implicitly depends on all
-   // the previously queued hard events.
-   auto hev = create<hard_event>(q, 0, ref_vector<event> {});
-
-   // And wait on it.
-   hev().wait();
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
diff --git a/src/gallium/frontends/clover/api/interop.cpp b/src/gallium/frontends/clover/api/interop.cpp
deleted file mode 100644
index b96069f5167..00000000000
--- a/src/gallium/frontends/clover/api/interop.cpp
+++ /dev/null
@@ -1,69 +0,0 @@
-//
-// Copyright 2015 Advanced Micro Devices, Inc.
-// All Rights Reserved.
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/event.hpp"
-#include "api/util.hpp"
-
-using namespace clover;
-
-extern "C" {
-
-PUBLIC bool
-opencl_dri_event_add_ref(cl_event event)
-{
-   /* This should fail if the event hasn't been created by
-    * clEnqueueReleaseGLObjects or clEnqueueReleaseEGLObjects.
-    *
-    * TODO: implement the CL functions
-    */
-   return false; /*return clRetainEvent(event) == CL_SUCCESS;*/
-}
-
-PUBLIC bool
-opencl_dri_event_release(cl_event event)
-{
-   return clReleaseEvent(event) == CL_SUCCESS;
-}
-
-PUBLIC bool
-opencl_dri_event_wait(cl_event event, uint64_t timeout) try {
-   if (!timeout) {
-      return obj(event).status() == CL_COMPLETE;
-   }
-
-   obj(event).wait();
-   return true;
-
-} catch (error &) {
-   return false;
-}
-
-PUBLIC struct pipe_fence_handle *
-opencl_dri_event_get_fence(cl_event event) try {
-   return obj(event).fence();
-
-} catch (error &) {
-   return NULL;
-}
-
-}
diff --git a/src/gallium/frontends/clover/api/invalid.cpp b/src/gallium/frontends/clover/api/invalid.cpp
deleted file mode 100644
index 6274e3a78ea..00000000000
--- a/src/gallium/frontends/clover/api/invalid.cpp
+++ /dev/null
@@ -1,100 +0,0 @@
-//
-// Copyright 2020 Red Hat
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/util.hpp"
-#include "core/context.hpp"
-#include "core/platform.hpp"
-
-using namespace clover;
-
-// This contains all the CL 2.x API entrypoints that return INVALID_OPERATON
-// on CL 3.0. If these are implemented they should be moved out of this file.
-
-CLOVER_API cl_mem
-clCreatePipe(cl_context d_ctx,
-	     cl_mem_flags flags,
-	     cl_uint pipe_packet_size,
-	     cl_uint pipe_max_packets,
-	     const cl_pipe_properties *properties,
-	     cl_int *r_errorcode) {
-   *r_errorcode = CL_INVALID_OPERATION;
-   return nullptr;
-}
-
-
-CLOVER_API cl_int
-clGetPipeInfo(cl_mem pipe,
-	      cl_pipe_info param_name,
-	      size_t param_value_size,
-	      void *param_value,
-	      size_t *param_value_size_ret) {
-   return CL_INVALID_MEM_OBJECT;
-}
-
-CLOVER_API cl_int
-clGetDeviceAndHostTimer(cl_device_id device,
-			cl_ulong *device_timestamp,
-			cl_ulong *host_timestamp) {
-   return CL_INVALID_OPERATION;
-}
-
-CLOVER_API cl_int
-clGetHostTimer(cl_device_id device,
-	       cl_ulong *host_timestamp) {
-   return CL_INVALID_OPERATION;
-}
-
-
-CLOVER_API cl_int
-clGetKernelSubGroupInfo(cl_kernel d_kern,
-			cl_device_id device,
-			cl_kernel_sub_group_info param_name,
-			size_t input_value_size,
-			const void *input_value,
-			size_t param_size_value,
-			void *param_value,
-			size_t *param_value_size_ret) {
-   return CL_INVALID_OPERATION;
-}
-
-
-CLOVER_API cl_int
-clSetDefaultDeviceCommandQueue(cl_context context,
-			       cl_device_id device,
-			       cl_command_queue command_queue) {
-   return CL_INVALID_OPERATION;
-}
-
-CLOVER_API cl_int
-clSetProgramReleaseCallback(cl_program d_prog,
-			    void (CL_CALLBACK *pfn_notify)(cl_program program, void *user_data),
-			    void *user_data) {
-   return CL_INVALID_OPERATION;
-}
-
-CLOVER_API cl_int
-clSetProgramSpecializationConstant(cl_program program,
-				   cl_uint spec_id,
-				   size_t spec_size,
-				   const void* spec_value) {
-   return CL_INVALID_OPERATION;
-}
diff --git a/src/gallium/frontends/clover/api/kernel.cpp b/src/gallium/frontends/clover/api/kernel.cpp
deleted file mode 100644
index 2e1786375bc..00000000000
--- a/src/gallium/frontends/clover/api/kernel.cpp
+++ /dev/null
@@ -1,436 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/util.hpp"
-#include "core/kernel.hpp"
-#include "core/event.hpp"
-
-using namespace clover;
-
-CLOVER_API cl_kernel
-clCreateKernel(cl_program d_prog, const char *name, cl_int *r_errcode) try {
-   auto &prog = obj(d_prog);
-
-   if (!name)
-      throw error(CL_INVALID_VALUE);
-
-   auto &sym = find(name_equals(name), prog.symbols());
-
-   ret_error(r_errcode, CL_SUCCESS);
-   return new kernel(prog, name, range(sym.args));
-
-} catch (std::out_of_range &) {
-   ret_error(r_errcode, CL_INVALID_KERNEL_NAME);
-   return NULL;
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_int
-clCreateKernelsInProgram(cl_program d_prog, cl_uint count,
-                         cl_kernel *rd_kerns, cl_uint *r_count) try {
-   auto &prog = obj(d_prog);
-   auto &syms = prog.symbols();
-
-   if (rd_kerns && count < syms.size())
-      throw error(CL_INVALID_VALUE);
-
-   if (rd_kerns)
-      copy(map([&](const binary::symbol &sym) {
-               return desc(new kernel(prog,
-                                      std::string(sym.name.begin(),
-                                                  sym.name.end()),
-                                      range(sym.args)));
-            }, syms),
-         rd_kerns);
-
-   if (r_count)
-      *r_count = syms.size();
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clRetainKernel(cl_kernel d_kern) try {
-   obj(d_kern).retain();
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clReleaseKernel(cl_kernel d_kern) try {
-   if (obj(d_kern).release())
-      delete pobj(d_kern);
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clSetKernelArg(cl_kernel d_kern, cl_uint idx, size_t size,
-               const void *value) try {
-   obj(d_kern).args().at(idx).set(size, value);
-   return CL_SUCCESS;
-
-} catch (std::out_of_range &) {
-   return CL_INVALID_ARG_INDEX;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetKernelInfo(cl_kernel d_kern, cl_kernel_info param,
-                size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &kern = obj(d_kern);
-
-   switch (param) {
-   case CL_KERNEL_FUNCTION_NAME:
-      buf.as_string() = kern.name();
-      break;
-
-   case CL_KERNEL_NUM_ARGS:
-      buf.as_scalar<cl_uint>() = kern.args().size();
-      break;
-
-   case CL_KERNEL_REFERENCE_COUNT:
-      buf.as_scalar<cl_uint>() = kern.ref_count();
-      break;
-
-   case CL_KERNEL_CONTEXT:
-      buf.as_scalar<cl_context>() = desc(kern.program().context());
-      break;
-
-   case CL_KERNEL_PROGRAM:
-      buf.as_scalar<cl_program>() = desc(kern.program());
-      break;
-
-   case CL_KERNEL_ATTRIBUTES:
-      buf.as_string() = find(name_equals(kern.name()), kern.program().symbols()).attributes;
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetKernelWorkGroupInfo(cl_kernel d_kern, cl_device_id d_dev,
-                         cl_kernel_work_group_info param,
-                         size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &kern = obj(d_kern);
-   auto &dev = (d_dev ? *pobj(d_dev) : unique(kern.program().devices()));
-
-   if (!count(dev, kern.program().devices()))
-      throw error(CL_INVALID_DEVICE);
-
-   switch (param) {
-   case CL_KERNEL_WORK_GROUP_SIZE:
-      buf.as_scalar<size_t>() = dev.max_threads_per_block();
-      break;
-
-   case CL_KERNEL_COMPILE_WORK_GROUP_SIZE:
-      buf.as_vector<size_t>() = kern.required_block_size();
-      break;
-
-   case CL_KERNEL_LOCAL_MEM_SIZE:
-      buf.as_scalar<cl_ulong>() = kern.mem_local();
-      break;
-
-   case CL_KERNEL_PREFERRED_WORK_GROUP_SIZE_MULTIPLE:
-      buf.as_scalar<size_t>() = dev.subgroup_size();
-      break;
-
-   case CL_KERNEL_PRIVATE_MEM_SIZE:
-      buf.as_scalar<cl_ulong>() = kern.mem_private();
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-
-} catch (std::out_of_range &) {
-   return CL_INVALID_DEVICE;
-}
-
-CLOVER_API cl_int
-clGetKernelArgInfo(cl_kernel d_kern,
-                   cl_uint idx, cl_kernel_arg_info param,
-                   size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-
-   auto info = obj(d_kern).args_infos().at(idx);
-
-   if (info.arg_name.empty())
-      return CL_KERNEL_ARG_INFO_NOT_AVAILABLE;
-
-   switch (param) {
-   case CL_KERNEL_ARG_ADDRESS_QUALIFIER:
-      buf.as_scalar<cl_kernel_arg_address_qualifier>() = info.address_qualifier;
-      break;
-
-   case CL_KERNEL_ARG_ACCESS_QUALIFIER:
-      buf.as_scalar<cl_kernel_arg_access_qualifier>() = info.access_qualifier;
-      break;
-
-   case CL_KERNEL_ARG_TYPE_NAME:
-      buf.as_string() = info.type_name;
-      break;
-
-   case CL_KERNEL_ARG_TYPE_QUALIFIER:
-      buf.as_scalar<cl_kernel_arg_type_qualifier>() = info.type_qualifier;
-      break;
-
-   case CL_KERNEL_ARG_NAME:
-      buf.as_string() = info.arg_name;
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (std::out_of_range &) {
-   return CL_INVALID_ARG_INDEX;
-
-} catch (error &e) {
-   return e.get();
-}
-
-namespace {
-   ///
-   /// Common argument checking shared by kernel invocation commands.
-   ///
-   void
-   validate_common(const command_queue &q, kernel &kern,
-                   const ref_vector<event> &deps) {
-      if (kern.program().context() != q.context() ||
-          any_of([&](const event &ev) {
-                return ev.context() != q.context();
-             }, deps))
-         throw error(CL_INVALID_CONTEXT);
-
-      if (any_of([](kernel::argument &arg) {
-               return !arg.set();
-            }, kern.args()))
-         throw error(CL_INVALID_KERNEL_ARGS);
-
-      // If the command queue's device is not associated to the program, we get
-      // a binary, with no sections, which will also fail the following test.
-      auto &b = kern.program().build(q.device()).bin;
-      if (!any_of(type_equals(binary::section::text_executable), b.secs))
-         throw error(CL_INVALID_PROGRAM_EXECUTABLE);
-   }
-
-   std::vector<size_t>
-   validate_grid_size(const command_queue &q, cl_uint dims,
-                      const size_t *d_grid_size) {
-      auto grid_size = range(d_grid_size, dims);
-
-      if (dims < 1 || dims > q.device().max_block_size().size())
-         throw error(CL_INVALID_WORK_DIMENSION);
-
-      return grid_size;
-   }
-
-   std::vector<size_t>
-   validate_grid_offset(const command_queue &q, cl_uint dims,
-                        const size_t *d_grid_offset) {
-      if (d_grid_offset)
-         return range(d_grid_offset, dims);
-      else
-         return std::vector<size_t>(dims, 0);
-   }
-
-   std::vector<size_t>
-   validate_block_size(const command_queue &q, const kernel &kern,
-                       cl_uint dims, const size_t *d_grid_size,
-                       const size_t *d_block_size) {
-      auto grid_size = range(d_grid_size, dims);
-
-      if (d_block_size) {
-         auto block_size = range(d_block_size, dims);
-
-         if (any_of(is_zero(), block_size) ||
-             any_of(greater(), block_size, q.device().max_block_size()))
-            throw error(CL_INVALID_WORK_ITEM_SIZE);
-
-         if (any_of(modulus(), grid_size, block_size))
-            throw error(CL_INVALID_WORK_GROUP_SIZE);
-
-         if (fold(multiplies(), 1u, block_size) >
-             q.device().max_threads_per_block())
-            throw error(CL_INVALID_WORK_GROUP_SIZE);
-
-         return block_size;
-
-      } else {
-         return kern.optimal_block_size(q, grid_size);
-      }
-   }
-}
-
-CLOVER_API cl_int
-clEnqueueNDRangeKernel(cl_command_queue d_q, cl_kernel d_kern,
-                       cl_uint dims, const size_t *d_grid_offset,
-                       const size_t *d_grid_size, const size_t *d_block_size,
-                       cl_uint num_deps, const cl_event *d_deps,
-                       cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &kern = obj(d_kern);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto grid_size = validate_grid_size(q, dims, d_grid_size);
-   auto grid_offset = validate_grid_offset(q, dims, d_grid_offset);
-   auto block_size = validate_block_size(q, kern, dims,
-                                         d_grid_size, d_block_size);
-
-   validate_common(q, kern, deps);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_NDRANGE_KERNEL, deps,
-      [=, &kern, &q](event &) {
-         kern.launch(q, grid_offset, grid_size, block_size);
-      });
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueTask(cl_command_queue d_q, cl_kernel d_kern,
-              cl_uint num_deps, const cl_event *d_deps,
-              cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &kern = obj(d_kern);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-
-   validate_common(q, kern, deps);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_TASK, deps,
-      [=, &kern, &q](event &) {
-         kern.launch(q, { 0 }, { 1 }, { 1 });
-      });
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueNativeKernel(cl_command_queue d_q,
-                      void (CL_CALLBACK * func)(void *),
-                      void *args, size_t args_size,
-                      cl_uint num_mems, const cl_mem *d_mems,
-                      const void **mem_handles, cl_uint num_deps,
-                      const cl_event *d_deps, cl_event *rd_ev) {
-   return CL_INVALID_OPERATION;
-}
-
-CLOVER_API cl_int
-clSetKernelArgSVMPointer(cl_kernel d_kern,
-                         cl_uint arg_index,
-                         const void *arg_value) try {
-  if (!any_of(std::mem_fn(&device::svm_support), obj(d_kern).program().devices()))
-      return CL_INVALID_OPERATION;
-   obj(d_kern).args().at(arg_index).set_svm(arg_value);
-   return CL_SUCCESS;
-
-} catch (std::out_of_range &) {
-   return CL_INVALID_ARG_INDEX;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clSetKernelExecInfo(cl_kernel d_kern,
-                    cl_kernel_exec_info param_name,
-                    size_t param_value_size,
-                    const void *param_value) try {
-
-   if (!any_of(std::mem_fn(&device::svm_support), obj(d_kern).program().devices()))
-      return CL_INVALID_OPERATION;
-
-   auto &kern = obj(d_kern);
-
-   const bool has_system_svm = all_of(std::mem_fn(&device::has_system_svm),
-                                      kern.program().context().devices());
-
-   if (!param_value)
-      return CL_INVALID_VALUE;
-
-   switch (param_name) {
-   case CL_KERNEL_EXEC_INFO_SVM_FINE_GRAIN_SYSTEM:
-   case CL_KERNEL_EXEC_INFO_SVM_FINE_GRAIN_SYSTEM_ARM: {
-      if (param_value_size != sizeof(cl_bool))
-         return CL_INVALID_VALUE;
-
-      cl_bool val = *static_cast<const cl_bool*>(param_value);
-      if (val == CL_TRUE && !has_system_svm)
-         return CL_INVALID_OPERATION;
-      else
-         return CL_SUCCESS;
-   }
-
-   case CL_KERNEL_EXEC_INFO_SVM_PTRS:
-   case CL_KERNEL_EXEC_INFO_SVM_PTRS_ARM:
-      if (has_system_svm)
-         return CL_SUCCESS;
-
-      CLOVER_NOT_SUPPORTED_UNTIL("2.0");
-      return CL_INVALID_VALUE;
-
-   default:
-      return CL_INVALID_VALUE;
-   }
-
-} catch (error &e) {
-   return e.get();
-}
diff --git a/src/gallium/frontends/clover/api/memory.cpp b/src/gallium/frontends/clover/api/memory.cpp
deleted file mode 100644
index ea553efe1f4..00000000000
--- a/src/gallium/frontends/clover/api/memory.cpp
+++ /dev/null
@@ -1,648 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "util/format/u_format.h"
-#include "util/u_math.h"
-#include "api/util.hpp"
-#include "core/memory.hpp"
-#include "core/format.hpp"
-
-using namespace clover;
-
-namespace {
-   cl_mem_flags
-   validate_flags(cl_mem d_parent, cl_mem_flags d_flags, bool svm) {
-      const cl_mem_flags dev_access_flags =
-         CL_MEM_READ_WRITE | CL_MEM_WRITE_ONLY | CL_MEM_READ_ONLY;
-      const cl_mem_flags host_ptr_flags =
-         CL_MEM_USE_HOST_PTR | CL_MEM_ALLOC_HOST_PTR | CL_MEM_COPY_HOST_PTR;
-      const cl_mem_flags host_access_flags =
-         CL_MEM_HOST_WRITE_ONLY | CL_MEM_HOST_READ_ONLY | CL_MEM_HOST_NO_ACCESS;
-      const cl_mem_flags svm_flags =
-         CL_MEM_SVM_FINE_GRAIN_BUFFER | CL_MEM_SVM_ATOMICS;
-
-      const cl_mem_flags valid_flags =
-         dev_access_flags
-            | (svm || d_parent ? 0 : host_ptr_flags)
-            | (svm ? svm_flags : host_access_flags);
-
-      if ((d_flags & ~valid_flags) ||
-          util_bitcount(d_flags & dev_access_flags) > 1 ||
-          util_bitcount(d_flags & host_access_flags) > 1)
-         throw error(CL_INVALID_VALUE);
-
-      if ((d_flags & CL_MEM_USE_HOST_PTR) &&
-          (d_flags & (CL_MEM_COPY_HOST_PTR | CL_MEM_ALLOC_HOST_PTR)))
-         throw error(CL_INVALID_VALUE);
-
-      if ((d_flags & CL_MEM_SVM_ATOMICS) &&
-          !(d_flags & CL_MEM_SVM_FINE_GRAIN_BUFFER))
-         throw error(CL_INVALID_VALUE);
-
-      if (d_parent) {
-         const auto &parent = obj(d_parent);
-         const cl_mem_flags flags = (d_flags |
-                                     (d_flags & dev_access_flags ? 0 :
-                                      parent.flags() & dev_access_flags) |
-                                     (d_flags & host_access_flags ? 0 :
-                                      parent.flags() & host_access_flags) |
-                                     (parent.flags() & host_ptr_flags));
-
-         if (~flags & parent.flags() & (dev_access_flags & ~CL_MEM_READ_WRITE))
-            throw error(CL_INVALID_VALUE);
-
-         // Check if new host access flags cause a mismatch between
-         // host-read/write-only.
-         if (!(flags & CL_MEM_HOST_NO_ACCESS) &&
-             (~flags & parent.flags() & host_access_flags))
-            throw error(CL_INVALID_VALUE);
-
-         return flags;
-
-      } else {
-         return d_flags | (d_flags & dev_access_flags ? 0 : CL_MEM_READ_WRITE);
-      }
-   }
-
-   std::vector<cl_mem_properties>
-   fill_properties(const cl_mem_properties *d_properties) {
-      std::vector<cl_mem_properties> properties;
-      if (d_properties) {
-         while (*d_properties) {
-            if (*d_properties != 0)
-               throw error(CL_INVALID_PROPERTY);
-
-            properties.push_back(*d_properties);
-            d_properties++;
-         };
-         properties.push_back(0);
-      }
-      return properties;
-   }
-}
-
-CLOVER_API cl_mem
-clCreateBufferWithProperties(cl_context d_ctx,
-                             const cl_mem_properties *d_properties,
-                             cl_mem_flags d_flags, size_t size,
-                             void *host_ptr, cl_int *r_errcode) try {
-
-   auto &ctx = obj(d_ctx);
-   const cl_mem_flags flags = validate_flags(NULL, d_flags, false);
-   std::vector<cl_mem_properties> properties = fill_properties(d_properties);
-
-   if (bool(host_ptr) != bool(flags & (CL_MEM_USE_HOST_PTR |
-                                       CL_MEM_COPY_HOST_PTR)))
-      throw error(CL_INVALID_HOST_PTR);
-
-   if (!size ||
-       size > fold(maximum(), cl_ulong(0),
-                   map(std::mem_fn(&device::max_mem_alloc_size), ctx.devices())
-          ))
-      throw error(CL_INVALID_BUFFER_SIZE);
-
-   ret_error(r_errcode, CL_SUCCESS);
-   return new root_buffer(ctx, properties, flags, size, host_ptr);
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-
-CLOVER_API cl_mem
-clCreateBuffer(cl_context d_ctx, cl_mem_flags d_flags, size_t size,
-               void *host_ptr, cl_int *r_errcode) {
-   return clCreateBufferWithProperties(d_ctx, NULL, d_flags, size,
-                                       host_ptr, r_errcode);
-}
-
-CLOVER_API cl_mem
-clCreateSubBuffer(cl_mem d_mem, cl_mem_flags d_flags,
-                  cl_buffer_create_type op,
-                  const void *op_info, cl_int *r_errcode) try {
-   auto &parent = obj<root_buffer>(d_mem);
-   const cl_mem_flags flags = validate_flags(d_mem, d_flags, false);
-
-   if (op == CL_BUFFER_CREATE_TYPE_REGION) {
-      auto reg = reinterpret_cast<const cl_buffer_region *>(op_info);
-
-      if (!reg ||
-          reg->origin > parent.size() ||
-          reg->origin + reg->size > parent.size())
-         throw error(CL_INVALID_VALUE);
-
-      if (!reg->size)
-         throw error(CL_INVALID_BUFFER_SIZE);
-
-      ret_error(r_errcode, CL_SUCCESS);
-      return new sub_buffer(parent, flags, reg->origin, reg->size);
-
-   } else {
-      throw error(CL_INVALID_VALUE);
-   }
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_mem
-clCreateImageWithProperties(cl_context d_ctx,
-                            const cl_mem_properties *d_properties,
-                            cl_mem_flags d_flags,
-                            const cl_image_format *format,
-                            const cl_image_desc *desc,
-                            void *host_ptr, cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-
-   if (!any_of(std::mem_fn(&device::image_support), ctx.devices()))
-      throw error(CL_INVALID_OPERATION);
-
-   if (!format)
-      throw error(CL_INVALID_IMAGE_FORMAT_DESCRIPTOR);
-
-   if (!desc)
-      throw error(CL_INVALID_IMAGE_DESCRIPTOR);
-
-   if (desc->image_array_size == 0 &&
-       (desc->image_type == CL_MEM_OBJECT_IMAGE1D_ARRAY ||
-        desc->image_type == CL_MEM_OBJECT_IMAGE2D_ARRAY))
-      throw error(CL_INVALID_IMAGE_DESCRIPTOR);
-
-   if (!host_ptr &&
-       (desc->image_row_pitch || desc->image_slice_pitch))
-      throw error(CL_INVALID_IMAGE_DESCRIPTOR);
-
-   if (desc->num_mip_levels || desc->num_samples)
-      throw error(CL_INVALID_IMAGE_DESCRIPTOR);
-
-   if (bool(desc->buffer) != (desc->image_type == CL_MEM_OBJECT_IMAGE1D_BUFFER))
-      throw error(CL_INVALID_IMAGE_DESCRIPTOR);
-
-   if (bool(host_ptr) != bool(d_flags & (CL_MEM_USE_HOST_PTR |
-                                         CL_MEM_COPY_HOST_PTR)))
-      throw error(CL_INVALID_HOST_PTR);
-
-   const cl_mem_flags flags = validate_flags(desc->buffer, d_flags, false);
-
-   if (!supported_formats(ctx, desc->image_type, d_flags).count(*format))
-      throw error(CL_IMAGE_FORMAT_NOT_SUPPORTED);
-
-   std::vector<cl_mem_properties> properties = fill_properties(d_properties);
-   ret_error(r_errcode, CL_SUCCESS);
-
-   const size_t row_pitch = desc->image_row_pitch ? desc->image_row_pitch :
-      util_format_get_blocksize(translate_format(*format)) * desc->image_width;
-
-   switch (desc->image_type) {
-   case CL_MEM_OBJECT_IMAGE1D:
-      if (!desc->image_width)
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      if (all_of([=](const device &dev) {
-               const size_t max = dev.max_image_size();
-               return (desc->image_width > max);
-            }, ctx.devices()))
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      return new image1d(ctx, properties, flags, format,
-                         desc->image_width,
-                         row_pitch, host_ptr);
-
-   case CL_MEM_OBJECT_IMAGE1D_BUFFER:
-      if (!desc->image_width)
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      if (all_of([=](const device &dev) {
-               const size_t max = dev.max_image_buffer_size();
-               return (desc->image_width > max);
-            }, ctx.devices()))
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      return new image1d_buffer(ctx, properties, flags, format,
-                                desc->image_width,
-                                row_pitch, host_ptr, desc->buffer);
-
-   case CL_MEM_OBJECT_IMAGE1D_ARRAY: {
-      if (!desc->image_width)
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      if (all_of([=](const device &dev) {
-               const size_t max = dev.max_image_size();
-               const size_t amax = dev.max_image_array_number();
-               return (desc->image_width > max ||
-                       desc->image_array_size > amax);
-            }, ctx.devices()))
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      const size_t slice_pitch = desc->image_slice_pitch ?
-         desc->image_slice_pitch : row_pitch;
-
-      return new image1d_array(ctx, properties, flags, format,
-                               desc->image_width,
-                               desc->image_array_size, slice_pitch,
-                               host_ptr);
-   }
-
-   case CL_MEM_OBJECT_IMAGE2D:
-      if (!desc->image_width || !desc->image_height)
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      if (all_of([=](const device &dev) {
-               const size_t max = dev.max_image_size();
-               return (desc->image_width > max ||
-                       desc->image_height > max);
-            }, ctx.devices()))
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      return new image2d(ctx, properties, flags, format,
-                         desc->image_width, desc->image_height,
-                         row_pitch, host_ptr);
-
-   case CL_MEM_OBJECT_IMAGE2D_ARRAY: {
-      if (!desc->image_width || !desc->image_height || !desc->image_array_size)
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      if (all_of([=](const device &dev) {
-               const size_t max = dev.max_image_size();
-               const size_t amax = dev.max_image_array_number();
-               return (desc->image_width > max ||
-                       desc->image_height > max ||
-                       desc->image_array_size > amax);
-            }, ctx.devices()))
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      const size_t slice_pitch = desc->image_slice_pitch ?
-         desc->image_slice_pitch : row_pitch * desc->image_height;
-
-      return new image2d_array(ctx, properties, flags, format,
-                               desc->image_width, desc->image_height,
-                               desc->image_array_size, row_pitch,
-                               slice_pitch, host_ptr);
-   }
-
-   case CL_MEM_OBJECT_IMAGE3D: {
-      if (!desc->image_width || !desc->image_height || !desc->image_depth)
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      if (all_of([=](const device &dev) {
-               const size_t max = dev.max_image_size_3d();
-               return (desc->image_width > max ||
-                       desc->image_height > max ||
-                       desc->image_depth > max);
-            }, ctx.devices()))
-         throw error(CL_INVALID_IMAGE_SIZE);
-
-      const size_t slice_pitch = desc->image_slice_pitch ?
-         desc->image_slice_pitch : row_pitch * desc->image_height;
-
-      return new image3d(ctx, properties, flags, format,
-                         desc->image_width, desc->image_height,
-                         desc->image_depth, row_pitch,
-                         slice_pitch, host_ptr);
-   }
-
-   default:
-      throw error(CL_INVALID_IMAGE_DESCRIPTOR);
-   }
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_mem
-clCreateImage(cl_context d_ctx,
-              cl_mem_flags d_flags,
-              const cl_image_format *format,
-              const cl_image_desc *desc,
-              void *host_ptr, cl_int *r_errcode) {
-   return clCreateImageWithProperties(d_ctx, NULL, d_flags, format, desc, host_ptr, r_errcode);
-}
-
-
-CLOVER_API cl_mem
-clCreateImage2D(cl_context d_ctx, cl_mem_flags d_flags,
-                const cl_image_format *format,
-                size_t width, size_t height, size_t row_pitch,
-                void *host_ptr, cl_int *r_errcode) {
-   const cl_image_desc desc = { CL_MEM_OBJECT_IMAGE2D, width, height, 0, 0,
-                                row_pitch, 0, 0, 0, { NULL } };
-
-   return clCreateImageWithProperties(d_ctx, NULL, d_flags, format, &desc, host_ptr, r_errcode);
-}
-
-CLOVER_API cl_mem
-clCreateImage3D(cl_context d_ctx, cl_mem_flags d_flags,
-                const cl_image_format *format,
-                size_t width, size_t height, size_t depth,
-                size_t row_pitch, size_t slice_pitch,
-                void *host_ptr, cl_int *r_errcode) {
-   const cl_image_desc desc = { CL_MEM_OBJECT_IMAGE3D, width, height, depth, 0,
-                                row_pitch, slice_pitch, 0, 0, { NULL } };
-
-   return clCreateImageWithProperties(d_ctx, NULL, d_flags, format, &desc, host_ptr, r_errcode);
-}
-
-CLOVER_API cl_int
-clGetSupportedImageFormats(cl_context d_ctx, cl_mem_flags flags,
-                           cl_mem_object_type type, cl_uint count,
-                           cl_image_format *r_buf, cl_uint *r_count) try {
-   auto &ctx = obj(d_ctx);
-   auto formats = supported_formats(ctx, type, flags);
-
-   if (flags & CL_MEM_KERNEL_READ_AND_WRITE) {
-      if (r_count)
-         *r_count = 0;
-      return CL_SUCCESS;
-   }
-
-   if (flags & (CL_MEM_WRITE_ONLY | CL_MEM_READ_WRITE) &&
-       type == CL_MEM_OBJECT_IMAGE3D) {
-      if (r_count)
-         *r_count = 0;
-      return CL_SUCCESS;
-   }
-
-   validate_flags(NULL, flags, false);
-
-   if (r_buf && !count)
-      throw error(CL_INVALID_VALUE);
-
-   if (r_buf)
-      std::copy_n(formats.begin(),
-                  std::min((cl_uint)formats.size(), count),
-                  r_buf);
-
-   if (r_count)
-      *r_count = formats.size();
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetMemObjectInfo(cl_mem d_mem, cl_mem_info param,
-                   size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &mem = obj(d_mem);
-
-   switch (param) {
-   case CL_MEM_TYPE:
-      buf.as_scalar<cl_mem_object_type>() = mem.type();
-      break;
-
-   case CL_MEM_FLAGS:
-      buf.as_scalar<cl_mem_flags>() = mem.flags();
-      break;
-
-   case CL_MEM_SIZE:
-      buf.as_scalar<size_t>() = mem.size();
-      break;
-
-   case CL_MEM_HOST_PTR:
-      buf.as_scalar<void *>() = mem.host_ptr();
-      break;
-
-   case CL_MEM_MAP_COUNT:
-      buf.as_scalar<cl_uint>() = 0;
-      break;
-
-   case CL_MEM_REFERENCE_COUNT:
-      buf.as_scalar<cl_uint>() = mem.ref_count();
-      break;
-
-   case CL_MEM_CONTEXT:
-      buf.as_scalar<cl_context>() = desc(mem.context());
-      break;
-
-   case CL_MEM_ASSOCIATED_MEMOBJECT: {
-      sub_buffer *sub = dynamic_cast<sub_buffer *>(&mem);
-      if (sub) {
-         buf.as_scalar<cl_mem>() = desc(sub->parent());
-         break;
-      }
-
-      image *img = dynamic_cast<image *>(&mem);
-      if (img) {
-         buf.as_scalar<cl_mem>() = desc(img->buffer());
-         break;
-      }
-
-      buf.as_scalar<cl_mem>() = NULL;
-      break;
-   }
-   case CL_MEM_OFFSET: {
-      sub_buffer *sub = dynamic_cast<sub_buffer *>(&mem);
-      buf.as_scalar<size_t>() = (sub ? sub->offset() : 0);
-      break;
-   }
-   case CL_MEM_USES_SVM_POINTER:
-   case CL_MEM_USES_SVM_POINTER_ARM: {
-      // with system SVM all host ptrs are SVM pointers
-      // TODO: once we support devices with lower levels of SVM, we have to
-      // check the ptr in more detail
-      const bool system_svm = all_of(std::mem_fn(&device::has_system_svm),
-                                     mem.context().devices());
-      buf.as_scalar<cl_bool>() = mem.host_ptr() && system_svm;
-      break;
-   }
-   case CL_MEM_PROPERTIES:
-      buf.as_vector<cl_mem_properties>() = mem.properties();
-      break;
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetImageInfo(cl_mem d_mem, cl_image_info param,
-               size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &img = obj<image>(d_mem);
-
-   switch (param) {
-   case CL_IMAGE_FORMAT:
-      buf.as_scalar<cl_image_format>() = img.format();
-      break;
-
-   case CL_IMAGE_ELEMENT_SIZE:
-      buf.as_scalar<size_t>() = img.pixel_size();
-      break;
-
-   case CL_IMAGE_ROW_PITCH:
-      buf.as_scalar<size_t>() = img.row_pitch();
-      break;
-
-   case CL_IMAGE_SLICE_PITCH:
-      buf.as_scalar<size_t>() = img.slice_pitch();
-      break;
-
-   case CL_IMAGE_WIDTH:
-      buf.as_scalar<size_t>() = img.width();
-      break;
-
-   case CL_IMAGE_HEIGHT:
-      buf.as_scalar<size_t>() = img.dimensions() > 1 ? img.height() : 0;
-      break;
-
-   case CL_IMAGE_DEPTH:
-      buf.as_scalar<size_t>() = img.dimensions() > 2 ? img.depth() : 0;
-      break;
-
-   case CL_IMAGE_ARRAY_SIZE:
-      buf.as_scalar<size_t>() = img.array_size();
-      break;
-
-   case CL_IMAGE_BUFFER:
-      buf.as_scalar<cl_mem>() = img.buffer();
-      break;
-
-   case CL_IMAGE_NUM_MIP_LEVELS:
-      buf.as_scalar<cl_uint>() = 0;
-      break;
-
-   case CL_IMAGE_NUM_SAMPLES:
-      buf.as_scalar<cl_uint>() = 0;
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clRetainMemObject(cl_mem d_mem) try {
-   obj(d_mem).retain();
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clReleaseMemObject(cl_mem d_mem) try {
-   if (obj(d_mem).release())
-      delete pobj(d_mem);
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clSetMemObjectDestructorCallback(cl_mem d_mem,
-                                 void (CL_CALLBACK *pfn_notify)(cl_mem, void *),
-                                 void *user_data) try {
-   auto &mem = obj(d_mem);
-
-   if (!pfn_notify)
-      return CL_INVALID_VALUE;
-
-   mem.destroy_notify([=]{ pfn_notify(d_mem, user_data); });
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API void *
-clSVMAlloc(cl_context d_ctx,
-           cl_svm_mem_flags flags,
-           size_t size,
-           unsigned int alignment) try {
-   auto &ctx = obj(d_ctx);
-
-   if (!any_of(std::mem_fn(&device::svm_support), ctx.devices()))
-      return NULL;
-
-   validate_flags(NULL, flags, true);
-
-   if (!size ||
-       size > fold(minimum(), cl_ulong(ULONG_MAX),
-                   map(std::mem_fn(&device::max_mem_alloc_size), ctx.devices())))
-      return nullptr;
-
-   if (!util_is_power_of_two_or_zero(alignment))
-      return nullptr;
-
-   if (!alignment)
-      alignment = 0x80; // sizeof(long16)
-
-#if defined(HAVE_POSIX_MEMALIGN)
-   bool can_emulate = all_of(std::mem_fn(&device::has_system_svm), ctx.devices());
-   if (can_emulate) {
-      // we can ignore all the flags as it's not required to honor them.
-      void *ptr = nullptr;
-      if (alignment < sizeof(void*))
-         alignment = sizeof(void*);
-      int ret = posix_memalign(&ptr, alignment, size);
-      if (ret)
-         return nullptr;
-
-      if (ptr)
-         ctx.add_svm_allocation(ptr, size);
-
-      return ptr;
-   }
-#endif
-
-   CLOVER_NOT_SUPPORTED_UNTIL("2.0");
-   return nullptr;
-
-} catch (error &) {
-   return nullptr;
-}
-
-CLOVER_API void
-clSVMFree(cl_context d_ctx,
-          void *svm_pointer) try {
-   auto &ctx = obj(d_ctx);
-
-   if (!any_of(std::mem_fn(&device::svm_support), ctx.devices()))
-      return;
-
-   bool can_emulate = all_of(std::mem_fn(&device::has_system_svm), ctx.devices());
-
-   if (can_emulate) {
-      ctx.remove_svm_allocation(svm_pointer);
-      return free(svm_pointer);
-   }
-
-   CLOVER_NOT_SUPPORTED_UNTIL("2.0");
-
-} catch (error &) {
-}
diff --git a/src/gallium/frontends/clover/api/platform.cpp b/src/gallium/frontends/clover/api/platform.cpp
deleted file mode 100644
index b2077d30360..00000000000
--- a/src/gallium/frontends/clover/api/platform.cpp
+++ /dev/null
@@ -1,256 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include <unordered_map>
-
-#include "api/dispatch.hpp"
-#include "api/util.hpp"
-#include "core/platform.hpp"
-#include "git_sha1.h"
-#include "util/u_debug.h"
-
-using namespace clover;
-
-namespace {
-   platform _clover_platform;
-}
-
-CLOVER_API cl_int
-clGetPlatformIDs(cl_uint num_entries, cl_platform_id *rd_platforms,
-                 cl_uint *rnum_platforms) {
-   if ((!num_entries && rd_platforms) ||
-       (!rnum_platforms && !rd_platforms))
-      return CL_INVALID_VALUE;
-
-   if (rnum_platforms)
-      *rnum_platforms = 1;
-   if (rd_platforms)
-      *rd_platforms = desc(_clover_platform);
-
-   return CL_SUCCESS;
-}
-
-platform &clover::find_platform(cl_platform_id d_platform)
-{
-   /* this error is only added in CL2.0 */
-   if (d_platform != desc(_clover_platform))
-      throw error(CL_INVALID_PLATFORM);
-   return obj(d_platform);
-}
-
-cl_int
-clover::GetPlatformInfo(cl_platform_id d_platform, cl_platform_info param,
-                        size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-
-   auto &platform = find_platform(d_platform);
-
-   switch (param) {
-   case CL_PLATFORM_PROFILE:
-      buf.as_string() = "FULL_PROFILE";
-      break;
-
-   case CL_PLATFORM_VERSION: {
-      buf.as_string() = "OpenCL " + platform.platform_version_as_string() + " Mesa " PACKAGE_VERSION MESA_GIT_SHA1;
-      break;
-   }
-   case CL_PLATFORM_NAME:
-      buf.as_string() = "Clover";
-      break;
-
-   case CL_PLATFORM_VENDOR:
-      buf.as_string() = "Mesa";
-      break;
-
-   case CL_PLATFORM_EXTENSIONS:
-      buf.as_string() = platform.supported_extensions_as_string();
-      break;
-
-   case CL_PLATFORM_ICD_SUFFIX_KHR:
-      buf.as_string() = "MESA";
-      break;
-
-   case CL_PLATFORM_NUMERIC_VERSION: {
-      buf.as_scalar<cl_version>() = platform.platform_version();
-      break;
-   }
-
-   case CL_PLATFORM_EXTENSIONS_WITH_VERSION:
-      buf.as_vector<cl_name_version>() = platform.supported_extensions();
-      break;
-
-   case CL_PLATFORM_HOST_TIMER_RESOLUTION:
-      buf.as_scalar<cl_ulong>() = 0;
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-void *
-clover::GetExtensionFunctionAddressForPlatform(cl_platform_id d_platform,
-                                               const char *p_name) try {
-   obj(d_platform);
-   return GetExtensionFunctionAddress(p_name);
-
-} catch (error &) {
-   return NULL;
-}
-
-namespace {
-
-cl_int
-enqueueSVMFreeARM(cl_command_queue command_queue,
-                  cl_uint num_svm_pointers,
-                  void *svm_pointers[],
-                  void (CL_CALLBACK *pfn_free_func) (
-                    cl_command_queue queue, cl_uint num_svm_pointers,
-                    void *svm_pointers[], void *user_data),
-                  void *user_data,
-                  cl_uint num_events_in_wait_list,
-                  const cl_event *event_wait_list,
-                  cl_event *event) {
-
-   return EnqueueSVMFree(command_queue, num_svm_pointers, svm_pointers,
-                         pfn_free_func, user_data, num_events_in_wait_list,
-                         event_wait_list, event, CL_COMMAND_SVM_FREE_ARM);
-}
-
-cl_int
-enqueueSVMMapARM(cl_command_queue command_queue,
-                 cl_bool blocking_map,
-                 cl_map_flags map_flags,
-                 void *svm_ptr,
-                 size_t size,
-                 cl_uint num_events_in_wait_list,
-                 const cl_event *event_wait_list,
-                 cl_event *event) {
-
-   return EnqueueSVMMap(command_queue, blocking_map, map_flags, svm_ptr, size,
-                        num_events_in_wait_list, event_wait_list, event,
-                        CL_COMMAND_SVM_MAP_ARM);
-}
-
-cl_int
-enqueueSVMMemcpyARM(cl_command_queue command_queue,
-                    cl_bool blocking_copy,
-                    void *dst_ptr,
-                    const void *src_ptr,
-                    size_t size,
-                    cl_uint num_events_in_wait_list,
-                    const cl_event *event_wait_list,
-                    cl_event *event) {
-
-   return EnqueueSVMMemcpy(command_queue, blocking_copy, dst_ptr, src_ptr,
-                           size, num_events_in_wait_list, event_wait_list,
-                           event, CL_COMMAND_SVM_MEMCPY_ARM);
-}
-
-cl_int
-enqueueSVMMemFillARM(cl_command_queue command_queue,
-                     void *svm_ptr,
-                     const void *pattern,
-                     size_t pattern_size,
-                     size_t size,
-                     cl_uint num_events_in_wait_list,
-                     const cl_event *event_wait_list,
-                     cl_event *event) {
-
-   return EnqueueSVMMemFill(command_queue, svm_ptr, pattern, pattern_size,
-                            size, num_events_in_wait_list, event_wait_list,
-                            event, CL_COMMAND_SVM_MEMFILL_ARM);
-}
-
-cl_int
-enqueueSVMUnmapARM(cl_command_queue command_queue,
-                   void *svm_ptr,
-                   cl_uint num_events_in_wait_list,
-                   const cl_event *event_wait_list,
-                   cl_event *event) {
-
-   return EnqueueSVMUnmap(command_queue, svm_ptr, num_events_in_wait_list,
-                          event_wait_list, event, CL_COMMAND_SVM_UNMAP_ARM);
-}
-
-const std::unordered_map<std::string, void *>
-ext_funcs = {
-   // cl_arm_shared_virtual_memory
-   { "clEnqueueSVMFreeARM", reinterpret_cast<void *>(enqueueSVMFreeARM) },
-   { "clEnqueueSVMMapARM", reinterpret_cast<void *>(enqueueSVMMapARM) },
-   { "clEnqueueSVMMemcpyARM", reinterpret_cast<void *>(enqueueSVMMemcpyARM) },
-   { "clEnqueueSVMMemFillARM", reinterpret_cast<void *>(enqueueSVMMemFillARM) },
-   { "clEnqueueSVMUnmapARM", reinterpret_cast<void *>(enqueueSVMUnmapARM) },
-   { "clSetKernelArgSVMPointerARM", reinterpret_cast<void *>(clSetKernelArgSVMPointer) },
-   { "clSetKernelExecInfoARM", reinterpret_cast<void *>(clSetKernelExecInfo) },
-   { "clSVMAllocARM", reinterpret_cast<void *>(clSVMAlloc) },
-   { "clSVMFreeARM", reinterpret_cast<void *>(clSVMFree) },
-
-   // cl_khr_icd
-   { "clIcdGetPlatformIDsKHR", reinterpret_cast<void *>(IcdGetPlatformIDsKHR) },
-
-   // cl_khr_il_program
-   { "clCreateProgramWithILKHR", reinterpret_cast<void *>(CreateProgramWithILKHR) },
-};
-
-} // anonymous namespace
-
-void *
-clover::GetExtensionFunctionAddress(const char *p_name) try {
-   return ext_funcs.at(p_name);
-} catch (...) {
-   return nullptr;
-}
-
-cl_int
-clover::IcdGetPlatformIDsKHR(cl_uint num_entries, cl_platform_id *rd_platforms,
-                             cl_uint *rnum_platforms) {
-   return clGetPlatformIDs(num_entries, rd_platforms, rnum_platforms);
-}
-
-CLOVER_ICD_API cl_int
-clGetPlatformInfo(cl_platform_id d_platform, cl_platform_info param,
-                  size_t size, void *r_buf, size_t *r_size) {
-   return GetPlatformInfo(d_platform, param, size, r_buf, r_size);
-}
-
-CLOVER_ICD_API void *
-clGetExtensionFunctionAddress(const char *p_name) {
-   return GetExtensionFunctionAddress(p_name);
-}
-
-CLOVER_ICD_API void *
-clGetExtensionFunctionAddressForPlatform(cl_platform_id d_platform,
-                                         const char *p_name) {
-   return GetExtensionFunctionAddressForPlatform(d_platform, p_name);
-}
-
-CLOVER_ICD_API cl_int
-clIcdGetPlatformIDsKHR(cl_uint num_entries, cl_platform_id *rd_platforms,
-                       cl_uint *rnum_platforms) {
-   return IcdGetPlatformIDsKHR(num_entries, rd_platforms, rnum_platforms);
-}
diff --git a/src/gallium/frontends/clover/api/program.cpp b/src/gallium/frontends/clover/api/program.cpp
deleted file mode 100644
index b01ce08d010..00000000000
--- a/src/gallium/frontends/clover/api/program.cpp
+++ /dev/null
@@ -1,580 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/util.hpp"
-#include "core/program.hpp"
-#include "core/platform.hpp"
-#include "util/u_debug.h"
-
-#include <limits>
-#include <sstream>
-
-using namespace clover;
-
-namespace {
-
-   std::string
-   build_options(const char *p_opts, const char *p_debug) {
-      auto opts = std::string(p_opts ? p_opts : "");
-      std::string extra_opts = debug_get_option(p_debug, "");
-
-      return detokenize(std::vector<std::string>{opts, extra_opts}, " ");
-   }
-
-   class build_notifier {
-   public:
-      build_notifier(cl_program prog,
-                     void (CL_CALLBACK * notifer)(cl_program, void *), void *data) :
-                     prog_(prog), notifer(notifer), data_(data) { }
-
-      ~build_notifier() {
-         if (notifer)
-            notifer(prog_, data_);
-      }
-
-   private:
-      cl_program prog_;
-      void (CL_CALLBACK * notifer)(cl_program, void *);
-      void *data_;
-   };
-
-   void
-   validate_build_common(const program &prog, cl_uint num_devs,
-                         const cl_device_id *d_devs,
-                         void (CL_CALLBACK * pfn_notify)(cl_program, void *),
-                         void *user_data) {
-      if (!pfn_notify && user_data)
-         throw error(CL_INVALID_VALUE);
-
-      if (prog.kernel_ref_count())
-         throw error(CL_INVALID_OPERATION);
-
-      if (any_of([&](const device &dev) {
-               return !count(dev, prog.devices());
-            }, objs<allow_empty_tag>(d_devs, num_devs)))
-         throw error(CL_INVALID_DEVICE);
-   }
-
-   enum program::il_type
-   identify_and_validate_il(const std::string &il,
-                            const cl_version opencl_version,
-                            const context::notify_action &notify) {
-
-      return program::il_type::none;
-   }
-}
-
-CLOVER_API cl_program
-clCreateProgramWithSource(cl_context d_ctx, cl_uint count,
-                          const char **strings, const size_t *lengths,
-                          cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-   std::string source;
-
-   if (!count || !strings ||
-       any_of(is_zero(), range(strings, count)))
-      throw error(CL_INVALID_VALUE);
-
-   // Concatenate all the provided fragments together
-   for (unsigned i = 0; i < count; ++i)
-         source += (lengths && lengths[i] ?
-                    std::string(strings[i], strings[i] + lengths[i]) :
-                    std::string(strings[i]));
-
-   // ...and create a program object for them.
-   ret_error(r_errcode, CL_SUCCESS);
-   return new program(ctx, std::move(source), program::il_type::source);
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_program
-clCreateProgramWithBinary(cl_context d_ctx, cl_uint n,
-                          const cl_device_id *d_devs,
-                          const size_t *lengths,
-                          const unsigned char **binaries,
-                          cl_int *r_status, cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-   auto devs = objs(d_devs, n);
-
-   if (!lengths || !binaries)
-      throw error(CL_INVALID_VALUE);
-
-   if (any_of([&](const device &dev) {
-            return !count(dev, ctx.devices());
-         }, devs))
-      throw error(CL_INVALID_DEVICE);
-
-   // Deserialize the provided binaries,
-   std::vector<std::pair<cl_int, binary>> result = map(
-      [](const unsigned char *p, size_t l) -> std::pair<cl_int, binary> {
-         if (!p || !l)
-            return { CL_INVALID_VALUE, {} };
-
-         try {
-            std::stringbuf bin( std::string{ (char*)p, l } );
-            std::istream s(&bin);
-
-            return { CL_SUCCESS, binary::deserialize(s) };
-
-         } catch (std::istream::failure &) {
-            return { CL_INVALID_BINARY, {} };
-         }
-      },
-      range(binaries, n),
-      range(lengths, n));
-
-   // update the status array,
-   if (r_status)
-      copy(map(keys(), result), r_status);
-
-   if (any_of(key_equals(CL_INVALID_VALUE), result))
-      throw error(CL_INVALID_VALUE);
-
-   if (any_of(key_equals(CL_INVALID_BINARY), result))
-      throw error(CL_INVALID_BINARY);
-
-   // initialize a program object with them.
-   ret_error(r_errcode, CL_SUCCESS);
-   return new program(ctx, devs, map(values(), result));
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-cl_program
-clover::CreateProgramWithILKHR(cl_context d_ctx, const void *il,
-                               size_t length, cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-
-   if (!il || !length)
-      throw error(CL_INVALID_VALUE);
-
-   // Compute the highest OpenCL version supported by all devices associated to
-   // the context. That is the version used for validating the SPIR-V binary.
-   cl_version min_opencl_version = std::numeric_limits<uint32_t>::max();
-   for (const device &dev : ctx.devices()) {
-      const cl_version opencl_version = dev.device_version();
-      min_opencl_version = std::min(opencl_version, min_opencl_version);
-   }
-
-   const char *stream = reinterpret_cast<const char *>(il);
-   std::string binary(stream, stream + length);
-   const enum program::il_type il_type = identify_and_validate_il(binary,
-                                                                  min_opencl_version,
-                                                                  ctx.notify);
-
-   if (il_type == program::il_type::none)
-      throw error(CL_INVALID_VALUE);
-
-   // Initialize a program object with it.
-   ret_error(r_errcode, CL_SUCCESS);
-   return new program(ctx, std::move(binary), il_type);
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_program
-clCreateProgramWithIL(cl_context d_ctx,
-                      const void *il,
-                      size_t length,
-                      cl_int *r_errcode) {
-   return CreateProgramWithILKHR(d_ctx, il, length, r_errcode);
-}
-
-CLOVER_API cl_program
-clCreateProgramWithBuiltInKernels(cl_context d_ctx, cl_uint n,
-                                  const cl_device_id *d_devs,
-                                  const char *kernel_names,
-                                  cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-   auto devs = objs(d_devs, n);
-
-   if (any_of([&](const device &dev) {
-            return !count(dev, ctx.devices());
-         }, devs))
-      throw error(CL_INVALID_DEVICE);
-
-   // No currently supported built-in kernels.
-   throw error(CL_INVALID_VALUE);
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-
-CLOVER_API cl_int
-clRetainProgram(cl_program d_prog) try {
-   obj(d_prog).retain();
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clReleaseProgram(cl_program d_prog) try {
-   if (obj(d_prog).release())
-      delete pobj(d_prog);
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clBuildProgram(cl_program d_prog, cl_uint num_devs,
-               const cl_device_id *d_devs, const char *p_opts,
-               void (CL_CALLBACK * pfn_notify)(cl_program, void *),
-               void *user_data) try {
-   auto &prog = obj(d_prog);
-   auto devs =
-      (d_devs ? objs(d_devs, num_devs) : ref_vector<device>(prog.devices()));
-   const auto opts = build_options(p_opts, "CLOVER_EXTRA_BUILD_OPTIONS");
-
-   validate_build_common(prog, num_devs, d_devs, pfn_notify, user_data);
-
-   auto notifier = build_notifier(d_prog, pfn_notify, user_data);
-
-   if (prog.il_type() != program::il_type::none) {
-      prog.compile(devs, opts);
-      prog.link(devs, opts, { prog });
-   } else if (any_of([&](const device &dev){
-         return prog.build(dev).binary_type() != CL_PROGRAM_BINARY_TYPE_EXECUTABLE;
-         }, devs)) {
-      // According to the OpenCL 1.2 specification, âif program is created
-      // with clCreateProgramWithBinary, then the program binary must be an
-      // executable binary (not a compiled binary or library).â
-      throw error(CL_INVALID_BINARY);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clCompileProgram(cl_program d_prog, cl_uint num_devs,
-                 const cl_device_id *d_devs, const char *p_opts,
-                 cl_uint num_headers, const cl_program *d_header_progs,
-                 const char **header_names,
-                 void (CL_CALLBACK * pfn_notify)(cl_program, void *),
-                 void *user_data) try {
-   auto &prog = obj(d_prog);
-   auto devs =
-       (d_devs ? objs(d_devs, num_devs) : ref_vector<device>(prog.devices()));
-   const auto opts = build_options(p_opts, "CLOVER_EXTRA_COMPILE_OPTIONS");
-   header_map headers;
-
-   validate_build_common(prog, num_devs, d_devs, pfn_notify, user_data);
-
-   auto notifier = build_notifier(d_prog, pfn_notify, user_data);
-
-   if (bool(num_headers) != bool(header_names))
-      throw error(CL_INVALID_VALUE);
-
-   if (prog.il_type() == program::il_type::none)
-      throw error(CL_INVALID_OPERATION);
-
-   for_each([&](const char *name, const program &header) {
-         if (header.il_type() == program::il_type::none)
-            throw error(CL_INVALID_OPERATION);
-
-         if (!any_of(key_equals(name), headers))
-            headers.push_back(std::pair<std::string, std::string>(
-                                 name, header.source()));
-      },
-      range(header_names, num_headers),
-      objs<allow_empty_tag>(d_header_progs, num_headers));
-
-   prog.compile(devs, opts, headers);
-   return CL_SUCCESS;
-
-} catch (invalid_build_options_error &) {
-   return CL_INVALID_COMPILER_OPTIONS;
-
-} catch (build_error &) {
-   return CL_COMPILE_PROGRAM_FAILURE;
-
-} catch (error &e) {
-   return e.get();
-}
-
-namespace {
-   ref_vector<device>
-   validate_link_devices(const ref_vector<program> &progs,
-                         const ref_vector<device> &all_devs,
-                         const std::string &opts) {
-      std::vector<device *> devs;
-      const bool create_library =
-         opts.find("-create-library") != std::string::npos;
-      const bool enable_link_options =
-         opts.find("-enable-link-options") != std::string::npos;
-      const bool has_link_options =
-         opts.find("-cl-denorms-are-zero") != std::string::npos ||
-         opts.find("-cl-no-signed-zeroes") != std::string::npos ||
-         opts.find("-cl-unsafe-math-optimizations") != std::string::npos ||
-         opts.find("-cl-finite-math-only") != std::string::npos ||
-         opts.find("-cl-fast-relaxed-math") != std::string::npos ||
-         opts.find("-cl-no-subgroup-ifp") != std::string::npos;
-
-      // According to the OpenCL 1.2 specification, "[the
-      // -enable-link-options] option must be specified with the
-      // create-library option".
-      if (enable_link_options && !create_library)
-         throw error(CL_INVALID_LINKER_OPTIONS);
-
-      // According to the OpenCL 1.2 specification, "the
-      // [program linking options] can be specified when linking a program
-      // executable".
-      if (has_link_options && create_library)
-         throw error(CL_INVALID_LINKER_OPTIONS);
-
-      for (auto &dev : all_devs) {
-         const auto has_binary = [&](const program &prog) {
-            const auto t = prog.build(dev).binary_type();
-            return t == CL_PROGRAM_BINARY_TYPE_COMPILED_OBJECT ||
-                   t == CL_PROGRAM_BINARY_TYPE_LIBRARY;
-         };
-
-         // According to the OpenCL 1.2 specification, a library is made of
-         // âcompiled binaries specified in input_programs argument to
-         // clLinkProgramâ; compiled binaries does not refer to libraries:
-         // âinput_programs is an array of program objects that are compiled
-         // binaries or libraries that are to be linked to create the program
-         // executableâ.
-         if (create_library && any_of([&](const program &prog) {
-                  const auto t = prog.build(dev).binary_type();
-                  return t != CL_PROGRAM_BINARY_TYPE_COMPILED_OBJECT;
-               }, progs))
-            throw error(CL_INVALID_OPERATION);
-
-         // According to the CL 1.2 spec, when "all programs specified [..]
-         // contain a compiled binary or library for the device [..] a link is
-         // performed",
-         else if (all_of(has_binary, progs))
-            devs.push_back(&dev);
-
-         // otherwise if "none of the programs contain a compiled binary or
-         // library for that device [..] no link is performed.  All other
-         // cases will return a CL_INVALID_OPERATION error."
-         else if (any_of(has_binary, progs))
-            throw error(CL_INVALID_OPERATION);
-
-         // According to the OpenCL 1.2 specification, "[t]he linker may apply
-         // [program linking options] to all compiled program objects
-         // specified to clLinkProgram. The linker may apply these options
-         // only to libraries which were created with the
-         // -enable-link-option."
-         else if (has_link_options && any_of([&](const program &prog) {
-                  const auto t = prog.build(dev).binary_type();
-                  return !(t == CL_PROGRAM_BINARY_TYPE_COMPILED_OBJECT ||
-                          (t == CL_PROGRAM_BINARY_TYPE_LIBRARY &&
-                           prog.build(dev).opts.find("-enable-link-options") !=
-                              std::string::npos));
-               }, progs))
-            throw error(CL_INVALID_LINKER_OPTIONS);
-      }
-
-      return map(derefs(), devs);
-   }
-}
-
-CLOVER_API cl_program
-clLinkProgram(cl_context d_ctx, cl_uint num_devs, const cl_device_id *d_devs,
-              const char *p_opts, cl_uint num_progs, const cl_program *d_progs,
-              void (CL_CALLBACK * pfn_notify) (cl_program, void *), void *user_data,
-              cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-   const auto opts = build_options(p_opts, "CLOVER_EXTRA_LINK_OPTIONS");
-   auto progs = objs(d_progs, num_progs);
-   auto all_devs =
-      (d_devs ? objs(d_devs, num_devs) : ref_vector<device>(ctx.devices()));
-   auto prog = create<program>(ctx, all_devs);
-   auto r_prog = ret_object(prog);
-
-   auto notifier = build_notifier(r_prog, pfn_notify, user_data);
-
-   auto devs = validate_link_devices(progs, all_devs, opts);
-
-   validate_build_common(prog, num_devs, d_devs, pfn_notify, user_data);
-
-   try {
-      prog().link(devs, opts, progs);
-      ret_error(r_errcode, CL_SUCCESS);
-
-   } catch (build_error &) {
-      ret_error(r_errcode, CL_LINK_PROGRAM_FAILURE);
-   }
-
-   return r_prog;
-
-} catch (invalid_build_options_error &) {
-   ret_error(r_errcode, CL_INVALID_LINKER_OPTIONS);
-   return NULL;
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_int
-clUnloadCompiler() {
-   return CL_SUCCESS;
-}
-
-CLOVER_API cl_int
-clUnloadPlatformCompiler(cl_platform_id d_platform) try {
-   find_platform(d_platform);
-   return CL_SUCCESS;
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetProgramInfo(cl_program d_prog, cl_program_info param,
-                 size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &prog = obj(d_prog);
-
-   switch (param) {
-   case CL_PROGRAM_REFERENCE_COUNT:
-      buf.as_scalar<cl_uint>() = prog.ref_count();
-      break;
-
-   case CL_PROGRAM_CONTEXT:
-      buf.as_scalar<cl_context>() = desc(prog.context());
-      break;
-
-   case CL_PROGRAM_NUM_DEVICES:
-      buf.as_scalar<cl_uint>() = (prog.devices().size() ?
-                                  prog.devices().size() :
-                                  prog.context().devices().size());
-      break;
-
-   case CL_PROGRAM_DEVICES:
-      buf.as_vector<cl_device_id>() = (prog.devices().size() ?
-                                       descs(prog.devices()) :
-                                       descs(prog.context().devices()));
-      break;
-
-   case CL_PROGRAM_SOURCE:
-      buf.as_string() = prog.source();
-      break;
-
-   case CL_PROGRAM_BINARY_SIZES:
-      buf.as_vector<size_t>() = map([&](const device &dev) {
-            return prog.build(dev).bin.size();
-         },
-         prog.devices());
-      break;
-
-   case CL_PROGRAM_BINARIES:
-      buf.as_matrix<unsigned char>() = map([&](const device &dev) {
-            std::stringbuf bin;
-            std::ostream s(&bin);
-            prog.build(dev).bin.serialize(s);
-            return bin.str();
-         },
-         prog.devices());
-      break;
-
-   case CL_PROGRAM_NUM_KERNELS:
-      buf.as_scalar<cl_uint>() = prog.symbols().size();
-      break;
-
-   case CL_PROGRAM_KERNEL_NAMES:
-      buf.as_string() = fold([](const std::string &a, const binary::symbol &s) {
-            return ((a.empty() ? "" : a + ";") + s.name);
-         }, std::string(), prog.symbols());
-      break;
-
-   case CL_PROGRAM_SCOPE_GLOBAL_CTORS_PRESENT:
-   case CL_PROGRAM_SCOPE_GLOBAL_DTORS_PRESENT:
-      buf.as_scalar<cl_bool>() = CL_FALSE;
-      break;
-
-   case CL_PROGRAM_IL:
-      if (prog.il_type() == program::il_type::spirv)
-         buf.as_vector<char>() = prog.source();
-      else if (r_size)
-         *r_size = 0u;
-      break;
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetProgramBuildInfo(cl_program d_prog, cl_device_id d_dev,
-                      cl_program_build_info param,
-                      size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &prog = obj(d_prog);
-   auto &dev = obj(d_dev);
-
-   if (!count(dev, prog.context().devices()))
-      return CL_INVALID_DEVICE;
-
-   switch (param) {
-   case CL_PROGRAM_BUILD_STATUS:
-      buf.as_scalar<cl_build_status>() = prog.build(dev).status();
-      break;
-
-   case CL_PROGRAM_BUILD_OPTIONS:
-      buf.as_string() = prog.build(dev).opts;
-      break;
-
-   case CL_PROGRAM_BUILD_LOG:
-      buf.as_string() = prog.build(dev).log;
-      break;
-
-   case CL_PROGRAM_BINARY_TYPE:
-      buf.as_scalar<cl_program_binary_type>() = prog.build(dev).binary_type();
-      break;
-
-   case CL_PROGRAM_BUILD_GLOBAL_VARIABLE_TOTAL_SIZE:
-      buf.as_scalar<size_t>() = 0;
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
diff --git a/src/gallium/frontends/clover/api/queue.cpp b/src/gallium/frontends/clover/api/queue.cpp
deleted file mode 100644
index 9d1123b2ddb..00000000000
--- a/src/gallium/frontends/clover/api/queue.cpp
+++ /dev/null
@@ -1,155 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/util.hpp"
-#include "core/queue.hpp"
-
-using namespace clover;
-
-CLOVER_API cl_command_queue
-clCreateCommandQueue(cl_context d_ctx, cl_device_id d_dev,
-                     cl_command_queue_properties props,
-                     cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-   auto &dev = obj(d_dev);
-
-   if (!count(dev, ctx.devices()))
-      throw error(CL_INVALID_DEVICE);
-
-   if (props & ~(CL_QUEUE_OUT_OF_ORDER_EXEC_MODE_ENABLE |
-                 CL_QUEUE_PROFILING_ENABLE))
-      throw error(CL_INVALID_VALUE);
-
-   ret_error(r_errcode, CL_SUCCESS);
-   return new command_queue(ctx, dev, props);
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_int
-clRetainCommandQueue(cl_command_queue d_q) try {
-   obj(d_q).retain();
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clReleaseCommandQueue(cl_command_queue d_q) try {
-   auto &q = obj(d_q);
-
-   q.flush();
-
-   if (q.release())
-      delete pobj(d_q);
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetCommandQueueInfo(cl_command_queue d_q, cl_command_queue_info param,
-                      size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &q = obj(d_q);
-
-   switch (param) {
-   case CL_QUEUE_CONTEXT:
-      buf.as_scalar<cl_context>() = desc(q.context());
-      break;
-
-   case CL_QUEUE_DEVICE:
-      buf.as_scalar<cl_device_id>() = desc(q.device());
-      break;
-
-   case CL_QUEUE_REFERENCE_COUNT:
-      buf.as_scalar<cl_uint>() = q.ref_count();
-      break;
-
-   case CL_QUEUE_PROPERTIES:
-      buf.as_scalar<cl_command_queue_properties>() = q.props();
-      break;
-
-   case CL_QUEUE_PROPERTIES_ARRAY:
-      buf.as_vector<cl_queue_properties>() = q.properties();
-      break;
-
-   case CL_QUEUE_DEVICE_DEFAULT:
-      if (r_size)
-	 *r_size = 0;
-      break;
-
-   case CL_QUEUE_SIZE:
-      throw error(CL_INVALID_COMMAND_QUEUE);
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clFlush(cl_command_queue d_q) try {
-   obj(d_q).flush();
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_command_queue
-clCreateCommandQueueWithProperties(cl_context d_ctx, cl_device_id d_dev,
-                                   const cl_queue_properties *d_properties,
-                                   cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-   auto &dev = obj(d_dev);
-
-   if (!count(dev, ctx.devices()))
-      throw error(CL_INVALID_DEVICE);
-
-   ret_error(r_errcode, CL_SUCCESS);
-   std::vector<cl_queue_properties> properties;
-
-   if (d_properties) {
-      int idx = -1;
-      /* these come in pairs, bail if the first is 0 */
-      do {
-         idx++;
-         properties.push_back(d_properties[idx]);
-      } while (d_properties[idx & ~1]);
-   }
-   return new command_queue(ctx, dev, properties);
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
diff --git a/src/gallium/frontends/clover/api/sampler.cpp b/src/gallium/frontends/clover/api/sampler.cpp
deleted file mode 100644
index 482e55a9ce9..00000000000
--- a/src/gallium/frontends/clover/api/sampler.cpp
+++ /dev/null
@@ -1,100 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "api/util.hpp"
-#include "core/sampler.hpp"
-
-using namespace clover;
-
-CLOVER_API cl_sampler
-clCreateSampler(cl_context d_ctx, cl_bool norm_mode,
-                cl_addressing_mode addr_mode, cl_filter_mode filter_mode,
-                cl_int *r_errcode) try {
-   auto &ctx = obj(d_ctx);
-
-   if (!any_of(std::mem_fn(&device::image_support), ctx.devices()))
-      throw error(CL_INVALID_OPERATION);
-
-   ret_error(r_errcode, CL_SUCCESS);
-   return new sampler(ctx, norm_mode, addr_mode, filter_mode);
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_int
-clRetainSampler(cl_sampler d_s) try {
-   obj(d_s).retain();
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clReleaseSampler(cl_sampler d_s) try {
-   if (obj(d_s).release())
-      delete pobj(d_s);
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clGetSamplerInfo(cl_sampler d_s, cl_sampler_info param,
-                 size_t size, void *r_buf, size_t *r_size) try {
-   property_buffer buf { r_buf, size, r_size };
-   auto &s = obj(d_s);
-
-   switch (param) {
-   case CL_SAMPLER_REFERENCE_COUNT:
-      buf.as_scalar<cl_uint>() = s.ref_count();
-      break;
-
-   case CL_SAMPLER_CONTEXT:
-      buf.as_scalar<cl_context>() = desc(s.context());
-      break;
-
-   case CL_SAMPLER_NORMALIZED_COORDS:
-      buf.as_scalar<cl_bool>() = s.norm_mode();
-      break;
-
-   case CL_SAMPLER_ADDRESSING_MODE:
-      buf.as_scalar<cl_addressing_mode>() = s.addr_mode();
-      break;
-
-   case CL_SAMPLER_FILTER_MODE:
-      buf.as_scalar<cl_filter_mode>() = s.filter_mode();
-      break;
-
-   default:
-      throw error(CL_INVALID_VALUE);
-   }
-
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
diff --git a/src/gallium/frontends/clover/api/transfer.cpp b/src/gallium/frontends/clover/api/transfer.cpp
deleted file mode 100644
index e6b68b267c3..00000000000
--- a/src/gallium/frontends/clover/api/transfer.cpp
+++ /dev/null
@@ -1,1326 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include <cstring>
-
-#include "util/bitscan.h"
-
-#include "api/dispatch.hpp"
-#include "api/util.hpp"
-#include "core/event.hpp"
-#include "core/memory.hpp"
-
-using namespace clover;
-
-namespace {
-   typedef resource::vector vector_t;
-
-   vector_t
-   vector(const size_t *p) {
-      if (!p)
-         throw error(CL_INVALID_VALUE);
-      return range(p, 3);
-   }
-
-   vector_t
-   pitch(const vector_t &region, vector_t pitch) {
-      for (auto x : zip(tail(pitch),
-                        map(multiplies(), region, pitch))) {
-         // The spec defines a value of zero as the natural pitch,
-         // i.e. the unaligned size of the previous dimension.
-         if (std::get<0>(x) == 0)
-            std::get<0>(x) = std::get<1>(x);
-      }
-
-      return pitch;
-   }
-
-   ///
-   /// Size of a region in bytes.
-   ///
-   size_t
-   size(const vector_t &pitch, const vector_t &region) {
-      if (any_of(is_zero(), region))
-         return 0;
-      else
-         return dot(pitch, region - vector_t{ 0, 1, 1 });
-   }
-
-   ///
-   /// Common argument checking shared by memory transfer commands.
-   ///
-   void
-   validate_common(command_queue &q,
-                   const ref_vector<event> &deps) {
-      if (any_of([&](const event &ev) {
-               return ev.context() != q.context();
-            }, deps))
-         throw error(CL_INVALID_CONTEXT);
-   }
-
-   ///
-   /// Common error checking for a buffer object argument.
-   ///
-   void
-   validate_object(command_queue &q, buffer &mem, const vector_t &origin,
-                   const vector_t &pitch, const vector_t &region) {
-      if (mem.context() != q.context())
-         throw error(CL_INVALID_CONTEXT);
-
-      // The region must fit within the specified pitch,
-      if (any_of(greater(), map(multiplies(), pitch, region), tail(pitch)))
-         throw error(CL_INVALID_VALUE);
-
-      // ...and within the specified object.
-      if (dot(pitch, origin) + size(pitch, region) > mem.size())
-         throw error(CL_INVALID_VALUE);
-
-      if (any_of(is_zero(), region))
-         throw error(CL_INVALID_VALUE);
-   }
-
-   ///
-   /// Common error checking for an image argument.
-   ///
-   void
-   validate_object(command_queue &q, image &img,
-                   const vector_t &orig, const vector_t &region) {
-      size_t height = img.type() == CL_MEM_OBJECT_IMAGE1D_ARRAY ? img.array_size() : img.height();
-      size_t depth = img.type() == CL_MEM_OBJECT_IMAGE2D_ARRAY ? img.array_size() : img.depth();
-      vector_t size = { img.width(), height, depth };
-      const auto &dev = q.device();
-
-      if (!dev.image_support())
-         throw error(CL_INVALID_OPERATION);
-
-      if (img.context() != q.context())
-         throw error(CL_INVALID_CONTEXT);
-
-      if (any_of(greater(), orig + region, size))
-         throw error(CL_INVALID_VALUE);
-
-      if (any_of(is_zero(), region))
-         throw error(CL_INVALID_VALUE);
-
-      switch (img.type()) {
-      case CL_MEM_OBJECT_IMAGE1D: {
-         const size_t max = dev.max_image_size();
-         if (img.width() > max)
-            throw error(CL_INVALID_IMAGE_SIZE);
-         break;
-      }
-      case CL_MEM_OBJECT_IMAGE1D_ARRAY: {
-         const size_t max_size = dev.max_image_size();
-         const size_t max_array = dev.max_image_array_number();
-         if (img.width() > max_size || img.array_size() > max_array)
-            throw error(CL_INVALID_IMAGE_SIZE);
-         break;
-      }
-      case CL_MEM_OBJECT_IMAGE2D: {
-         const size_t max = dev.max_image_size();
-         if (img.width() > max || img.height() > max)
-            throw error(CL_INVALID_IMAGE_SIZE);
-         break;
-      }
-      case CL_MEM_OBJECT_IMAGE2D_ARRAY: {
-         const size_t max_size = dev.max_image_size();
-         const size_t max_array = dev.max_image_array_number();
-         if (img.width() > max_size || img.height() > max_size || img.array_size() > max_array)
-            throw error(CL_INVALID_IMAGE_SIZE);
-         break;
-      }
-      case CL_MEM_OBJECT_IMAGE3D: {
-         const size_t max = dev.max_image_size_3d();
-         if (img.width() > max || img.height() > max || img.depth() > max)
-            throw error(CL_INVALID_IMAGE_SIZE);
-         break;
-      }
-      // XXX: Implement missing checks once Clover supports more image types.
-      default:
-         throw error(CL_INVALID_IMAGE_SIZE);
-      }
-   }
-
-   ///
-   /// Common error checking for a host pointer argument.
-   ///
-   void
-   validate_object(command_queue &q, const void *ptr, const vector_t &orig,
-                   const vector_t &pitch, const vector_t &region) {
-      if (!ptr)
-         throw error(CL_INVALID_VALUE);
-
-      // The region must fit within the specified pitch.
-      if (any_of(greater(), map(multiplies(), pitch, region), tail(pitch)))
-         throw error(CL_INVALID_VALUE);
-   }
-
-   ///
-   /// Common argument checking for a copy between two buffer objects.
-   ///
-   void
-   validate_copy(command_queue &q, buffer &dst_mem,
-                 const vector_t &dst_orig, const vector_t &dst_pitch,
-                 buffer &src_mem,
-                 const vector_t &src_orig, const vector_t &src_pitch,
-                 const vector_t &region) {
-      if (dst_mem == src_mem) {
-         auto dst_offset = dot(dst_pitch, dst_orig);
-         auto src_offset = dot(src_pitch, src_orig);
-
-         if (interval_overlaps()(
-                dst_offset, dst_offset + size(dst_pitch, region),
-                src_offset, src_offset + size(src_pitch, region)))
-            throw error(CL_MEM_COPY_OVERLAP);
-      }
-   }
-
-   ///
-   /// Common argument checking for a copy between two image objects.
-   ///
-   void
-   validate_copy(command_queue &q,
-                 image &dst_img, const vector_t &dst_orig,
-                 image &src_img, const vector_t &src_orig,
-                 const vector_t &region) {
-      if (dst_img.format() != src_img.format())
-         throw error(CL_IMAGE_FORMAT_MISMATCH);
-
-      if (dst_img == src_img) {
-         if (all_of(interval_overlaps(),
-                    dst_orig, dst_orig + region,
-                    src_orig, src_orig + region))
-            throw error(CL_MEM_COPY_OVERLAP);
-      }
-   }
-
-   ///
-   /// Checks that the host access flags of the memory object are
-   /// within the allowed set \a flags.
-   ///
-   void
-   validate_object_access(const memory_obj &mem, const cl_mem_flags flags) {
-      if (mem.flags() & ~flags &
-          (CL_MEM_HOST_READ_ONLY | CL_MEM_HOST_WRITE_ONLY |
-           CL_MEM_HOST_NO_ACCESS))
-         throw error(CL_INVALID_OPERATION);
-   }
-
-   ///
-   /// Checks that the mapping flags are correct.
-   ///
-   void
-   validate_map_flags(const memory_obj &mem, const cl_map_flags flags) {
-      if ((flags & (CL_MAP_WRITE | CL_MAP_READ)) &&
-          (flags & CL_MAP_WRITE_INVALIDATE_REGION))
-         throw error(CL_INVALID_VALUE);
-
-      if (flags & CL_MAP_READ)
-         validate_object_access(mem, CL_MEM_HOST_READ_ONLY);
-
-      if (flags & (CL_MAP_WRITE | CL_MAP_WRITE_INVALIDATE_REGION))
-         validate_object_access(mem, CL_MEM_HOST_WRITE_ONLY);
-   }
-
-   ///
-   /// Checks that the memory migration flags are correct.
-   ///
-   void
-   validate_mem_migration_flags(const cl_mem_migration_flags flags) {
-      const cl_mem_migration_flags valid =
-         CL_MIGRATE_MEM_OBJECT_HOST |
-         CL_MIGRATE_MEM_OBJECT_CONTENT_UNDEFINED;
-
-      if (flags & ~valid)
-         throw error(CL_INVALID_VALUE);
-   }
-
-   ///
-   /// Class that encapsulates the task of mapping an object of type
-   /// \a T.  The return value of get() should be implicitly
-   /// convertible to \a void *.
-   ///
-   template<typename T>
-   struct _map;
-
-   template<>
-   struct _map<image*> {
-      _map(command_queue &q, image *img, cl_map_flags flags,
-           vector_t offset, vector_t pitch, vector_t region) :
-         map(q, img->resource_in(q), flags, true, offset, region),
-         pitch(map.pitch())
-      { }
-
-      template<typename T>
-      operator T *() const {
-         return static_cast<T *>(map);
-      }
-
-      mapping map;
-      vector_t pitch;
-   };
-
-   template<>
-   struct _map<buffer*> {
-      _map(command_queue &q, buffer *mem, cl_map_flags flags,
-           vector_t offset, vector_t pitch, vector_t region) :
-         map(q, mem->resource_in(q), flags, true,
-             {{ dot(pitch, offset) }}, {{ size(pitch, region) }}),
-         pitch(pitch)
-      { }
-
-      template<typename T>
-      operator T *() const {
-         return static_cast<T *>(map);
-      }
-
-      mapping map;
-      vector_t pitch;
-   };
-
-   template<typename P>
-   struct _map<P *> {
-      _map(command_queue &q, P *ptr, cl_map_flags flags,
-           vector_t offset, vector_t pitch, vector_t region) :
-         ptr((P *)((char *)ptr + dot(pitch, offset))), pitch(pitch)
-      { }
-
-      template<typename T>
-      operator T *() const {
-         return static_cast<T *>(ptr);
-      }
-
-      P *ptr;
-      vector_t pitch;
-   };
-
-   ///
-   /// Software copy from \a src_obj to \a dst_obj.  They can be
-   /// either pointers or memory objects.
-   ///
-   template<typename T, typename S>
-   std::function<void (event &)>
-   soft_copy_op(command_queue &q,
-                T dst_obj, const vector_t &dst_orig, const vector_t &dst_pitch,
-                S src_obj, const vector_t &src_orig, const vector_t &src_pitch,
-                const vector_t &region) {
-      return [=, &q](event &) {
-         _map<T> dst = { q, dst_obj, CL_MAP_WRITE,
-                         dst_orig, dst_pitch, region };
-         _map<S> src = { q, src_obj, CL_MAP_READ,
-                         src_orig, src_pitch, region };
-         assert(src.pitch[0] == dst.pitch[0]);
-         vector_t v = {};
-
-         for (v[2] = 0; v[2] < region[2]; ++v[2]) {
-            for (v[1] = 0; v[1] < region[1]; ++v[1]) {
-               std::memcpy(
-                  static_cast<char *>(dst) + dot(dst.pitch, v),
-                  static_cast<const char *>(src) + dot(src.pitch, v),
-                  src.pitch[0] * region[0]);
-            }
-         }
-      };
-   }
-
-   ///
-   /// Hardware copy from \a src_obj to \a dst_obj.
-   ///
-   template<typename T, typename S>
-   std::function<void (event &)>
-   hard_copy_op(command_queue &q, T dst_obj, const vector_t &dst_orig,
-                S src_obj, const vector_t &src_orig, const vector_t &region) {
-      return [=, &q](event &) {
-         dst_obj->resource_in(q).copy(q, dst_orig, region,
-                                      src_obj->resource_in(q), src_orig);
-      };
-   }
-}
-
-CLOVER_API cl_int
-clEnqueueReadBuffer(cl_command_queue d_q, cl_mem d_mem, cl_bool blocking,
-                    size_t offset, size_t size, void *ptr,
-                    cl_uint num_deps, const cl_event *d_deps,
-                    cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &mem = obj<buffer>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   vector_t region = { size, 1, 1 };
-   vector_t obj_origin = { offset };
-   auto obj_pitch = pitch(region, {{ 1 }});
-
-   validate_common(q, deps);
-   validate_object(q, ptr, {}, obj_pitch, region);
-   validate_object(q, mem, obj_origin, obj_pitch, region);
-   validate_object_access(mem, CL_MEM_HOST_READ_ONLY);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_READ_BUFFER, deps,
-      soft_copy_op(q, ptr, {}, obj_pitch,
-                   &mem, obj_origin, obj_pitch,
-                   region));
-
-   if (blocking)
-       hev().wait_signalled();
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueWriteBuffer(cl_command_queue d_q, cl_mem d_mem, cl_bool blocking,
-                     size_t offset, size_t size, const void *ptr,
-                     cl_uint num_deps, const cl_event *d_deps,
-                     cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &mem = obj<buffer>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   vector_t region = { size, 1, 1 };
-   vector_t obj_origin = { offset };
-   auto obj_pitch = pitch(region, {{ 1 }});
-
-   validate_common(q, deps);
-   validate_object(q, mem, obj_origin, obj_pitch, region);
-   validate_object(q, ptr, {}, obj_pitch, region);
-   validate_object_access(mem, CL_MEM_HOST_WRITE_ONLY);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_WRITE_BUFFER, deps,
-      soft_copy_op(q, &mem, obj_origin, obj_pitch,
-                   ptr, {}, obj_pitch,
-                   region));
-
-   if (blocking)
-       hev().wait_signalled();
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueReadBufferRect(cl_command_queue d_q, cl_mem d_mem, cl_bool blocking,
-                        const size_t *p_obj_origin,
-                        const size_t *p_host_origin,
-                        const size_t *p_region,
-                        size_t obj_row_pitch, size_t obj_slice_pitch,
-                        size_t host_row_pitch, size_t host_slice_pitch,
-                        void *ptr,
-                        cl_uint num_deps, const cl_event *d_deps,
-                        cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &mem = obj<buffer>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   auto obj_origin = vector(p_obj_origin);
-   auto obj_pitch = pitch(region, {{ 1, obj_row_pitch, obj_slice_pitch }});
-   auto host_origin = vector(p_host_origin);
-   auto host_pitch = pitch(region, {{ 1, host_row_pitch, host_slice_pitch }});
-
-   validate_common(q, deps);
-   validate_object(q, ptr, host_origin, host_pitch, region);
-   validate_object(q, mem, obj_origin, obj_pitch, region);
-   validate_object_access(mem, CL_MEM_HOST_READ_ONLY);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_READ_BUFFER_RECT, deps,
-      soft_copy_op(q, ptr, host_origin, host_pitch,
-                   &mem, obj_origin, obj_pitch,
-                   region));
-
-   if (blocking)
-       hev().wait_signalled();
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueWriteBufferRect(cl_command_queue d_q, cl_mem d_mem, cl_bool blocking,
-                         const size_t *p_obj_origin,
-                         const size_t *p_host_origin,
-                         const size_t *p_region,
-                         size_t obj_row_pitch, size_t obj_slice_pitch,
-                         size_t host_row_pitch, size_t host_slice_pitch,
-                         const void *ptr,
-                         cl_uint num_deps, const cl_event *d_deps,
-                         cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &mem = obj<buffer>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   auto obj_origin = vector(p_obj_origin);
-   auto obj_pitch = pitch(region, {{ 1, obj_row_pitch, obj_slice_pitch }});
-   auto host_origin = vector(p_host_origin);
-   auto host_pitch = pitch(region, {{ 1, host_row_pitch, host_slice_pitch }});
-
-   validate_common(q, deps);
-   validate_object(q, mem, obj_origin, obj_pitch, region);
-   validate_object(q, ptr, host_origin, host_pitch, region);
-   validate_object_access(mem, CL_MEM_HOST_WRITE_ONLY);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_WRITE_BUFFER_RECT, deps,
-      soft_copy_op(q, &mem, obj_origin, obj_pitch,
-                   ptr, host_origin, host_pitch,
-                   region));
-
-   if (blocking)
-       hev().wait_signalled();
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueFillBuffer(cl_command_queue d_queue, cl_mem d_mem,
-                    const void *pattern, size_t pattern_size,
-                    size_t offset, size_t size,
-                    cl_uint num_deps, const cl_event *d_deps,
-                    cl_event *rd_ev) try {
-   auto &q = obj(d_queue);
-   auto &mem = obj<buffer>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   vector_t region = { size, 1, 1 };
-   vector_t origin = { offset };
-   auto dst_pitch = pitch(region, {{ 1 }});
-
-   validate_common(q, deps);
-   validate_object(q, mem, origin, dst_pitch, region);
-
-   if (!pattern)
-      return CL_INVALID_VALUE;
-
-   if (!util_is_power_of_two_nonzero_uintptr(pattern_size) ||
-      pattern_size > 128 || size % pattern_size
-      || offset % pattern_size) {
-      return CL_INVALID_VALUE;
-   }
-
-   auto sub = dynamic_cast<sub_buffer *>(&mem);
-   if (sub && sub->offset() % q.device().mem_base_addr_align()) {
-      return CL_MISALIGNED_SUB_BUFFER_OFFSET;
-   }
-
-   std::string data = std::string((char *)pattern, pattern_size);
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_FILL_BUFFER, deps,
-      [=, &q, &mem](event &) {
-         mem.resource_in(q).clear(q, origin, region, data);
-      });
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueCopyBuffer(cl_command_queue d_q, cl_mem d_src_mem, cl_mem d_dst_mem,
-                    size_t src_offset, size_t dst_offset, size_t size,
-                    cl_uint num_deps, const cl_event *d_deps,
-                    cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &src_mem = obj<buffer>(d_src_mem);
-   auto &dst_mem = obj<buffer>(d_dst_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   vector_t region = { size, 1, 1 };
-   vector_t dst_origin = { dst_offset };
-   auto dst_pitch = pitch(region, {{ 1 }});
-   vector_t src_origin = { src_offset };
-   auto src_pitch = pitch(region, {{ 1 }});
-
-   validate_common(q, deps);
-   validate_object(q, dst_mem, dst_origin, dst_pitch, region);
-   validate_object(q, src_mem, src_origin, src_pitch, region);
-   validate_copy(q, dst_mem, dst_origin, dst_pitch,
-                 src_mem, src_origin, src_pitch, region);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_COPY_BUFFER, deps,
-      hard_copy_op(q, &dst_mem, dst_origin,
-                   &src_mem, src_origin, region));
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueCopyBufferRect(cl_command_queue d_q, cl_mem d_src_mem,
-                        cl_mem d_dst_mem,
-                        const size_t *p_src_origin, const size_t *p_dst_origin,
-                        const size_t *p_region,
-                        size_t src_row_pitch, size_t src_slice_pitch,
-                        size_t dst_row_pitch, size_t dst_slice_pitch,
-                        cl_uint num_deps, const cl_event *d_deps,
-                        cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &src_mem = obj<buffer>(d_src_mem);
-   auto &dst_mem = obj<buffer>(d_dst_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   auto dst_origin = vector(p_dst_origin);
-   auto dst_pitch = pitch(region, {{ 1, dst_row_pitch, dst_slice_pitch }});
-   auto src_origin = vector(p_src_origin);
-   auto src_pitch = pitch(region, {{ 1, src_row_pitch, src_slice_pitch }});
-
-   validate_common(q, deps);
-   validate_object(q, dst_mem, dst_origin, dst_pitch, region);
-   validate_object(q, src_mem, src_origin, src_pitch, region);
-   validate_copy(q, dst_mem, dst_origin, dst_pitch,
-                 src_mem, src_origin, src_pitch, region);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_COPY_BUFFER_RECT, deps,
-      soft_copy_op(q, &dst_mem, dst_origin, dst_pitch,
-                   &src_mem, src_origin, src_pitch,
-                   region));
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueReadImage(cl_command_queue d_q, cl_mem d_mem, cl_bool blocking,
-                   const size_t *p_origin, const size_t *p_region,
-                   size_t row_pitch, size_t slice_pitch, void *ptr,
-                   cl_uint num_deps, const cl_event *d_deps,
-                   cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &img = obj<image>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   auto dst_pitch = pitch(region, {{ img.pixel_size(),
-                                     row_pitch, slice_pitch }});
-   auto src_origin = vector(p_origin);
-   auto src_pitch = pitch(region, {{ img.pixel_size(),
-                                     img.row_pitch(), img.slice_pitch() }});
-
-   validate_common(q, deps);
-   validate_object(q, ptr, {}, dst_pitch, region);
-   validate_object(q, img, src_origin, region);
-   validate_object_access(img, CL_MEM_HOST_READ_ONLY);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_READ_IMAGE, deps,
-      soft_copy_op(q, ptr, {}, dst_pitch,
-                   &img, src_origin, src_pitch,
-                   region));
-
-   if (blocking)
-       hev().wait_signalled();
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueWriteImage(cl_command_queue d_q, cl_mem d_mem, cl_bool blocking,
-                    const size_t *p_origin, const size_t *p_region,
-                    size_t row_pitch, size_t slice_pitch, const void *ptr,
-                    cl_uint num_deps, const cl_event *d_deps,
-                    cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &img = obj<image>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   auto dst_origin = vector(p_origin);
-   auto dst_pitch = pitch(region, {{ img.pixel_size(),
-                                     img.row_pitch(), img.slice_pitch() }});
-   auto src_pitch = pitch(region, {{ img.pixel_size(),
-                                     row_pitch, slice_pitch }});
-
-   validate_common(q, deps);
-   validate_object(q, img, dst_origin, region);
-   validate_object(q, ptr, {}, src_pitch, region);
-   validate_object_access(img, CL_MEM_HOST_WRITE_ONLY);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_WRITE_IMAGE, deps,
-      soft_copy_op(q, &img, dst_origin, dst_pitch,
-                   ptr, {}, src_pitch,
-                   region));
-
-   if (blocking)
-       hev().wait_signalled();
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueFillImage(cl_command_queue d_queue, cl_mem d_mem,
-                   const void *fill_color,
-                   const size_t *p_origin, const size_t *p_region,
-                   cl_uint num_deps, const cl_event *d_deps,
-                   cl_event *rd_ev) try {
-   auto &q = obj(d_queue);
-   auto &img = obj<image>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto origin = vector(p_origin);
-   auto region = vector(p_region);
-
-   validate_common(q, deps);
-   validate_object(q, img, origin, region);
-
-   if (!fill_color)
-      return CL_INVALID_VALUE;
-
-   std::string data = std::string((char *)fill_color, sizeof(cl_uint4));
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_FILL_IMAGE, deps,
-      [=, &q, &img](event &) {
-         img.resource_in(q).clear(q, origin, region, data);
-      });
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueCopyImage(cl_command_queue d_q, cl_mem d_src_mem, cl_mem d_dst_mem,
-                   const size_t *p_src_origin, const size_t *p_dst_origin,
-                   const size_t *p_region,
-                   cl_uint num_deps, const cl_event *d_deps,
-                   cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &src_img = obj<image>(d_src_mem);
-   auto &dst_img = obj<image>(d_dst_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   auto dst_origin = vector(p_dst_origin);
-   auto src_origin = vector(p_src_origin);
-
-   validate_common(q, deps);
-   validate_object(q, dst_img, dst_origin, region);
-   validate_object(q, src_img, src_origin, region);
-   validate_copy(q, dst_img, dst_origin, src_img, src_origin, region);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_COPY_IMAGE, deps,
-      hard_copy_op(q, &dst_img, dst_origin,
-                   &src_img, src_origin,
-                   region));
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueCopyImageToBuffer(cl_command_queue d_q,
-                           cl_mem d_src_mem, cl_mem d_dst_mem,
-                           const size_t *p_src_origin, const size_t *p_region,
-                           size_t dst_offset,
-                           cl_uint num_deps, const cl_event *d_deps,
-                           cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &src_img = obj<image>(d_src_mem);
-   auto &dst_mem = obj<buffer>(d_dst_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   vector_t dst_origin = { dst_offset };
-   auto dst_pitch = pitch(region, {{ src_img.pixel_size() }});
-   auto src_origin = vector(p_src_origin);
-   auto src_pitch = pitch(region, {{ src_img.pixel_size(),
-                                     src_img.row_pitch(),
-                                     src_img.slice_pitch() }});
-
-   validate_common(q, deps);
-   validate_object(q, dst_mem, dst_origin, dst_pitch, region);
-   validate_object(q, src_img, src_origin, region);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_COPY_IMAGE_TO_BUFFER, deps,
-      soft_copy_op(q, &dst_mem, dst_origin, dst_pitch,
-                   &src_img, src_origin, src_pitch,
-                   region));
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueCopyBufferToImage(cl_command_queue d_q,
-                           cl_mem d_src_mem, cl_mem d_dst_mem,
-                           size_t src_offset,
-                           const size_t *p_dst_origin, const size_t *p_region,
-                           cl_uint num_deps, const cl_event *d_deps,
-                           cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &src_mem = obj<buffer>(d_src_mem);
-   auto &dst_img = obj<image>(d_dst_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   auto dst_origin = vector(p_dst_origin);
-   auto dst_pitch = pitch(region, {{ dst_img.pixel_size(),
-                                     dst_img.row_pitch(),
-                                     dst_img.slice_pitch() }});
-   vector_t src_origin = { src_offset };
-   auto src_pitch = pitch(region, {{ dst_img.pixel_size() }});
-
-   validate_common(q, deps);
-   validate_object(q, dst_img, dst_origin, region);
-   validate_object(q, src_mem, src_origin, src_pitch, region);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_COPY_BUFFER_TO_IMAGE, deps,
-      soft_copy_op(q, &dst_img, dst_origin, dst_pitch,
-                   &src_mem, src_origin, src_pitch,
-                   region));
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API void *
-clEnqueueMapBuffer(cl_command_queue d_q, cl_mem d_mem, cl_bool blocking,
-                   cl_map_flags flags, size_t offset, size_t size,
-                   cl_uint num_deps, const cl_event *d_deps,
-                   cl_event *rd_ev, cl_int *r_errcode) try {
-   auto &q = obj(d_q);
-   auto &mem = obj<buffer>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   vector_t region = { size, 1, 1 };
-   vector_t obj_origin = { offset };
-   auto obj_pitch = pitch(region, {{ 1 }});
-
-   validate_common(q, deps);
-   validate_object(q, mem, obj_origin, obj_pitch, region);
-   validate_map_flags(mem, flags);
-
-   auto *map = mem.resource_in(q).add_map(q, flags, blocking, obj_origin, region);
-
-   auto hev = create<hard_event>(q, CL_COMMAND_MAP_BUFFER, deps);
-   if (blocking)
-       hev().wait_signalled();
-
-   ret_object(rd_ev, hev);
-   ret_error(r_errcode, CL_SUCCESS);
-   return *map;
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API void *
-clEnqueueMapImage(cl_command_queue d_q, cl_mem d_mem, cl_bool blocking,
-                  cl_map_flags flags,
-                  const size_t *p_origin, const size_t *p_region,
-                  size_t *row_pitch, size_t *slice_pitch,
-                  cl_uint num_deps, const cl_event *d_deps,
-                  cl_event *rd_ev, cl_int *r_errcode) try {
-   auto &q = obj(d_q);
-   auto &img = obj<image>(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-   auto region = vector(p_region);
-   auto origin = vector(p_origin);
-
-   validate_common(q, deps);
-   validate_object(q, img, origin, region);
-   validate_map_flags(img, flags);
-
-   if (!row_pitch)
-      throw error(CL_INVALID_VALUE);
-
-   if ((img.slice_pitch() || img.array_size()) && !slice_pitch)
-      throw error(CL_INVALID_VALUE);
-
-   auto *map = img.resource_in(q).add_map(q, flags, blocking, origin, region);
-   *row_pitch = map->pitch()[1];
-   if (slice_pitch)
-      *slice_pitch = map->pitch()[2];
-
-   auto hev = create<hard_event>(q, CL_COMMAND_MAP_IMAGE, deps);
-   if (blocking)
-       hev().wait_signalled();
-
-   ret_object(rd_ev, hev);
-   ret_error(r_errcode, CL_SUCCESS);
-   return *map;
-
-} catch (error &e) {
-   ret_error(r_errcode, e);
-   return NULL;
-}
-
-CLOVER_API cl_int
-clEnqueueUnmapMemObject(cl_command_queue d_q, cl_mem d_mem, void *ptr,
-                        cl_uint num_deps, const cl_event *d_deps,
-                        cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto &mem = obj(d_mem);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-
-   validate_common(q, deps);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_UNMAP_MEM_OBJECT, deps,
-      [=, &q, &mem](event &) {
-         mem.resource_in(q).del_map(ptr);
-      });
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueMigrateMemObjects(cl_command_queue d_q,
-                           cl_uint num_mems,
-                           const cl_mem *d_mems,
-                           cl_mem_migration_flags flags,
-                           cl_uint num_deps,
-                           const cl_event *d_deps,
-                           cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto mems = objs<memory_obj>(d_mems, num_mems);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-
-   validate_common(q, deps);
-   validate_mem_migration_flags(flags);
-
-   if (any_of([&](const memory_obj &m) {
-         return m.context() != q.context();
-         }, mems))
-      throw error(CL_INVALID_CONTEXT);
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_MIGRATE_MEM_OBJECTS, deps,
-      [=, &q](event &) {
-         for (auto &mem: mems) {
-            if (flags & CL_MIGRATE_MEM_OBJECT_HOST) {
-               if ((flags & CL_MIGRATE_MEM_OBJECT_CONTENT_UNDEFINED))
-                  mem.resource_out(q);
-
-               // For flags == CL_MIGRATE_MEM_OBJECT_HOST only to be
-               // efficient we would need cl*ReadBuffer* to implement
-               // reading from host memory.
-
-            } else {
-               if (flags & CL_MIGRATE_MEM_OBJECT_CONTENT_UNDEFINED)
-                  mem.resource_undef(q);
-               else
-                  mem.resource_in(q);
-            }
-         }
-      });
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;;
-
-} catch (error &e) {
-   return e.get();
-}
-
-static void CL_CALLBACK
-free_queue(cl_command_queue d_q, cl_uint num_svm_pointers,
-                         void *svm_pointers[], void *) {
-   clover::context &ctx = obj(d_q).context();
-   for (void *p : range(svm_pointers, num_svm_pointers)) {
-      ctx.remove_svm_allocation(p);
-      free(p);
-   }
-}
-
-cl_int
-clover::EnqueueSVMFree(cl_command_queue d_q,
-                       cl_uint num_svm_pointers,
-                       void *svm_pointers[],
-                       void (CL_CALLBACK *pfn_free_func) (
-                           cl_command_queue queue, cl_uint num_svm_pointers,
-                           void *svm_pointers[], void *user_data),
-                       void *user_data,
-                       cl_uint num_events_in_wait_list,
-                       const cl_event *event_wait_list,
-                       cl_event *event,
-                       cl_int cmd) try {
-
-   if (bool(num_svm_pointers) != bool(svm_pointers))
-      return CL_INVALID_VALUE;
-
-   auto &q = obj(d_q);
-
-   if (!q.device().svm_support())
-      return CL_INVALID_OPERATION;
-
-   bool can_emulate = q.device().has_system_svm();
-   auto deps = objs<wait_list_tag>(event_wait_list, num_events_in_wait_list);
-
-   validate_common(q, deps);
-
-   std::vector<void *> svm_pointers_cpy(svm_pointers,
-                                        svm_pointers + num_svm_pointers);
-   if (!pfn_free_func) {
-      if (!can_emulate) {
-         CLOVER_NOT_SUPPORTED_UNTIL("2.0");
-         return CL_INVALID_VALUE;
-      }
-      pfn_free_func = free_queue;
-   }
-
-   auto hev = create<hard_event>(q, cmd, deps,
-      [=](clover::event &) mutable {
-         pfn_free_func(d_q, num_svm_pointers, svm_pointers_cpy.data(),
-                       user_data);
-      });
-
-   ret_object(event, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueSVMFree(cl_command_queue d_q,
-                 cl_uint num_svm_pointers,
-                 void *svm_pointers[],
-                 void (CL_CALLBACK *pfn_free_func) (
-                    cl_command_queue queue, cl_uint num_svm_pointers,
-                    void *svm_pointers[], void *user_data),
-                 void *user_data,
-                 cl_uint num_events_in_wait_list,
-                 const cl_event *event_wait_list,
-                 cl_event *event) {
-
-   return EnqueueSVMFree(d_q, num_svm_pointers, svm_pointers,
-                         pfn_free_func, user_data, num_events_in_wait_list,
-                         event_wait_list, event, CL_COMMAND_SVM_FREE);
-}
-
-cl_int
-clover::EnqueueSVMMemcpy(cl_command_queue d_q,
-                         cl_bool blocking_copy,
-                         void *dst_ptr,
-                         const void *src_ptr,
-                         size_t size,
-                         cl_uint num_events_in_wait_list,
-                         const cl_event *event_wait_list,
-                         cl_event *event,
-                         cl_int cmd) try {
-   auto &q = obj(d_q);
-
-   if (!q.device().svm_support())
-      return CL_INVALID_OPERATION;
-
-   if (dst_ptr == nullptr || src_ptr == nullptr)
-      return CL_INVALID_VALUE;
-
-   if (static_cast<size_t>(abs(reinterpret_cast<ptrdiff_t>(dst_ptr) -
-                               reinterpret_cast<ptrdiff_t>(src_ptr))) < size)
-      return CL_MEM_COPY_OVERLAP;
-
-
-   bool can_emulate = q.device().has_system_svm();
-   auto deps = objs<wait_list_tag>(event_wait_list, num_events_in_wait_list);
-
-   validate_common(q, deps);
-
-   if (can_emulate) {
-      auto hev = create<hard_event>(q, cmd, deps,
-         [=](clover::event &) {
-            memcpy(dst_ptr, src_ptr, size);
-         });
-
-      if (blocking_copy)
-         hev().wait();
-      ret_object(event, hev);
-      return CL_SUCCESS;
-   }
-
-   CLOVER_NOT_SUPPORTED_UNTIL("2.0");
-   return CL_INVALID_VALUE;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueSVMMemcpy(cl_command_queue d_q,
-                   cl_bool blocking_copy,
-                   void *dst_ptr,
-                   const void *src_ptr,
-                   size_t size,
-                   cl_uint num_events_in_wait_list,
-                   const cl_event *event_wait_list,
-                   cl_event *event) {
-
-   return EnqueueSVMMemcpy(d_q, blocking_copy, dst_ptr, src_ptr,
-                           size, num_events_in_wait_list, event_wait_list,
-                           event, CL_COMMAND_SVM_MEMCPY);
-}
-
-cl_int
-clover::EnqueueSVMMemFill(cl_command_queue d_q,
-                          void *svm_ptr,
-                          const void *pattern,
-                          size_t pattern_size,
-                          size_t size,
-                          cl_uint num_events_in_wait_list,
-                          const cl_event *event_wait_list,
-                          cl_event *event,
-                          cl_int cmd) try {
-   auto &q = obj(d_q);
-
-   if (!q.device().svm_support())
-      return CL_INVALID_OPERATION;
-
-   if (svm_ptr == nullptr || pattern == nullptr ||
-       !util_is_power_of_two_nonzero_uintptr(pattern_size) ||
-       pattern_size > 128 ||
-       !ptr_is_aligned(svm_ptr, pattern_size) ||
-       size % pattern_size)
-      return CL_INVALID_VALUE;
-
-   bool can_emulate = q.device().has_system_svm();
-   auto deps = objs<wait_list_tag>(event_wait_list, num_events_in_wait_list);
-
-   validate_common(q, deps);
-
-   if (can_emulate) {
-      auto hev = create<hard_event>(q, cmd, deps,
-         [=](clover::event &) {
-            void *ptr = svm_ptr;
-            for (size_t s = size; s; s -= pattern_size) {
-               memcpy(ptr, pattern, pattern_size);
-               ptr = static_cast<uint8_t*>(ptr) + pattern_size;
-            }
-         });
-
-      ret_object(event, hev);
-      return CL_SUCCESS;
-   }
-
-   CLOVER_NOT_SUPPORTED_UNTIL("2.0");
-   return CL_INVALID_VALUE;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueSVMMemFill(cl_command_queue d_q,
-                    void *svm_ptr,
-                    const void *pattern,
-                    size_t pattern_size,
-                    size_t size,
-                    cl_uint num_events_in_wait_list,
-                    const cl_event *event_wait_list,
-                    cl_event *event) {
-
-   return EnqueueSVMMemFill(d_q, svm_ptr, pattern, pattern_size,
-                            size, num_events_in_wait_list, event_wait_list,
-                            event, CL_COMMAND_SVM_MEMFILL);
-}
-
-cl_int
-clover::EnqueueSVMMap(cl_command_queue d_q,
-                      cl_bool blocking_map,
-                      cl_map_flags map_flags,
-                      void *svm_ptr,
-                      size_t size,
-                      cl_uint num_events_in_wait_list,
-                      const cl_event *event_wait_list,
-                      cl_event *event,
-                      cl_int cmd) try {
-   auto &q = obj(d_q);
-
-   if (!q.device().svm_support())
-      return CL_INVALID_OPERATION;
-
-   if (svm_ptr == nullptr || size == 0)
-      return CL_INVALID_VALUE;
-
-   bool can_emulate = q.device().has_system_svm();
-   auto deps = objs<wait_list_tag>(event_wait_list, num_events_in_wait_list);
-
-   validate_common(q, deps);
-
-   if (can_emulate) {
-      auto hev = create<hard_event>(q, cmd, deps,
-         [](clover::event &) { });
-
-      ret_object(event, hev);
-      return CL_SUCCESS;
-   }
-
-   CLOVER_NOT_SUPPORTED_UNTIL("2.0");
-   return CL_INVALID_VALUE;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueSVMMap(cl_command_queue d_q,
-                cl_bool blocking_map,
-                cl_map_flags map_flags,
-                void *svm_ptr,
-                size_t size,
-                cl_uint num_events_in_wait_list,
-                const cl_event *event_wait_list,
-                cl_event *event) {
-
-   return EnqueueSVMMap(d_q, blocking_map, map_flags, svm_ptr, size,
-                        num_events_in_wait_list, event_wait_list, event,
-                        CL_COMMAND_SVM_MAP);
-}
-
-cl_int
-clover::EnqueueSVMUnmap(cl_command_queue d_q,
-                        void *svm_ptr,
-                        cl_uint num_events_in_wait_list,
-                        const cl_event *event_wait_list,
-                        cl_event *event,
-                        cl_int cmd) try {
-   auto &q = obj(d_q);
-
-   if (!q.device().svm_support())
-      return CL_INVALID_OPERATION;
-
-   if (svm_ptr == nullptr)
-      return CL_INVALID_VALUE;
-
-   bool can_emulate = q.device().has_system_svm();
-   auto deps = objs<wait_list_tag>(event_wait_list, num_events_in_wait_list);
-
-   validate_common(q, deps);
-
-   if (can_emulate) {
-      auto hev = create<hard_event>(q, cmd, deps,
-         [](clover::event &) { });
-
-      ret_object(event, hev);
-      return CL_SUCCESS;
-   }
-
-   CLOVER_NOT_SUPPORTED_UNTIL("2.0");
-   return CL_INVALID_VALUE;
-
-} catch (error &e) {
-   return e.get();
-}
-
-CLOVER_API cl_int
-clEnqueueSVMUnmap(cl_command_queue d_q,
-                  void *svm_ptr,
-                  cl_uint num_events_in_wait_list,
-                  const cl_event *event_wait_list,
-                  cl_event *event) {
-
-   return EnqueueSVMUnmap(d_q, svm_ptr, num_events_in_wait_list,
-                          event_wait_list, event, CL_COMMAND_SVM_UNMAP);
-}
-
-CLOVER_API cl_int
-clEnqueueSVMMigrateMem(cl_command_queue d_q,
-                       cl_uint num_svm_pointers,
-                       const void **svm_pointers,
-                       const size_t *sizes,
-                       const cl_mem_migration_flags flags,
-                       cl_uint num_deps,
-                       const cl_event *d_deps,
-                       cl_event *rd_ev) try {
-   auto &q = obj(d_q);
-   auto deps = objs<wait_list_tag>(d_deps, num_deps);
-
-   validate_common(q, deps);
-   validate_mem_migration_flags(flags);
-
-   if (!q.device().svm_support())
-      return CL_INVALID_OPERATION;
-
-   if (!num_svm_pointers || !svm_pointers)
-      return CL_INVALID_VALUE;
-
-   std::vector<size_t> sizes_copy(num_svm_pointers);
-   std::vector<const void*>  ptrs(num_svm_pointers);
-
-   for (unsigned i = 0; i < num_svm_pointers; ++i) {
-      const void *ptr = svm_pointers[i];
-      size_t size = sizes ? sizes[i] : 0;
-      if (!ptr)
-         return CL_INVALID_VALUE;
-
-      auto p = q.context().find_svm_allocation(ptr);
-      if (!p.first)
-         return CL_INVALID_VALUE;
-
-      std::ptrdiff_t pdiff = (uint8_t*)ptr - (uint8_t*)p.first;
-      if (size && size + pdiff > p.second)
-         return CL_INVALID_VALUE;
-
-      sizes_copy[i] = size ? size : p.second;
-      ptrs[i] = size ? svm_pointers[i] : p.first;
-   }
-
-   auto hev = create<hard_event>(
-      q, CL_COMMAND_MIGRATE_MEM_OBJECTS, deps,
-      [=, &q](event &) {
-         q.svm_migrate(ptrs, sizes_copy, flags);
-      });
-
-   ret_object(rd_ev, hev);
-   return CL_SUCCESS;
-
-} catch (error &e) {
-   return e.get();
-}
diff --git a/src/gallium/frontends/clover/api/util.hpp b/src/gallium/frontends/clover/api/util.hpp
deleted file mode 100644
index 788c99adbd2..00000000000
--- a/src/gallium/frontends/clover/api/util.hpp
+++ /dev/null
@@ -1,88 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_API_UTIL_HPP
-#define CLOVER_API_UTIL_HPP
-
-#include <cassert>
-#include <iostream>
-
-#include "core/error.hpp"
-#include "core/property.hpp"
-#include "util/algorithm.hpp"
-#include "util/detect_os.h"
-
-#if DETECT_OS_WINDOWS
-#define CLOVER_API
-#define CLOVER_ICD_API
-#elif HAVE_CLOVER_ICD
-#define CLOVER_API
-#define CLOVER_ICD_API PUBLIC
-#else
-#define CLOVER_API PUBLIC
-#define CLOVER_ICD_API PUBLIC
-#endif
-
-#define CLOVER_NOT_SUPPORTED_UNTIL(version)                    \
-   do {                                                        \
-      std::cerr << "CL user error: " << __func__               \
-                << "() requires OpenCL version " << (version)  \
-                << " or greater." << std::endl;                \
-   } while (0)
-
-namespace clover {
-   ///
-   /// Return an error code in \a p if non-zero.
-   ///
-   inline void
-   ret_error(cl_int *p, const clover::error &e) {
-      if (p)
-         *p = e.get();
-   }
-
-   ///
-   /// Return a clover object in \a p if non-zero incrementing the
-   /// reference count of the object.
-   ///
-   template<typename T>
-   void
-   ret_object(typename T::descriptor_type **p,
-              const intrusive_ref<T> &v) {
-      if (p) {
-         v().retain();
-         *p = desc(v());
-      }
-   }
-
-   ///
-   /// Return an API object from an intrusive reference to a Clover object,
-   /// incrementing the reference count of the object.
-   ///
-   template<typename T>
-   typename T::descriptor_type *
-   ret_object(const intrusive_ref<T> &v) {
-      v().retain();
-      return desc(v());
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/binary.cpp b/src/gallium/frontends/clover/core/binary.cpp
deleted file mode 100644
index 3bc3fe14bdb..00000000000
--- a/src/gallium/frontends/clover/core/binary.cpp
+++ /dev/null
@@ -1,243 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include <type_traits>
-#include <iostream>
-
-#include "core/binary.hpp"
-
-using namespace clover;
-
-namespace {
-   template<typename T, typename = void>
-   struct _serializer;
-
-   /// Serialize the specified object.
-   template<typename T>
-   void
-   _proc(std::ostream &os, const T &x) {
-      _serializer<T>::proc(os, x);
-   }
-
-   /// Deserialize the specified object.
-   template<typename T>
-   void
-   _proc(std::istream &is, T &x) {
-      _serializer<T>::proc(is, x);
-   }
-
-   template<typename T>
-   T
-   _proc(std::istream &is) {
-      T x;
-      _serializer<T>::proc(is, x);
-      return x;
-   }
-
-   /// Calculate the size of the specified object.
-   template<typename T>
-   void
-   _proc(binary::size_t &sz, const T &x) {
-      _serializer<T>::proc(sz, x);
-   }
-
-   /// (De)serialize a scalar value.
-   template<typename T>
-   struct _serializer<T, typename std::enable_if<
-                            std::is_scalar<T>::value>::type> {
-      static void
-      proc(std::ostream &os, const T &x) {
-         os.write(reinterpret_cast<const char *>(&x), sizeof(x));
-      }
-
-      static void
-      proc(std::istream &is, T &x) {
-         is.read(reinterpret_cast<char *>(&x), sizeof(x));
-      }
-
-      static void
-      proc(binary::size_t &sz, const T &x) {
-         sz += sizeof(x);
-      }
-   };
-
-   /// (De)serialize a vector.
-   template<typename T>
-   struct _serializer<std::vector<T>,
-                      typename std::enable_if<
-                         !std::is_scalar<T>::value>::type> {
-      static void
-      proc(std::ostream &os, const std::vector<T> &v) {
-         _proc<uint32_t>(os, v.size());
-
-         for (size_t i = 0; i < v.size(); i++)
-            _proc<T>(os, v[i]);
-      }
-
-      static void
-      proc(std::istream &is, std::vector<T> &v) {
-         v.resize(_proc<uint32_t>(is));
-
-         for (size_t i = 0; i < v.size(); i++)
-            new(&v[i]) T(_proc<T>(is));
-      }
-
-      static void
-      proc(binary::size_t &sz, const std::vector<T> &v) {
-         sz += sizeof(uint32_t);
-
-         for (size_t i = 0; i < v.size(); i++)
-            _proc<T>(sz, v[i]);
-      }
-   };
-
-   template<typename T>
-   struct _serializer<std::vector<T>,
-                      typename std::enable_if<
-                         std::is_scalar<T>::value>::type> {
-      static void
-      proc(std::ostream &os, const std::vector<T> &v) {
-         _proc<uint32_t>(os, v.size());
-         os.write(reinterpret_cast<const char *>(&v[0]),
-                  v.size() * sizeof(T));
-      }
-
-      static void
-      proc(std::istream &is, std::vector<T> &v) {
-         v.resize(_proc<uint32_t>(is));
-         is.read(reinterpret_cast<char *>(&v[0]),
-                 v.size() * sizeof(T));
-      }
-
-      static void
-      proc(binary::size_t &sz, const std::vector<T> &v) {
-         sz += sizeof(uint32_t) + sizeof(T) * v.size();
-      }
-   };
-
-   /// (De)serialize a string.
-   template<>
-   struct _serializer<std::string> {
-      static void
-      proc(std::ostream &os, const std::string &s) {
-         _proc<uint32_t>(os, s.size());
-         os.write(&s[0], s.size() * sizeof(std::string::value_type));
-      }
-
-      static void
-      proc(std::istream &is, std::string &s) {
-         s.resize(_proc<uint32_t>(is));
-         is.read(&s[0], s.size() * sizeof(std::string::value_type));
-      }
-
-      static void
-      proc(binary::size_t &sz, const std::string &s) {
-         sz += sizeof(uint32_t) + sizeof(std::string::value_type) * s.size();
-      }
-   };
-
-   /// (De)serialize a printf format
-   template<>
-   struct _serializer<binary::printf_info> {
-      template<typename S, typename QT>
-      static void
-      proc(S & s, QT &x) {
-         _proc(s, x.arg_sizes);
-         _proc(s, x.strings);
-      }
-   };
-
-   /// (De)serialize a binary::section.
-   template<>
-   struct _serializer<binary::section> {
-      template<typename S, typename QT>
-      static void
-      proc(S &s, QT &x) {
-         _proc(s, x.id);
-         _proc(s, x.type);
-         _proc(s, x.size);
-         _proc(s, x.data);
-      }
-   };
-
-   /// (De)serialize a binary::argument.
-   template<>
-   struct _serializer<binary::argument> {
-      template<typename S, typename QT>
-      static void
-      proc(S &s, QT &x) {
-         _proc(s, x.type);
-         _proc(s, x.size);
-         _proc(s, x.target_size);
-         _proc(s, x.target_align);
-         _proc(s, x.ext_type);
-         _proc(s, x.semantic);
-      }
-   };
-
-   /// (De)serialize a binary::symbol.
-   template<>
-   struct _serializer<binary::symbol> {
-      template<typename S, typename QT>
-      static void
-      proc(S &s, QT &x) {
-         _proc(s, x.name);
-         _proc(s, x.attributes);
-         _proc(s, x.reqd_work_group_size);
-         _proc(s, x.section);
-         _proc(s, x.offset);
-         _proc(s, x.args);
-      }
-   };
-
-   /// (De)serialize a binary.
-   template<>
-   struct _serializer<binary> {
-      template<typename S, typename QT>
-      static void
-      proc(S &s, QT &x) {
-         _proc(s, x.syms);
-         _proc(s, x.secs);
-         _proc(s, x.printf_infos);
-         _proc(s, x.printf_strings_in_buffer);
-      }
-   };
-};
-
-namespace clover {
-   void
-   binary::serialize(std::ostream &os) const {
-      _proc(os, *this);
-   }
-
-   binary
-   binary::deserialize(std::istream &is) {
-      return _proc<binary>(is);
-   }
-
-   binary::size_t
-   binary::size() const {
-      size_t sz = 0;
-      _proc(sz, *this);
-      return sz;
-   }
-}
diff --git a/src/gallium/frontends/clover/core/binary.hpp b/src/gallium/frontends/clover/core/binary.hpp
deleted file mode 100644
index a854453b550..00000000000
--- a/src/gallium/frontends/clover/core/binary.hpp
+++ /dev/null
@@ -1,169 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_BINARY_HPP
-#define CLOVER_CORE_BINARY_HPP
-
-#include <vector>
-#include <string>
-
-#include "CL/cl.h"
-
-namespace clover {
-   struct binary {
-      typedef uint32_t resource_id;
-      typedef uint32_t size_t;
-
-      struct section {
-         enum type {
-            text_intermediate,
-            text_library,
-            text_executable,
-            data_constant,
-            data_global,
-            data_local,
-            data_private
-         };
-
-         section(resource_id id, enum type type, size_t size,
-                 const std::vector<char> &data) :
-                 id(id), type(type), size(size), data(data) { }
-         section() : id(0), type(text_intermediate), size(0), data() { }
-
-         resource_id id;
-         type type;
-         size_t size;
-         std::vector<char> data;
-      };
-
-      struct printf_info {
-         std::vector<uint32_t> arg_sizes;
-         std::vector<char> strings;
-      };
-
-      struct arg_info {
-         arg_info(const std::string &arg_name, const std::string &type_name,
-                  const cl_kernel_arg_type_qualifier type_qualifier,
-                  const cl_kernel_arg_address_qualifier address_qualifier,
-                  const cl_kernel_arg_access_qualifier access_qualifier) :
-            arg_name(arg_name), type_name(type_name),
-            type_qualifier(type_qualifier),
-            address_qualifier(address_qualifier),
-            access_qualifier(access_qualifier) { };
-         arg_info() : arg_name(""), type_name(""), type_qualifier(0),
-            address_qualifier(0), access_qualifier(0) { };
-
-         std::string arg_name;
-         std::string type_name;
-         cl_kernel_arg_type_qualifier type_qualifier;
-         cl_kernel_arg_address_qualifier address_qualifier;
-         cl_kernel_arg_access_qualifier access_qualifier;
-      };
-
-      struct argument {
-         enum type {
-            scalar,
-            constant,
-            global,
-            local,
-            image_rd,
-            image_wr,
-            sampler
-         };
-
-         enum ext_type {
-            zero_ext,
-            sign_ext
-         };
-
-         enum semantic {
-            general,
-            grid_dimension,
-            grid_offset,
-            image_size,
-            image_format,
-            constant_buffer,
-            printf_buffer
-         };
-
-         argument(enum type type, size_t size,
-                  size_t target_size, size_t target_align,
-                  enum ext_type ext_type,
-                  enum semantic semantic = general) :
-            type(type), size(size),
-            target_size(target_size), target_align(target_align),
-            ext_type(ext_type), semantic(semantic) { }
-
-         argument(enum type type, size_t size) :
-            type(type), size(size),
-            target_size(size), target_align(1),
-            ext_type(zero_ext), semantic(general) { }
-
-         argument() : type(scalar), size(0),
-                      target_size(0), target_align(1),
-                      ext_type(zero_ext), semantic(general) { }
-
-         type type;
-         size_t size;
-         size_t target_size;
-         size_t target_align; // For arguments of type local, this represents
-                              // the alignment requirement for the pointed
-                              // type and for the pointer itself.
-         ext_type ext_type;
-         semantic semantic;
-         arg_info info;
-      };
-
-      struct symbol {
-         symbol(const std::string &name, const std::string &attributes,
-                const std::vector<::size_t> &reqd_work_group_size,
-                resource_id section, size_t offset,
-                const std::vector<argument> &args) :
-            name(name), attributes(attributes),
-            reqd_work_group_size(reqd_work_group_size),
-            section(section),
-            offset(offset), args(args) { }
-         symbol() : name(), attributes(), reqd_work_group_size({0, 0, 0}),
-            section(0), offset(0), args() { }
-
-         std::string name;
-         std::string attributes;
-         std::vector<::size_t> reqd_work_group_size;
-         resource_id section;
-         size_t offset;
-         std::vector<argument> args;
-      };
-
-      binary() : printf_strings_in_buffer(0) { }
-      void serialize(std::ostream &os) const;
-      static binary deserialize(std::istream &is);
-      size_t size() const;
-
-      std::vector<symbol> syms;
-      std::vector<section> secs;
-      std::vector<printf_info> printf_infos;
-      // printfs strings stored in output buffer
-      uint32_t printf_strings_in_buffer;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/compiler.hpp b/src/gallium/frontends/clover/core/compiler.hpp
deleted file mode 100644
index c598a9ea879..00000000000
--- a/src/gallium/frontends/clover/core/compiler.hpp
+++ /dev/null
@@ -1,62 +0,0 @@
-//
-// Copyright 2019 Red Hat, Inc.
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_COMPILER_HPP
-#define CLOVER_CORE_COMPILER_HPP
-
-#include "core/device.hpp"
-#include "core/binary.hpp"
-#include "llvm/invocation.hpp"
-
-namespace clover {
-   namespace compiler {
-      static inline binary
-      compile_program(const program &prog, const header_map &headers,
-                      const device &dev, const std::string &opts,
-                      std::string &log) {
-         switch (dev.ir_format()) {
-         case PIPE_SHADER_IR_NATIVE:
-            if (prog.il_type() == program::il_type::source)
-               return llvm::compile_program(prog.source(), headers, dev, opts, log);
-            else
-               throw error(CL_INVALID_VALUE);
-         default:
-            unreachable("device with unsupported IR");
-            throw error(CL_INVALID_VALUE);
-         }
-      }
-
-      static inline binary
-      link_program(const std::vector<binary> &bs, const device &dev,
-                   const std::string &opts, std::string &log) {
-         switch (dev.ir_format()) {
-         case PIPE_SHADER_IR_NATIVE:
-            return llvm::link_program(bs, dev, opts, log);
-         default:
-            unreachable("device with unsupported IR");
-            throw error(CL_INVALID_VALUE);
-         }
-      }
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/context.cpp b/src/gallium/frontends/clover/core/context.cpp
deleted file mode 100644
index d81fbeca8b8..00000000000
--- a/src/gallium/frontends/clover/core/context.cpp
+++ /dev/null
@@ -1,92 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/context.hpp"
-
-using namespace clover;
-
-context::context(const property_list &props,
-                 const ref_vector<device> &devs,
-                 const notify_action &notify) :
-   notify(notify), props(props), devs(devs) {
-}
-
-context::~context() {
-   while (_destroy_notify.size()) {
-      _destroy_notify.top()();
-      _destroy_notify.pop();
-   }
-}
-
-bool
-context::operator==(const context &ctx) const {
-   return this == &ctx;
-}
-
-bool
-context::operator!=(const context &ctx) const {
-   return this != &ctx;
-}
-
-void
-context::destroy_notify(std::function<void ()> f) {
-   _destroy_notify.push(f);
-}
-
-const context::property_list &
-context::properties() const {
-   return props;
-}
-
-context::device_range
-context::devices() const {
-   return map(evals(), devs);
-}
-
-void
-context::add_svm_allocation(const void *ptr, size_t size) {
-   svm_ptrs.emplace(ptr, size);
-}
-
-void
-context::remove_svm_allocation(const void *ptr) {
-   svm_ptrs.erase(ptr);
-}
-
-context::svm_pointer_map::value_type
-context::find_svm_allocation(const void *ptr) const {
-   // std::prev on an iterator of an empty container causes SIGSEGVs
-   if (svm_ptrs.empty())
-      return { nullptr, 0 };
-
-   auto it = std::prev(svm_ptrs.upper_bound(ptr));
-   if (it == svm_ptrs.end())
-      return { nullptr, 0 };
-
-   uintptr_t base = reinterpret_cast<uintptr_t>((*it).first);
-   uintptr_t end  = (*it).second + base;
-   uintptr_t ptrv = reinterpret_cast<uintptr_t>(ptr);
-   if (ptrv >= base && ptrv < end)
-      return *it;
-
-   return { nullptr, 0 };
-}
diff --git a/src/gallium/frontends/clover/core/context.hpp b/src/gallium/frontends/clover/core/context.hpp
deleted file mode 100644
index 2ecde235182..00000000000
--- a/src/gallium/frontends/clover/core/context.hpp
+++ /dev/null
@@ -1,86 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_CONTEXT_HPP
-#define CLOVER_CORE_CONTEXT_HPP
-
-#include <map>
-#include <stack>
-
-#include "core/object.hpp"
-#include "core/device.hpp"
-#include "core/property.hpp"
-
-namespace clover {
-   class context : public ref_counter, public _cl_context {
-   private:
-      typedef adaptor_range<
-            evals, const std::vector<intrusive_ref<device>> &
-         > device_range;
-      typedef clover::property_list<cl_context_properties> property_list;
-
-   public:
-      ~context();
-
-      typedef std::function<void (const char *)> notify_action;
-      typedef std::map<const void *, size_t> svm_pointer_map;
-
-      context(const property_list &props, const ref_vector<device> &devs,
-              const notify_action &notify);
-
-      context(const context &ctx) = delete;
-      context &
-      operator=(const context &ctx) = delete;
-
-      bool
-      operator==(const context &ctx) const;
-      bool
-      operator!=(const context &ctx) const;
-
-      void destroy_notify(std::function<void ()> f);
-
-      const property_list &
-      properties() const;
-
-      device_range
-      devices() const;
-
-      void
-      add_svm_allocation(const void *ptr, size_t size);
-
-      void
-      remove_svm_allocation(const void *ptr);
-
-      svm_pointer_map::value_type
-      find_svm_allocation(const void *ptr) const;
-
-      const notify_action notify;
-
-   private:
-      property_list props;
-      const std::vector<intrusive_ref<device>> devs;
-      std::stack<std::function<void ()>> _destroy_notify;
-      svm_pointer_map svm_ptrs;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/device.cpp b/src/gallium/frontends/clover/core/device.cpp
deleted file mode 100644
index 2de4c5268ee..00000000000
--- a/src/gallium/frontends/clover/core/device.cpp
+++ /dev/null
@@ -1,559 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include <algorithm>
-#include "core/device.hpp"
-#include "core/platform.hpp"
-#include "pipe/p_screen.h"
-#include "pipe/p_state.h"
-#include "util/bitscan.h"
-#include "util/disk_cache.h"
-#include "util/u_debug.h"
-#include "nir.h"
-#include <fstream>
-
-using namespace clover;
-
-namespace {
-   cl_version
-   get_highest_supported_version(const device &dev) {
-      // All the checks below assume that the device supports FULL_PROFILE
-      // (which is the only profile support by clover) and that a device is
-      // not CUSTOM.
-      assert(dev.type() != CL_DEVICE_TYPE_CUSTOM);
-
-      cl_version version = CL_MAKE_VERSION(0, 0, 0);
-
-      const auto has_extension =
-         [extensions = dev.supported_extensions()](const char *extension_name){
-            return std::find_if(extensions.begin(), extensions.end(),
-                  [extension_name](const cl_name_version &extension){
-                     return strcmp(extension.name, extension_name) == 0;
-               }) != extensions.end();
-      };
-      const bool supports_images = dev.image_support();
-
-      // Check requirements for OpenCL 1.0
-      if (dev.max_compute_units() < 1 ||
-          dev.max_block_size().size() < 3 ||
-          // TODO: Check CL_DEVICE_MAX_WORK_ITEM_SIZES
-          dev.max_threads_per_block() < 1 ||
-          (dev.address_bits() != 32 && dev.address_bits() != 64) ||
-          dev.max_mem_alloc_size() < std::max(dev.max_mem_global() / 4,
-                                              (cl_ulong)128 * 1024 * 1024) ||
-          dev.max_mem_input() < 256 ||
-          dev.max_const_buffer_size() < 64 * 1024 ||
-          dev.max_const_buffers() < 8 ||
-          dev.max_mem_local() < 16 * 1024 ||
-          dev.clc_version < CL_MAKE_VERSION(1, 0, 0)) {
-         return version;
-      }
-      version = CL_MAKE_VERSION(1, 0, 0);
-
-      // Check requirements for OpenCL 1.1
-      if (!has_extension("cl_khr_byte_addressable_store") ||
-          !has_extension("cl_khr_global_int32_base_atomics") ||
-          !has_extension("cl_khr_global_int32_extended_atomics") ||
-          !has_extension("cl_khr_local_int32_base_atomics") ||
-          !has_extension("cl_khr_local_int32_extended_atomics") ||
-          // OpenCL 1.1 increased the minimum value for
-          // CL_DEVICE_MAX_PARAMETER_SIZE to 1024 bytes.
-          dev.max_mem_input() < 1024 ||
-          dev.mem_base_addr_align() < sizeof(cl_long16) ||
-          // OpenCL 1.1 increased the minimum value for
-          // CL_DEVICE_LOCAL_MEM_SIZE to 32 KB.
-          dev.max_mem_local() < 32 * 1024 ||
-          dev.clc_version < CL_MAKE_VERSION(1, 1, 0)) {
-         return version;
-      }
-      version = CL_MAKE_VERSION(1, 1, 0);
-
-      // Check requirements for OpenCL 1.2
-      if ((dev.has_doubles() && !has_extension("cl_khr_fp64")) ||
-          dev.clc_version < CL_MAKE_VERSION(1, 2, 0) ||
-          dev.max_printf_buffer_size() < 1 * 1024 * 1024 ||
-          (supports_images &&
-           (dev.max_image_buffer_size()  < 65536 ||
-            dev.max_image_array_number() < 2048))) {
-         return version;
-      }
-      version = CL_MAKE_VERSION(1, 2, 0);
-
-      // Check requirements for OpenCL 3.0
-      if (dev.max_mem_alloc_size() < std::max(std::min((cl_ulong)1024 * 1024 * 1024,
-                                                       dev.max_mem_global() / 4),
-                                              (cl_ulong)128 * 1024 * 1024) ||
-          // TODO: If pipes are supported, check:
-          //       * CL_DEVICE_MAX_PIPE_ARGS
-          //       * CL_DEVICE_PIPE_MAX_ACTIVE_RESERVATIONS
-          //       * CL_DEVICE_PIPE_MAX_PACKET_SIZE
-          // TODO: If on-device queues are supported, check:
-          //       * CL_DEVICE_QUEUE_ON_DEVICE_PROPERTIES
-          //       * CL_DEVICE_QUEUE_ON_DEVICE_PREFERRED_SIZE
-          //       * CL_DEVICE_QUEUE_ON_DEVICE_MAX_SIZE
-          //       * CL_DEVICE_MAX_ON_DEVICE_QUEUES
-          //       * CL_DEVICE_MAX_ON_DEVICE_EVENTS
-          dev.clc_version < CL_MAKE_VERSION(3, 0, 0) ||
-          (supports_images &&
-           (dev.max_images_write() < 64 ||
-            dev.max_image_size() < 16384))) {
-         return version;
-      }
-      version = CL_MAKE_VERSION(3, 0, 0);
-
-      return version;
-   }
-
-   static cl_device_type
-   parse_env_device_type() {
-      const char* val = getenv("CLOVER_DEVICE_TYPE");
-      if (!val) {
-         return 0;
-      }
-      if (strcmp(val, "cpu") == 0) {
-         return CL_DEVICE_TYPE_CPU;
-      }
-      if (strcmp(val, "gpu") == 0) {
-         return CL_DEVICE_TYPE_GPU;
-      }
-      if (strcmp(val, "accelerator") == 0) {
-         return CL_DEVICE_TYPE_ACCELERATOR;
-      }
-      /* CL_DEVICE_TYPE_CUSTOM isn't implemented
-      because CL_DEVICE_TYPE_CUSTOM is OpenCL 1.2
-      and Clover is OpenCL 1.1. */
-      return 0;
-   }
-}
-
-device::device(clover::platform &platform, pipe_loader_device *ldev) :
-   platform(platform), clc_cache(NULL), ldev(ldev) {
-   pipe = pipe_loader_create_screen(ldev, false);
-   if (pipe && pipe->caps.compute) {
-      const bool has_supported_ir = supports_ir(PIPE_SHADER_IR_NATIVE);
-      if (has_supported_ir) {
-         unsigned major = 1, minor = 1;
-         debug_get_version_option("CLOVER_DEVICE_CLC_VERSION_OVERRIDE",
-                                  &major, &minor);
-         clc_version = CL_MAKE_VERSION(major, minor, 0);
-
-         version = get_highest_supported_version(*this);
-         major = CL_VERSION_MAJOR(version);
-         minor = CL_VERSION_MINOR(version);
-         debug_get_version_option("CLOVER_DEVICE_VERSION_OVERRIDE", &major,
-                                  &minor);
-         version = CL_MAKE_VERSION(major, minor, 0);
-
-      }
-
-      if (supports_ir(PIPE_SHADER_IR_NATIVE))
-         return;
-   }
-   if (pipe)
-      pipe->destroy(pipe);
-   throw error(CL_INVALID_DEVICE);
-}
-
-device::~device() {
-   if (clc_cache)
-      disk_cache_destroy(clc_cache);
-   if (pipe)
-      pipe->destroy(pipe);
-   if (ldev)
-      pipe_loader_release(&ldev, 1);
-}
-
-bool
-device::operator==(const device &dev) const {
-   return this == &dev;
-}
-
-cl_device_type
-device::type() const {
-   cl_device_type type = parse_env_device_type();
-   if (type != 0) {
-      return type;
-   }
-
-   switch (ldev->type) {
-   case PIPE_LOADER_DEVICE_SOFTWARE:
-      return CL_DEVICE_TYPE_CPU;
-   case PIPE_LOADER_DEVICE_PCI:
-   case PIPE_LOADER_DEVICE_PLATFORM:
-      return CL_DEVICE_TYPE_GPU;
-   default:
-      unreachable("Unknown device type.");
-   }
-}
-
-cl_uint
-device::vendor_id() const {
-   switch (ldev->type) {
-   case PIPE_LOADER_DEVICE_SOFTWARE:
-   case PIPE_LOADER_DEVICE_PLATFORM:
-      return 0;
-   case PIPE_LOADER_DEVICE_PCI:
-      return ldev->u.pci.vendor_id;
-   default:
-      unreachable("Unknown device type.");
-   }
-}
-
-size_t
-device::max_images_read() const {
-   return pipe->shader_caps[PIPE_SHADER_COMPUTE].max_sampler_views;
-}
-
-size_t
-device::max_images_write() const {
-   return pipe->shader_caps[PIPE_SHADER_COMPUTE].max_shader_images;
-}
-
-size_t
-device::max_image_buffer_size() const {
-   return pipe->caps.max_texel_buffer_elements;
-}
-
-cl_uint
-device::max_image_size() const {
-   return pipe->caps.max_texture_2d_size;
-}
-
-cl_uint
-device::max_image_size_3d() const {
-   return 1 << (pipe->caps.max_texture_3d_levels - 1);
-}
-
-size_t
-device::max_image_array_number() const {
-   return pipe->caps.max_texture_array_layers;
-}
-
-cl_uint
-device::max_samplers() const {
-   return pipe->shader_caps[PIPE_SHADER_COMPUTE].max_texture_samplers;
-}
-
-cl_ulong
-device::max_mem_global() const {
-   return pipe->compute_caps.max_global_size;
-}
-
-cl_ulong
-device::max_mem_local() const {
-   return pipe->compute_caps.max_local_size;
-}
-
-cl_ulong
-device::max_mem_input() const {
-   return pipe->compute_caps.max_input_size;
-}
-
-cl_ulong
-device::max_const_buffer_size() const {
-   return pipe->shader_caps[PIPE_SHADER_COMPUTE].max_const_buffer0_size;
-}
-
-cl_uint
-device::max_const_buffers() const {
-   return pipe->shader_caps[PIPE_SHADER_COMPUTE].max_const_buffers;
-}
-
-size_t
-device::max_threads_per_block() const {
-   return pipe->compute_caps.max_threads_per_block_clover;
-}
-
-cl_ulong
-device::max_mem_alloc_size() const {
-   return pipe->compute_caps.max_mem_alloc_size;
-}
-
-cl_uint
-device::max_clock_frequency() const {
-   return pipe->compute_caps.max_clock_frequency;
-}
-
-cl_uint
-device::max_compute_units() const {
-   return pipe->compute_caps.max_compute_units;
-}
-
-cl_uint
-device::max_printf_buffer_size() const {
-   return 1024 * 1024;
-}
-
-bool
-device::image_support() const {
-   bool supports_images = pipe->compute_caps.images_supported;
-   if (!supports_images)
-      return false;
-
-   /* If the gallium driver supports images, but does not support the
-    * minimum requirements for opencl 1.0 images, then don't claim to
-    * support images.
-    */
-   if (max_images_read() < 128 ||
-       max_images_write() < 8 ||
-       max_image_size() < 8192 ||
-       max_image_size_3d() < 2048 ||
-       max_samplers() < 16)
-      return false;
-
-   return true;
-}
-
-bool
-device::has_doubles() const {
-   nir_shader_compiler_options *options =
-         (nir_shader_compiler_options *)pipe->get_compiler_options(pipe,
-                                                                   PIPE_SHADER_IR_NIR,
-                                                                   PIPE_SHADER_COMPUTE);
-   return pipe->caps.doubles &&
-         !(options->lower_doubles_options & nir_lower_fp64_full_software);
-}
-
-bool
-device::has_halves() const {
-   return pipe->shader_caps[PIPE_SHADER_COMPUTE].fp16;
-}
-
-bool
-device::has_int64_atomics() const {
-   return pipe->shader_caps[PIPE_SHADER_COMPUTE].int64_atomics;
-}
-
-bool
-device::has_unified_memory() const {
-   return pipe->caps.uma;
-}
-
-size_t
-device::mem_base_addr_align() const {
-   uint64_t page_size = 0;
-   os_get_page_size(&page_size);
-   return std::max((size_t)page_size, sizeof(cl_long) * 16);
-}
-
-cl_device_svm_capabilities
-device::svm_support() const {
-   // Without CAP_RESOURCE_FROM_USER_MEMORY SVM and CL_MEM_USE_HOST_PTR
-   // interactions won't work according to spec as clover manages a GPU side
-   // copy of the host data.
-   //
-   // The biggest problem are memory buffers created with CL_MEM_USE_HOST_PTR,
-   // but the application and/or the kernel updates the memory via SVM and not
-   // the cl_mem buffer.
-   // We can't even do proper tracking on what memory might have been accessed
-   // as the host ptr to the buffer could be within a SVM region, where through
-   // the CL API there is no reliable way of knowing if a certain cl_mem buffer
-   // was accessed by a kernel or not and the runtime can't reliably know from
-   // which side the GPU buffer content needs to be updated.
-   //
-   // Another unsolvable scenario is a cl_mem object passed by cl_mem reference
-   // and SVM pointer into the same kernel at the same time.
-   if (allows_user_pointers() && pipe->caps.system_svm)
-      // we can emulate all lower levels if we support fine grain system
-      return CL_DEVICE_SVM_FINE_GRAIN_SYSTEM |
-             CL_DEVICE_SVM_COARSE_GRAIN_BUFFER |
-             CL_DEVICE_SVM_FINE_GRAIN_BUFFER;
-   return 0;
-}
-
-bool
-device::allows_user_pointers() const {
-   return pipe->caps.resource_from_user_memory ||
-          pipe->caps.resource_from_user_memory_compute_only;
-}
-
-std::vector<size_t>
-device::max_block_size() const {
-   auto v = pipe->compute_caps.max_block_size_clover;
-   return {v[0], v[1], v[2]};
-}
-
-cl_uint
-device::subgroup_size() const {
-   cl_uint subgroup_sizes = pipe->compute_caps.subgroup_sizes;
-   if (!subgroup_sizes)
-      return 0;
-   return 1 << (util_last_bit(subgroup_sizes) - 1);
-}
-
-cl_uint
-device::address_bits() const {
-   return pipe->compute_caps.address_bits;
-}
-
-std::string
-device::device_name() const {
-   return pipe->get_name(pipe);
-}
-
-std::string
-device::vendor_name() const {
-   return pipe->get_device_vendor(pipe);
-}
-
-enum pipe_shader_ir
-device::ir_format() const {
-   assert(supports_ir(PIPE_SHADER_IR_NATIVE));
-   return PIPE_SHADER_IR_NATIVE;
-}
-
-std::string
-device::ir_target() const {
-   return pipe->compute_caps.ir_target;
-}
-
-enum pipe_endian
-device::endianness() const {
-   return pipe->caps.endianness;
-}
-
-std::string
-device::device_version_as_string() const {
-   static const std::string version_string =
-      std::to_string(CL_VERSION_MAJOR(version)) + "." +
-      std::to_string(CL_VERSION_MINOR(version));
-   return version_string;
-}
-
-std::string
-device::device_clc_version_as_string() const {
-   int major = CL_VERSION_MAJOR(clc_version);
-   int minor = CL_VERSION_MINOR(clc_version);
-
-   /* for CL 3.0 we need this to be 1.2 until we support 2.0. */
-   if (major == 3) {
-      major = 1;
-      minor = 2;
-   }
-   static const std::string version_string =
-      std::to_string(major) + "." +
-      std::to_string(minor);
-   return version_string;
-}
-
-bool
-device::supports_ir(enum pipe_shader_ir ir) const {
-   return pipe->shader_caps[PIPE_SHADER_COMPUTE].supported_irs & (1 << ir);
-}
-
-std::vector<cl_name_version>
-device::supported_extensions() const {
-   std::vector<cl_name_version> vec;
-
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_byte_addressable_store" } );
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_global_int32_base_atomics" } );
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_global_int32_extended_atomics" } );
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_local_int32_base_atomics" } );
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_local_int32_extended_atomics" } );
-   if (has_int64_atomics()) {
-      vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_int64_base_atomics" } );
-      vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_int64_extended_atomics" } );
-   }
-   if (has_doubles())
-      vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_fp64" } );
-   if (has_halves())
-      vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_fp16" } );
-   if (svm_support())
-      vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_arm_shared_virtual_memory" } );
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_extended_versioning" } );
-   return vec;
-}
-
-std::string
-device::supported_extensions_as_string() const {
-   static std::string extensions_string;
-
-   if (!extensions_string.empty())
-      return extensions_string;
-
-   const auto extension_list = supported_extensions();
-   for (const auto &extension : extension_list) {
-      if (!extensions_string.empty())
-         extensions_string += " ";
-      extensions_string += extension.name;
-   }
-   return extensions_string;
-}
-
-std::vector<cl_name_version>
-device::supported_il_versions() const {
-   return {};
-}
-
-const void *
-device::get_compiler_options(enum pipe_shader_ir ir) const {
-   return pipe->get_compiler_options(pipe, ir, PIPE_SHADER_COMPUTE);
-}
-
-cl_version
-device::device_version() const {
-   return version;
-}
-
-cl_version
-device::device_clc_version(bool api) const {
-   /*
-    * For the API we have to limit this to 1.2,
-    * but internally we want 3.0 if it works.
-    */
-   if (!api)
-      return clc_version;
-
-   int major = CL_VERSION_MAJOR(clc_version);
-   /* for CL 3.0 we need this to be 1.2 until we support 2.0. */
-   if (major == 3) {
-      return CL_MAKE_VERSION(1, 2, 0);
-   }
-   return clc_version;
-}
-
-std::vector<cl_name_version>
-device::opencl_c_all_versions() const {
-   std::vector<cl_name_version> vec;
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "OpenCL C" } );
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 1, 0), "OpenCL C" } );
-
-   if (CL_VERSION_MAJOR(clc_version) == 1 &&
-       CL_VERSION_MINOR(clc_version) == 2)
-      vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 2, 0), "OpenCL C" } );
-   if (CL_VERSION_MAJOR(clc_version) == 3) {
-      vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 2, 0), "OpenCL C" } );
-      vec.push_back( cl_name_version{ CL_MAKE_VERSION(3, 0, 0), "OpenCL C" } );
-   }
-   return vec;
-}
-
-std::vector<cl_name_version>
-device::opencl_c_features() const {
-   std::vector<cl_name_version> vec;
-
-   vec.push_back( cl_name_version {CL_MAKE_VERSION(3, 0, 0), "__opencl_c_int64" });
-   if (has_doubles())
-      vec.push_back( cl_name_version {CL_MAKE_VERSION(3, 0, 0), "__opencl_c_fp64" });
-
-   return vec;
-}
diff --git a/src/gallium/frontends/clover/core/device.hpp b/src/gallium/frontends/clover/core/device.hpp
deleted file mode 100644
index 4020ae96269..00000000000
--- a/src/gallium/frontends/clover/core/device.hpp
+++ /dev/null
@@ -1,129 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_DEVICE_HPP
-#define CLOVER_CORE_DEVICE_HPP
-
-#include <set>
-#include <vector>
-
-#include "core/object.hpp"
-#include "core/format.hpp"
-#include "core/binary.hpp"
-#include "util/lazy.hpp"
-#include "pipe-loader/pipe_loader.h"
-
-struct nir_shader;
-struct disk_cache;
-
-namespace clover {
-   class platform;
-   class root_resource;
-   class hard_event;
-
-   class device : public ref_counter, public _cl_device_id {
-   public:
-      device(clover::platform &platform, pipe_loader_device *ldev);
-      ~device();
-
-      device(const device &dev) = delete;
-      device &
-      operator=(const device &dev) = delete;
-
-      bool
-      operator==(const device &dev) const;
-
-      cl_device_type type() const;
-      cl_uint vendor_id() const;
-      size_t max_images_read() const;
-      size_t max_images_write() const;
-      size_t max_image_buffer_size() const;
-      // Use for 1D and 2D images.
-      cl_uint max_image_size() const;
-      // Use for 3D images.
-      cl_uint max_image_size_3d() const;
-      size_t max_image_array_number() const;
-      cl_uint max_samplers() const;
-      cl_ulong max_mem_global() const;
-      cl_ulong max_mem_local() const;
-      cl_ulong max_mem_input() const;
-      cl_ulong max_const_buffer_size() const;
-      cl_uint max_const_buffers() const;
-      size_t max_threads_per_block() const;
-      cl_ulong max_mem_alloc_size() const;
-      cl_uint max_clock_frequency() const;
-      cl_uint max_compute_units() const;
-      cl_uint max_printf_buffer_size() const;
-      bool image_support() const;
-      bool has_doubles() const;
-      bool has_halves() const;
-      bool has_int64_atomics() const;
-      bool has_unified_memory() const;
-      size_t mem_base_addr_align() const;
-      cl_device_svm_capabilities svm_support() const;
-      bool allows_user_pointers() const;
-
-      std::vector<size_t> max_block_size() const;
-      cl_uint subgroup_size() const;
-      cl_uint address_bits() const;
-      std::string device_name() const;
-      std::string vendor_name() const;
-      std::string device_version_as_string() const;
-      std::string device_clc_version_as_string() const;
-      enum pipe_shader_ir ir_format() const;
-      std::string ir_target() const;
-      enum pipe_endian endianness() const;
-      bool supports_ir(enum pipe_shader_ir ir) const;
-      std::string supported_extensions_as_string() const;
-      cl_version device_version() const;
-      cl_version device_clc_version(bool api = false) const;
-      std::vector<cl_name_version> opencl_c_all_versions() const;
-      std::vector<cl_name_version> supported_extensions() const;
-      std::vector<cl_name_version> supported_il_versions() const;
-
-      std::vector<cl_name_version> opencl_c_features() const;
-
-      friend class command_queue;
-      friend class root_resource;
-      friend class hard_event;
-      friend std::set<cl_image_format>
-      supported_formats(const context &, cl_mem_object_type, cl_mem_flags flags);
-      const void *get_compiler_options(enum pipe_shader_ir ir) const;
-
-      clover::platform &platform;
-
-      inline bool
-      has_system_svm() const {
-         return svm_support() & CL_DEVICE_SVM_FINE_GRAIN_SYSTEM;
-      }
-
-      lazy<std::shared_ptr<nir_shader>> clc_nir;
-      disk_cache *clc_cache;
-      cl_version version;
-      cl_version clc_version;
-   private:
-      pipe_screen *pipe;
-      pipe_loader_device *ldev;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/error.hpp b/src/gallium/frontends/clover/core/error.hpp
deleted file mode 100644
index e46c05b865b..00000000000
--- a/src/gallium/frontends/clover/core/error.hpp
+++ /dev/null
@@ -1,207 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_ERROR_HPP
-#define CLOVER_CORE_ERROR_HPP
-
-#include "CL/cl.h"
-#if defined(__ALTIVEC__) && !defined(__APPLE_ALTIVEC__)
-   #undef vector
-   #undef pixel
-   #undef bool
-#endif
-
-#include <stdexcept>
-#include <string>
-
-namespace clover {
-   class command_queue;
-   class context;
-   class device;
-   class event;
-   class hard_event;
-   class soft_event;
-   class kernel;
-   class memory_obj;
-   class buffer;
-   class root_buffer;
-   class sub_buffer;
-   class image;
-   class image2d;
-   class image3d;
-   class platform;
-   class program;
-   class sampler;
-
-   ///
-   /// Class that represents an error that can be converted to an
-   /// OpenCL status code.
-   ///
-   class error : public std::runtime_error {
-   public:
-      error(cl_int code, std::string what = "") :
-         std::runtime_error(what), code(code) {
-      }
-
-      cl_int get() const {
-         return code;
-      }
-
-   protected:
-      cl_int code;
-   };
-
-   class invalid_build_options_error : public error {
-   public:
-      invalid_build_options_error(const std::string &what = "") :
-         error(CL_INVALID_BUILD_OPTIONS, what) {}
-   };
-
-   class build_error : public error {
-   public:
-      build_error(const std::string &what = "") :
-         error(CL_BUILD_PROGRAM_FAILURE, what) {}
-   };
-
-   template<typename O>
-   class invalid_object_error;
-
-   template<>
-   class invalid_object_error<command_queue> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_COMMAND_QUEUE, what) {}
-   };
-
-   template<>
-   class invalid_object_error<context> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_CONTEXT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<device> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_DEVICE, what) {}
-   };
-
-   template<>
-   class invalid_object_error<event> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_EVENT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<soft_event> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_EVENT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<kernel> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_KERNEL, what) {}
-   };
-
-   template<>
-   class invalid_object_error<memory_obj> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_MEM_OBJECT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<buffer> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_MEM_OBJECT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<root_buffer> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_MEM_OBJECT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<sub_buffer> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_MEM_OBJECT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<image> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_MEM_OBJECT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<image2d> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_MEM_OBJECT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<image3d> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_MEM_OBJECT, what) {}
-   };
-
-   template<>
-   class invalid_object_error<platform> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_PLATFORM, what) {}
-   };
-
-   template<>
-   class invalid_object_error<program> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_PROGRAM, what) {}
-   };
-
-   template<>
-   class invalid_object_error<sampler> : public error {
-   public:
-      invalid_object_error(std::string what = "") :
-         error(CL_INVALID_SAMPLER, what) {}
-   };
-
-   class invalid_wait_list_error : public error {
-   public:
-      invalid_wait_list_error(std::string what = "") :
-         error(CL_INVALID_EVENT_WAIT_LIST, what) {}
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/event.cpp b/src/gallium/frontends/clover/core/event.cpp
deleted file mode 100644
index e02a354251e..00000000000
--- a/src/gallium/frontends/clover/core/event.cpp
+++ /dev/null
@@ -1,272 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/event.hpp"
-#include "pipe/p_screen.h"
-
-using namespace clover;
-
-event::event(clover::context &ctx, const ref_vector<event> &deps,
-             action action_ok, action action_fail) :
-   context(ctx), _wait_count(1), _status(0),
-   action_ok(action_ok), action_fail(action_fail) {
-   for (auto &ev : deps)
-      ev.chain(*this);
-}
-
-event::~event() {
-}
-
-std::vector<intrusive_ref<event>>
-event::trigger_self() {
-   std::lock_guard<std::mutex> lock(mutex);
-   std::vector<intrusive_ref<event>> evs;
-
-   if (_wait_count && !--_wait_count)
-      std::swap(_chain, evs);
-
-   cv.notify_all();
-   return evs;
-}
-
-void
-event::trigger() try {
-   if (wait_count() == 1)
-      action_ok(*this);
-
-   for (event &ev : trigger_self())
-      ev.trigger();
-} catch (error &e) {
-   abort(e.get());
-}
-
-std::vector<intrusive_ref<event>>
-event::abort_self(cl_int status) {
-   std::lock_guard<std::mutex> lock(mutex);
-   std::vector<intrusive_ref<event>> evs;
-
-   _status = status;
-   _wait_count = 0;
-   std::swap(_chain, evs);
-
-   cv.notify_all();
-   return evs;
-}
-
-void
-event::abort(cl_int status) {
-   action_fail(*this);
-
-   for (event &ev : abort_self(status))
-      ev.abort(status);
-}
-
-unsigned
-event::wait_count() const {
-   std::lock_guard<std::mutex> lock(mutex);
-   return _wait_count;
-}
-
-bool
-event::signalled() const {
-   return !wait_count();
-}
-
-cl_int
-event::status() const {
-   std::lock_guard<std::mutex> lock(mutex);
-   return _status;
-}
-
-void
-event::chain(event &ev) {
-   std::unique_lock<std::mutex> lock(mutex, std::defer_lock);
-   std::unique_lock<std::mutex> lock_ev(ev.mutex, std::defer_lock);
-   std::lock(lock, lock_ev);
-
-   if (_wait_count) {
-      ev._wait_count++;
-      _chain.push_back(ev);
-   }
-   ev.deps.push_back(*this);
-}
-
-void
-event::wait_signalled() const {
-   std::unique_lock<std::mutex> lock(mutex);
-   cv.wait(lock, [=]{ return !_wait_count; });
-}
-
-void
-event::wait() const {
-   std::vector<intrusive_ref<event>> evs;
-   std::swap(deps, evs);
-
-   for (event &ev : evs)
-      ev.wait();
-
-   wait_signalled();
-}
-
-hard_event::hard_event(command_queue &q, cl_command_type command,
-                       const ref_vector<event> &deps, action action) :
-   event(q.context(), deps, profile(q, action), [](event &ev){}),
-   _queue(q), _command(command), _fence(NULL) {
-   if (q.profiling_enabled())
-      _time_queued = timestamp::current(q);
-
-   q.sequence(*this);
-   trigger();
-}
-
-hard_event::~hard_event() {
-   pipe_screen *screen = queue()->device().pipe;
-   screen->fence_reference(screen, &_fence, NULL);
-}
-
-cl_int
-hard_event::status() const {
-   pipe_screen *screen = queue()->device().pipe;
-
-   if (event::status() < 0)
-      return event::status();
-
-   else if (!_fence)
-      return CL_QUEUED;
-
-   else if (!screen->fence_finish(screen, NULL, _fence, 0))
-      return CL_SUBMITTED;
-
-   else
-      return CL_COMPLETE;
-}
-
-command_queue *
-hard_event::queue() const {
-   return &_queue();
-}
-
-cl_command_type
-hard_event::command() const {
-   return _command;
-}
-
-void
-hard_event::wait() const {
-   pipe_screen *screen = queue()->device().pipe;
-
-   event::wait();
-
-   if (status() == CL_QUEUED)
-      queue()->flush();
-
-   if (!_fence ||
-       !screen->fence_finish(screen, NULL, _fence, OS_TIMEOUT_INFINITE))
-      throw error(CL_EXEC_STATUS_ERROR_FOR_EVENTS_IN_WAIT_LIST);
-}
-
-const lazy<cl_ulong> &
-hard_event::time_queued() const {
-   return _time_queued;
-}
-
-const lazy<cl_ulong> &
-hard_event::time_submit() const {
-   return _time_submit;
-}
-
-const lazy<cl_ulong> &
-hard_event::time_start() const {
-   return _time_start;
-}
-
-const lazy<cl_ulong> &
-hard_event::time_end() const {
-   return _time_end;
-}
-
-void
-hard_event::fence(pipe_fence_handle *fence) {
-   assert(fence);
-   pipe_screen *screen = queue()->device().pipe;
-   screen->fence_reference(screen, &_fence, fence);
-   deps.clear();
-}
-
-event::action
-hard_event::profile(command_queue &q, const action &action) const {
-   if (q.profiling_enabled()) {
-      return [&q, action] (event &ev) {
-         auto &hev = static_cast<hard_event &>(ev);
-
-         hev._time_submit = timestamp::current(q);
-         hev._time_start = timestamp::query(q);
-
-         action(ev);
-
-         hev._time_end = timestamp::query(q);
-      };
-
-   } else {
-      return action;
-   }
-}
-
-soft_event::soft_event(clover::context &ctx, const ref_vector<event> &deps,
-                       bool _trigger, action action) :
-   event(ctx, deps, action, action) {
-   if (_trigger)
-      trigger();
-}
-
-cl_int
-soft_event::status() const {
-   if (event::status() < 0)
-      return event::status();
-
-   else if (!signalled() ||
-            any_of([](const event &ev) {
-                  return ev.status() != CL_COMPLETE;
-               }, deps))
-      return CL_SUBMITTED;
-
-   else
-      return CL_COMPLETE;
-}
-
-command_queue *
-soft_event::queue() const {
-   return NULL;
-}
-
-cl_command_type
-soft_event::command() const {
-   return CL_COMMAND_USER;
-}
-
-void
-soft_event::wait() const {
-   event::wait();
-
-   if (status() != CL_COMPLETE)
-      throw error(CL_EXEC_STATUS_ERROR_FOR_EVENTS_IN_WAIT_LIST);
-}
diff --git a/src/gallium/frontends/clover/core/event.hpp b/src/gallium/frontends/clover/core/event.hpp
deleted file mode 100644
index 5817893d0da..00000000000
--- a/src/gallium/frontends/clover/core/event.hpp
+++ /dev/null
@@ -1,164 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_EVENT_HPP
-#define CLOVER_CORE_EVENT_HPP
-
-#include <condition_variable>
-#include <functional>
-
-#include "core/object.hpp"
-#include "core/queue.hpp"
-#include "core/timestamp.hpp"
-#include "util/lazy.hpp"
-
-namespace clover {
-   ///
-   /// Class that represents a task that might be executed
-   /// asynchronously at some point in the future.
-   ///
-   /// An event consists of a list of dependencies, a boolean
-   /// signalled() flag, and an associated task.  An event is
-   /// considered signalled as soon as all its dependencies (if any)
-   /// are signalled as well, and the trigger() method is called; at
-   /// that point the associated task will be started through the
-   /// specified \a action_ok.  If the abort() method is called
-   /// instead, the specified \a action_fail is executed and the
-   /// associated task will never be started.  Dependent events will
-   /// be aborted recursively.
-   ///
-   /// The execution status of the associated task can be queried
-   /// using the status() method, and it can be waited for completion
-   /// using the wait() method.
-   ///
-   class event : public ref_counter, public _cl_event {
-   public:
-      typedef std::function<void (event &)> action;
-
-      event(clover::context &ctx, const ref_vector<event> &deps,
-            action action_ok, action action_fail);
-      virtual ~event();
-
-      event(const event &ev) = delete;
-      event &
-      operator=(const event &ev) = delete;
-
-      void trigger();
-      void abort(cl_int status);
-      bool signalled() const;
-
-      virtual cl_int status() const;
-      virtual command_queue *queue() const = 0;
-      virtual cl_command_type command() const = 0;
-      void wait_signalled() const;
-      virtual void wait() const;
-
-      virtual struct pipe_fence_handle *fence() const {
-         return NULL;
-      }
-
-      const intrusive_ref<clover::context> context;
-
-   protected:
-      void chain(event &ev);
-
-      mutable std::vector<intrusive_ref<event>> deps;
-
-   private:
-      std::vector<intrusive_ref<event>> trigger_self();
-      std::vector<intrusive_ref<event>> abort_self(cl_int status);
-      unsigned wait_count() const;
-
-      unsigned _wait_count;
-      cl_int _status;
-      action action_ok;
-      action action_fail;
-      std::vector<intrusive_ref<event>> _chain;
-      mutable std::condition_variable cv;
-      mutable std::mutex mutex;
-   };
-
-   ///
-   /// Class that represents a task executed by a command queue.
-   ///
-   /// Similar to a normal clover::event.  In addition it's associated
-   /// with a given command queue \a q and a given OpenCL \a command.
-   /// hard_event instances created for the same queue are implicitly
-   /// ordered with respect to each other, and they are implicitly
-   /// triggered on construction.
-   ///
-   /// A hard_event is considered complete when the associated
-   /// hardware task finishes execution.
-   ///
-   class hard_event : public event {
-   public:
-      hard_event(command_queue &q, cl_command_type command,
-                 const ref_vector<event> &deps,
-                 action action = [](event &){});
-      ~hard_event();
-
-      virtual cl_int status() const;
-      virtual command_queue *queue() const;
-      virtual cl_command_type command() const;
-      virtual void wait() const;
-
-      const lazy<cl_ulong> &time_queued() const;
-      const lazy<cl_ulong> &time_submit() const;
-      const lazy<cl_ulong> &time_start() const;
-      const lazy<cl_ulong> &time_end() const;
-
-      friend class command_queue;
-
-      virtual struct pipe_fence_handle *fence() const {
-         return _fence;
-      }
-
-   private:
-      virtual void fence(pipe_fence_handle *fence);
-      action profile(command_queue &q, const action &action) const;
-
-      const intrusive_ref<command_queue> _queue;
-      cl_command_type _command;
-      pipe_fence_handle *_fence;
-      lazy<cl_ulong> _time_queued, _time_submit, _time_start, _time_end;
-   };
-
-   ///
-   /// Class that represents a software event.
-   ///
-   /// A soft_event is not associated with any specific hardware task
-   /// or command queue.  It's considered complete as soon as all its
-   /// dependencies finish execution.
-   ///
-   class soft_event : public event {
-   public:
-      soft_event(clover::context &ctx, const ref_vector<event> &deps,
-                 bool trigger, action action = [](event &){});
-
-      virtual cl_int status() const;
-      virtual command_queue *queue() const;
-      virtual cl_command_type command() const;
-      virtual void wait() const;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/format.cpp b/src/gallium/frontends/clover/core/format.cpp
deleted file mode 100644
index 6a0a2690cfe..00000000000
--- a/src/gallium/frontends/clover/core/format.cpp
+++ /dev/null
@@ -1,149 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/format.hpp"
-#include "core/memory.hpp"
-#include "pipe/p_screen.h"
-#include "pipe/p_context.h"
-
-namespace clover {
-   // see table 16 and 17 in the 3.0 CL spec under "5.3.1.1. Image Format Descriptor"
-   // TODO optional channel orders:
-   //  * CL_Rx
-   //  * CL_RGx
-   //  * CL_RGBx
-   //  * CL_sRGBx
-   #define _FF(c, b, g) \
-      { { CL_R, c }, PIPE_FORMAT_R##b##_##g },                      \
-      { { CL_A, c }, PIPE_FORMAT_A##b##_##g },                      \
-      { { CL_RG, c }, PIPE_FORMAT_R##b##G##b##_##g },               \
-      { { CL_RA, c }, PIPE_FORMAT_R##b##A##b##_##g },               \
-      { { CL_RGB, c }, PIPE_FORMAT_R##b##G##b##B##b##_##g },        \
-      { { CL_RGBA, c }, PIPE_FORMAT_R##b##G##b##B##b##A##b##_##g }
-      // broken but also optional
-      //{ { CL_LUMINANCE, c }, PIPE_FORMAT_L##b##_##g },
-      //{ { CL_INTENSITY, c }, PIPE_FORMAT_I##b##_##g },
-
-   #define _FI(c, b, g) \
-      _FF(c##b, b, g)
-
-   static const std::map<cl_image_format, pipe_format> formats {
-      //required in CL 2.0 but broken
-      //_FI(CL_SNORM_INT, 8, SNORM),
-      //_FI(CL_SNORM_INT, 16, SNORM),
-      _FI(CL_UNORM_INT, 8, UNORM),
-      _FI(CL_UNORM_INT, 16, UNORM),
-      _FI(CL_SIGNED_INT, 8, SINT),
-      _FI(CL_SIGNED_INT, 16, SINT),
-      _FI(CL_SIGNED_INT, 32, SINT),
-      _FI(CL_UNSIGNED_INT, 8, UINT),
-      _FI(CL_UNSIGNED_INT, 16, UINT),
-      _FI(CL_UNSIGNED_INT, 32, UINT),
-      _FF(CL_HALF_FLOAT, 16, FLOAT),
-      _FF(CL_FLOAT, 32, FLOAT),
-
-      // TODO: next three can be CL_RGBx as well
-      { { CL_RGB, CL_UNORM_SHORT_565 }, PIPE_FORMAT_B5G6R5_UNORM },
-      { { CL_RGB, CL_UNORM_SHORT_555 }, PIPE_FORMAT_B5G5R5A1_UNORM },
-      { { CL_RGB, CL_UNORM_INT_101010 }, PIPE_FORMAT_B10G10R10X2_UNORM },
-
-      { { CL_RGBA, CL_UNORM_INT_101010_2 }, PIPE_FORMAT_B10G10R10A2_UNORM },
-
-      { { CL_ARGB, CL_UNORM_INT8 }, PIPE_FORMAT_A8R8G8B8_UNORM },
-      { { CL_ARGB, CL_UNSIGNED_INT8 }, PIPE_FORMAT_A8R8G8B8_UINT },
-
-      { { CL_BGRA, CL_SNORM_INT8 }, PIPE_FORMAT_B8G8R8A8_SNORM },
-      { { CL_BGRA, CL_UNORM_INT8 }, PIPE_FORMAT_B8G8R8A8_UNORM },
-      { { CL_BGRA, CL_SIGNED_INT8 }, PIPE_FORMAT_B8G8R8A8_SINT },
-      { { CL_BGRA, CL_UNSIGNED_INT8 }, PIPE_FORMAT_B8G8R8A8_UINT },
-
-      { { CL_ABGR, CL_SNORM_INT8 }, PIPE_FORMAT_A8B8G8R8_SNORM },
-      { { CL_ABGR, CL_UNORM_INT8 }, PIPE_FORMAT_A8B8G8R8_UNORM },
-      { { CL_ABGR, CL_SIGNED_INT8 }, PIPE_FORMAT_A8B8G8R8_SINT },
-      { { CL_ABGR, CL_UNSIGNED_INT8 }, PIPE_FORMAT_A8B8G8R8_UINT },
-
-      // disable for now as it needs CL C 2.0 support
-      //{ { CL_DEPTH, CL_UNORM_INT16 }, PIPE_FORMAT_Z16_UNORM },
-      //{ { CL_DEPTH, CL_FLOAT }, PIPE_FORMAT_Z32_FLOAT },
-
-      // required in CL 2.0 but broken
-      //{ { CL_sRGBA, CL_UNORM_INT8 }, PIPE_FORMAT_R8G8B8A8_SRGB },
-      // optional but broken
-      //{ { CL_sRGB, CL_UNORM_INT8 }, PIPE_FORMAT_R8G8B8_SRGB },
-      //{ { CL_sBGRA, CL_UNORM_INT8 }, PIPE_FORMAT_B8G8R8A8_SRGB },
-   };
-   #undef _FF
-   #undef _FI
-
-   pipe_texture_target
-   translate_target(cl_mem_object_type type) {
-      switch (type) {
-      case CL_MEM_OBJECT_BUFFER:
-      case CL_MEM_OBJECT_IMAGE1D_BUFFER:
-         return PIPE_BUFFER;
-      case CL_MEM_OBJECT_IMAGE1D:
-         return PIPE_TEXTURE_1D;
-      case CL_MEM_OBJECT_IMAGE2D:
-         return PIPE_TEXTURE_2D;
-      case CL_MEM_OBJECT_IMAGE3D:
-         return PIPE_TEXTURE_3D;
-      case CL_MEM_OBJECT_IMAGE1D_ARRAY:
-         return PIPE_TEXTURE_1D_ARRAY;
-      case CL_MEM_OBJECT_IMAGE2D_ARRAY:
-         return PIPE_TEXTURE_2D_ARRAY;
-      default:
-         throw error(CL_INVALID_VALUE);
-      }
-   }
-
-   pipe_format
-   translate_format(const cl_image_format &format) {
-      auto it = formats.find(format);
-
-      if (it == formats.end())
-         throw error(CL_IMAGE_FORMAT_NOT_SUPPORTED);
-
-      return it->second;
-   }
-
-   std::set<cl_image_format>
-   supported_formats(const context &ctx, cl_mem_object_type type, cl_mem_flags flags) {
-      std::set<cl_image_format> s;
-      pipe_texture_target target = translate_target(type);
-      unsigned bindings = 0;
-
-      if (flags & (CL_MEM_READ_ONLY | CL_MEM_READ_WRITE | CL_MEM_KERNEL_READ_AND_WRITE))
-         bindings |= PIPE_BIND_SAMPLER_VIEW;
-      if (flags & (CL_MEM_WRITE_ONLY | CL_MEM_READ_WRITE | CL_MEM_KERNEL_READ_AND_WRITE))
-         bindings |= PIPE_BIND_SHADER_IMAGE;
-
-      for (auto f : formats) {
-         if (all_of([=](const device &dev) {
-                  return dev.pipe->is_format_supported(
-                     dev.pipe, f.second, target, 1, 1, bindings);
-               }, ctx.devices()))
-            s.insert(f.first);
-      }
-
-      return s;
-   }
-}
diff --git a/src/gallium/frontends/clover/core/format.hpp b/src/gallium/frontends/clover/core/format.hpp
deleted file mode 100644
index f93f7a7381a..00000000000
--- a/src/gallium/frontends/clover/core/format.hpp
+++ /dev/null
@@ -1,63 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_FORMAT_HPP
-#define CLOVER_CORE_FORMAT_HPP
-
-#include <set>
-
-#include "core/object.hpp"
-#include "pipe/p_defines.h"
-#include "util/format/u_formats.h"
-
-namespace clover {
-   pipe_texture_target translate_target(cl_mem_object_type type);
-   pipe_format translate_format(const cl_image_format &format);
-
-   ///
-   /// Return all the image formats supported by a given context for
-   /// the given memory object type.
-   ///
-   std::set<cl_image_format> supported_formats(const context &ctx,
-                                               cl_mem_object_type type,
-                                               cl_mem_flags flags);
-}
-
-static inline bool
-operator<(const cl_image_format &a, const cl_image_format &b) {
-   return (a.image_channel_order != b.image_channel_order ?
-           a.image_channel_order < b.image_channel_order :
-           a.image_channel_data_type < b.image_channel_data_type);
-}
-
-static inline bool
-operator==(const cl_image_format &a, const cl_image_format &b) {
-   return (a.image_channel_order == b.image_channel_order &&
-           a.image_channel_data_type == b.image_channel_data_type);
-}
-
-static inline bool
-operator!=(const cl_image_format &a, const cl_image_format &b) {
-   return !(a == b);
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/kernel.cpp b/src/gallium/frontends/clover/core/kernel.cpp
deleted file mode 100644
index 92dce0f8703..00000000000
--- a/src/gallium/frontends/clover/core/kernel.cpp
+++ /dev/null
@@ -1,675 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/kernel.hpp"
-#include "core/resource.hpp"
-#include "util/factor.hpp"
-#include "util/u_math.h"
-#include "pipe/p_context.h"
-
-using namespace clover;
-
-kernel::kernel(clover::program &prog, const std::string &name,
-               const std::vector<binary::argument> &bargs) :
-   program(prog), _name(name), exec(*this),
-   program_ref(prog._kernel_ref_counter) {
-   for (auto &barg : bargs) {
-      if (barg.semantic == binary::argument::general)
-         _args.emplace_back(argument::create(barg));
-   }
-   for (auto &dev : prog.devices()) {
-      auto &b = prog.build(dev).bin;
-      auto bsym = find(name_equals(name), b.syms);
-      const auto f = id_type_equals(bsym.section, binary::section::data_constant);
-      if (!any_of(f, b.secs))
-         continue;
-
-      auto mconst = find(f, b.secs);
-      auto rb = std::make_unique<root_buffer>(prog.context(), std::vector<cl_mem_properties>(),
-                                              CL_MEM_COPY_HOST_PTR | CL_MEM_READ_ONLY,
-                                              mconst.size, mconst.data.data());
-      _constant_buffers.emplace(&dev, std::move(rb));
-   }
-}
-
-template<typename V>
-static inline std::vector<uint>
-pad_vector(command_queue &q, const V &v, uint x) {
-   std::vector<uint> w { v.begin(), v.end() };
-   w.resize(q.device().max_block_size().size(), x);
-   return w;
-}
-
-void
-kernel::launch(command_queue &q,
-               const std::vector<size_t> &grid_offset,
-               const std::vector<size_t> &grid_size,
-               const std::vector<size_t> &block_size) {
-   const auto b = program().build(q.device()).bin;
-   const auto reduced_grid_size =
-      map(divides(), grid_size, block_size);
-
-   if (any_of(is_zero(), grid_size))
-      return;
-
-   void *st = exec.bind(&q, grid_offset);
-   struct pipe_grid_info info = {};
-
-   // The handles are created during exec_context::bind(), so we need make
-   // sure to call exec_context::bind() before retrieving them.
-   std::vector<uint32_t *> g_handles = map([&](size_t h) {
-         return (uint32_t *)&exec.input[h];
-      }, exec.g_handles);
-
-   q.pipe->bind_compute_state(q.pipe, st);
-   q.pipe->bind_sampler_states(q.pipe, PIPE_SHADER_COMPUTE,
-                               0, exec.samplers.size(),
-                               exec.samplers.data());
-
-   q.pipe->set_sampler_views(q.pipe, PIPE_SHADER_COMPUTE, 0,
-                             exec.sviews.size(), 0, exec.sviews.data());
-   q.pipe->set_shader_images(q.pipe, PIPE_SHADER_COMPUTE, 0,
-                             exec.iviews.size(), 0, exec.iviews.data());
-   q.pipe->set_compute_resources(q.pipe, 0, exec.resources.size(),
-                                 exec.resources.data());
-   q.pipe->set_global_binding(q.pipe, 0, exec.g_buffers.size(),
-                              exec.g_buffers.data(), g_handles.data());
-
-   // Fill information for the launch_grid() call.
-   info.work_dim = grid_size.size();
-   copy(pad_vector(q, block_size, 1), info.block);
-   copy(pad_vector(q, reduced_grid_size, 1), info.grid);
-   info.pc = find(name_equals(_name), b.syms).offset;
-   info.input = exec.input.data();
-   info.variable_shared_mem = exec.mem_local;
-
-   q.pipe->launch_grid(q.pipe, &info);
-
-   q.pipe->set_global_binding(q.pipe, 0, exec.g_buffers.size(), NULL, NULL);
-   q.pipe->set_compute_resources(q.pipe, 0, exec.resources.size(), NULL);
-   q.pipe->set_shader_images(q.pipe, PIPE_SHADER_COMPUTE, 0,
-                             0, exec.iviews.size(), NULL);
-   q.pipe->set_sampler_views(q.pipe, PIPE_SHADER_COMPUTE, 0,
-                             0, exec.sviews.size(), NULL);
-   q.pipe->bind_sampler_states(q.pipe, PIPE_SHADER_COMPUTE, 0,
-                               exec.samplers.size(), NULL);
-
-   q.pipe->memory_barrier(q.pipe, PIPE_BARRIER_GLOBAL_BUFFER);
-   exec.unbind();
-}
-
-size_t
-kernel::mem_local() const {
-   size_t sz = 0;
-
-   for (auto &arg : args()) {
-      if (dynamic_cast<local_argument *>(&arg))
-         sz += arg.storage();
-   }
-
-   return sz;
-}
-
-size_t
-kernel::mem_private() const {
-   return 0;
-}
-
-const std::string &
-kernel::name() const {
-   return _name;
-}
-
-std::vector<size_t>
-kernel::optimal_block_size(const command_queue &q,
-                           const std::vector<size_t> &grid_size) const {
-   if (any_of(is_zero(), grid_size))
-      return grid_size;
-
-   return factor::find_grid_optimal_factor<size_t>(
-      q.device().max_threads_per_block(), q.device().max_block_size(),
-      grid_size);
-}
-
-std::vector<size_t>
-kernel::required_block_size() const {
-   return find(name_equals(_name), program().symbols()).reqd_work_group_size;
-}
-
-kernel::argument_range
-kernel::args() {
-   return map(derefs(), _args);
-}
-
-kernel::const_argument_range
-kernel::args() const {
-   return map(derefs(), _args);
-}
-
-std::vector<clover::binary::arg_info>
-kernel::args_infos() {
-   std::vector<clover::binary::arg_info> infos;
-   for (auto &barg: find(name_equals(_name), program().symbols()).args)
-      if (barg.semantic == clover::binary::argument::general)
-         infos.emplace_back(barg.info);
-
-   return infos;
-}
-
-const binary &
-kernel::binary(const command_queue &q) const {
-   return program().build(q.device()).bin;
-}
-
-kernel::exec_context::exec_context(kernel &kern) :
-   kern(kern), q(NULL), print_handler(), mem_local(0), st(NULL), cs() {
-}
-
-kernel::exec_context::~exec_context() {
-   if (st)
-      q->pipe->delete_compute_state(q->pipe, st);
-}
-
-void *
-kernel::exec_context::bind(intrusive_ptr<command_queue> _q,
-                           const std::vector<size_t> &grid_offset) {
-   std::swap(q, _q);
-
-   // Bind kernel arguments.
-   auto &b = kern.program().build(q->device()).bin;
-   auto bsym = find(name_equals(kern.name()), b.syms);
-   auto bargs = bsym.args;
-   auto msec = find(id_type_equals(bsym.section, binary::section::text_executable), b.secs);
-   auto explicit_arg = kern._args.begin();
-
-   for (auto &barg : bargs) {
-      switch (barg.semantic) {
-      case binary::argument::general:
-         (*(explicit_arg++))->bind(*this, barg);
-         break;
-
-      case binary::argument::grid_dimension: {
-         const cl_uint dimension = grid_offset.size();
-         auto arg = argument::create(barg);
-
-         arg->set(sizeof(dimension), &dimension);
-         arg->bind(*this, barg);
-         break;
-      }
-      case binary::argument::grid_offset: {
-         for (cl_uint x : pad_vector(*q, grid_offset, 0)) {
-            auto arg = argument::create(barg);
-
-            arg->set(sizeof(x), &x);
-            arg->bind(*this, barg);
-         }
-         break;
-      }
-      case binary::argument::image_size: {
-         auto img = dynamic_cast<image_argument &>(**(explicit_arg - 1)).get();
-         std::vector<cl_uint> image_size{
-               static_cast<cl_uint>(img->width()),
-               static_cast<cl_uint>(img->height()),
-               static_cast<cl_uint>(img->depth())};
-         for (auto x : image_size) {
-            auto arg = argument::create(barg);
-
-            arg->set(sizeof(x), &x);
-            arg->bind(*this, barg);
-         }
-         break;
-      }
-      case binary::argument::image_format: {
-         auto img = dynamic_cast<image_argument &>(**(explicit_arg - 1)).get();
-         cl_image_format fmt = img->format();
-         std::vector<cl_uint> image_format{
-               static_cast<cl_uint>(fmt.image_channel_data_type),
-               static_cast<cl_uint>(fmt.image_channel_order)};
-         for (auto x : image_format) {
-            auto arg = argument::create(barg);
-
-            arg->set(sizeof(x), &x);
-            arg->bind(*this, barg);
-         }
-         break;
-      }
-      case binary::argument::constant_buffer: {
-         auto arg = argument::create(barg);
-         cl_mem buf = kern._constant_buffers.at(&q->device()).get();
-         arg->set(sizeof(buf), &buf);
-         arg->bind(*this, barg);
-         break;
-      }
-      case binary::argument::printf_buffer: {
-         print_handler = printf_handler::create(q, b.printf_infos,
-                                                b.printf_strings_in_buffer,
-                                                q->device().max_printf_buffer_size());
-         cl_mem print_mem = print_handler->get_mem();
-
-         auto arg = argument::create(barg);
-         arg->set(sizeof(cl_mem), &print_mem);
-         arg->bind(*this, barg);
-         break;
-      }
-      }
-   }
-
-   // Create a new compute state if anything changed.
-   if (!st || q != _q ||
-       cs.req_input_mem != input.size()) {
-      if (st)
-         _q->pipe->delete_compute_state(_q->pipe, st);
-
-      cs.ir_type = q->device().ir_format();
-      cs.prog = &(msec.data[0]);
-      // we only pass in NIRs or LLVMs and both IRs decode the size
-      cs.static_shared_mem = 0;
-      cs.req_input_mem = input.size();
-      st = q->pipe->create_compute_state(q->pipe, &cs);
-      if (!st) {
-         unbind(); // Cleanup
-         throw error(CL_OUT_OF_RESOURCES);
-      }
-   }
-
-   return st;
-}
-
-void
-kernel::exec_context::unbind() {
-   if (print_handler)
-      print_handler->print();
-
-   for (auto &arg : kern.args())
-      arg.unbind(*this);
-
-   input.clear();
-   samplers.clear();
-   sviews.clear();
-   iviews.clear();
-   resources.clear();
-   g_buffers.clear();
-   g_handles.clear();
-   mem_local = 0;
-}
-
-namespace {
-   template<typename T>
-   std::vector<uint8_t>
-   bytes(const T& x) {
-      return { (uint8_t *)&x, (uint8_t *)&x + sizeof(x) };
-   }
-
-   ///
-   /// Transform buffer \a v from the native byte order into the byte
-   /// order specified by \a e.
-   ///
-   template<typename T>
-   void
-   byteswap(T &v, pipe_endian e) {
-      if (PIPE_ENDIAN_NATIVE != e)
-         std::reverse(v.begin(), v.end());
-   }
-
-   ///
-   /// Pad buffer \a v to the next multiple of \a n.
-   ///
-   template<typename T>
-   void
-   align_vector(T &v, size_t n) {
-      v.resize(util_align_npot(v.size(), n));
-   }
-
-   bool
-   msb(const std::vector<uint8_t> &s) {
-      if (PIPE_ENDIAN_NATIVE == PIPE_ENDIAN_LITTLE)
-         return s.back() & 0x80;
-      else
-         return s.front() & 0x80;
-   }
-
-   ///
-   /// Resize buffer \a v to size \a n using sign or zero extension
-   /// according to \a ext.
-   ///
-   template<typename T>
-   void
-   extend(T &v, enum binary::argument::ext_type ext, size_t n) {
-      const size_t m = std::min(v.size(), n);
-      const bool sign_ext = (ext == binary::argument::sign_ext);
-      const uint8_t fill = (sign_ext && msb(v) ? ~0 : 0);
-      T w(n, fill);
-
-      if (PIPE_ENDIAN_NATIVE == PIPE_ENDIAN_LITTLE)
-         std::copy_n(v.begin(), m, w.begin());
-      else
-         std::copy_n(v.end() - m, m, w.end() - m);
-
-      std::swap(v, w);
-   }
-
-   ///
-   /// Append buffer \a w to \a v.
-   ///
-   template<typename T>
-   void
-   insert(T &v, const T &w) {
-      v.insert(v.end(), w.begin(), w.end());
-   }
-
-   ///
-   /// Append \a n elements to the end of buffer \a v.
-   ///
-   template<typename T>
-   size_t
-   allocate(T &v, size_t n) {
-      size_t pos = v.size();
-      v.resize(pos + n);
-      return pos;
-   }
-}
-
-std::unique_ptr<kernel::argument>
-kernel::argument::create(const binary::argument &barg) {
-   switch (barg.type) {
-   case binary::argument::scalar:
-      return std::unique_ptr<kernel::argument>(new scalar_argument(barg.size));
-
-   case binary::argument::global:
-      return std::unique_ptr<kernel::argument>(new global_argument);
-
-   case binary::argument::local:
-      return std::unique_ptr<kernel::argument>(new local_argument);
-
-   case binary::argument::constant:
-      return std::unique_ptr<kernel::argument>(new constant_argument);
-
-   case binary::argument::image_rd:
-      return std::unique_ptr<kernel::argument>(new image_rd_argument);
-
-   case binary::argument::image_wr:
-      return std::unique_ptr<kernel::argument>(new image_wr_argument);
-
-   case binary::argument::sampler:
-      return std::unique_ptr<kernel::argument>(new sampler_argument);
-
-   }
-   throw error(CL_INVALID_KERNEL_DEFINITION);
-}
-
-kernel::argument::argument() : _set(false) {
-}
-
-bool
-kernel::argument::set() const {
-   return _set;
-}
-
-size_t
-kernel::argument::storage() const {
-   return 0;
-}
-
-kernel::scalar_argument::scalar_argument(size_t size) : size(size) {
-}
-
-void
-kernel::scalar_argument::set(size_t size, const void *value) {
-   if (!value)
-      throw error(CL_INVALID_ARG_VALUE);
-
-   if (size != this->size)
-      throw error(CL_INVALID_ARG_SIZE);
-
-   v = { (uint8_t *)value, (uint8_t *)value + size };
-   _set = true;
-}
-
-void
-kernel::scalar_argument::bind(exec_context &ctx,
-                              const binary::argument &barg) {
-   auto w = v;
-
-   extend(w, barg.ext_type, barg.target_size);
-   byteswap(w, ctx.q->device().endianness());
-   align_vector(ctx.input, barg.target_align);
-   insert(ctx.input, w);
-}
-
-void
-kernel::scalar_argument::unbind(exec_context &ctx) {
-}
-
-kernel::global_argument::global_argument() : buf(nullptr), svm(nullptr) {
-}
-
-void
-kernel::global_argument::set(size_t size, const void *value) {
-   if (size != sizeof(cl_mem))
-      throw error(CL_INVALID_ARG_SIZE);
-
-   buf = pobj<buffer>(value ? *(cl_mem *)value : NULL);
-   svm = nullptr;
-   _set = true;
-}
-
-void
-kernel::global_argument::set_svm(const void *value) {
-   svm = value;
-   buf = nullptr;
-   _set = true;
-}
-
-void
-kernel::global_argument::bind(exec_context &ctx,
-                              const binary::argument &barg) {
-   align_vector(ctx.input, barg.target_align);
-
-   if (buf) {
-      const resource &r = buf->resource_in(*ctx.q);
-      ctx.g_handles.push_back(ctx.input.size());
-      ctx.g_buffers.push_back(r.pipe);
-
-      // How to handle multi-demensional offsets?
-      // We don't need to.  Buffer offsets are always
-      // one-dimensional.
-      auto v = bytes(r.offset[0]);
-      extend(v, barg.ext_type, barg.target_size);
-      byteswap(v, ctx.q->device().endianness());
-      insert(ctx.input, v);
-   } else if (svm) {
-      auto v = bytes(svm);
-      extend(v, barg.ext_type, barg.target_size);
-      byteswap(v, ctx.q->device().endianness());
-      insert(ctx.input, v);
-   } else {
-      // Null pointer.
-      allocate(ctx.input, barg.target_size);
-   }
-}
-
-void
-kernel::global_argument::unbind(exec_context &ctx) {
-}
-
-size_t
-kernel::local_argument::storage() const {
-   return _storage;
-}
-
-void
-kernel::local_argument::set(size_t size, const void *value) {
-   if (value)
-      throw error(CL_INVALID_ARG_VALUE);
-
-   if (!size)
-      throw error(CL_INVALID_ARG_SIZE);
-
-   _storage = size;
-   _set = true;
-}
-
-void
-kernel::local_argument::bind(exec_context &ctx,
-                             const binary::argument &barg) {
-   ctx.mem_local = ::align(ctx.mem_local, barg.target_align);
-   auto v = bytes(ctx.mem_local);
-
-   extend(v, binary::argument::zero_ext, barg.target_size);
-   byteswap(v, ctx.q->device().endianness());
-   align_vector(ctx.input, ctx.q->device().address_bits() / 8);
-   insert(ctx.input, v);
-
-   ctx.mem_local += _storage;
-}
-
-void
-kernel::local_argument::unbind(exec_context &ctx) {
-}
-
-kernel::constant_argument::constant_argument() : buf(nullptr), st(nullptr) {
-}
-
-void
-kernel::constant_argument::set(size_t size, const void *value) {
-   if (size != sizeof(cl_mem))
-      throw error(CL_INVALID_ARG_SIZE);
-
-   buf = pobj<buffer>(value ? *(cl_mem *)value : NULL);
-   _set = true;
-}
-
-void
-kernel::constant_argument::bind(exec_context &ctx,
-                                const binary::argument &barg) {
-   align_vector(ctx.input, barg.target_align);
-
-   if (buf) {
-      resource &r = buf->resource_in(*ctx.q);
-      auto v = bytes(ctx.resources.size() << 24 | r.offset[0]);
-
-      extend(v, binary::argument::zero_ext, barg.target_size);
-      byteswap(v, ctx.q->device().endianness());
-      insert(ctx.input, v);
-
-      st = r.bind_surface(*ctx.q, false);
-      ctx.resources.push_back(st);
-   } else {
-      // Null pointer.
-      allocate(ctx.input, barg.target_size);
-   }
-}
-
-void
-kernel::constant_argument::unbind(exec_context &ctx) {
-   if (buf)
-      buf->resource_in(*ctx.q).unbind_surface(*ctx.q, st);
-}
-
-kernel::image_rd_argument::image_rd_argument() : st(nullptr) {
-}
-
-void
-kernel::image_rd_argument::set(size_t size, const void *value) {
-   if (!value)
-      throw error(CL_INVALID_ARG_VALUE);
-
-   if (size != sizeof(cl_mem))
-      throw error(CL_INVALID_ARG_SIZE);
-
-   img = &obj<image>(*(cl_mem *)value);
-   _set = true;
-}
-
-void
-kernel::image_rd_argument::bind(exec_context &ctx,
-                                const binary::argument &barg) {
-   auto v = bytes(ctx.sviews.size());
-
-   extend(v, binary::argument::zero_ext, barg.target_size);
-   byteswap(v, ctx.q->device().endianness());
-   align_vector(ctx.input, barg.target_align);
-   insert(ctx.input, v);
-
-   st = img->resource_in(*ctx.q).bind_sampler_view(*ctx.q);
-   ctx.sviews.push_back(st);
-}
-
-void
-kernel::image_rd_argument::unbind(exec_context &ctx) {
-   img->resource_in(*ctx.q).unbind_sampler_view(*ctx.q, st);
-}
-
-void
-kernel::image_wr_argument::set(size_t size, const void *value) {
-   if (!value)
-      throw error(CL_INVALID_ARG_VALUE);
-
-   if (size != sizeof(cl_mem))
-      throw error(CL_INVALID_ARG_SIZE);
-
-   img = &obj<image>(*(cl_mem *)value);
-   _set = true;
-}
-
-void
-kernel::image_wr_argument::bind(exec_context &ctx,
-                                const binary::argument &barg) {
-   auto v = bytes(ctx.iviews.size());
-
-   extend(v, binary::argument::zero_ext, barg.target_size);
-   byteswap(v, ctx.q->device().endianness());
-   align_vector(ctx.input, barg.target_align);
-   insert(ctx.input, v);
-   ctx.iviews.push_back(img->resource_in(*ctx.q).create_image_view(*ctx.q));
-}
-
-void
-kernel::image_wr_argument::unbind(exec_context &ctx) {
-}
-
-kernel::sampler_argument::sampler_argument() : s(nullptr), st(nullptr) {
-}
-
-void
-kernel::sampler_argument::set(size_t size, const void *value) {
-   if (!value)
-      throw error(CL_INVALID_SAMPLER);
-
-   if (size != sizeof(cl_sampler))
-      throw error(CL_INVALID_ARG_SIZE);
-
-   s = &obj(*(cl_sampler *)value);
-   _set = true;
-}
-
-void
-kernel::sampler_argument::bind(exec_context &ctx,
-                               const binary::argument &barg) {
-   st = s->bind(*ctx.q);
-   ctx.samplers.push_back(st);
-}
-
-void
-kernel::sampler_argument::unbind(exec_context &ctx) {
-   s->unbind(*ctx.q, st);
-}
diff --git a/src/gallium/frontends/clover/core/kernel.hpp b/src/gallium/frontends/clover/core/kernel.hpp
deleted file mode 100644
index 2b543ce6d3c..00000000000
--- a/src/gallium/frontends/clover/core/kernel.hpp
+++ /dev/null
@@ -1,262 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_KERNEL_HPP
-#define CLOVER_CORE_KERNEL_HPP
-
-#include <map>
-#include <memory>
-
-#include "core/object.hpp"
-#include "core/printf.hpp"
-#include "core/program.hpp"
-#include "core/memory.hpp"
-#include "core/sampler.hpp"
-#include "pipe/p_state.h"
-
-namespace clover {
-   class kernel : public ref_counter, public _cl_kernel {
-   private:
-      ///
-      /// Class containing all the state required to execute a compute
-      /// kernel.
-      ///
-      struct exec_context {
-         exec_context(kernel &kern);
-         ~exec_context();
-
-         exec_context(const exec_context &) = delete;
-         exec_context &
-         operator=(const exec_context &) = delete;
-
-         void *bind(intrusive_ptr<command_queue> _q,
-                    const std::vector<size_t> &grid_offset);
-         void unbind();
-
-         kernel &kern;
-         intrusive_ptr<command_queue> q;
-         std::unique_ptr<printf_handler> print_handler;
-
-         std::vector<uint8_t> input;
-         std::vector<void *> samplers;
-         std::vector<pipe_sampler_view *> sviews;
-         std::vector<pipe_image_view> iviews;
-         std::vector<pipe_surface *> resources;
-         std::vector<pipe_resource *> g_buffers;
-         std::vector<size_t> g_handles;
-         size_t mem_local;
-
-      private:
-         void *st;
-         pipe_compute_state cs;
-      };
-
-   public:
-      class argument {
-      public:
-         static std::unique_ptr<argument>
-         create(const binary::argument &barg);
-
-         argument(const argument &arg) = delete;
-         argument &
-         operator=(const argument &arg) = delete;
-
-         /// \a true if the argument has been set.
-         bool set() const;
-
-         /// Storage space required for the referenced object.
-         virtual size_t storage() const;
-
-         /// Set this argument to some object.
-         virtual void set(size_t size, const void *value) = 0;
-
-         /// Set this argument to an SVM pointer.
-         virtual void set_svm(const void *value) {
-            throw error(CL_INVALID_ARG_INDEX);
-         };
-
-         /// Allocate the necessary resources to bind the specified
-         /// object to this argument, and update \a ctx accordingly.
-         virtual void bind(exec_context &ctx,
-                           const binary::argument &barg) = 0;
-
-         /// Free any resources that were allocated in bind().
-         virtual void unbind(exec_context &ctx) = 0;
-
-         virtual ~argument() {};
-      protected:
-         argument();
-
-         bool _set;
-      };
-
-   private:
-      typedef adaptor_range<
-            derefs, std::vector<std::unique_ptr<argument>> &
-         > argument_range;
-
-      typedef adaptor_range<
-            derefs, const std::vector<std::unique_ptr<argument>> &
-         > const_argument_range;
-
-   public:
-      kernel(clover::program &prog, const std::string &name,
-             const std::vector<clover::binary::argument> &bargs);
-
-      kernel(const kernel &kern) = delete;
-      kernel &
-      operator=(const kernel &kern) = delete;
-
-      void launch(command_queue &q,
-                  const std::vector<size_t> &grid_offset,
-                  const std::vector<size_t> &grid_size,
-                  const std::vector<size_t> &block_size);
-
-      size_t mem_local() const;
-      size_t mem_private() const;
-
-      const std::string &name() const;
-
-      std::vector<size_t>
-      optimal_block_size(const command_queue &q,
-                         const std::vector<size_t> &grid_size) const;
-      std::vector<size_t>
-      required_block_size() const;
-
-      argument_range args();
-      const_argument_range args() const;
-      std::vector<clover::binary::arg_info> args_infos();
-
-      const intrusive_ref<clover::program> program;
-
-   private:
-      const clover::binary &binary(const command_queue &q) const;
-
-      class scalar_argument : public argument {
-      public:
-         scalar_argument(size_t size);
-
-         virtual void set(size_t size, const void *value);
-         virtual void bind(exec_context &ctx,
-                           const binary::argument &barg);
-         virtual void unbind(exec_context &ctx);
-
-      private:
-         size_t size;
-         std::vector<uint8_t> v;
-      };
-
-      class global_argument : public argument {
-      public:
-         global_argument();
-
-         virtual void set(size_t size, const void *value);
-         virtual void set_svm(const void *value);
-         virtual void bind(exec_context &ctx,
-                           const binary::argument &barg);
-         virtual void unbind(exec_context &ctx);
-
-      private:
-         buffer *buf;
-         const void *svm;
-      };
-
-      class local_argument : public argument {
-      public:
-         virtual size_t storage() const;
-
-         virtual void set(size_t size, const void *value);
-         virtual void bind(exec_context &ctx,
-                           const binary::argument &barg);
-         virtual void unbind(exec_context &ctx);
-
-      private:
-         size_t _storage = 0;
-      };
-
-      class constant_argument : public argument {
-      public:
-         constant_argument();
-
-         virtual void set(size_t size, const void *value);
-         virtual void bind(exec_context &ctx,
-                           const binary::argument &barg);
-         virtual void unbind(exec_context &ctx);
-
-      private:
-         buffer *buf;
-         pipe_surface *st;
-      };
-
-      class image_argument : public argument {
-      public:
-         const image *get() const {
-            return img;
-         }
-      protected:
-         image *img;
-      };
-
-      class image_rd_argument : public image_argument {
-      public:
-         image_rd_argument();
-
-         virtual void set(size_t size, const void *value);
-         virtual void bind(exec_context &ctx,
-                           const binary::argument &barg);
-         virtual void unbind(exec_context &ctx);
-
-      private:
-         pipe_sampler_view *st;
-      };
-
-      class image_wr_argument : public image_argument {
-      public:
-         virtual void set(size_t size, const void *value);
-         virtual void bind(exec_context &ctx,
-                           const binary::argument &barg);
-         virtual void unbind(exec_context &ctx);
-      };
-
-      class sampler_argument : public argument {
-      public:
-         sampler_argument();
-
-         virtual void set(size_t size, const void *value);
-         virtual void bind(exec_context &ctx,
-                           const binary::argument &barg);
-         virtual void unbind(exec_context &ctx);
-
-      private:
-         sampler *s;
-         void *st;
-      };
-
-      std::vector<std::unique_ptr<argument>> _args;
-      std::map<device *, std::unique_ptr<root_buffer> > _constant_buffers;
-      std::string _name;
-      exec_context exec;
-      const ref_holder program_ref;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/memory.cpp b/src/gallium/frontends/clover/core/memory.cpp
deleted file mode 100644
index 6270107e94c..00000000000
--- a/src/gallium/frontends/clover/core/memory.cpp
+++ /dev/null
@@ -1,325 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/memory.hpp"
-#include "core/resource.hpp"
-#include "util/format/u_format.h"
-
-using namespace clover;
-
-memory_obj::memory_obj(clover::context &ctx,
-                       std::vector<cl_mem_properties> properties,
-                       cl_mem_flags flags,
-                       size_t size, void *host_ptr) :
-   context(ctx), _properties(properties), _flags(flags),
-   _size(size), _host_ptr(host_ptr) {
-   if (flags & CL_MEM_COPY_HOST_PTR)
-      data.append((char *)host_ptr, size);
-}
-
-memory_obj::~memory_obj() {
-   while (_destroy_notify.size()) {
-      _destroy_notify.top()();
-      _destroy_notify.pop();
-   }
-}
-
-bool
-memory_obj::operator==(const memory_obj &obj) const {
-   return this == &obj;
-}
-
-void
-memory_obj::destroy_notify(std::function<void ()> f) {
-   _destroy_notify.push(f);
-}
-
-std::vector<cl_mem_properties>
-memory_obj::properties() const {
-   return _properties;
-}
-
-cl_mem_flags
-memory_obj::flags() const {
-   return _flags;
-}
-
-size_t
-memory_obj::size() const {
-   return _size;
-}
-
-void *
-memory_obj::host_ptr() const {
-   return _host_ptr;
-}
-
-buffer::buffer(clover::context &ctx,
-               std::vector<cl_mem_properties> properties,
-               cl_mem_flags flags,
-               size_t size, void *host_ptr) :
-   memory_obj(ctx, properties, flags, size, host_ptr) {
-}
-
-cl_mem_object_type
-buffer::type() const {
-   return CL_MEM_OBJECT_BUFFER;
-}
-
-root_buffer::root_buffer(clover::context &ctx,
-                         std::vector<cl_mem_properties> properties,
-                         cl_mem_flags flags,
-                         size_t size, void *host_ptr) :
-   buffer(ctx, properties, flags, size, host_ptr) {
-}
-
-resource &
-root_buffer::resource_in(command_queue &q) {
-   const void *data_ptr = NULL;
-   if (flags() & (CL_MEM_USE_HOST_PTR | CL_MEM_COPY_HOST_PTR))
-      data_ptr = !data.empty() ? data.data() : host_ptr();
-
-   return resource(q, data_ptr);
-}
-
-resource &
-root_buffer::resource_undef(command_queue &q) {
-   return resource(q, NULL);
-}
-
-resource &
-root_buffer::resource(command_queue &q, const void *data_ptr) {
-   std::lock_guard<std::mutex> lock(resources_mtx);
-   // Create a new resource if there's none for this device yet.
-   if (!resources.count(&q.device())) {
-      auto r = (!resources.empty() ?
-                new root_resource(q.device(), *this,
-                                  *resources.begin()->second) :
-                new root_resource(q.device(), *this, q, data_ptr));
-
-      resources.insert(std::make_pair(&q.device(),
-                                      std::unique_ptr<root_resource>(r)));
-      data.clear();
-   }
-
-   return *resources.find(&q.device())->second;
-}
-
-void
-root_buffer::resource_out(command_queue &q) {
-   std::lock_guard<std::mutex> lock(resources_mtx);
-   resources.erase(&q.device());
-}
-
-sub_buffer::sub_buffer(root_buffer &parent, cl_mem_flags flags,
-                       size_t offset, size_t size) :
-   buffer(parent.context(), std::vector<cl_mem_properties>(), flags, size,
-          (char *)parent.host_ptr() + offset),
-   parent(parent), _offset(offset) {
-}
-
-resource &
-sub_buffer::resource_in(command_queue &q) {
-   std::lock_guard<std::mutex> lock(resources_mtx);
-   // Create a new resource if there's none for this device yet.
-   if (!resources.count(&q.device())) {
-      auto r = new sub_resource(parent().resource_in(q), {{ offset() }});
-
-      resources.insert(std::make_pair(&q.device(),
-                                      std::unique_ptr<sub_resource>(r)));
-   }
-
-   return *resources.find(&q.device())->second;
-}
-
-resource &
-sub_buffer::resource_undef(command_queue &q) {
-   return resource_in(q);
-}
-
-void
-sub_buffer::resource_out(command_queue &q) {
-   std::lock_guard<std::mutex> lock(resources_mtx);
-   resources.erase(&q.device());
-}
-
-size_t
-sub_buffer::offset() const {
-   return _offset;
-}
-
-image::image(clover::context &ctx,
-             std::vector<cl_mem_properties> properties,
-             cl_mem_flags flags,
-             const cl_image_format *format,
-             size_t width, size_t height, size_t depth, size_t array_size,
-             size_t row_pitch, size_t slice_pitch, size_t size,
-             void *host_ptr, cl_mem buffer) :
-   memory_obj(ctx, properties, flags, size, host_ptr),
-   _format(*format), _width(width), _height(height), _depth(depth),
-   _row_pitch(row_pitch), _slice_pitch(slice_pitch), _array_size(array_size),
-   _buffer(buffer) {
-}
-
-resource &
-image::resource_in(command_queue &q) {
-   const void *data_ptr = !data.empty() ? data.data() : NULL;
-   return resource(q, data_ptr);
-}
-
-resource &
-image::resource_undef(command_queue &q) {
-   return resource(q, NULL);
-}
-
-resource &
-image::resource(command_queue &q, const void *data_ptr) {
-   std::lock_guard<std::mutex> lock(resources_mtx);
-   // Create a new resource if there's none for this device yet.
-   if (!resources.count(&q.device())) {
-      auto r = (!resources.empty() ?
-                new root_resource(q.device(), *this,
-                                  *resources.begin()->second) :
-                new root_resource(q.device(), *this, q, data_ptr));
-
-      resources.insert(std::make_pair(&q.device(),
-                                      std::unique_ptr<root_resource>(r)));
-      data.clear();
-   }
-
-   return *resources.find(&q.device())->second;
-}
-
-void
-image::resource_out(command_queue &q) {
-   std::lock_guard<std::mutex> lock(resources_mtx);
-   resources.erase(&q.device());
-}
-
-cl_image_format
-image::format() const {
-   return _format;
-}
-
-size_t
-image::width() const {
-   return _width;
-}
-
-size_t
-image::height() const {
-   return _height;
-}
-
-size_t
-image::depth() const {
-   return _depth;
-}
-
-size_t
-image::pixel_size() const {
-   return util_format_get_blocksize(translate_format(_format));
-}
-
-size_t
-image::row_pitch() const {
-   return _row_pitch;
-}
-
-size_t
-image::slice_pitch() const {
-   return _slice_pitch;
-}
-
-size_t
-image::array_size() const {
-   return _array_size;
-}
-
-cl_mem
-image::buffer() const {
-   return _buffer;
-}
-
-image1d::image1d(clover::context &ctx,
-                 std::vector<cl_mem_properties> properties,
-                 cl_mem_flags flags,
-                 const cl_image_format *format,
-                 size_t width, size_t row_pitch,
-                 void *host_ptr) :
-   basic_image(ctx, properties, flags, format, width, 1, 1, 0,
-               row_pitch, 0, row_pitch, host_ptr, nullptr) {
-}
-
-image1d_buffer::image1d_buffer(clover::context &ctx,
-                               std::vector<cl_mem_properties> properties,
-                               cl_mem_flags flags,
-                               const cl_image_format *format,
-                               size_t width, size_t row_pitch,
-                               void *host_ptr, cl_mem buffer) :
-   basic_image(ctx, properties, flags, format, width, 1, 1, 0,
-               row_pitch, 0, row_pitch, host_ptr, buffer) {
-}
-
-image1d_array::image1d_array(clover::context &ctx,
-                             std::vector<cl_mem_properties> properties,
-                             cl_mem_flags flags,
-                             const cl_image_format *format,
-                             size_t width,
-                             size_t array_size, size_t slice_pitch,
-                             void *host_ptr) :
-   basic_image(ctx, properties, flags, format, width, 1, 1, array_size,
-               0, slice_pitch, slice_pitch * array_size, host_ptr, nullptr) {
-}
-
-image2d::image2d(clover::context &ctx,
-                 std::vector<cl_mem_properties> properties,
-                 cl_mem_flags flags,
-                 const cl_image_format *format, size_t width,
-                 size_t height, size_t row_pitch,
-                 void *host_ptr) :
-   basic_image(ctx, properties, flags, format, width, height, 1, 0,
-               row_pitch, 0, height * row_pitch, host_ptr, nullptr) {
-}
-
-image2d_array::image2d_array(clover::context &ctx,
-                             std::vector<cl_mem_properties> properties,
-                             cl_mem_flags flags,
-                             const cl_image_format *format,
-                             size_t width, size_t height, size_t array_size,
-                             size_t row_pitch, size_t slice_pitch,
-                             void *host_ptr) :
-   basic_image(ctx, properties, flags, format, width, height, 1, array_size,
-               row_pitch, slice_pitch, slice_pitch * array_size, host_ptr, nullptr) {
-}
-
-image3d::image3d(clover::context &ctx,
-                 std::vector<cl_mem_properties> properties,
-                 cl_mem_flags flags,
-                 const cl_image_format *format,
-                 size_t width, size_t height, size_t depth,
-                 size_t row_pitch, size_t slice_pitch,
-                 void *host_ptr) :
-   basic_image(ctx, properties, flags, format, width, height, depth, 0,
-               row_pitch, slice_pitch, depth * slice_pitch,
-               host_ptr, nullptr) {
-}
diff --git a/src/gallium/frontends/clover/core/memory.hpp b/src/gallium/frontends/clover/core/memory.hpp
deleted file mode 100644
index d6a170bcfb9..00000000000
--- a/src/gallium/frontends/clover/core/memory.hpp
+++ /dev/null
@@ -1,256 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_MEMORY_HPP
-#define CLOVER_CORE_MEMORY_HPP
-
-#include <functional>
-#include <map>
-#include <memory>
-#include <stack>
-
-#include "core/object.hpp"
-#include "core/queue.hpp"
-#include "core/resource.hpp"
-
-namespace clover {
-   class memory_obj : public ref_counter, public _cl_mem {
-   protected:
-      memory_obj(clover::context &ctx,
-                 std::vector<cl_mem_properties> properties,
-                 cl_mem_flags flags,
-                 size_t size, void *host_ptr);
-
-      memory_obj(const memory_obj &obj) = delete;
-      memory_obj &
-      operator=(const memory_obj &obj) = delete;
-
-   public:
-      virtual ~memory_obj();
-
-      bool
-      operator==(const memory_obj &obj) const;
-
-      virtual cl_mem_object_type type() const = 0;
-      virtual clover::resource &
-      resource_in(command_queue &q) = 0;
-      virtual clover::resource &
-      resource_undef(command_queue &q) = 0;
-      virtual void resource_out(command_queue &q) = 0;
-
-      void destroy_notify(std::function<void ()> f);
-      std::vector<cl_mem_properties> properties() const;
-      cl_mem_flags flags() const;
-      size_t size() const;
-      void *host_ptr() const;
-
-      const intrusive_ref<clover::context> context;
-
-   private:
-      std::vector<cl_mem_properties> _properties;
-      cl_mem_flags _flags;
-      size_t _size;
-      void *_host_ptr;
-      std::stack<std::function<void ()>> _destroy_notify;
-
-   protected:
-      std::string data;
-   };
-
-   class buffer : public memory_obj {
-   protected:
-      buffer(clover::context &ctx,
-             std::vector<cl_mem_properties> properties,
-             cl_mem_flags flags,
-             size_t size, void *host_ptr);
-
-   public:
-      virtual cl_mem_object_type type() const;
-   };
-
-   class root_buffer : public buffer {
-   public:
-      root_buffer(clover::context &ctx,
-                  std::vector<cl_mem_properties> properties,
-                  cl_mem_flags flags,
-                  size_t size, void *host_ptr);
-
-      virtual clover::resource &
-      resource_in(command_queue &q);
-      virtual clover::resource &
-      resource_undef(command_queue &q);
-      virtual void
-      resource_out(command_queue &q);
-
-   private:
-      clover::resource &
-         resource(command_queue &q, const void *data_ptr);
-
-      std::map<device *,
-               std::unique_ptr<root_resource>> resources;
-      std::mutex resources_mtx;
-   };
-
-   class sub_buffer : public buffer {
-   public:
-      sub_buffer(root_buffer &parent, cl_mem_flags flags,
-                 size_t offset, size_t size);
-
-      virtual clover::resource &
-      resource_in(command_queue &q);
-      virtual clover::resource &
-      resource_undef(command_queue &q);
-      virtual void
-      resource_out(command_queue &q);
-      size_t offset() const;
-
-      const intrusive_ref<root_buffer> parent;
-
-   private:
-      size_t _offset;
-      std::map<device *,
-               std::unique_ptr<sub_resource>> resources;
-      std::mutex resources_mtx;
-   };
-
-   class image : public memory_obj {
-   protected:
-      image(clover::context &ctx,
-            std::vector<cl_mem_properties> properties,
-            cl_mem_flags flags,
-            const cl_image_format *format,
-            size_t width, size_t height, size_t depth, size_t array_size,
-            size_t row_pitch, size_t slice_pitch, size_t size,
-            void *host_ptr, cl_mem buffer);
-
-   public:
-      cl_image_format format() const;
-      virtual cl_uint dimensions() const = 0;
-      size_t width() const;
-      size_t height() const;
-      size_t depth() const;
-      size_t pixel_size() const;
-      size_t row_pitch() const;
-      size_t slice_pitch() const;
-      size_t array_size() const;
-      cl_mem buffer() const;
-      virtual clover::resource &
-      resource_in(command_queue &q);
-      virtual clover::resource &
-      resource_undef(command_queue &q);
-      virtual void
-      resource_out(command_queue &q);
-
-   private:
-      clover::resource &
-         resource(command_queue &q, const void *data_ptr);
-
-      cl_image_format _format;
-      size_t _width;
-      size_t _height;
-      size_t _depth;
-      size_t _row_pitch;
-      size_t _slice_pitch;
-      size_t _array_size;
-      cl_mem _buffer;
-      std::map<device *,
-               std::unique_ptr<root_resource>> resources;
-      std::mutex resources_mtx;
-   };
-
-   template<cl_mem_object_type Type, cl_uint Dim>
-   class basic_image : public image {
-   public:
-      using image::image;
-      virtual cl_mem_object_type type() const {
-         return Type;
-      }
-      virtual cl_uint dimensions() const {
-         return Dim;
-      }
-   };
-
-   class image1d : public basic_image<CL_MEM_OBJECT_IMAGE1D, 1> {
-   public:
-      image1d(clover::context &ctx,
-              std::vector<cl_mem_properties> properties,
-              cl_mem_flags flags,
-              const cl_image_format *format,
-              size_t width, size_t row_pitch,
-              void *host_ptr);
-   };
-
-   class image1d_buffer : public basic_image<CL_MEM_OBJECT_IMAGE1D_BUFFER, 1> {
-   public:
-      image1d_buffer(clover::context &ctx,
-                     std::vector<cl_mem_properties> properties,
-                     cl_mem_flags flags,
-                     const cl_image_format *format,
-                     size_t width, size_t row_pitch,
-                     void *host_ptr, cl_mem buffer);
-   };
-
-   class image1d_array : public basic_image<CL_MEM_OBJECT_IMAGE1D_ARRAY, 1> {
-   public:
-      image1d_array(clover::context &ctx,
-                    std::vector<cl_mem_properties> properties,
-                    cl_mem_flags flags,
-                    const cl_image_format *format,
-                    size_t width,
-                    size_t array_size, size_t slice_pitch,
-                    void *host_ptr);
-   };
-
-   class image2d : public basic_image<CL_MEM_OBJECT_IMAGE2D, 2> {
-   public:
-      image2d(clover::context &ctx,
-              std::vector<cl_mem_properties> properties,
-              cl_mem_flags flags,
-              const cl_image_format *format, size_t width,
-              size_t height, size_t row_pitch,
-              void *host_ptr);
-   };
-
-   class image2d_array : public basic_image<CL_MEM_OBJECT_IMAGE2D_ARRAY, 2> {
-   public:
-      image2d_array(clover::context &ctx,
-                    std::vector<cl_mem_properties> properties,
-                    cl_mem_flags flags,
-                    const cl_image_format *format,
-                    size_t width, size_t height, size_t array_size,
-                    size_t row_pitch, size_t slice_pitch,
-                    void *host_ptr);
-   };
-
-   class image3d : public basic_image<CL_MEM_OBJECT_IMAGE3D, 3>{
-   public:
-      image3d(clover::context &ctx,
-              std::vector<cl_mem_properties> properties,
-              cl_mem_flags flags,
-              const cl_image_format *format,
-              size_t width, size_t height, size_t depth,
-              size_t row_pitch, size_t slice_pitch,
-              void *host_ptr);
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/object.hpp b/src/gallium/frontends/clover/core/object.hpp
deleted file mode 100644
index 4f233425145..00000000000
--- a/src/gallium/frontends/clover/core/object.hpp
+++ /dev/null
@@ -1,239 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_OBJECT_HPP
-#define CLOVER_CORE_OBJECT_HPP
-
-#include <cassert>
-#include <functional>
-#include <vector>
-
-#include "CL/cl.h"
-
-#include "core/error.hpp"
-#include "core/property.hpp"
-#include "api/dispatch.hpp"
-#include "util/macros.h"
-
-///
-/// Main namespace of the CL gallium frontend.
-///
-namespace clover {
-   ///
-   /// Class that represents a CL API object.
-   ///
-   template<typename T, typename S>
-   struct descriptor {
-      typedef T object_type;
-      typedef S descriptor_type;
-
-      descriptor() : dispatch(&_dispatch) {
-         static_assert(std::is_standard_layout<descriptor_type>::value,
-                       "ICD requires CL API objects to be standard layout.");
-      }
-
-      const cl_icd_dispatch *dispatch;
-   };
-
-   struct default_tag;
-   struct allow_empty_tag;
-   struct wait_list_tag;
-   struct property_list_tag;
-
-   namespace detail {
-      template<typename T, typename D>
-      struct descriptor_traits {
-         typedef T object_type;
-
-         static void
-         validate(D *d) {
-            auto o = static_cast<typename D::object_type *>(d);
-            if (!o || o->dispatch != &_dispatch ||
-                !dynamic_cast<object_type *>(o))
-               throw invalid_object_error<T>();
-         }
-
-         static void
-         validate_list(D * const *ds, size_t n) {
-            if (!ds || !n)
-               throw error(CL_INVALID_VALUE);
-         }
-      };
-
-      template<typename D>
-      struct descriptor_traits<default_tag, D> {
-         typedef typename D::object_type object_type;
-
-         static void
-         validate(D *d) {
-            if (!d || d->dispatch != &_dispatch)
-               throw invalid_object_error<object_type>();
-         }
-
-         static void
-         validate_list(D *const *ds, size_t n) {
-            if (!ds || !n)
-               throw error(CL_INVALID_VALUE);
-         }
-      };
-
-      template<typename D>
-      struct descriptor_traits<allow_empty_tag, D> {
-         typedef typename D::object_type object_type;
-
-         static void
-         validate(D *d) {
-            if (!d || d->dispatch != &_dispatch)
-               throw invalid_object_error<object_type>();
-         }
-
-         static void
-         validate_list(D *const *ds, size_t n) {
-            if (bool(ds) != bool(n))
-               throw error(CL_INVALID_VALUE);
-         }
-      };
-
-      template<typename D>
-      struct descriptor_traits<wait_list_tag, D> {
-         typedef typename D::object_type object_type;
-
-         static void
-         validate(D *d) {
-            if (!d || d->dispatch != &_dispatch)
-               throw invalid_wait_list_error();
-         }
-
-         static void
-         validate_list(D *const *ds, size_t n) {
-            if (bool(ds) != bool(n))
-               throw invalid_wait_list_error();
-         }
-      };
-   }
-
-   ///
-   /// Get a Clover object from an API object performing object
-   /// validation.
-   ///
-   /// \a T can either be the Clover object type to return or a \a tag
-   /// object to select some special validation behavior by means of a
-   /// specialization of the detail::descriptor_traits template.  The
-   /// default behavior is to infer the most general Clover object
-   /// type for the given API object.
-   ///
-   template<typename T = default_tag, typename D>
-   typename detail::descriptor_traits<T, D>::object_type &
-   obj(D *d) {
-      detail::descriptor_traits<T, D>::validate(d);
-
-      return static_cast<
-         typename detail::descriptor_traits<T, D>::object_type &>(*d);
-   }
-
-   ///
-   /// Get a pointer to a Clover object from an API object performing
-   /// object validation.  Returns \c NULL if its argument is \c NULL.
-   ///
-   /// \sa obj
-   ///
-   template<typename T = default_tag, typename D>
-   typename detail::descriptor_traits<T, D>::object_type *
-   pobj(D *d) {
-      if (d)
-         detail::descriptor_traits<T, D>::validate(d);
-
-      return static_cast<
-         typename detail::descriptor_traits<T, D>::object_type *>(d);
-   }
-
-   ///
-   /// Get an API object from a Clover object.
-   ///
-   template<typename O>
-   typename O::descriptor_type *
-   desc(O &o) {
-      return static_cast<typename O::descriptor_type *>(&o);
-   }
-
-   ///
-   /// Get an API object from a pointer to a Clover object.
-   ///
-   template<typename O>
-   typename O::descriptor_type *
-   desc(O *o) {
-      return static_cast<typename O::descriptor_type *>(o);
-   }
-
-   ///
-   /// Get a range of Clover objects from a range of API objects
-   /// performing object validation.
-   ///
-   /// \sa obj
-   ///
-   template<typename T = default_tag, typename D>
-   ref_vector<typename detail::descriptor_traits<T, D>::object_type>
-   objs(D *const *ds, size_t n) {
-      detail::descriptor_traits<T, D>::validate_list(ds, n);
-      return map(obj<T, D>, range(ds, n));
-   }
-
-   ///
-   /// Get a range of API objects from a range of Clover objects.
-   ///
-   template<typename Os>
-   std::vector<typename Os::value_type::descriptor_type *>
-   descs(const Os &os) {
-      return map([](typename Os::value_type &o) {
-            return desc(o);
-         }, os);
-   }
-}
-
-struct _cl_context :
-   public clover::descriptor<clover::context, _cl_context> {};
-
-struct _cl_device_id :
-   public clover::descriptor<clover::device, _cl_device_id> {};
-
-struct _cl_event :
-   public clover::descriptor<clover::event, _cl_event> {};
-
-struct _cl_kernel :
-   public clover::descriptor<clover::kernel, _cl_kernel> {};
-
-struct _cl_mem :
-   public clover::descriptor<clover::memory_obj, _cl_mem> {};
-
-struct _cl_platform_id :
-   public clover::descriptor<clover::platform, _cl_platform_id> {};
-
-struct _cl_program :
-   public clover::descriptor<clover::program, _cl_program> {};
-
-struct _cl_command_queue :
-   public clover::descriptor<clover::command_queue, _cl_command_queue> {};
-
-struct _cl_sampler :
-   public clover::descriptor<clover::sampler, _cl_sampler> {};
-
-#endif
diff --git a/src/gallium/frontends/clover/core/platform.cpp b/src/gallium/frontends/clover/core/platform.cpp
deleted file mode 100644
index 581d13a4bf4..00000000000
--- a/src/gallium/frontends/clover/core/platform.cpp
+++ /dev/null
@@ -1,83 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/platform.hpp"
-#include "util/u_debug.h"
-
-using namespace clover;
-
-platform::platform() : adaptor_range(evals(), devs) {
-   int n = pipe_loader_probe(NULL, 0, false);
-   std::vector<pipe_loader_device *> ldevs(n);
-
-   unsigned major = 1, minor = 1;
-   debug_get_version_option("CLOVER_PLATFORM_VERSION_OVERRIDE", &major, &minor);
-   version = CL_MAKE_VERSION(major, minor, 0);
-
-   pipe_loader_probe(&ldevs.front(), n, false);
-
-   for (pipe_loader_device *ldev : ldevs) {
-      try {
-         if (ldev)
-            devs.push_back(create<device>(*this, ldev));
-      } catch (error &) {
-         pipe_loader_release(&ldev, 1);
-      }
-   }
-}
-
-std::vector<cl_name_version>
-platform::supported_extensions() const {
-   std::vector<cl_name_version> vec;
-
-   vec.push_back( cl_name_version{ CL_MAKE_VERSION(1, 0, 0), "cl_khr_icd" } );
-   return vec;
-}
-
-std::string
-platform::supported_extensions_as_string() const {
-   static std::string extensions_string;
-
-   if (!extensions_string.empty())
-      return extensions_string;
-
-   const auto extension_list = supported_extensions();
-   for (const auto &extension : extension_list) {
-      if (!extensions_string.empty())
-         extensions_string += " ";
-      extensions_string += extension.name;
-   }
-   return extensions_string;
-}
-
-std::string
-platform::platform_version_as_string() const {
-   static const std::string version_string =
-      std::to_string(CL_VERSION_MAJOR(version)) + "." +
-      std::to_string(CL_VERSION_MINOR(version));
-   return version_string;
-}
-
-cl_version
-platform::platform_version() const {
-   return version;
-}
diff --git a/src/gallium/frontends/clover/core/platform.hpp b/src/gallium/frontends/clover/core/platform.hpp
deleted file mode 100644
index 983d4e6aa99..00000000000
--- a/src/gallium/frontends/clover/core/platform.hpp
+++ /dev/null
@@ -1,57 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_PLATFORM_HPP
-#define CLOVER_CORE_PLATFORM_HPP
-
-#include <vector>
-
-#include "core/object.hpp"
-#include "core/device.hpp"
-#include "util/range.hpp"
-
-namespace clover {
-   class platform : public _cl_platform_id,
-                    public adaptor_range<
-      evals, std::vector<intrusive_ref<device>> &> {
-   public:
-      platform();
-
-      platform(const platform &platform) = delete;
-      platform &
-      operator=(const platform &platform) = delete;
-
-      std::string supported_extensions_as_string() const;
-      std::vector<cl_name_version> supported_extensions() const;
-
-      std::string platform_version_as_string() const;
-      cl_version platform_version() const;
-
-   protected:
-      cl_version version;
-      std::vector<intrusive_ref<device>> devs;
-   };
-
-   platform &find_platform(cl_platform_id d_platform);
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/printf.cpp b/src/gallium/frontends/clover/core/printf.cpp
deleted file mode 100644
index 5a72fd729fe..00000000000
--- a/src/gallium/frontends/clover/core/printf.cpp
+++ /dev/null
@@ -1,129 +0,0 @@
-//
-// Copyright 2020 Serge Martin
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include <cstring>
-#include <cstdio>
-#include <string>
-#include <iostream>
-
-#include "util/u_math.h"
-#include "core/printf.hpp"
-
-#include "util/u_printf.h"
-using namespace clover;
-
-namespace {
-
-   const cl_uint hdr_dwords = 2;
-   const cl_uint initial_buffer_offset = hdr_dwords * sizeof(cl_uint);
-
-   /* all valid chars that can appear in CL C printf string. */
-   const std::string clc_printf_whitelist = "%0123456789-+ #.AacdeEfFgGhilopsuvxX";
-
-   void
-   print_formatted(std::vector<binary::printf_info> &formatters,
-                   bool _strings_in_buffer,
-                   const std::vector<char> &buffer) {
-
-      static std::atomic<unsigned> warn_count;
-
-      if (buffer.empty() && !warn_count++)
-         std::cerr << "Printf used but no printf occurred - may cause performance issue." << std::endl;
-
-      std::vector<u_printf_info> infos;
-      for (auto &f : formatters) {
-         u_printf_info info;
-
-         info.num_args = f.arg_sizes.size();
-         info.arg_sizes = f.arg_sizes.data();
-         info.string_size = f.strings.size();
-         info.strings = f.strings.data();
-
-         infos.push_back(info);
-      }
-
-      u_printf(stdout, buffer.data(), buffer.size(), infos.data(), infos.size());
-   }
-}
-
-std::unique_ptr<printf_handler>
-printf_handler::create(const intrusive_ptr<command_queue> &q,
-                       const std::vector<binary::printf_info> &infos,
-                       bool strings_in_buffer,
-                       cl_uint size) {
-   return std::unique_ptr<printf_handler>(
-                                       new printf_handler(q, infos, strings_in_buffer, size));
-}
-
-printf_handler::printf_handler(const intrusive_ptr<command_queue> &q,
-                               const std::vector<binary::printf_info> &infos,
-                               bool strings_in_buffer,
-                               cl_uint size) :
-   _q(q), _formatters(infos), _strings_in_buffer(strings_in_buffer), _size(size), _buffer() {
-
-   if (_size) {
-      std::string data;
-      data.reserve(_size);
-      cl_uint header[2] = { 0 };
-
-      header[0] = initial_buffer_offset;
-      header[1] = _size;
-
-      data.append((char *)header, (char *)(header+hdr_dwords));
-      _buffer = std::unique_ptr<root_buffer>(new root_buffer(_q->context,
-                                             std::vector<cl_mem_properties>(),
-                                             CL_MEM_COPY_HOST_PTR,
-                                             _size, (char*)data.data()));
-   }
-}
-
-cl_mem
-printf_handler::get_mem() {
-   return (cl_mem)(_buffer.get());
-}
-
-void
-printf_handler::print() {
-   if (!_buffer)
-      return;
-
-   mapping src = { *_q, _buffer->resource_in(*_q), CL_MAP_READ, true,
-                  {{ 0 }}, {{ _size, 1, 1 }} };
-
-   cl_uint header[2] = { 0 };
-   std::memcpy(header,
-               static_cast<const char *>(src),
-               initial_buffer_offset);
-
-   cl_uint buffer_size = header[0];
-   buffer_size -= initial_buffer_offset;
-   std::vector<char> buf;
-   buf.resize(buffer_size);
-
-   std::memcpy(buf.data(),
-               static_cast<const char *>(src) + initial_buffer_offset,
-               buffer_size);
-
-   // mixed endian isn't going to work, sort it out if anyone cares later.
-   assert(_q->device().endianness() == PIPE_ENDIAN_NATIVE);
-   print_formatted(_formatters, _strings_in_buffer, buf);
-}
diff --git a/src/gallium/frontends/clover/core/printf.hpp b/src/gallium/frontends/clover/core/printf.hpp
deleted file mode 100644
index 4d57a7150bd..00000000000
--- a/src/gallium/frontends/clover/core/printf.hpp
+++ /dev/null
@@ -1,60 +0,0 @@
-//
-// Copyright 2020 Serge Martin
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_PRINTF_HANDLER_HPP
-#define CLOVER_CORE_PRINTF_HANDLER_HPP
-
-#include <memory>
-
-#include "core/memory.hpp"
-
-namespace clover {
-   class printf_handler {
-   public:
-      static std::unique_ptr<printf_handler>
-      create(const intrusive_ptr<command_queue> &q,
-             const std::vector<binary::printf_info> &info,
-             bool strings_in_buffer, cl_uint size);
-
-      printf_handler(const printf_handler &arg) = delete;
-      printf_handler &
-      operator=(const printf_handler &arg) = delete;
-
-      ~printf_handler() {};
-
-      cl_mem get_mem();
-      void print();
-
-   private:
-      printf_handler(const intrusive_ptr<command_queue> &q,
-                     const std::vector<binary::printf_info> &infos,
-                     bool strings_in_buffer, cl_uint size);
-
-      intrusive_ptr<command_queue> _q;
-      std::vector<binary::printf_info> _formatters;
-      bool _strings_in_buffer;
-      cl_uint _size;
-      std::unique_ptr<root_buffer> _buffer;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/program.cpp b/src/gallium/frontends/clover/core/program.cpp
deleted file mode 100644
index 43609a25248..00000000000
--- a/src/gallium/frontends/clover/core/program.cpp
+++ /dev/null
@@ -1,141 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/compiler.hpp"
-#include "core/program.hpp"
-
-using namespace clover;
-
-program::program(clover::context &ctx, std::string &&source,
-                 enum il_type il_type) :
-   context(ctx), _devices(ctx.devices()), _source(std::move(source)),
-   _kernel_ref_counter(0), _il_type(il_type) {
-}
-
-program::program(clover::context &ctx,
-                 const ref_vector<device> &devs,
-                 const std::vector<binary> &binaries) :
-   context(ctx), _devices(devs), _kernel_ref_counter(0),
-   _il_type(il_type::none) {
-   for_each([&](device &dev, const binary &bin) {
-         _builds[&dev] = { bin };
-      },
-      devs, binaries);
-}
-
-void
-program::compile(const ref_vector<device> &devs, const std::string &opts,
-                 const header_map &headers) {
-   if (_il_type != il_type::none) {
-      _devices = devs;
-
-      for (auto &dev : devs) {
-         std::string log;
-
-         try {
-            const binary b =
-               compiler::compile_program(*this, headers, dev, opts, log);
-            _builds[&dev] = { b, opts, log };
-         } catch (...) {
-            _builds[&dev] = { binary(), opts, log };
-            throw;
-         }
-      }
-   }
-}
-
-void
-program::link(const ref_vector<device> &devs, const std::string &opts,
-              const ref_vector<program> &progs) {
-   _devices = devs;
-
-   for (auto &dev : devs) {
-      const std::vector<binary> bs = map([&](const program &prog) {
-         return prog.build(dev).bin;
-         }, progs);
-      std::string log = _builds[&dev].log;
-
-      try {
-         const binary b = compiler::link_program(bs, dev, opts, log);
-         _builds[&dev] = { b, opts, log };
-      } catch (...) {
-         _builds[&dev] = { binary(), opts, log };
-         throw;
-      }
-   }
-}
-
-enum program::il_type
-program::il_type() const {
-   return _il_type;
-}
-
-const std::string &
-program::source() const {
-   return _source;
-}
-
-program::device_range
-program::devices() const {
-   return map(evals(), _devices);
-}
-
-cl_build_status
-program::build::status() const {
-   if (!bin.secs.empty())
-      return CL_BUILD_SUCCESS;
-   else if (log.size())
-      return CL_BUILD_ERROR;
-   else
-      return CL_BUILD_NONE;
-}
-
-cl_program_binary_type
-program::build::binary_type() const {
-   if (any_of(type_equals(binary::section::text_intermediate), bin.secs))
-      return CL_PROGRAM_BINARY_TYPE_COMPILED_OBJECT;
-   else if (any_of(type_equals(binary::section::text_library), bin.secs))
-      return CL_PROGRAM_BINARY_TYPE_LIBRARY;
-   else if (any_of(type_equals(binary::section::text_executable), bin.secs))
-      return CL_PROGRAM_BINARY_TYPE_EXECUTABLE;
-   else
-      return CL_PROGRAM_BINARY_TYPE_NONE;
-}
-
-const struct program::build &
-program::build(const device &dev) const {
-   static const struct build null;
-   return _builds.count(&dev) ? _builds.find(&dev)->second : null;
-}
-
-const std::vector<binary::symbol> &
-program::symbols() const {
-   if (_builds.empty())
-      throw error(CL_INVALID_PROGRAM_EXECUTABLE);
-
-   return _builds.begin()->second.bin.syms;
-}
-
-unsigned
-program::kernel_ref_count() const {
-   return _kernel_ref_counter.ref_count();
-}
diff --git a/src/gallium/frontends/clover/core/program.hpp b/src/gallium/frontends/clover/core/program.hpp
deleted file mode 100644
index 3969f4fd29d..00000000000
--- a/src/gallium/frontends/clover/core/program.hpp
+++ /dev/null
@@ -1,95 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_PROGRAM_HPP
-#define CLOVER_CORE_PROGRAM_HPP
-
-#include <map>
-
-#include "core/object.hpp"
-#include "core/context.hpp"
-#include "core/binary.hpp"
-
-namespace clover {
-   typedef std::vector<std::pair<std::string, std::string>> header_map;
-
-   class program : public ref_counter, public _cl_program {
-   private:
-      typedef adaptor_range<
-         evals, const std::vector<intrusive_ref<device>> &> device_range;
-
-   public:
-      enum class il_type { none, source, spirv };
-
-      program(clover::context &ctx,
-              std::string &&il,
-              enum il_type il_type);
-      program(clover::context &ctx,
-              const ref_vector<device> &devs = {},
-              const std::vector<binary> &binaries = {});
-
-      program(const program &prog) = delete;
-      program &
-      operator=(const program &prog) = delete;
-
-      void compile(const ref_vector<device> &devs, const std::string &opts,
-                   const header_map &headers = {});
-      void link(const ref_vector<device> &devs, const std::string &opts,
-                const ref_vector<program> &progs);
-
-      const std::string &source() const;
-      enum il_type il_type() const;
-
-      device_range devices() const;
-
-      struct build {
-         build(const binary &b = {}, const std::string &opts = {},
-               const std::string &log = {}) : bin(b), opts(opts), log(log) {}
-
-         cl_build_status status() const;
-         cl_program_binary_type binary_type() const;
-
-         binary bin;
-         std::string opts;
-         std::string log;
-      };
-
-      const build &build(const device &dev) const;
-
-      const std::vector<binary::symbol> &symbols() const;
-
-      unsigned kernel_ref_count() const;
-
-      const intrusive_ref<clover::context> context;
-
-      friend class kernel;
-
-   private:
-      std::vector<intrusive_ref<device>> _devices;
-      std::map<const device *, struct build> _builds;
-      std::string _source;
-      ref_counter _kernel_ref_counter;
-      enum il_type _il_type;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/property.hpp b/src/gallium/frontends/clover/core/property.hpp
deleted file mode 100644
index 518f10dcaf9..00000000000
--- a/src/gallium/frontends/clover/core/property.hpp
+++ /dev/null
@@ -1,267 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_PROPERTY_HPP
-#define CLOVER_CORE_PROPERTY_HPP
-
-#include <map>
-
-#include "util/range.hpp"
-#include "util/algorithm.hpp"
-
-namespace clover {
-   class property_buffer;
-
-   namespace detail {
-      template<typename T>
-      class property_scalar {
-      public:
-         property_scalar(property_buffer &buf) : buf(buf) {
-         }
-
-         inline property_scalar &
-         operator=(const T &x);
-
-      private:
-         property_buffer &buf;
-      };
-
-      template<typename T>
-      class property_vector {
-      public:
-         property_vector(property_buffer &buf) : buf(buf) {
-         }
-
-         template<typename S>
-         inline property_vector &
-         operator=(const S &v);
-
-      private:
-         property_buffer &buf;
-      };
-
-      template<typename T>
-      class property_matrix {
-      public:
-         property_matrix(property_buffer &buf) : buf(buf) {
-         }
-
-         template<typename S>
-         inline property_matrix &
-         operator=(const S &v);
-
-      private:
-         property_buffer &buf;
-      };
-
-      class property_string {
-      public:
-         property_string(property_buffer &buf) : buf(buf) {
-         }
-
-         inline property_string &
-         operator=(const std::string &v);
-
-      private:
-         property_buffer &buf;
-      };
-   };
-
-   ///
-   /// Return value buffer used by the CL property query functions.
-   ///
-   class property_buffer {
-   public:
-      property_buffer(void *r_buf, size_t size, size_t *r_size) :
-         r_buf(r_buf), size(size), r_size(r_size) {
-      }
-
-      template<typename T>
-      detail::property_scalar<T>
-      as_scalar() {
-         return { *this };
-      }
-
-      template<typename T>
-      detail::property_vector<T>
-      as_vector() {
-         return { *this };
-      }
-
-      template<typename T>
-      detail::property_matrix<T>
-      as_matrix() {
-         return { *this };
-      }
-
-      detail::property_string
-      as_string() {
-         return { *this };
-      }
-
-      template<typename T>
-      iterator_range<T *>
-      allocate(size_t n) {
-         if (r_buf && size < n * sizeof(T))
-            throw error(CL_INVALID_VALUE);
-
-         if (r_size)
-            *r_size = n * sizeof(T);
-
-         if (r_buf)
-            return range((T *)r_buf, n);
-         else
-            return { };
-      }
-
-   private:
-      void *const r_buf;
-      const size_t size;
-      size_t *const r_size;
-   };
-
-   namespace detail {
-      template<typename T>
-      inline property_scalar<T> &
-      property_scalar<T>::operator=(const T &x) {
-         auto r = buf.allocate<T>(1);
-
-         if (!r.empty())
-            r.front() = x;
-
-         return *this;
-      }
-
-      template<typename T>
-      template<typename S>
-      inline property_vector<T> &
-      property_vector<T>::operator=(const S &v) {
-         auto r = buf.allocate<T>(v.size());
-
-         if (!r.empty())
-            copy(v, r.begin());
-
-         return *this;
-      }
-
-      template<typename T>
-      template<typename S>
-      inline property_matrix<T> &
-      property_matrix<T>::operator=(const S &v) {
-         auto r = buf.allocate<T *>(v.size());
-
-         if (!r.empty())
-            for_each([](typename S::value_type src, T *dst) {
-                  if (dst)
-                     copy(src, dst);
-               }, v, r);
-
-         return *this;
-      }
-
-      inline property_string &
-      property_string::operator=(const std::string &v) {
-         auto r = buf.allocate<char>(v.size() + 1);
-
-         if (!r.empty())
-            copy(range(v.begin(), r.size()), r.begin());
-
-         return *this;
-      }
-   };
-
-   template<typename T>
-   class property_element {
-   public:
-      property_element() : x() {
-      }
-
-      property_element(T x) : x(x) {
-      }
-
-      template<typename S>
-      typename std::enable_if<!std::is_convertible<T, S>::value, S>::type
-      as() const {
-         static_assert(sizeof(S) <= sizeof(T), "Ensure type fits in property list");
-         return reinterpret_cast<S>(x);
-      }
-
-      template<typename S>
-      typename std::enable_if<std::is_convertible<T, S>::value, S>::type
-      as() const {
-         return static_cast<S>(x);
-      }
-
-   private:
-      T x;
-   };
-
-   template<typename D>
-   using property_list = std::map<D, property_element<D>>;
-
-   struct property_list_tag;
-
-   ///
-   /// Create a clover::property_list object from a zero-terminated
-   /// CL property list.
-   ///
-   template<typename T, typename D,
-            typename = typename std::enable_if<
-               std::is_same<T, property_list_tag>::value>::type>
-   property_list<D>
-   obj(const D *d_props) {
-      property_list<D> props;
-
-      while (d_props && *d_props) {
-         auto key = *d_props++;
-         auto value = *d_props++;
-
-         if (props.count(key))
-            throw error(CL_INVALID_PROPERTY);
-
-         props.insert({ key, value });
-      }
-
-      return props;
-   }
-
-   ///
-   /// Create a zero-terminated CL property list from a
-   /// clover::property_list object.
-   ///
-   template<typename D>
-   std::vector<D>
-   desc(const property_list<D> &props) {
-      std::vector<D> d_props;
-
-      for (auto &prop : props) {
-         d_props.push_back(prop.first);
-         d_props.push_back(prop.second.template as<D>());
-      }
-
-      d_props.push_back(0);
-
-      return d_props;
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/queue.cpp b/src/gallium/frontends/clover/core/queue.cpp
deleted file mode 100644
index cd4caadb5f9..00000000000
--- a/src/gallium/frontends/clover/core/queue.cpp
+++ /dev/null
@@ -1,158 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/queue.hpp"
-#include "core/event.hpp"
-#include "pipe/p_screen.h"
-#include "pipe/p_context.h"
-#include "pipe/p_state.h"
-#include "util/u_debug.h"
-
-using namespace clover;
-
-namespace {
-   void
-   debug_notify_callback(void *data,
-                         unsigned *id,
-                         enum util_debug_type type,
-                         const char *fmt,
-                         va_list args) {
-      const command_queue *queue = (const command_queue *)data;
-      char buffer[1024];
-      vsnprintf(buffer, sizeof(buffer), fmt, args);
-      queue->context().notify(buffer);
-   }
-}
-
-command_queue::command_queue(clover::context &ctx, clover::device &dev,
-                             cl_command_queue_properties props) :
-   context(ctx), device(dev), _props(props) {
-   pipe = dev.pipe->context_create(dev.pipe, NULL, PIPE_CONTEXT_COMPUTE_ONLY);
-   if (!pipe)
-      throw error(CL_INVALID_DEVICE);
-
-   if (ctx.notify) {
-      struct util_debug_callback cb;
-      memset(&cb, 0, sizeof(cb));
-      cb.debug_message = &debug_notify_callback;
-      cb.data = this;
-      if (pipe->set_debug_callback)
-         pipe->set_debug_callback(pipe, &cb);
-   }
-}
-command_queue::command_queue(clover::context &ctx, clover::device &dev,
-                             std::vector<cl_queue_properties> properties) :
-   context(ctx), device(dev), _properties(properties), _props(0) {
-
-   for(std::vector<cl_queue_properties>::size_type i = 0; i != properties.size(); i += 2) {
-      if (properties[i] == 0)
-         break;
-      if (properties[i] == CL_QUEUE_PROPERTIES)
-         _props |= properties[i + 1];
-      else if (properties[i] != CL_QUEUE_SIZE)
-         throw error(CL_INVALID_VALUE);
-   }
-
-   pipe = dev.pipe->context_create(dev.pipe, NULL, PIPE_CONTEXT_COMPUTE_ONLY);
-   if (!pipe)
-      throw error(CL_INVALID_DEVICE);
-
-   if (ctx.notify) {
-      struct util_debug_callback cb;
-      memset(&cb, 0, sizeof(cb));
-      cb.debug_message = &debug_notify_callback;
-      cb.data = this;
-      if (pipe->set_debug_callback)
-         pipe->set_debug_callback(pipe, &cb);
-   }
-}
-
-command_queue::~command_queue() {
-   pipe->destroy(pipe);
-}
-
-void
-command_queue::flush() {
-   std::lock_guard<std::mutex> lock(queued_events_mutex);
-   flush_unlocked();
-}
-
-void
-command_queue::flush_unlocked() {
-   pipe_screen *screen = device().pipe;
-   pipe_fence_handle *fence = NULL;
-
-   if (!queued_events.empty()) {
-      pipe->flush(pipe, &fence, 0);
-
-      while (!queued_events.empty() &&
-             queued_events.front()().signalled()) {
-         queued_events.front()().fence(fence);
-         queued_events.pop_front();
-      }
-
-      screen->fence_reference(screen, &fence, NULL);
-   }
-}
-
-void
-command_queue::svm_migrate(const std::vector<void const*> &svm_pointers,
-                           const std::vector<size_t> &sizes,
-                           cl_mem_migration_flags flags) {
-   if (!pipe->svm_migrate)
-      return;
-
-   bool to_device = !(flags & CL_MIGRATE_MEM_OBJECT_HOST);
-   bool mem_undefined = flags & CL_MIGRATE_MEM_OBJECT_CONTENT_UNDEFINED;
-   pipe->svm_migrate(pipe, svm_pointers.size(), svm_pointers.data(),
-                     sizes.data(), to_device, mem_undefined);
-}
-
-cl_command_queue_properties
-command_queue::props() const {
-   return _props;
-}
-
-std::vector<cl_queue_properties>
-command_queue::properties() const {
-   return _properties;
-}
-
-bool
-command_queue::profiling_enabled() const {
-   return _props & CL_QUEUE_PROFILING_ENABLE;
-}
-
-void
-command_queue::sequence(hard_event &ev) {
-   std::lock_guard<std::mutex> lock(queued_events_mutex);
-   if (!queued_events.empty())
-      queued_events.back()().chain(ev);
-
-   queued_events.push_back(ev);
-
-   // Arbitrary threshold.
-   // The CTS tends to run a lot of subtests without flushing with the image
-   // tests, so flush regularly to prevent stack overflows.
-   if (queued_events.size() > 1000)
-      flush_unlocked();
-}
diff --git a/src/gallium/frontends/clover/core/queue.hpp b/src/gallium/frontends/clover/core/queue.hpp
deleted file mode 100644
index b132cd7ad0f..00000000000
--- a/src/gallium/frontends/clover/core/queue.hpp
+++ /dev/null
@@ -1,87 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_QUEUE_HPP
-#define CLOVER_CORE_QUEUE_HPP
-
-#include <deque>
-#include <mutex>
-
-#include "core/object.hpp"
-#include "core/context.hpp"
-#include "core/timestamp.hpp"
-#include "pipe/p_context.h"
-
-namespace clover {
-   class resource;
-   class mapping;
-   class hard_event;
-
-   class command_queue : public ref_counter, public _cl_command_queue {
-   public:
-      command_queue(clover::context &ctx, clover::device &dev,
-                    std::vector<cl_queue_properties> properties);
-      command_queue(clover::context &ctx, clover::device &dev,
-                    cl_command_queue_properties props);
-      ~command_queue();
-
-      command_queue(const command_queue &q) = delete;
-      command_queue &
-      operator=(const command_queue &q) = delete;
-
-      void flush();
-      void svm_migrate(const std::vector<void const *> &svm_pointers,
-                       const std::vector<size_t> &sizes, cl_mem_migration_flags flags);
-
-      cl_command_queue_properties props() const;
-
-      std::vector<cl_queue_properties> properties() const;
-      bool profiling_enabled() const;
-
-      const intrusive_ref<clover::context> context;
-      const intrusive_ref<clover::device> device;
-
-      friend class resource;
-      friend class root_resource;
-      friend class mapping;
-      friend class hard_event;
-      friend class sampler;
-      friend class kernel;
-      friend class clover::timestamp::query;
-      friend class clover::timestamp::current;
-
-   private:
-      /// Serialize a hardware event with respect to the previous ones,
-      /// and push it to the pending list.
-      void sequence(hard_event &ev);
-      // Use this instead of flush() if `queued_events_mutex` is acquired.
-      void flush_unlocked();
-
-      std::vector<cl_queue_properties> _properties;
-      cl_command_queue_properties _props;
-      pipe_context *pipe;
-      std::mutex queued_events_mutex;
-      std::deque<intrusive_ref<hard_event>> queued_events;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/resource.cpp b/src/gallium/frontends/clover/core/resource.cpp
deleted file mode 100644
index 3bef96ed3ee..00000000000
--- a/src/gallium/frontends/clover/core/resource.cpp
+++ /dev/null
@@ -1,281 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/resource.hpp"
-#include "core/memory.hpp"
-#include "pipe/p_screen.h"
-#include "util/u_sampler.h"
-#include "util/format/u_format.h"
-#include "util/u_inlines.h"
-#include "util/u_resource.h"
-#include "util/u_surface.h"
-
-using namespace clover;
-
-namespace {
-   class box {
-   public:
-      box(const resource::vector &origin, const resource::vector &size) {
-         u_box_3d(origin[0], origin[1], origin[2], size[0], size[1], size[2], &pipe);
-      }
-
-      operator const pipe_box *() {
-         return &pipe;
-      }
-
-   protected:
-      pipe_box pipe;
-   };
-}
-
-resource::resource(clover::device &dev, memory_obj &obj) :
-   device(dev), obj(obj), pipe(NULL), offset() {
-}
-
-resource::~resource() {
-}
-
-void
-resource::copy(command_queue &q, const vector &origin, const vector &region,
-               resource &src_res, const vector &src_origin) {
-   auto p = offset + origin;
-
-   q.pipe->resource_copy_region(q.pipe, pipe, 0, p[0], p[1], p[2],
-                                src_res.pipe, 0,
-                                box(src_res.offset + src_origin, region));
-}
-
-void
-resource::clear(command_queue &q, const vector &origin, const vector &region,
-                const std::string &data) {
-   auto from = offset + origin;
-
-   if (pipe->target == PIPE_BUFFER) {
-      q.pipe->clear_buffer(q.pipe, pipe, from[0], region[0], data.data(), data.size());
-   } else {
-      std::string texture_data;
-      texture_data.reserve(util_format_get_blocksize(pipe->format));
-      util_format_pack_rgba(pipe->format, &texture_data[0], data.data(), 1);
-      if (q.pipe->clear_texture) {
-         q.pipe->clear_texture(q.pipe, pipe, 0, box(from, region), texture_data.data());
-      } else {
-         u_default_clear_texture(q.pipe, pipe, 0, box(from, region), texture_data.data());
-      }
-   }
-}
-
-mapping *
-resource::add_map(command_queue &q, cl_map_flags flags, bool blocking,
-                  const vector &origin, const vector &region) {
-   maps.emplace_back(q, *this, flags, blocking, origin, region);
-   return &maps.back();
-}
-
-void
-resource::del_map(void *p) {
-   erase_if([&](const mapping &b) {
-         return static_cast<void *>(b) == p;
-      }, maps);
-}
-
-unsigned
-resource::map_count() const {
-   return maps.size();
-}
-
-pipe_sampler_view *
-resource::bind_sampler_view(command_queue &q) {
-   pipe_sampler_view info;
-
-   u_sampler_view_default_template(&info, pipe, pipe->format);
-   return q.pipe->create_sampler_view(q.pipe, pipe, &info);
-}
-
-void
-resource::unbind_sampler_view(command_queue &q,
-                              pipe_sampler_view *st) {
-   q.pipe->sampler_view_release(q.pipe, st);
-}
-
-pipe_image_view
-resource::create_image_view(command_queue &q) {
-   pipe_image_view view;
-   view.resource = pipe;
-   view.format = pipe->format;
-   view.access = 0;
-   view.shader_access = PIPE_IMAGE_ACCESS_WRITE;
-
-   if (pipe->target == PIPE_BUFFER) {
-      view.u.buf.offset = 0;
-      view.u.buf.size = obj.size();
-   } else {
-      view.u.tex.first_layer = 0;
-      if (util_texture_is_array(pipe->target))
-         view.u.tex.last_layer = pipe->array_size - 1;
-      else
-         view.u.tex.last_layer = 0;
-      view.u.tex.level = 0;
-   }
-
-   return view;
-}
-
-pipe_surface *
-resource::bind_surface(command_queue &q, bool rw) {
-   pipe_surface info {};
-
-   info.format = pipe->format;
-   info.writable = rw;
-
-   if (pipe->target == PIPE_BUFFER)
-      info.u.buf.last_element = pipe->width0 - 1;
-
-   return q.pipe->create_surface(q.pipe, pipe, &info);
-}
-
-void
-resource::unbind_surface(command_queue &q, pipe_surface *st) {
-   q.pipe->surface_destroy(q.pipe, st);
-}
-
-root_resource::root_resource(clover::device &dev, memory_obj &obj,
-                             command_queue &q, const void *data_ptr) :
-   resource(dev, obj) {
-   pipe_resource info {};
-
-   if (image *img = dynamic_cast<image *>(&obj)) {
-      info.format = translate_format(img->format());
-      info.width0 = img->width();
-      info.height0 = img->height();
-      info.depth0 = img->depth();
-      info.array_size = MAX2(1, img->array_size());
-   } else {
-      info.width0 = obj.size();
-      info.height0 = 1;
-      info.depth0 = 1;
-      info.array_size = 1;
-   }
-
-   info.target = translate_target(obj.type());
-   info.bind = (PIPE_BIND_SAMPLER_VIEW |
-                PIPE_BIND_COMPUTE_RESOURCE |
-                PIPE_BIND_GLOBAL);
-
-   if (obj.flags() & CL_MEM_USE_HOST_PTR && dev.allows_user_pointers()) {
-      // Page alignment is normally required for this, just try, hope for the
-      // best and fall back if it fails.
-      pipe = dev.pipe->resource_from_user_memory(dev.pipe, &info, obj.host_ptr());
-      if (pipe)
-         return;
-   }
-
-   if (obj.flags() & (CL_MEM_ALLOC_HOST_PTR | CL_MEM_USE_HOST_PTR)) {
-      info.usage = PIPE_USAGE_STAGING;
-   }
-
-   pipe = dev.pipe->resource_create(dev.pipe, &info);
-   if (!pipe)
-      throw error(CL_OUT_OF_RESOURCES);
-
-   if (data_ptr) {
-      box rect { {{ 0, 0, 0 }}, {{ info.width0, info.height0, info.depth0 }} };
-      unsigned cpp = util_format_get_blocksize(info.format);
-
-      if (pipe->target == PIPE_BUFFER)
-         q.pipe->buffer_subdata(q.pipe, pipe, PIPE_MAP_WRITE,
-                                0, info.width0, data_ptr);
-      else
-         q.pipe->texture_subdata(q.pipe, pipe, 0, PIPE_MAP_WRITE,
-                                 rect, data_ptr, cpp * info.width0,
-                                 cpp * info.width0 * info.height0);
-   }
-}
-
-root_resource::root_resource(clover::device &dev, memory_obj &obj,
-                             root_resource &r) :
-   resource(dev, obj) {
-   assert(0); // XXX -- resource shared among dev and r.dev
-}
-
-root_resource::~root_resource() {
-   pipe_resource_reference(&this->pipe, NULL);
-}
-
-sub_resource::sub_resource(resource &r, const vector &offset) :
-   resource(r.device(), r.obj) {
-   this->pipe = r.pipe;
-   this->offset = r.offset + offset;
-}
-
-mapping::mapping(command_queue &q, resource &r,
-                 cl_map_flags flags, bool blocking,
-                 const resource::vector &origin,
-                 const resource::vector &region) :
-   pctx(q.pipe), pres(NULL) {
-   unsigned usage = ((flags & CL_MAP_WRITE ? PIPE_MAP_WRITE : 0 ) |
-                     (flags & CL_MAP_READ ? PIPE_MAP_READ : 0 ) |
-                     (flags & CL_MAP_WRITE_INVALIDATE_REGION ?
-                      PIPE_MAP_DISCARD_RANGE : 0) |
-                     (!blocking ? PIPE_MAP_UNSYNCHRONIZED : 0));
-
-   p = pctx->buffer_map(pctx, r.pipe, 0, usage,
-                          box(origin + r.offset, region), &pxfer);
-   if (!p) {
-      pxfer = NULL;
-      throw error(CL_OUT_OF_RESOURCES);
-   }
-   pipe_resource_reference(&pres, r.pipe);
-}
-
-mapping::mapping(mapping &&m) :
-   pctx(m.pctx), pxfer(m.pxfer), pres(m.pres), p(m.p) {
-   m.pctx = NULL;
-   m.pxfer = NULL;
-   m.pres = NULL;
-   m.p = NULL;
-}
-
-mapping::~mapping() {
-   if (pxfer) {
-      pctx->buffer_unmap(pctx, pxfer);
-   }
-   pipe_resource_reference(&pres, NULL);
-}
-
-mapping &
-mapping::operator=(mapping m) {
-   std::swap(pctx, m.pctx);
-   std::swap(pxfer, m.pxfer);
-   std::swap(pres, m.pres);
-   std::swap(p, m.p);
-   return *this;
-}
-
-resource::vector
-mapping::pitch() const
-{
-   return {
-      util_format_get_blocksize(pres->format),
-      pxfer->stride,
-      pxfer->layer_stride,
-   };
-}
diff --git a/src/gallium/frontends/clover/core/resource.hpp b/src/gallium/frontends/clover/core/resource.hpp
deleted file mode 100644
index facf31e13bd..00000000000
--- a/src/gallium/frontends/clover/core/resource.hpp
+++ /dev/null
@@ -1,140 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_RESOURCE_HPP
-#define CLOVER_CORE_RESOURCE_HPP
-
-#include <list>
-
-#include "core/queue.hpp"
-#include "util/algebra.hpp"
-#include "pipe/p_state.h"
-
-namespace clover {
-   class memory_obj;
-   class mapping;
-
-   ///
-   /// Class that represents a device-specific instance of some memory
-   /// object.
-   ///
-   class resource {
-   public:
-      typedef std::array<size_t, 3> vector;
-
-      virtual ~resource();
-
-      resource(const resource &r) = delete;
-      resource &
-      operator=(const resource &r) = delete;
-
-      void copy(command_queue &q, const vector &origin, const vector &region,
-                resource &src_resource, const vector &src_origin);
-
-      void clear(command_queue &q, const vector &origin, const vector &region,
-                 const std::string &data);
-
-      mapping *add_map(command_queue &q, cl_map_flags flags, bool blocking,
-                       const vector &origin, const vector &region);
-      void del_map(void *p);
-      unsigned map_count() const;
-
-      const intrusive_ref<clover::device> device;
-      memory_obj &obj;
-
-      friend class sub_resource;
-      friend class mapping;
-      friend class kernel;
-
-   protected:
-      resource(clover::device &dev, memory_obj &obj);
-
-      pipe_sampler_view *bind_sampler_view(command_queue &q);
-      void unbind_sampler_view(command_queue &q,
-                               pipe_sampler_view *st);
-
-      pipe_surface *bind_surface(command_queue &q, bool rw);
-      void unbind_surface(command_queue &q, pipe_surface *st);
-
-      pipe_image_view create_image_view(command_queue &q);
-
-      pipe_resource *pipe;
-      vector offset;
-
-   private:
-      std::list<mapping> maps;
-   };
-
-   ///
-   /// Resource associated with its own top-level data storage
-   /// allocated in some device.
-   ///
-   class root_resource : public resource {
-   public:
-      root_resource(clover::device &dev, memory_obj &obj,
-                    command_queue &q, const void *data_ptr);
-      root_resource(clover::device &dev, memory_obj &obj, root_resource &r);
-      virtual ~root_resource();
-   };
-
-   ///
-   /// Resource that reuses a portion of some other resource as data
-   /// storage.
-   ///
-   class sub_resource : public resource {
-   public:
-      sub_resource(resource &r, const vector &offset);
-   };
-
-   ///
-   /// Class that represents a mapping of some resource into the CPU
-   /// memory space.
-   ///
-   class mapping {
-   public:
-      mapping(command_queue &q, resource &r, cl_map_flags flags,
-              bool blocking, const resource::vector &origin,
-              const resource::vector &region);
-      mapping(mapping &&m);
-      ~mapping();
-
-      mapping &
-      operator=(mapping m);
-
-      mapping(const mapping &m) = delete;
-
-      template<typename T>
-      operator T *() const {
-         return (T *)p;
-      }
-
-      resource::vector pitch() const;
-
-   private:
-      pipe_context *pctx;
-      pipe_transfer *pxfer;
-      pipe_resource *pres;
-      void *p;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/sampler.cpp b/src/gallium/frontends/clover/core/sampler.cpp
deleted file mode 100644
index 3a0dd4dc7c3..00000000000
--- a/src/gallium/frontends/clover/core/sampler.cpp
+++ /dev/null
@@ -1,73 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/sampler.hpp"
-#include "pipe/p_state.h"
-
-using namespace clover;
-
-sampler::sampler(clover::context &ctx, bool norm_mode,
-                 cl_addressing_mode addr_mode,
-                 cl_filter_mode filter_mode) :
-   context(ctx), _norm_mode(norm_mode),
-   _addr_mode(addr_mode), _filter_mode(filter_mode) {
-}
-
-bool
-sampler::norm_mode() {
-   return _norm_mode;
-}
-
-cl_addressing_mode
-sampler::addr_mode() {
-   return _addr_mode;
-}
-
-cl_filter_mode
-sampler::filter_mode() {
-   return _filter_mode;
-}
-
-void *
-sampler::bind(command_queue &q) {
-   struct pipe_sampler_state info {};
-
-   info.unnormalized_coords = !norm_mode();
-
-   info.wrap_s = info.wrap_t = info.wrap_r =
-      (addr_mode() == CL_ADDRESS_CLAMP_TO_EDGE ? PIPE_TEX_WRAP_CLAMP_TO_EDGE :
-       addr_mode() == CL_ADDRESS_CLAMP ? PIPE_TEX_WRAP_CLAMP_TO_BORDER :
-       addr_mode() == CL_ADDRESS_REPEAT ? PIPE_TEX_WRAP_REPEAT :
-       addr_mode() == CL_ADDRESS_MIRRORED_REPEAT ? PIPE_TEX_WRAP_MIRROR_REPEAT :
-       PIPE_TEX_WRAP_CLAMP_TO_EDGE);
-
-   info.min_img_filter = info.mag_img_filter =
-      (filter_mode() == CL_FILTER_LINEAR ? PIPE_TEX_FILTER_LINEAR :
-       PIPE_TEX_FILTER_NEAREST);
-
-   return q.pipe->create_sampler_state(q.pipe, &info);
-}
-
-void
-sampler::unbind(command_queue &q, void *st) {
-   q.pipe->delete_sampler_state(q.pipe, st);
-}
diff --git a/src/gallium/frontends/clover/core/sampler.hpp b/src/gallium/frontends/clover/core/sampler.hpp
deleted file mode 100644
index 2632c3067fa..00000000000
--- a/src/gallium/frontends/clover/core/sampler.hpp
+++ /dev/null
@@ -1,58 +0,0 @@
-//
-// Copyright 2012 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_SAMPLER_HPP
-#define CLOVER_CORE_SAMPLER_HPP
-
-#include "core/object.hpp"
-#include "core/queue.hpp"
-
-namespace clover {
-   class sampler : public ref_counter, public _cl_sampler {
-   public:
-      sampler(clover::context &ctx, bool norm_mode,
-              cl_addressing_mode addr_mode,
-              cl_filter_mode filter_mode);
-
-      sampler(const sampler &s) = delete;
-      sampler &
-      operator=(const sampler &s) = delete;
-
-      bool norm_mode();
-      cl_addressing_mode addr_mode();
-      cl_filter_mode filter_mode();
-
-      const intrusive_ref<clover::context> context;
-
-      friend class kernel;
-
-   private:
-      void *bind(command_queue &q);
-      void unbind(command_queue &q, void *st);
-
-      bool _norm_mode;
-      cl_addressing_mode _addr_mode;
-      cl_filter_mode _filter_mode;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/core/timestamp.cpp b/src/gallium/frontends/clover/core/timestamp.cpp
deleted file mode 100644
index 3fd341f30da..00000000000
--- a/src/gallium/frontends/clover/core/timestamp.cpp
+++ /dev/null
@@ -1,64 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#include "core/timestamp.hpp"
-#include "core/queue.hpp"
-#include "pipe/p_screen.h"
-#include "pipe/p_context.h"
-
-using namespace clover;
-
-timestamp::query::query(command_queue &q) :
-   q(q),
-   _query(q.pipe->create_query(q.pipe, PIPE_QUERY_TIMESTAMP, 0)) {
-   q.pipe->end_query(q.pipe, _query);
-}
-
-timestamp::query::query(query &&other) :
-   q(other.q),
-   _query(other._query) {
-   other._query = NULL;
-}
-
-timestamp::query::~query() {
-   if (_query)
-      q().pipe->destroy_query(q().pipe, _query);
-}
-
-cl_ulong
-timestamp::query::operator()() const {
-   pipe_query_result result;
-
-   if (!q().pipe->get_query_result(q().pipe, _query, false, &result))
-      throw error(CL_PROFILING_INFO_NOT_AVAILABLE);
-
-   return result.u64;
-}
-
-timestamp::current::current(command_queue &q) :
-   result(q.pipe->screen->get_timestamp(q.pipe->screen)) {
-}
-
-cl_ulong
-timestamp::current::operator()() const {
-   return result;
-}
diff --git a/src/gallium/frontends/clover/core/timestamp.hpp b/src/gallium/frontends/clover/core/timestamp.hpp
deleted file mode 100644
index b4b2c83eb92..00000000000
--- a/src/gallium/frontends/clover/core/timestamp.hpp
+++ /dev/null
@@ -1,74 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_CORE_TIMESTAMP_HPP
-#define CLOVER_CORE_TIMESTAMP_HPP
-
-#include "core/object.hpp"
-
-struct pipe_query;
-
-namespace clover {
-   class command_queue;
-
-   namespace timestamp {
-      ///
-      /// Emit a timestamp query that is executed asynchronously by
-      /// the command queue \a q.
-      ///
-      class query {
-      public:
-         query(command_queue &q);
-         query(query &&other);
-         ~query();
-
-         query &operator=(const query &) = delete;
-
-         ///
-         /// Retrieve the query results.
-         ///
-         cl_ulong operator()() const;
-
-      private:
-         const intrusive_ref<command_queue> q;
-         pipe_query *_query;
-      };
-
-      ///
-      /// Get the current timestamp value.
-      ///
-      class current {
-      public:
-         current(command_queue &q);
-
-         ///
-         /// Retrieve the query results.
-         ///
-         cl_ulong operator()() const;
-
-      private:
-         cl_ulong result;
-      };
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/llvm/codegen.hpp b/src/gallium/frontends/clover/llvm/codegen.hpp
deleted file mode 100644
index c07debe0313..00000000000
--- a/src/gallium/frontends/clover/llvm/codegen.hpp
+++ /dev/null
@@ -1,68 +0,0 @@
-//
-// Copyright 2016 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-///
-/// \file
-/// Tools to generate various forms of binary code from existing LLVM IR in
-/// the given llvm::Module object and output the result as a clover::binary.
-///
-
-#ifndef CLOVER_LLVM_CODEGEN_HPP
-#define CLOVER_LLVM_CODEGEN_HPP
-
-#include "llvm/util.hpp"
-#include "core/binary.hpp"
-
-#include <llvm/IR/Module.h>
-
-#include <clang/Frontend/CompilerInstance.h>
-
-namespace clover {
-   namespace llvm {
-      std::string
-      print_module_bitcode(const ::llvm::Module &mod);
-
-      binary
-      build_module_library(const ::llvm::Module &mod,
-                           enum binary::section::type section_type);
-
-      std::unique_ptr< ::llvm::Module>
-      parse_module_library(const binary &b, ::llvm::LLVMContext &ctx,
-                           std::string &r_log);
-
-      binary
-      build_module_native(::llvm::Module &mod, const target &target,
-                          const clang::CompilerInstance &c,
-                          std::string &r_log);
-
-      std::string
-      print_module_native(const ::llvm::Module &mod, const target &target);
-
-      binary
-      build_module_common(const ::llvm::Module &mod,
-                          const std::vector<char> &code,
-                          const std::map<std::string, unsigned> &offsets,
-                          const clang::CompilerInstance &c);
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/llvm/codegen/bitcode.cpp b/src/gallium/frontends/clover/llvm/codegen/bitcode.cpp
deleted file mode 100644
index 568bdd993f5..00000000000
--- a/src/gallium/frontends/clover/llvm/codegen/bitcode.cpp
+++ /dev/null
@@ -1,91 +0,0 @@
-//
-// Copyright 2012-2016 Francisco Jerez
-// Copyright 2012-2016 Advanced Micro Devices, Inc.
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-///
-/// \file
-/// Trivial codegen back-end that simply passes through the existing LLVM IR
-/// and either formats it so it can be consumed by pipe drivers (if
-/// build_module_bitcode() is used) or serializes so it can be deserialized at
-/// a later point and passed to the actual codegen back-end (if
-/// build_module_library() / parse_module_library() is used), potentially
-/// after linking against other bitcode object files.
-///
-
-#include <llvm/Support/Allocator.h>
-
-#include "llvm/codegen.hpp"
-#include "llvm/compat.hpp"
-#include "llvm/metadata.hpp"
-#include "core/error.hpp"
-#include "util/algorithm.hpp"
-
-#include <map>
-#include <llvm/Config/llvm-config.h>
-#include <llvm/Bitcode/BitcodeReader.h>
-#include <llvm/Bitcode/BitcodeWriter.h>
-#include <llvm/Support/raw_ostream.h>
-
-using clover::binary;
-using namespace clover::llvm;
-
-namespace {
-   std::vector<char>
-   emit_code(const ::llvm::Module &mod) {
-      ::llvm::SmallVector<char, 1024> data;
-      ::llvm::raw_svector_ostream os { data };
-      ::llvm::WriteBitcodeToFile(mod, os);
-      return { os.str().begin(), os.str().end() };
-   }
-}
-
-std::string
-clover::llvm::print_module_bitcode(const ::llvm::Module &mod) {
-   std::string s;
-   ::llvm::raw_string_ostream os { s };
-   mod.print(os, NULL);
-   return os.str();
-}
-
-binary
-clover::llvm::build_module_library(const ::llvm::Module &mod,
-                                   enum binary::section::type section_type) {
-   binary b;
-   const auto code = emit_code(mod);
-   b.secs.emplace_back(0, section_type, code.size(), code);
-   return b;
-}
-
-std::unique_ptr< ::llvm::Module>
-clover::llvm::parse_module_library(const binary &b, ::llvm::LLVMContext &ctx,
-                                   std::string &r_log) {
-   auto mod = ::llvm::parseBitcodeFile(::llvm::MemoryBufferRef(
-                                        as_string(b.secs[0].data), " "), ctx);
-
-   if (::llvm::Error err = mod.takeError()) {
-      ::llvm::handleAllErrors(std::move(err), [&](::llvm::ErrorInfoBase &eib) {
-         fail(r_log, error(CL_INVALID_PROGRAM), eib.message());
-      });
-   }
-
-   return std::unique_ptr< ::llvm::Module>(std::move(*mod));
-}
diff --git a/src/gallium/frontends/clover/llvm/codegen/common.cpp b/src/gallium/frontends/clover/llvm/codegen/common.cpp
deleted file mode 100644
index 64a41ccc408..00000000000
--- a/src/gallium/frontends/clover/llvm/codegen/common.cpp
+++ /dev/null
@@ -1,358 +0,0 @@
-//
-// Copyright 2012-2016 Francisco Jerez
-// Copyright 2012-2016 Advanced Micro Devices, Inc.
-// Copyright 2015 Zoltan Gilian
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-///
-/// \file
-/// Codegen back-end-independent part of the construction of an executable
-/// clover::binary, including kernel argument metadata extraction and
-/// formatting of the pre-generated binary code in a form that can be
-/// understood by pipe drivers.
-///
-
-#include <llvm/IR/Type.h>
-#include <llvm/Support/Allocator.h>
-
-#include "llvm/codegen.hpp"
-#include "llvm/compat.hpp"
-#include "llvm/metadata.hpp"
-
-#include "CL/cl.h"
-
-#include "pipe/p_state.h"
-#include "util/u_math.h"
-
-#include <clang/Basic/TargetInfo.h>
-
-using clover::binary;
-using clover::detokenize;
-using namespace clover::llvm;
-
-using ::llvm::Module;
-using ::llvm::Function;
-using ::llvm::Type;
-using ::llvm::isa;
-using ::llvm::cast;
-using ::llvm::dyn_cast;
-
-namespace {
-   enum binary::argument::type
-   get_image_type(const std::string &type,
-                  const std::string &qual) {
-      if (type == "image1d_t" || type == "image2d_t" || type == "image3d_t") {
-         if (qual == "read_only")
-            return binary::argument::image_rd;
-         else if (qual == "write_only")
-            return binary::argument::image_wr;
-      }
-
-      unreachable("Unsupported image type");
-   }
-
-   binary::arg_info create_arg_info(const std::string &arg_name,
-                                    const std::string &type_name,
-                                    const std::string &type_qualifier,
-                                    const uint64_t address_qualifier,
-                                    const std::string &access_qualifier) {
-
-      cl_kernel_arg_type_qualifier cl_type_qualifier =
-                                                   CL_KERNEL_ARG_TYPE_NONE;
-      if (type_qualifier.find("const") != std::string::npos)
-         cl_type_qualifier |= CL_KERNEL_ARG_TYPE_CONST;
-      if (type_qualifier.find("restrict") != std::string::npos)
-         cl_type_qualifier |=  CL_KERNEL_ARG_TYPE_RESTRICT;
-      if (type_qualifier.find("volatile") != std::string::npos)
-         cl_type_qualifier |=  CL_KERNEL_ARG_TYPE_VOLATILE;
-
-      cl_kernel_arg_address_qualifier cl_address_qualifier =
-                                             CL_KERNEL_ARG_ADDRESS_PRIVATE;
-      if (address_qualifier == 1)
-         cl_address_qualifier = CL_KERNEL_ARG_ADDRESS_GLOBAL;
-      else if (address_qualifier == 2)
-         cl_address_qualifier =  CL_KERNEL_ARG_ADDRESS_CONSTANT;
-      else if (address_qualifier == 3)
-         cl_address_qualifier =  CL_KERNEL_ARG_ADDRESS_LOCAL;
-
-      cl_kernel_arg_access_qualifier cl_access_qualifier =
-                                                   CL_KERNEL_ARG_ACCESS_NONE;
-      if (access_qualifier == "read_only")
-         cl_access_qualifier = CL_KERNEL_ARG_ACCESS_READ_ONLY;
-      else if (access_qualifier == "write_only")
-         cl_access_qualifier = CL_KERNEL_ARG_ACCESS_WRITE_ONLY;
-      else if (access_qualifier == "read_write")
-         cl_access_qualifier = CL_KERNEL_ARG_ACCESS_READ_WRITE;
-
-      return binary::arg_info(arg_name, type_name, cl_type_qualifier,
-                              cl_address_qualifier, cl_access_qualifier);
-   }
-
-   std::vector<size_t>
-   get_reqd_work_group_size(const Module &mod,
-                            const std::string &kernel_name) {
-      const Function &f = *mod.getFunction(kernel_name);
-      auto vector_metadata = get_uint_vector_kernel_metadata(f, "reqd_work_group_size");
-
-      return vector_metadata.empty() ? std::vector<size_t>({0, 0, 0}) : vector_metadata;
-   }
-
-
-   std::string
-   kernel_attributes(const Module &mod, const std::string &kernel_name) {
-      std::vector<std::string> attributes;
-
-      const Function &f = *mod.getFunction(kernel_name);
-
-      auto vec_type_hint = get_type_kernel_metadata(f, "vec_type_hint");
-      if (!vec_type_hint.empty())
-         attributes.emplace_back("vec_type_hint(" + vec_type_hint + ")");
-
-      auto work_group_size_hint = get_uint_vector_kernel_metadata(f, "work_group_size_hint");
-      if (!work_group_size_hint.empty()) {
-         std::string s = "work_group_size_hint(";
-         s += detokenize(work_group_size_hint, ",");
-         s += ")";
-         attributes.emplace_back(s);
-      }
-
-      auto reqd_work_group_size = get_uint_vector_kernel_metadata(f, "reqd_work_group_size");
-      if (!reqd_work_group_size.empty()) {
-         std::string s = "reqd_work_group_size(";
-         s += detokenize(reqd_work_group_size, ",");
-         s += ")";
-         attributes.emplace_back(s);
-      }
-
-      auto nosvm = get_str_kernel_metadata(f, "nosvm");
-      if (!nosvm.empty())
-         attributes.emplace_back("nosvm");
-
-      return detokenize(attributes, " ");
-   }
-
-   // Parse the type which are pointers to CL vector types with no prefix.
-   // so e.g. char/uchar, short/ushort, int/uint, long/ulong
-   // half/float/double, followed by the vector length, followed by *.
-   // uint8 is 8x32-bit integer, short4 is 4x16-bit integer etc.
-   // Since this is a pointer only path, assert the * is on the end.
-   ::llvm::Type *
-   ptr_arg_to_llvm_type(const Module &mod, std::string type_name) {
-      int len = type_name.length();
-      assert (type_name[len-1] == '*');
-      ::llvm::Type *base_type = NULL;
-      if (type_name.find("void") != std::string::npos)
-         base_type = ::llvm::Type::getVoidTy(mod.getContext());
-      else if (type_name.find("char") != std::string::npos)
-         base_type = ::llvm::Type::getInt8Ty(mod.getContext());
-      else if (type_name.find("short") != std::string::npos)
-         base_type = ::llvm::Type::getInt16Ty(mod.getContext());
-      else if (type_name.find("int") != std::string::npos)
-         base_type = ::llvm::Type::getInt32Ty(mod.getContext());
-      else if (type_name.find("long") != std::string::npos)
-         base_type = ::llvm::Type::getInt64Ty(mod.getContext());
-      else if (type_name.find("half") != std::string::npos)
-         base_type = ::llvm::Type::getHalfTy(mod.getContext());
-      else if (type_name.find("float") != std::string::npos)
-         base_type = ::llvm::Type::getFloatTy(mod.getContext());
-      else if (type_name.find("double") != std::string::npos)
-         base_type = ::llvm::Type::getDoubleTy(mod.getContext());
-
-      assert(base_type);
-      if (type_name.find("2") != std::string::npos)
-         base_type = ::llvm::FixedVectorType::get(base_type, 2);
-      else if (type_name.find("3") != std::string::npos)
-         base_type = ::llvm::FixedVectorType::get(base_type, 3);
-      else if (type_name.find("4") != std::string::npos)
-         base_type = ::llvm::FixedVectorType::get(base_type, 4);
-      else if (type_name.find("8") != std::string::npos)
-         base_type = ::llvm::FixedVectorType::get(base_type, 8);
-      else if (type_name.find("16") != std::string::npos)
-         base_type = ::llvm::FixedVectorType::get(base_type, 16);
-      return base_type;
-   }
-
-   std::vector<binary::argument>
-   make_kernel_args(const Module &mod, const std::string &kernel_name,
-                    const clang::CompilerInstance &c) {
-      std::vector<binary::argument> args;
-      const Function &f = *mod.getFunction(kernel_name);
-#if LLVM_VERSION_MAJOR >= 20
-      const ::llvm::DataLayout &dl = mod.getDataLayout();
-#else
-      ::llvm::DataLayout dl(&mod);
-#endif
-      const auto size_type =
-         dl.getSmallestLegalIntType(mod.getContext(), sizeof(cl_uint) * 8);
-      const unsigned size_align = compat::get_abi_type_alignment(dl, size_type);
-
-      for (const auto &arg : f.args()) {
-         const auto arg_type = arg.getType();
-
-         // OpenCL 1.2 specification, Ch. 6.1.5: "A built-in data
-         // type that is not a power of two bytes in size must be
-         // aligned to the next larger power of two.
-         // This rule applies to built-in types only, not structs or unions."
-         const unsigned arg_api_size = dl.getTypeAllocSize(arg_type);
-
-         const unsigned target_size = dl.getTypeStoreSize(arg_type);
-         const unsigned target_align = compat::get_abi_type_alignment(dl, arg_type);
-
-         const auto type_name = get_str_argument_metadata(f, arg,
-                                                          "kernel_arg_type");
-         if (type_name == "image2d_t" || type_name == "image3d_t") {
-            // Image.
-            const auto access_qual = get_str_argument_metadata(
-               f, arg, "kernel_arg_access_qual");
-            args.emplace_back(get_image_type(type_name, access_qual),
-                              target_size, target_size,
-                              target_align, binary::argument::zero_ext);
-
-         } else if (type_name == "sampler_t") {
-            args.emplace_back(binary::argument::sampler, arg_api_size,
-                              target_size, target_align,
-                              binary::argument::zero_ext);
-
-         } else if (type_name == "__llvm_image_size") {
-            // Image size implicit argument.
-            args.emplace_back(binary::argument::scalar, sizeof(cl_uint),
-                              dl.getTypeStoreSize(size_type),
-                              size_align,
-                              binary::argument::zero_ext,
-                              binary::argument::image_size);
-
-         } else if (type_name == "__llvm_image_format") {
-            // Image format implicit argument.
-            args.emplace_back(binary::argument::scalar, sizeof(cl_uint),
-                              dl.getTypeStoreSize(size_type),
-                              size_align,
-                              binary::argument::zero_ext,
-                              binary::argument::image_format);
-
-         } else {
-            // Other types.
-            const auto actual_type =
-               isa< ::llvm::PointerType>(arg_type) && arg.hasByValAttr() ?
-               ptr_arg_to_llvm_type(mod, type_name) : arg_type;
-
-            if (actual_type->isPointerTy()) {
-               const unsigned address_space =
-                  cast< ::llvm::PointerType>(actual_type)->getAddressSpace();
-
-               const auto &map = c.getTarget().getAddressSpaceMap();
-               const auto offset =
-                           static_cast<unsigned>(clang::LangAS::opencl_local);
-               if (address_space == map[offset]) {
-                  const auto pointee_type = ptr_arg_to_llvm_type(mod, type_name);
-
-                  args.emplace_back(binary::argument::local, arg_api_size,
-                                    target_size,
-                                    (pointee_type->isVoidTy()) ? 8 :
-                                    compat::get_abi_type_alignment(dl, pointee_type),
-                                    binary::argument::zero_ext);
-               } else {
-                  // XXX: Correctly handle constant address space.  There is no
-                  // way for r600g to pass a handle for constant buffers back
-                  // to clover like it can for global buffers, so
-                  // creating constant arguments will break r600g.  For now,
-                  // continue treating constant buffers as global buffers
-                  // until we can come up with a way to create handles for
-                  // constant buffers.
-                  args.emplace_back(binary::argument::global, arg_api_size,
-                                    target_size, target_align,
-                                    binary::argument::zero_ext);
-               }
-
-            } else {
-               const bool needs_sign_ext = f.getAttributes().hasParamAttr(
-                  arg.getArgNo(), ::llvm::Attribute::SExt);
-
-               args.emplace_back(binary::argument::scalar, arg_api_size,
-                                 target_size, target_align,
-                                 (needs_sign_ext ? binary::argument::sign_ext :
-                                  binary::argument::zero_ext));
-            }
-
-            // Add kernel argument infos if built with -cl-kernel-arg-info.
-            if (c.getCodeGenOpts().EmitOpenCLArgMetadata) {
-               args.back().info = create_arg_info(
-                  get_str_argument_metadata(f, arg, "kernel_arg_name"),
-                  type_name,
-                  get_str_argument_metadata(f, arg, "kernel_arg_type_qual"),
-                  get_uint_argument_metadata(f, arg, "kernel_arg_addr_space"),
-                  get_str_argument_metadata(f, arg, "kernel_arg_access_qual"));
-            }
-         }
-      }
-
-      // Append implicit arguments.  XXX - The types, ordering and
-      // vector size of the implicit arguments should depend on the
-      // target according to the selected calling convention.
-      args.emplace_back(binary::argument::scalar, sizeof(cl_uint),
-                        dl.getTypeStoreSize(size_type),
-                        size_align,
-                        binary::argument::zero_ext,
-                        binary::argument::grid_dimension);
-
-      args.emplace_back(binary::argument::scalar, sizeof(cl_uint),
-                        dl.getTypeStoreSize(size_type),
-                        size_align,
-                        binary::argument::zero_ext,
-                        binary::argument::grid_offset);
-
-      return args;
-   }
-
-   binary::section
-   make_text_section(const std::vector<char> &code) {
-      const pipe_binary_program_header header { uint32_t(code.size()) };
-      binary::section text { 0, binary::section::text_executable,
-                             header.num_bytes, {} };
-
-      text.data.insert(text.data.end(), reinterpret_cast<const char *>(&header),
-                       reinterpret_cast<const char *>(&header) + sizeof(header));
-      text.data.insert(text.data.end(), code.begin(), code.end());
-
-      return text;
-   }
-}
-
-binary
-clover::llvm::build_module_common(const Module &mod,
-                                  const std::vector<char> &code,
-                                  const std::map<std::string,
-                                                 unsigned> &offsets,
-                                  const clang::CompilerInstance &c) {
-   binary b;
-
-   for (const auto &llvm_name : map(std::mem_fn(&Function::getName),
-                               get_kernels(mod))) {
-      const ::std::string name(llvm_name);
-      if (offsets.count(name))
-         b.syms.emplace_back(name, kernel_attributes(mod, name),
-                             get_reqd_work_group_size(mod, name),
-                             0, offsets.at(name),
-                             make_kernel_args(mod, name, c));
-   }
-
-   b.secs.push_back(make_text_section(code));
-   return b;
-}
diff --git a/src/gallium/frontends/clover/llvm/codegen/native.cpp b/src/gallium/frontends/clover/llvm/codegen/native.cpp
deleted file mode 100644
index 72046c8a188..00000000000
--- a/src/gallium/frontends/clover/llvm/codegen/native.cpp
+++ /dev/null
@@ -1,190 +0,0 @@
-//
-// Copyright 2012-2016 Francisco Jerez
-// Copyright 2012-2016 Advanced Micro Devices, Inc.
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-///
-/// \file
-/// Generate code using an arbitrary LLVM back-end capable of emitting
-/// executable code as an ELF object file.
-///
-
-#include <llvm/Target/TargetMachine.h>
-#include <llvm/Transforms/Utils/Cloning.h>
-
-#include "llvm/codegen.hpp"
-#include "llvm/compat.hpp"
-#include "llvm/util.hpp"
-#include "core/error.hpp"
-
-using clover::binary;
-using clover::build_error;
-using namespace clover::llvm;
-using ::llvm::TargetMachine;
-
-#if defined(USE_LIBELF)
-
-#include <libelf.h>
-#include <gelf.h>
-
-namespace {
-   namespace elf {
-      std::unique_ptr<Elf, int (*)(Elf *)>
-      get(const std::vector<char> &code) {
-         // One of the libelf implementations
-         // (http://www.mr511.de/software/english.htm) requires calling
-         // elf_version() before elf_memory().
-         elf_version(EV_CURRENT);
-         return { elf_memory(const_cast<char *>(code.data()), code.size()),
-                  elf_end };
-      }
-
-      Elf_Scn *
-      get_symbol_table(Elf *elf) {
-         size_t section_str_index;
-         elf_getshdrstrndx(elf, &section_str_index);
-
-         for (Elf_Scn *s = elf_nextscn(elf, NULL); s; s = elf_nextscn(elf, s)) {
-            GElf_Shdr header;
-            if (gelf_getshdr(s, &header) != &header)
-               return nullptr;
-
-            if (!std::strcmp(elf_strptr(elf, section_str_index, header.sh_name),
-                             ".symtab"))
-               return s;
-         }
-
-         return nullptr;
-      }
-
-      std::map<std::string, unsigned>
-      get_symbol_offsets(Elf *elf, Elf_Scn *symtab) {
-         Elf_Data *const symtab_data = elf_getdata(symtab, NULL);
-         GElf_Shdr header;
-         if (gelf_getshdr(symtab, &header) != &header)
-            return {};
-
-         std::map<std::string, unsigned> symbol_offsets;
-         GElf_Sym symbol;
-         unsigned i = 0;
-
-         while (GElf_Sym *s = gelf_getsym(symtab_data, i++, &symbol)) {
-            const char *name = elf_strptr(elf, header.sh_link, s->st_name);
-            symbol_offsets[name] = s->st_value;
-         }
-
-         return symbol_offsets;
-      }
-   }
-
-   std::map<std::string, unsigned>
-   get_symbol_offsets(const std::vector<char> &code, std::string &r_log) {
-      const auto elf = elf::get(code);
-      const auto symtab = elf::get_symbol_table(elf.get());
-      if (!symtab)
-         fail(r_log, build_error(), "Unable to find symbol table.");
-
-      return elf::get_symbol_offsets(elf.get(), symtab);
-   }
-
-   std::vector<char>
-   emit_code(::llvm::Module &mod, const target &target,
-             compat::CodeGenFileType ft,
-             std::string &r_log) {
-      std::string err;
-      auto t = ::llvm::TargetRegistry::lookupTarget(target.triple, err);
-      if (!t)
-         fail(r_log, build_error(), err);
-
-      std::unique_ptr<TargetMachine> tm {
-         t->createTargetMachine(target.triple, target.cpu, "", {},
-#if LLVM_VERSION_MAJOR >= 16
-                                std::nullopt, std::nullopt,
-#else
-                                ::llvm::None, ::llvm::None,
-#endif
-#if LLVM_VERSION_MAJOR >= 18
-                                ::llvm::CodeGenOptLevel::Default) };
-#else
-                                ::llvm::CodeGenOpt::Default) };
-#endif
-      if (!tm)
-         fail(r_log, build_error(),
-              "Could not create TargetMachine: " + target.triple);
-
-      ::llvm::SmallVector<char, 1024> data;
-
-      {
-         ::llvm::legacy::PassManager pm;
-         ::llvm::raw_svector_ostream os { data };
-
-         mod.setDataLayout(tm->createDataLayout());
-         tm->Options.MCOptions.AsmVerbose =
-            (ft == compat::CGFT_AssemblyFile);
-
-         if (tm->addPassesToEmitFile(pm, os, nullptr, ft))
-            fail(r_log, build_error(), "TargetMachine can't emit this file");
-
-         pm.run(mod);
-      }
-
-      return { data.begin(), data.end() };
-   }
-}
-
-binary
-clover::llvm::build_module_native(::llvm::Module &mod, const target &target,
-                                  const clang::CompilerInstance &c,
-                                  std::string &r_log) {
-   const auto code = emit_code(mod, target,
-                               compat::CGFT_ObjectFile, r_log);
-   return build_module_common(mod, code, get_symbol_offsets(code, r_log), c);
-}
-
-std::string
-clover::llvm::print_module_native(const ::llvm::Module &mod,
-                                  const target &target) {
-   std::string log;
-   try {
-      std::unique_ptr< ::llvm::Module> cmod { ::llvm::CloneModule(mod) };
-      return as_string(emit_code(*cmod, target,
-                                 compat::CGFT_AssemblyFile, log));
-   } catch (...) {
-      return "Couldn't output native disassembly: " + log;
-   }
-}
-
-#else
-
-binary
-clover::llvm::build_module_native(::llvm::Module &mod, const target &target,
-                                  const clang::CompilerInstance &c,
-                                  std::string &r_log) {
-   unreachable("Native codegen support disabled at build time");
-}
-
-std::string
-clover::llvm::print_module_native(const ::llvm::Module &mod,
-                                  const target &target) {
-   unreachable("Native codegen support disabled at build time");
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/llvm/compat.hpp b/src/gallium/frontends/clover/llvm/compat.hpp
deleted file mode 100644
index 3b04adb88f2..00000000000
--- a/src/gallium/frontends/clover/llvm/compat.hpp
+++ /dev/null
@@ -1,140 +0,0 @@
-//
-// Copyright 2016 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-///
-/// \file
-/// Some thin wrappers around the Clang/LLVM API used to preserve
-/// compatibility with older API versions while keeping the ifdef clutter low
-/// in the rest of the clover::llvm subtree.  In case of an API break please
-/// consider whether it's possible to preserve backwards compatibility by
-/// introducing a new one-liner inline function or typedef here under the
-/// compat namespace in order to keep the running code free from preprocessor
-/// conditionals.
-///
-
-#ifndef CLOVER_LLVM_COMPAT_HPP
-#define CLOVER_LLVM_COMPAT_HPP
-
-#include "util/algorithm.hpp"
-
-#include <llvm/Config/llvm-config.h>
-
-#include <llvm/Analysis/TargetLibraryInfo.h>
-#include <llvm/IR/LegacyPassManager.h>
-#include <llvm/IR/LLVMContext.h>
-#include <llvm/IR/Type.h>
-#include <llvm/Linker/Linker.h>
-#include <llvm/Support/CodeGen.h>
-#include <llvm/Target/TargetMachine.h>
-#include <llvm/Transforms/IPO.h>
-#include <llvm/Transforms/Utils/Cloning.h>
-
-#include <clang/Basic/TargetInfo.h>
-#include <clang/Frontend/CompilerInstance.h>
-#include <clang/Lex/PreprocessorOptions.h>
-
-#if LLVM_VERSION_MAJOR >= 14
-#include <llvm/MC/TargetRegistry.h>
-#else
-#include <llvm/Support/TargetRegistry.h>
-#endif
-
-#if LLVM_VERSION_MAJOR >= 17
-#include <llvm/TargetParser/Triple.h>
-#else
-#include <llvm/ADT/Triple.h>
-#endif
-
-namespace clover {
-   namespace llvm {
-      namespace compat {
-
-#if LLVM_VERSION_MAJOR >= 18
-         const auto CGFT_ObjectFile = ::llvm::CodeGenFileType::ObjectFile;
-         const auto CGFT_AssemblyFile = ::llvm::CodeGenFileType::AssemblyFile;
-#else
-         const auto CGFT_ObjectFile = ::llvm::CGFT_ObjectFile;
-         const auto CGFT_AssemblyFile = ::llvm::CGFT_AssemblyFile;
-#endif
-         typedef ::llvm::CodeGenFileType CodeGenFileType;
-
-         const clang::InputKind ik_opencl = clang::Language::OpenCL;
-
-         template<typename T> inline bool
-         create_compiler_invocation_from_args(clang::CompilerInvocation &cinv,
-                                              T copts,
-                                              clang::DiagnosticsEngine &diag)
-         {
-            return clang::CompilerInvocation::CreateFromArgs(
-               cinv, copts, diag);
-         }
-
-         static inline void
-         compiler_set_lang_defaults(std::unique_ptr<clang::CompilerInstance> &c,
-                                    clang::InputKind ik, const ::llvm::Triple& triple,
-                                    clang::LangStandard::Kind d)
-         {
-#if LLVM_VERSION_MAJOR >= 15
-            c->getLangOpts().setLangDefaults(c->getLangOpts(), ik.getLanguage(), triple,
-#else
-            c->getInvocation().setLangDefaults(c->getLangOpts(), ik, triple,
-#endif
-#if LLVM_VERSION_MAJOR >= 12
-                                               c->getPreprocessorOpts().Includes,
-#else
-                                               c->getPreprocessorOpts(),
-#endif
-                                               d);
-         }
-
-         static inline unsigned
-         get_abi_type_alignment(::llvm::DataLayout dl, ::llvm::Type *type)
-         {
-#if LLVM_VERSION_MAJOR >= 16
-            return dl.getABITypeAlign(type).value();
-#else
-            return dl.getABITypeAlignment(type);
-#endif
-         }
-
-         static inline bool
-         is_scalable_vector(const ::llvm::Type *type)
-         {
-            return ::llvm::isa<::llvm::ScalableVectorType>(type);
-         }
-
-         static inline bool
-         is_fixed_vector(const ::llvm::Type *type)
-         {
-            return ::llvm::isa<::llvm::FixedVectorType>(type);
-         }
-
-         static inline unsigned
-         get_fixed_vector_elements(const ::llvm::Type *type)
-         {
-            return ::llvm::cast<::llvm::FixedVectorType>(type)->getNumElements();
-         }
-      }
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/llvm/invocation.cpp b/src/gallium/frontends/clover/llvm/invocation.cpp
deleted file mode 100644
index ccec22fb621..00000000000
--- a/src/gallium/frontends/clover/llvm/invocation.cpp
+++ /dev/null
@@ -1,580 +0,0 @@
-//
-// Copyright 2012-2016 Francisco Jerez
-// Copyright 2012-2016 Advanced Micro Devices, Inc.
-// Copyright 2014-2016 Jan Vesely
-// Copyright 2014-2015 Serge Martin
-// Copyright 2015 Zoltan Gilian
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifdef HAVE_DLFCN_H
-#include <dlfcn.h>
-#endif
-
-#include <llvm/IR/DiagnosticPrinter.h>
-#include <llvm/IR/DiagnosticInfo.h>
-#include <llvm/IR/LLVMContext.h>
-#include <llvm/IR/Module.h>
-#include <llvm/Support/raw_ostream.h>
-#include <llvm/Transforms/IPO/Internalize.h>
-#include <llvm-c/Target.h>
-#include <llvm-c/TargetMachine.h>
-#include <llvm-c/Transforms/PassBuilder.h>
-#include <llvm/Support/CBindingWrapping.h>
-#include <clang/CodeGen/CodeGenAction.h>
-#include <clang/Lex/PreprocessorOptions.h>
-#include <clang/Frontend/TextDiagnosticBuffer.h>
-#include <clang/Frontend/TextDiagnosticPrinter.h>
-#include <clang/Basic/TargetInfo.h>
-#include <clang/Config/config.h>
-#include <clang/Driver/Driver.h>
-
-#if LLVM_VERSION_MAJOR >= 20
-#include <llvm/Support/VirtualFileSystem.h>
-#endif
-
-// We need to include internal headers last, because the internal headers
-// include CL headers which have #define's like:
-//
-//#define cl_khr_gl_sharing 1
-//#define cl_khr_icd 1
-//
-// Which will break the compilation of clang/Basic/OpenCLOptions.h
-
-#include "core/error.hpp"
-#include "llvm/codegen.hpp"
-#include "llvm/compat.hpp"
-#include "llvm/invocation.hpp"
-#include "llvm/metadata.hpp"
-#include "llvm/util.hpp"
-#include "util/algorithm.hpp"
-
-
-using clover::binary;
-using clover::device;
-using clover::build_error;
-using clover::invalid_build_options_error;
-using clover::map;
-using clover::header_map;
-using namespace clover::llvm;
-
-using ::llvm::Function;
-using ::llvm::LLVMContext;
-using ::llvm::Module;
-using ::llvm::raw_string_ostream;
-
-namespace {
-
-   static const cl_version ANY_VERSION = CL_MAKE_VERSION(9, 9, 9);
-   const cl_version cl_versions[] = {
-      CL_MAKE_VERSION(1, 1, 0),
-      CL_MAKE_VERSION(1, 2, 0),
-      CL_MAKE_VERSION(2, 0, 0),
-      CL_MAKE_VERSION(2, 1, 0),
-      CL_MAKE_VERSION(2, 2, 0),
-      CL_MAKE_VERSION(3, 0, 0),
-   };
-
-    struct clc_version_lang_std {
-        cl_version version_number; // CLC Version
-        clang::LangStandard::Kind clc_lang_standard;
-    };
-
-    const clc_version_lang_std cl_version_lang_stds[] = {
-       { CL_MAKE_VERSION(1, 0, 0), clang::LangStandard::lang_opencl10},
-       { CL_MAKE_VERSION(1, 1, 0), clang::LangStandard::lang_opencl11},
-       { CL_MAKE_VERSION(1, 2, 0), clang::LangStandard::lang_opencl12},
-       { CL_MAKE_VERSION(2, 0, 0), clang::LangStandard::lang_opencl20},
-#if LLVM_VERSION_MAJOR >= 12
-       { CL_MAKE_VERSION(3, 0, 0), clang::LangStandard::lang_opencl30},
-#endif
-    };
-
-   bool
-   are_equal(cl_version_khr version1, cl_version_khr version2,
-             bool ignore_patch_version = false) {
-      if (ignore_patch_version) {
-         version1 &= ~CL_VERSION_PATCH_MASK_KHR;
-         version2 &= ~CL_VERSION_PATCH_MASK_KHR;
-      }
-      return version1 == version2;
-   }
-
-   void
-   init_targets() {
-      static bool targets_initialized = false;
-      if (!targets_initialized) {
-         LLVMInitializeAllTargets();
-         LLVMInitializeAllTargetInfos();
-         LLVMInitializeAllTargetMCs();
-         LLVMInitializeAllAsmParsers();
-         LLVMInitializeAllAsmPrinters();
-         targets_initialized = true;
-      }
-   }
-
-   void
-#if LLVM_VERSION_MAJOR >= 19
-   diagnostic_handler(const ::llvm::DiagnosticInfo *di, void *data) {
-      if (di->getSeverity() == ::llvm::DS_Error) {
-#else
-   diagnostic_handler(const ::llvm::DiagnosticInfo &di, void *data) {
-      if (di.getSeverity() == ::llvm::DS_Error) {
-#endif
-         raw_string_ostream os { *reinterpret_cast<std::string *>(data) };
-         ::llvm::DiagnosticPrinterRawOStream printer { os };
-#if LLVM_VERSION_MAJOR >= 19
-         di->print(printer);
-#else
-         di.print(printer);
-#endif
-         throw build_error();
-      }
-   }
-
-   std::unique_ptr<LLVMContext>
-   create_context(std::string &r_log) {
-      init_targets();
-      std::unique_ptr<LLVMContext> ctx { new LLVMContext };
-
-      ctx->setDiagnosticHandlerCallBack(diagnostic_handler, &r_log);
-      return ctx;
-   }
-
-   const struct clc_version_lang_std&
-   get_cl_lang_standard(unsigned requested, unsigned max = ANY_VERSION) {
-       for (const struct clc_version_lang_std &version : cl_version_lang_stds) {
-           if (version.version_number == max ||
-                   version.version_number == requested) {
-               return version;
-           }
-       }
-       throw build_error("Unknown/Unsupported language version");
-   }
-
-   const cl_version
-   get_cl_version(cl_version requested,
-                  cl_version max = ANY_VERSION) {
-      for (const auto &version : cl_versions) {
-         if (are_equal(version, max, true) ||
-             are_equal(version, requested, true)) {
-            return version;
-         }
-      }
-      throw build_error("Unknown/Unsupported language version");
-   }
-
-   clang::LangStandard::Kind
-   get_lang_standard_from_version(const cl_version input_version,
-                                  bool is_build_opt = false) {
-
-       //Per CL 2.0 spec, section 5.8.4.5:
-       //  If it's an option, use the value directly.
-       //  If it's a device version, clamp to max 1.x version, a.k.a. 1.2
-      const cl_version version =
-         get_cl_version(input_version, is_build_opt ? ANY_VERSION : 120);
-
-      const struct clc_version_lang_std standard =
-         get_cl_lang_standard(version);
-
-      return standard.clc_lang_standard;
-   }
-
-   clang::LangStandard::Kind
-   get_language_version(const std::vector<std::string> &opts,
-                        const cl_version device_version) {
-
-      const std::string search = "-cl-std=CL";
-
-      for (auto &opt: opts) {
-         auto pos = opt.find(search);
-         if (pos == 0){
-            std::stringstream ver_str(opt.substr(pos + search.size()));
-            unsigned int ver_major = 0;
-            char separator = '\0';
-            unsigned int ver_minor = 0;
-            ver_str >> ver_major >> separator >> ver_minor;
-            if (ver_str.fail() || ver_str.bad() || !ver_str.eof() ||
-                 separator != '.') {
-               throw build_error();
-            }
-            const auto ver = CL_MAKE_VERSION_KHR(ver_major, ver_minor, 0);
-            const auto device_ver = get_cl_version(device_version);
-            const auto requested = get_cl_version(ver);
-            if (requested > device_ver) {
-               throw build_error();
-            }
-            return get_lang_standard_from_version(ver, true);
-         }
-      }
-
-      return get_lang_standard_from_version(device_version);
-   }
-
-   std::unique_ptr<clang::CompilerInstance>
-   create_compiler_instance(const device &dev, const std::string& ir_target,
-                            const std::vector<std::string> &opts,
-                            std::string &r_log) {
-      std::unique_ptr<clang::CompilerInstance> c { new clang::CompilerInstance };
-      clang::TextDiagnosticBuffer *diag_buffer = new clang::TextDiagnosticBuffer;
-      clang::DiagnosticsEngine diag { new clang::DiagnosticIDs,
-            new clang::DiagnosticOptions, diag_buffer };
-
-      // Parse the compiler options.  A file name should be present at the end
-      // and must have the .cl extension in order for the CompilerInvocation
-      // class to recognize it as an OpenCL source file.
-#if LLVM_VERSION_MAJOR >= 12
-      std::vector<const char *> copts;
-#if LLVM_VERSION_MAJOR == 15 || LLVM_VERSION_MAJOR == 16
-      // Before LLVM commit 702d5de4 opaque pointers were supported but not enabled
-      // by default when building LLVM. They were made default in commit 702d5de4.
-      // LLVM commit d69e9f9d introduced -opaque-pointers/-no-opaque-pointers cc1
-      // options to enable or disable them whatever the LLVM default is.
-
-      // Those two commits follow llvmorg-15-init and precede llvmorg-15.0.0-rc1 tags.
-
-      // Since LLVM commit d785a8ea, the CLANG_ENABLE_OPAQUE_POINTERS build option of
-      // LLVM is removed, meaning there is no way to build LLVM with opaque pointers
-      // enabled by default.
-      // It was said at the time it was still possible to explicitly disable opaque
-      // pointers via cc1 -no-opaque-pointers option, but it is known a later commit
-      // broke backward compatibility provided by -no-opaque-pointers as verified with
-      // arbitrary commit d7d586e5, so there is no way to use opaque pointers starting
-      // with LLVM 16.
-
-      // Those two commits follow llvmorg-16-init and precede llvmorg-16.0.0-rc1 tags.
-
-      // Since Mesa commit 977dbfc9 opaque pointers are properly implemented in Clover
-      // and used.
-
-      // If we don't pass -opaque-pointers to Clang on LLVM versions supporting opaque
-      // pointers but disabling them by default, there will be an API mismatch between
-      // Mesa and LLVM and Clover will not work.
-      copts.push_back("-opaque-pointers");
-#endif
-      for (auto &opt : opts) {
-         if (opt == "-cl-denorms-are-zero")
-            copts.push_back("-fdenormal-fp-math=positive-zero");
-         else
-            copts.push_back(opt.c_str());
-      }
-#else
-      const std::vector<const char *> copts =
-         map(std::mem_fn(&std::string::c_str), opts);
-#endif
-
-      const target &target = ir_target;
-      const cl_version device_clc_version = dev.device_clc_version();
-
-      if (!compat::create_compiler_invocation_from_args(
-             c->getInvocation(), copts, diag))
-         throw invalid_build_options_error();
-
-      diag_buffer->FlushDiagnostics(diag);
-      if (diag.hasErrorOccurred())
-         throw invalid_build_options_error();
-
-      c->getTargetOpts().CPU = target.cpu;
-      c->getTargetOpts().Triple = target.triple;
-      c->getLangOpts().NoBuiltin = true;
-
-#if LLVM_VERSION_MAJOR >= 13
-      c->getTargetOpts().OpenCLExtensionsAsWritten.push_back("-__opencl_c_generic_address_space");
-      c->getTargetOpts().OpenCLExtensionsAsWritten.push_back("-__opencl_c_pipes");
-      c->getTargetOpts().OpenCLExtensionsAsWritten.push_back("-__opencl_c_device_enqueue");
-      c->getTargetOpts().OpenCLExtensionsAsWritten.push_back("-__opencl_c_program_scope_global_variables");
-      c->getTargetOpts().OpenCLExtensionsAsWritten.push_back("-__opencl_c_subgroups");
-      c->getTargetOpts().OpenCLExtensionsAsWritten.push_back("-__opencl_c_work_group_collective_functions");
-      c->getTargetOpts().OpenCLExtensionsAsWritten.push_back("-__opencl_c_atomic_scope_device");
-      c->getTargetOpts().OpenCLExtensionsAsWritten.push_back("-__opencl_c_atomic_order_seq_cst");
-#endif
-
-      // This is a workaround for a Clang bug which causes the number
-      // of warnings and errors to be printed to stderr.
-      // http://www.llvm.org/bugs/show_bug.cgi?id=19735
-      c->getDiagnosticOpts().ShowCarets = false;
-
-      compat::compiler_set_lang_defaults(c, compat::ik_opencl,
-                                ::llvm::Triple(target.triple),
-                                get_language_version(opts, device_clc_version));
-
-      c->createDiagnostics(
-#if LLVM_VERSION_MAJOR >= 20
-                           *llvm::vfs::getRealFileSystem(),
-#endif
-                           new clang::TextDiagnosticPrinter(
-                              *new raw_string_ostream(r_log),
-                              &c->getDiagnosticOpts(), true));
-
-      c->setTarget(clang::TargetInfo::CreateTargetInfo(
-                           c->getDiagnostics(), c->getInvocation().TargetOpts));
-
-      return c;
-   }
-
-   std::string getResourceDirectory() {
-#ifdef HAVE_DLFCN_H
-      Dl_info info;
-      if (dladdr((void *)clang::CompilerInvocation::CreateFromArgs, &info) == 0) {
-         return FALLBACK_CLANG_RESOURCE_DIR;
-      }
-
-      char *libclang_path = realpath(info.dli_fname, NULL);
-      if (libclang_path == nullptr) {
-         return FALLBACK_CLANG_RESOURCE_DIR;
-      }
-
-      // GetResourcePath is a way to retrieve the actual libclang resource dir based on a given
-      // binary or library.
-      std::string clang_resource_dir =
-#if LLVM_VERSION_MAJOR >= 20
-         clang::driver::Driver::GetResourcesPath(std::string(libclang_path));
-#else
-         clang::driver::Driver::GetResourcesPath(std::string(libclang_path), CLANG_RESOURCE_DIR);
-#endif
-      free(libclang_path);
-
-      return clang_resource_dir;
-#else
-      return FALLBACK_CLANG_RESOURCE_DIR;
-#endif
-   }
-
-   std::unique_ptr<Module>
-   compile(LLVMContext &ctx, clang::CompilerInstance &c,
-           const std::string &name, const std::string &source,
-           const header_map &headers, const device &dev,
-           const std::string &opts, bool use_libclc, std::string &r_log) {
-      c.getFrontendOpts().ProgramAction = clang::frontend::EmitLLVMOnly;
-      c.getHeaderSearchOpts().UseBuiltinIncludes = true;
-      c.getHeaderSearchOpts().UseStandardSystemIncludes = true;
-
-      std::string clang_resource_dir = getResourceDirectory();
-      c.getHeaderSearchOpts().ResourceDir = clang_resource_dir;
-
-      // Add opencl-c generic search path
-      std::string clang_include_path = clang_resource_dir + "/include";
-      c.getHeaderSearchOpts().AddPath(clang_include_path,
-                                      clang::frontend::Angled,
-                                      false, false);
-
-      // Add opencl include
-      c.getPreprocessorOpts().Includes.push_back("opencl-c.h");
-
-      // Add definition for the OpenCL version
-      const auto dev_version = dev.device_version();
-      c.getPreprocessorOpts().addMacroDef("__OPENCL_VERSION__=" +
-                                          std::to_string(CL_VERSION_MAJOR_KHR(dev_version)) +
-                                          std::to_string(CL_VERSION_MINOR_KHR(dev_version)) + "0");
-
-      if (CL_VERSION_MAJOR(dev.version) >= 3) {
-         const auto features = dev.opencl_c_features();
-         for (const auto &feature : features)
-            c.getPreprocessorOpts().addMacroDef(feature.name);
-      }
-
-      // clc.h requires that this macro be defined:
-      c.getPreprocessorOpts().addMacroDef("cl_clang_storage_class_specifiers");
-      c.getPreprocessorOpts().addRemappedFile(
-              name, ::llvm::MemoryBuffer::getMemBuffer(source).release());
-
-      if (headers.size()) {
-         const std::string tmp_header_path = "/tmp/clover/";
-
-         c.getHeaderSearchOpts().AddPath(tmp_header_path,
-                                         clang::frontend::Angled,
-                                         false, false);
-
-         for (const auto &header : headers)
-            c.getPreprocessorOpts().addRemappedFile(
-               tmp_header_path + header.first,
-               ::llvm::MemoryBuffer::getMemBuffer(header.second).release());
-      }
-
-      // Tell clang to link this file before performing any
-      // optimizations.  This is required so that we can replace calls
-      // to the OpenCL C barrier() builtin with calls to target
-      // intrinsics that have the noduplicate attribute.  This
-      // attribute will prevent Clang from creating illegal uses of
-      // barrier() (e.g. Moving barrier() inside a conditional that is
-      // no executed by all threads) during its optimizaton passes.
-      if (use_libclc) {
-         clang::CodeGenOptions::BitcodeFileToLink F;
-
-         F.Filename = LIBCLC_LIBEXECDIR + dev.ir_target() + ".bc";
-         F.PropagateAttrs = true;
-         F.LinkFlags = ::llvm::Linker::Flags::None;
-         c.getCodeGenOpts().LinkBitcodeFiles.emplace_back(F);
-      }
-
-      // undefine __IMAGE_SUPPORT__ for device without image support
-      if (!dev.image_support())
-         c.getPreprocessorOpts().addMacroUndef("__IMAGE_SUPPORT__");
-
-      // Compile the code
-      clang::EmitLLVMOnlyAction act(&ctx);
-      if (!c.ExecuteAction(act))
-         throw build_error();
-
-      return act.takeModule();
-   }
-}
-
-binary
-clover::llvm::compile_program(const std::string &source,
-                              const header_map &headers,
-                              const device &dev,
-                              const std::string &opts,
-                              std::string &r_log) {
-   if (has_flag(debug::clc))
-      debug::log(".cl", "// Options: " + opts + '\n' + source);
-
-   auto ctx = create_context(r_log);
-   auto c = create_compiler_instance(dev, dev.ir_target(),
-                                     tokenize(opts + " input.cl"), r_log);
-   auto mod = compile(*ctx, *c, "input.cl", source, headers, dev, opts, true,
-                      r_log);
-
-   if (has_flag(debug::llvm))
-      debug::log(".ll", print_module_bitcode(*mod));
-
-   return build_module_library(*mod, binary::section::text_intermediate);
-}
-
-namespace {
-   void
-   optimize(Module &mod,
-            const std::string& ir_target,
-            unsigned optimization_level,
-            bool internalize_symbols) {
-      // By default, the function internalizer pass will look for a function
-      // called "main" and then mark all other functions as internal.  Marking
-      // functions as internal enables the optimizer to perform optimizations
-      // like function inlining and global dead-code elimination.
-      //
-      // When there is no "main" function in a binary, the internalize pass will
-      // treat the binary like a library, and it won't internalize any functions.
-      // Since there is no "main" function in our kernels, we need to tell
-      // the internalizer pass that this binary is not a library by passing a
-      // list of kernel functions to the internalizer.  The internalizer will
-      // treat the functions in the list as "main" functions and internalize
-      // all of the other functions.
-      if (internalize_symbols) {
-         std::vector<std::string> names =
-            map(std::mem_fn(&Function::getName), get_kernels(mod));
-         internalizeModule(mod,
-                      [=](const ::llvm::GlobalValue &gv) {
-                         return std::find(names.begin(), names.end(),
-                                          gv.getName()) != names.end();
-                      });
-      }
-
-
-      const char *opt_str = NULL;
-      LLVMCodeGenOptLevel level;
-      switch (optimization_level) {
-      case 0:
-      default:
-         opt_str = "default<O0>";
-         level = LLVMCodeGenLevelNone;
-         break;
-      case 1:
-         opt_str = "default<O1>";
-         level = LLVMCodeGenLevelLess;
-         break;
-      case 2:
-         opt_str = "default<O2>";
-         level = LLVMCodeGenLevelDefault;
-         break;
-      case 3:
-         opt_str = "default<O3>";
-         level = LLVMCodeGenLevelAggressive;
-         break;
-      }
-
-      const target &target = ir_target;
-      LLVMTargetRef targ;
-      char *err_message;
-
-      if (LLVMGetTargetFromTriple(target.triple.c_str(), &targ, &err_message))
-         return;
-      LLVMTargetMachineRef tm =
-         LLVMCreateTargetMachine(targ, target.triple.c_str(),
-                                 target.cpu.c_str(), "", level,
-                                 LLVMRelocDefault, LLVMCodeModelDefault);
-
-      if (!tm)
-         return;
-      LLVMPassBuilderOptionsRef opts = LLVMCreatePassBuilderOptions();
-      LLVMRunPasses(wrap(&mod), opt_str, tm, opts);
-
-      LLVMDisposeTargetMachine(tm);
-      LLVMDisposePassBuilderOptions(opts);
-   }
-
-   std::unique_ptr<Module>
-   link(LLVMContext &ctx, const clang::CompilerInstance &c,
-        const std::vector<binary> &binaries, std::string &r_log) {
-      std::unique_ptr<Module> mod { new Module("link", ctx) };
-      std::unique_ptr< ::llvm::Linker> linker { new ::llvm::Linker(*mod) };
-
-      for (auto &b : binaries) {
-         if (linker->linkInModule(parse_module_library(b, ctx, r_log)))
-            throw build_error();
-      }
-
-      return mod;
-   }
-}
-
-binary
-clover::llvm::link_program(const std::vector<binary> &binaries,
-                           const device &dev, const std::string &opts,
-                           std::string &r_log) {
-   std::vector<std::string> options = tokenize(opts + " input.cl");
-   const bool create_library = count("-create-library", options);
-   erase_if(equals("-create-library"), options);
-
-   auto ctx = create_context(r_log);
-   auto c = create_compiler_instance(dev, dev.ir_target(), options, r_log);
-   auto mod = link(*ctx, *c, binaries, r_log);
-
-   optimize(*mod, dev.ir_target(), c->getCodeGenOpts().OptimizationLevel, !create_library);
-
-   static std::atomic_uint seq(0);
-   const std::string id = "." + mod->getModuleIdentifier() + "-" +
-      std::to_string(seq++);
-
-   if (has_flag(debug::llvm))
-      debug::log(id + ".ll", print_module_bitcode(*mod));
-
-   if (create_library) {
-      return build_module_library(*mod, binary::section::text_library);
-
-   } else if (dev.ir_format() == PIPE_SHADER_IR_NATIVE) {
-      if (has_flag(debug::native))
-         debug::log(id +  ".asm", print_module_native(*mod, dev.ir_target()));
-
-      return build_module_native(*mod, dev.ir_target(), *c, r_log);
-
-   } else {
-      unreachable("Unsupported IR.");
-   }
-}
diff --git a/src/gallium/frontends/clover/llvm/invocation.hpp b/src/gallium/frontends/clover/llvm/invocation.hpp
deleted file mode 100644
index 3ef51c77175..00000000000
--- a/src/gallium/frontends/clover/llvm/invocation.hpp
+++ /dev/null
@@ -1,46 +0,0 @@
-//
-// Copyright 2016 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_LLVM_INVOCATION_HPP
-#define CLOVER_LLVM_INVOCATION_HPP
-
-#include "core/error.hpp"
-#include "core/binary.hpp"
-#include "core/program.hpp"
-#include "pipe/p_defines.h"
-
-namespace clover {
-   namespace llvm {
-      binary compile_program(const std::string &source,
-                             const header_map &headers,
-                             const device &device,
-                             const std::string &opts,
-                             std::string &r_log);
-
-      binary link_program(const std::vector<binary> &binaries,
-                          const device &device,
-                          const std::string &opts,
-                          std::string &r_log);
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/llvm/metadata.hpp b/src/gallium/frontends/clover/llvm/metadata.hpp
deleted file mode 100644
index 92548c0f0a3..00000000000
--- a/src/gallium/frontends/clover/llvm/metadata.hpp
+++ /dev/null
@@ -1,203 +0,0 @@
-//
-// Copyright 2016 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-///
-/// \file
-/// Utility functions for LLVM IR metadata introspection.
-///
-
-#ifndef CLOVER_LLVM_METADATA_HPP
-#define CLOVER_LLVM_METADATA_HPP
-
-#include "llvm/compat.hpp"
-#include "util/algorithm.hpp"
-
-#include <vector>
-#include <llvm/Config/llvm-config.h>
-#include <llvm/IR/Constants.h>
-#include <llvm/IR/Module.h>
-#include <llvm/IR/Metadata.h>
-
-namespace clover {
-   namespace llvm {
-      namespace detail {
-         inline bool
-         is_kernel(const ::llvm::Function &f) {
-            return f.getMetadata("kernel_arg_type");
-         }
-
-         inline iterator_range< ::llvm::MDNode::op_iterator>
-         get_kernel_metadata_operands(const ::llvm::Function &f,
-                                      const std::string &name) {
-            const auto data_node = f.getMetadata(name);
-            if (data_node)
-               return range(data_node->op_begin(), data_node->op_end());
-            else
-               return iterator_range< ::llvm::MDNode::op_iterator>();
-         }
-      }
-
-      ///
-      /// Extract the string metadata node \p name.
-      ///
-      inline std::string
-      get_str_kernel_metadata(const ::llvm::Function &f,
-                          const std::string &name) {
-         auto operands = detail::get_kernel_metadata_operands(f, name);
-         if (operands.size()) {
-            return ::llvm::cast< ::llvm::MDString>(
-               detail::get_kernel_metadata_operands(f, name)[0])
-               ->getString().str();
-         } else {
-            return "";
-         }
-      }
-
-      ///
-      /// Extract the string metadata node \p name.
-      ///
-      inline std::vector<size_t>
-      get_uint_vector_kernel_metadata(const ::llvm::Function &f,
-                          const std::string &name) {
-         auto operands = detail::get_kernel_metadata_operands(f, name);
-         if (operands.size()) {
-            return map([=](const ::llvm::MDOperand& o) {
-               auto value = ::llvm::cast< ::llvm::ConstantAsMetadata>(o)
-                                                               ->getValue();
-               return ::llvm::cast< ::llvm::ConstantInt>(value)
-                                                ->getLimitedValue(UINT_MAX);
-            }, operands);
-         } else {
-            return {};
-         }
-      }
-
-      ///
-      /// Extract the string metadata node \p name.
-      ///
-      inline std::string
-      get_type_kernel_metadata(const ::llvm::Function &f,
-                          const std::string &name) {
-         auto operands = detail::get_kernel_metadata_operands(f, name);
-         if (operands.size()) {
-            auto value = ::llvm::cast< ::llvm::ConstantAsMetadata>(operands[0])
-                                                               ->getValue();
-            auto type = ::llvm::cast< ::llvm::UndefValue>(value)
-                                                               ->getType();
-
-            value = ::llvm::cast< ::llvm::ConstantAsMetadata>(operands[1])
-                                                               ->getValue();
-            bool is_signed = ::llvm::cast< ::llvm::ConstantInt>(value)
-                                                ->getLimitedValue(UINT_MAX);
-
-            std::string data;
-            if (type->isIntOrIntVectorTy()) {
-               if (!is_signed)
-                  data = "unsigned ";
-
-               const auto size = type->getScalarSizeInBits();
-               switch(size) {
-                  case 8:
-                     data += "char";
-                     break;
-                  case 16:
-                     data += "short";
-                     break;
-                  case 32:
-                     data += "int";
-                     break;
-                  case 64:
-                     data += "long";
-                     break;
-               }
-               if (compat::is_scalable_vector(type))
-                  throw build_error("hit unexpected scalable vector");
-               if (compat::is_fixed_vector(type))
-                  data += std::to_string(compat::get_fixed_vector_elements(type));
-
-            } else {
-               ::llvm::raw_string_ostream os { data };
-               type->print(os);
-               os.flush();
-            }
-
-            return data;
-         } else {
-            return "";
-         }
-      }
-
-      ///
-      /// Extract the string metadata node \p name corresponding to the kernel
-      /// argument given by \p arg.
-      ///
-      inline std::string
-      get_str_argument_metadata(const ::llvm::Function &f,
-                            const ::llvm::Argument &arg,
-                            const std::string &name) {
-         auto operands = detail::get_kernel_metadata_operands(f, name);
-         if (operands.size() > arg.getArgNo()) {
-            return ::llvm::cast< ::llvm::MDString>(operands[arg.getArgNo()])
-               ->getString().str();
-         } else {
-            return "";
-         }
-      }
-
-      ///
-      /// Extract the int metadata node \p name corresponding to the kernel
-      /// argument given by \p arg.
-      ///
-      inline uint64_t
-      get_uint_argument_metadata(const ::llvm::Function &f,
-                            const ::llvm::Argument &arg,
-                            const std::string &name) {
-         auto operands = detail::get_kernel_metadata_operands(f, name);
-         if (operands.size() >= arg.getArgNo()) {
-            auto meta_arg_value = ::llvm::cast< ::llvm::ConstantAsMetadata>(
-               operands[arg.getArgNo()])->getValue();
-            return ::llvm::cast< ::llvm::ConstantInt>(meta_arg_value)
-               ->getLimitedValue(UINT_MAX);
-         } else {
-            return 0;
-         }
-      }
-
-      ///
-      /// Return a vector with all CL kernel functions found in the LLVM
-      /// module \p mod.
-      ///
-      inline std::vector<const ::llvm::Function *>
-      get_kernels(const ::llvm::Module &mod) {
-         std::vector<const ::llvm::Function *> fs;
-
-         for (auto &f : mod.getFunctionList()) {
-            if (detail::is_kernel(f))
-               fs.push_back(&f);
-         }
-
-         return fs;
-      }
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/llvm/util.hpp b/src/gallium/frontends/clover/llvm/util.hpp
deleted file mode 100644
index 7cd994bdc86..00000000000
--- a/src/gallium/frontends/clover/llvm/util.hpp
+++ /dev/null
@@ -1,93 +0,0 @@
-//
-// Copyright 2012-2016 Francisco Jerez
-// Copyright 2012-2016 Advanced Micro Devices, Inc.
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_LLVM_UTIL_HPP
-#define CLOVER_LLVM_UTIL_HPP
-
-#include "core/error.hpp"
-#include "util/u_debug.h"
-
-#include <vector>
-#include <fstream>
-#include <iostream>
-
-namespace clover {
-   namespace llvm {
-      template<typename E> void
-      fail(std::string &r_log, E &&e, const std::string &s) {
-         r_log += s;
-         throw std::forward<E>(e);
-      }
-
-      inline std::string
-      as_string(const std::vector<char> &v) {
-         return { v.begin(), v.end() };
-      }
-
-      struct target {
-         target(const std::string &s) :
-            cpu(s.begin(), s.begin() + s.find_first_of("-")),
-            triple(s.begin() + s.find_first_of("-") + 1, s.end()) {}
-
-         std::string cpu;
-         std::string triple;
-      };
-
-      namespace debug {
-         enum flag {
-            clc = 1 << 0,
-            llvm = 1 << 1,
-            native = 1 << 2,
-            spirv = 1 << 3,
-         };
-
-         inline bool
-         has_flag(flag f) {
-            static const struct debug_named_value debug_options[] = {
-               { "clc", clc, "Dump the OpenCL C code for all kernels." },
-               { "llvm", llvm, "Dump the generated LLVM IR for all kernels." },
-               { "native", native, "Dump kernel assembly code for targets "
-                 "specifying PIPE_SHADER_IR_NATIVE" },
-               { "spirv", spirv, "Dump the generated SPIR-V for all kernels." },
-               DEBUG_NAMED_VALUE_END
-            };
-            static const unsigned flags =
-               debug_get_flags_option("CLOVER_DEBUG", debug_options, 0);
-
-            return flags & f;
-         }
-
-         inline void
-         log(const std::string &suffix, const std::string &s) {
-            const std::string path = debug_get_option("CLOVER_DEBUG_FILE",
-                                                      "stderr");
-            if (path == "stderr")
-               std::cerr << s;
-            else
-               std::ofstream(path + suffix, std::ios::app) << s;
-         }
-      }
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/meson.build b/src/gallium/frontends/clover/meson.build
deleted file mode 100644
index 56a9894f0db..00000000000
--- a/src/gallium/frontends/clover/meson.build
+++ /dev/null
@@ -1,125 +0,0 @@
-# Copyright Â© 2017-2018 Intel Corporation
-# SPDX-License-Identifier: MIT
-
-clover_cpp_args = []
-clover_opencl_cpp_args = [
-  '-DCL_TARGET_OPENCL_VERSION=300',
-  '-DCL_USE_DEPRECATED_OPENCL_1_0_APIS',
-  '-DCL_USE_DEPRECATED_OPENCL_1_1_APIS',
-  '-DCL_USE_DEPRECATED_OPENCL_1_2_APIS',
-  '-DCL_USE_DEPRECATED_OPENCL_2_0_APIS',
-  '-DCL_USE_DEPRECATED_OPENCL_2_1_APIS',
-  '-DCL_USE_DEPRECATED_OPENCL_2_2_APIS',
-  '-DLIBCLC_LIBEXECDIR="@0@/"'.format(dep_clc.get_variable(pkgconfig : 'libexecdir'))
-]
-clover_incs = [inc_include, inc_src, inc_gallium, inc_gallium_aux]
-
-# the CL header files declare attributes on the CL types. Compilers warn if
-# we use them as template arguments. Disable the warning as there isn't
-# anything we can do about it
-if cpp.has_argument('-Wno-ignored-attributes')
-   clover_cpp_args += '-Wno-ignored-attributes'
-endif
-
-if with_opencl_icd
-  clover_cpp_args += '-DHAVE_CLOVER_ICD'
-endif
-
-libclllvm = static_library(
-  'clllvm',
-  files(
-    'llvm/codegen/bitcode.cpp',
-    'llvm/codegen/common.cpp',
-    'llvm/codegen/native.cpp',
-    'llvm/codegen.hpp',
-    'llvm/compat.hpp',
-    'llvm/invocation.cpp',
-    'llvm/invocation.hpp',
-    'llvm/metadata.hpp',
-    'llvm/util.hpp',
-  ),
-  include_directories : clover_incs,
-  cpp_args : [
-    clover_cpp_args,
-    clover_opencl_cpp_args,
-    '-DFALLBACK_CLANG_RESOURCE_DIR="@0@"'.format(join_paths(
-      dep_llvm.get_variable(cmake : 'LLVM_LIBRARY_DIR', configtool: 'libdir'), 'clang',
-      dep_llvm.version()
-    )),
-  ],
-  gnu_symbol_visibility : 'hidden',
-  dependencies : [dep_llvm, dep_elf, dep_llvmspirvlib, idep_mesautil],
-)
-
-clover_files = files(
-  'api/context.cpp',
-  'api/device.cpp',
-  'api/dispatch.cpp',
-  'api/dispatch.hpp',
-  'api/event.cpp',
-  'api/interop.cpp',
-  'api/invalid.cpp',
-  'api/kernel.cpp',
-  'api/memory.cpp',
-  'api/platform.cpp',
-  'api/program.cpp',
-  'api/queue.cpp',
-  'api/sampler.cpp',
-  'api/transfer.cpp',
-  'api/util.hpp',
-  'core/binary.cpp',
-  'core/binary.hpp',
-  'core/compiler.hpp',
-  'core/context.cpp',
-  'core/context.hpp',
-  'core/device.cpp',
-  'core/device.hpp',
-  'core/error.hpp',
-  'core/event.cpp',
-  'core/event.hpp',
-  'core/format.cpp',
-  'core/format.hpp',
-  'core/kernel.cpp',
-  'core/kernel.hpp',
-  'core/memory.cpp',
-  'core/memory.hpp',
-  'core/object.hpp',
-  'core/platform.cpp',
-  'core/platform.hpp',
-  'core/printf.cpp',
-  'core/printf.hpp',
-  'core/program.cpp',
-  'core/program.hpp',
-  'core/property.hpp',
-  'core/queue.cpp',
-  'core/queue.hpp',
-  'core/resource.cpp',
-  'core/resource.hpp',
-  'core/sampler.cpp',
-  'core/sampler.hpp',
-  'core/timestamp.cpp',
-  'core/timestamp.hpp',
-  'util/adaptor.hpp',
-  'util/algebra.hpp',
-  'util/algorithm.hpp',
-  'util/compat.hpp',
-  'util/factor.hpp',
-  'util/functional.hpp',
-  'util/lazy.hpp',
-  'util/pointer.hpp',
-  'util/range.hpp',
-  'util/tuple.hpp',
-)
-
-libclover = static_library(
-  'clover',
-  [clover_files, sha1_h],
-  include_directories : clover_incs,
-  cpp_args : [
-    clover_opencl_cpp_args,
-    clover_cpp_args,
-  ],
-  gnu_symbol_visibility : 'hidden',
-  link_with : [libclllvm],
-  dependencies : [idep_mesautil, idep_nir],
-)
diff --git a/src/gallium/frontends/clover/util/adaptor.hpp b/src/gallium/frontends/clover/util/adaptor.hpp
deleted file mode 100644
index 08601fc416b..00000000000
--- a/src/gallium/frontends/clover/util/adaptor.hpp
+++ /dev/null
@@ -1,184 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_ADAPTOR_HPP
-#define CLOVER_UTIL_ADAPTOR_HPP
-
-#include <iterator>
-
-#include "util/compat.hpp"
-#include "util/tuple.hpp"
-#include "util/pointer.hpp"
-#include "util/functional.hpp"
-
-namespace clover {
-   namespace detail {
-      ///
-      /// Implementation of the iterator concept that transforms the
-      /// value of the source iterators \a Is on dereference by use of
-      /// a functor \a F.
-      ///
-      /// The exact category of the resulting iterator should be the
-      /// least common denominator of the source iterator categories.
-      ///
-      template<typename F, typename... Is>
-      class iterator_adaptor {
-      public:
-         typedef std::forward_iterator_tag iterator_category;
-         typedef typename invoke_result<
-               F, typename std::iterator_traits<Is>::reference...
-            >::type reference;
-         typedef typename std::remove_reference<reference>::type value_type;
-         typedef pseudo_ptr<value_type> pointer;
-         typedef std::ptrdiff_t difference_type;
-
-         iterator_adaptor() {
-         }
-
-         iterator_adaptor(F f, std::tuple<Is...> &&its) :
-            f(f), its(std::move(its)) {
-         }
-
-         reference
-         operator*() const {
-            return tuple::apply(f, tuple::map(derefs(), its));
-         }
-
-         iterator_adaptor &
-         operator++() {
-            tuple::map(preincs(), its);
-            return *this;
-         }
-
-         iterator_adaptor
-         operator++(int) {
-            auto jt = *this;
-            ++*this;
-            return jt;
-         }
-
-         bool
-         operator==(const iterator_adaptor &jt) const {
-            return its == jt.its;
-         }
-
-         bool
-         operator!=(const iterator_adaptor &jt) const {
-            return its != jt.its;
-         }
-
-         pointer
-         operator->() const {
-            return { **this };
-         }
-
-         iterator_adaptor &
-         operator--() {
-            tuple::map(predecs(), its);
-            return *this;
-         }
-
-         iterator_adaptor
-         operator--(int) {
-            auto jt = *this;
-            --*this;
-            return jt;
-         }
-
-         iterator_adaptor &
-         operator+=(difference_type n) {
-            tuple::map(advances_by(n), its);
-            return *this;
-         }
-
-         iterator_adaptor &
-         operator-=(difference_type n) {
-            tuple::map(advances_by(-n), its);
-            return *this;
-         }
-
-         iterator_adaptor
-         operator+(difference_type n) const {
-            auto jt = *this;
-            jt += n;
-            return jt;
-         }
-
-         iterator_adaptor
-         operator-(difference_type n) const {
-            auto jt = *this;
-            jt -= n;
-            return jt;
-         }
-
-         difference_type
-         operator-(const iterator_adaptor &jt) const {
-            return std::get<0>(its) - std::get<0>(jt.its);
-         }
-
-         reference
-         operator[](difference_type n) const {
-            return *(*this + n);
-         }
-
-         bool
-         operator<(iterator_adaptor &jt) const {
-            return *this - jt < 0;
-         }
-
-         bool
-         operator>(iterator_adaptor &jt) const {
-            return *this - jt > 0;
-         }
-
-         bool
-         operator>=(iterator_adaptor &jt) const {
-            return !(*this < jt);
-         }
-
-         bool
-         operator<=(iterator_adaptor &jt) const {
-            return !(*this > jt);
-         }
-
-      protected:
-         F f;
-         std::tuple<Is...> its;
-      };
-
-      template<typename F, typename... Is>
-      iterator_adaptor<F, Is...>
-      operator+(typename iterator_adaptor<F, Is...>::difference_type n,
-                const iterator_adaptor<F, Is...> &jt) {
-         return (jt + n);
-      }
-
-      template<typename F, typename... Is>
-      iterator_adaptor<F, Is...>
-      operator-(typename iterator_adaptor<F, Is...>::difference_type n,
-                const iterator_adaptor<F, Is...> &jt) {
-         return (jt - n);
-      }
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/algebra.hpp b/src/gallium/frontends/clover/util/algebra.hpp
deleted file mode 100644
index 43a9d8bbf5f..00000000000
--- a/src/gallium/frontends/clover/util/algebra.hpp
+++ /dev/null
@@ -1,160 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_ALGEBRA_HPP
-#define CLOVER_UTIL_ALGEBRA_HPP
-
-#include <type_traits>
-
-#include "util/range.hpp"
-#include "util/functional.hpp"
-
-namespace clover {
-   ///
-   /// Class that identifies vectors (in the linear-algebraic sense).
-   ///
-   /// There should be a definition of this class for each type that
-   /// makes sense as vector arithmetic operand.
-   ///
-   template<typename V, typename = void>
-   struct vector_traits;
-
-   ///
-   /// References of vectors are vectors.
-   ///
-   template<typename T>
-   struct vector_traits<T &, typename vector_traits<T>::enable> {
-      typedef void enable;
-   };
-
-   ///
-   /// Constant vectors are vectors.
-   ///
-   template<typename T>
-   struct vector_traits<const T, typename vector_traits<T>::enable> {
-      typedef void enable;
-   };
-
-   ///
-   /// Arrays of arithmetic types are vectors.
-   ///
-   template<typename T, std::size_t N>
-   struct vector_traits<std::array<T, N>,
-                        typename std::enable_if<
-                           std::is_arithmetic<T>::value>::type> {
-      typedef void enable;
-   };
-
-   namespace detail {
-      template<typename... Ts>
-      struct are_defined {
-         typedef void enable;
-      };
-   }
-
-   ///
-   /// The result of mapping a vector is a vector.
-   ///
-   template<typename F, typename... Vs>
-   struct vector_traits<adaptor_range<F, Vs...>,
-                        typename detail::are_defined<
-                           typename vector_traits<Vs>::enable...>::enable> {
-      typedef void enable;
-   };
-
-   ///
-   /// Vector sum.
-   ///
-   template<typename U, typename V,
-            typename = typename vector_traits<U>::enable,
-            typename = typename vector_traits<V>::enable>
-   adaptor_range<plus, U, V>
-   operator+(U &&u, V &&v) {
-      return map(plus(), std::forward<U>(u), std::forward<V>(v));
-   }
-
-   ///
-   /// Vector difference.
-   ///
-   template<typename U, typename V,
-            typename = typename vector_traits<U>::enable,
-            typename = typename vector_traits<V>::enable>
-   adaptor_range<minus, U, V>
-   operator-(U &&u, V &&v) {
-      return map(minus(), std::forward<U>(u), std::forward<V>(v));
-   }
-
-   ///
-   /// Scalar multiplication.
-   ///
-   template<typename U, typename T,
-            typename = typename vector_traits<U>::enable>
-   adaptor_range<multiplies_by_t<T>, U>
-   operator*(U &&u, T &&a) {
-      return map(multiplies_by<T>(std::forward<T>(a)), std::forward<U>(u));
-   }
-
-   ///
-   /// Scalar multiplication.
-   ///
-   template<typename U, typename T,
-            typename = typename vector_traits<U>::enable>
-   adaptor_range<multiplies_by_t<T>, U>
-   operator*(T &&a, U &&u) {
-      return map(multiplies_by<T>(std::forward<T>(a)), std::forward<U>(u));
-   }
-
-   ///
-   /// Additive inverse.
-   ///
-   template<typename U,
-            typename = typename vector_traits<U>::enable>
-   adaptor_range<negate, U>
-   operator-(U &&u) {
-      return map(negate(), std::forward<U>(u));
-   }
-
-   namespace detail {
-      template<typename U, typename V>
-      using dot_type = typename std::common_type<
-           typename std::remove_reference<U>::type::value_type,
-           typename std::remove_reference<V>::type::value_type
-         >::type;
-   }
-
-   ///
-   /// Dot product of two vectors.
-   ///
-   /// It can also do matrix multiplication if \a u or \a v is a
-   /// vector of vectors.
-   ///
-   template<typename U, typename V,
-            typename = typename vector_traits<U>::enable,
-            typename = typename vector_traits<V>::enable>
-   detail::dot_type<U, V>
-   dot(U &&u, V &&v) {
-      return fold(plus(), detail::dot_type<U, V>(),
-                  map(multiplies(), u, v));
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/algorithm.hpp b/src/gallium/frontends/clover/util/algorithm.hpp
deleted file mode 100644
index 306c045cb2a..00000000000
--- a/src/gallium/frontends/clover/util/algorithm.hpp
+++ /dev/null
@@ -1,294 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_ALGORITHM_HPP
-#define CLOVER_UTIL_ALGORITHM_HPP
-
-#include <algorithm>
-#include <sstream>
-#include <stdexcept>
-
-#include "util/range.hpp"
-#include "util/functional.hpp"
-
-namespace clover {
-   namespace detail {
-      template<typename R>
-      using preferred_reference_type = decltype(*std::declval<R>().begin());
-   }
-
-   ///
-   /// Return the first element in a range.
-   ///
-   template<typename R>
-   detail::preferred_reference_type<R>
-   head(R &&r) {
-      assert(!r.empty());
-      return r.front();
-   }
-
-   ///
-   /// Return all elements in a range but the first.
-   ///
-   template<typename R>
-   slice_range<R>
-   tail(R &&r) {
-      assert(!r.empty());
-      return { std::forward<R>(r), 1, r.size() };
-   }
-
-   ///
-   /// Return the only element in a range.
-   ///
-   template<typename R>
-   detail::preferred_reference_type<R>
-   unique(R &&r) {
-      if (r.size() != 1)
-         throw std::out_of_range("");
-
-      return r.front();
-   }
-
-   ///
-   /// Combine a variable number of ranges element-wise in a single
-   /// range of tuples.
-   ///
-   template<typename... Rs>
-   adaptor_range<zips, Rs...>
-   zip(Rs &&... rs) {
-      return map(zips(), std::forward<Rs>(rs)...);
-   }
-
-   ///
-   /// Evaluate the elements of a range.
-   ///
-   /// Useful because most of the range algorithms evaluate their
-   /// result lazily.
-   ///
-   template<typename R>
-   void
-   eval(R &&r) {
-      for (auto i = r.begin(), e = r.end(); i != e; ++i)
-         *i;
-   }
-
-   ///
-   /// Apply functor \a f element-wise on a variable number of ranges
-   /// \a rs.
-   ///
-   /// The functor \a f should take as many arguments as ranges are
-   /// provided.
-   ///
-   template<typename F, typename... Rs>
-   void
-   for_each(F &&f, Rs &&... rs) {
-      eval(map(std::forward<F>(f), std::forward<Rs>(rs)...));
-   }
-
-   ///
-   /// Copy all elements from range \a r into an output container
-   /// starting from iterator \a i.
-   ///
-   template<typename R, typename I>
-   void
-   copy(R &&r, I i) {
-      for (detail::preferred_reference_type<R> x : r)
-         *(i++) = x;
-   }
-
-   ///
-   /// Reduce the elements of range \a r by applying functor \a f
-   /// element by element.
-   ///
-   /// \a f should take an accumulator value (which is initialized to
-   /// \a a) and an element value as arguments, and return an updated
-   /// accumulator value.
-   ///
-   /// \returns The final value of the accumulator.
-   ///
-   template<typename F, typename A, typename R>
-   A
-   fold(F &&f, A a, R &&r) {
-      for (detail::preferred_reference_type<R> x : r)
-         a = f(a, x);
-
-      return a;
-   }
-
-   ///
-   /// Return how many elements of range \a r are equal to \a x.
-   ///
-   template<typename T, typename R>
-   typename std::remove_reference<R>::type::size_type
-   count(T &&x, R &&r) {
-      typename std::remove_reference<R>::type::size_type n = 0;
-
-      for (detail::preferred_reference_type<R> y : r) {
-         if (x == y)
-            n++;
-      }
-
-      return n;
-   }
-
-   ///
-   /// Return the first element in range \a r for which predicate \a f
-   /// evaluates to true.
-   ///
-   template<typename F, typename R>
-   detail::preferred_reference_type<R>
-   find(F &&f, R &&r) {
-      for (detail::preferred_reference_type<R> x : r) {
-         if (f(x))
-            return x;
-      }
-
-      throw std::out_of_range("");
-   }
-
-   ///
-   /// Return true if the element-wise application of predicate \a f
-   /// on \a rs evaluates to true for all elements.
-   ///
-   template<typename F, typename... Rs>
-   bool
-   all_of(F &&f, Rs &&... rs) {
-      for (auto b : map(f, rs...)) {
-         if (!b)
-            return false;
-      }
-
-      return true;
-   }
-
-   ///
-   /// Return true if the element-wise application of predicate \a f
-   /// on \a rs evaluates to true for any element.
-   ///
-   template<typename F, typename... Rs>
-   bool
-   any_of(F &&f, Rs &&... rs) {
-      for (auto b : map(f, rs...)) {
-         if (b)
-            return true;
-      }
-
-      return false;
-   }
-
-   ///
-   /// Erase elements for which predicate \a f evaluates to true from
-   /// container \a r.
-   ///
-   template<typename F, typename R>
-   void
-   erase_if(F &&f, R &&r) {
-      auto i = r.begin(), e = r.end();
-
-      for (auto j = r.begin(); j != e; ++j) {
-         if (!f(*j)) {
-            if (j != i)
-               *i = std::move(*j);
-            ++i;
-         }
-      }
-
-      r.erase(i, e);
-   }
-
-   ///
-   /// Build a vector of string from a space separated string
-   /// quoted parts content is preserved and unquoted
-   ///
-   inline std::vector<std::string>
-   tokenize(const std::string &s) {
-      std::vector<std::string> ss;
-      std::ostringstream oss;
-
-      // OpenCL programs can pass a quoted argument, most frequently the
-      // include path. This is useful so that path containing spaces is
-      // treated as a single argument instead of being split by the spaces.
-      // Additionally, the argument should also be unquoted before being
-      // passed to the compiler. We avoid using std::string::replace here to
-      // remove quotes, as the single and double quote characters can be a
-      // part of the file name.
-      bool escape_next = false;
-      bool in_quote_double = false;
-      bool in_quote_single = false;
-
-      for (auto c : s) {
-         if (escape_next) {
-            oss.put(c);
-            escape_next = false;
-         } else if (c == '\\') {
-            escape_next = true;
-         } else if (c == '"' && !in_quote_single) {
-            in_quote_double = !in_quote_double;
-         } else if (c == '\'' && !in_quote_double) {
-            in_quote_single = !in_quote_single;
-         } else if (c != ' ' || in_quote_single || in_quote_double) {
-            oss.put(c);
-         } else if (oss.tellp() > 0) {
-            ss.emplace_back(oss.str());
-            oss.str("");
-         }
-      }
-
-      if (oss.tellp() > 0)
-         ss.emplace_back(oss.str());
-
-      if (in_quote_double || in_quote_single)
-         throw invalid_build_options_error();
-
-      return ss;
-   }
-
-   ///
-   /// Build a \a sep separated string from a vector of T
-   ///
-   template<typename T>
-   std::string
-   detokenize(const std::vector<T> &ss, const std::string &sep) {
-      std::string r;
-
-      for (const auto &s : ss)
-         r += (r.empty() ? "" : sep) + std::to_string(s);
-
-      return r;
-   }
-
-   ///
-   /// Build a \a sep separated string from a vector of string
-   ///
-   template <>
-   inline std::string
-   detokenize(const std::vector<std::string> &ss, const std::string &sep) {
-      std::string r;
-
-      for (const auto &s : ss)
-         r += (r.empty() || s.empty() ? "" : sep) + s;
-
-      return r;
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/compat.hpp b/src/gallium/frontends/clover/util/compat.hpp
deleted file mode 100644
index dd8db8d2c51..00000000000
--- a/src/gallium/frontends/clover/util/compat.hpp
+++ /dev/null
@@ -1,43 +0,0 @@
-//
-// Copyright Â© Microsoft Corporation
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_COMPAT_HPP
-#define CLOVER_UTIL_COMPAT_HPP
-
-#include <type_traits>
-
-namespace clover {
-   template<typename F, typename... Args>
-   struct invoke_result {
-#if __cplusplus >= 201703L
-      typedef typename std::invoke_result<
-         F, Args...
-      >::type type;
-#else
-      typedef typename std::result_of<
-         F(Args...)
-      >::type type;
-#endif
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/factor.hpp b/src/gallium/frontends/clover/util/factor.hpp
deleted file mode 100644
index 76d3bfe343f..00000000000
--- a/src/gallium/frontends/clover/util/factor.hpp
+++ /dev/null
@@ -1,131 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_FACTOR_HPP
-#define CLOVER_UTIL_FACTOR_HPP
-
-#include "util/range.hpp"
-
-namespace clover {
-   namespace factor {
-      ///
-      /// Calculate all prime integer factors of \p x.
-      ///
-      /// If \p limit is non-zero, terminate early as soon as enough
-      /// factors have been collected to reach the product \p limit.
-      ///
-      template<typename T>
-      std::vector<T>
-      find_integer_prime_factors(T x, T limit = 0)
-      {
-         const T max_d = (limit > 0 && limit < x ? limit : x);
-         const T min_x = x / max_d;
-         std::vector<T> factors;
-
-         for (T d = 2; d <= max_d && x > min_x; d++) {
-            if (x % d == 0) {
-               for (; x % d == 0; x /= d);
-               factors.push_back(d);
-            }
-         }
-
-         return factors;
-      }
-
-      namespace detail {
-         ///
-         /// Walk the power set of prime factors of the n-dimensional
-         /// integer array \p grid subject to the constraints given by
-         /// \p limits.
-         ///
-         template<typename T>
-         std::pair<T, std::vector<T>>
-         next_grid_factor(const std::pair<T, std::vector<T>> &limits,
-                          const std::vector<T> &grid,
-                          const std::vector<std::vector<T>> &factors,
-                          std::pair<T, std::vector<T>> block,
-                          unsigned d = 0, unsigned i = 0) {
-            if (d >= factors.size()) {
-               // We're done.
-               return {};
-
-            } else if (i >= factors[d].size()) {
-               // We're done with this grid dimension, try the next.
-               return next_grid_factor(limits, grid, factors,
-                                       std::move(block), d + 1, 0);
-
-            } else {
-               T f = factors[d][i];
-
-               // Try the next power of this factor.
-               block.first *= f;
-               block.second[d] *= f;
-
-               if (block.first <= limits.first &&
-                   block.second[d] <= limits.second[d] &&
-                   grid[d] % block.second[d] == 0) {
-                  // We've found a valid grid divisor.
-                  return block;
-
-               } else {
-                  // Overflow, back off to the zeroth power,
-                  while (block.second[d] % f == 0) {
-                     block.second[d] /= f;
-                     block.first /= f;
-                  }
-
-                  // ...and carry to the next factor.
-                  return next_grid_factor(limits, grid, factors,
-                                          std::move(block), d, i + 1);
-               }
-            }
-         }
-      }
-
-      ///
-      /// Find the divisor of the integer array \p grid that gives the
-      /// highest possible product not greater than \p product_limit
-      /// subject to the constraints given by \p coord_limit.
-      ///
-      template<typename T>
-      std::vector<T>
-      find_grid_optimal_factor(T product_limit,
-                               const std::vector<T> &coord_limit,
-                               const std::vector<T> &grid) {
-         const std::vector<std::vector<T>> factors =
-            map(find_integer_prime_factors<T>, grid, coord_limit);
-         const auto limits = std::make_pair(product_limit, coord_limit);
-         auto best = std::make_pair(T(1), std::vector<T>(grid.size(), T(1)));
-
-         for (auto block = best;
-              block.first != 0 && best.first != product_limit;
-              block = detail::next_grid_factor(limits, grid, factors, block)) {
-            if (block.first > best.first)
-               best = block;
-         }
-
-         return best.second;
-      }
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/functional.hpp b/src/gallium/frontends/clover/util/functional.hpp
deleted file mode 100644
index 81bfa644352..00000000000
--- a/src/gallium/frontends/clover/util/functional.hpp
+++ /dev/null
@@ -1,428 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_FUNCTIONAL_HPP
-#define CLOVER_UTIL_FUNCTIONAL_HPP
-
-#include <type_traits>
-
-namespace clover {
-   struct identity {
-      template<typename T>
-      typename std::remove_reference<T>::type
-      operator()(T &&x) const {
-         return x;
-      }
-   };
-
-   struct plus {
-      template<typename T, typename S>
-      typename std::common_type<T, S>::type
-      operator()(T x, S y) const {
-         return x + y;
-      }
-   };
-
-   struct minus {
-      template<typename T, typename S>
-      typename std::common_type<T, S>::type
-      operator()(T x, S y) const {
-         return x - y;
-      }
-   };
-
-   struct negate {
-      template<typename T>
-      T
-      operator()(T x) const {
-         return -x;
-      }
-   };
-
-   struct multiplies {
-      template<typename T, typename S>
-      typename std::common_type<T, S>::type
-      operator()(T x, S y) const {
-         return x * y;
-      }
-   };
-
-   struct divides {
-      template<typename T, typename S>
-      typename std::common_type<T, S>::type
-      operator()(T x, S y) const {
-         return x / y;
-      }
-   };
-
-   struct modulus {
-      template<typename T, typename S>
-      typename std::common_type<T, S>::type
-      operator()(T x, S y) const {
-         return x % y;
-      }
-   };
-
-   struct minimum {
-      template<typename T>
-      T
-      operator()(T x) const {
-         return x;
-      }
-
-      template<typename T, typename... Ts>
-      T
-      operator()(T x, Ts... xs) const {
-         T y = minimum()(xs...);
-         return x < y ? x : y;
-      }
-   };
-
-   struct maximum {
-      template<typename T>
-      T
-      operator()(T x) const {
-         return x;
-      }
-
-      template<typename T, typename... Ts>
-      T
-      operator()(T x, Ts... xs) const {
-         T y = maximum()(xs...);
-         return x < y ? y : x;
-      }
-   };
-
-   struct preincs {
-      template<typename T>
-      T &
-      operator()(T &x) const {
-         return ++x;
-      }
-   };
-
-   struct predecs {
-      template<typename T>
-      T &
-      operator()(T &x) const {
-         return --x;
-      }
-   };
-
-   template<typename T>
-   class multiplies_by_t {
-   public:
-      multiplies_by_t(T x) : x(x) {
-      }
-
-      template<typename S>
-      typename std::common_type<T, S>::type
-      operator()(S y) const {
-         return x * y;
-      }
-
-   private:
-      T x;
-   };
-
-   template<typename T>
-   multiplies_by_t<T>
-   multiplies_by(T x) {
-      return { x };
-   }
-
-   template<typename T>
-   class preincs_by_t {
-   public:
-      preincs_by_t(T n) : n(n) {
-      }
-
-      template<typename S>
-      S &
-      operator()(S &x) const {
-         return x += n;
-      }
-
-   private:
-      T n;
-   };
-
-   template<typename T>
-   preincs_by_t<T>
-   preincs_by(T n) {
-      return { n };
-   }
-
-   template<typename T>
-   class predecs_by_t {
-   public:
-      predecs_by_t(T n) : n(n) {
-      }
-
-      template<typename S>
-      S &
-      operator()(S &x) const {
-         return x -= n;
-      }
-
-   private:
-      T n;
-   };
-
-   template<typename T>
-   predecs_by_t<T>
-   predecs_by(T n) {
-      return { n };
-   }
-
-   struct greater {
-      template<typename T, typename S>
-      bool
-      operator()(T x, S y) const {
-         return x > y;
-      }
-   };
-
-   struct evals {
-      template<typename T>
-      auto
-      operator()(T &&x) const -> decltype(x()) {
-         return x();
-      }
-   };
-
-   struct derefs {
-      template<typename T>
-      auto
-      operator()(T &&x) const -> decltype(*x) {
-         return *x;
-      }
-   };
-
-   struct addresses {
-      template<typename T>
-      T *
-      operator()(T &x) const {
-         return &x;
-      }
-
-      template<typename T>
-      T *
-      operator()(std::reference_wrapper<T> x) const {
-         return &x.get();
-      }
-   };
-
-   struct begins {
-      template<typename T>
-      auto
-      operator()(T &x) const -> decltype(x.begin()) {
-         return x.begin();
-      }
-   };
-
-   struct ends {
-      template<typename T>
-      auto
-      operator()(T &x) const -> decltype(x.end()) {
-         return x.end();
-      }
-   };
-
-   struct sizes {
-      template<typename T>
-      auto
-      operator()(T &x) const -> decltype(x.size()) {
-         return x.size();
-      }
-   };
-
-   template<typename T>
-   class advances_by_t {
-   public:
-      advances_by_t(T n) : n(n) {
-      }
-
-      template<typename S>
-      S
-      operator()(S &&it) const {
-         std::advance(it, n);
-         return std::forward<S>(it);
-      }
-
-   private:
-      T n;
-   };
-
-   template<typename T>
-   advances_by_t<T>
-   advances_by(T n) {
-      return { n };
-   }
-
-   struct zips {
-      template<typename... Ts>
-      std::tuple<Ts...>
-      operator()(Ts &&... xs) const {
-         return std::tuple<Ts...>(std::forward<Ts>(xs)...);
-      }
-   };
-
-   struct is_zero {
-      template<typename T>
-      bool
-      operator()(const T &x) const {
-         return x == 0;
-      }
-   };
-
-   struct keys {
-      template<typename P>
-      auto
-      operator()(P &&p) const -> decltype(std::get<0>(std::forward<P>(p))) {
-         return std::get<0>(std::forward<P>(p));
-      }
-   };
-
-   struct values {
-      template<typename P>
-      auto
-      operator()(P &&p) const -> decltype(std::get<1>(std::forward<P>(p))) {
-         return std::get<1>(std::forward<P>(p));
-      }
-   };
-
-   template<typename T>
-   class equals_t {
-   public:
-      equals_t(T &&x) : x(x) {}
-
-      template<typename S>
-      bool
-      operator()(S &&y) const {
-         return x == y;
-      }
-
-   private:
-      T x;
-   };
-
-   template<typename T>
-   equals_t<T>
-   equals(T &&x) {
-      return { std::forward<T>(x) };
-   }
-
-   class name_equals {
-   public:
-      name_equals(const std::string &name) : name(name) {
-      }
-
-      template<typename T>
-      bool
-      operator()(const T &x) const {
-         return std::string(x.name.begin(), x.name.end()) == name;
-      }
-
-   private:
-      const std::string &name;
-   };
-
-   template<typename T>
-   class key_equals_t {
-   public:
-      key_equals_t(T &&x) : x(x) {
-      }
-
-      template<typename P>
-      bool
-      operator()(const P &p) const {
-         return p.first == x;
-      }
-
-   private:
-      T x;
-   };
-
-   template<typename T>
-   key_equals_t<T>
-   key_equals(T &&x) {
-      return { std::forward<T>(x) };
-   }
-
-   template<typename T>
-   class type_equals_t {
-   public:
-      type_equals_t(T type) : type(type) {
-      }
-
-      template<typename S>
-      bool
-      operator()(const S &x) const {
-         return x.type == type;
-      }
-
-   private:
-      T type;
-   };
-
-   template<typename T>
-   type_equals_t<T>
-   type_equals(T x) {
-      return { x };
-   }
-
-   template<typename T>
-   class id_type_equals_t {
-   public:
-      id_type_equals_t(const uint32_t id, T t) :
-         id(id), type(t) {
-      }
-
-      template<typename X>
-      bool
-      operator()(const X &x) const {
-         return id == x.id && type(x);
-      }
-
-   private:
-      const uint32_t id;
-      type_equals_t<T> type;
-   };
-
-   template<typename T>
-   id_type_equals_t<T>
-   id_type_equals(const uint32_t id, T x) {
-      return { id, x };
-   }
-
-   struct interval_overlaps {
-      template<typename T>
-      bool
-      operator()(T x0, T x1, T y0, T y1) {
-         return ((x0 <= y0 && y0 < x1) ||
-                 (y0 <= x0 && x0 < y1));
-      }
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/lazy.hpp b/src/gallium/frontends/clover/util/lazy.hpp
deleted file mode 100644
index e32a8f8b1b9..00000000000
--- a/src/gallium/frontends/clover/util/lazy.hpp
+++ /dev/null
@@ -1,161 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_LAZY_HPP
-#define CLOVER_UTIL_LAZY_HPP
-
-#include <type_traits>
-#include <stdexcept>
-#include <memory>
-
-namespace clover {
-   namespace detail {
-      template<typename T>
-      class basic_lazy {
-      public:
-         virtual
-         ~basic_lazy() {
-         }
-
-         virtual basic_lazy *
-         clone() const = 0;
-
-         virtual
-         operator T() const = 0;
-      };
-
-      template<typename T, typename F>
-      class deferred_lazy : public basic_lazy<T> {
-      public:
-         template<typename G>
-         deferred_lazy(G &&f) : f(new F(std::forward<G>(f))) {
-         }
-
-         virtual basic_lazy<T> *
-         clone() const {
-            return new deferred_lazy(*this);
-         }
-
-         operator T() const {
-            if (f) {
-               x = (*f)();
-               f = {};
-            }
-
-            return x;
-         }
-
-      private:
-         mutable std::shared_ptr<F> f;
-         mutable T x;
-      };
-
-      template<typename T>
-      class strict_lazy : public basic_lazy<T> {
-      public:
-         template<typename S>
-         strict_lazy(S &&x) : x(std::forward<S>(x)) {
-         }
-
-         virtual basic_lazy<T> *
-         clone() const {
-            return new strict_lazy(*this);
-         }
-
-         operator T() const {
-            return x;
-         }
-
-      private:
-         T x;
-      };
-   }
-
-   ///
-   /// Object that represents a value of type \a T that is calculated
-   /// lazily as soon as it is required.
-   ///
-   template<typename T>
-   class lazy {
-   public:
-      class undefined_error : std::logic_error {
-      public:
-         undefined_error() : std::logic_error("") {
-         }
-      };
-
-      ///
-      /// Initialize to some fixed value \a x which isn't calculated
-      /// lazily.
-      ///
-      lazy(T x) : obj(new detail::strict_lazy<T>(x)) {
-      }
-
-      ///
-      /// Initialize by providing a functor \a f that will calculate
-      /// the value on-demand.
-      ///
-      template<typename F>
-      lazy(F &&f) : obj(new detail::deferred_lazy<
-                           T, typename std::remove_reference<F>::type
-                        >(std::forward<F>(f))) {
-      }
-
-      ///
-      /// Initialize to undefined.
-      ///
-      lazy() : lazy([]() {
-               throw undefined_error();
-               return T();
-            }) {
-      }
-
-      lazy(const lazy &other) : obj(obj->clone()) {
-      }
-
-      lazy(lazy &&other) : obj(NULL) {
-         std::swap(obj, other.obj);
-      }
-
-      ~lazy() {
-         delete obj;
-      }
-
-      lazy &
-      operator=(lazy other) {
-         std::swap(obj, other.obj);
-         return *this;
-      }
-
-      ///
-      /// Evaluate the value.
-      ///
-      operator T() const {
-         return *obj;
-      }
-
-   private:
-      detail::basic_lazy<T> *obj;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/pointer.hpp b/src/gallium/frontends/clover/util/pointer.hpp
deleted file mode 100644
index 7bb9951aef6..00000000000
--- a/src/gallium/frontends/clover/util/pointer.hpp
+++ /dev/null
@@ -1,284 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_POINTER_HPP
-#define CLOVER_UTIL_POINTER_HPP
-
-#include <atomic>
-
-namespace clover {
-   ///
-   /// Some helper functions for raw pointer operations
-   ///
-   template <class T>
-   static bool
-   ptr_is_aligned(const T *ptr, uintptr_t a) noexcept {
-      assert(a == (a & -a));
-      uintptr_t ptr_value = reinterpret_cast<uintptr_t>(ptr);
-      return (ptr_value & (a - 1)) == 0;
-   }
-
-   ///
-   /// Base class for objects that support reference counting.
-   ///
-   class ref_counter {
-   public:
-      ref_counter(unsigned value = 1) : _ref_count(value) {}
-
-      unsigned
-      ref_count() const {
-         return _ref_count;
-      }
-
-      void
-      retain() {
-         _ref_count++;
-      }
-
-      bool
-      release() {
-         return (--_ref_count) == 0;
-      }
-
-   private:
-      std::atomic<unsigned> _ref_count;
-   };
-
-   ///
-   /// Simple reference to a clover::ref_counter object.  Unlike
-   /// clover::intrusive_ptr and clover::intrusive_ref, it does nothing
-   /// special when the reference count drops to zero.
-   ///
-   class ref_holder {
-   public:
-      ref_holder(ref_counter &o) : p(&o) {
-         p->retain();
-      }
-
-      ref_holder(const ref_holder &ref) :
-         ref_holder(*ref.p) {
-      }
-
-      ref_holder(ref_holder &&ref) :
-         p(ref.p) {
-         ref.p = NULL;
-      }
-
-      ~ref_holder() {
-         if (p)
-            p->release();
-      }
-
-      ref_holder &
-      operator=(ref_holder ref) {
-         std::swap(ref.p, p);
-         return *this;
-      }
-
-      bool
-      operator==(const ref_holder &ref) const {
-         return p == ref.p;
-      }
-
-      bool
-      operator!=(const ref_holder &ref) const {
-         return p != ref.p;
-      }
-
-   private:
-      ref_counter *p;
-   };
-
-   ///
-   /// Intrusive smart pointer for objects that implement the
-   /// clover::ref_counter interface.
-   ///
-   template<typename T>
-   class intrusive_ptr {
-   public:
-      intrusive_ptr(T *q = NULL) : p(q) {
-         if (p)
-            p->retain();
-      }
-
-      intrusive_ptr(const intrusive_ptr &ptr) :
-         intrusive_ptr(ptr.p) {
-      }
-
-      intrusive_ptr(intrusive_ptr &&ptr) :
-         p(ptr.p) {
-         ptr.p = NULL;
-      }
-
-      ~intrusive_ptr() {
-         if (p && p->release())
-            delete p;
-      }
-
-      intrusive_ptr &
-      operator=(intrusive_ptr ptr) {
-         std::swap(ptr.p, p);
-         return *this;
-      }
-
-      bool
-      operator==(const intrusive_ptr &ref) const {
-         return p == ref.p;
-      }
-
-      bool
-      operator!=(const intrusive_ptr &ref) const {
-         return p != ref.p;
-      }
-
-      T &
-      operator*() const {
-         return *p;
-      }
-
-      T *
-      operator->() const {
-         return p;
-      }
-
-      T *
-      operator()() const {
-         return p;
-      }
-
-      explicit operator bool() const {
-         return p;
-      }
-
-      explicit operator T *() const {
-         return p;
-      }
-
-   private:
-      T *p;
-   };
-
-   ///
-   /// Intrusive smart reference for objects that implement the
-   /// clover::ref_counter interface.
-   ///
-   template<typename T>
-   class intrusive_ref {
-   public:
-      intrusive_ref(T &o) : p(&o) {
-         p->retain();
-      }
-
-      intrusive_ref(const intrusive_ref &ref) :
-         intrusive_ref(*ref.p) {
-      }
-
-      intrusive_ref(intrusive_ref &&ref) :
-         p(ref.p) {
-         ref.p = NULL;
-      }
-
-      ~intrusive_ref() {
-         if (p && p->release())
-            delete p;
-      }
-
-      intrusive_ref &
-      operator=(intrusive_ref ref) {
-         std::swap(ref.p, p);
-         return *this;
-      }
-
-      bool
-      operator==(const intrusive_ref &ref) const {
-         return p == ref.p;
-      }
-
-      bool
-      operator!=(const intrusive_ref &ref) const {
-         return p != ref.p;
-      }
-
-      T &
-      operator()() const {
-         return *p;
-      }
-
-      operator T &() const {
-         return *p;
-      }
-
-   private:
-      T *p;
-   };
-
-   ///
-   /// Initialize a clover::intrusive_ref from a newly created object
-   /// using the specified constructor arguments.
-   ///
-   template<typename T, typename... As>
-   intrusive_ref<T>
-   create(As &&... as) {
-      intrusive_ref<T> ref { *new T(std::forward<As>(as)...) };
-      ref().release();
-      return ref;
-   }
-
-   ///
-   /// Class that implements the usual pointer interface but in fact
-   /// contains the object it seems to be pointing to.
-   ///
-   template<typename T>
-   class pseudo_ptr {
-   public:
-      pseudo_ptr(T x) : x(x) {
-      }
-
-      pseudo_ptr(const pseudo_ptr &p) : x(p.x) {
-      }
-
-      pseudo_ptr &
-      operator=(const pseudo_ptr &p) {
-         x = p.x;
-         return *this;
-      }
-
-      T &
-      operator*() {
-         return x;
-      }
-
-      T *
-      operator->() {
-         return &x;
-      }
-
-      explicit operator bool() const {
-         return true;
-      }
-
-   private:
-      T x;
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/range.hpp b/src/gallium/frontends/clover/util/range.hpp
deleted file mode 100644
index b082359ee86..00000000000
--- a/src/gallium/frontends/clover/util/range.hpp
+++ /dev/null
@@ -1,419 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_RANGE_HPP
-#define CLOVER_UTIL_RANGE_HPP
-
-#include <array>
-#include <vector>
-
-#include "util/adaptor.hpp"
-
-namespace clover {
-   ///
-   /// Class that identifies container types where the elements of a
-   /// range can be stored by the type conversion operator.
-   ///
-   /// \a T identifies the range element type.
-   ///
-   template<typename T, typename V>
-   struct range_store_traits;
-
-   template<typename T, typename S>
-   struct range_store_traits<T, std::vector<S>> {
-      typedef void enable;
-
-      template<typename R>
-      static std::vector<S>
-      create(const R &r) {
-         return { r.begin(), r.end() };
-      }
-   };
-
-   template<typename T, typename S, std::size_t N>
-   struct range_store_traits<T, std::array<S, N>> {
-      typedef void enable;
-
-      template<typename R>
-      static std::array<S, N>
-      create(const R &r) {
-         std::array<S, N> v;
-         assert(r.size() == v.size());
-         copy(r, v.begin());
-         return v;
-      }
-   };
-
-   namespace detail {
-      ///
-      /// Common functionality that is shared by other implementations
-      /// of the container concept.
-      ///
-      template<typename R, typename I, typename CI>
-      class basic_range {
-      public:
-         typedef I iterator;
-         typedef CI const_iterator;
-         typedef typename std::iterator_traits<iterator>::value_type value_type;
-         typedef typename std::iterator_traits<iterator>::reference
-            reference;
-         typedef typename std::iterator_traits<const_iterator>::reference
-            const_reference;
-         typedef typename std::iterator_traits<iterator>::difference_type
-            difference_type;
-         typedef std::size_t size_type;
-
-         bool
-         operator==(const basic_range &r) const {
-            return *static_cast<const R *>(this) == r;
-         }
-
-         bool
-         operator!=(const basic_range &r) const {
-            return !(*this == r);
-         }
-
-         iterator
-         begin() {
-            return static_cast<R *>(this)->begin();
-         }
-
-         iterator
-         end() {
-            return static_cast<R *>(this)->end();
-         }
-
-         const_iterator
-         begin() const {
-            return static_cast<const R *>(this)->begin();
-         }
-
-         const_iterator
-         end() const {
-            return static_cast<const R *>(this)->end();
-         }
-
-         std::reverse_iterator<iterator>
-         rbegin() {
-            return { begin() };
-         }
-
-         std::reverse_iterator<iterator>
-         rend() {
-            return { end() };
-         }
-
-         reference
-         front() {
-            return *begin();
-         }
-
-         reference
-         back() {
-            return *(end() - 1);
-         }
-
-         bool
-         empty() const {
-            return begin() == end();
-         }
-
-         reference
-         at(size_type i) {
-            if (i >= static_cast<const R *>(this)->size())
-               throw std::out_of_range("");
-
-            return begin()[i];
-         }
-
-         const_reference
-         at(size_type i) const {
-            if (i >= static_cast<const R *>(this)->size())
-               throw std::out_of_range("");
-
-            return begin()[i];
-         }
-
-         reference
-         operator[](size_type i) {
-            return begin()[i];
-         }
-
-         const_reference
-         operator[](size_type i) const {
-            return begin()[i];
-         }
-
-         template<typename V>
-         using store_traits = range_store_traits<
-               typename std::remove_cv<value_type>::type, V
-            >;
-
-         template<typename V,
-                  typename = typename store_traits<V>::enable>
-         operator V() const {
-            return store_traits<V>::create(*static_cast<const R *>(this));
-         }
-      };
-   }
-
-   ///
-   /// Range that contains all elements delimited by an iterator pair
-   /// (\a i, \a j).  Use range() as convenience constructor.
-   ///
-   template<typename I>
-   class iterator_range : public detail::basic_range<iterator_range<I>, I, I> {
-   public:
-      typedef detail::basic_range<iterator_range<I>, I, I> super;
-
-      iterator_range() : i(), j() {
-      }
-
-      iterator_range(I i, I j) : i(i), j(j) {
-      }
-
-      bool
-      operator==(const iterator_range &r) const {
-         return i == r.i && j == r.j;
-      }
-
-      I
-      begin() const {
-         return i;
-      }
-
-      I
-      end() const {
-         return j;
-      }
-
-      typename super::size_type
-      size() const {
-         return end() - begin();
-      }
-
-   private:
-      I i, j;
-   };
-
-   namespace detail {
-      template<typename T>
-      using preferred_iterator_type = decltype(std::declval<T>().begin());
-   }
-
-   ///
-   /// Range that transforms the contents of a number of source ranges
-   /// \a os element-wise by using the provided functor \a f.  Use
-   /// map() as convenience constructor.
-   ///
-   template<typename F, typename... Os>
-   class adaptor_range :
-      public detail::basic_range<adaptor_range<F, Os...>,
-                                 detail::iterator_adaptor<
-                                    F, detail::preferred_iterator_type<Os>...>,
-                                 detail::iterator_adaptor<
-                                    F, detail::preferred_iterator_type<const Os>...>
-                                 > {
-   public:
-      typedef detail::basic_range<adaptor_range<F, Os...>,
-                                  detail::iterator_adaptor<
-                                     F, detail::preferred_iterator_type<Os>...>,
-                                  detail::iterator_adaptor<
-                                     F, detail::preferred_iterator_type<const Os>...>
-                                  > super;
-
-      template<typename G, typename... Rs>
-      adaptor_range(G &&f, Rs &&... os) :
-         f(std::forward<G>(f)), os(std::forward<Rs>(os)...) {
-      }
-
-      bool
-      operator==(const adaptor_range &r) const {
-         return f == r.f && os == r.os;
-      }
-
-      typename super::iterator
-      begin() {
-         return { f, tuple::map(begins(), os) };
-      }
-
-      typename super::iterator
-      end() {
-         return { f, tuple::map(advances_by(size()),
-                                tuple::map(begins(), os)) };
-      }
-
-      typename super::const_iterator
-      begin() const {
-         return { f, tuple::map(begins(), os) };
-      }
-
-      typename super::const_iterator
-      end() const {
-         return { f, tuple::map(advances_by(size()),
-                                tuple::map(begins(), os)) };
-      }
-
-      typename super::size_type
-      size() const {
-         return tuple::apply(minimum(), tuple::map(sizes(), os));
-      }
-
-   private:
-      F f;
-      std::tuple<Os...> os;
-   };
-
-   ///
-   /// Range that contains all elements delimited by the index pair
-   /// (\a i, \a j) in the source range \a r.  Use slice() as
-   /// convenience constructor.
-   ///
-   template<typename O>
-   class slice_range :
-      public detail::basic_range<slice_range<O>,
-                                 detail::preferred_iterator_type<O>,
-                                 detail::preferred_iterator_type<const O>> {
-   public:
-      typedef detail::basic_range<slice_range<O>,
-                                 detail::preferred_iterator_type<O>,
-                                 detail::preferred_iterator_type<const O>
-                                  > super;
-
-      template<typename R>
-      slice_range(R &&r, typename super::size_type i,
-                  typename super::size_type j) :
-         o(std::forward<R>(r)), i(i), j(j) {
-      }
-
-      bool
-      operator==(const slice_range &r) const {
-         return o == r.o && i == r.i && j == r.j;
-      }
-
-      typename super::iterator
-      begin() {
-         return std::next(o.begin(), i);
-      }
-
-      typename super::iterator
-      end() {
-         return std::next(o.begin(), j);
-      }
-
-      typename super::const_iterator
-      begin() const {
-         return std::next(o.begin(), i);
-      }
-
-      typename super::const_iterator
-      end() const {
-         return std::next(o.begin(), j);
-      }
-
-      typename super::size_type
-      size() const {
-         return j - i;
-      }
-
-   private:
-      O o;
-      typename super::size_type i, j;
-   };
-
-   ///
-   /// Create a range from an iterator pair (\a i, \a j).
-   ///
-   /// \sa iterator_range.
-   ///
-   template<typename T>
-   iterator_range<T>
-   range(T i, T j) {
-      return { i, j };
-   }
-
-   ///
-   /// Create a range of \a n elements starting from iterator \a i.
-   ///
-   /// \sa iterator_range.
-   ///
-   template<typename T>
-   iterator_range<T>
-   range(T i, typename std::iterator_traits<T>::difference_type n) {
-      return { i, i + n };
-   }
-
-   ///
-   /// Create a range by transforming the contents of a number of
-   /// source ranges \a rs element-wise using a provided functor \a f.
-   ///
-   /// \sa adaptor_range.
-   ///
-   template<typename F, typename... Rs>
-   adaptor_range<F, Rs...>
-   map(F &&f, Rs &&... rs) {
-      return { std::forward<F>(f), std::forward<Rs>(rs)... };
-   }
-
-   ///
-   /// Create a range identical to another range \a r.
-   ///
-   template<typename R>
-   adaptor_range<identity, R>
-   range(R &&r) {
-      return { identity(), std::forward<R>(r) };
-   }
-
-   ///
-   /// Create a range by taking the elements delimited by the index
-   /// pair (\a i, \a j) in a source range \a r.
-   ///
-   /// \sa slice_range.
-   ///
-   template<typename R>
-   slice_range<R>
-   slice(R &&r, typename slice_range<R>::size_type i,
-         typename slice_range<R>::size_type j) {
-      return { std::forward<R>(r), i, j };
-   }
-
-   ///
-   /// Range that behaves as a vector of references of type \a T.
-   ///
-   /// Useful because STL containers cannot contain references to
-   /// objects as elements.
-   ///
-   template<typename T>
-   class ref_vector : public adaptor_range<derefs, std::vector<T *>> {
-   public:
-      ref_vector(std::initializer_list<std::reference_wrapper<T>> il) :
-         adaptor_range<derefs, std::vector<T *>>(derefs(), map(addresses(), il)) {
-      }
-
-      template<typename R>
-      ref_vector(R &&r) : adaptor_range<derefs, std::vector<T *>>(
-         derefs(), map(addresses(), std::forward<R>(r))) {
-      }
-   };
-}
-
-#endif
diff --git a/src/gallium/frontends/clover/util/tuple.hpp b/src/gallium/frontends/clover/util/tuple.hpp
deleted file mode 100644
index bd49684a314..00000000000
--- a/src/gallium/frontends/clover/util/tuple.hpp
+++ /dev/null
@@ -1,117 +0,0 @@
-//
-// Copyright 2013 Francisco Jerez
-//
-// Permission is hereby granted, free of charge, to any person obtaining a
-// copy of this software and associated documentation files (the "Software"),
-// to deal in the Software without restriction, including without limitation
-// the rights to use, copy, modify, merge, publish, distribute, sublicense,
-// and/or sell copies of the Software, and to permit persons to whom the
-// Software is furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
-// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
-// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
-// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
-// OTHER DEALINGS IN THE SOFTWARE.
-//
-
-#ifndef CLOVER_UTIL_TUPLE_HPP
-#define CLOVER_UTIL_TUPLE_HPP
-
-#include <tuple>
-
-namespace clover {
-   namespace tuple {
-      ///
-      /// Static sequence of integers.
-      ///
-      template<int... Is>
-      struct integral_sequence;
-
-      ///
-      /// Static sequence containing all integers from 0 to N-1.
-      ///
-      template<int N, int... Is>
-      struct enumerate {
-         typedef typename enumerate<N-1, N-1, Is...>::type
-            type;
-      };
-
-      template<int... Is>
-      struct enumerate<0, Is...> {
-         typedef integral_sequence<Is...> type;
-      };
-
-      namespace detail {
-         template<typename F, typename T,
-                  typename E = typename enumerate<std::tuple_size<
-                        typename std::remove_reference<T>::type>::value
-                     >::type>
-         struct _apply;
-
-         template<typename F, typename T, int... Is>
-         struct _apply<F, T, integral_sequence<Is...>> {
-            typedef typename std::remove_reference<F>::type func_type;
-            typedef decltype(
-               std::declval<func_type>()(std::get<Is>(std::declval<T &&>())...)
-               ) value_type;
-
-            static value_type
-               eval(F &&f, T &&t) {
-               return f(std::get<Is>(std::forward<T>(t))...);
-            }
-         };
-      }
-
-      ///
-      /// Evaluate function \a f with the elements of tuple \a t
-      /// expanded as arguments.
-      ///
-      template<typename F, typename T>
-      typename detail::_apply<F, T>::value_type
-      apply(F &&f, T &&t) {
-         return detail::_apply<F, T>::eval(std::forward<F>(f),
-                                           std::forward<T>(t));
-      }
-
-      namespace detail {
-         template<typename F, typename T,
-                  typename E = typename enumerate<std::tuple_size<
-                        typename std::remove_reference<T>::type>::value
-                     >::type>
-         struct _map;
-
-         template<typename F, typename T, int... Is>
-         struct _map<F, T, integral_sequence<Is...>> {
-            typedef typename std::remove_reference<F>::type func_type;
-            typedef std::tuple<
-               decltype(std::declval<func_type>()(
-                           std::get<Is>(std::declval<T &&>())))...
-               > value_type;
-
-            static value_type
-               eval(F &&f, T &&t) {
-               return value_type(f(std::get<Is>(std::forward<T>(t)))...);
-            }
-         };
-      }
-
-      ///
-      /// Evaluate function \a f on each element of the tuple \a t and
-      /// return the resulting values as a new tuple.
-      ///
-      template<typename F, typename T>
-      typename detail::_map<F, T>::value_type
-      map(F &&f, T &&t) {
-         return detail::_map<F, T>::eval(std::forward<F>(f),
-                                         std::forward<T>(t));
-      }
-   }
-}
-
-#endif
diff --git a/src/gallium/frontends/dri/dri_drawable.c b/src/gallium/frontends/dri/dri_drawable.c
index 46275ba921a..b219caefa60 100644
--- a/src/gallium/frontends/dri/dri_drawable.c
+++ b/src/gallium/frontends/dri/dri_drawable.c
@@ -96,9 +96,11 @@ dri_st_framebuffer_validate(struct st_context *st,
        pscreen->set_damage_region) {
       struct pipe_resource *resource = textures[ST_ATTACHMENT_BACK_LEFT];
 
-      pscreen->set_damage_region(pscreen, resource,
-                                 drawable->num_damage_rects,
-                                 drawable->damage_rects);
+      if (resource) {
+         pscreen->set_damage_region(pscreen, resource,
+                                    drawable->num_damage_rects,
+                                    drawable->damage_rects);
+      }
    }
 
    if (!out)
diff --git a/src/gallium/frontends/lavapipe/ci/gitlab-ci-inc.yml b/src/gallium/frontends/lavapipe/ci/gitlab-ci-inc.yml
index 13be382910e..267d558b44e 100644
--- a/src/gallium/frontends/lavapipe/ci/gitlab-ci-inc.yml
+++ b/src/gallium/frontends/lavapipe/ci/gitlab-ci-inc.yml
@@ -26,7 +26,7 @@
       when: on_success
 
 .lavapipe-manual-rules:
-  stage: software-renderer-postmerge
+  stage: software-renderer-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
diff --git a/src/gallium/frontends/lavapipe/ci/gitlab-ci.yml b/src/gallium/frontends/lavapipe/ci/gitlab-ci.yml
index 73ff5dd5f31..ffe7cfe6583 100644
--- a/src/gallium/frontends/lavapipe/ci/gitlab-ci.yml
+++ b/src/gallium/frontends/lavapipe/ci/gitlab-ci.yml
@@ -28,12 +28,13 @@ lavapipe-vk-asan:
     DEQP_SUITE: lvp-asan
     GPU_VERSION: lvp-asan
     DEQP_FORCE_ASAN: 1
+    S3_ARTIFACT_NAME: mesa-x86_64-asan-debugoptimized
   needs:
     - debian/x86_64_test-vk
     - debian-testing-asan
 
 lavapipe-vkd3d:
-  stage: software-renderer-postmerge
+  stage: software-renderer-nightly
   extends:
     - .lavapipe-test
     - .lavapipe-manual-rules
diff --git a/src/gallium/frontends/lavapipe/ci/lvp-android-angle-android-cts-include.txt b/src/gallium/frontends/lavapipe/ci/lvp-android-angle-android-cts-include.txt
new file mode 100644
index 00000000000..511845a71ce
--- /dev/null
+++ b/src/gallium/frontends/lavapipe/ci/lvp-android-angle-android-cts-include.txt
@@ -0,0 +1,10 @@
+x86_64 CtsGraphicsTestCases
+x86_64 CtsNativeHardwareTestCases
+x86_64 CtsSkQPTestCases
+
+# When adding more entries like the ones below, uncommented, remember to add
+# the respective modules (e.g. CtsDeqpTestCases) to ANDROID_CTS_MODULES in
+# .gitlab-ci/container/gitlab-ci.yml::.android-variables
+
+#x86_64 CtsDeqpTestCases dEQP-VK.wsi.android.*
+#x86_64 CtsDeqpTestCases dEQP-VK.api.external.memory.android_hardware_buffer.*
diff --git a/src/gallium/frontends/lavapipe/ci/lvp-android-angle-android-cts-skips.txt b/src/gallium/frontends/lavapipe/ci/lvp-android-angle-android-cts-skips.txt
index 9202b8e987d..5f669d02ac0 100644
--- a/src/gallium/frontends/lavapipe/ci/lvp-android-angle-android-cts-skips.txt
+++ b/src/gallium/frontends/lavapipe/ci/lvp-android-angle-android-cts-skips.txt
@@ -27,6 +27,10 @@ x86_64 CtsGraphicsTestCases android.graphics.drawable.cts.AnimatedVectorDrawable
 x86_64 CtsGraphicsTestCases android.graphics.drawable.cts.AnimationDrawableTest
 x86_64 CtsGraphicsTestCases android.graphics.drawable.cts.IconTest
 
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#Blob_BlobTest_GpuDataBufferCpuRead_BLOB
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#Blob_BlobTest_GpuDataBufferCpuWrite_BLOB
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#Blob_BlobTest_GpuDataBufferVertexBuffer_BLOB
+
 # Failures
 x86_64 CtsGraphicsTestCases android.graphics.cts.BitmapTest#testHardwareBitmapNotLeaking
 x86_64 CtsGraphicsTestCases android.graphics.cts.VulkanFeaturesTest#testVulkanRequiredExtensions
@@ -38,3 +42,19 @@ x86_64 CtsGraphicsTestCases android.graphics.cts.VulkanFeaturesTest#testAndroidB
 x86_64 CtsGraphicsTestCases android.graphics.cts.VulkanFeaturesTest#testVulkanVersionForVrHighPerformance
 x86_64 CtsGraphicsTestCases android.graphics.cts.VulkanFeaturesTest#testVulkanBlockedExtensions
 x86_64 CtsGraphicsTestCases android.graphics.cts.VulkanFeaturesTest#testVulkan1_1Requirements
+
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_CpuWriteColorGpuRead_R10G10B10A2_UNORM
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_CpuWriteColorGpuRead_R16G16B16A16_FLOAT
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_CpuWriteColorGpuRead_R5G6B5_UNORM
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_CpuWriteColorGpuRead_R8G8B8A8_UNORM
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_CpuWriteColorGpuRead_R8G8B8A8_UNORM_sRGB
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_CpuWriteColorGpuRead_R8G8B8X8_UNORM
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_CpuWriteColorGpuRead_R8G8B8X8_UNORM_sRGB
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_GpuColorOutputCpuRead_R5G6B5_UNORM
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_GpuColorOutputCpuRead_R8G8B8A8_UNORM
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_GpuColorOutputCpuRead_R8G8B8A8_UNORM_sRGB
+x86_64 CtsNativeHardwareTestCases android.hardware.nativehardware.cts.AHardwareBufferNativeTests#SingleLayer_ColorTest_GpuColorOutputCpuRead_R8G8B8X8_UNORM
+
+x86_64 CtsSkQPTestCases org.skia.skqp.SkQPRunner#UnitTest_ES2BlendWithNoTexture
+x86_64 CtsSkQPTestCases org.skia.skqp.SkQPRunner#UnitTest_GrAHardwareBuffer_BasicDrawTest
+x86_64 CtsSkQPTestCases org.skia.skqp.SkQPRunner#UnitTest_VkYCbcrSampler_DrawImageWithYcbcrSampler
diff --git a/src/gallium/frontends/lavapipe/lvp_acceleration_structure.c b/src/gallium/frontends/lavapipe/lvp_acceleration_structure.c
index 9e3602f4546..043b9c181b3 100644
--- a/src/gallium/frontends/lavapipe/lvp_acceleration_structure.c
+++ b/src/gallium/frontends/lavapipe/lvp_acceleration_structure.c
@@ -646,7 +646,7 @@ lvp_get_as_size(VkDevice device,
 }
 
 static uint32_t
-lvp_get_encode_key(VkAccelerationStructureTypeKHR type,
+lvp_get_encode_key(struct vk_device *device, VkAccelerationStructureTypeKHR type,
                    VkBuildAccelerationStructureFlagBitsKHR flags)
 {
    return 0;
diff --git a/src/gallium/frontends/lavapipe/lvp_ray_tracing_pipeline.c b/src/gallium/frontends/lavapipe/lvp_ray_tracing_pipeline.c
index 2f8dd30c990..f81493207d8 100644
--- a/src/gallium/frontends/lavapipe/lvp_ray_tracing_pipeline.c
+++ b/src/gallium/frontends/lavapipe/lvp_ray_tracing_pipeline.c
@@ -266,6 +266,7 @@ struct lvp_ray_tracing_state {
    nir_variable *tmax;
 
    nir_variable *instance_addr;
+   nir_variable *primitive_addr;
    nir_variable *primitive_id;
    nir_variable *geometry_id_and_flags;
    nir_variable *hit_kind;
@@ -312,8 +313,10 @@ lvp_ray_tracing_pipeline_compiler_get_stack_size(
 }
 
 static void
-lvp_ray_tracing_state_init(nir_shader *nir, struct lvp_ray_tracing_state *state)
+lvp_ray_tracing_state_init(nir_shader *nir, struct lvp_ray_tracing_pipeline_compiler *compiler)
 {
+   struct lvp_ray_tracing_state *state = &compiler->state;
+
    state->bvh_base = nir_variable_create(nir, nir_var_shader_temp, glsl_uint64_t_type(), "bvh_base");
    state->flags = nir_variable_create(nir, nir_var_shader_temp, glsl_uint_type(), "flags");
    state->cull_mask = nir_variable_create(nir, nir_var_shader_temp, glsl_uint_type(), "cull_mask");
@@ -338,6 +341,9 @@ lvp_ray_tracing_state_init(nir_shader *nir, struct lvp_ray_tracing_state *state)
    state->accept = nir_variable_create(nir, nir_var_shader_temp, glsl_bool_type(), "accept");
    state->terminate = nir_variable_create(nir, nir_var_shader_temp, glsl_bool_type(), "terminate");
    state->opaque = nir_variable_create(nir, nir_var_shader_temp, glsl_bool_type(), "opaque");
+
+   if (compiler->pipeline->device->vk.enabled_features.rayTracingPositionFetch)
+      state->primitive_addr = nir_variable_create(nir, nir_var_shader_temp, glsl_uint64_t_type(), "primitive_addr");
 }
 
 static void
@@ -655,6 +661,12 @@ lvp_handle_triangle_intersection(nir_builder *b,
    nir_store_var(b, state->hit_kind,
                  nir_bcsel(b, intersection->frontface, nir_imm_int(b, 0xFE), nir_imm_int(b, 0xFF)), 0x1);
 
+   nir_def *prev_primitive_addr = NULL;
+   if (state->primitive_addr) {
+      prev_primitive_addr = nir_load_var(b, state->primitive_addr);
+      nir_store_var(b, state->primitive_addr, intersection->base.node_addr, 0x1);
+   }         
+
    nir_store_scratch(b, intersection->barycentrics, barycentrics_offset);
 
    nir_def *geometry_id = nir_iand_imm(b, intersection->base.geometry_id_and_flags, 0xfffffff);
@@ -702,6 +714,8 @@ lvp_handle_triangle_intersection(nir_builder *b,
       nir_store_var(b, state->geometry_id_and_flags, prev_geometry_id_and_flags, 0x1);
       nir_store_var(b, state->hit_kind, prev_hit_kind, 0x1);
       nir_store_scratch(b, prev_barycentrics, barycentrics_offset);
+      if (state->primitive_addr)
+         nir_store_var(b, state->primitive_addr, prev_primitive_addr, 0x1);
    }
    nir_pop_if(b, NULL);
 }
@@ -993,8 +1007,7 @@ lvp_lower_ray_tracing_instr(nir_builder *b, nir_instr *instr, void *data)
    }
    case nir_intrinsic_load_ray_triangle_vertex_positions: {
       def = lvp_load_vertex_position(
-         b, nir_load_var(b, state->instance_addr), nir_load_var(b, state->primitive_id),
-         nir_intrinsic_column(intr));
+         b, nir_load_var(b, state->primitive_addr), nir_intrinsic_column(intr));
       break;
    }
    /* Internal system values */
@@ -1041,7 +1054,7 @@ lvp_compile_ray_tracing_pipeline(struct lvp_pipeline *pipeline,
       .pipeline = pipeline,
       .flags = vk_rt_pipeline_create_flags(create_info),
    };
-   lvp_ray_tracing_state_init(b->shader, &compiler.state);
+   lvp_ray_tracing_state_init(b->shader, &compiler);
    compiler.functions = _mesa_pointer_hash_table_create(NULL);
 
    nir_def *launch_id = nir_load_ray_launch_id(b);
diff --git a/src/gallium/frontends/lavapipe/nir/lvp_nir.h b/src/gallium/frontends/lavapipe/nir/lvp_nir.h
index 20910879e2d..a4b6535b696 100644
--- a/src/gallium/frontends/lavapipe/nir/lvp_nir.h
+++ b/src/gallium/frontends/lavapipe/nir/lvp_nir.h
@@ -14,8 +14,7 @@ nir_def *lvp_mul_vec3_mat(nir_builder *b, nir_def *vec, nir_def *matrix[], bool
 
 void lvp_load_wto_matrix(nir_builder *b, nir_def *instance_addr, nir_def **node_data, nir_def **out);
 
-nir_def *lvp_load_vertex_position(nir_builder *b, nir_def *instance_addr,
-                                  nir_def *primitive_id, uint32_t index);
+nir_def *lvp_load_vertex_position(nir_builder *b, nir_def *primitive_addr, uint32_t index);
 
 struct lvp_ray_traversal_args;
 
diff --git a/src/gallium/frontends/lavapipe/nir/lvp_nir_lower_ray_queries.c b/src/gallium/frontends/lavapipe/nir/lvp_nir_lower_ray_queries.c
index 2ad9f41aeba..3ca66b9c5c4 100644
--- a/src/gallium/frontends/lavapipe/nir/lvp_nir_lower_ray_queries.c
+++ b/src/gallium/frontends/lavapipe/nir/lvp_nir_lower_ray_queries.c
@@ -121,6 +121,7 @@ struct ray_query_traversal_vars {
 };
 
 struct ray_query_intersection_vars {
+   rq_variable *primitive_addr;
    rq_variable *primitive_id;
    rq_variable *geometry_id_and_flags;
    rq_variable *instance_addr;
@@ -182,6 +183,8 @@ init_ray_query_intersection_vars(void *ctx, nir_shader *shader, unsigned array_l
 
    const struct glsl_type *vec2_type = glsl_vector_type(GLSL_TYPE_FLOAT, 2);
 
+   result.primitive_addr =
+      rq_variable_create(ctx, shader, array_length, glsl_uint64_t_type(), VAR_NAME("_primitive_addr"));
    result.primitive_id =
       rq_variable_create(ctx, shader, array_length, glsl_uint_type(), VAR_NAME("_primitive_id"));
    result.geometry_id_and_flags = rq_variable_create(ctx, shader, array_length, glsl_uint_type(),
@@ -249,6 +252,7 @@ lower_ray_query(nir_shader *shader, nir_variable *ray_query, struct hash_table *
 static void
 copy_candidate_to_closest(nir_builder *b, nir_def *index, struct ray_query_vars *vars)
 {
+   rq_copy_var(b, index, vars->closest.primitive_addr, vars->candidate.primitive_addr, 0x1);
    rq_copy_var(b, index, vars->closest.barycentrics, vars->candidate.barycentrics, 0x3);
    rq_copy_var(b, index, vars->closest.geometry_id_and_flags, vars->candidate.geometry_id_and_flags,
                0x1);
@@ -431,8 +435,7 @@ lower_rq_load(nir_builder *b, nir_def *index, nir_intrinsic_instr *instr,
       return rq_load_var(b, index, vars->origin);
    case nir_ray_query_value_intersection_triangle_vertex_positions:
       return lvp_load_vertex_position(
-         b, rq_load_var(b, index, intersection->instance_addr),
-         rq_load_var(b, index, intersection->primitive_id), column);
+         b, rq_load_var(b, index, intersection->primitive_addr), column);
    default:
       unreachable("Invalid nir_ray_query_value!");
    }
@@ -474,6 +477,7 @@ handle_candidate_triangle(nir_builder *b, struct lvp_triangle_intersection *inte
    nir_def *index = data->index;
 
    rq_store_var(b, index, vars->candidate.barycentrics, intersection->barycentrics, 3);
+   rq_store_var(b, index, vars->candidate.primitive_addr, intersection->base.node_addr, 1);
    rq_store_var(b, index, vars->candidate.primitive_id, intersection->base.primitive_id, 1);
    rq_store_var(b, index, vars->candidate.geometry_id_and_flags,
                 intersection->base.geometry_id_and_flags, 1);
diff --git a/src/gallium/frontends/lavapipe/nir/lvp_nir_ray_tracing.c b/src/gallium/frontends/lavapipe/nir/lvp_nir_ray_tracing.c
index f5cc2dddf26..42f1aab3899 100644
--- a/src/gallium/frontends/lavapipe/nir/lvp_nir_ray_tracing.c
+++ b/src/gallium/frontends/lavapipe/nir/lvp_nir_ray_tracing.c
@@ -56,20 +56,9 @@ lvp_load_wto_matrix(nir_builder *b, nir_def *instance_addr, nir_def **node_data,
 }
 
 nir_def *
-lvp_load_vertex_position(nir_builder *b, nir_def *instance_addr, nir_def *primitive_id,
-                         uint32_t index)
+lvp_load_vertex_position(nir_builder *b, nir_def *primitive_addr, uint32_t index)
 {
-   nir_def *bvh_addr = nir_build_load_global(
-      b, 1, 64, nir_iadd_imm(b, instance_addr, offsetof(struct lvp_bvh_instance_node, bvh_ptr)));
-
-   nir_def *leaf_nodes_offset = nir_build_load_global(
-      b, 1, 32, nir_iadd_imm(b, bvh_addr, offsetof(struct lvp_bvh_header, leaf_nodes_offset)));
-
-   nir_def *offset = nir_imul_imm(b, primitive_id, sizeof(struct lvp_bvh_triangle_node));
-   offset = nir_iadd(b, offset, leaf_nodes_offset);
-   offset = nir_iadd_imm(b, offset, index * 3 * sizeof(float));
-
-   return nir_build_load_global(b, 3, 32, nir_iadd(b, bvh_addr, nir_u2u64(b, offset)));
+   return nir_build_load_global(b, 3, 32, nir_iadd_imm(b, primitive_addr, index * 3 * sizeof(float)));
 }
 
 static nir_def *
diff --git a/src/gallium/frontends/rusticl/api/context.rs b/src/gallium/frontends/rusticl/api/context.rs
index da74b7ddc17..5654f0e0115 100644
--- a/src/gallium/frontends/rusticl/api/context.rs
+++ b/src/gallium/frontends/rusticl/api/context.rs
@@ -80,7 +80,8 @@ pub fn get_gl_context_info_khr(
     // SAFETY: properties is a 0 terminated array by spec.
     let props = unsafe { Properties::new(properties) }.ok_or(CL_INVALID_PROPERTY)?;
     for (&key, &val) in props.iter() {
-        match key as u32 {
+        let key = u32::try_from(key).or(Err(CL_INVALID_PROPERTY))?;
+        match key {
             // CL_INVALID_PLATFORM [...] if platform value specified in properties is not a valid platform.
             CL_CONTEXT_PLATFORM => {
                 (val as cl_platform_id).get_ref()?;
@@ -143,7 +144,8 @@ fn create_context(
     // SAFETY: properties is a 0 terminated array by spec.
     let props = unsafe { Properties::new(properties) }.ok_or(CL_INVALID_PROPERTY)?;
     for (&key, &val) in props.iter() {
-        match key as u32 {
+        let key = u32::try_from(key).or(Err(CL_INVALID_PROPERTY))?;
+        match key {
             // CL_INVALID_PLATFORM [...] if platform value specified in properties is not a valid platform.
             CL_CONTEXT_PLATFORM => {
                 (val as cl_platform_id).get_ref()?;
diff --git a/src/gallium/frontends/rusticl/api/device.rs b/src/gallium/frontends/rusticl/api/device.rs
index 497bcb49109..e4433812157 100644
--- a/src/gallium/frontends/rusticl/api/device.rs
+++ b/src/gallium/frontends/rusticl/api/device.rs
@@ -100,7 +100,7 @@ unsafe impl CLInfo<cl_device_info> for cl_device_id {
             }
             CL_DEVICE_HOST_UNIFIED_MEMORY => v.write::<bool>(dev.unified_memory()),
             CL_DEVICE_IL_VERSION => v.write::<&CStr>(SPIRV_SUPPORT_STRING),
-            CL_DEVICE_ILS_WITH_VERSION => v.write::<Vec<cl_name_version>>(SPIRV_SUPPORT.to_vec()),
+            CL_DEVICE_ILS_WITH_VERSION => v.write::<&[cl_name_version]>(&SPIRV_SUPPORT),
             CL_DEVICE_IMAGE_BASE_ADDRESS_ALIGNMENT => {
                 v.write::<cl_uint>(dev.image_base_address_alignment())
             }
@@ -189,7 +189,7 @@ unsafe impl CLInfo<cl_device_info> for cl_device_id {
             CL_DEVICE_MAX_SAMPLERS => v.write::<cl_uint>(dev.max_samplers()),
             CL_DEVICE_MAX_WORK_GROUP_SIZE => v.write::<usize>(dev.max_threads_per_block()),
             CL_DEVICE_MAX_WORK_ITEM_DIMENSIONS => v.write::<cl_uint>(dev.max_grid_dimensions()),
-            CL_DEVICE_MAX_WORK_ITEM_SIZES => v.write::<Vec<usize>>(dev.max_block_sizes()),
+            CL_DEVICE_MAX_WORK_ITEM_SIZES => v.write::<&[usize]>(&dev.max_block_sizes()),
             CL_DEVICE_MAX_WRITE_IMAGE_ARGS => v.write::<cl_uint>(dev.caps.max_write_images),
             // TODO proper retrival from devices
             CL_DEVICE_MEM_BASE_ADDR_ALIGN => v.write::<cl_uint>(0x1000),
diff --git a/src/gallium/frontends/rusticl/api/kernel.rs b/src/gallium/frontends/rusticl/api/kernel.rs
index ae864a67fdc..22679682094 100644
--- a/src/gallium/frontends/rusticl/api/kernel.rs
+++ b/src/gallium/frontends/rusticl/api/kernel.rs
@@ -50,8 +50,10 @@ unsafe impl CLInfoObj<cl_kernel_arg_info, cl_uint> for cl_kernel {
     fn query(&self, idx: cl_uint, q: cl_kernel_arg_info, v: CLInfoValue) -> CLResult<CLInfoRes> {
         let kernel = Kernel::ref_from_raw(*self)?;
 
+        let idx = idx as usize;
+
         // CL_INVALID_ARG_INDEX if arg_index is not a valid argument index.
-        if idx as usize >= kernel.kernel_info.args.len() {
+        if idx >= kernel.kernel_info.args.len() {
             return Err(CL_INVALID_ARG_INDEX);
         }
 
@@ -99,13 +101,15 @@ unsafe impl CLInfoObj<cl_kernel_work_group_info, cl_device_id> for cl_kernel {
                 kernel.prog.devs[0]
             }
         } else {
-            Device::ref_from_raw(dev)?
-        };
+            let dev = Device::ref_from_raw(dev)?;
 
-        // CL_INVALID_DEVICE if device is not in the list of devices associated with kernel
-        if !kernel.prog.devs.contains(&dev) {
-            return Err(CL_INVALID_DEVICE);
-        }
+            // CL_INVALID_DEVICE if device is not in the list of devices associated with kernel
+            if !kernel.prog.devs.contains(&dev) {
+                return Err(CL_INVALID_DEVICE);
+            }
+
+            dev
+        };
 
         match *q {
             CL_KERNEL_COMPILE_WORK_GROUP_SIZE => v.write::<[usize; 3]>(kernel.work_group_size()),
diff --git a/src/gallium/frontends/rusticl/api/memory.rs b/src/gallium/frontends/rusticl/api/memory.rs
index 729214c7b56..1229cdfe76e 100644
--- a/src/gallium/frontends/rusticl/api/memory.rs
+++ b/src/gallium/frontends/rusticl/api/memory.rs
@@ -656,7 +656,7 @@ fn validate_buffer(
                                 let addr_alignment = dev.image_base_address_alignment();
                                 if addr_alignment == 0 {
                                     return Err(CL_INVALID_OPERATION);
-                                } else if !is_alligned(host_ptr, addr_alignment as usize) {
+                                } else if !is_aligned_to(host_ptr, addr_alignment as usize) {
                                     return Err(err);
                                 }
                             }
@@ -1020,10 +1020,16 @@ fn create_sampler_with_properties(
     let sampler_properties =
         unsafe { Properties::new(sampler_properties) }.ok_or(CL_INVALID_VALUE)?;
     for (&key, &val) in sampler_properties.iter() {
-        match key as u32 {
-            CL_SAMPLER_ADDRESSING_MODE => addressing_mode = val as u32,
-            CL_SAMPLER_FILTER_MODE => filter_mode = val as u32,
-            CL_SAMPLER_NORMALIZED_COORDS => normalized_coords = val as u32,
+        match u32::try_from(key).or(Err(CL_INVALID_VALUE))? {
+            CL_SAMPLER_ADDRESSING_MODE => {
+                addressing_mode = cl_addressing_mode::try_from(val).or(Err(CL_INVALID_VALUE))?
+            }
+            CL_SAMPLER_FILTER_MODE => {
+                filter_mode = cl_filter_mode::try_from(val).or(Err(CL_INVALID_VALUE))?
+            }
+            CL_SAMPLER_NORMALIZED_COORDS => {
+                normalized_coords = cl_bool::try_from(val).or(Err(CL_INVALID_VALUE))?
+            }
             // CL_INVALID_VALUE if the property name in sampler_properties is not a supported
             // property name
             _ => return Err(CL_INVALID_VALUE),
diff --git a/src/gallium/frontends/rusticl/api/queue.rs b/src/gallium/frontends/rusticl/api/queue.rs
index bf032666de1..1b6b887a9fb 100644
--- a/src/gallium/frontends/rusticl/api/queue.rs
+++ b/src/gallium/frontends/rusticl/api/queue.rs
@@ -132,9 +132,9 @@ fn create_command_queue_with_properties(
 
     // SAFETY: properties is a 0 terminated array by spec.
     let properties = unsafe { Properties::new(properties) }.ok_or(CL_INVALID_PROPERTY)?;
-    for (k, v) in properties.iter() {
-        match *k as cl_uint {
-            CL_QUEUE_PROPERTIES => queue_properties = *v,
+    for (&key, &val) in properties.iter() {
+        match u32::try_from(key).or(Err(CL_INVALID_PROPERTY))? {
+            CL_QUEUE_PROPERTIES => queue_properties = val,
             // CL_INVALID_QUEUE_PROPERTIES if values specified in properties are valid but are not
             // supported by the device.
             CL_QUEUE_SIZE => return Err(CL_INVALID_QUEUE_PROPERTIES),
diff --git a/src/gallium/frontends/rusticl/api/util.rs b/src/gallium/frontends/rusticl/api/util.rs
index dcd059d8699..db913743008 100644
--- a/src/gallium/frontends/rusticl/api/util.rs
+++ b/src/gallium/frontends/rusticl/api/util.rs
@@ -491,10 +491,6 @@ pub fn checked_compare(a: usize, o: cmp::Ordering, b: u64) -> bool {
     }
 }
 
-pub fn is_alligned<T>(ptr: *const T, alignment: usize) -> bool {
-    ptr as usize & (alignment - 1) == 0
-}
-
 pub fn bit_check<A: BitAnd<Output = A> + PartialEq + Default, B: Into<A>>(a: A, b: B) -> bool {
     a & b.into() != A::default()
 }
diff --git a/src/gallium/frontends/rusticl/core/device.rs b/src/gallium/frontends/rusticl/core/device.rs
index 0b6cc238129..260e162ab30 100644
--- a/src/gallium/frontends/rusticl/core/device.rs
+++ b/src/gallium/frontends/rusticl/core/device.rs
@@ -785,7 +785,7 @@ impl Device {
             1 << 26,
             min(
                 self.max_mem_alloc(),
-                self.screen.caps().max_shader_buffer_size as u64,
+                self.screen.caps().max_shader_buffer_size.into(),
             ),
         )
     }
@@ -923,7 +923,7 @@ impl Device {
     }
 
     pub fn global_mem_size(&self) -> cl_ulong {
-        if let Some(memory_info) = self.screen().query_memory_info() {
+        if let Some(memory_info) = self.screen.query_memory_info() {
             let memory: cl_ulong = if memory_info.total_device_memory != 0 {
                 memory_info.total_device_memory.into()
             } else {
@@ -1003,17 +1003,20 @@ impl Device {
         self.screen.compute_caps().max_local_size as cl_ulong
     }
 
-    pub fn max_block_sizes(&self) -> Vec<usize> {
-        let v: [u32; 3] = self.screen.compute_caps().max_block_size;
-        v.into_iter().map(|v| v as usize).collect()
+    pub fn max_block_sizes(&self) -> [usize; 3] {
+        self.screen
+            .compute_caps()
+            .max_block_size
+            .map(|value| value as usize)
     }
 
-    pub fn max_grid_size(&self) -> Vec<usize> {
-        let v: [u32; 3] = self.screen.compute_caps().max_grid_size;
-        v.into_iter()
-            .map(|a| min(a, Platform::dbg().max_grid_size))
-            .map(|v| v as usize)
-            .collect()
+    pub fn max_grid_size(&self) -> [usize; 3] {
+        self.screen
+            .compute_caps()
+            .max_grid_size
+            .map(|screen_max_grid_size| {
+                min(screen_max_grid_size, Platform::dbg().max_grid_size) as usize
+            })
     }
 
     pub fn max_clock_freq(&self) -> cl_uint {
@@ -1025,7 +1028,12 @@ impl Device {
     }
 
     pub fn max_grid_dimensions(&self) -> cl_uint {
-        self.screen.compute_caps().grid_dimension
+        // Much of the kernel code assumes three-dimensional grids, implicitly
+        // capping this value. The OpenCL spec requires a minimum value of 3 for
+        // devices not of type CL_DEVICE_TYPE_CUSTOM.
+        const MAX_GRID_DIM: cl_uint = 3;
+
+        MAX_GRID_DIM
     }
 
     /// Returns the maximum size in bytes of a memory allocation for this
diff --git a/src/gallium/frontends/rusticl/core/kernel.rs b/src/gallium/frontends/rusticl/core/kernel.rs
index 497516ef7ed..1a778738a97 100644
--- a/src/gallium/frontends/rusticl/core/kernel.rs
+++ b/src/gallium/frontends/rusticl/core/kernel.rs
@@ -122,7 +122,7 @@ impl KernelArgType {
 
 #[derive(Hash, PartialEq, Eq, Clone)]
 enum CompiledKernelArgType {
-    APIArg(u32),
+    APIArg(usize),
     ConstantBuffer,
     GlobalWorkOffsets,
     GlobalWorkSize,
@@ -235,7 +235,7 @@ struct CompiledKernelArg {
     kind: CompiledKernelArgType,
     /// The binding for image/sampler args, the offset into the input buffer
     /// for anything else.
-    offset: u32,
+    offset: usize,
     dead: bool,
 }
 
@@ -254,7 +254,7 @@ impl CompiledKernelArg {
                 var.data.binding
             } else {
                 var.data.driver_location
-            };
+            } as usize;
         }
     }
 
@@ -262,7 +262,7 @@ impl CompiledKernelArg {
         unsafe {
             blob_write_uint16(blob, args.len() as u16);
             for arg in args {
-                blob_write_uint32(blob, arg.offset);
+                blob_write_uint32(blob, arg.offset as u32);
                 blob_write_uint8(blob, arg.dead.into());
                 match arg.kind {
                     CompiledKernelArgType::ConstantBuffer => blob_write_uint8(blob, 0),
@@ -282,7 +282,7 @@ impl CompiledKernelArg {
                     CompiledKernelArgType::GlobalWorkSize => blob_write_uint8(blob, 9),
                     CompiledKernelArgType::APIArg(idx) => {
                         blob_write_uint8(blob, 10);
-                        blob_write_uint32(blob, idx)
+                        blob_write_uint32(blob, idx as u32)
                     }
                 };
             }
@@ -295,7 +295,7 @@ impl CompiledKernelArg {
             let mut res = Vec::with_capacity(len);
 
             for _ in 0..len {
-                let offset = blob_read_uint32(blob);
+                let offset = blob_read_uint32(blob) as usize;
                 let dead = blob_read_uint8(blob) != 0;
 
                 let kind = match blob_read_uint8(blob) {
@@ -315,7 +315,7 @@ impl CompiledKernelArg {
                     8 => CompiledKernelArgType::NumWorkgroups,
                     9 => CompiledKernelArgType::GlobalWorkSize,
                     10 => {
-                        let idx = blob_read_uint32(blob);
+                        let idx = blob_read_uint32(blob) as usize;
                         CompiledKernelArgType::APIArg(idx)
                     }
                     _ => return None,
@@ -527,11 +527,10 @@ impl_cl_type_trait!(cl_kernel, Kernel, CL_INVALID_KERNEL);
 fn create_kernel_arr<T>(vals: &[usize], val: T) -> CLResult<[T; 3]>
 where
     T: std::convert::TryFrom<usize> + Copy,
-    <T as std::convert::TryFrom<usize>>::Error: std::fmt::Debug,
 {
     let mut res = [val; 3];
     for (i, v) in vals.iter().enumerate() {
-        res[i] = (*v).try_into().ok().ok_or(CL_OUT_OF_RESOURCES)?;
+        res[i] = (*v).try_into().or(Err(CL_OUT_OF_RESOURCES))?;
     }
 
     Ok(res)
@@ -1009,7 +1008,7 @@ fn compile_nir_variant(
     /* update the has_variable_shared_mem info as we might have DCEed all of them */
     nir.set_has_variable_shared_mem(compiled_args.iter().any(|arg| {
         if let CompiledKernelArgType::APIArg(idx) = arg.kind {
-            args[idx as usize].kind == KernelArgType::MemLocal && !arg.dead
+            args[idx].kind == KernelArgType::MemLocal && !arg.dead
         } else {
             false
         }
@@ -1042,7 +1041,7 @@ fn compile_nir_remaining(
     // add all API kernel args
     let mut compiled_args: Vec<_> = (0..args.len())
         .map(|idx| CompiledKernelArg {
-            kind: CompiledKernelArgType::APIArg(idx as u32),
+            kind: CompiledKernelArgType::APIArg(idx),
             offset: 0,
             dead: true,
         })
@@ -1196,7 +1195,7 @@ pub(super) fn convert_spirv_to_nir(
 
                 for arg in &build.compiled_args {
                     if let CompiledKernelArgType::APIArg(idx) = arg.kind {
-                        args[idx as usize].dead &= arg.dead;
+                        args[idx].dead &= arg.dead;
                     }
                 }
             }
@@ -1351,7 +1350,7 @@ impl Kernel {
         self.optimize_local_size(q.device, &mut grid, &mut block);
 
         Ok(Box::new(move |q, ctx| {
-            let hw_max_grid: Vec<usize> = q.device.max_grid_size();
+            let hw_max_grid = q.device.max_grid_size();
 
             let variant = if offsets == [0; 3]
                 && grid[0] <= hw_max_grid[0]
@@ -1432,23 +1431,23 @@ impl Kernel {
 
             for arg in &nir_kernel_build.compiled_args {
                 let is_opaque = if let CompiledKernelArgType::APIArg(idx) = arg.kind {
-                    kernel_info.args[idx as usize].kind.is_opaque()
+                    kernel_info.args[idx].kind.is_opaque()
                 } else {
                     false
                 };
 
-                if !is_opaque && arg.offset as usize > input.len() {
-                    input.resize(arg.offset as usize, 0);
+                if !is_opaque && arg.offset > input.len() {
+                    input.resize(arg.offset, 0);
                 }
 
                 match arg.kind {
                     CompiledKernelArgType::APIArg(idx) => {
-                        let api_arg = &kernel_info.args[idx as usize];
+                        let api_arg = &kernel_info.args[idx];
                         if api_arg.dead {
                             continue;
                         }
 
-                        let Some(value) = &arg_values[idx as usize] else {
+                        let Some(value) = &arg_values[idx] else {
                             continue;
                         };
 
@@ -1480,11 +1479,10 @@ impl Kernel {
                                     (&mut tex_formats, &mut tex_orders)
                                 };
 
-                                let binding = arg.offset as usize;
-                                assert!(binding >= formats.len());
+                                assert!(arg.offset >= formats.len());
 
-                                formats.resize(binding, 0);
-                                orders.resize(binding, 0);
+                                formats.resize(arg.offset, 0);
+                                orders.resize(arg.offset, 0);
 
                                 formats.push(image.image_format.image_channel_data_type as u16);
                                 orders.push(image.image_format.image_channel_order as u16);
@@ -1655,8 +1653,8 @@ impl Kernel {
         Ok(())
     }
 
-    pub fn access_qualifier(&self, idx: cl_uint) -> cl_kernel_arg_access_qualifier {
-        let aq = self.kernel_info.args[idx as usize].spirv.access_qualifier;
+    pub fn access_qualifier(&self, idx: usize) -> cl_kernel_arg_access_qualifier {
+        let aq = self.kernel_info.args[idx].spirv.access_qualifier;
 
         if aq
             == clc_kernel_arg_access_qualifier::CLC_KERNEL_ARG_ACCESS_READ
@@ -1672,8 +1670,8 @@ impl Kernel {
         }
     }
 
-    pub fn address_qualifier(&self, idx: cl_uint) -> cl_kernel_arg_address_qualifier {
-        match self.kernel_info.args[idx as usize].spirv.address_qualifier {
+    pub fn address_qualifier(&self, idx: usize) -> cl_kernel_arg_address_qualifier {
+        match self.kernel_info.args[idx].spirv.address_qualifier {
             clc_kernel_arg_address_qualifier::CLC_KERNEL_ARG_ADDRESS_PRIVATE => {
                 CL_KERNEL_ARG_ADDRESS_PRIVATE
             }
@@ -1689,8 +1687,8 @@ impl Kernel {
         }
     }
 
-    pub fn type_qualifier(&self, idx: cl_uint) -> cl_kernel_arg_type_qualifier {
-        let tq = self.kernel_info.args[idx as usize].spirv.type_qualifier;
+    pub fn type_qualifier(&self, idx: usize) -> cl_kernel_arg_type_qualifier {
+        let tq = self.kernel_info.args[idx].spirv.type_qualifier;
         let zero = clc_kernel_arg_type_qualifier(0);
         let mut res = CL_KERNEL_ARG_TYPE_NONE;
 
@@ -1721,13 +1719,13 @@ impl Kernel {
         self.kernel_info.subgroup_size
     }
 
-    pub fn arg_name(&self, idx: cl_uint) -> Option<&CStr> {
-        let name = &self.kernel_info.args[idx as usize].spirv.name;
+    pub fn arg_name(&self, idx: usize) -> Option<&CStr> {
+        let name = &self.kernel_info.args[idx].spirv.name;
         name.is_empty().not().then_some(name)
     }
 
-    pub fn arg_type_name(&self, idx: cl_uint) -> Option<&CStr> {
-        let type_name = &self.kernel_info.args[idx as usize].spirv.type_name;
+    pub fn arg_type_name(&self, idx: usize) -> Option<&CStr> {
+        let type_name = &self.kernel_info.args[idx].spirv.type_name;
         type_name.is_empty().not().then_some(type_name)
     }
 
diff --git a/src/gallium/frontends/rusticl/core/memory.rs b/src/gallium/frontends/rusticl/core/memory.rs
index 2afbe9a08b6..d6ab7ec15ad 100644
--- a/src/gallium/frontends/rusticl/core/memory.rs
+++ b/src/gallium/frontends/rusticl/core/memory.rs
@@ -959,14 +959,15 @@ impl MemBase {
         let (shadow_map, texture) = if is_cube_map_face(export_in.target) {
             let shadow = create_shadow_slice(&imported_gl_tex, image_format)?;
 
-            let mut res_map = HashMap::new();
-            shadow
+            let res_map = shadow
                 .iter()
-                .map(|(k, v)| {
-                    let gl_res = Arc::clone(imported_gl_tex.get(k).unwrap());
-                    res_map.insert(Arc::clone(v), gl_res);
+                .map(|(dev, resource)| {
+                    (
+                        Arc::clone(resource),
+                        Arc::clone(imported_gl_tex.get(dev).unwrap()),
+                    )
                 })
-                .for_each(drop);
+                .collect();
 
             (Some(res_map), shadow)
         } else {
diff --git a/src/gallium/frontends/rusticl/core/program.rs b/src/gallium/frontends/rusticl/core/program.rs
index cc7969e2528..d6da0ba325a 100644
--- a/src/gallium/frontends/rusticl/core/program.rs
+++ b/src/gallium/frontends/rusticl/core/program.rs
@@ -479,15 +479,17 @@ impl Program {
     // we need to precalculate the size
     pub fn bin_sizes(&self) -> Vec<usize> {
         let lock = self.build_info();
-        let mut res = Vec::new();
-        for d in &self.devs {
-            let info = lock.dev_build(d);
 
-            res.push(info.spirv.as_ref().map_or(0, |s| {
-                s.to_bin().len() + d.screen().name().to_bytes().len() + BIN_HEADER_SIZE
-            }));
-        }
-        res
+        self.devs
+            .iter()
+            .map(|&device| {
+                let info = lock.dev_build(device);
+
+                info.spirv.as_ref().map_or(0, |s| {
+                    s.to_bin().len() + device.screen().name().to_bytes().len() + BIN_HEADER_SIZE
+                })
+            })
+            .collect()
     }
 
     pub fn binaries(&self, ptrs: &[*mut u8]) -> CLResult<()> {
diff --git a/src/gallium/frontends/rusticl/mesa/compiler/nir.rs b/src/gallium/frontends/rusticl/mesa/compiler/nir.rs
index 15922386804..1ed8517d7fe 100644
--- a/src/gallium/frontends/rusticl/mesa/compiler/nir.rs
+++ b/src/gallium/frontends/rusticl/mesa/compiler/nir.rs
@@ -1,10 +1,10 @@
 use mesa_rust_gen::*;
 use mesa_rust_util::bitset;
-use mesa_rust_util::offset_of;
 
 use std::convert::TryInto;
 use std::ffi::CStr;
 use std::marker::PhantomData;
+use std::mem::offset_of;
 use std::ops::Not;
 use std::ptr;
 use std::ptr::NonNull;
diff --git a/src/gallium/frontends/rusticl/mesa/pipe/device.rs b/src/gallium/frontends/rusticl/mesa/pipe/device.rs
index f5d1cb36435..7925d951aee 100644
--- a/src/gallium/frontends/rusticl/mesa/pipe/device.rs
+++ b/src/gallium/frontends/rusticl/mesa/pipe/device.rs
@@ -64,6 +64,8 @@ fn get_enabled_devs() -> HashMap<String, u32> {
     let default_devs: &[&str] = &[
         #[cfg(any(rusticl_enable_asahi, rusticl_enable_auto))]
         "asahi",
+        #[cfg(any(rusticl_enable_radeonsi))]
+        "radeonsi",
     ];
 
     // I wished we could use different iterators, but that's not really working out.
diff --git a/src/gallium/frontends/rusticl/util/ptr.rs b/src/gallium/frontends/rusticl/util/ptr.rs
index 2bb4f9fa6ff..f14fdec1014 100644
--- a/src/gallium/frontends/rusticl/util/ptr.rs
+++ b/src/gallium/frontends/rusticl/util/ptr.rs
@@ -95,6 +95,8 @@ impl<T> CheckedPtr<T> for *mut T {
     }
 }
 
+// While std::mem::offset_of!() is stable from 1.77.0, support for nested fields
+// (required in some rusticl cases) wasn't stabilized until 1.82.0.
 // from https://internals.rust-lang.org/t/discussion-on-offset-of/7440/2
 #[macro_export]
 macro_rules! offset_of {
@@ -115,7 +117,7 @@ macro_rules! offset_of {
     }};
 }
 
-// Adapted from libstd since std::ptr::is_aligned is still unstable
+// Adapted from libstd since std::ptr::is_aligned isn't stable until 1.79.0
 // See https://github.com/rust-lang/rust/issues/96284
 #[must_use]
 #[inline]
@@ -123,11 +125,18 @@ pub fn is_aligned<T>(ptr: *const T) -> bool
 where
     T: Sized,
 {
-    let align = mem::align_of::<T>();
+    is_aligned_to(ptr, mem::align_of::<T>())
+}
+
+// Adapted from libstd since std::ptr::is_aligned_to is still unstable
+// See https://github.com/rust-lang/rust/issues/96284
+#[must_use]
+#[inline]
+pub fn is_aligned_to<T>(ptr: *const T, align: usize) -> bool {
     addr(ptr) & (align - 1) == 0
 }
 
-// Adapted from libstd since std::ptr::addr is still unstable
+// Adapted from libstd since std::ptr::addr isn't stable until 1.84.0
 // See https://github.com/rust-lang/rust/issues/95228
 #[must_use]
 #[inline(always)]
diff --git a/src/gallium/frontends/teflon/tfl_device.c b/src/gallium/frontends/teflon/tfl_device.c
index 127c894d678..b57b2a75302 100644
--- a/src/gallium/frontends/teflon/tfl_device.c
+++ b/src/gallium/frontends/teflon/tfl_device.c
@@ -169,6 +169,8 @@ fill_operation(struct teflon_delegate *delegate, TfLiteContext *tf_context, TfLi
          operation->pad.after_x = paddings[3];
          operation->pad.before_y = paddings[4];
          operation->pad.after_y = paddings[5];
+         operation->pad.before_z = paddings[6];
+         operation->pad.after_z = paddings[7];
          break;
       }
       case kTfLiteBuiltinFullyConnected: {
@@ -182,6 +184,34 @@ fill_operation(struct teflon_delegate *delegate, TfLiteContext *tf_context, TfLi
    }
 }
 
+static bool
+all_scales_equal(const TfLiteAffineQuantization *quant)
+{
+   float scale = quant->scale->data[0];
+   int i;
+
+   for (i = 1; i < quant->scale->size; i++) {
+      if (quant->scale->data[i] != scale)
+         return false;
+   }
+
+   return true;
+}
+
+static bool
+all_zero_points_equal(const TfLiteAffineQuantization *quant)
+{
+   int zero_point = quant->zero_point->data[0];
+   int i;
+
+   for (i = 1; i < quant->zero_point->size; i++) {
+      if (quant->zero_point->data[i] != zero_point)
+         return false;
+   }
+
+   return true;
+}
+
 static void
 fill_tensor(struct teflon_delegate *delegate, TfLiteContext *tf_context, struct pipe_tensor *tensor, unsigned index)
 {
@@ -195,23 +225,39 @@ fill_tensor(struct teflon_delegate *delegate, TfLiteContext *tf_context, struct
       tensor->resource = create_resource(context, tf_tensor);
 
    tensor->index = index;
-   memcpy(tensor->dims, tf_tensor.dims->data, tf_tensor.dims->size * sizeof(*tensor->dims));
+   for (int out_dim = 0; out_dim < 4; out_dim++) {
+      int in_dim = tf_tensor.dims->size - 4 + out_dim;
+      if (in_dim >= 0)
+         tensor->dims[out_dim] = tf_tensor.dims->data[in_dim];
+      else
+         tensor->dims[out_dim] = 1;
+   }
 
    if (tf_tensor.quantization.type == kTfLiteAffineQuantization) {
       const TfLiteAffineQuantization *quant = (const TfLiteAffineQuantization *)tf_tensor.quantization.params;
       tensor->scale = quant->scale->data[0];
       tensor->zero_point = quant->zero_point->data[0];
+
+      assert(quant->scale->size == quant->zero_point->size);
+      if (quant->scale->size > 1 &&
+          (!all_scales_equal(quant) || !all_zero_points_equal(quant))) {
+         tensor->scales = calloc(quant->scale->size, sizeof(*tensor->scales));
+         memcpy(tensor->scales, quant->scale->data, quant->scale->size * sizeof(*tensor->scales));
+
+         tensor->zero_points = calloc(quant->zero_point->size, sizeof(*tensor->zero_points));
+         memcpy(tensor->zero_points, quant->zero_point->data, quant->zero_point->size * sizeof(*tensor->zero_points));
+      }
    }
 
    switch(tf_tensor.type) {
-      case kTfLiteUInt8:
-      case kTfLiteUInt16:
-      case kTfLiteUInt32:
-      case kTfLiteUInt64:
-         tensor->is_signed = false;
+      case kTfLiteInt8:
+      case kTfLiteInt16:
+      case kTfLiteInt32:
+      case kTfLiteInt64:
+         tensor->is_signed = true;
          break;
       default:
-         tensor->is_signed = true;
+         tensor->is_signed = false;
    }
 }
 
@@ -323,9 +369,6 @@ partition_init(TfLiteContext *tf_context, const char *buffer, size_t length)
                                           operations,
                                           params->nodes_to_replace->size);
 
-   for (int i = 0; i < tf_context->tensors_size; i++)
-      pipe_resource_reference(&tensors[i].resource, NULL);
-
    struct teflon_subgraph *tsubgraph = calloc(1, sizeof(*tsubgraph));
    tsubgraph->base = subgraph;
 
@@ -351,6 +394,19 @@ partition_init(TfLiteContext *tf_context, const char *buffer, size_t length)
       teflon_debug("teflon: compiled graph, took %ld ms\n", (end - start));
    }
 
+   for (int i = 0; i < tf_context->tensors_size; i++) {
+      free(tensors[i].scales);
+      free(tensors[i].zero_points);
+   }
+
+   for (int i = 0; i < params->nodes_to_replace->size; i++) {
+      free(operations[i].input_tensors);
+      free(operations[i].output_tensors);
+   }
+
+   for (int i = 0; i < tf_context->tensors_size; i++)
+      pipe_resource_reference(&tensors[i].resource, NULL);
+
    return tsubgraph;
 }
 
@@ -397,10 +453,10 @@ partition_invoke(TfLiteContext *tf_context, TfLiteNode *node)
       TfLiteTensor tf_tensor = tf_context->tensors[tsubgraph->input_tensors[i]];
 
       buffers[i] = tf_tensor.data.data;
-      is_signed[i] = !(tf_tensor.type == kTfLiteUInt8 ||
-                       tf_tensor.type == kTfLiteUInt16 ||
-                       tf_tensor.type == kTfLiteUInt32 ||
-                       tf_tensor.type == kTfLiteUInt64);
+      is_signed[i] = tf_tensor.type == kTfLiteInt8 ||
+                     tf_tensor.type == kTfLiteInt16 ||
+                     tf_tensor.type == kTfLiteInt32 ||
+                     tf_tensor.type == kTfLiteInt64;
    }
    context->ml_subgraph_invoke(context, subgraph, tsubgraph->input_count, tsubgraph->input_tensors, buffers, is_signed);
    free(buffers);
@@ -412,10 +468,10 @@ partition_invoke(TfLiteContext *tf_context, TfLiteNode *node)
       TfLiteTensor tf_tensor = tf_context->tensors[tsubgraph->output_tensors[i]];
 
       buffers[i] = tf_tensor.data.data;
-      is_signed[i] = !(tf_tensor.type == kTfLiteUInt8 ||
-                       tf_tensor.type == kTfLiteUInt16 ||
-                       tf_tensor.type == kTfLiteUInt32 ||
-                       tf_tensor.type == kTfLiteUInt64);
+      is_signed[i] = tf_tensor.type == kTfLiteInt8 ||
+                     tf_tensor.type == kTfLiteInt16 ||
+                     tf_tensor.type == kTfLiteInt32 ||
+                     tf_tensor.type == kTfLiteInt64;
    }
    context->ml_subgraph_read_output(context, subgraph, tsubgraph->output_count, tsubgraph->output_tensors, buffers, is_signed);
    free(buffers);
@@ -491,6 +547,29 @@ tensor_quantization_supported(TfLiteTensor *tensor)
    return false;
 }
 
+static bool
+weight_tensor_quantization_supported(TfLiteTensor *tensor, int axis)
+{
+   if (tensor->quantization.type == kTfLiteAffineQuantization) {
+      TfLiteAffineQuantization *affine = (TfLiteAffineQuantization *)tensor->quantization.params;
+
+      return (affine->scale->size == 1 && affine->zero_point->size == 1) ||
+             affine->quantized_dimension == axis;
+   }
+   return false;
+}
+
+static bool
+bias_tensor_quantization_supported(TfLiteTensor *tensor)
+{
+   if (tensor->quantization.type == kTfLiteAffineQuantization) {
+      TfLiteAffineQuantization *affine = (TfLiteAffineQuantization *)tensor->quantization.params;
+
+      return affine->quantized_dimension == 0;
+   }
+   return false;
+}
+
 static bool
 fused_relu6_supported(TfLiteTensor *tensor)
 {
@@ -564,8 +643,8 @@ PrepareDelegate(TfLiteContext *context, TfLiteDelegate *delegate)
 
             // Dilation and per-axis quantization not yet implemented
             if (tensor_quantization_supported(input_tensor) &&
-                tensor_quantization_supported(weight_tensor) &&
-                tensor_quantization_supported(bias_tensor) &&
+                weight_tensor_quantization_supported(weight_tensor, 0) &&
+                bias_tensor_quantization_supported(bias_tensor) &&
                 tensor_quantization_supported(output_tensor) &&
                 fused_activation_supported(params->activation, output_tensor) &&
                 (registration->version < 2 ||
@@ -584,8 +663,8 @@ PrepareDelegate(TfLiteContext *context, TfLiteDelegate *delegate)
 
             // Dilation and per-axis quantization not yet implemented
             if (tensor_quantization_supported(input_tensor) &&
-                tensor_quantization_supported(weight_tensor) &&
-                tensor_quantization_supported(bias_tensor) &&
+                weight_tensor_quantization_supported(weight_tensor, 3) &&
+                bias_tensor_quantization_supported(bias_tensor) &&
                 tensor_quantization_supported(output_tensor) &&
                 fused_activation_supported(params->activation, output_tensor) &&
                 (registration->version < 2 ||
@@ -608,11 +687,6 @@ PrepareDelegate(TfLiteContext *context, TfLiteDelegate *delegate)
                 params->axis != -1)
                supported = false;
 
-            unsigned input_channels = context->tensors[node->inputs->data[0]].dims->data[3];
-            for (unsigned i = 1; i < node->inputs->size; i++)
-               if (input_channels != context->tensors[node->inputs->data[i]].dims->data[3])
-                  supported = false;
-
             break;
          }
          case kTfLiteBuiltinSplit: {
@@ -631,20 +705,36 @@ PrepareDelegate(TfLiteContext *context, TfLiteDelegate *delegate)
             break;
          }
          case kTfLiteBuiltinPad: {
-            uint32_t *padding = context->tensors[node->inputs->data[1]].data.data;
-            supported = padding[0] == 0 &&
-                        padding[1] == 0 &&
-                        padding[2] == 1 &&
-                        padding[3] == 1 &&
-                        padding[4] == 1 &&
-                        padding[5] == 1 &&
-                        padding[6] == 0 &&
-                        padding[7] == 0;
+            // Values tensor for non-zero padding not yet implemented
+            if (node->inputs->size == 2) {
+               TfLiteTensor *padding_tensor = &context->tensors[node->inputs->data[1]];
+               if (padding_tensor->type == kTfLiteInt32) {
+                  int32_t *paddings = padding_tensor->data.data;
+                  if (padding_tensor->dims->size == 2 &&
+                      padding_tensor->dims->data[0] == 4 &&
+                      padding_tensor->dims->data[1] == 2) {
+                     if (paddings[0] == 0 &&
+                         paddings[1] == 0 &&
+                         paddings[2] >= 0 && paddings[2] <= 2 &&
+                         paddings[3] >= 0 && paddings[3] <= 2 &&
+                         paddings[4] >= 0 && paddings[4] <= 2 &&
+                         paddings[5] >= 0 && paddings[5] <= 2 &&
+                         paddings[6] >= 0 && paddings[6] <= 2 &&
+                         paddings[7] >= 0 && paddings[7] <= 2) {
+                        supported = true;
+                     }
+                  }
+               }
+            }
             break;
          }
-         case kTfLiteBuiltinFullyConnected:
-            supported = true;
+         case kTfLiteBuiltinFullyConnected: {
+            TfLiteTensor *input_tensor = &context->tensors[node->inputs->data[0]];
+            supported = input_tensor->type == kTfLiteInt8 ||
+                        input_tensor->type == kTfLiteUInt8;
+            supported = input_tensor->dims->data[input_tensor->dims->size - 1] < 1280;
             break;
+         }
       }
 
       teflon_debug("%3d %7s v%-2d %-11s in:", node_index,
diff --git a/src/gallium/include/frontend/api.h b/src/gallium/include/frontend/api.h
index 1bf6ea0ced6..26712fe7180 100644
--- a/src/gallium/include/frontend/api.h
+++ b/src/gallium/include/frontend/api.h
@@ -198,7 +198,6 @@ struct st_config_options
    bool force_integer_tex_nearest;
    int reuse_gl_names;
    bool force_gl_map_buffer_synchronized;
-   bool force_gl_depth_component_type_int;
    bool transcode_etc;
    bool transcode_astc;
    bool allow_compressed_fallback;
diff --git a/src/gallium/include/pipe/p_state.h b/src/gallium/include/pipe/p_state.h
index 23a99a81a36..a1d46ea3157 100644
--- a/src/gallium/include/pipe/p_state.h
+++ b/src/gallium/include/pipe/p_state.h
@@ -1039,13 +1039,21 @@ struct pipe_tensor {
     */
    unsigned dims[4];
    /**
-    * Scale used to quantize this tensor. Only per-tensor quantization is supported.
+    * Scale used to quantize this tensor, per-tensor quantization.
     */
    float scale;
    /**
-    * Zero-point used to quantize this tensor.
+    * Scales used to quantize this tensor, per-axis quantization.
+    */
+   float *scales;
+   /**
+    * Zero-point used to quantize this tensor, per-tensor quantization.
     */
    int zero_point;
+   /**
+    * Zero-points used to quantize this tensor, per-axis quantization.
+    */
+   int *zero_points;
    /**
     * Whether the tensor contains data in INT8 or UINT8 format.
     */
@@ -1170,10 +1178,21 @@ struct pipe_ml_operation
           * Top padding.
           */
          unsigned before_y;
+
          /**
           * Bottom padding.
           */
          unsigned after_y;
+
+         /**
+          * Channel before padding.
+          */
+         unsigned before_z;
+
+         /**
+          * Channel after padding.
+          */
+         unsigned after_z;
       } pad;
 
       struct {
diff --git a/src/gallium/meson.build b/src/gallium/meson.build
index 4d06365c7ea..4928f5c8d24 100644
--- a/src/gallium/meson.build
+++ b/src/gallium/meson.build
@@ -195,15 +195,6 @@ if with_gallium_d3d12
 else
   driver_d3d12 = declare_dependency()
 endif
-if with_gallium_clover or with_tests
-  # At the moment, clover and gallium/tests are the only two consumers
-  # for pipe-loader
-  subdir('targets/pipe-loader')
-endif
-if with_gallium_clover
-  subdir('frontends/clover')
-  subdir('targets/opencl')
-endif
 if with_gallium_rusticl
   subdir('frontends/rusticl')
   subdir('targets/rusticl')
diff --git a/src/gallium/targets/opencl/mesa.icd.in b/src/gallium/targets/opencl/mesa.icd.in
deleted file mode 100644
index 1b77b4e4929..00000000000
--- a/src/gallium/targets/opencl/mesa.icd.in
+++ /dev/null
@@ -1 +0,0 @@
-lib@OPENCL_LIBNAME@.so.@OPENCL_VERSION@
diff --git a/src/gallium/targets/opencl/meson.build b/src/gallium/targets/opencl/meson.build
deleted file mode 100644
index ab2c83556a8..00000000000
--- a/src/gallium/targets/opencl/meson.build
+++ /dev/null
@@ -1,69 +0,0 @@
-# Copyright Â© 2017 Intel Corporation
-# SPDX-License-Identifier: MIT
-
-opencl_link_args = []
-opencl_link_deps = []
-opencl_version = '1'
-
-if with_ld_version_script
-  opencl_link_args += [
-    '-Wl,--version-script', join_paths(meson.current_source_dir(), 'opencl.sym')
-  ]
-  opencl_link_deps += files('opencl.sym')
-endif
-
-llvm_libdir = dep_llvm.get_variable(cmake : 'LLVM_LIBRARY_DIR', configtool: 'libdir')
-opencl_libname = with_opencl_icd ? 'MesaOpenCL' : 'OpenCL'
-
-polly_dep = null_dep
-polly_isl_dep = null_dep
-if dep_llvm.version().version_compare('>=10.0.0')
-  polly_dep = cpp.find_library('Polly', dirs : llvm_libdir, required : false)
-  polly_isl_dep = cpp.find_library('PollyISL', dirs : llvm_libdir, required : false)
-endif
-
-ocldef_in = files(opencl_libname + '.def.in')[0]
-ocldef = custom_target(
-  'ocldef.def',
-  input: ocldef_in,
-  output : 'ocldef.def',
-  command : gen_vs_module_defs_normal_command,
-)
-
-libopencl = shared_library(
-  opencl_libname,
-  [],
-  vs_module_defs : ocldef,
-  link_args : [ld_args_gc_sections, opencl_link_args],
-  link_depends : opencl_link_deps,
-  link_whole : libclover,
-  link_with : [libpipe_loader_dynamic, libgallium],
-  dependencies : [
-    idep_mesautil,
-    dep_clock, dep_dl, dep_unwind, dep_elf, dep_clang, polly_dep, polly_isl_dep, dep_version
-  ],
-  name_prefix : host_machine.system() == 'windows' ? '' : [],  # otherwise mingw will create libOpenCL-1.dll or libMesaOpenCL-1.dll
-  version : '@0@.0.0'.format(opencl_version),
-  soversion : host_machine.system() == 'windows' ? '' : opencl_version,
-  install : true,
-)
-
-if with_opencl_icd
-  _config = configuration_data()
-  _config.set('OPENCL_LIBNAME', 'MesaOpenCL')
-  _config.set('OPENCL_VERSION', opencl_version)
-  configure_file(
-    configuration : _config,
-    input : 'mesa.icd.in',
-    output : 'mesa.icd',
-    install : true,
-    install_tag : 'runtime',
-    install_dir : join_paths(get_option('sysconfdir'), 'OpenCL', 'vendors'),
-  )
-
-  # .so is hardcoded in the icd as well
-  devenv.prepend(
-    'OCL_ICD_FILENAMES',
-    meson.current_build_dir() / 'libMesaOpenCL.so.@0@'.format(opencl_version)
-  )
-endif
diff --git a/src/gallium/targets/opencl/opencl.sym b/src/gallium/targets/opencl/opencl.sym
deleted file mode 100644
index 9fcc57692b8..00000000000
--- a/src/gallium/targets/opencl/opencl.sym
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-	global:
-		cl*;
-		opencl_dri_*;
-	local:
-		*;
-};
diff --git a/src/gallium/targets/teflon/test_teflon.cpp b/src/gallium/targets/teflon/test_teflon.cpp
index 3d3ec918942..5664c2ffb91 100644
--- a/src/gallium/targets/teflon/test_teflon.cpp
+++ b/src/gallium/targets/teflon/test_teflon.cpp
@@ -5,12 +5,16 @@
 
 #include <cstdio>
 #include <fcntl.h>
+#include <sys/mman.h>
 #include <filesystem>
 #include <fstream>
 #include <gtest/gtest.h>
 #include <xtensor/xrandom.hpp>
 
 #include <iostream>
+#include <sstream>
+#include <string>
+#include <vector>
 #include "tensorflow/lite/c/c_api.h"
 #include "test_executor.h"
 
@@ -18,14 +22,9 @@
 #define TEST_DEPTHWISE        1
 #define TEST_ADD              1
 #define TEST_FULLY_CONNECTED  1
-#define TEST_MOBILENETV1      1
-#define TEST_MOBILEDET        1
-#define TEST_YOLOX            1
+#define TEST_MODELS           1
 
 #define TOLERANCE       2
-#define MODEL_TOLERANCE 8
-#define YOLOX_TOLERANCE 38
-#define QUANT_TOLERANCE 2
 
 std::vector<bool> is_signed{false}; /* TODO: Support INT8? */
 std::vector<bool> padding_same{false, true};
@@ -63,13 +62,35 @@ test_model(void *buf, size_t buf_size, std::string cache_dir, unsigned tolerance
    run_model(model, EXECUTOR_CPU, &input, &num_inputs, &cpu_output, &output_sizes, &output_types, &num_outputs, cache_dir);
    run_model(model, EXECUTOR_NPU, &input, &num_inputs, &npu_output, &output_sizes, &output_types, &num_outputs, cache_dir);
 
+   char *dump_output = getenv("TEFLON_DUMP_OUTPUT");
+   if (dump_output && atoi(dump_output) == 1) {
+      for (unsigned i = 0; i < num_outputs; i++) {
+         char name[250];
+         int fd;
+         unsigned size = output_sizes[i];
+
+         if (output_types[i] == kTfLiteFloat32)
+            size *= 4;
+
+         sprintf(name, "out-%d.bin", i);
+         fd = open(name, O_RDWR | O_CREAT | O_TRUNC, S_IRWXU);
+         write(fd, npu_output[i], size);
+         close(fd);
+
+         sprintf(name, "cpu-out-%d.bin", i);
+         fd = open(name, O_RDWR | O_CREAT | O_TRUNC, S_IRWXU);
+         write(fd, cpu_output[i], size);
+         close(fd);
+      }
+   }
+
    for (size_t i = 0; i < num_outputs; i++) {
       for (size_t j = 0; j < output_sizes[i]; j++) {
          switch (output_types[i]) {
             case kTfLiteFloat32: {
                float *cpu = ((float**)cpu_output)[i];
                float *npu = ((float**)npu_output)[i];
-               if (abs(cpu[j] - npu[j]) > tolerance) {
+               if (abs(cpu[j] - npu[j]) > tolerance / 33.0) {
                   std::cout << "CPU: ";
                   for (int k = 0; k < std::min(int(output_sizes[i]), 24); k++)
                      std::cout << std::setfill('0') << std::setw(6) << cpu[k] << " ";
@@ -83,7 +104,24 @@ test_model(void *buf, size_t buf_size, std::string cache_dir, unsigned tolerance
                }
                break;
             }
-            default: {
+            case kTfLiteInt8: {
+               int8_t *cpu = ((int8_t**)cpu_output)[i];
+               int8_t *npu = ((int8_t**)npu_output)[i];
+               if (abs(cpu[j] - npu[j]) > tolerance) {
+                  std::cout << "CPU: ";
+                  for (int k = 0; k < std::min(int(output_sizes[i]), 24); k++)
+                     std::cout << std::setfill('0') << std::setw(2) << std::hex << int(cpu[k] & 0xff) << " ";
+                  std::cout << "\n";
+                  std::cout << "NPU: ";
+                  for (int k = 0; k < std::min(int(output_sizes[i]), 24); k++)
+                     std::cout << std::setfill('0') << std::setw(2) << std::hex << int(npu[k] & 0xff) << " ";
+                  std::cout << "\n";
+
+                  FAIL() << "Output at " << j << " from the NPU (" << std::setfill('0') << std::setw(2) << std::hex << int(npu[j] & 0xff) << ") doesn't match that from the CPU (" << std::setfill('0') << std::setw(2) << std::hex << int(cpu[j] & 0xff) << ").";
+               }
+               break;
+            }
+            case kTfLiteUInt8: {
                uint8_t *cpu = ((uint8_t**)cpu_output)[i];
                uint8_t *npu = ((uint8_t**)npu_output)[i];
                if (abs(cpu[j] - npu[j]) > tolerance) {
@@ -100,6 +138,8 @@ test_model(void *buf, size_t buf_size, std::string cache_dir, unsigned tolerance
                }
                break;
             }
+            default:
+               assert(!"Unsupported data type for output tensor");
          }
       }
    }
@@ -127,15 +167,23 @@ test_model_file(std::string file_name, unsigned tolerance, bool use_cache)
 {
    std::ostringstream cache_dir;
 
-   if (use_cache)
-      cache_dir << "/var/cache/teflon_tests/" << std::filesystem::path(file_name).stem().c_str();
+   if (use_cache) {
+      auto path = std::filesystem::path(file_name);
+      cache_dir << "/var/cache/teflon_tests/";
+      cache_dir << path.parent_path().filename().string();
+      cache_dir << "_";
+      cache_dir << path.stem().string();
+   }
 
    set_seed(4);
 
-   std::ifstream model_file(file_name, std::ios::binary);
-   std::vector<uint8_t> buffer((std::istreambuf_iterator<char>(model_file)),
-                               std::istreambuf_iterator<char>());
-   test_model(buffer.data(), buffer.size(), cache_dir.str(), tolerance);
+   struct stat sb;
+   int model_fd = open(file_name.c_str(), O_RDONLY);
+   fstat(model_fd, &sb);
+   void *model_data = mmap(0, sb.st_size, PROT_READ, MAP_PRIVATE, model_fd, 0);
+   test_model(model_data, sb.st_size, cache_dir.str(), tolerance);
+   munmap(model_data, sb.st_size);
+   close(model_fd);
 }
 
 void
@@ -412,7 +460,7 @@ TEST_P(AddQuant, Op)
             false, /* is_signed */
             false, /* depthwise */
             GetParam(),
-            QUANT_TOLERANCE);
+            TOLERANCE);
 }
 
 INSTANTIATE_TEST_SUITE_P(
@@ -456,138 +504,56 @@ INSTANTIATE_TEST_SUITE_P(
 
 #endif
 
-#if TEST_MOBILENETV1
-
-class MobileNetV1 : public ::testing::Test {};
+#if TEST_MODELS
 
-class MobileNetV1Param : public testing::TestWithParam<int> {};
+class Models : public testing::TestWithParam<std::string> {};
 
-TEST(MobileNetV1, Whole)
+TEST_P(Models, Op)
 {
    std::ostringstream file_path;
+   auto test_name = GetParam();
+   test_name.replace(test_name.find("_"), 1, "/");
    assert(getenv("TEFLON_TEST_DATA"));
-   file_path << getenv("TEFLON_TEST_DATA") << "/mobilenet_v1_1.0_224_quant.tflite";
+   file_path << getenv("TEFLON_TEST_DATA") << "/models/" << test_name << ".tflite";
 
-   test_model_file(file_path.str(), MODEL_TOLERANCE, true);
+   test_model_file(file_path.str(), TOLERANCE, true);
 }
 
-TEST_P(MobileNetV1Param, Op)
+std::vector<std::string>
+get_model_files(void)
 {
-   std::ostringstream file_path;
    assert(getenv("TEFLON_TEST_DATA"));
-   file_path << getenv("TEFLON_TEST_DATA") << "/mb-" << std::setfill('0') << std::setw(3) << GetParam() << ".tflite";
-
-   test_model_file(file_path.str(), MODEL_TOLERANCE, true);
-}
-
-static inline std::string
-MobileNetV1TestCaseName(
-   const testing::TestParamInfo<int> &info)
-{
-   std::string name = "";
-   std::string param = std::to_string(info.param);
-
-   name += "mb";
-   name += std::string(3 - param.length(), '0');
-   name += param;
-
-   return name;
-}
-
-INSTANTIATE_TEST_SUITE_P(
-   , MobileNetV1Param,
-   ::testing::Range(0, 31),
-   MobileNetV1TestCaseName);
-
-#endif
-
-#if TEST_MOBILEDET
-
-class MobileDet : public ::testing::Test {};
-
-class MobileDetParam : public testing::TestWithParam<int> {};
-
-TEST(MobileDet, Whole)
-{
-   std::ostringstream file_path;
-   assert(getenv("TEFLON_TEST_DATA"));
-   file_path << getenv("TEFLON_TEST_DATA") << "/ssdlite_mobiledet_coco_qat_postprocess.tflite";
-
-   test_model_file(file_path.str(), MODEL_TOLERANCE, true);
-}
-
-TEST_P(MobileDetParam, Op)
-{
-   std::ostringstream file_path;
-   assert(getenv("TEFLON_TEST_DATA"));
-   file_path << getenv("TEFLON_TEST_DATA") << "/mobiledet-" << std::setfill('0') << std::setw(3) << GetParam() << ".tflite";
-
-   test_model_file(file_path.str(), MODEL_TOLERANCE, true);
-}
-
-static inline std::string
-MobileDetTestCaseName(
-   const testing::TestParamInfo<int> &info)
-{
-   std::string name = "";
-   std::string param = std::to_string(info.param);
-
-   name += "mobiledet";
-   name += std::string(3 - param.length(), '0');
-   name += param;
-
-   return name;
-}
-
-INSTANTIATE_TEST_SUITE_P(
-   , MobileDetParam,
-   ::testing::Range(0, 124),
-   MobileDetTestCaseName);
-
-#endif
-
-#if TEST_YOLOX
-
-class YoloX : public ::testing::Test {};
-
-class YoloXParam : public testing::TestWithParam<int> {};
-
-TEST(YoloX, Whole)
-{
-   std::ostringstream file_path;
-   assert(getenv("TEFLON_TEST_DATA"));
-   file_path << getenv("TEFLON_TEST_DATA") << "/yolox.tflite";
-
-   test_model_file(file_path.str(), YOLOX_TOLERANCE, true);
-}
+   std::stringstream dir;
+   dir << getenv("TEFLON_TEST_DATA") << "/models";
+
+   std::vector<std::string> paths;
+   std::filesystem::recursive_directory_iterator b(dir.str());
+   for (auto const& f : b) {
+      if (f.path().extension() != ".tflite")
+         continue;
+
+      std::stringstream path;
+      path << f.path().parent_path().filename().string();
+      path << "_" << f.path().stem().string();
+      paths.push_back(path.str());
+   }
 
-TEST_P(YoloXParam, Op)
-{
-   std::ostringstream file_path;
-   assert(getenv("TEFLON_TEST_DATA"));
-   file_path << getenv("TEFLON_TEST_DATA") << "/yolox-" << std::setfill('0') << std::setw(3) << GetParam() << ".tflite";
+   std::sort(paths.begin(), paths.end());
 
-   test_model_file(file_path.str(), MODEL_TOLERANCE, true);
+   return paths;
 }
 
 static inline std::string
-YoloXTestCaseName(
-   const testing::TestParamInfo<int> &info)
+ModelsTestCaseName(
+   const testing::TestParamInfo<std::string> &info)
 {
-   std::string name = "";
-   std::string param = std::to_string(info.param);
-
-   name += "yolox";
-   name += std::string(3 - param.length(), '0');
-   name += param;
-
-   return name;
+   return info.param;
 }
 
 INSTANTIATE_TEST_SUITE_P(
-   , YoloXParam,
-   ::testing::Range(0, 128),
-   YoloXTestCaseName);
+   , Models,
+   ::testing::ValuesIn(get_model_files()),
+   ModelsTestCaseName);
 
 #endif
 
@@ -626,7 +592,7 @@ main(int argc, char **argv)
 
       return 0;
    } else if (argc > 1 && !strcmp(argv[1], "run_model")) {
-      test_model_file(std::string(argv[2]), MODEL_TOLERANCE, false);
+      test_model_file(std::string(argv[2]), TOLERANCE, false);
    } else {
       testing::InitGoogleTest(&argc, argv);
       return RUN_ALL_TESTS();
diff --git a/src/gallium/targets/teflon/tests/mobiledet-000.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/000.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-000.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/000.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-001.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/001.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-001.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/001.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-002.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/002.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-002.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/002.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-003.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/003.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-003.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/003.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-004.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/004.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-004.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/004.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-005.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/005.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-005.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/005.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-006.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/006.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-006.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/006.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-007.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/007.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-007.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/007.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-008.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/008.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-008.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/008.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-009.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/009.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-009.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/009.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-010.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/010.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-010.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/010.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-011.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/011.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-011.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/011.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-012.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/012.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-012.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/012.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-013.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/013.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-013.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/013.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-014.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/014.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-014.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/014.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-015.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/015.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-015.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/015.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-016.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/016.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-016.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/016.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-017.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/017.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-017.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/017.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-018.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/018.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-018.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/018.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-019.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/019.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-019.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/019.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-020.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/020.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-020.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/020.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-021.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/021.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-021.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/021.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-022.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/022.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-022.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/022.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-023.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/023.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-023.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/023.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-024.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/024.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-024.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/024.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-025.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/025.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-025.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/025.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-026.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/026.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-026.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/026.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-027.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/027.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-027.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/027.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-028.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/028.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-028.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/028.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-029.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/029.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-029.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/029.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-030.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/030.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-030.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/030.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-031.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/031.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-031.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/031.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-032.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/032.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-032.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/032.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-033.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/033.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-033.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/033.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-034.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/034.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-034.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/034.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-035.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/035.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-035.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/035.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-036.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/036.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-036.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/036.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-037.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/037.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-037.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/037.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-038.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/038.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-038.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/038.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-039.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/039.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-039.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/039.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-040.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/040.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-040.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/040.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-041.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/041.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-041.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/041.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-042.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/042.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-042.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/042.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-043.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/043.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-043.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/043.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-044.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/044.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-044.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/044.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-045.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/045.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-045.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/045.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-046.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/046.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-046.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/046.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-047.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/047.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-047.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/047.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-048.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/048.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-048.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/048.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-049.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/049.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-049.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/049.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-050.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/050.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-050.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/050.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-051.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/051.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-051.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/051.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-052.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/052.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-052.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/052.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-053.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/053.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-053.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/053.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-054.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/054.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-054.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/054.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-055.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/055.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-055.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/055.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-056.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/056.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-056.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/056.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-057.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/057.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-057.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/057.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-058.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/058.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-058.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/058.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-059.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/059.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-059.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/059.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-060.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/060.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-060.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/060.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-061.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/061.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-061.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/061.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-062.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/062.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-062.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/062.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-063.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/063.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-063.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/063.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-064.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/064.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-064.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/064.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-065.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/065.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-065.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/065.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-066.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/066.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-066.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/066.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-067.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/067.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-067.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/067.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-068.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/068.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-068.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/068.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-069.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/069.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-069.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/069.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-070.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/070.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-070.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/070.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-071.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/071.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-071.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/071.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-072.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/072.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-072.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/072.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-073.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/073.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-073.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/073.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-074.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/074.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-074.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/074.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-075.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/075.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-075.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/075.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-076.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/076.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-076.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/076.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-077.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/077.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-077.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/077.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-078.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/078.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-078.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/078.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-079.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/079.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-079.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/079.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-080.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/080.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-080.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/080.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-081.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/081.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-081.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/081.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-082.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/082.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-082.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/082.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-083.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/083.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-083.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/083.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-084.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/084.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-084.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/084.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-085.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/085.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-085.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/085.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-086.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/086.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-086.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/086.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-087.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/087.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-087.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/087.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-088.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/088.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-088.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/088.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-089.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/089.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-089.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/089.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-090.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/090.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-090.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/090.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-091.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/091.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-091.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/091.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-092.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/092.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-092.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/092.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-093.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/093.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-093.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/093.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-094.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/094.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-094.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/094.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-095.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/095.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-095.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/095.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-096.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/096.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-096.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/096.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-097.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/097.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-097.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/097.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-098.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/098.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-098.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/098.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-099.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/099.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-099.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/099.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-100.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/100.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-100.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/100.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-101.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/101.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-101.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/101.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-102.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/102.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-102.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/102.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-103.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/103.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-103.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/103.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-104.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/104.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-104.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/104.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-105.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/105.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-105.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/105.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-106.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/106.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-106.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/106.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-107.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/107.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-107.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/107.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-108.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/108.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-108.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/108.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-109.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/109.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-109.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/109.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-110.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/110.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-110.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/110.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-111.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/111.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-111.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/111.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-112.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/112.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-112.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/112.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-113.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/113.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-113.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/113.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-114.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/114.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-114.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/114.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-115.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/115.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-115.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/115.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-116.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/116.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-116.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/116.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-117.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/117.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-117.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/117.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-118.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/118.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-118.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/118.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-119.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/119.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-119.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/119.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-120.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/120.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-120.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/120.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-121.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/121.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-121.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/121.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-122.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/122.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-122.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/122.tflite
diff --git a/src/gallium/targets/teflon/tests/mobiledet-123.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/123.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobiledet-123.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/123.tflite
diff --git a/src/gallium/targets/teflon/tests/ssdlite_mobiledet_coco_qat_postprocess.tflite b/src/gallium/targets/teflon/tests/models/mobiledet/ssdlite_mobiledet_coco_qat_postprocess.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/ssdlite_mobiledet_coco_qat_postprocess.tflite
rename to src/gallium/targets/teflon/tests/models/mobiledet/ssdlite_mobiledet_coco_qat_postprocess.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-000.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/000.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-000.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/000.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-001.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/001.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-001.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/001.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-002.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/002.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-002.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/002.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-003.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/003.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-003.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/003.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-004.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/004.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-004.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/004.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-005.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/005.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-005.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/005.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-006.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/006.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-006.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/006.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-007.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/007.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-007.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/007.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-008.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/008.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-008.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/008.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-009.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/009.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-009.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/009.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-010.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/010.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-010.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/010.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-011.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/011.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-011.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/011.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-012.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/012.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-012.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/012.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-013.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/013.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-013.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/013.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-014.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/014.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-014.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/014.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-015.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/015.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-015.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/015.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-016.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/016.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-016.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/016.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-017.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/017.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-017.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/017.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-018.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/018.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-018.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/018.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-019.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/019.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-019.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/019.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-020.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/020.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-020.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/020.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-021.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/021.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-021.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/021.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-022.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/022.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-022.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/022.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-023.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/023.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-023.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/023.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-024.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/024.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-024.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/024.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-025.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/025.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-025.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/025.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-026.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/026.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-026.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/026.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-027.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/027.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-027.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/027.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-028.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/028.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-028.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/028.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-029.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/029.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-029.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/029.tflite
diff --git a/src/gallium/targets/teflon/tests/mb-030.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/030.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mb-030.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/030.tflite
diff --git a/src/gallium/targets/teflon/tests/mobilenet_v1_1.0_224_quant.tflite b/src/gallium/targets/teflon/tests/models/mobilenetv1/mobilenet_v1_1_224_quant.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/mobilenet_v1_1.0_224_quant.tflite
rename to src/gallium/targets/teflon/tests/models/mobilenetv1/mobilenet_v1_1_224_quant.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-000.tflite b/src/gallium/targets/teflon/tests/models/yolox/000.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-000.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/000.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-001.tflite b/src/gallium/targets/teflon/tests/models/yolox/001.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-001.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/001.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-002.tflite b/src/gallium/targets/teflon/tests/models/yolox/002.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-002.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/002.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-003.tflite b/src/gallium/targets/teflon/tests/models/yolox/003.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-003.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/003.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-004.tflite b/src/gallium/targets/teflon/tests/models/yolox/004.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-004.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/004.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-005.tflite b/src/gallium/targets/teflon/tests/models/yolox/005.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-005.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/005.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-006.tflite b/src/gallium/targets/teflon/tests/models/yolox/006.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-006.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/006.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-007.tflite b/src/gallium/targets/teflon/tests/models/yolox/007.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-007.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/007.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-008.tflite b/src/gallium/targets/teflon/tests/models/yolox/008.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-008.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/008.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-009.tflite b/src/gallium/targets/teflon/tests/models/yolox/009.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-009.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/009.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-010.tflite b/src/gallium/targets/teflon/tests/models/yolox/010.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-010.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/010.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-011.tflite b/src/gallium/targets/teflon/tests/models/yolox/011.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-011.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/011.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-012.tflite b/src/gallium/targets/teflon/tests/models/yolox/012.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-012.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/012.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-013.tflite b/src/gallium/targets/teflon/tests/models/yolox/013.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-013.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/013.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-014.tflite b/src/gallium/targets/teflon/tests/models/yolox/014.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-014.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/014.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-015.tflite b/src/gallium/targets/teflon/tests/models/yolox/015.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-015.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/015.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-016.tflite b/src/gallium/targets/teflon/tests/models/yolox/016.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-016.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/016.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-017.tflite b/src/gallium/targets/teflon/tests/models/yolox/017.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-017.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/017.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-018.tflite b/src/gallium/targets/teflon/tests/models/yolox/018.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-018.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/018.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-019.tflite b/src/gallium/targets/teflon/tests/models/yolox/019.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-019.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/019.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-020.tflite b/src/gallium/targets/teflon/tests/models/yolox/020.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-020.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/020.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-021.tflite b/src/gallium/targets/teflon/tests/models/yolox/021.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-021.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/021.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-022.tflite b/src/gallium/targets/teflon/tests/models/yolox/022.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-022.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/022.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-023.tflite b/src/gallium/targets/teflon/tests/models/yolox/023.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-023.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/023.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-024.tflite b/src/gallium/targets/teflon/tests/models/yolox/024.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-024.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/024.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-025.tflite b/src/gallium/targets/teflon/tests/models/yolox/025.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-025.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/025.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-026.tflite b/src/gallium/targets/teflon/tests/models/yolox/026.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-026.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/026.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-027.tflite b/src/gallium/targets/teflon/tests/models/yolox/027.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-027.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/027.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-028.tflite b/src/gallium/targets/teflon/tests/models/yolox/028.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-028.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/028.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-029.tflite b/src/gallium/targets/teflon/tests/models/yolox/029.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-029.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/029.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-030.tflite b/src/gallium/targets/teflon/tests/models/yolox/030.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-030.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/030.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-031.tflite b/src/gallium/targets/teflon/tests/models/yolox/031.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-031.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/031.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-032.tflite b/src/gallium/targets/teflon/tests/models/yolox/032.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-032.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/032.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-033.tflite b/src/gallium/targets/teflon/tests/models/yolox/033.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-033.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/033.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-034.tflite b/src/gallium/targets/teflon/tests/models/yolox/034.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-034.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/034.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-035.tflite b/src/gallium/targets/teflon/tests/models/yolox/035.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-035.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/035.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-036.tflite b/src/gallium/targets/teflon/tests/models/yolox/036.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-036.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/036.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-037.tflite b/src/gallium/targets/teflon/tests/models/yolox/037.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-037.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/037.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-038.tflite b/src/gallium/targets/teflon/tests/models/yolox/038.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-038.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/038.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-039.tflite b/src/gallium/targets/teflon/tests/models/yolox/039.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-039.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/039.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-040.tflite b/src/gallium/targets/teflon/tests/models/yolox/040.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-040.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/040.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-041.tflite b/src/gallium/targets/teflon/tests/models/yolox/041.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-041.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/041.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-042.tflite b/src/gallium/targets/teflon/tests/models/yolox/042.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-042.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/042.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-043.tflite b/src/gallium/targets/teflon/tests/models/yolox/043.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-043.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/043.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-044.tflite b/src/gallium/targets/teflon/tests/models/yolox/044.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-044.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/044.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-045.tflite b/src/gallium/targets/teflon/tests/models/yolox/045.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-045.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/045.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-046.tflite b/src/gallium/targets/teflon/tests/models/yolox/046.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-046.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/046.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-047.tflite b/src/gallium/targets/teflon/tests/models/yolox/047.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-047.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/047.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-048.tflite b/src/gallium/targets/teflon/tests/models/yolox/048.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-048.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/048.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-049.tflite b/src/gallium/targets/teflon/tests/models/yolox/049.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-049.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/049.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-050.tflite b/src/gallium/targets/teflon/tests/models/yolox/050.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-050.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/050.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-051.tflite b/src/gallium/targets/teflon/tests/models/yolox/051.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-051.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/051.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-052.tflite b/src/gallium/targets/teflon/tests/models/yolox/052.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-052.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/052.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-053.tflite b/src/gallium/targets/teflon/tests/models/yolox/053.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-053.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/053.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-054.tflite b/src/gallium/targets/teflon/tests/models/yolox/054.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-054.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/054.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-055.tflite b/src/gallium/targets/teflon/tests/models/yolox/055.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-055.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/055.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-056.tflite b/src/gallium/targets/teflon/tests/models/yolox/056.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-056.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/056.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-057.tflite b/src/gallium/targets/teflon/tests/models/yolox/057.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-057.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/057.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-058.tflite b/src/gallium/targets/teflon/tests/models/yolox/058.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-058.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/058.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-059.tflite b/src/gallium/targets/teflon/tests/models/yolox/059.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-059.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/059.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-060.tflite b/src/gallium/targets/teflon/tests/models/yolox/060.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-060.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/060.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-061.tflite b/src/gallium/targets/teflon/tests/models/yolox/061.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-061.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/061.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-062.tflite b/src/gallium/targets/teflon/tests/models/yolox/062.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-062.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/062.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-063.tflite b/src/gallium/targets/teflon/tests/models/yolox/063.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-063.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/063.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-064.tflite b/src/gallium/targets/teflon/tests/models/yolox/064.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-064.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/064.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-065.tflite b/src/gallium/targets/teflon/tests/models/yolox/065.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-065.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/065.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-066.tflite b/src/gallium/targets/teflon/tests/models/yolox/066.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-066.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/066.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-067.tflite b/src/gallium/targets/teflon/tests/models/yolox/067.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-067.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/067.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-068.tflite b/src/gallium/targets/teflon/tests/models/yolox/068.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-068.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/068.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-069.tflite b/src/gallium/targets/teflon/tests/models/yolox/069.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-069.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/069.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-070.tflite b/src/gallium/targets/teflon/tests/models/yolox/070.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-070.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/070.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-071.tflite b/src/gallium/targets/teflon/tests/models/yolox/071.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-071.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/071.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-072.tflite b/src/gallium/targets/teflon/tests/models/yolox/072.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-072.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/072.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-073.tflite b/src/gallium/targets/teflon/tests/models/yolox/073.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-073.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/073.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-074.tflite b/src/gallium/targets/teflon/tests/models/yolox/074.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-074.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/074.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-075.tflite b/src/gallium/targets/teflon/tests/models/yolox/075.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-075.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/075.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-076.tflite b/src/gallium/targets/teflon/tests/models/yolox/076.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-076.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/076.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-077.tflite b/src/gallium/targets/teflon/tests/models/yolox/077.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-077.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/077.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-078.tflite b/src/gallium/targets/teflon/tests/models/yolox/078.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-078.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/078.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-079.tflite b/src/gallium/targets/teflon/tests/models/yolox/079.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-079.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/079.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-080.tflite b/src/gallium/targets/teflon/tests/models/yolox/080.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-080.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/080.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-081.tflite b/src/gallium/targets/teflon/tests/models/yolox/081.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-081.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/081.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-082.tflite b/src/gallium/targets/teflon/tests/models/yolox/082.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-082.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/082.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-083.tflite b/src/gallium/targets/teflon/tests/models/yolox/083.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-083.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/083.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-084.tflite b/src/gallium/targets/teflon/tests/models/yolox/084.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-084.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/084.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-085.tflite b/src/gallium/targets/teflon/tests/models/yolox/085.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-085.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/085.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-086.tflite b/src/gallium/targets/teflon/tests/models/yolox/086.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-086.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/086.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-087.tflite b/src/gallium/targets/teflon/tests/models/yolox/087.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-087.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/087.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-088.tflite b/src/gallium/targets/teflon/tests/models/yolox/088.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-088.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/088.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-089.tflite b/src/gallium/targets/teflon/tests/models/yolox/089.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-089.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/089.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-090.tflite b/src/gallium/targets/teflon/tests/models/yolox/090.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-090.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/090.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-091.tflite b/src/gallium/targets/teflon/tests/models/yolox/091.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-091.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/091.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-092.tflite b/src/gallium/targets/teflon/tests/models/yolox/092.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-092.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/092.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-093.tflite b/src/gallium/targets/teflon/tests/models/yolox/093.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-093.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/093.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-094.tflite b/src/gallium/targets/teflon/tests/models/yolox/094.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-094.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/094.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-095.tflite b/src/gallium/targets/teflon/tests/models/yolox/095.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-095.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/095.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-096.tflite b/src/gallium/targets/teflon/tests/models/yolox/096.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-096.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/096.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-097.tflite b/src/gallium/targets/teflon/tests/models/yolox/097.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-097.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/097.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-098.tflite b/src/gallium/targets/teflon/tests/models/yolox/098.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-098.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/098.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-099.tflite b/src/gallium/targets/teflon/tests/models/yolox/099.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-099.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/099.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-100.tflite b/src/gallium/targets/teflon/tests/models/yolox/100.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-100.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/100.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-101.tflite b/src/gallium/targets/teflon/tests/models/yolox/101.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-101.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/101.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-102.tflite b/src/gallium/targets/teflon/tests/models/yolox/102.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-102.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/102.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-103.tflite b/src/gallium/targets/teflon/tests/models/yolox/103.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-103.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/103.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-104.tflite b/src/gallium/targets/teflon/tests/models/yolox/104.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-104.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/104.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-105.tflite b/src/gallium/targets/teflon/tests/models/yolox/105.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-105.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/105.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-106.tflite b/src/gallium/targets/teflon/tests/models/yolox/106.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-106.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/106.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-107.tflite b/src/gallium/targets/teflon/tests/models/yolox/107.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-107.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/107.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-108.tflite b/src/gallium/targets/teflon/tests/models/yolox/108.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-108.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/108.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-109.tflite b/src/gallium/targets/teflon/tests/models/yolox/109.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-109.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/109.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-110.tflite b/src/gallium/targets/teflon/tests/models/yolox/110.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-110.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/110.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-111.tflite b/src/gallium/targets/teflon/tests/models/yolox/111.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-111.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/111.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-112.tflite b/src/gallium/targets/teflon/tests/models/yolox/112.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-112.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/112.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-113.tflite b/src/gallium/targets/teflon/tests/models/yolox/113.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-113.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/113.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-114.tflite b/src/gallium/targets/teflon/tests/models/yolox/114.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-114.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/114.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-115.tflite b/src/gallium/targets/teflon/tests/models/yolox/115.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-115.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/115.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-116.tflite b/src/gallium/targets/teflon/tests/models/yolox/116.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-116.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/116.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-117.tflite b/src/gallium/targets/teflon/tests/models/yolox/117.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-117.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/117.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-118.tflite b/src/gallium/targets/teflon/tests/models/yolox/118.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-118.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/118.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-119.tflite b/src/gallium/targets/teflon/tests/models/yolox/119.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-119.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/119.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-120.tflite b/src/gallium/targets/teflon/tests/models/yolox/120.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-120.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/120.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-121.tflite b/src/gallium/targets/teflon/tests/models/yolox/121.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-121.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/121.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-122.tflite b/src/gallium/targets/teflon/tests/models/yolox/122.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-122.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/122.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-123.tflite b/src/gallium/targets/teflon/tests/models/yolox/123.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-123.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/123.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-124.tflite b/src/gallium/targets/teflon/tests/models/yolox/124.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-124.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/124.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-125.tflite b/src/gallium/targets/teflon/tests/models/yolox/125.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-125.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/125.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-126.tflite b/src/gallium/targets/teflon/tests/models/yolox/126.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-126.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/126.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox-127.tflite b/src/gallium/targets/teflon/tests/models/yolox/127.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox-127.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/127.tflite
diff --git a/src/gallium/targets/teflon/tests/yolox.tflite b/src/gallium/targets/teflon/tests/models/yolox/yolox.tflite
similarity index 100%
rename from src/gallium/targets/teflon/tests/yolox.tflite
rename to src/gallium/targets/teflon/tests/models/yolox/yolox.tflite
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_bo.c b/src/gallium/winsys/amdgpu/drm/amdgpu_bo.c
index dfefc468bca..1f606b4e286 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_bo.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_bo.c
@@ -180,7 +180,7 @@ static int amdgpu_bo_va_op_common(struct amdgpu_winsys *aws, struct amdgpu_winsy
 {
    int r;
 
-   if (aws->info.use_userq) {
+   if (aws->info.userq_ip_mask) {
       uint32_t syncobj_arr[AMDGPU_MAX_QUEUES + 1];
       uint32_t num_fences = 0;
 
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
index 40884772c9a..6b4f2b38489 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
@@ -978,8 +978,7 @@ amdgpu_cs_create(struct radeon_cmdbuf *rcs,
    if (!amdgpu_get_new_ib(ctx->aws, rcs, &acs->main_ib, acs))
       goto fail;
 
-   /* Currently only gfx, compute and sdma queues supports user queue. */
-   if (acs->aws->info.use_userq && ip_type <= AMD_IP_SDMA) {
+   if (acs->aws->info.userq_ip_mask & BITFIELD_BIT(acs->ip_type)) {
       if (!amdgpu_userq_init(acs->aws, &acs->aws->queues[acs->queue_index].userq, ip_type))
          goto fail;
    }
@@ -1202,7 +1201,8 @@ static void amdgpu_cs_add_fence_dependency(struct radeon_cmdbuf *rcs,
    util_queue_fence_wait(&fence->submitted);
 
    if (!fence->imported) {
-      if (!aws->info.use_userq || fence->ip_type != acs->ip_type || acs->ip_type > AMD_IP_SDMA) {
+      if (!(aws->info.userq_ip_mask & BITFIELD_BIT(acs->ip_type)) ||
+          fence->ip_type != acs->ip_type) {
          /* Ignore idle fences. This will only check the user fence in memory. */
          if (!amdgpu_fence_wait((struct pipe_fence_handle *)fence, 0, false)) {
             add_seq_no_to_list(acs->aws, &csc->seq_no_dependencies, fence->queue_index,
@@ -1495,6 +1495,7 @@ static int amdgpu_cs_submit_ib_userq(struct amdgpu_userq *userq,
 
    struct drm_amdgpu_userq_fence_info *fence_info;
    struct drm_amdgpu_userq_wait userq_wait_data = {
+      .waitq_id = userq->userq_handle,
       .syncobj_handles = (uintptr_t)syncobj_dependencies_list,
       .syncobj_timeline_handles = (uintptr_t)&syncobj_timeline_dependency,
       .syncobj_timeline_points = (uintptr_t)&syncobj_timeline_dependency_point,
@@ -2162,8 +2163,7 @@ static int amdgpu_cs_flush(struct radeon_cmdbuf *rcs,
       csc_current = amdgpu_csc_get_current(acs);
       struct amdgpu_cs_context *csc_submitted = amdgpu_csc_get_submitted(acs);
 
-      /* only gfx, compute and sdma queues are supported in userqueues. */
-      if (aws->info.use_userq && acs->ip_type <= AMD_IP_SDMA) {
+      if (aws->info.userq_ip_mask & BITFIELD_BIT(acs->ip_type)) {
          util_queue_add_job(&aws->cs_queue, acs, &acs->flush_completed,
                             amdgpu_cs_submit_ib<USERQ>, NULL, 0);
       } else {
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c b/src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c
index 433ffaa0f1b..f5a7f5ed9dd 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c
@@ -36,7 +36,7 @@ static bool do_winsys_init(struct amdgpu_winsys *aws,
                            const struct pipe_screen_config *config,
                            int fd)
 {
-   if (ac_query_gpu_info(fd, aws->dev, &aws->info, false) != AC_QUERY_GPU_INFO_SUCCESS)
+   if (!ac_query_gpu_info(fd, aws->dev, &aws->info, false))
       goto fail;
 
    aws->addrlib = ac_addrlib_create(&aws->info, &aws->info.max_alignment);
@@ -56,13 +56,12 @@ static bool do_winsys_init(struct amdgpu_winsys *aws,
                       strstr(debug_get_option("AMD_DEBUG", ""), "sqtt") != NULL;
    aws->zero_all_vram_allocs = strstr(debug_get_option("R600_DEBUG", ""), "zerovram") != NULL ||
                               driQueryOptionb(config->options, "radeonsi_zerovram");
-   aws->info.use_userq = debug_get_bool_option("AMD_USERQ", false);
 
    for (unsigned i = 0; i < ARRAY_SIZE(aws->queues); i++)
       simple_mtx_init(&aws->queues[i].userq.lock, mtx_plain);
 
    /* TODO: Enable this once the kernel handles it efficiently. */
-   if (!aws->info.use_userq)
+   if (!aws->info.userq_ip_mask)
       aws->info.has_local_buffers = false;
 
    return true;
diff --git a/src/glx/glxext.c b/src/glx/glxext.c
index e80d383cfa1..9682ca1f8a3 100644
--- a/src/glx/glxext.c
+++ b/src/glx/glxext.c
@@ -1060,22 +1060,6 @@ __glXInitialize(Display * dpy)
 #ifdef GLX_USE_WINDOWSGL
    if (glx_direct && glx_accel)
       glx_driver |= GLX_DRIVER_WINDOWS;
-#else
-#ifndef RTLD_NOW
-#define RTLD_NOW 0
-#endif
-#ifndef RTLD_GLOBAL
-#define RTLD_GLOBAL 0
-#endif
-
-#ifndef GL_LIB_NAME
-#define GL_LIB_NAME "libGL.so.1"
-#endif
-
-   void *glhandle = dlopen(GL_LIB_NAME, RTLD_NOW | RTLD_GLOBAL);
-   if (glhandle)
-      dlclose(glhandle);
-
 #endif
 #endif /* GLX_DIRECT_RENDERING && !GLX_USE_APPLEGL */
 
diff --git a/src/glx/meson.build b/src/glx/meson.build
index 7c42053401f..c3ebfb62536 100644
--- a/src/glx/meson.build
+++ b/src/glx/meson.build
@@ -115,9 +115,6 @@ libglx = static_library(
   [files_libglx, glx_generated, main_dispatch_h],
   include_directories : [inc_include, inc_src, inc_glapi, inc_loader, inc_loader_x11,
                          inc_gallium, inc_mesa, inc_st_dri, inc_gallium_aux],
-  c_args : [
-    '-DGL_LIB_NAME="lib@0@.so.@1@"'.format(gl_lib_name, gl_lib_version.split('.')[0]),
-  ],
   gnu_symbol_visibility : 'hidden',
   link_with : [
     libloader, libloader_x11,
diff --git a/src/intel/ci/gitlab-ci-inc.yml b/src/intel/ci/gitlab-ci-inc.yml
index 730f481d7c9..380a38268ea 100644
--- a/src/intel/ci/gitlab-ci-inc.yml
+++ b/src/intel/ci/gitlab-ci-inc.yml
@@ -27,7 +27,7 @@
       when: on_success
 
 .intel-common-manual-rules:
-  stage: intel-postmerge
+  stage: intel-nightly
   rules:
     - changes:
         *intel_common_file_list
@@ -51,7 +51,7 @@
       when: on_success
 
 .i915g-manual-rules:
-  stage: intel-postmerge
+  stage: intel-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -75,7 +75,7 @@
       when: on_success
 
 .crocus-manual-rules:
-  stage: intel-postmerge
+  stage: intel-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -100,7 +100,7 @@
       when: on_success
 
 .iris-manual-rules:
-  stage: intel-postmerge
+  stage: intel-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -131,7 +131,7 @@
     LAVA_S3_ARTIFACT_NAME: mesa-x86_64-default-release
     S3_ARTIFACT_NAME: mesa-python-ci-artifacts
   needs:
-    - kernel+rootfs_x86_64
+    - debian/x86_64_test-gl
     - debian-release
 
 .anv-rules:
@@ -147,7 +147,7 @@
       when: on_success
 
 .anv-manual-rules:
-  stage: intel-postmerge
+  stage: intel-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -170,7 +170,7 @@
       when: on_success
 
 .hasvk-manual-rules:
-  stage: intel-postmerge
+  stage: intel-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -190,7 +190,7 @@
     - !reference [.anv-rules, rules]
 
 .intel-manual-rules:
-  stage: intel-postmerge
+  stage: intel-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -337,8 +337,6 @@
 
 
 .intel-common-test:
-  extends:
-    - .lava-test-deqp:x86_64
   variables:
     DTB: ""
     BOOT_METHOD: depthcharge
@@ -356,6 +354,7 @@
 
 .iris-test:
   extends:
+    - .lava-x86_64-test-gl
     - .intel-common-test
     - .iris-rules
   variables:
@@ -369,7 +368,9 @@
 ## ANV only
 .anv-angle-test:
   extends:
-    - .anv-test
+    - .lava-x86_64-test-gl
+    - .intel-common-test
+    - .anv-rules
     - .test-angle
   variables:
     VK_DRIVER: intel
@@ -468,6 +469,7 @@
 ## Intel (anv + iris)
 .intel-adl-test:
   extends:
+    - .lava-x86_64-test-gl
     - .anv-test
     - .intel-test
   variables:
@@ -475,6 +477,7 @@
 
 .intel-tgl-test:
   extends:
+    - .lava-x86_64-test-gl
     - .anv-test
     - .intel-test
   variables:
@@ -482,6 +485,7 @@
 
 .intel-whl-test:
   extends:
+    - .lava-x86_64-test-gl
     - .iris-whl-test
     - .intel-test
   variables:
diff --git a/src/intel/ci/gitlab-ci.yml b/src/intel/ci/gitlab-ci.yml
index 4d6bf4b0f03..771e534aacc 100644
--- a/src/intel/ci/gitlab-ci.yml
+++ b/src/intel/ci/gitlab-ci.yml
@@ -3,13 +3,12 @@ include:
 
 anv-jsl-vk:
   extends:
+    - .lava-x86_64-test-vk
     - .anv-test
     - .lava-acer-cb317-1h-c3z6-dedede:x86_64
   variables:
     DEQP_SUITE: anv-jsl
     VK_DRIVER: intel
-    # force fixed kernel, since too many flakes and unexpected results seen with 6.13-rc4 and 6.11-rc7
-    EXTERNAL_KERNEL_TAG: "v6.6.21-mesa-f8ea"
   parallel: 5
 
 anv-jsl-vk-full:
@@ -23,6 +22,7 @@ anv-jsl-vk-full:
 
 anv-adl-vk:
   extends:
+    - .lava-x86_64-test-vk
     - .anv-test
     - .lava-acer-cbv514-1h-34uz-brya:x86_64
   variables:
@@ -42,6 +42,7 @@ anv-adl-vk-full:
 
 anv-tgl-vk:
   extends:
+    - .lava-x86_64-test-vk
     - .anv-test
     - .lava-acer-cp514-2h-1160g7-volteer:x86_64
   variables:
@@ -206,6 +207,7 @@ iris-amly-egl:
 iris-kbl-piglit:
   extends:
     - .iris-kbl-test
+    - .test-piglit
   parallel: 2
   variables:
     HWCI_START_XORG: 1
@@ -282,6 +284,7 @@ intel-adl-cl:
     - .intel-adl-test
     - .lava-acer-n20q11-r856ltn-p1s2-nissa:x86_64
     - .intel-rules
+    - .test-piglit
   rules:
     - !reference [.intel-adl-test, rules]
     - !reference [.intel-rules, rules]
diff --git a/src/intel/ci/iris-kbl-fails.txt b/src/intel/ci/iris-kbl-fails.txt
index bb82b09fad6..7069979a6f5 100644
--- a/src/intel/ci/iris-kbl-fails.txt
+++ b/src/intel/ci/iris-kbl-fails.txt
@@ -10,8 +10,8 @@ glx@glx-swap-pixmap-bad,Fail
 #   Value in failed request:  0x1e
 #   Serial number of failed request:  1177
 #   Current serial number in output stream:  1181
-glx@glx-visuals-depth -pixmap,Crash
-glx@glx-visuals-stencil -pixmap,Crash
+glx@glx-visuals-depth -pixmap,Fail
+glx@glx-visuals-stencil -pixmap,Fail
 
 spec@!opengl 1.0@rasterpos,Fail
 
diff --git a/src/intel/compiler/brw_compiler.c b/src/intel/compiler/brw_compiler.c
index 9159b5356cf..1ce6eea63e0 100644
--- a/src/intel/compiler/brw_compiler.c
+++ b/src/intel/compiler/brw_compiler.c
@@ -221,13 +221,21 @@ brw_get_compiler_config_value(const struct brw_compiler *compiler)
    insert_u64_bit(&config, compiler->mesh.mue_compaction);
    bits++;
 
-   uint64_t mask = DEBUG_DISK_CACHE_MASK;
-   bits += util_bitcount64(mask);
-
-   u_foreach_bit64(bit, mask)
-      insert_u64_bit(&config, INTEL_DEBUG(1ULL << bit));
+   enum intel_debug_flag debug_bits[] = {
+      DEBUG_NO_DUAL_OBJECT_GS,
+      DEBUG_SPILL_FS,
+      DEBUG_SPILL_VEC4,
+      DEBUG_NO_COMPACTION,
+      DEBUG_DO32,
+      DEBUG_SOFT64,
+      DEBUG_NO_SEND_GATHER,
+   };
+   for (uint32_t i = 0; i < ARRAY_SIZE(debug_bits); i++) {
+      insert_u64_bit(&config, INTEL_DEBUG(debug_bits[i]));
+      bits++;
+   }
 
-   mask = SIMD_DISK_CACHE_MASK;
+   uint64_t mask = SIMD_DISK_CACHE_MASK;
    bits += util_bitcount64(mask);
 
    u_foreach_bit64(bit, mask)
diff --git a/src/intel/compiler/brw_from_nir.cpp b/src/intel/compiler/brw_from_nir.cpp
index 4a9fd0b3289..9cd4ffa1efd 100644
--- a/src/intel/compiler/brw_from_nir.cpp
+++ b/src/intel/compiler/brw_from_nir.cpp
@@ -1842,6 +1842,31 @@ brw_from_nir_emit_alu(nir_to_brw_state &ntb, nir_alu_instr *instr,
       break;
    }
 
+   /* BFloat16 values in NIR are represented by uint16_t,
+    * but BRW can handle them natively.
+    */
+
+   case nir_op_bf2f:
+      bld.MOV(result, retype(op[0], BRW_TYPE_BF));
+      break;
+
+   case nir_op_f2bf:
+      bld.MOV(retype(result, BRW_TYPE_BF), op[0]);
+      break;
+
+   case nir_op_bfmul:
+      bld.MUL(retype(result, BRW_TYPE_BF),
+              retype(op[0], BRW_TYPE_BF),
+              retype(op[1], BRW_TYPE_BF));
+      break;
+
+   case nir_op_bffma:
+      bld.MAD(retype(result, BRW_TYPE_BF),
+              retype(op[2], BRW_TYPE_BF),
+              retype(op[1], BRW_TYPE_BF),
+              retype(op[0], BRW_TYPE_BF));
+      break;
+
    default:
       unreachable("unhandled instruction");
    }
@@ -4054,8 +4079,8 @@ emit_samplemaskin_setup(nir_to_brw_state &ntb)
    if (ntb.system_values[SYSTEM_VALUE_SAMPLE_ID].file == BAD_FILE)
       ntb.system_values[SYSTEM_VALUE_SAMPLE_ID] = emit_sampleid_setup(ntb);
 
-   brw_reg one = abld.MOV(brw_imm_ud(1));
-   brw_reg enabled_mask = abld.SHL(one, ntb.system_values[SYSTEM_VALUE_SAMPLE_ID]);
+   brw_reg enabled_mask =
+      abld.SHL(brw_imm_ud(1), ntb.system_values[SYSTEM_VALUE_SAMPLE_ID]);
    brw_reg mask = abld.AND(enabled_mask, coverage_mask);
 
    if (wm_prog_data->persample_dispatch == INTEL_ALWAYS)
@@ -4693,9 +4718,9 @@ brw_from_nir_emit_cs_intrinsic(nir_to_brw_state &ntb,
       const unsigned rcount = nir_intrinsic_repeat_count(instr);
 
       const brw_reg_type dest_type =
-         brw_type_for_nir_type(devinfo, nir_intrinsic_dest_type(instr));
+         brw_type_for_base_type(nir_intrinsic_dest_base_type(instr));
       const brw_reg_type src_type =
-         brw_type_for_nir_type(devinfo, nir_intrinsic_src_type(instr));
+         brw_type_for_base_type(nir_intrinsic_src_base_type(instr));
 
       brw_reg src[3] = {};
       for (unsigned i = 0; i < ARRAY_SIZE(src); i++) {
diff --git a/src/intel/compiler/brw_inst.cpp b/src/intel/compiler/brw_inst.cpp
index 1b5480d7f53..4422b3d7f8d 100644
--- a/src/intel/compiler/brw_inst.cpp
+++ b/src/intel/compiler/brw_inst.cpp
@@ -1082,7 +1082,7 @@ has_dst_aligned_region_restriction(const intel_device_info *devinfo,
        (brw_type_size_bytes(exec_type) == 4 && is_dword_multiply))
       return intel_device_info_is_9lp(devinfo) || devinfo->verx10 >= 125;
 
-   else if (brw_type_is_float(dst_type))
+   else if (brw_type_is_float_or_bfloat(dst_type))
       return devinfo->verx10 >= 125;
 
    else
diff --git a/src/intel/compiler/brw_inst.h b/src/intel/compiler/brw_inst.h
index d81c770f1a9..10aff1917c9 100644
--- a/src/intel/compiler/brw_inst.h
+++ b/src/intel/compiler/brw_inst.h
@@ -345,6 +345,20 @@ is_unordered(const intel_device_info *devinfo, const brw_inst *inst)
             inst->dst.type == BRW_TYPE_DF));
 }
 
+static inline bool
+has_bfloat_operands(const brw_inst *inst)
+{
+   if (brw_type_is_bfloat(inst->dst.type))
+      return true;
+
+   for (int i = 0; i < inst->sources; i++) {
+      if (brw_type_is_bfloat(inst->src[i].type))
+         return true;
+   }
+
+   return false;
+}
+
 bool has_dst_aligned_region_restriction(const intel_device_info *devinfo,
                                         const brw_inst *inst,
                                         brw_reg_type dst_type);
diff --git a/src/intel/compiler/brw_lower.cpp b/src/intel/compiler/brw_lower.cpp
index baa126c65b0..81f1ac6119d 100644
--- a/src/intel/compiler/brw_lower.cpp
+++ b/src/intel/compiler/brw_lower.cpp
@@ -591,6 +591,46 @@ unsupported_64bit_type(const intel_device_info *devinfo,
                                        type == BRW_TYPE_Q));
 }
 
+bool
+brw_lower_bfloat_conversion(brw_shader &s, brw_inst *inst)
+{
+   assert(s.devinfo->has_bfloat16);
+   assert(inst->dst.type == BRW_TYPE_BF || inst->src[0].type == BRW_TYPE_BF);
+
+   if (inst->dst.type == inst->src[0].type) {
+      /* Except for DPAS, instructions with only bfloat operands are
+       * not supported, so just move the bits using UW.
+       */
+      inst->dst    = retype(inst->dst, BRW_TYPE_UW);
+      inst->src[0] = retype(inst->src[0], BRW_TYPE_UW);
+      return true;
+
+   } else if (inst->dst.type == BRW_TYPE_BF &&
+              byte_stride(inst->dst) == 2) {
+      /* Converting to packed BF is not supported natively.  Using
+       * ADD with -0.0f preserves NaN correctly.  Note +0.0f would
+       * not work since it doesn't preserve -0.0f!
+       */
+      assert(inst->src[0].type == BRW_TYPE_F);
+      inst->resize_sources(2);
+      inst->opcode = BRW_OPCODE_ADD;
+      inst->src[1] = brw_imm_f(-0.0f);
+      return true;
+
+   } else if (inst->dst.type == BRW_TYPE_F &&
+              byte_stride(inst->src[0]) != 2) {
+      /* Converting from a unpacked BF is not supported natively. */
+      const brw_builder ibld(inst);
+      ibld.SHL(retype(inst->dst, BRW_TYPE_UD),
+               retype(inst->src[0], BRW_TYPE_UW),
+               brw_imm_uw(16));
+      inst->remove();
+      return true;
+   }
+
+   return false;
+}
+
 /**
  * Perform lowering to legalize the IR for various ALU restrictions.
  *
@@ -626,7 +666,38 @@ brw_lower_alu_restrictions(brw_shader &s)
             inst->remove();
             progress = true;
          }
+
+         if (inst->dst.type == BRW_TYPE_BF || inst->src[0].type == BRW_TYPE_BF)
+            progress |= brw_lower_bfloat_conversion(s, inst);
+
+         break;
+
+      case BRW_OPCODE_MUL:
+      case BRW_OPCODE_MAD: {
+         /* BFloat16 restrictions:
+          *
+          *   "Bfloat16 not in Src1 of 2-source instructions involving
+          *    multiplier."
+          *
+          * and
+          *
+          *   "Bfloat16 not allowed in Src2 of 3-source instructions
+          *   involving multiplier."
+          */
+         brw_reg &last_src = inst->src[inst->sources - 1];
+         if (last_src.type == BRW_TYPE_BF) {
+            assert(devinfo->has_bfloat16);
+            const brw_builder ibld = brw_builder(inst);
+
+            brw_reg src2_as_f = ibld.vgrf(BRW_TYPE_F);
+            brw_inst *conv = ibld.MOV(src2_as_f, last_src);
+            brw_lower_bfloat_conversion(s, conv);
+            last_src = src2_as_f;
+
+            progress = true;
+         }
          break;
+      }
 
       case BRW_OPCODE_SEL:
          if (unsupported_64bit_type(devinfo, inst->dst.type)) {
@@ -662,8 +733,8 @@ brw_lower_alu_restrictions(brw_shader &s)
    }
 
    if (progress) {
-      s.invalidate_analysis(BRW_DEPENDENCY_INSTRUCTION_DATA_FLOW |
-                            BRW_DEPENDENCY_INSTRUCTION_IDENTITY);
+      s.invalidate_analysis(BRW_DEPENDENCY_INSTRUCTIONS |
+                            BRW_DEPENDENCY_VARIABLES);
    }
 
    return progress;
@@ -958,3 +1029,4 @@ brw_lower_indirect_mov(brw_shader &s)
 
    return progress;
 }
+
diff --git a/src/intel/compiler/brw_lower_regioning.cpp b/src/intel/compiler/brw_lower_regioning.cpp
index e0e7ebee5bd..f2418f948be 100644
--- a/src/intel/compiler/brw_lower_regioning.cpp
+++ b/src/intel/compiler/brw_lower_regioning.cpp
@@ -52,7 +52,10 @@ namespace {
    required_src_byte_stride(const intel_device_info *devinfo, const brw_inst *inst,
                             unsigned i)
    {
-      if (has_dst_aligned_region_restriction(devinfo, inst)) {
+      if (devinfo->has_bfloat16 && has_bfloat_operands(inst)) {
+         return brw_type_size_bytes(inst->src[i].type);
+
+      } else if (has_dst_aligned_region_restriction(devinfo, inst)) {
          return MAX2(brw_type_size_bytes(inst->dst.type),
                      byte_stride(inst->dst));
 
@@ -143,7 +146,7 @@ namespace {
     * that requires it to have some particular alignment.
     */
    unsigned
-   required_dst_byte_stride(const brw_inst *inst)
+   required_dst_byte_stride(const intel_device_info *devinfo, const brw_inst *inst)
    {
       if (inst->dst.is_accumulator()) {
          /* If the destination is an accumulator, insist that we leave the
@@ -159,6 +162,11 @@ namespace {
           * and fix the sources of the multiply instead of the destination.
           */
          return inst->dst.hstride * brw_type_size_bytes(inst->dst.type);
+
+      } else if (devinfo->has_bfloat16 && has_bfloat_operands(inst)) {
+         /* Prefer packed since it can be used as a source. */
+         return brw_type_size_bytes(inst->dst.type);
+
       } else if (brw_type_size_bytes(inst->dst.type) < get_exec_type_size(inst) &&
           !is_byte_raw_mov(inst)) {
          return get_exec_type_size(inst);
@@ -201,6 +209,8 @@ namespace {
    unsigned
    required_dst_byte_offset(const intel_device_info *devinfo, const brw_inst *inst)
    {
+      assert(!brw_type_is_bfloat(inst->dst.type));
+
       for (unsigned i = 0; i < inst->sources; i++) {
          if (!is_uniform(inst->src[i]) && !inst->is_control_source(i))
             if (reg_offset(inst->src[i]) % (reg_unit(devinfo) * REG_SIZE) !=
@@ -314,6 +324,25 @@ namespace {
       const unsigned dst_byte_offset = reg_offset(inst->dst) % (reg_unit(devinfo) * REG_SIZE);
       const unsigned src_byte_offset = reg_offset(inst->src[i]) % (reg_unit(devinfo) * REG_SIZE);
 
+      if (devinfo->has_bfloat16 && has_bfloat_operands(inst)) {
+         if (brw_type_is_bfloat(inst->src[i].type)) {
+            const unsigned half_register = REG_SIZE * reg_unit(devinfo) / 2;
+            const unsigned offset = reg_offset(inst->src[i]);
+
+            /* Region restrictions described by PRM
+             *
+             *   Bfloat16 source must be packed.
+             *
+             *   Bfloat16 source must have register offset 0 or half of GRF register.
+             */
+            return !(byte_stride(inst->src[i]) == 2 && (offset == 0 || offset == half_register));
+         } else {
+            assert(inst->src[i].type == BRW_TYPE_F);
+            /* Restrict Floats sources mixed with BFloats to also be aligned and packed. */
+            return !is_uniform(inst->src[i]) && src_byte_offset != 0 && byte_stride(inst->src[i]) != 4;
+         }
+      }
+
       return (has_dst_aligned_region_restriction(devinfo, inst) &&
               !is_uniform(inst->src[i]) &&
               (byte_stride(inst->src[i]) != required_src_byte_stride(devinfo, inst, i) ||
@@ -333,6 +362,29 @@ namespace {
    {
       if (is_send(inst)) {
          return false;
+
+      } else if (devinfo->has_bfloat16 && has_bfloat_operands(inst)) {
+         const unsigned stride = byte_stride(inst->dst);
+         const unsigned offset = reg_offset(inst->dst);
+         const unsigned half_register = REG_SIZE * reg_unit(devinfo) / 2;
+
+         /* Region restrictions described by PRM
+          *
+          *   Packed bfloat16 destination must have register offset of 0 or half of GRF register.
+          *
+          *   Unpacked bfloat16 destination must have stride 2 and register offset 0 or 1.
+          *
+          * Note numbers above are in terms of elements (2 bytes).
+          */
+         if (inst->dst.type == BRW_TYPE_BF) {
+            return !(stride == 2 && (offset == 0 || offset == half_register)) &&
+                   !(stride == 4 && (offset == 0 || offset == 2));
+         } else {
+            assert(inst->dst.type == BRW_TYPE_F);
+            /* Restrict Floats sources mixed with BFloats to also be aligned and packed. */
+            return !(stride == 4 && offset == 0);
+         }
+
       } else {
          const brw_reg_type exec_type = get_exec_type(inst);
          const unsigned dst_byte_offset = reg_offset(inst->dst) % (reg_unit(devinfo) * REG_SIZE);
@@ -340,10 +392,10 @@ namespace {
             brw_type_size_bytes(inst->dst.type) < brw_type_size_bytes(exec_type);
 
          return (has_dst_aligned_region_restriction(devinfo, inst) &&
-                 (required_dst_byte_stride(inst) != byte_stride(inst->dst) ||
+                 (required_dst_byte_stride(devinfo, inst) != byte_stride(inst->dst) ||
                   required_dst_byte_offset(devinfo, inst) != dst_byte_offset)) ||
                 (is_narrowing_conversion &&
-                 required_dst_byte_stride(inst) != byte_stride(inst->dst));
+                 required_dst_byte_stride(devinfo, inst) != byte_stride(inst->dst));
       }
    }
 
@@ -615,7 +667,7 @@ namespace {
              brw_type_is_float(inst->dst.type));
 
       const brw_builder ibld(inst);
-      const unsigned stride = required_dst_byte_stride(inst) /
+      const unsigned stride = required_dst_byte_stride(v->devinfo, inst) /
                               brw_type_size_bytes(inst->dst.type);
       assert(stride > 0);
       brw_reg tmp = ibld.vgrf(inst->dst.type, stride);
diff --git a/src/intel/compiler/brw_lower_simd_width.cpp b/src/intel/compiler/brw_lower_simd_width.cpp
index 2404ad09453..28e57ec43fa 100644
--- a/src/intel/compiler/brw_lower_simd_width.cpp
+++ b/src/intel/compiler/brw_lower_simd_width.cpp
@@ -110,6 +110,9 @@ get_fpu_lowered_simd_width(const brw_shader *shader,
    if (inst->is_3src(compiler) && !devinfo->supports_simd16_3src)
       max_width = MIN2(max_width, inst->exec_size / reg_count);
 
+   if (has_bfloat_operands(inst))
+      max_width = MIN2(max_width, devinfo->ver < 20 ? 8 : 16);
+
    if (inst->opcode != BRW_OPCODE_MOV) {
       /* From the SKL PRM, Special Restrictions for Handling Mixed Mode
        * Float Operations:
diff --git a/src/intel/compiler/brw_nir.c b/src/intel/compiler/brw_nir.c
index 0ce844ea783..c51269f9f41 100644
--- a/src/intel/compiler/brw_nir.c
+++ b/src/intel/compiler/brw_nir.c
@@ -41,6 +41,7 @@ type_size_xvec4(const struct glsl_type *type, bool as_vec4, bool bindless)
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
    case GLSL_TYPE_BOOL:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_UINT16:
@@ -2252,6 +2253,28 @@ lsc_op_for_nir_intrinsic(const nir_intrinsic_instr *intrin)
    }
 }
 
+enum brw_reg_type
+brw_type_for_base_type(enum glsl_base_type base_type)
+{
+   switch (base_type) {
+   case GLSL_TYPE_UINT:      return BRW_TYPE_UD;
+   case GLSL_TYPE_INT:       return BRW_TYPE_D;
+   case GLSL_TYPE_FLOAT:     return BRW_TYPE_F;
+   case GLSL_TYPE_FLOAT16:   return BRW_TYPE_HF;
+   case GLSL_TYPE_BFLOAT16:  return BRW_TYPE_BF;
+   case GLSL_TYPE_DOUBLE:    return BRW_TYPE_DF;
+   case GLSL_TYPE_UINT16:    return BRW_TYPE_UW;
+   case GLSL_TYPE_INT16:     return BRW_TYPE_W;
+   case GLSL_TYPE_UINT8:     return BRW_TYPE_UB;
+   case GLSL_TYPE_INT8:      return BRW_TYPE_B;
+   case GLSL_TYPE_UINT64:    return BRW_TYPE_UQ;
+   case GLSL_TYPE_INT64:     return BRW_TYPE_Q;
+
+   default:
+      unreachable("invalid base type");
+   }
+}
+
 enum brw_reg_type
 brw_type_for_nir_type(const struct intel_device_info *devinfo,
                       nir_alu_type type)
diff --git a/src/intel/compiler/brw_nir.h b/src/intel/compiler/brw_nir.h
index d520b14a7e7..3e6f57ccd99 100644
--- a/src/intel/compiler/brw_nir.h
+++ b/src/intel/compiler/brw_nir.h
@@ -154,13 +154,6 @@ brw_nir_fs_needs_null_rt(const struct intel_device_info *devinfo,
    if (devinfo->ver < 11)
       return true;
 
-   /* Depth/Stencil needs a valid render target even if there is no color
-    * output.
-    */
-   if (nir->info.outputs_written & (BITFIELD_BIT(FRAG_RESULT_DEPTH) |
-                                    BITFIELD_BIT(FRAG_RESULT_STENCIL)))
-      return true;
-
    uint64_t relevant_outputs = 0;
    if (multisample_fbo)
       relevant_outputs |= BITFIELD64_BIT(FRAG_RESULT_SAMPLE_MASK);
@@ -249,6 +242,7 @@ unsigned brw_nir_api_subgroup_size(const nir_shader *nir,
 
 enum brw_conditional_mod brw_cmod_for_nir_comparison(nir_op op);
 enum lsc_opcode lsc_op_for_nir_intrinsic(const nir_intrinsic_instr *intrin);
+enum brw_reg_type brw_type_for_base_type(enum glsl_base_type base_type);
 enum brw_reg_type brw_type_for_nir_type(const struct intel_device_info *devinfo,
                                         nir_alu_type type);
 
diff --git a/src/intel/compiler/brw_nir_lower_cooperative_matrix.c b/src/intel/compiler/brw_nir_lower_cooperative_matrix.c
index 659904387e1..8969a1f048f 100644
--- a/src/intel/compiler/brw_nir_lower_cooperative_matrix.c
+++ b/src/intel/compiler/brw_nir_lower_cooperative_matrix.c
@@ -50,33 +50,71 @@
 
 #include "brw_nir.h"
 
+typedef struct {
+   /* Vector type that holds the elements packed. */
+   const glsl_type *type;
+
+   /* How many cmat elements per slice element. */
+   unsigned packing_factor;
+
+   struct glsl_cmat_description desc;
+
+   /* Used by the tables.  Variable holding a slice or
+    * arrays-of-arrays of slices.
+    *
+    * If present, the var->type (without arrays!) should match
+    * the type above.
+    */
+   nir_variable *var;
+} slice_info;
+
+#define BRW_MAX_PACKING_FACTOR 4
+
 struct lower_cmat_state {
+   void *temp_ctx;
+
    nir_shader *shader;
 
-   struct hash_table *slice_coop_types;
+   struct hash_table *slice_var_to_slice_info;
 
-   struct hash_table *vars_to_slice;
+   struct hash_table *mat_var_to_slice_info;
 
    unsigned subgroup_size;
+
+   struct {
+      nir_def *tmp[NIR_MAX_VEC_COMPONENTS * BRW_MAX_PACKING_FACTOR];
+   } scratch;
 };
 
+static bool
+cmat_descriptions_are_equal(struct glsl_cmat_description a,
+                            struct glsl_cmat_description b)
+{
+   return a.element_type == b.element_type &&
+          a.scope == b.scope &&
+          a.rows == b.rows &&
+          a.cols == b.cols &&
+          a.use == b.use;
+}
+
 static void
 print_coop_types(struct lower_cmat_state *state)
 {
    fprintf(stderr, "--- Slices to Cooperative Matrix type table\n");
-   hash_table_foreach(state->slice_coop_types, e) {
+   hash_table_foreach(state->slice_var_to_slice_info, e) {
       nir_variable *var = (void *)e->key;
-      const struct glsl_type *t = e->data;
-      fprintf(stderr, "%p: %s -> %s\n", var, var->name, glsl_get_type_name(t));
+      const slice_info *info = e->data;
+      fprintf(stderr, "%p: %s -> %s\n", var, var->name,
+              glsl_get_type_name(glsl_cmat_type(&info->desc)));
    }
    fprintf(stderr, "\n\n");
 }
 
-static const struct glsl_type *
-get_coop_type_for_slice(struct lower_cmat_state *state, nir_deref_instr *deref)
+static const slice_info *
+get_slice_info(struct lower_cmat_state *state, nir_deref_instr *deref)
 {
    nir_variable *var = nir_deref_instr_get_variable(deref);
-   struct hash_entry *entry = _mesa_hash_table_search(state->slice_coop_types, var);
+   struct hash_entry *entry = _mesa_hash_table_search(state->slice_var_to_slice_info, var);
 
    assert(entry != NULL);
 
@@ -101,6 +139,7 @@ lower_cmat_filter(const nir_instr *instr, const void *_state)
    case nir_intrinsic_cmat_store:
    case nir_intrinsic_cmat_length:
    case nir_intrinsic_cmat_muladd:
+   case nir_intrinsic_cmat_convert:
    case nir_intrinsic_cmat_unary_op:
    case nir_intrinsic_cmat_binary_op:
    case nir_intrinsic_cmat_scalar_op:
@@ -115,26 +154,10 @@ lower_cmat_filter(const nir_instr *instr, const void *_state)
    }
 }
 
-/**
- * Get number of matrix elements packed in each component of the slice.
- */
-static unsigned
-get_packing_factor(const struct glsl_cmat_description desc,
-                   const struct glsl_type *slice_type)
-{
-   const struct glsl_type *slice_element_type = glsl_without_array(slice_type);
-
-   assert(!glsl_type_is_cmat(slice_type));
-
-   assert(glsl_get_bit_size(slice_element_type) >= glsl_base_type_get_bit_size(desc.element_type));
-   assert(glsl_get_bit_size(slice_element_type) % glsl_base_type_get_bit_size(desc.element_type) == 0);
-
-   return glsl_get_bit_size(slice_element_type) / glsl_base_type_get_bit_size(desc.element_type);
-}
-
-static const struct glsl_type *
-get_slice_type_from_desc(const struct lower_cmat_state *state,
-                         const struct glsl_cmat_description desc)
+static void
+init_slice_info(struct lower_cmat_state *state,
+                struct glsl_cmat_description desc,
+                slice_info *info)
 {
    enum glsl_base_type base_type;
 
@@ -154,6 +177,7 @@ get_slice_type_from_desc(const struct lower_cmat_state *state,
     * matrix of uint8_t data must pack 4 values in each entry.
     */
    const unsigned packing_factor = element_bits / bits;
+   assert(packing_factor <= BRW_MAX_PACKING_FACTOR);
 
    assert(elements_per_invocation >= packing_factor);
 
@@ -163,6 +187,7 @@ get_slice_type_from_desc(const struct lower_cmat_state *state,
       break;
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
    case GLSL_TYPE_UINT8:
    case GLSL_TYPE_UINT16:
       base_type = GLSL_TYPE_UINT;
@@ -194,36 +219,9 @@ get_slice_type_from_desc(const struct lower_cmat_state *state,
 
    const struct glsl_type *slice_type = glsl_vector_type(base_type, len);
 
-   assert(packing_factor == get_packing_factor(desc, slice_type));
-
-   return slice_type;
-}
-
-static const struct glsl_type *
-get_slice_type(const struct lower_cmat_state *state,
-               const struct glsl_type *type)
-{
-   if (glsl_type_is_array(type)) {
-      const struct glsl_type *slice_type =
-         get_slice_type(state, glsl_get_array_element(type));
-
-      return glsl_array_type(slice_type, glsl_array_size(type), 0);
-   }
-
-   assert(glsl_type_is_cmat(type));
-
-   return get_slice_type_from_desc(state,
-                                   *glsl_get_cmat_description(type));
-}
-
-static nir_deref_instr *
-create_local_slice(struct lower_cmat_state *state, nir_builder *b,
-                   const struct glsl_type *mat_type, const char *name)
-{
-   const struct glsl_type *slice_type = get_slice_type(state, mat_type);
-   nir_variable *slice_var = nir_local_variable_create(b->impl, slice_type, name);
-   _mesa_hash_table_insert(state->slice_coop_types, slice_var, (void *)mat_type);
-   return nir_build_deref_var(b, slice_var);
+   info->type = slice_type;
+   info->desc = desc;
+   info->packing_factor = packing_factor;
 }
 
 static void
@@ -235,12 +233,11 @@ lower_cmat_load_store(nir_builder *b, nir_intrinsic_instr *intrin,
    const unsigned ptr_src = load ? 1 : 0;
 
    nir_deref_instr *slice = nir_src_as_deref(intrin->src[mat_src]);
-   const struct glsl_type *mat_type = get_coop_type_for_slice(state, slice);
-   const struct glsl_cmat_description *desc = glsl_get_cmat_description(mat_type);
+   const slice_info *info = get_slice_info(state, slice);
+   const struct glsl_cmat_description desc = info->desc;
 
    nir_def *results[NIR_MAX_VEC_COMPONENTS];
    const unsigned num_components = glsl_get_vector_elements(slice->type);
-   const unsigned packing_factor = get_packing_factor(*desc, slice->type);
 
    nir_deref_instr *pointer = nir_src_as_deref(intrin->src[ptr_src]);
    const unsigned ptr_comp_width = glsl_get_bit_size(pointer->type);
@@ -254,14 +251,14 @@ lower_cmat_load_store(nir_builder *b, nir_intrinsic_instr *intrin,
                                   nir_imul_imm(b,
                                                intrin->src[2].ssa,
                                                ptr_comp_width * ptr_num_comps),
-                                  glsl_base_type_get_bit_size(desc->element_type));
+                                  glsl_base_type_get_bit_size(desc.element_type));
 
    /* The data that will be packed is in successive columns for A and
     * accumulator matrices. The data that will be packed for B matrices is in
     * successive rows.
     */
    const unsigned cols =
-      desc->use != GLSL_CMAT_USE_B ? desc->cols / packing_factor : desc->cols;
+      desc.use != GLSL_CMAT_USE_B ? desc.cols / info->packing_factor : desc.cols;
 
    nir_def *invocation = nir_load_subgroup_invocation(b);
    nir_def *invocation_div_cols = nir_udiv_imm(b, invocation, cols);
@@ -271,14 +268,14 @@ lower_cmat_load_store(nir_builder *b, nir_intrinsic_instr *intrin,
 
    const bool memory_layout_matches_register_layout =
       (nir_intrinsic_matrix_layout(intrin) == GLSL_MATRIX_LAYOUT_ROW_MAJOR) ==
-      (desc->use != GLSL_CMAT_USE_B);
+      (desc.use != GLSL_CMAT_USE_B);
 
    if (memory_layout_matches_register_layout) {
       /* In the row-major arrangement, data is loaded a dword at a time
        * instead of a single element at a time. For this reason the stride is
        * divided by the packing factor.
        */
-      i_stride = nir_udiv_imm(b, stride, packing_factor);
+      i_stride = nir_udiv_imm(b, stride, info->packing_factor);
    } else {
       /* In the column-major arrangement, data is loaded a single element at a
        * time. Because the data elements are transposed, the step direction
@@ -289,7 +286,7 @@ lower_cmat_load_store(nir_builder *b, nir_intrinsic_instr *intrin,
        * NOTE: The unscaled stride is also still needed when stepping from one
        * packed element to the next. This occurs in the for-j loop below.
        */
-      i_stride = nir_imul_imm(b, stride, packing_factor);
+      i_stride = nir_imul_imm(b, stride, info->packing_factor);
    }
 
    nir_def *base_offset;
@@ -340,8 +337,8 @@ lower_cmat_load_store(nir_builder *b, nir_intrinsic_instr *intrin,
          }
       }
    } else {
-      const struct glsl_type *element_type = glsl_scalar_type(desc->element_type);
-      const unsigned element_bits = glsl_base_type_get_bit_size(desc->element_type);
+      const struct glsl_type *element_type = glsl_scalar_type(desc.element_type);
+      const unsigned element_bits = glsl_base_type_get_bit_size(desc.element_type);
       const unsigned element_stride = element_bits / 8;
 
       pointer = nir_build_deref_cast(b, &pointer->def, pointer->modes, element_type,
@@ -351,7 +348,7 @@ lower_cmat_load_store(nir_builder *b, nir_intrinsic_instr *intrin,
          nir_def *i_offset = nir_imul_imm(b, i_step, i);
          nir_def *v[4];
 
-         for (unsigned j = 0; j < packing_factor; j++) {
+         for (unsigned j = 0; j < info->packing_factor; j++) {
             nir_def *offset = nir_iadd(b, nir_imul_imm(b, stride, j), i_offset);
 
             nir_deref_instr *memory_deref =
@@ -375,8 +372,8 @@ lower_cmat_load_store(nir_builder *b, nir_intrinsic_instr *intrin,
          }
 
          if (load) {
-            results[i] = nir_pack_bits(b, nir_vec(b, v, packing_factor),
-                                       packing_factor * element_bits);
+            results[i] = nir_pack_bits(b, nir_vec(b, v, info->packing_factor),
+                                       info->packing_factor * element_bits);
          }
       }
    }
@@ -386,68 +383,146 @@ lower_cmat_load_store(nir_builder *b, nir_intrinsic_instr *intrin,
                       nir_component_mask(num_components));
 }
 
+/* Unpack, apply operation, then pack again. */
+static nir_def *
+emit_packed_alu1(nir_builder *b,
+                 struct lower_cmat_state *state,
+                 const slice_info *src_info,
+                 const slice_info *dst_info,
+                 nir_op op,
+                 nir_def *src)
+{
+   const unsigned dst_bits = glsl_base_type_bit_size(dst_info->desc.element_type);
+   const unsigned src_bits = glsl_base_type_bit_size(src_info->desc.element_type);
+
+   const unsigned src_components = glsl_get_vector_elements(src_info->type);
+   const unsigned dst_components = glsl_get_vector_elements(dst_info->type);
+   assert(src_components * src_info->packing_factor ==
+          dst_components * dst_info->packing_factor);
+
+   /* Store the result of all individual unpacked values. */
+   assert(src_components * src_info->packing_factor <= ARRAY_SIZE(state->scratch.tmp));
+   nir_def **tmp = state->scratch.tmp;
+
+   for (unsigned i = 0; i < src_components; i++) {
+      nir_def *chan = nir_channel(b, src, i);
+
+      for (unsigned j = 0; j < src_info->packing_factor; j++) {
+         const unsigned pos = (i * src_info->packing_factor) + j;
+         nir_def *val = nir_channel(b, nir_unpack_bits(b, chan, src_bits), j);
+         tmp[pos] = nir_build_alu1(b, op, val);
+      }
+   }
+
+   /* Store each element of the result, might pack multiple values. */
+   nir_def *results[NIR_MAX_VEC_COMPONENTS] = {};
+   assert(dst_components <= ARRAY_SIZE(results));
+
+   /* Store each packed element in destination, to be combined
+    * into results.
+    */
+   nir_def *partial[BRW_MAX_PACKING_FACTOR];
+
+   for (unsigned i = 0; i < dst_components; i++) {
+      for (unsigned j = 0; j < dst_info->packing_factor; j++) {
+         const unsigned pos = (i * dst_info->packing_factor) + j;
+         partial[j] = tmp[pos];
+      }
+
+      results[i] =
+         nir_pack_bits(b, nir_vec(b, partial, dst_info->packing_factor),
+                       dst_info->packing_factor * dst_bits);
+   }
+
+   return nir_vec(b, results, dst_components);
+}
+
+static nir_op
+get_cmat_conversion_op(enum glsl_base_type src,
+                       enum glsl_base_type dst)
+{
+   if (src == GLSL_TYPE_BFLOAT16) {
+      assert(dst == GLSL_TYPE_FLOAT);
+      return nir_op_bf2f;
+
+   } else if (dst == GLSL_TYPE_BFLOAT16) {
+      assert(src == GLSL_TYPE_FLOAT);
+      return nir_op_f2bf;
+
+   } else {
+      return nir_type_conversion_op(nir_get_nir_type_for_glsl_base_type(src),
+                                    nir_get_nir_type_for_glsl_base_type(dst),
+                                    nir_rounding_mode_undef);
+   }
+}
+
 static void
-lower_cmat_unary_op(nir_builder *b, nir_intrinsic_instr *intrin,
-                    struct lower_cmat_state *state)
+lower_cmat_convert(nir_builder *b, nir_intrinsic_instr *intrin,
+                   struct lower_cmat_state *state)
 {
    nir_deref_instr *dst_slice = nir_src_as_deref(intrin->src[0]);
    nir_deref_instr *src_slice = nir_src_as_deref(intrin->src[1]);
-   nir_def *results[NIR_MAX_VEC_COMPONENTS];
-   const unsigned num_components = glsl_get_vector_elements(dst_slice->type);
 
-   const struct glsl_type *dst_mat_type =
-      get_coop_type_for_slice(state, dst_slice);
-   const struct glsl_type *src_mat_type =
-      get_coop_type_for_slice(state, src_slice);
+   const slice_info *dst_info = get_slice_info(state, dst_slice);
+   const slice_info *src_info = get_slice_info(state, src_slice);
 
-   const struct glsl_cmat_description dst_desc =
-      *glsl_get_cmat_description(dst_mat_type);
+   const nir_cmat_signed cmat_signed_mask = nir_intrinsic_cmat_signed_mask(intrin);
 
-   const struct glsl_cmat_description src_desc =
-      *glsl_get_cmat_description(src_mat_type);
+   enum glsl_base_type src_element_type = glsl_apply_signedness_to_base_type(
+      src_info->desc.element_type, cmat_signed_mask & NIR_CMAT_A_SIGNED);
+   enum glsl_base_type dst_element_type = glsl_apply_signedness_to_base_type(
+      dst_info->desc.element_type, cmat_signed_mask & NIR_CMAT_RESULT_SIGNED);
 
-   const unsigned dst_bits = glsl_base_type_bit_size(dst_desc.element_type);
-   const unsigned src_bits = glsl_base_type_bit_size(src_desc.element_type);
+   bool needs_intermediate =
+      (src_element_type == GLSL_TYPE_BFLOAT16 && dst_element_type != GLSL_TYPE_FLOAT) ||
+      (src_element_type != GLSL_TYPE_FLOAT    && dst_element_type == GLSL_TYPE_BFLOAT16);
 
-   /* The type of the returned slice may be different from the type of the
-    * input slice.
-    */
-   const unsigned dst_packing_factor =
-      get_packing_factor(dst_desc, dst_slice->type);
+   nir_def *result;
+   nir_def *src = nir_load_deref(b, src_slice);
 
-   const unsigned src_packing_factor =
-      get_packing_factor(src_desc, src_slice->type);
+   if (needs_intermediate) {
+      /* Cooperative matrices must have the same "shape" to be converted. */
+      assert(src_info->desc.rows  == dst_info->desc.rows);
+      assert(src_info->desc.cols  == dst_info->desc.cols);
+      assert(src_info->desc.use   == dst_info->desc.use);
+      assert(src_info->desc.scope == dst_info->desc.scope);
 
-   const nir_op op = nir_intrinsic_alu_op(intrin);
+      struct glsl_cmat_description float_desc = src_info->desc;
+      float_desc.element_type = GLSL_TYPE_FLOAT;
 
-   /* With the combinations of formats exposed on all platforms, matrices with
-    * the same dimensions will always have the same data size. The only real
-    * type conversion possible is int32 <-> float32. As a result
-    * dst_packing_factor == src_packing_factor.
-    */
-   assert(dst_packing_factor == src_packing_factor);
+      slice_info float_info = {};
+      init_slice_info(state, float_desc, &float_info);
 
-   /* Stores at most dst_packing_factor partial results. */
-   nir_def *v[4];
-   assert(dst_packing_factor <= 4);
+      nir_op op1 = get_cmat_conversion_op(src_element_type, GLSL_TYPE_FLOAT);
+      nir_op op2 = get_cmat_conversion_op(GLSL_TYPE_FLOAT,  dst_element_type);
 
-   for (unsigned i = 0; i < num_components; i++) {
-      nir_def *chan = nir_channel(b, nir_load_deref(b, src_slice), i);
+      nir_def *tmp = emit_packed_alu1(b, state, src_info, &float_info, op1, src);
+      result = emit_packed_alu1(b, state, &float_info, dst_info, op2, tmp);
 
-      for (unsigned j = 0; j < dst_packing_factor; j++) {
-         nir_def *src =
-            nir_channel(b, nir_unpack_bits(b, chan, src_bits), j);
+   } else {
+      nir_op op = get_cmat_conversion_op(src_element_type, dst_element_type);
+      result = emit_packed_alu1(b, state, src_info, dst_info, op, src);
+   }
 
-         v[j] = nir_build_alu1(b, op, src);
-      }
+   nir_store_deref(b, dst_slice, result, nir_component_mask(result->num_components));
+}
 
-      results[i] =
-         nir_pack_bits(b, nir_vec(b, v, dst_packing_factor),
-                       dst_packing_factor * dst_bits);
-   }
+static void
+lower_cmat_unary_op(nir_builder *b, nir_intrinsic_instr *intrin,
+                    struct lower_cmat_state *state)
+{
+   nir_deref_instr *dst_slice = nir_src_as_deref(intrin->src[0]);
+   nir_deref_instr *src_slice = nir_src_as_deref(intrin->src[1]);
 
-   nir_store_deref(b, dst_slice, nir_vec(b, results, num_components),
-                   nir_component_mask(num_components));
+   const slice_info *dst_info = get_slice_info(state, dst_slice);
+   const slice_info *src_info = get_slice_info(state, src_slice);
+   assert(cmat_descriptions_are_equal(src_info->desc, dst_info->desc));
+
+   nir_def *result = emit_packed_alu1(b, state, src_info, dst_info,
+                                      nir_intrinsic_alu_op(intrin),
+                                      nir_load_deref(b, src_slice));
+
+   nir_store_deref(b, dst_slice, result, nir_component_mask(result->num_components));
 }
 
 static void
@@ -463,18 +538,14 @@ lower_cmat_binary_op(nir_builder *b, nir_intrinsic_instr *intrin,
    nir_def *results[NIR_MAX_VEC_COMPONENTS];
    const unsigned num_components = glsl_get_vector_elements(dst_slice->type);
 
-   const struct glsl_type *dst_mat_type = get_coop_type_for_slice(state, dst_slice);
-   ASSERTED const struct glsl_type *src_a_mat_type = get_coop_type_for_slice(state, src_a_slice);
-   ASSERTED const struct glsl_type *src_b_mat_type = get_coop_type_for_slice(state, src_b_slice);
+   const slice_info *info = get_slice_info(state, dst_slice);
+   ASSERTED const slice_info *src_a_info = get_slice_info(state, src_a_slice);
+   ASSERTED const slice_info *src_b_info = get_slice_info(state, src_b_slice);
 
-   const struct glsl_cmat_description desc =
-      *glsl_get_cmat_description(dst_mat_type);
+   assert(cmat_descriptions_are_equal(info->desc, src_a_info->desc));
+   assert(cmat_descriptions_are_equal(info->desc, src_b_info->desc));
 
-   assert(dst_mat_type == src_a_mat_type);
-   assert(dst_mat_type == src_b_mat_type);
-
-   const unsigned bits = glsl_base_type_bit_size(desc.element_type);
-   const unsigned packing_factor = get_packing_factor(desc, dst_slice->type);
+   const unsigned bits = glsl_base_type_bit_size(info->desc.element_type);
 
    for (unsigned i = 0; i < num_components; i++) {
       nir_def *val_a = nir_channel(b, src_a, i);
@@ -484,7 +555,7 @@ lower_cmat_binary_op(nir_builder *b, nir_intrinsic_instr *intrin,
          nir_pack_bits(b, nir_build_alu2(b, nir_intrinsic_alu_op(intrin),
                                          nir_unpack_bits(b, val_a, bits),
                                          nir_unpack_bits(b, val_b, bits)),
-                       packing_factor * bits);
+                       info->packing_factor * bits);
    }
 
    nir_store_deref(b, dst_slice, nir_vec(b, results, num_components),
@@ -503,15 +574,11 @@ lower_cmat_scalar_op(nir_builder *b, nir_intrinsic_instr *intrin,
    nir_def *results[NIR_MAX_VEC_COMPONENTS];
    const unsigned num_components = glsl_get_vector_elements(dst_slice->type);
 
-   ASSERTED const struct glsl_type *dst_mat_type = get_coop_type_for_slice(state, dst_slice);
-   ASSERTED const struct glsl_type *src_mat_type = get_coop_type_for_slice(state, src_slice);
-   assert(dst_mat_type == src_mat_type);
-
-   const struct glsl_cmat_description desc =
-      *glsl_get_cmat_description(dst_mat_type);
+   const slice_info *info = get_slice_info(state, dst_slice);
+   ASSERTED const slice_info *src_info = get_slice_info(state, src_slice);
+   assert(cmat_descriptions_are_equal(info->desc, src_info->desc));
 
-   const unsigned bits = glsl_base_type_bit_size(desc.element_type);
-   const unsigned packing_factor = get_packing_factor(desc, dst_slice->type);
+   const unsigned bits = glsl_base_type_bit_size(info->desc.element_type);
 
    for (unsigned i = 0; i < num_components; i++) {
       nir_def *val = nir_channel(b, src, i);
@@ -520,7 +587,7 @@ lower_cmat_scalar_op(nir_builder *b, nir_intrinsic_instr *intrin,
          nir_pack_bits(b, nir_build_alu2(b, nir_intrinsic_alu_op(intrin),
                                          nir_unpack_bits(b, val, bits),
                                          scalar),
-                       packing_factor * bits);
+                       info->packing_factor * bits);
    }
 
    nir_store_deref(b, dst_slice, nir_vec(b, results, num_components),
@@ -541,9 +608,10 @@ lower_cmat_deref(nir_builder *b, nir_deref_instr *deref,
       assert(deref->var);
       assert(glsl_type_is_cmat(glsl_without_array(deref->var->type)));
 
-      struct hash_entry *entry = _mesa_hash_table_search(state->vars_to_slice, deref->var);
+      struct hash_entry *entry = _mesa_hash_table_search(state->mat_var_to_slice_info, deref->var);
       assert(entry);
-      return nir_build_deref_var(b, (nir_variable *)entry->data);
+      const slice_info *info = entry->data;
+      return nir_build_deref_var(b, info->var);
    }
 }
 
@@ -568,14 +636,11 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
       nir_deref_instr *slice = nir_src_as_deref(intrin->src[0]);
       nir_def *src = intrin->src[1].ssa;
 
-      const struct glsl_type *mat_type = get_coop_type_for_slice(state, slice);
-      const struct glsl_cmat_description desc =
-         *glsl_get_cmat_description(mat_type);
-      const unsigned packing_factor = get_packing_factor(desc, slice->type);
+      const slice_info *info = get_slice_info(state, slice);
 
-      if (packing_factor > 1) {
-         src = nir_pack_bits(b, nir_replicate(b, src, packing_factor),
-                             packing_factor * glsl_base_type_get_bit_size(desc.element_type));
+      if (info->packing_factor > 1) {
+         src = nir_pack_bits(b, nir_replicate(b, src, info->packing_factor),
+                             info->packing_factor * glsl_base_type_get_bit_size(info->desc.element_type));
       }
 
       const unsigned num_components = glsl_get_vector_elements(slice->type);
@@ -585,6 +650,10 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
       return NIR_LOWER_INSTR_PROGRESS_REPLACE;
    }
 
+   case nir_intrinsic_cmat_convert:
+      lower_cmat_convert(b, intrin, state);
+      return NIR_LOWER_INSTR_PROGRESS_REPLACE;
+
    case nir_intrinsic_cmat_unary_op:
       lower_cmat_unary_op(b, intrin, state);
       return NIR_LOWER_INSTR_PROGRESS_REPLACE;
@@ -598,11 +667,10 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
       return NIR_LOWER_INSTR_PROGRESS_REPLACE;
 
    case nir_intrinsic_cmat_length: {
-      const struct glsl_cmat_description desc = nir_intrinsic_cmat_desc(intrin);
-      const struct glsl_type *mat_type = glsl_cmat_type(&desc);
-      const struct glsl_type *slice_type = get_slice_type(state, mat_type);
-      return nir_imm_intN_t(b, (get_packing_factor(desc, slice_type) *
-                                glsl_get_vector_elements(slice_type)), 32);
+      slice_info info = {};
+      init_slice_info(state, nir_intrinsic_cmat_desc(intrin), &info);
+      return nir_imm_intN_t(b, info.packing_factor *
+                               glsl_get_vector_elements(info.type), 32);
    }
 
    case nir_intrinsic_cmat_muladd: {
@@ -611,13 +679,9 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
       nir_deref_instr *B_slice = nir_src_as_deref(intrin->src[2]);
       nir_deref_instr *accum_slice = nir_src_as_deref(intrin->src[3]);
 
-      const struct glsl_type *dst_mat_type = get_coop_type_for_slice(state, dst_slice);
-      const struct glsl_cmat_description dst_desc = *glsl_get_cmat_description(dst_mat_type);
-
-      const struct glsl_type *src_mat_type = get_coop_type_for_slice(state, A_slice);
-      const struct glsl_cmat_description src_desc = *glsl_get_cmat_description(src_mat_type);
+      const slice_info *dst_info = get_slice_info(state, dst_slice);
+      const slice_info *src_info = get_slice_info(state, A_slice);
 
-      const unsigned packing_factor = get_packing_factor(dst_desc, dst_slice->type);
       const unsigned num_components = glsl_get_vector_elements(dst_slice->type);
 
       const nir_cmat_signed cmat_signed_mask =
@@ -630,34 +694,31 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
       assert(((cmat_signed_mask & NIR_CMAT_A_SIGNED) == 0) ==
              ((cmat_signed_mask & NIR_CMAT_RESULT_SIGNED) == 0));
 
-      nir_alu_type src_type =
-         nir_get_nir_type_for_glsl_base_type(src_desc.element_type);
-      nir_alu_type dest_type =
-         nir_get_nir_type_for_glsl_base_type(dst_desc.element_type);
+      enum glsl_base_type src_type = src_info->desc.element_type;
+      enum glsl_base_type dst_type = dst_info->desc.element_type;
 
       /* For integer types, the signedness is determined by flags on the
        * muladd instruction. The types of the sources play no role. Adjust the
        * types passed to the dpas_intel intrinsic to match.
        */
-      if (nir_alu_type_get_base_type(src_type) == nir_type_uint ||
-          nir_alu_type_get_base_type(src_type) == nir_type_int) {
+      if (glsl_base_type_is_integer(src_type)) {
          if ((cmat_signed_mask & NIR_CMAT_A_SIGNED) == 0) {
-            src_type = nir_alu_type_get_type_size(src_type) | nir_type_uint;
-            dest_type = nir_alu_type_get_type_size(dest_type) | nir_type_uint;
+            src_type = glsl_unsigned_base_type_of(src_type);
+            dst_type = glsl_unsigned_base_type_of(dst_type);
          } else {
-            src_type = nir_alu_type_get_type_size(src_type) | nir_type_int;
-            dest_type = nir_alu_type_get_type_size(dest_type) | nir_type_int;
+            src_type = glsl_signed_base_type_of(src_type);
+            dst_type = glsl_signed_base_type_of(dst_type);
          }
       }
 
       nir_def *result =
          nir_dpas_intel(b,
-                        packing_factor * glsl_base_type_get_bit_size(dst_desc.element_type),
+                        dst_info->packing_factor * glsl_base_type_get_bit_size(dst_info->desc.element_type),
                         nir_load_deref(b, accum_slice),
                         nir_load_deref(b, A_slice),
                         nir_load_deref(b, B_slice),
-                        .dest_type = dest_type,
-                        .src_type = src_type,
+                        .dest_base_type = dst_type,
+                        .src_base_type = src_type,
                         .saturate = nir_intrinsic_saturate(intrin),
                         .systolic_depth = 8,
                         .repeat_count = 8);
@@ -693,23 +754,19 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
       nir_deref_instr *src_slice = nir_src_as_deref(intrin->src[2]);
       const nir_src dst_index = intrin->src[3];
 
-      const struct glsl_type *dst_mat_type = get_coop_type_for_slice(state, dst_slice);
-      ASSERTED const struct glsl_type *src_mat_type = get_coop_type_for_slice(state, src_slice);
-      assert(dst_mat_type == src_mat_type);
-
-      const struct glsl_cmat_description desc =
-         *glsl_get_cmat_description(dst_mat_type);
+      const slice_info *info = get_slice_info(state, dst_slice);
+      ASSERTED const slice_info *src_info = get_slice_info(state, src_slice);
+      assert(cmat_descriptions_are_equal(info->desc, src_info->desc));
 
-      const unsigned bits = glsl_base_type_bit_size(desc.element_type);
-      const unsigned packing_factor = get_packing_factor(desc, dst_slice->type);
+      const unsigned bits = glsl_base_type_bit_size(info->desc.element_type);
       const unsigned num_components = glsl_get_vector_elements(dst_slice->type);
 
-      nir_def *slice_index = nir_udiv_imm(b, dst_index.ssa, packing_factor);
-      nir_def *vector_index = nir_umod_imm(b, dst_index.ssa, packing_factor);
+      nir_def *slice_index = nir_udiv_imm(b, dst_index.ssa, info->packing_factor);
+      nir_def *vector_index = nir_umod_imm(b, dst_index.ssa, info->packing_factor);
       nir_def *results[NIR_MAX_VEC_COMPONENTS];
 
       const int slice_constant_index = nir_src_is_const(dst_index)
-         ? nir_src_as_uint(dst_index) / packing_factor
+         ? nir_src_as_uint(dst_index) / info->packing_factor
          : -1;
 
       for (unsigned i = 0; i < num_components; i++) {
@@ -717,13 +774,13 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
          nir_def *insert;
 
          if (slice_constant_index < 0 || slice_constant_index == i) {
-            if (packing_factor == 1) {
+            if (info->packing_factor == 1) {
                insert = scalar;
             } else {
                nir_def *unpacked = nir_unpack_bits(b, val, bits);
                nir_def *v = nir_vector_insert(b, unpacked, scalar, vector_index);
 
-               insert = nir_pack_bits(b, v, bits * packing_factor);
+               insert = nir_pack_bits(b, v, bits * info->packing_factor);
             }
          } else {
             insert = val;
@@ -742,25 +799,21 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
 
    case nir_intrinsic_cmat_extract: {
       nir_deref_instr *slice = nir_src_as_deref(intrin->src[0]);
-      const struct glsl_type *mat_type = get_coop_type_for_slice(state, slice);
+      const slice_info *info = get_slice_info(state, slice);
       nir_def *index = intrin->src[1].ssa;
 
-      const struct glsl_cmat_description desc =
-         *glsl_get_cmat_description(mat_type);
-
-      const unsigned bits = glsl_base_type_bit_size(desc.element_type);
-      const unsigned packing_factor = get_packing_factor(desc, slice->type);
+      const unsigned bits = glsl_base_type_bit_size(info->desc.element_type);
 
       nir_def *src =
          nir_vector_extract(b, nir_load_deref(b, slice),
-                            nir_udiv_imm(b, index, packing_factor));
+                            nir_udiv_imm(b, index, info->packing_factor));
 
-      if (packing_factor == 1) {
+      if (info->packing_factor == 1) {
          return src;
       } else {
          return nir_vector_extract(b,
                                    nir_unpack_bits(b, src, bits),
-                                   nir_umod_imm(b, index, packing_factor));
+                                   nir_umod_imm(b, index, info->packing_factor));
       }
 
       return NIR_LOWER_INSTR_PROGRESS_REPLACE;
@@ -771,25 +824,40 @@ lower_cmat_instr(nir_builder *b, nir_instr *instr, void *_state)
    }
 }
 
+static const glsl_type *
+make_aoa_slice_type(const glsl_type *t, const glsl_type *slice_type)
+{
+   if (glsl_type_is_array(t)) {
+      const glsl_type *s = make_aoa_slice_type(glsl_get_array_element(t), slice_type);
+      return glsl_array_type(s, glsl_array_size(t), 0);
+   }
+
+   assert(glsl_type_is_cmat(t));
+   return slice_type;
+}
+
 static void
 create_slice_var(struct lower_cmat_state *state, nir_variable *var,
                  nir_function_impl *impl)
 {
-   // TODO: without array
    const struct glsl_type *mat_type = glsl_without_array(var->type);
 
    assert(glsl_type_is_cmat(mat_type));
    assert((!impl && var->data.mode == nir_var_shader_temp) ||
           ( impl && var->data.mode == nir_var_function_temp));
 
-   const struct glsl_type *slice_type = get_slice_type(state, var->type);
+   slice_info *info = rzalloc(state->temp_ctx, slice_info);
+   init_slice_info(state, *glsl_get_cmat_description(mat_type), info);
+
+   const glsl_type *aoa_slice_type = make_aoa_slice_type(var->type, info->type);
+
    const char *slice_name = ralloc_asprintf(state->shader, "%s_slice", var->name);
-   nir_variable *slice_var = impl ?
-      nir_local_variable_create(impl, slice_type, slice_name) :
-      nir_variable_create(state->shader, var->data.mode, slice_type, slice_name);
+   info->var = impl ?
+      nir_local_variable_create(impl, aoa_slice_type, slice_name) :
+      nir_variable_create(state->shader, var->data.mode, aoa_slice_type, slice_name);
 
-   _mesa_hash_table_insert(state->vars_to_slice, var, slice_var);
-   _mesa_hash_table_insert(state->slice_coop_types, slice_var, (void *)mat_type);
+   _mesa_hash_table_insert(state->mat_var_to_slice_info, var, info);
+   _mesa_hash_table_insert(state->slice_var_to_slice_info, info->var, info);
 }
 
 bool
@@ -798,9 +866,10 @@ brw_nir_lower_cmat(nir_shader *shader, unsigned subgroup_size)
    void *temp_ctx = ralloc_context(NULL);
 
    struct lower_cmat_state state = {
+      .temp_ctx = temp_ctx,
       .shader = shader,
-      .slice_coop_types = _mesa_pointer_hash_table_create(temp_ctx),
-      .vars_to_slice = _mesa_pointer_hash_table_create(temp_ctx),
+      .slice_var_to_slice_info = _mesa_pointer_hash_table_create(temp_ctx),
+      .mat_var_to_slice_info = _mesa_pointer_hash_table_create(temp_ctx),
       .subgroup_size = subgroup_size,
    };
 
diff --git a/src/intel/compiler/brw_nir_lower_intersection_shader.c b/src/intel/compiler/brw_nir_lower_intersection_shader.c
index c3e035140bf..3e576796881 100644
--- a/src/intel/compiler/brw_nir_lower_intersection_shader.c
+++ b/src/intel/compiler/brw_nir_lower_intersection_shader.c
@@ -200,10 +200,11 @@ brw_nir_lower_intersection_shader(nir_shader *intersection,
                nir_def *min_t = nir_load_ray_t_min(b);
 
                struct brw_nir_rt_mem_ray_defs ray_def;
-               brw_nir_rt_load_mem_ray(b, &ray_def, BRW_RT_BVH_LEVEL_WORLD);
+               brw_nir_rt_load_mem_ray(b, &ray_def, BRW_RT_BVH_LEVEL_WORLD,
+                                       devinfo);
 
                struct brw_nir_rt_mem_hit_defs hit_in = {};
-               brw_nir_rt_load_mem_hit(b, &hit_in, false);
+               brw_nir_rt_load_mem_hit(b, &hit_in, false, devinfo);
 
                nir_def *max_t = ray_def.t_far;
 
@@ -241,9 +242,37 @@ brw_nir_lower_intersection_shader(nir_shader *intersection,
                         brw_nir_rt_mem_ray_addr(b, brw_nir_rt_stack_addr(b), BRW_RT_BVH_LEVEL_WORLD);
 
                      nir_store_global(b, nir_iadd_imm(b, ray_addr, 16 + 12), 4,  hit_t, 0x1);
-                     nir_store_global(b, t_addr, 4,
-                                      nir_vec2(b, nir_fmin(b, hit_t, hit_in.t), hit_kind),
-                                      0x3);
+                     if (devinfo->ver >= 30) {
+                        /* For Xe3+, the most significant 8 bits of the second
+                         * DW in the potential hit are used to store
+                         * hitGroupIndex0, which will later be used by HW to
+                         * reconstruct the whole hitGroupIndex while issuing a
+                         * TRACE_RAY_COMMIT. So we can't corrupt the data
+                         * stored here. We can still use the lower 24bits to
+                         * store aabb_hit_kind tho.
+                         */
+                        nir_def *potential_hit_dword_1 =
+                           brw_nir_rt_load(b, nir_iadd_imm(b, t_addr, 4), 4, 1, 32);
+                        nir_def *hit_group_index_0 =
+                           nir_iand_imm(b, potential_hit_dword_1, 0xff000000);
+
+                        /* Chop off hit_kind and make it only 24bits. This
+                         * prevents the hit_group_index_0 to be corrupted, but
+                         * also implies the application shouldn't pass a
+                         * gl_HitKindEXT that uses more than 24bits.
+                         */
+                        nir_def *hit_kind_24b = nir_iand_imm(b, hit_kind, 0xffffff);
+                        nir_store_global(b, t_addr, 4,
+                                         nir_vec2(b,
+                                                  nir_fmin(b, hit_t, hit_in.t),
+                                                  nir_ior(b, hit_group_index_0, hit_kind_24b)),
+                                         0x3);
+
+                     } else {
+                        nir_store_global(b, t_addr, 4,
+                                         nir_vec2(b, nir_fmin(b, hit_t, hit_in.t), hit_kind),
+                                         0x3);
+                     }
 
                      /* There may be multiple reportIntersection() calls in
                       * the shader, so if terminateOnFirstHit was requested,
diff --git a/src/intel/compiler/brw_nir_lower_ray_queries.c b/src/intel/compiler/brw_nir_lower_ray_queries.c
index 5ca3aec2588..a45100d59b9 100644
--- a/src/intel/compiler/brw_nir_lower_ray_queries.c
+++ b/src/intel/compiler/brw_nir_lower_ray_queries.c
@@ -271,7 +271,8 @@ lower_ray_query_intrinsic(nir_builder *b,
          brw_nir_rt_mem_ray_addr(b, stack_addr, BRW_RT_BVH_LEVEL_WORLD);
 
       brw_nir_rt_query_mark_init(b, stack_addr);
-      brw_nir_rt_store_mem_ray_query_at_addr(b, ray_addr, &ray_defs);
+      brw_nir_rt_store_mem_ray_query_at_addr(b, ray_addr, &ray_defs,
+                                             state->devinfo);
 
       update_trace_ctrl_level(b, ctrl_level_deref,
                               NULL, NULL,
@@ -282,7 +283,7 @@ lower_ray_query_intrinsic(nir_builder *b,
 
    case nir_intrinsic_rq_proceed: {
       nir_def *not_done =
-         nir_inot(b, brw_nir_rt_query_done(b, stack_addr));
+         nir_inot(b, brw_nir_rt_query_done(b, stack_addr, state->devinfo));
       nir_def *not_done_then, *not_done_else;
 
       nir_push_if(b, not_done);
@@ -307,7 +308,8 @@ lower_ray_query_intrinsic(nir_builder *b,
          nir_trace_ray_intel(b, state->rq_globals, level, ctrl, .synchronous = true);
 
          struct brw_nir_rt_mem_hit_defs hit_in = {};
-         brw_nir_rt_load_mem_hit_from_addr(b, &hit_in, hw_stack_addr, false);
+         brw_nir_rt_load_mem_hit_from_addr(b, &hit_in, hw_stack_addr, false,
+                                           state->devinfo);
 
          if (shadow_stack_addr)
             spill_query(b, hw_stack_addr, shadow_stack_addr);
@@ -362,10 +364,13 @@ lower_ray_query_intrinsic(nir_builder *b,
       struct brw_nir_rt_mem_ray_defs object_ray_in = {};
       struct brw_nir_rt_mem_hit_defs hit_in = {};
       brw_nir_rt_load_mem_ray_from_addr(b, &world_ray_in, stack_addr,
-                                        BRW_RT_BVH_LEVEL_WORLD);
+                                        BRW_RT_BVH_LEVEL_WORLD,
+                                        state->devinfo);
       brw_nir_rt_load_mem_ray_from_addr(b, &object_ray_in, stack_addr,
-                                        BRW_RT_BVH_LEVEL_OBJECT);
-      brw_nir_rt_load_mem_hit_from_addr(b, &hit_in, stack_addr, committed);
+                                        BRW_RT_BVH_LEVEL_OBJECT,
+                                        state->devinfo);
+      brw_nir_rt_load_mem_hit_from_addr(b, &hit_in, stack_addr, committed,
+                                        state->devinfo);
 
       nir_def *sysval = NULL;
       switch (nir_intrinsic_ray_query_value(intrin)) {
@@ -398,21 +403,24 @@ lower_ray_query_intrinsic(nir_builder *b,
 
       case nir_ray_query_value_intersection_instance_custom_index: {
          struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr,
+                                           state->devinfo);
          sysval = leaf.instance_id;
          break;
       }
 
       case nir_ray_query_value_intersection_instance_id: {
          struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr,
+                                           state->devinfo);
          sysval = leaf.instance_index;
          break;
       }
 
       case nir_ray_query_value_intersection_instance_sbt_index: {
          struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr,
+                                           state->devinfo);
          sysval = leaf.contribution_to_hit_group_index;
          break;
       }
@@ -430,7 +438,8 @@ lower_ray_query_intrinsic(nir_builder *b,
          break;
 
       case nir_ray_query_value_intersection_barycentrics:
-         sysval = hit_in.tri_bary;
+         sysval = brw_nir_rt_load_tri_bary_from_addr(b, stack_addr, committed,
+                                                     state->devinfo);
          break;
 
       case nir_ray_query_value_intersection_front_face:
@@ -447,14 +456,16 @@ lower_ray_query_intrinsic(nir_builder *b,
 
       case nir_ray_query_value_intersection_object_to_world: {
          struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr,
+                                           state->devinfo);
          sysval = leaf.object_to_world[nir_intrinsic_column(intrin)];
          break;
       }
 
       case nir_ray_query_value_intersection_world_to_object: {
          struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+         brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr,
+                                           state->devinfo);
          sysval = leaf.world_to_object[nir_intrinsic_column(intrin)];
          break;
       }
@@ -508,7 +519,8 @@ lower_ray_query_impl(nir_function_impl *impl, struct lowering_state *state)
 
    state->rq_globals = nir_load_ray_query_global_intel(b);
 
-   brw_nir_rt_load_globals_addr(b, &state->globals, state->rq_globals);
+   brw_nir_rt_load_globals_addr(b, &state->globals, state->rq_globals,
+                                state->devinfo);
 
    nir_foreach_block_safe(block, impl) {
       nir_foreach_instr_safe(instr, block) {
diff --git a/src/intel/compiler/brw_nir_lower_rt_intrinsics.c b/src/intel/compiler/brw_nir_lower_rt_intrinsics.c
index 5194862ef71..b6c25867dc4 100644
--- a/src/intel/compiler/brw_nir_lower_rt_intrinsics.c
+++ b/src/intel/compiler/brw_nir_lower_rt_intrinsics.c
@@ -73,7 +73,7 @@ lower_rt_intrinsics_impl(nir_function_impl *impl,
    nir_builder *b = &build;
 
    struct brw_nir_rt_globals_defs globals;
-   brw_nir_rt_load_globals(b, &globals);
+   brw_nir_rt_load_globals(b, &globals, devinfo);
 
    nir_def *hotzone_addr = brw_nir_rt_sw_hotzone_addr(b, devinfo);
    nir_def *hotzone = nir_load_global(b, hotzone_addr, 16, 4, 32);
@@ -87,14 +87,14 @@ lower_rt_intrinsics_impl(nir_function_impl *impl,
    case MESA_SHADER_CLOSEST_HIT:
    case MESA_SHADER_INTERSECTION:
       brw_nir_rt_load_mem_hit(b, &hit_in,
-                              stage == MESA_SHADER_CLOSEST_HIT);
+                              stage == MESA_SHADER_CLOSEST_HIT, devinfo);
       brw_nir_rt_load_mem_ray(b, &object_ray_in,
-                              BRW_RT_BVH_LEVEL_OBJECT);
+                              BRW_RT_BVH_LEVEL_OBJECT, devinfo);
       FALLTHROUGH;
 
    case MESA_SHADER_MISS:
       brw_nir_rt_load_mem_ray(b, &world_ray_in,
-                              BRW_RT_BVH_LEVEL_WORLD);
+                              BRW_RT_BVH_LEVEL_WORLD, devinfo);
       break;
 
    default:
@@ -190,7 +190,8 @@ lower_rt_intrinsics_impl(nir_function_impl *impl,
          case nir_intrinsic_load_ray_object_origin:
             if (stage == MESA_SHADER_CLOSEST_HIT) {
                struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-               brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+               brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr,
+                                                 devinfo);
 
                sysval = nir_build_vec3_mat_mult_col_major(
                   b, world_ray_in.orig, leaf.world_to_object, true);
@@ -202,7 +203,8 @@ lower_rt_intrinsics_impl(nir_function_impl *impl,
          case nir_intrinsic_load_ray_object_direction:
             if (stage == MESA_SHADER_CLOSEST_HIT) {
                struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-               brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+               brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr,
+                                                 devinfo);
 
                sysval = nir_build_vec3_mat_mult_col_major(
                   b, world_ray_in.dir, leaf.world_to_object, false);
@@ -231,21 +233,21 @@ lower_rt_intrinsics_impl(nir_function_impl *impl,
 
          case nir_intrinsic_load_instance_id: {
             struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-            brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+            brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr, devinfo);
             sysval = leaf.instance_index;
             break;
          }
 
          case nir_intrinsic_load_ray_object_to_world: {
             struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-            brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+            brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr, devinfo);
             sysval = leaf.object_to_world[nir_intrinsic_column(intrin)];
             break;
          }
 
          case nir_intrinsic_load_ray_world_to_object: {
             struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-            brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+            brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr, devinfo);
             sysval = leaf.world_to_object[nir_intrinsic_column(intrin)];
             break;
          }
@@ -286,7 +288,7 @@ lower_rt_intrinsics_impl(nir_function_impl *impl,
 
          case nir_intrinsic_load_ray_instance_custom_index: {
             struct brw_nir_rt_bvh_instance_leaf_defs leaf;
-            brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr);
+            brw_nir_rt_load_bvh_instance_leaf(b, &leaf, hit_in.inst_leaf_ptr, devinfo);
             sysval = leaf.instance_id;
             break;
          }
diff --git a/src/intel/compiler/brw_nir_lower_rt_intrinsics_pre_trace.c b/src/intel/compiler/brw_nir_lower_rt_intrinsics_pre_trace.c
deleted file mode 100644
index 84771ed8935..00000000000
--- a/src/intel/compiler/brw_nir_lower_rt_intrinsics_pre_trace.c
+++ /dev/null
@@ -1,111 +0,0 @@
-/* Copyright Â© 2025 Intel Corporation
- * SPDX-License-Identifier: MIT
- */
-
-#include "brw_nir_rt.h"
-
-static bool
-add_intrinsics_to_set(nir_builder *b,
-                      nir_intrinsic_instr *intrin,
-                      void *data)
-{
-   switch (intrin->intrinsic) {
-   case nir_intrinsic_load_ray_world_origin:
-   case nir_intrinsic_load_ray_world_direction:
-   case nir_intrinsic_load_ray_object_origin:
-   case nir_intrinsic_load_ray_object_direction:
-   case nir_intrinsic_load_ray_t_min:
-   case nir_intrinsic_load_ray_t_max:
-   case nir_intrinsic_load_ray_object_to_world:
-   case nir_intrinsic_load_ray_flags: {
-      struct set *intrinsics = data;
-      _mesa_set_add(intrinsics, intrin);
-      return false;
-   }
-
-   default:
-      return false;
-   }
-}
-
-/** Move some RT intrinsics pre shader calls
- *
- * Some RT intrinsics are implemented by reading the ray structure in memory.
- * This structure is written just before triggering a tracing call. Those
- * intrinsics should be considered as input values to the shader (kind of like
- * thread payload in legacy stages).
- *
- * If the values are read after a bindless shader call, we need to move the
- * read from memory prior to the call because called shaders could overwrite
- * the memory location if they trigger another tracing call.
- *
- * Call this pass before nir_lower_shader_calls().
- */
-bool
-brw_nir_lower_rt_intrinsics_pre_trace(nir_shader *nir)
-{
-   /* According to spec, only those stages can do a recursing traceRayEXT().
-    */
-   if (nir->info.stage != MESA_SHADER_CLOSEST_HIT &&
-       nir->info.stage != MESA_SHADER_MISS)
-      return false;
-
-   /* Find all the intrinsics we might need to move */
-   struct set *intrinsics = _mesa_set_create(NULL,
-                                             _mesa_hash_pointer,
-                                             _mesa_key_pointer_equal);
-
-   nir_shader_intrinsics_pass(nir,
-                              add_intrinsics_to_set,
-                              nir_metadata_all,
-                              intrinsics);
-
-   bool progress = false;
-
-   if (intrinsics->entries > 0) {
-      nir_foreach_function_with_impl(func, impl, nir) {
-         nir_metadata_require(impl, nir_metadata_dominance);
-
-         /* Going in reverse order of blocks, move the intrinsics gather above
-          * in the LCA block to trace calls.
-          */
-         nir_foreach_block_reverse(block, impl) {
-            nir_foreach_instr_reverse_safe(instr, block) {
-               if (instr->type != nir_instr_type_intrinsic)
-                  continue;
-
-               nir_intrinsic_instr *trace = nir_instr_as_intrinsic(instr);
-               if (trace->intrinsic != nir_intrinsic_trace_ray)
-                  continue;
-
-               set_foreach(intrinsics, entry) {
-                  nir_intrinsic_instr *intrin = (void *)entry->key;
-
-                  /* Coming from a different function, ignore */
-                  if (nir_cf_node_get_function(&intrin->instr.block->cf_node) != impl)
-                     continue;
-
-                  /* The trace dominates the intrinsic, move it before */
-                  nir_block *move_block = nir_dominance_lca(trace->instr.block,
-                                                            intrin->instr.block);
-                  if (move_block == trace->instr.block) {
-                     if (nir_instr_is_before(&trace->instr, &intrin->instr)) {
-                        nir_instr_move(nir_before_instr(&trace->instr),
-                                       &intrin->instr);
-                        progress = true;
-                     }
-                  } else {
-                     nir_instr_move(nir_before_block_after_phis(move_block),
-                                    &intrin->instr);
-                     progress = true;
-                  }
-               }
-            }
-         }
-      }
-   }
-
-   _mesa_set_destroy(intrinsics, NULL);
-
-   return progress;
-}
diff --git a/src/intel/compiler/brw_nir_lower_shader_calls.c b/src/intel/compiler/brw_nir_lower_shader_calls.c
index 3a3f6402082..84b3d2d62e7 100644
--- a/src/intel/compiler/brw_nir_lower_shader_calls.c
+++ b/src/intel/compiler/brw_nir_lower_shader_calls.c
@@ -147,7 +147,9 @@ store_resume_addr(nir_builder *b, nir_intrinsic_instr *call)
 static bool
 lower_shader_trace_ray_instr(struct nir_builder *b, nir_instr *instr, void *data)
 {
-   struct brw_bs_prog_key *key = data;
+   const struct brw_nir_lower_shader_calls_state *state = data;
+   const struct intel_device_info *devinfo = state->devinfo;
+   struct brw_bs_prog_key *key = state->key;
 
    if (instr->type != nir_instr_type_intrinsic)
       return false;
@@ -224,9 +226,6 @@ lower_shader_trace_ray_instr(struct nir_builder *b, nir_instr *instr, void *data
        */
       .ray_flags = nir_ior_imm(b, nir_u2u16(b, ray_flags), key->pipeline_ray_flags),
       .ray_mask = cull_mask,
-      .hit_group_sr_base_ptr = hit_sbt_addr,
-      .hit_group_sr_stride = nir_u2u16(b, hit_sbt_stride_B),
-      .miss_sr_ptr = miss_sbt_addr,
       .orig = ray_orig,
       .t_near = ray_t_min,
       .dir = ray_dir,
@@ -240,7 +239,17 @@ lower_shader_trace_ray_instr(struct nir_builder *b, nir_instr *instr, void *data
        */
       .inst_leaf_ptr = nir_u2u64(b, ray_flags),
    };
-   brw_nir_rt_store_mem_ray(b, &ray_defs, BRW_RT_BVH_LEVEL_WORLD);
+
+   if (devinfo->ver >= 30) {
+      ray_defs.hit_group_index = sbt_offset;
+      ray_defs.miss_shader_index = nir_u2u16(b, miss_index);
+   } else {
+      ray_defs.hit_group_sr_base_ptr = hit_sbt_addr;
+      ray_defs.hit_group_sr_stride = nir_u2u16(b, hit_sbt_stride_B);
+      ray_defs.miss_sr_ptr = miss_sbt_addr;
+   }
+
+   brw_nir_rt_store_mem_ray(b, &ray_defs, BRW_RT_BVH_LEVEL_WORLD, devinfo);
 
    nir_trace_ray_intel(b,
                        nir_load_btd_global_arg_addr_intel(b),
@@ -272,12 +281,13 @@ lower_shader_call_instr(struct nir_builder *b, nir_intrinsic_instr *call,
 }
 
 bool
-brw_nir_lower_shader_calls(nir_shader *shader, struct brw_bs_prog_key *key)
+brw_nir_lower_shader_calls(nir_shader *shader,
+                           struct brw_nir_lower_shader_calls_state *state)
 {
    bool a = nir_shader_instructions_pass(shader,
                                          lower_shader_trace_ray_instr,
                                          nir_metadata_none,
-                                         key);
+                                         state);
    bool b = nir_shader_intrinsics_pass(shader, lower_shader_call_instr,
                                          nir_metadata_control_flow,
                                          NULL);
diff --git a/src/intel/compiler/brw_nir_rt.c b/src/intel/compiler/brw_nir_rt.c
index 853a6ece8fc..7c869d19eae 100644
--- a/src/intel/compiler/brw_nir_rt.c
+++ b/src/intel/compiler/brw_nir_rt.c
@@ -55,7 +55,7 @@ resize_deref(nir_builder *b, nir_deref_instr *deref,
 }
 
 static bool
-lower_rt_io_derefs(nir_shader *shader)
+lower_rt_io_derefs(nir_shader *shader, const struct intel_device_info *devinfo)
 {
    nir_function_impl *impl = nir_shader_get_entrypoint(shader);
 
@@ -94,13 +94,24 @@ lower_rt_io_derefs(nir_shader *shader)
       assert(stage == MESA_SHADER_ANY_HIT ||
              stage == MESA_SHADER_CLOSEST_HIT ||
              stage == MESA_SHADER_INTERSECTION);
-      nir_def *hit_addr =
-         brw_nir_rt_mem_hit_addr(&b, stage == MESA_SHADER_CLOSEST_HIT);
-      /* The vec2 barycentrics are in 2nd and 3rd dwords of MemHit */
-      nir_def *bary_addr = nir_iadd_imm(&b, hit_addr, 4);
-      hit_attrib_addr = nir_bcsel(&b, nir_load_leaf_procedural_intel(&b),
-                                      brw_nir_rt_hit_attrib_data_addr(&b),
-                                      bary_addr);
+      hit_attrib_addr = brw_nir_rt_hit_attrib_data_addr(&b);
+
+      /* For tri, we store tri_bary at hit_attrib_data_addr.
+       * The reason we don't directly provide the address where u and v is
+       * located is that for Xe3+ u and v needs extra unorm_to_float
+       * calculation, so we write the computed value to hit_attrib_data_addr
+       * for shader to dereference.
+       */
+      nir_push_if(&b, nir_inot(&b, nir_load_leaf_procedural_intel(&b)));
+      {
+         nir_def* tri_bary =
+            brw_nir_rt_load_tri_bary_from_addr(&b,
+                                               brw_nir_rt_stack_addr(&b),
+                                               stage == MESA_SHADER_CLOSEST_HIT,
+                                               devinfo);
+         nir_store_global(&b, hit_attrib_addr, 4, tri_bary, 0x3);
+      }
+      nir_pop_if(&b, NULL);
       progress = true;
    }
 
@@ -183,7 +194,7 @@ lower_rt_io_derefs(nir_shader *shader)
  * variable down the call stack.
  */
 static void
-lower_rt_io_and_scratch(nir_shader *nir)
+lower_rt_io_and_scratch(nir_shader *nir, const struct intel_device_info *devinfo)
 {
    /* First, we to ensure all the I/O variables have explicit types.  Because
     * these are shader-internal and don't come in from outside, they don't
@@ -196,7 +207,7 @@ lower_rt_io_and_scratch(nir_shader *nir)
               glsl_get_natural_size_align_bytes);
 
    /* Now patch any derefs to I/O vars */
-   NIR_PASS_V(nir, lower_rt_io_derefs);
+   NIR_PASS_V(nir, lower_rt_io_derefs, devinfo);
 
    /* Finally, lower any remaining function_temp, mem_constant, or
     * ray_hit_attrib access to 64-bit global memory access.
@@ -329,11 +340,11 @@ lower_ray_walk_intrinsics(nir_shader *shader,
 }
 
 void
-brw_nir_lower_raygen(nir_shader *nir)
+brw_nir_lower_raygen(nir_shader *nir, const struct intel_device_info *devinfo)
 {
    assert(nir->info.stage == MESA_SHADER_RAYGEN);
    NIR_PASS_V(nir, brw_nir_lower_shader_returns);
-   lower_rt_io_and_scratch(nir);
+   lower_rt_io_and_scratch(nir, devinfo);
 }
 
 void
@@ -342,31 +353,31 @@ brw_nir_lower_any_hit(nir_shader *nir, const struct intel_device_info *devinfo)
    assert(nir->info.stage == MESA_SHADER_ANY_HIT);
    NIR_PASS_V(nir, brw_nir_lower_shader_returns);
    NIR_PASS_V(nir, lower_ray_walk_intrinsics, devinfo);
-   lower_rt_io_and_scratch(nir);
+   lower_rt_io_and_scratch(nir, devinfo);
 }
 
 void
-brw_nir_lower_closest_hit(nir_shader *nir)
+brw_nir_lower_closest_hit(nir_shader *nir, const struct intel_device_info *devinfo)
 {
    assert(nir->info.stage == MESA_SHADER_CLOSEST_HIT);
    NIR_PASS_V(nir, brw_nir_lower_shader_returns);
-   lower_rt_io_and_scratch(nir);
+   lower_rt_io_and_scratch(nir, devinfo);
 }
 
 void
-brw_nir_lower_miss(nir_shader *nir)
+brw_nir_lower_miss(nir_shader *nir, const struct intel_device_info *devinfo)
 {
    assert(nir->info.stage == MESA_SHADER_MISS);
    NIR_PASS_V(nir, brw_nir_lower_shader_returns);
-   lower_rt_io_and_scratch(nir);
+   lower_rt_io_and_scratch(nir, devinfo);
 }
 
 void
-brw_nir_lower_callable(nir_shader *nir)
+brw_nir_lower_callable(nir_shader *nir, const struct intel_device_info *devinfo)
 {
    assert(nir->info.stage == MESA_SHADER_CALLABLE);
    NIR_PASS_V(nir, brw_nir_lower_shader_returns);
-   lower_rt_io_and_scratch(nir);
+   lower_rt_io_and_scratch(nir, devinfo);
 }
 
 void
@@ -380,7 +391,7 @@ brw_nir_lower_combined_intersection_any_hit(nir_shader *intersection,
    NIR_PASS_V(intersection, brw_nir_lower_intersection_shader,
               any_hit, devinfo);
    NIR_PASS_V(intersection, lower_ray_walk_intrinsics, devinfo);
-   lower_rt_io_and_scratch(intersection);
+   lower_rt_io_and_scratch(intersection, devinfo);
 }
 
 static nir_def *
diff --git a/src/intel/compiler/brw_nir_rt.h b/src/intel/compiler/brw_nir_rt.h
index aaa1ddc8659..e58779b04a9 100644
--- a/src/intel/compiler/brw_nir_rt.h
+++ b/src/intel/compiler/brw_nir_rt.h
@@ -30,12 +30,16 @@
 extern "C" {
 #endif
 
-void brw_nir_lower_raygen(nir_shader *nir);
+void brw_nir_lower_raygen(nir_shader *nir,
+                          const struct intel_device_info *devinfo);
 void brw_nir_lower_any_hit(nir_shader *nir,
                            const struct intel_device_info *devinfo);
-void brw_nir_lower_closest_hit(nir_shader *nir);
-void brw_nir_lower_miss(nir_shader *nir);
-void brw_nir_lower_callable(nir_shader *nir);
+void brw_nir_lower_closest_hit(nir_shader *nir,
+                               const struct intel_device_info *devinfo);
+void brw_nir_lower_miss(nir_shader *nir,
+                        const struct intel_device_info *devinfo);
+void brw_nir_lower_callable(nir_shader *nir,
+                            const struct intel_device_info *devinfo);
 void brw_nir_lower_combined_intersection_any_hit(nir_shader *intersection,
                                                  const nir_shader *any_hit,
                                                  const struct intel_device_info *devinfo);
@@ -48,14 +52,18 @@ void brw_nir_lower_combined_intersection_any_hit(nir_shader *intersection,
 /* We require the stack to be 8B aligned at the start of a shader */
 #define BRW_BTD_STACK_ALIGN 8
 
+struct brw_nir_lower_shader_calls_state {
+   const struct intel_device_info *devinfo;
+   struct brw_bs_prog_key *key;
+};
+
 bool brw_nir_lower_ray_queries(nir_shader *shader,
                                const struct intel_device_info *devinfo);
 
 void brw_nir_lower_shader_returns(nir_shader *shader);
 
-bool brw_nir_lower_shader_calls(nir_shader *shader, struct brw_bs_prog_key *key);
-
-bool brw_nir_lower_rt_intrinsics_pre_trace(nir_shader *nir);
+bool brw_nir_lower_shader_calls(nir_shader *shader,
+                                struct brw_nir_lower_shader_calls_state *state);
 
 void brw_nir_lower_rt_intrinsics(nir_shader *shader,
                                  const struct brw_base_prog_key *key,
diff --git a/src/intel/compiler/brw_nir_rt_builder.h b/src/intel/compiler/brw_nir_rt_builder.h
index 767f381a65e..1ff103ec757 100644
--- a/src/intel/compiler/brw_nir_rt_builder.h
+++ b/src/intel/compiler/brw_nir_rt_builder.h
@@ -33,6 +33,7 @@
 
 #include "brw_rt.h"
 #include "nir_builder.h"
+#include "nir_format_convert.h"
 
 #define is_access_for_builder(b) \
    ((b)->shader->info.stage == MESA_SHADER_FRAGMENT ? \
@@ -305,7 +306,8 @@ struct brw_nir_rt_globals_defs {
 static inline void
 brw_nir_rt_load_globals_addr(nir_builder *b,
                              struct brw_nir_rt_globals_defs *defs,
-                             nir_def *addr)
+                             nir_def *addr,
+                             const struct intel_device_info *devinfo)
 {
    nir_def *data;
    data = brw_nir_rt_load_const(b, 16, addr);
@@ -316,59 +318,110 @@ brw_nir_rt_load_globals_addr(nir_builder *b,
 
    defs->hw_stack_size = nir_channel(b, data, 4);
    defs->num_dss_rt_stacks = nir_iand_imm(b, nir_channel(b, data, 5), 0xffff);
-   defs->hit_sbt_addr =
-      nir_pack_64_2x32_split(b, nir_channel(b, data, 8),
-                                nir_extract_i16(b, nir_channel(b, data, 9),
-                                                   nir_imm_int(b, 0)));
-   defs->hit_sbt_stride =
-      nir_unpack_32_2x16_split_y(b, nir_channel(b, data, 9));
-   defs->miss_sbt_addr =
-      nir_pack_64_2x32_split(b, nir_channel(b, data, 10),
-                                nir_extract_i16(b, nir_channel(b, data, 11),
-                                                   nir_imm_int(b, 0)));
-   defs->miss_sbt_stride =
-      nir_unpack_32_2x16_split_y(b, nir_channel(b, data, 11));
+   if (devinfo->ver >= 30) {
+      /* maxBVHLevels are not used yet. */
+      defs->hit_sbt_stride =
+         nir_iand_imm(b, nir_ishr_imm(b, nir_channel(b, data, 6), 0x3), 0x1fff);
+      defs->miss_sbt_stride =
+         nir_iand_imm(b, nir_unpack_32_2x16_split_y(b, nir_channel(b, data, 6)),
+                      0x1fff);
+      /* per context control flags are not used yet. */
+
+      /* Bspec 56933 (r58935):
+       *
+       * hitGroupBasePtr: [63:4] Canonical address with 58b address-space,16B
+       *                  aligned GPUVA : base pointer of hit group shader
+       *                  record array (16-bytes alignment)
+       */
+      defs->hit_sbt_addr = nir_pack_64_2x32(b, nir_channels(b, data, 0x3 << 8));
+
+      /* Bspec 56933 (r58935):
+       *
+       * missShaderBasePtr: [63:3] Canonical address with 58b address-space,8B
+       *                    aligned GPUVA: base pointer of miss shader record
+       *                    array (8-bytes alignment)
+       */
+      defs->miss_sbt_addr = nir_pack_64_2x32(b, nir_channels(b, data, 0x3 << 10));
+   } else {
+      defs->hit_sbt_addr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data, 8),
+                                   nir_extract_i16(b, nir_channel(b, data, 9),
+                                                      nir_imm_int(b, 0)));
+      defs->hit_sbt_stride =
+         nir_unpack_32_2x16_split_y(b, nir_channel(b, data, 9));
+      defs->miss_sbt_addr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data, 10),
+                                   nir_extract_i16(b, nir_channel(b, data, 11),
+                                                      nir_imm_int(b, 0)));
+      defs->miss_sbt_stride =
+         nir_unpack_32_2x16_split_y(b, nir_channel(b, data, 11));
+   }
+
    defs->sw_stack_size = nir_channel(b, data, 12);
    defs->launch_size = nir_channels(b, data, 0x7u << 13);
 
    data = brw_nir_rt_load_const(b, 8, nir_iadd_imm(b, addr, 64));
-   defs->call_sbt_addr =
-      nir_pack_64_2x32_split(b, nir_channel(b, data, 0),
-                                nir_extract_i16(b, nir_channel(b, data, 1),
-                                                   nir_imm_int(b, 0)));
-   defs->call_sbt_stride =
-      nir_unpack_32_2x16_split_y(b, nir_channel(b, data, 1));
 
-   defs->resume_sbt_addr =
-      nir_pack_64_2x32(b, nir_channels(b, data, 0x3 << 2));
+   if (devinfo->ver >= 30) {
+      defs->call_sbt_addr = nir_pack_64_2x32_split(b, nir_channel(b, data, 0),
+                                                   nir_channel(b, data, 1));
+      defs->call_sbt_stride =
+         nir_iand_imm(b, nir_unpack_32_2x16_split_x(b, nir_channel(b, data, 2)),
+                      0x1fff);
+      defs->resume_sbt_addr =
+         nir_pack_64_2x32(b, nir_channels(b, data, 0x3 << 3));
+   } else {
+      defs->call_sbt_addr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data, 0),
+                                   nir_extract_i16(b, nir_channel(b, data, 1),
+                                                      nir_imm_int(b, 0)));
+      defs->call_sbt_stride =
+         nir_unpack_32_2x16_split_y(b, nir_channel(b, data, 1));
+
+      defs->resume_sbt_addr =
+         nir_pack_64_2x32(b, nir_channels(b, data, 0x3 << 2));
+   }
 }
 
 static inline void
 brw_nir_rt_load_globals(nir_builder *b,
-                        struct brw_nir_rt_globals_defs *defs)
+                        struct brw_nir_rt_globals_defs *defs,
+                        const struct intel_device_info *devinfo)
 {
-   brw_nir_rt_load_globals_addr(b, defs, nir_load_btd_global_arg_addr_intel(b));
+   brw_nir_rt_load_globals_addr(b, defs, nir_load_btd_global_arg_addr_intel(b),
+                                devinfo);
 }
 
 static inline nir_def *
-brw_nir_rt_unpack_leaf_ptr(nir_builder *b, nir_def *vec2)
+brw_nir_rt_unpack_leaf_ptr(nir_builder *b, nir_def *vec2,
+                           const struct intel_device_info *devinfo)
 {
-   /* Hit record leaf pointers are 42-bit and assumed to be in 64B chunks.
-    * This leaves 22 bits at the top for other stuff.
-    */
-   nir_def *ptr64 = nir_imul_imm(b, nir_pack_64_2x32(b, vec2), 64);
+   nir_def *result;
+   if (devinfo->ver >= 30) {
+      /* Hit record leaf pointers are at the higher 58-bit.
+       * We get rid of the lower 6bit to make an address.
+       * The lower 6bit being zero indicates that this ptr is 64B aligned.
+       */
+      result = nir_iand_imm(b, nir_pack_64_2x32(b, vec2), 0xFFFFFFFFFFFFFFC0);
+   } else {
+      /* Hit record leaf pointers are 42-bit and assumed to be in 64B chunks.
+       * This leaves 22 bits at the top for other stuff.
+       *
+       * The top 16 bits (remember, we shifted by 6 already) contain garbage
+       * that we need to get rid of.
+       */
+      nir_def *ptr64 = nir_imul_imm(b, nir_pack_64_2x32(b, vec2), 64);
+      nir_def *ptr_lo = nir_unpack_64_2x32_split_x(b, ptr64);
+      nir_def *ptr_hi = nir_unpack_64_2x32_split_y(b, ptr64);
+      ptr_hi = nir_extract_i16(b, ptr_hi, nir_imm_int(b, 0));
+      result = nir_pack_64_2x32_split(b, ptr_lo, ptr_hi);
+   }
 
-   /* The top 16 bits (remember, we shifted by 6 already) contain garbage
-    * that we need to get rid of.
-    */
-   nir_def *ptr_lo = nir_unpack_64_2x32_split_x(b, ptr64);
-   nir_def *ptr_hi = nir_unpack_64_2x32_split_y(b, ptr64);
-   ptr_hi = nir_extract_i16(b, ptr_hi, nir_imm_int(b, 0));
-   return nir_pack_64_2x32_split(b, ptr_lo, ptr_hi);
+   return result;
 }
 
 /**
- * MemHit memory layout (BSpec 47547) :
+ * On Gfx < Xe3, MemHit memory layout (BSpec 47547) :
  *
  *      name            bits    description
  *    - t               32      hit distance of current hit (or initial traversal distance)
@@ -385,10 +438,33 @@ brw_nir_rt_unpack_leaf_ptr(nir_builder *b, nir_def *vec2)
  *    - hitGroupRecPtr0 22      LSB of hit group record of the hit triangle (multiple of 16 bytes)
  *    - instLeafPtr     42      pointer to BVH instance leaf node (in multiple of 64 bytes)
  *    - hitGroupRecPtr1 22      MSB of hit group record of the hit triangle (multiple of 32 bytes)
+ *
+ * MemHit memory layout on Xe3+ (Bspec 56933) :
+ *
+ *      name            bits    description
+ *    - t               32      hit distance of current hit (or initial traversal distance)
+ *    - u               24      barycentric u hit coordinate stored as 24 bit unorm
+ *    - hitGroupIndex0   8      1st bits of hitGroupIndex
+ *    - v               24      barycentric v hit coordinate stored as 24 bit unorm
+ *    - hitGroupIndex1   8      2nd bits of hitGroupIndex
+ *    - primIndexDelta   5      prim index delta for compressed meshlets and quads
+ *    - pad1             7      unused bits
+ *    - leafNodeSubType  4      sub-type of leaf node
+ *    - valid            1      set if there is a hit
+ *    - leafType         3      type of node primLeafPtr is pointing to
+ *    - primLeafIndex    4      index of the hit primitive inside the leaf
+ *    - bvhLevel         3      the instancing level at which the hit occured
+ *    - frontFace        1      whether we hit the front-facing side of a triangle (also used to pass opaque flag when calling intersection shaders)
+ *    - done             1      used in sync mode to indicate that traversal is done
+ *    - needSWSTOC       1      if set, AnyHit Shader must perform a SW fallback STOC test
+ *    - pad0             2      unused bits
+ *    - hitGroupIndex2   6      3rd bits of hitGroupIndex
+ *    - primLeafPtr     58      pointer to BVH leaf node (MSBs of 64b pointer aligned to 64B)
+ *    - hitGroupIndex3   6      4th bits of hit group index
+ *    - instLeafPtr     58      pointer to BVH instance leaf node (MSBs of 64b pointer aligned to 64B)
  */
 struct brw_nir_rt_mem_hit_defs {
    nir_def *t;
-   nir_def *tri_bary; /**< Only valid for triangle geometry */
    nir_def *aabb_hit_kind; /**< Only valid for AABB geometry */
    nir_def *valid;
    nir_def *leaf_type;
@@ -401,22 +477,61 @@ struct brw_nir_rt_mem_hit_defs {
    nir_def *inst_leaf_ptr;
 };
 
+/* For Xe3+, barycentric coordinates are stored as 24 bit unorm.
+ * Since unorm_float could be expensive, we calculate tri_bary on
+ * demand. We do this for Xe3+ and Xe1/2 for consistency.
+ */
+static inline nir_def *
+brw_nir_rt_load_tri_bary_from_addr(nir_builder *b,
+                                   nir_def *stack_addr,
+                                   bool committed,
+                                   const struct intel_device_info *devinfo)
+{
+   nir_def *hit_addr =
+      brw_nir_rt_mem_hit_addr_from_addr(b, stack_addr, committed);
+
+   nir_def *data = brw_nir_rt_load(b, hit_addr, 16, 4, 32);
+   nir_def *tri_bary;
+   if (devinfo->ver >= 30) {
+      nir_def *u = nir_iand_imm(b, nir_channel(b, data, 1), 0xffffff);
+      nir_def *v = nir_iand_imm(b, nir_channel(b, data, 2), 0xffffff);
+      const unsigned bits[1] = {24};
+      tri_bary = nir_vec2(b,
+                          nir_format_unorm_to_float_precise(b, u, bits),
+                          nir_format_unorm_to_float_precise(b, v, bits));
+   } else {
+      tri_bary = nir_channels(b, data, 0x6);
+   }
+
+   return tri_bary;
+}
 static inline void
 brw_nir_rt_load_mem_hit_from_addr(nir_builder *b,
                                   struct brw_nir_rt_mem_hit_defs *defs,
                                   nir_def *stack_addr,
-                                  bool committed)
+                                  bool committed,
+                                  const struct intel_device_info *devinfo)
 {
    nir_def *hit_addr =
       brw_nir_rt_mem_hit_addr_from_addr(b, stack_addr, committed);
 
    nir_def *data = brw_nir_rt_load(b, hit_addr, 16, 4, 32);
    defs->t = nir_channel(b, data, 0);
-   defs->aabb_hit_kind = nir_channel(b, data, 1);
-   defs->tri_bary = nir_channels(b, data, 0x6);
+
    nir_def *bitfield = nir_channel(b, data, 3);
-   defs->prim_index_delta =
-      nir_ubitfield_extract(b, bitfield, nir_imm_int(b, 0), nir_imm_int(b, 16));
+   if (devinfo->ver >= 30) {
+      defs->aabb_hit_kind = nir_iand_imm(b, nir_channel(b, data, 1),
+                                         0xffffff);
+      defs->prim_index_delta = nir_ubitfield_extract(b, bitfield,
+                                                     nir_imm_int(b, 0),
+                                                     nir_imm_int(b, 5));
+   } else {
+      defs->aabb_hit_kind = nir_channel(b, data, 1);
+      defs->prim_index_delta = nir_ubitfield_extract(b, bitfield,
+                                                     nir_imm_int(b, 0),
+                                                     nir_imm_int(b, 16));
+   }
+
    defs->valid = nir_i2b(b, nir_iand_imm(b, bitfield, 1u << 16));
    defs->leaf_type =
       nir_ubitfield_extract(b, bitfield, nir_imm_int(b, 17), nir_imm_int(b, 3));
@@ -425,22 +540,24 @@ brw_nir_rt_load_mem_hit_from_addr(nir_builder *b,
    defs->bvh_level =
       nir_ubitfield_extract(b, bitfield, nir_imm_int(b, 24), nir_imm_int(b, 3));
    defs->front_face = nir_i2b(b, nir_iand_imm(b, bitfield, 1 << 27));
+
    defs->done = nir_i2b(b, nir_iand_imm(b, bitfield, 1 << 28));
 
    data = brw_nir_rt_load(b, nir_iadd_imm(b, hit_addr, 16), 16, 4, 32);
    defs->prim_leaf_ptr =
-      brw_nir_rt_unpack_leaf_ptr(b, nir_channels(b, data, 0x3 << 0));
+      brw_nir_rt_unpack_leaf_ptr(b, nir_channels(b, data, 0x3 << 0), devinfo);
    defs->inst_leaf_ptr =
-      brw_nir_rt_unpack_leaf_ptr(b, nir_channels(b, data, 0x3 << 2));
+      brw_nir_rt_unpack_leaf_ptr(b, nir_channels(b, data, 0x3 << 2), devinfo);
 }
 
 static inline void
 brw_nir_rt_load_mem_hit(nir_builder *b,
                         struct brw_nir_rt_mem_hit_defs *defs,
-                        bool committed)
+                        bool committed,
+                        const struct intel_device_info *devinfo)
 {
    brw_nir_rt_load_mem_hit_from_addr(b, defs, brw_nir_rt_stack_addr(b),
-                                     committed);
+                                     committed, devinfo);
 }
 
 static inline void
@@ -480,11 +597,12 @@ brw_nir_memclear_global(nir_builder *b,
 }
 
 static inline nir_def *
-brw_nir_rt_query_done(nir_builder *b, nir_def *stack_addr)
+brw_nir_rt_query_done(nir_builder *b, nir_def *stack_addr,
+                      const struct intel_device_info *devinfo)
 {
    struct brw_nir_rt_mem_hit_defs hit_in = {};
    brw_nir_rt_load_mem_hit_from_addr(b, &hit_in, stack_addr,
-                                     false /* committed */);
+                                     false /* committed */, devinfo);
 
    return hit_in.done;
 }
@@ -641,12 +759,17 @@ struct brw_nir_rt_mem_ray_defs {
    nir_def *shader_index_multiplier;
    nir_def *inst_leaf_ptr;
    nir_def *ray_mask;
+
+   /* Valid on Xe3+ */
+   nir_def *hit_group_index;
+   nir_def *miss_shader_index;
 };
 
 static inline void
 brw_nir_rt_store_mem_ray_query_at_addr(nir_builder *b,
                                        nir_def *ray_addr,
-                                       const struct brw_nir_rt_mem_ray_defs *defs)
+                                       const struct brw_nir_rt_mem_ray_defs *defs,
+                                       const struct intel_device_info *devinfo)
 {
    assert_def_size(defs->orig, 3, 32);
    assert_def_size(defs->dir, 3, 32);
@@ -666,15 +789,6 @@ brw_nir_rt_store_mem_ray_query_at_addr(nir_builder *b,
                   defs->t_far),
       ~0 /* write mask */);
 
-   assert_def_size(defs->root_node_ptr, 1, 64);
-   assert_def_size(defs->ray_flags, 1, 16);
-   brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 32), 16,
-      nir_vec2(b, nir_unpack_64_2x32_split_x(b, defs->root_node_ptr),
-                  nir_pack_32_2x16_split(b,
-                     nir_unpack_64_4x16_split_z(b, defs->root_node_ptr),
-                     defs->ray_flags)),
-      0x3 /* write mask */);
-
    /* leaf_ptr is optional */
    nir_def *inst_leaf_ptr;
    if (defs->inst_leaf_ptr) {
@@ -683,20 +797,47 @@ brw_nir_rt_store_mem_ray_query_at_addr(nir_builder *b,
       inst_leaf_ptr = nir_imm_int64(b, 0);
    }
 
+   assert_def_size(defs->root_node_ptr, 1, 64);
    assert_def_size(inst_leaf_ptr, 1, 64);
-   assert_def_size(defs->ray_mask, 1, 32);
-   brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 56), 8,
-      nir_vec2(b, nir_unpack_64_2x32_split_x(b, inst_leaf_ptr),
-                  nir_pack_32_2x16_split(b,
-                     nir_unpack_64_4x16_split_z(b, inst_leaf_ptr),
-                     nir_unpack_32_2x16_split_x(b, defs->ray_mask))),
-      ~0 /* write mask */);
+   assert_def_size(defs->ray_flags, 1, 16);
+
+   if (devinfo->ver >= 30) {
+      brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 32), 16,
+         nir_vec4(b, nir_unpack_64_2x32_split_x(b, defs->root_node_ptr),
+                     nir_unpack_64_2x32_split_y(b, defs->root_node_ptr),
+                     nir_unpack_64_2x32_split_x(b, inst_leaf_ptr),
+                     nir_unpack_64_2x32_split_y(b, inst_leaf_ptr)),
+         ~0 /* write mask */);
+
+      assert_def_size(defs->ray_mask, 1, 32);
+      brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 48), 8,
+         nir_pack_32_2x16_split(b,
+            defs->ray_flags,
+            nir_unpack_32_2x16_split_x(b, defs->ray_mask)),
+         0x1 /* write mask */);
+   } else {
+      brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 32), 16,
+         nir_vec2(b, nir_unpack_64_2x32_split_x(b, defs->root_node_ptr),
+                     nir_pack_32_2x16_split(b,
+                        nir_unpack_64_4x16_split_z(b, defs->root_node_ptr),
+                        defs->ray_flags)),
+         0x3 /* write mask */);
+
+      assert_def_size(defs->ray_mask, 1, 32);
+      brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 56), 8,
+         nir_vec2(b, nir_unpack_64_2x32_split_x(b, inst_leaf_ptr),
+                     nir_pack_32_2x16_split(b,
+                        nir_unpack_64_4x16_split_z(b, inst_leaf_ptr),
+                        nir_unpack_32_2x16_split_x(b, defs->ray_mask))),
+         ~0 /* write mask */);
+   }
 }
 
 static inline void
 brw_nir_rt_store_mem_ray(nir_builder *b,
                          const struct brw_nir_rt_mem_ray_defs *defs,
-                         enum brw_rt_bvh_level bvh_level)
+                         enum brw_rt_bvh_level bvh_level,
+                         const struct intel_device_info *devinfo)
 {
    nir_def *ray_addr =
       brw_nir_rt_mem_ray_addr(b, brw_nir_rt_stack_addr(b), bvh_level);
@@ -719,21 +860,6 @@ brw_nir_rt_store_mem_ray(nir_builder *b,
                   defs->t_far),
       ~0 /* write mask */);
 
-   assert_def_size(defs->root_node_ptr, 1, 64);
-   assert_def_size(defs->ray_flags, 1, 16);
-   assert_def_size(defs->hit_group_sr_base_ptr, 1, 64);
-   assert_def_size(defs->hit_group_sr_stride, 1, 16);
-   brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 32), 16,
-      nir_vec4(b, nir_unpack_64_2x32_split_x(b, defs->root_node_ptr),
-                  nir_pack_32_2x16_split(b,
-                     nir_unpack_64_4x16_split_z(b, defs->root_node_ptr),
-                     defs->ray_flags),
-                  nir_unpack_64_2x32_split_x(b, defs->hit_group_sr_base_ptr),
-                  nir_pack_32_2x16_split(b,
-                     nir_unpack_64_4x16_split_z(b, defs->hit_group_sr_base_ptr),
-                     defs->hit_group_sr_stride)),
-      ~0 /* write mask */);
-
    /* leaf_ptr is optional */
    nir_def *inst_leaf_ptr;
    if (defs->inst_leaf_ptr) {
@@ -742,33 +868,122 @@ brw_nir_rt_store_mem_ray(nir_builder *b,
       inst_leaf_ptr = nir_imm_int64(b, 0);
    }
 
-   assert_def_size(defs->miss_sr_ptr, 1, 64);
-   assert_def_size(defs->shader_index_multiplier, 1, 32);
+   assert_def_size(defs->root_node_ptr, 1, 64);
    assert_def_size(inst_leaf_ptr, 1, 64);
-   assert_def_size(defs->ray_mask, 1, 32);
-   brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 48), 16,
-      nir_vec4(b, nir_unpack_64_2x32_split_x(b, defs->miss_sr_ptr),
-                  nir_pack_32_2x16_split(b,
-                     nir_unpack_64_4x16_split_z(b, defs->miss_sr_ptr),
-                     nir_unpack_32_2x16_split_x(b,
-                        nir_ishl(b, defs->shader_index_multiplier,
-                                    nir_imm_int(b, 8)))),
-                  nir_unpack_64_2x32_split_x(b, inst_leaf_ptr),
-                  nir_pack_32_2x16_split(b,
-                     nir_unpack_64_4x16_split_z(b, inst_leaf_ptr),
-                     nir_unpack_32_2x16_split_x(b, defs->ray_mask))),
-      ~0 /* write mask */);
+   assert_def_size(defs->ray_flags, 1, 16);
+
+   if (devinfo->ver >= 30) {
+      brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 32), 16,
+         nir_vec4(b, nir_unpack_64_2x32_split_x(b, defs->root_node_ptr),
+                     nir_unpack_64_2x32_split_y(b, defs->root_node_ptr),
+                     nir_unpack_64_2x32_split_x(b, inst_leaf_ptr),
+                     nir_unpack_64_2x32_split_y(b, inst_leaf_ptr)),
+         ~0 /* write mask */);
+
+      assert_def_size(defs->ray_mask, 1, 32);
+      assert_def_size(defs->miss_shader_index, 1, 16);
+      assert_def_size(defs->shader_index_multiplier, 1, 32);
+
+      nir_def *packed0 = nir_pack_32_2x16_split(b,
+                            defs->ray_flags,
+                            nir_unpack_32_2x16_split_x(b, defs->ray_mask));
+      /* internalRayFlags are not used at the moment */
+      nir_def *packed1 = nir_pack_32_2x16_split(b,
+                            defs->miss_shader_index,
+                            nir_unpack_32_2x16_split_x(b, defs->shader_index_multiplier));
+      brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 48), 16,
+         nir_vec3(b, packed0, defs->hit_group_index, packed1),
+         0x7 /* write mask */);
+   } else {
+      assert_def_size(defs->hit_group_sr_base_ptr, 1, 64);
+      assert_def_size(defs->hit_group_sr_stride, 1, 16);
+      brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 32), 16,
+         nir_vec4(b, nir_unpack_64_2x32_split_x(b, defs->root_node_ptr),
+                     nir_pack_32_2x16_split(b,
+                        nir_unpack_64_4x16_split_z(b, defs->root_node_ptr),
+                        defs->ray_flags),
+                     nir_unpack_64_2x32_split_x(b, defs->hit_group_sr_base_ptr),
+                     nir_pack_32_2x16_split(b,
+                        nir_unpack_64_4x16_split_z(b, defs->hit_group_sr_base_ptr),
+                        defs->hit_group_sr_stride)),
+         ~0 /* write mask */);
+
+      assert_def_size(defs->miss_sr_ptr, 1, 64);
+      assert_def_size(defs->shader_index_multiplier, 1, 32);
+      assert_def_size(defs->ray_mask, 1, 32);
+      brw_nir_rt_store(b, nir_iadd_imm(b, ray_addr, 48), 16,
+         nir_vec4(b, nir_unpack_64_2x32_split_x(b, defs->miss_sr_ptr),
+                     nir_pack_32_2x16_split(b,
+                        nir_unpack_64_4x16_split_z(b, defs->miss_sr_ptr),
+                        nir_unpack_32_2x16_split_x(b,
+                           nir_ishl(b, defs->shader_index_multiplier,
+                                       nir_imm_int(b, 8)))),
+                     nir_unpack_64_2x32_split_x(b, inst_leaf_ptr),
+                     nir_pack_32_2x16_split(b,
+                        nir_unpack_64_4x16_split_z(b, inst_leaf_ptr),
+                        nir_unpack_32_2x16_split_x(b, defs->ray_mask))),
+         ~0 /* write mask */);
+   }
 }
 
+/* On Xe3+, MemRay memory data structure (Bspec 56933):
+ * 64b version:
+ *
+ * org_x                   32    the origin of the ray
+ * org_y                   32    the origin of the ray
+ * org_z                   32    the origin of the ray
+ * dir_x                   32    the direction of the ray
+ * dir_y                   32    the direction of the ray
+ * dir_z                   32    the direction of the ray
+ * tnear                   32    the start of the ray
+ * tfar                    32    the end of the ray
+ * rootNodePtr             64    root node to start traversal at (64-byte
+ *                               alignment)
+ * instLeafPtr             64    the pointer to instance leaf in case we
+ *                               traverse an instance (64-bytes alignment)
+ * rayFlags                16    ray flags (see RayFlag structure)
+ * rayMask                  8    ray mask used for ray masking
+ * comparisonValue          7    to be compared with Instance.ComparisonMask
+ * pad                      1
+ * hitGroupIndex           32    hit group shader index
+ * missShaderIndex         16    index of miss shader to invoke on a miss
+ * shaderIndexMultiplier    4    shader index multiplier
+ * pad2                     4
+ * internalRayFlags         8    internal ray flags
+ *
+ * On older platforms (< Xe3):
+ * 48b version:
+ *
+ * org_x                   32    the origin of the ray
+ * org_y                   32    the origin of the ray
+ * org_z                   32    the origin of the ray
+ * dir_x                   32    the direction of the ray
+ * dir_y                   32    the direction of the ray
+ * dir_z                   32    the direction of the ray
+ * tnear                   32    the start of the ray
+ * tfar                    32    the end of the ray
+ * rootNodePtr             48    root node to start traversal at
+ * rayFlags                16    ray flags (see RayFlag structure)
+ * hitGroupSRBasePtr       48    base of hit group shader record array (8-bytes
+ *                               alignment)
+ * hitGroupSRStride        16    stride of hit group shader record array (8-bytes
+ *                               alignment)
+ * missSRPtr               48    pointer to miss shader record to invoke on a
+ *                               miss (8-bytes alignment)
+ * pad                     8
+ * shaderIndexMultiplier   8     shader index multiplier
+ * instLeafPtr             48    the pointer to instance leaf in case we traverse an
+ *                               instance (64-bytes alignment)
+ * rayMask                 8     ray mask used for ray masking
+ */
 static inline void
 brw_nir_rt_load_mem_ray_from_addr(nir_builder *b,
                                   struct brw_nir_rt_mem_ray_defs *defs,
                                   nir_def *ray_base_addr,
-                                  enum brw_rt_bvh_level bvh_level)
+                                  enum brw_rt_bvh_level bvh_level,
+                                  const struct intel_device_info *devinfo)
 {
-   nir_def *ray_addr = brw_nir_rt_mem_ray_addr(b,
-                                                   ray_base_addr,
-                                                   bvh_level);
+   nir_def *ray_addr = brw_nir_rt_mem_ray_addr(b, ray_base_addr, bvh_level);
 
    nir_def *data[4] = {
       brw_nir_rt_load(b, nir_iadd_imm(b, ray_addr,  0), 16, 4, 32),
@@ -783,40 +998,62 @@ brw_nir_rt_load_mem_ray_from_addr(nir_builder *b,
                            nir_channel(b, data[1], 1));
    defs->t_near = nir_channel(b, data[1], 2);
    defs->t_far = nir_channel(b, data[1], 3);
-   defs->root_node_ptr =
-      nir_pack_64_2x32_split(b, nir_channel(b, data[2], 0),
+
+   if (devinfo->ver >= 30) {
+      defs->root_node_ptr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data[2], 0),
+                                   nir_channel(b, data[2], 1));
+      defs->inst_leaf_ptr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data[2], 2),
+                                   nir_channel(b, data[2], 3));
+      defs->ray_flags =
+         nir_unpack_32_2x16_split_x(b, nir_channel(b, data[3], 0));
+      defs->ray_mask =
+         nir_iand_imm(b, nir_unpack_32_2x16_split_y(b, nir_channel(b, data[3], 0)),
+                      0xff);
+      defs->hit_group_index = nir_channel(b, data[3], 1);
+      defs->miss_shader_index =
+         nir_unpack_32_2x16_split_x(b, nir_channel(b, data[3], 2));
+      defs->shader_index_multiplier =
+         nir_iand_imm(b, nir_unpack_32_2x16_split_y(b, nir_channel(b, data[3], 2)),
+                      0xf);
+   } else {
+      defs->root_node_ptr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data[2], 0),
                                 nir_extract_i16(b, nir_channel(b, data[2], 1),
                                                    nir_imm_int(b, 0)));
-   defs->ray_flags =
-      nir_unpack_32_2x16_split_y(b, nir_channel(b, data[2], 1));
-   defs->hit_group_sr_base_ptr =
-      nir_pack_64_2x32_split(b, nir_channel(b, data[2], 2),
+      defs->ray_flags =
+         nir_unpack_32_2x16_split_y(b, nir_channel(b, data[2], 1));
+      defs->hit_group_sr_base_ptr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data[2], 2),
                                 nir_extract_i16(b, nir_channel(b, data[2], 3),
                                                    nir_imm_int(b, 0)));
-   defs->hit_group_sr_stride =
-      nir_unpack_32_2x16_split_y(b, nir_channel(b, data[2], 3));
-   defs->miss_sr_ptr =
-      nir_pack_64_2x32_split(b, nir_channel(b, data[3], 0),
+      defs->hit_group_sr_stride =
+         nir_unpack_32_2x16_split_y(b, nir_channel(b, data[2], 3));
+      defs->miss_sr_ptr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data[3], 0),
                                 nir_extract_i16(b, nir_channel(b, data[3], 1),
                                                    nir_imm_int(b, 0)));
-   defs->shader_index_multiplier =
-      nir_ushr(b, nir_unpack_32_2x16_split_y(b, nir_channel(b, data[3], 1)),
-                  nir_imm_int(b, 8));
-   defs->inst_leaf_ptr =
-      nir_pack_64_2x32_split(b, nir_channel(b, data[3], 2),
+      defs->shader_index_multiplier =
+         nir_ushr(b, nir_unpack_32_2x16_split_y(b, nir_channel(b, data[3], 1)),
+                     nir_imm_int(b, 8));
+      defs->inst_leaf_ptr =
+         nir_pack_64_2x32_split(b, nir_channel(b, data[3], 2),
                                 nir_extract_i16(b, nir_channel(b, data[3], 3),
                                                    nir_imm_int(b, 0)));
-   defs->ray_mask =
-      nir_unpack_32_2x16_split_y(b, nir_channel(b, data[3], 3));
+      defs->ray_mask =
+         nir_unpack_32_2x16_split_y(b, nir_channel(b, data[3], 3));
+   }
 }
 
 static inline void
 brw_nir_rt_load_mem_ray(nir_builder *b,
                         struct brw_nir_rt_mem_ray_defs *defs,
-                        enum brw_rt_bvh_level bvh_level)
+                        enum brw_rt_bvh_level bvh_level,
+                        const struct intel_device_info *devinfo)
 {
    brw_nir_rt_load_mem_ray_from_addr(b, defs, brw_nir_rt_stack_addr(b),
-                                     bvh_level);
+                                     bvh_level, devinfo);
 }
 
 struct brw_nir_rt_bvh_instance_leaf_defs {
@@ -831,14 +1068,22 @@ struct brw_nir_rt_bvh_instance_leaf_defs {
 static inline void
 brw_nir_rt_load_bvh_instance_leaf(nir_builder *b,
                                   struct brw_nir_rt_bvh_instance_leaf_defs *defs,
-                                  nir_def *leaf_addr)
+                                  nir_def *leaf_addr,
+                                  const struct intel_device_info *devinfo)
 {
    nir_def *leaf_desc = brw_nir_rt_load(b, leaf_addr, 4, 2, 32);
 
-   defs->shader_index =
-      nir_iand_imm(b, nir_channel(b, leaf_desc, 0), (1 << 24) - 1);
-   defs->contribution_to_hit_group_index =
-      nir_iand_imm(b, nir_channel(b, leaf_desc, 1), (1 << 24) - 1);
+   if (devinfo->ver >= 30) {
+      /* Not used for Xe3+, just putting 0 for consistency */
+      defs->shader_index = nir_imm_int(b, 0);
+      defs->contribution_to_hit_group_index =
+         nir_iand_imm(b, nir_channel(b, leaf_desc, 0), (1 << 24) - 1);
+   } else {
+      defs->shader_index =
+         nir_iand_imm(b, nir_channel(b, leaf_desc, 0), (1 << 24) - 1);
+      defs->contribution_to_hit_group_index =
+         nir_iand_imm(b, nir_channel(b, leaf_desc, 1), (1 << 24) - 1);
+   }
 
    defs->world_to_object[0] =
       brw_nir_rt_load(b, nir_iadd_imm(b, leaf_addr, 16), 4, 3, 32);
diff --git a/src/intel/compiler/brw_opt.cpp b/src/intel/compiler/brw_opt.cpp
index 7c00367d8ae..4a4d6f37f8d 100644
--- a/src/intel/compiler/brw_opt.cpp
+++ b/src/intel/compiler/brw_opt.cpp
@@ -203,8 +203,8 @@ brw_optimize(brw_shader &s)
       /* No need for standard copy_propagation since
        * brw_opt_address_reg_load will only optimize defs.
        */
-      if (OPT(brw_opt_copy_propagation_defs))
-         OPT(brw_opt_algebraic);
+      OPT(brw_opt_copy_propagation_defs);
+      OPT(brw_opt_algebraic);
       OPT(brw_opt_address_reg_load);
       OPT(brw_opt_dead_code_eliminate);
    }
diff --git a/src/intel/compiler/brw_opt_algebraic.cpp b/src/intel/compiler/brw_opt_algebraic.cpp
index db6f2a40248..00d50ce3c3d 100644
--- a/src/intel/compiler/brw_opt_algebraic.cpp
+++ b/src/intel/compiler/brw_opt_algebraic.cpp
@@ -135,7 +135,9 @@ fold_multiplicands_of_MAD(brw_inst *inst)
 bool
 brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *inst)
 {
-   bool progress = false;
+   brw_reg result;
+
+   result.file = BAD_FILE;
 
    switch (inst->opcode) {
    case BRW_OPCODE_ADD:
@@ -146,15 +148,12 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
          const uint64_t src0 = src_as_uint(inst->src[0]);
          const uint64_t src1 = src_as_uint(inst->src[1]);
 
-         inst->src[0] = brw_imm_for_type(src0 + src1, inst->dst.type);
+         result = brw_imm_for_type(src0 + src1, inst->dst.type);
       } else {
          assert(inst->src[0].type == BRW_TYPE_F);
-         inst->src[0].f += inst->src[1].f;
+         result = brw_imm_f(inst->src[0].f + inst->src[1].f);
       }
 
-      inst->opcode = BRW_OPCODE_MOV;
-      inst->resize_sources(1);
-      progress = true;
       break;
 
    case BRW_OPCODE_ADD3:
@@ -165,11 +164,7 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
          const uint64_t src1 = src_as_uint(inst->src[1]);
          const uint64_t src2 = src_as_uint(inst->src[2]);
 
-         inst->opcode = BRW_OPCODE_MOV;
-         inst->src[0] = brw_imm_for_type(src0 + src1 + src2,
-                                         inst->dst.type);
-         inst->resize_sources(1);
-         progress = true;
+         result = brw_imm_for_type(src0 + src1 + src2, inst->dst.type);
       }
 
       break;
@@ -179,10 +174,7 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
          const uint64_t src0 = src_as_uint(inst->src[0]);
          const uint64_t src1 = src_as_uint(inst->src[1]);
 
-         inst->opcode = BRW_OPCODE_MOV;
-         inst->src[0] = brw_imm_for_type(src0 & src1, inst->dst.type);
-         inst->resize_sources(1);
-         progress = true;
+         result = brw_imm_for_type(src0 & src1, inst->dst.type);
          break;
       }
 
@@ -201,8 +193,7 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
          ASSERTED bool folded = brw_opt_constant_fold_instruction(devinfo, inst);
          assert(folded);
 
-         progress = true;
-         break;
+         return true;
       }
 
       break;
@@ -235,10 +226,7 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
          break;
 
       if (inst->src[0].is_zero() || inst->src[1].is_zero()) {
-         inst->opcode = BRW_OPCODE_MOV;
-         inst->src[0] = brw_imm_d(0);
-         inst->resize_sources(1);
-         progress = true;
+         result = brw_imm_d(0);
          break;
       }
 
@@ -246,10 +234,7 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
          const uint64_t src0 = src_as_uint(inst->src[0]);
          const uint64_t src1 = src_as_uint(inst->src[1]);
 
-         inst->opcode = BRW_OPCODE_MOV;
-         inst->src[0] = brw_imm_for_type(src0 * src1, inst->dst.type);
-         inst->resize_sources(1);
-         progress = true;
+         result = brw_imm_for_type(src0 * src1, inst->dst.type);
          break;
       }
       break;
@@ -259,10 +244,7 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
          const uint64_t src0 = src_as_uint(inst->src[0]);
          const uint64_t src1 = src_as_uint(inst->src[1]);
 
-         inst->opcode = BRW_OPCODE_MOV;
-         inst->src[0] = brw_imm_for_type(src0 | src1, inst->dst.type);
-         inst->resize_sources(1);
-         progress = true;
+         result = brw_imm_for_type(src0 | src1, inst->dst.type);
          break;
       }
 
@@ -275,8 +257,6 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
           */
          assert(!inst->saturate);
 
-         brw_reg result;
-
          switch (brw_type_size_bytes(inst->src[0].type)) {
          case 2:
             result = brw_imm_uw(0x0ffff & (inst->src[0].ud << (inst->src[1].ud & 0x1f)));
@@ -292,11 +272,7 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
             unreachable("Invalid source size.");
          }
 
-         inst->opcode = BRW_OPCODE_MOV;
-         inst->src[0] = retype(result, inst->dst.type);
-         inst->resize_sources(1);
-
-         progress = true;
+         result = retype(result, inst->dst.type);
       }
       break;
 
@@ -312,44 +288,40 @@ brw_opt_constant_fold_instruction(const intel_device_info *devinfo, brw_inst *in
           */
          inst->exec_size = 8 * reg_unit(devinfo);
          assert(inst->size_written == inst->dst.component_size(inst->exec_size));
-         progress = true;
+
+         return true;
       }
       break;
 
    case SHADER_OPCODE_SHUFFLE:
-      if (inst->src[0].file == IMM) {
-         inst->opcode = BRW_OPCODE_MOV;
-         inst->resize_sources(1);
-         progress = true;
-      }
+      if (inst->src[0].file == IMM)
+         result = inst->src[0];
+
       break;
 
    case FS_OPCODE_DDX_COARSE:
    case FS_OPCODE_DDX_FINE:
    case FS_OPCODE_DDY_COARSE:
    case FS_OPCODE_DDY_FINE:
-      if (is_uniform(inst->src[0]) || inst->src[0].is_scalar) {
-         inst->opcode = BRW_OPCODE_MOV;
-         inst->src[0] = retype(brw_imm_uq(0), inst->dst.type);
-         progress = true;
-      }
+      if (is_uniform(inst->src[0]) || inst->src[0].is_scalar)
+         result = retype(brw_imm_uq(0), inst->dst.type);
+
       break;
 
    default:
       break;
    }
 
-#ifndef NDEBUG
-   /* The function is only intended to do constant folding, so the result of
-    * progress must be a MOV of an immediate value.
-    */
-   if (progress) {
-      assert(inst->opcode == BRW_OPCODE_MOV);
-      assert(inst->src[0].file == IMM);
+   if (result.file != BAD_FILE) {
+      assert(result.file == IMM);
+
+      inst->opcode = BRW_OPCODE_MOV;
+      inst->src[0] = result;
+      inst->resize_sources(1);
+      return true;
    }
-#endif
 
-   return progress;
+   return false;
 }
 
 bool
@@ -517,6 +489,29 @@ brw_opt_algebraic(brw_shader &s)
             }
          }
          break;
+
+      case BRW_OPCODE_NOT:
+         /*    not.nz    null, g17
+          *
+          * becomes
+          *
+          *    mov.z     null, g17
+          *
+          * These are equivalent, but the latter is easier for cmod prop.
+          */
+         if (inst->dst.is_null() &&
+             inst->conditional_mod != BRW_CONDITIONAL_NONE) {
+            assert(!inst->src[0].abs);
+
+            if (!inst->src[0].negate)
+               inst->conditional_mod = brw_negate_cmod(inst->conditional_mod);
+
+            inst->opcode = BRW_OPCODE_MOV;
+            inst->src[0].negate = false;
+            progress = true;
+         }
+         break;
+
       case BRW_OPCODE_OR:
          if (inst->src[0].equals(inst->src[1]) || inst->src[1].is_zero()) {
             /* On Gfx8+, the OR instruction can have a source modifier that
diff --git a/src/intel/compiler/brw_opt_cmod_propagation.cpp b/src/intel/compiler/brw_opt_cmod_propagation.cpp
index 33f8ae85ae2..ab921662162 100644
--- a/src/intel/compiler/brw_opt_cmod_propagation.cpp
+++ b/src/intel/compiler/brw_opt_cmod_propagation.cpp
@@ -103,6 +103,17 @@ cmod_propagate_cmp_to_add(const intel_device_info *devinfo, brw_inst *inst)
          if (isinf(src_as_float(inst->src[1])) != 0)
             return false;
       }
+   } else {
+      /* This optimization can fail for integers.  For inputs a = 0x80000000,
+       * b = 4, int(0x80000000) < 4, but int(0x80000000) - 4 overflows and
+       * results in 0x7ffffffc.  that's not less than zero, so the flags get
+       * set differently than for (a < b).
+       *
+       * However, it is safe if the comparison is Z or NZ.
+       */
+      if (inst->conditional_mod != BRW_CONDITIONAL_Z &&
+          inst->conditional_mod != BRW_CONDITIONAL_NZ)
+         return false;
    }
 
    foreach_inst_in_block_reverse_starting_from(brw_inst, scan_inst, inst) {
@@ -179,9 +190,14 @@ cmod_propagate_cmp_to_add(const intel_device_info *devinfo, brw_inst *inst)
             : inst->conditional_mod;
 
          if (scan_inst->saturate) {
+            /* Note: Integer types can only have NZ or Z, so this path does
+             * not need to worry about integer handling.
+             */
             if (cond != BRW_CONDITIONAL_G)
                goto not_match;
 
+            assert(!brw_type_is_int(scan_inst->dst.type));
+
             if (inst->src[1].file != IMM)
                goto not_match;
 
@@ -216,74 +232,6 @@ cmod_propagate_cmp_to_add(const intel_device_info *devinfo, brw_inst *inst)
    return false;
 }
 
-/**
- * Propagate conditional modifiers from NOT instructions
- *
- * Attempt to convert sequences like
- *
- *    or(8)           g78<8,8,1>      g76<8,8,1>UD    g77<8,8,1>UD
- *    ...
- *    not.nz.f0(8)    null            g78<8,8,1>UD
- *
- * into
- *
- *    or.z.f0(8)      g78<8,8,1>      g76<8,8,1>UD    g77<8,8,1>UD
- */
-static bool
-cmod_propagate_not(const intel_device_info *devinfo, brw_inst *inst)
-{
-   const enum brw_conditional_mod cond = brw_negate_cmod(inst->conditional_mod);
-   bool read_flag = false;
-   const unsigned flags_written = inst->flags_written(devinfo);
-
-   if (cond != BRW_CONDITIONAL_Z && cond != BRW_CONDITIONAL_NZ)
-      return false;
-
-   foreach_inst_in_block_reverse_starting_from(brw_inst, scan_inst, inst) {
-      if (regions_overlap(scan_inst->dst, scan_inst->size_written,
-                          inst->src[0], inst->size_read(devinfo, 0))) {
-         if (scan_inst->opcode != BRW_OPCODE_OR &&
-             scan_inst->opcode != BRW_OPCODE_AND)
-            break;
-
-         if (scan_inst->predicate ||
-             !scan_inst->dst.is_contiguous() ||
-             scan_inst->dst.offset != inst->src[0].offset ||
-             scan_inst->exec_size != inst->exec_size)
-            break;
-
-         /* If the scan instruction writes a different flag register than the
-          * instruction we're trying to propagate from, bail.
-          *
-          * FINISHME: The second part of the condition may be too strong.
-          * Perhaps (scan_inst->flags_written() & flags_written) !=
-          * flags_written?
-          */
-         if (scan_inst->flags_written(devinfo) != 0 &&
-             scan_inst->flags_written(devinfo) != flags_written)
-            break;
-
-         if (scan_inst->can_do_cmod() &&
-             ((!read_flag && scan_inst->conditional_mod == BRW_CONDITIONAL_NONE) ||
-              scan_inst->conditional_mod == cond)) {
-            scan_inst->conditional_mod = cond;
-            scan_inst->flag_subreg = inst->flag_subreg;
-            inst->remove();
-            return true;
-         }
-         break;
-      }
-
-      if ((scan_inst->flags_written(devinfo) & flags_written) != 0)
-         break;
-
-      read_flag = read_flag ||
-                  (scan_inst->flags_read(devinfo) & flags_written) != 0;
-   }
-
-   return false;
-}
-
 static bool
 opt_cmod_propagation_local(const intel_device_info *devinfo, bblock_t *block)
 {
@@ -292,8 +240,7 @@ opt_cmod_propagation_local(const intel_device_info *devinfo, bblock_t *block)
    foreach_inst_in_block_reverse_safe(brw_inst, inst, block) {
       if ((inst->opcode != BRW_OPCODE_AND &&
            inst->opcode != BRW_OPCODE_CMP &&
-           inst->opcode != BRW_OPCODE_MOV &&
-           inst->opcode != BRW_OPCODE_NOT) ||
+           inst->opcode != BRW_OPCODE_MOV) ||
           inst->predicate != BRW_PREDICATE_NONE ||
           !inst->dst.is_null() ||
           (inst->src[0].file != VGRF && inst->src[0].file != ATTR &&
@@ -307,12 +254,10 @@ opt_cmod_propagation_local(const intel_device_info *devinfo, bblock_t *block)
           (inst->opcode != BRW_OPCODE_CMP || inst->src[1].is_zero()))
          continue;
 
-      /* Only an AND.NZ can be propagated.  Many AND.Z instructions are
-       * generated (for ir_unop_not in brw_shader::emit_bool_to_cond_code).
-       * Propagating those would require inverting the condition on the CMP.
-       * This changes both the flag value and the register destination of the
-       * CMP.  That result may be used elsewhere, so we can't change its value
-       * on a whim.
+      /* Only an AND.NZ can be propagated. Propagating AND.Z would require
+       * inverting the condition on the CMP. This changes both the flag value
+       * and the register destination of the CMP. That result may be used
+       * elsewhere, so we can't change its value on a whim.
        */
       if (inst->opcode == BRW_OPCODE_AND &&
           !(inst->src[1].is_one() &&
@@ -323,25 +268,14 @@ opt_cmod_propagation_local(const intel_device_info *devinfo, bblock_t *block)
       /* A CMP with a second source of zero can match with anything.  A CMP
        * with a second source that is not zero can only match with an ADD
        * instruction.
-       *
-       * Only apply this optimization to float-point sources.  It can fail for
-       * integers.  For inputs a = 0x80000000, b = 4, int(0x80000000) < 4, but
-       * int(0x80000000) - 4 overflows and results in 0x7ffffffc.  that's not
-       * less than zero, so the flags get set differently than for (a < b).
        */
       if (inst->opcode == BRW_OPCODE_CMP && !inst->src[1].is_zero()) {
-         if (brw_type_is_float(inst->src[0].type) &&
-             cmod_propagate_cmp_to_add(devinfo, inst))
+         if (cmod_propagate_cmp_to_add(devinfo, inst))
             progress = true;
 
          continue;
       }
 
-      if (inst->opcode == BRW_OPCODE_NOT) {
-         progress = cmod_propagate_not(devinfo, inst) || progress;
-         continue;
-      }
-
       bool read_flag = false;
       const unsigned flags_written = inst->flags_written(devinfo);
       foreach_inst_in_block_reverse_starting_from(brw_inst, scan_inst, inst) {
diff --git a/src/intel/compiler/brw_opt_copy_propagation.cpp b/src/intel/compiler/brw_opt_copy_propagation.cpp
index 34cba38115f..b37798f78ba 100644
--- a/src/intel/compiler/brw_opt_copy_propagation.cpp
+++ b/src/intel/compiler/brw_opt_copy_propagation.cpp
@@ -793,6 +793,12 @@ try_copy_propagate(brw_shader &s, brw_inst *inst,
        (reg_offset(inst->dst) % (REG_SIZE * reg_unit(devinfo))) != (reg_offset(entry->src) % (REG_SIZE * reg_unit(devinfo))))
       return false;
 
+   /* BFloat16 sources always must be packed and not scalars,
+    * so don't propagate those cases.
+    */
+   if (brw_type_is_bfloat(inst->src[arg].type) && entry_stride != 1)
+      return false;
+
    /*
     * Bail if the composition of both regions would be affected by the Xe2+
     * regioning restrictions that apply to integer types smaller than a dword.
@@ -1740,6 +1746,12 @@ try_copy_propagate_def(brw_shader &s,
        (reg_offset(inst->dst) % (REG_SIZE * reg_unit(devinfo))) != (reg_offset(val) % (REG_SIZE * reg_unit(devinfo))))
       return false;
 
+   /* BFloat16 sources always must be packed and not scalars,
+    * so don't propagate those cases.
+    */
+   if (brw_type_is_bfloat(inst->src[arg].type) && entry_stride != 1)
+      return false;
+
    /* The <8;8,0> regions used for FS attributes in multipolygon
     * dispatch mode could violate regioning restrictions, don't copy
     * propagate them in such cases.
diff --git a/src/intel/compiler/brw_shader.h b/src/intel/compiler/brw_shader.h
index d6f85638eaf..f317aaf79ad 100644
--- a/src/intel/compiler/brw_shader.h
+++ b/src/intel/compiler/brw_shader.h
@@ -295,6 +295,7 @@ void brw_assign_regs_trivial(brw_shader &s);
 bool brw_lower_3src_null_dest(brw_shader &s);
 bool brw_lower_alu_restrictions(brw_shader &s);
 bool brw_lower_barycentrics(brw_shader &s);
+bool brw_lower_bfloat_conversion(brw_shader &s, brw_inst *inst);
 bool brw_lower_constant_loads(brw_shader &s);
 bool brw_lower_csel(brw_shader &s);
 bool brw_lower_derivatives(brw_shader &s);
diff --git a/src/intel/compiler/elk/elk_compiler.c b/src/intel/compiler/elk/elk_compiler.c
index 75432e53a55..d0a39dde4e5 100644
--- a/src/intel/compiler/elk/elk_compiler.c
+++ b/src/intel/compiler/elk/elk_compiler.c
@@ -155,13 +155,21 @@ elk_get_compiler_config_value(const struct elk_compiler *compiler)
    insert_u64_bit(&config, compiler->precise_trig);
    bits++;
 
-   uint64_t mask = DEBUG_DISK_CACHE_MASK;
-   bits += util_bitcount64(mask);
-
-   u_foreach_bit64(bit, mask)
-      insert_u64_bit(&config, INTEL_DEBUG(1ULL << bit));
+   enum intel_debug_flag debug_bits[] = {
+      DEBUG_NO_DUAL_OBJECT_GS,
+      DEBUG_SPILL_FS,
+      DEBUG_SPILL_VEC4,
+      DEBUG_NO_COMPACTION,
+      DEBUG_DO32,
+      DEBUG_SOFT64,
+      DEBUG_NO_SEND_GATHER,
+   };
+   for (uint32_t i = 0; i < ARRAY_SIZE(debug_bits); i++) {
+      insert_u64_bit(&config, INTEL_DEBUG(debug_bits[i]));
+      bits++;
+   }
 
-   mask = SIMD_DISK_CACHE_MASK;
+   uint64_t mask = SIMD_DISK_CACHE_MASK;
    bits += util_bitcount64(mask);
 
    u_foreach_bit64(bit, mask)
diff --git a/src/intel/compiler/elk/elk_eu_compact.c b/src/intel/compiler/elk/elk_eu_compact.c
index a45283024f1..522a3f17eb0 100644
--- a/src/intel/compiler/elk/elk_eu_compact.c
+++ b/src/intel/compiler/elk/elk_eu_compact.c
@@ -1964,8 +1964,12 @@ elk_compact_instructions(struct elk_codegen *p, int start_offset,
       if (try_compact_instruction(&c, dst, &inst)) {
          compacted_count++;
 
-         if (INTEL_DEBUG(DEBUG_VS | DEBUG_GS | DEBUG_TCS |
-                         DEBUG_WM | DEBUG_CS | DEBUG_TES)) {
+         if (INTEL_DEBUG(DEBUG_VS) ||
+             INTEL_DEBUG(DEBUG_GS) ||
+             INTEL_DEBUG(DEBUG_TCS) ||
+             INTEL_DEBUG(DEBUG_WM) ||
+             INTEL_DEBUG(DEBUG_CS) ||
+             INTEL_DEBUG(DEBUG_TES)) {
             elk_inst uncompacted;
             uncompact_instruction(&c, &uncompacted, dst);
             if (memcmp(&saved, &uncompacted, sizeof(uncompacted))) {
diff --git a/src/intel/compiler/elk/elk_shader.cpp b/src/intel/compiler/elk/elk_shader.cpp
index 8b0fe866e37..affaf16eeed 100644
--- a/src/intel/compiler/elk/elk_shader.cpp
+++ b/src/intel/compiler/elk/elk_shader.cpp
@@ -76,6 +76,7 @@ elk_type_for_base_type(const struct glsl_type *type)
    case GLSL_TYPE_VOID:
    case GLSL_TYPE_ERROR:
    case GLSL_TYPE_COOPERATIVE_MATRIX:
+   case GLSL_TYPE_BFLOAT16:
       unreachable("not reached");
    }
 
diff --git a/src/intel/compiler/elk/elk_test_simd_selection.cpp b/src/intel/compiler/elk/elk_test_simd_selection.cpp
index 63fbb7624a7..98281e49d57 100644
--- a/src/intel/compiler/elk/elk_test_simd_selection.cpp
+++ b/src/intel/compiler/elk/elk_test_simd_selection.cpp
@@ -272,7 +272,7 @@ TEST_F(SIMDSelectionCS, SpillAtSIMD16)
 
 TEST_F(SIMDSelectionCS, EnvironmentVariable32)
 {
-   intel_debug |= DEBUG_DO32;
+   BITSET_SET(intel_debug, DEBUG_DO32);
 
    ASSERT_TRUE(elk_simd_should_compile(simd_state, SIMD8));
    elk_simd_mark_compiled(simd_state, SIMD8, not_spilled);
@@ -286,7 +286,7 @@ TEST_F(SIMDSelectionCS, EnvironmentVariable32)
 
 TEST_F(SIMDSelectionCS, EnvironmentVariable32ButSpills)
 {
-   intel_debug |= DEBUG_DO32;
+   BITSET_SET(intel_debug, DEBUG_DO32);
 
    ASSERT_TRUE(elk_simd_should_compile(simd_state, SIMD8));
    elk_simd_mark_compiled(simd_state, SIMD8, not_spilled);
diff --git a/src/intel/compiler/elk/elk_vec4_visitor.cpp b/src/intel/compiler/elk/elk_vec4_visitor.cpp
index b79bf91a612..f5eb25be279 100644
--- a/src/intel/compiler/elk/elk_vec4_visitor.cpp
+++ b/src/intel/compiler/elk/elk_vec4_visitor.cpp
@@ -574,6 +574,7 @@ elk_type_size_xvec4(const struct glsl_type *type, bool as_vec4, bool bindless)
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
+   case GLSL_TYPE_BFLOAT16:
    case GLSL_TYPE_BOOL:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_UINT16:
diff --git a/src/intel/compiler/meson.build b/src/intel/compiler/meson.build
index e8580c8824c..877d7bc0fb1 100644
--- a/src/intel/compiler/meson.build
+++ b/src/intel/compiler/meson.build
@@ -74,7 +74,6 @@ libintel_compiler_brw_files = files(
   'brw_nir_lower_intersection_shader.c',
   'brw_nir_lower_ray_queries.c',
   'brw_nir_lower_rt_intrinsics.c',
-  'brw_nir_lower_rt_intrinsics_pre_trace.c',
   'brw_nir_lower_sample_index_in_coord.c',
   'brw_nir_lower_shader_calls.c',
   'brw_nir_lower_storage_image.c',
diff --git a/src/intel/compiler/test_opt_cmod_propagation.cpp b/src/intel/compiler/test_opt_cmod_propagation.cpp
index 463606d8482..f99e614dc04 100644
--- a/src/intel/compiler/test_opt_cmod_propagation.cpp
+++ b/src/intel/compiler/test_opt_cmod_propagation.cpp
@@ -2007,6 +2007,8 @@ TEST_F(cmod_propagation_test, not_to_or)
     * 0: or.z.f0(8)    dest  src0  src1
     */
 
+   EXPECT_NO_PROGRESS(brw_opt_cmod_propagation, bld);
+   EXPECT_PROGRESS(brw_opt_algebraic, bld);
    EXPECT_PROGRESS(brw_opt_cmod_propagation, bld);
 
    exp.OR(dest, src0, src1)->conditional_mod = BRW_CONDITIONAL_Z;
@@ -2029,6 +2031,8 @@ TEST_F(cmod_propagation_test, not_to_and)
    bld.AND(dest, src0, src1);
    bld.NOT(bld.null_reg_ud(), dest)->conditional_mod = BRW_CONDITIONAL_NZ;
 
+   EXPECT_NO_PROGRESS(brw_opt_cmod_propagation, bld);
+   EXPECT_PROGRESS(brw_opt_algebraic, bld);
    EXPECT_PROGRESS(brw_opt_cmod_propagation, bld);
 
    exp.AND(dest, src0, src1)->conditional_mod = BRW_CONDITIONAL_Z;
@@ -2124,6 +2128,8 @@ TEST_F(cmod_propagation_test, not_to_or_intervening_flag_read_compatible_value)
    set_predicate(BRW_PREDICATE_NORMAL, bld.SEL(dest1, src2, zero));
    set_condmod(BRW_CONDITIONAL_NZ,     bld.NOT(bld.null_reg_ud(), dest0));
 
+   EXPECT_NO_PROGRESS(brw_opt_cmod_propagation, bld);
+   EXPECT_PROGRESS(brw_opt_algebraic, bld);
    EXPECT_PROGRESS(brw_opt_cmod_propagation, bld);
 
    set_condmod(BRW_CONDITIONAL_Z,      exp.OR(dest0, src0, src1));
@@ -2197,6 +2203,8 @@ TEST_F(cmod_propagation_test, not_to_or_intervening_mismatch_flag_write)
       ->flag_subreg = 1;
    set_condmod(BRW_CONDITIONAL_NZ, bld.NOT(bld.null_reg_ud(), dest0));
 
+   EXPECT_NO_PROGRESS(brw_opt_cmod_propagation, bld);
+   EXPECT_PROGRESS(brw_opt_algebraic, bld);
    EXPECT_PROGRESS(brw_opt_cmod_propagation, bld);
 
    set_condmod(BRW_CONDITIONAL_Z, exp.OR(dest0, src0, src1));
@@ -2227,6 +2235,8 @@ TEST_F(cmod_propagation_test, not_to_or_intervening_mismatch_flag_read)
       ->flag_subreg = 1;
    set_condmod(BRW_CONDITIONAL_NZ, bld.NOT(bld.null_reg_ud(), dest0));
 
+   EXPECT_NO_PROGRESS(brw_opt_cmod_propagation, bld);
+   EXPECT_PROGRESS(brw_opt_algebraic, bld);
    EXPECT_PROGRESS(brw_opt_cmod_propagation, bld);
 
    exp.OR(dest0, src0, src1)->conditional_mod = BRW_CONDITIONAL_Z;
diff --git a/src/intel/compiler/test_simd_selection.cpp b/src/intel/compiler/test_simd_selection.cpp
index 462d922607f..f59238bf734 100644
--- a/src/intel/compiler/test_simd_selection.cpp
+++ b/src/intel/compiler/test_simd_selection.cpp
@@ -272,7 +272,7 @@ TEST_F(SIMDSelectionCS, SpillAtSIMD16)
 
 TEST_F(SIMDSelectionCS, EnvironmentVariable32)
 {
-   intel_debug |= DEBUG_DO32;
+   BITSET_SET(intel_debug, DEBUG_DO32);
 
    ASSERT_TRUE(brw_simd_should_compile(simd_state, SIMD8));
    brw_simd_mark_compiled(simd_state, SIMD8, not_spilled);
@@ -286,7 +286,7 @@ TEST_F(SIMDSelectionCS, EnvironmentVariable32)
 
 TEST_F(SIMDSelectionCS, EnvironmentVariable32ButSpills)
 {
-   intel_debug |= DEBUG_DO32;
+   BITSET_SET(intel_debug, DEBUG_DO32);
 
    ASSERT_TRUE(brw_simd_should_compile(simd_state, SIMD8));
    brw_simd_mark_compiled(simd_state, SIMD8, not_spilled);
diff --git a/src/intel/dev/intel_debug.c b/src/intel/dev/intel_debug.c
index 41c36e3b52d..e10759dfdbd 100644
--- a/src/intel/dev/intel_debug.c
+++ b/src/intel/dev/intel_debug.c
@@ -39,88 +39,93 @@
 #include "util/u_math.h"
 #include "c11/threads.h"
 
-uint64_t intel_debug = 0;
-
-#define DEBUG_NO16                (1ull << 16)
-#define DEBUG_NO8                 (1ull << 20)
-#define DEBUG_NO32                (1ull << 39)
-
-static const struct debug_control debug_control[] = {
-   { "tex",         DEBUG_TEXTURE},
-   { "blit",        DEBUG_BLIT},
-   { "fall",        DEBUG_PERF},
-   { "perf",        DEBUG_PERF},
-   { "perfmon",     DEBUG_PERFMON},
-   { "bat",         DEBUG_BATCH},
-   { "buf",         DEBUG_BUFMGR},
-   { "fs",          DEBUG_WM },
-   { "gs",          DEBUG_GS},
-   { "sync",        DEBUG_SYNC},
-   { "sf",          DEBUG_SF },
-   { "submit",      DEBUG_SUBMIT },
-   { "wm",          DEBUG_WM },
-   { "urb",         DEBUG_URB },
-   { "vs",          DEBUG_VS },
-   { "clip",        DEBUG_CLIP },
-   { "no16",        DEBUG_NO16 },
-   { "blorp",       DEBUG_BLORP },
-   { "nodualobj",   DEBUG_NO_DUAL_OBJECT_GS },
-   { "optimizer",   DEBUG_OPTIMIZER },
-   { "ann",         DEBUG_ANNOTATION },
-   { "no8",         DEBUG_NO8 },
-   { "no-oaconfig", DEBUG_NO_OACONFIG },
-   { "spill_fs",    DEBUG_SPILL_FS },
-   { "spill_vec4",  DEBUG_SPILL_VEC4 },
-   { "cs",          DEBUG_CS },
-   { "hex",         DEBUG_HEX },
-   { "nocompact",   DEBUG_NO_COMPACTION },
-   { "hs",          DEBUG_TCS },
-   { "tcs",         DEBUG_TCS },
-   { "ds",          DEBUG_TES },
-   { "tes",         DEBUG_TES },
-   { "l3",          DEBUG_L3 },
-   { "do32",        DEBUG_DO32 },
-   { "norbc",       DEBUG_NO_CCS },
-   { "noccs",       DEBUG_NO_CCS },
-   { "nohiz",       DEBUG_NO_HIZ },
-   { "color",       DEBUG_COLOR },
-   { "reemit",      DEBUG_REEMIT },
-   { "soft64",      DEBUG_SOFT64 },
-   { "bt",          DEBUG_BT },
-   { "pc",          DEBUG_PIPE_CONTROL },
-   { "nofc",        DEBUG_NO_FAST_CLEAR },
-   { "no32",        DEBUG_NO32 },
-   { "shaders",     DEBUG_WM | DEBUG_VS | DEBUG_TCS |
-                    DEBUG_TES | DEBUG_GS | DEBUG_CS |
-                    DEBUG_RT | DEBUG_TASK | DEBUG_MESH },
-   { "rt",          DEBUG_RT },
-   { "rt_notrace",  DEBUG_RT_NO_TRACE},
-   { "bvh_blas",    DEBUG_BVH_BLAS},
-   { "bvh_tlas",    DEBUG_BVH_TLAS},
-   { "bvh_blas_ir_hdr", DEBUG_BVH_BLAS_IR_HDR},
-   { "bvh_tlas_ir_hdr", DEBUG_BVH_TLAS_IR_HDR},
-   { "bvh_blas_ir_as",  DEBUG_BVH_BLAS_IR_AS},
-   { "bvh_tlas_ir_as",  DEBUG_BVH_TLAS_IR_AS},
-   { "bvh_no_build",    DEBUG_BVH_NO_BUILD},
-   { "task",        DEBUG_TASK },
-   { "mesh",        DEBUG_MESH },
-   { "stall",       DEBUG_STALL },
-   { "capture-all", DEBUG_CAPTURE_ALL },
-   { "perf-symbol-names", DEBUG_PERF_SYMBOL_NAMES },
-   { "swsb-stall",  DEBUG_SWSB_STALL },
-   { "heaps",       DEBUG_HEAPS },
-   { "isl",         DEBUG_ISL },
-   { "sparse",      DEBUG_SPARSE },
-   { "draw_bkp",    DEBUG_DRAW_BKP },
-   { "bat-stats",   DEBUG_BATCH_STATS },
-   { "reg-pressure", DEBUG_REG_PRESSURE },
-   { "shader-print", DEBUG_SHADER_PRINT },
-   { "cl-quiet",     DEBUG_CL_QUIET },
-   { "no-send-gather", DEBUG_NO_SEND_GATHER },
-   { "shaders-lineno", DEBUG_SHADERS_LINENO },
-   { NULL,    0 }
+BITSET_WORD intel_debug[BITSET_WORDS(INTEL_DEBUG_MAX)] = {0};
+
+struct debug_control_bitset {
+   const char *string;
+   uint32_t range[2];
 };
 
+static const struct debug_control_bitset debug_control[] = {
+#define OPT1(name, bit) \
+   { .string = name, .range = { bit, bit }, }
+#define OPT2(name, start, end) \
+   { .string = name, .range = { start, end }, }
+   OPT1("tex",               DEBUG_TEXTURE),
+   OPT1("blit",              DEBUG_BLIT),
+   OPT1("fall",              DEBUG_PERF),
+   OPT1("perf",              DEBUG_PERF),
+   OPT1("perfmon",           DEBUG_PERFMON),
+   OPT1("bat",               DEBUG_BATCH),
+   OPT1("buf",               DEBUG_BUFMGR),
+   OPT1("fs",                DEBUG_WM),
+   OPT1("gs",                DEBUG_GS),
+   OPT1("sync",              DEBUG_SYNC),
+   OPT1("sf",                DEBUG_SF),
+   OPT1("submit",            DEBUG_SUBMIT),
+   OPT1("wm",                DEBUG_WM),
+   OPT1("urb",               DEBUG_URB),
+   OPT1("vs",                DEBUG_VS),
+   OPT1("clip",              DEBUG_CLIP),
+   OPT1("no16",              DEBUG_NO16),
+   OPT1("blorp",             DEBUG_BLORP),
+   OPT1("nodualobj",         DEBUG_NO_DUAL_OBJECT_GS),
+   OPT1("optimizer",         DEBUG_OPTIMIZER),
+   OPT1("ann",               DEBUG_ANNOTATION),
+   OPT1("no8",               DEBUG_NO8),
+   OPT1("no-oaconfig",       DEBUG_NO_OACONFIG),
+   OPT1("spill_fs",          DEBUG_SPILL_FS),
+   OPT1("spill_vec4",        DEBUG_SPILL_VEC4),
+   OPT1("cs",                DEBUG_CS),
+   OPT1("hex",               DEBUG_HEX),
+   OPT1("nocompact",         DEBUG_NO_COMPACTION),
+   OPT1("hs",                DEBUG_TCS),
+   OPT1("tcs",               DEBUG_TCS),
+   OPT1("ds",                DEBUG_TES),
+   OPT1("tes",               DEBUG_TES),
+   OPT1("l3",                DEBUG_L3),
+   OPT1("do32",              DEBUG_DO32),
+   OPT1("norbc",             DEBUG_NO_CCS),
+   OPT1("noccs",             DEBUG_NO_CCS),
+   OPT1("nohiz",             DEBUG_NO_HIZ),
+   OPT1("color",             DEBUG_COLOR),
+   OPT1("reemit",            DEBUG_REEMIT),
+   OPT1("soft64",            DEBUG_SOFT64),
+   OPT1("bt",                DEBUG_BT),
+   OPT1("pc",                DEBUG_PIPE_CONTROL),
+   OPT1("nofc",              DEBUG_NO_FAST_CLEAR),
+   OPT1("no32",              DEBUG_NO32),
+   OPT2("shaders",           DEBUG_VS, DEBUG_RT),
+   OPT1("rt",                DEBUG_RT),
+   OPT1("rt_notrace",        DEBUG_RT_NO_TRACE),
+   OPT1("bvh_blas",          DEBUG_BVH_BLAS),
+   OPT1("bvh_tlas",          DEBUG_BVH_TLAS),
+   OPT1("bvh_blas_ir_hdr",   DEBUG_BVH_BLAS_IR_HDR),
+   OPT1("bvh_tlas_ir_hdr",   DEBUG_BVH_TLAS_IR_HDR),
+   OPT1("bvh_blas_ir_as",    DEBUG_BVH_BLAS_IR_AS),
+   OPT1("bvh_tlas_ir_as",    DEBUG_BVH_TLAS_IR_AS),
+   OPT1("bvh_no_build",      DEBUG_BVH_NO_BUILD),
+   OPT1("task",              DEBUG_TASK),
+   OPT1("mesh",              DEBUG_MESH),
+   OPT1("stall",             DEBUG_STALL),
+   OPT1("capture-all",       DEBUG_CAPTURE_ALL),
+   OPT1("perf-symbol-names", DEBUG_PERF_SYMBOL_NAMES),
+   OPT1("swsb-stall",        DEBUG_SWSB_STALL),
+   OPT1("heaps",             DEBUG_HEAPS),
+   OPT1("isl",               DEBUG_ISL),
+   OPT1("sparse",            DEBUG_SPARSE),
+   OPT1("draw_bkp",          DEBUG_DRAW_BKP),
+   OPT1("bat-stats",         DEBUG_BATCH_STATS),
+   OPT1("reg-pressure",      DEBUG_REG_PRESSURE),
+   OPT1("shader-print",      DEBUG_SHADER_PRINT),
+   OPT1("cl-quiet",          DEBUG_CL_QUIET),
+   OPT1("no-send-gather",    DEBUG_NO_SEND_GATHER),
+   OPT1("shaders-lineno",    DEBUG_SHADERS_LINENO),
+   OPT1("show_shader_stage", DEBUG_SHOW_SHADER_STAGE),
+   { NULL, }
+#undef OPT1
+#undef OPT2
+};
 uint64_t intel_simd = 0;
 
 static const struct debug_control simd_control[] = {
@@ -204,10 +209,46 @@ uint64_t intel_debug_batch_frame_stop = -1;
 uint32_t intel_debug_bkp_before_draw_count = 0;
 uint32_t intel_debug_bkp_after_draw_count = 0;
 
+static void
+parse_debug_bitset(const char *env, const struct debug_control_bitset *tbl)
+{
+   /* Check if env is NULL or empty */
+   if (!env || !*env)
+      return;
+
+   char *copy = strdup(env);
+   if (!copy)
+      return;
+
+   /* Tokenize the string by space or comma */
+   for (char *tok = strtok(copy, ", "); tok; tok = strtok(NULL, ", ")) {
+      /* Check for negation prefix, useful if user would like to disable certian flags */
+      bool negate = (*tok == '~' || *tok == '-');
+      if (negate)
+         tok++;
+
+      for (unsigned i = 0; tbl[i].string; i++) {
+         if (strcasecmp(tok, tbl[i].string) != 0)
+            continue;
+
+         for (unsigned bit = tbl[i].range[0]; bit <= tbl[i].range[1]; bit++) {
+            if (negate)
+               BITSET_CLEAR(intel_debug, bit);
+            else
+               BITSET_SET(intel_debug, bit);
+         }
+         break;
+      }
+   }
+   free(copy);
+}
+
 static void
 process_intel_debug_variable_once(void)
 {
-   intel_debug = parse_debug_string(getenv("INTEL_DEBUG"), debug_control);
+   BITSET_ZERO(intel_debug);
+   parse_debug_bitset(getenv("INTEL_DEBUG"), debug_control);
+
    intel_simd = parse_debug_string(getenv("INTEL_SIMD_DEBUG"), simd_control);
    intel_debug_batch_frame_start =
       debug_get_num_option("INTEL_DEBUG_BATCH_FRAME_START", 0);
@@ -230,13 +271,18 @@ process_intel_debug_variable_once(void)
    if (!(intel_simd & DEBUG_RT_SIMD))
       intel_simd |=   DEBUG_RT_SIMD;
 
-   if (intel_debug & DEBUG_NO8)
+   if (BITSET_TEST(intel_debug, DEBUG_NO8))
       intel_simd &= ~DEBUG_SIMD8_ALL;
-   if (intel_debug & DEBUG_NO16)
+
+   if (BITSET_TEST(intel_debug, DEBUG_NO16))
       intel_simd &= ~DEBUG_SIMD16_ALL;
-   if (intel_debug & DEBUG_NO32)
+
+   if (BITSET_TEST(intel_debug, DEBUG_NO32))
       intel_simd &= ~DEBUG_SIMD32_ALL;
-   intel_debug &= ~(DEBUG_NO8 | DEBUG_NO16 | DEBUG_NO32);
+
+   BITSET_CLEAR(intel_debug, DEBUG_NO8);
+   BITSET_CLEAR(intel_debug, DEBUG_NO16);
+   BITSET_CLEAR(intel_debug, DEBUG_NO32);
 }
 
 void
diff --git a/src/intel/dev/intel_debug.h b/src/intel/dev/intel_debug.h
index bc97b71498e..b861dfe51b1 100644
--- a/src/intel/dev/intel_debug.h
+++ b/src/intel/dev/intel_debug.h
@@ -28,6 +28,7 @@
 
 #include <stdint.h>
 #include "compiler/shader_enums.h"
+#include "util/bitset.h"
 #include "util/macros.h"
 
 #ifdef __cplusplus
@@ -40,92 +41,95 @@ extern "C" {
  * list of debugging flags, as well as some macros for handling them.
  */
 
-extern uint64_t intel_debug;
-
-/* Returns 0/1, not the matching bit mask. */
-#define INTEL_DEBUG(flags)        unlikely(intel_debug & (flags))
-
-#define DEBUG_TEXTURE             (1ull <<  0)
-#define DEBUG_BLIT                (1ull <<  1)
-#define DEBUG_PERF                (1ull <<  2)
-#define DEBUG_PERFMON             (1ull <<  3)
-#define DEBUG_BATCH               (1ull <<  4)
-#define DEBUG_BUFMGR              (1ull <<  5)
-#define DEBUG_GS                  (1ull <<  6)
-#define DEBUG_SYNC                (1ull <<  7)
-#define DEBUG_SF                  (1ull <<  8)
-#define DEBUG_SUBMIT              (1ull <<  9)
-#define DEBUG_WM                  (1ull << 10)
-#define DEBUG_URB                 (1ull << 11)
-#define DEBUG_VS                  (1ull << 12)
-#define DEBUG_CLIP                (1ull << 13)
-#define DEBUG_STALL               (1ull << 14)
-#define DEBUG_BLORP               (1ull << 15)
-/* reserved                       (1ull << 16) */
-#define DEBUG_NO_DUAL_OBJECT_GS   (1ull << 17)
-#define DEBUG_OPTIMIZER           (1ull << 18)
-#define DEBUG_ANNOTATION          (1ull << 19)
-/* reserved                       (1ull << 20) */
-#define DEBUG_NO_OACONFIG         (1ull << 21)
-#define DEBUG_SPILL_FS            (1ull << 22)
-#define DEBUG_SPILL_VEC4          (1ull << 23)
-#define DEBUG_CS                  (1ull << 24)
-#define DEBUG_HEX                 (1ull << 25)
-#define DEBUG_NO_COMPACTION       (1ull << 26)
-#define DEBUG_TCS                 (1ull << 27)
-#define DEBUG_TES                 (1ull << 28)
-#define DEBUG_L3                  (1ull << 29)
-#define DEBUG_DO32                (1ull << 30)
-#define DEBUG_NO_CCS              (1ull << 31)
-#define DEBUG_NO_HIZ              (1ull << 32)
-#define DEBUG_COLOR               (1ull << 33)
-#define DEBUG_REEMIT              (1ull << 34)
-#define DEBUG_SOFT64              (1ull << 35)
-#define DEBUG_BT                  (1ull << 36)
-#define DEBUG_PIPE_CONTROL        (1ull << 37)
-#define DEBUG_NO_FAST_CLEAR       (1ull << 38)
-/* reserved                       (1ull << 39) */
-#define DEBUG_RT                  (1ull << 40)
-#define DEBUG_TASK                (1ull << 41)
-#define DEBUG_MESH                (1ull << 42)
-#define DEBUG_CAPTURE_ALL         (1ull << 43)
-#define DEBUG_PERF_SYMBOL_NAMES   (1ull << 44)
-#define DEBUG_SWSB_STALL          (1ull << 45)
-#define DEBUG_HEAPS               (1ull << 46)
-#define DEBUG_ISL                 (1ull << 47)
-#define DEBUG_SPARSE              (1ull << 48)
-#define DEBUG_DRAW_BKP            (1ull << 49)
-#define DEBUG_BATCH_STATS         (1ull << 50)
-#define DEBUG_REG_PRESSURE        (1ull << 51)
-#define DEBUG_SHADER_PRINT        (1ull << 52)
-#define DEBUG_CL_QUIET            (1ull << 53)
-#define DEBUG_BVH_BLAS            (1ull << 54)
-#define DEBUG_BVH_TLAS            (1ull << 55)
-#define DEBUG_BVH_BLAS_IR_HDR     (1ull << 56)
-#define DEBUG_BVH_TLAS_IR_HDR     (1ull << 57)
-#define DEBUG_BVH_BLAS_IR_AS      (1ull << 58)
-#define DEBUG_BVH_TLAS_IR_AS      (1ull << 59)
-#define DEBUG_BVH_NO_BUILD        (1ull << 60)
-#define DEBUG_NO_SEND_GATHER      (1ull << 61)
-#define DEBUG_RT_NO_TRACE         (1ull << 62)
-#define DEBUG_SHADERS_LINENO      (1ull << 63)
-
-#define DEBUG_ANY                 (~0ull)
+enum intel_debug_flag {
+   DEBUG_TEXTURE = 0,
+   DEBUG_BLIT,
+   DEBUG_PERF,
+   DEBUG_PERFMON,
+   DEBUG_BATCH,
+   DEBUG_BUFMGR,
+   DEBUG_SYNC,
+   DEBUG_SF,
+   DEBUG_SUBMIT,
+   DEBUG_URB,
+   DEBUG_CLIP,
+   DEBUG_STALL,
+   DEBUG_BLORP,
+   DEBUG_NO_DUAL_OBJECT_GS,
+   DEBUG_OPTIMIZER,
+   DEBUG_ANNOTATION,
+   DEBUG_NO_OACONFIG,
+   DEBUG_SPILL_FS,
+   DEBUG_SPILL_VEC4,
+   DEBUG_HEX,
+   DEBUG_NO_COMPACTION,
+   DEBUG_L3,
+   DEBUG_NO_CCS,
+   DEBUG_NO_HIZ,
+   DEBUG_COLOR,
+   DEBUG_REEMIT,
+   DEBUG_SOFT64,
+   DEBUG_BT,
+   DEBUG_PIPE_CONTROL,
+   DEBUG_NO_FAST_CLEAR,
+   DEBUG_CAPTURE_ALL,
+   DEBUG_PERF_SYMBOL_NAMES,
+   DEBUG_SWSB_STALL,
+   DEBUG_HEAPS,
+   DEBUG_ISL,
+   DEBUG_SPARSE,
+   DEBUG_DRAW_BKP,
+   DEBUG_BATCH_STATS,
+   DEBUG_REG_PRESSURE,
+   DEBUG_SHADER_PRINT,
+   DEBUG_CL_QUIET,
+   DEBUG_BVH_BLAS,
+   DEBUG_BVH_TLAS,
+   DEBUG_BVH_BLAS_IR_HDR,
+   DEBUG_BVH_TLAS_IR_HDR,
+   DEBUG_BVH_BLAS_IR_AS,
+   DEBUG_BVH_TLAS_IR_AS,
+   DEBUG_BVH_NO_BUILD,
+   DEBUG_NO_SEND_GATHER,
+   DEBUG_RT_NO_TRACE,
+   DEBUG_SHADERS_LINENO,
+   DEBUG_SHOW_SHADER_STAGE,
+   /* Keep the stages grouped */
+   DEBUG_VS,
+   DEBUG_TCS,
+   DEBUG_TES,
+   DEBUG_GS,
+   DEBUG_WM,
+   DEBUG_TASK,
+   DEBUG_MESH,
+   DEBUG_CS,
+   DEBUG_RT,
+   DEBUG_NO8,
+
+   DEBUG_NO16,
+   DEBUG_NO32,
+   DEBUG_DO32,
+
+   /* Must be the last entry */
+   INTEL_DEBUG_MAX,
+};
+
+extern BITSET_WORD intel_debug[BITSET_WORDS(INTEL_DEBUG_MAX)];
+
+
+/* Check if a debug flag is enabled by testing its bit position */
+#define INTEL_DEBUG(flag) unlikely(BITSET_TEST(intel_debug, (flag)))
 
 /* These flags are not compatible with the disk shader cache */
 #define DEBUG_DISK_CACHE_DISABLE_MASK 0
 
-/* These flags may affect program generation */
-#define DEBUG_DISK_CACHE_MASK \
-   (DEBUG_NO_DUAL_OBJECT_GS | DEBUG_SPILL_FS | \
-   DEBUG_SPILL_VEC4 | DEBUG_NO_COMPACTION | DEBUG_DO32 | DEBUG_SOFT64 | \
-   DEBUG_NO_SEND_GATHER)
-
 /* Flags to determine what bvh to dump out */
-#define DEBUG_BVH_ANV (DEBUG_BVH_BLAS | DEBUG_BVH_TLAS)
-#define DEBUG_BVH_IR_HDR (DEBUG_BVH_BLAS_IR_HDR | DEBUG_BVH_TLAS_IR_HDR)
-#define DEBUG_BVH_IR_AS (DEBUG_BVH_BLAS_IR_AS | DEBUG_BVH_TLAS_IR_AS)
-#define DEBUG_BVH_ANY (DEBUG_BVH_ANV | DEBUG_BVH_IR_HDR | DEBUG_BVH_IR_AS)
+#define INTEL_DEBUG_BVH_ANY (unlikely(INTEL_DEBUG(DEBUG_BVH_BLAS) ||    \
+                                      INTEL_DEBUG(DEBUG_BVH_TLAS) ||    \
+                                      INTEL_DEBUG(DEBUG_BVH_BLAS_IR_HDR) || \
+                                      INTEL_DEBUG(DEBUG_BVH_TLAS_IR_HDR) || \
+                                      INTEL_DEBUG(DEBUG_BVH_BLAS_IR_AS) || \
+                                      INTEL_DEBUG(DEBUG_BVH_TLAS_IR_AS)))
 
 extern uint64_t intel_simd;
 extern uint32_t intel_debug_bkp_before_draw_count;
diff --git a/src/intel/dev/intel_device_info.c b/src/intel/dev/intel_device_info.c
index 5265ce4bb74..bb850cd14a5 100644
--- a/src/intel/dev/intel_device_info.c
+++ b/src/intel/dev/intel_device_info.c
@@ -521,17 +521,36 @@ static const struct intel_device_info intel_device_info_chv = {
    .simulator_id = 13,
 };
 
+#define CMAT_PRE_XEHP_CONFIGURATIONS                                                                                            \
+   .cooperative_matrix_configurations = {                                                                                       \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT32, INTEL_CMAT_FLOAT32 },    \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 32, INTEL_CMAT_SINT8, INTEL_CMAT_SINT8, INTEL_CMAT_SINT32, INTEL_CMAT_SINT32 },          \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 32, INTEL_CMAT_UINT8, INTEL_CMAT_UINT8, INTEL_CMAT_UINT32, INTEL_CMAT_UINT32 },          \
+   }
+
+#define CMAT_XEHP_CONFIGURATIONS                                                                                                \
+   .cooperative_matrix_configurations = {                                                                                       \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT32, INTEL_CMAT_FLOAT32 },    \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 16, INTEL_CMAT_BFLOAT16, INTEL_CMAT_BFLOAT16, INTEL_CMAT_FLOAT32, INTEL_CMAT_FLOAT32 },  \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 32, INTEL_CMAT_SINT8, INTEL_CMAT_SINT8, INTEL_CMAT_SINT32, INTEL_CMAT_SINT32 },          \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 32, INTEL_CMAT_UINT8, INTEL_CMAT_UINT8, INTEL_CMAT_UINT32, INTEL_CMAT_UINT32 },          \
+   }
+
+#define CMAT_XE2_CONFIGURATIONS                                                                                                 \
+   .cooperative_matrix_configurations = {                                                                                       \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 16, 16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT32, INTEL_CMAT_FLOAT32 },   \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 16, 16, INTEL_CMAT_BFLOAT16, INTEL_CMAT_BFLOAT16, INTEL_CMAT_FLOAT32, INTEL_CMAT_FLOAT32 }, \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 16, 32, INTEL_CMAT_SINT8, INTEL_CMAT_SINT8, INTEL_CMAT_SINT32, INTEL_CMAT_SINT32 },         \
+    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 16, 32, INTEL_CMAT_UINT8, INTEL_CMAT_UINT8, INTEL_CMAT_UINT32, INTEL_CMAT_UINT32 },         \
+   }
+
 #define GFX9_FEATURES                               \
    GFX8_FEATURES,                                   \
+   CMAT_PRE_XEHP_CONFIGURATIONS,                    \
    .ver = 9,                                        \
    .has_sample_with_hiz = true,                     \
    .has_illegal_ccs_values = true,                  \
-   .timestamp_frequency = 12000000,                 \
-   .cooperative_matrix_configurations = {           \
-    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT32, INTEL_CMAT_FLOAT32 }, \
-    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 32, INTEL_CMAT_SINT8, INTEL_CMAT_SINT8, INTEL_CMAT_SINT32, INTEL_CMAT_SINT32 },       \
-    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 8, 32, INTEL_CMAT_UINT8, INTEL_CMAT_UINT8, INTEL_CMAT_UINT32, INTEL_CMAT_UINT32 },       \
-   }
+   .timestamp_frequency = 12000000
 
 #define GFX9_MAX_THREADS                            \
    .max_vs_threads = 336,                           \
@@ -1034,6 +1053,7 @@ static const struct intel_device_info intel_device_info_sg1 = {
 
 #define XEHP_FEATURES                                           \
    GFX12_FEATURES,                                              \
+   CMAT_XEHP_CONFIGURATIONS,                                    \
    .verx10 = 125,                                               \
    .has_lsc = true,                                             \
    .has_llc = false,                                            \
@@ -1102,6 +1122,7 @@ static const struct intel_device_info intel_device_info_atsm_g11 = {
 
 #define MTL_CONFIG(platform_suffix)                             \
    XEHP_FEATURES, XEHP_PLACEHOLDER_THREADS_AND_URB,             \
+   CMAT_PRE_XEHP_CONFIGURATIONS,                                \
    .platform = INTEL_PLATFORM_ ## platform_suffix,              \
    .has_64bit_float = true,                                     \
    .has_64bit_float_via_math_pipe = true,                       \
@@ -1137,10 +1158,12 @@ static const struct intel_device_info intel_device_info_arl_h = {
    .has_bfloat16 = true,
    /* BSpec 55414 (r53716). */
    .has_systolic = true,
+   CMAT_XEHP_CONFIGURATIONS,
 };
 
 #define XE2_FEATURES                                            \
    XEHP_FEATURES,                                               \
+   CMAT_XE2_CONFIGURATIONS,                                     \
    .ver = 20,                                                   \
    .verx10 = 200,                                               \
    .grf_size = 64,                                              \
@@ -1149,13 +1172,14 @@ static const struct intel_device_info intel_device_info_arl_h = {
    .has_64bit_int = true,                                       \
    .has_indirect_unroll = true,                                 \
    .has_aux_map = false,                                        \
-   .has_flat_ccs = true,                                        \
-   .cooperative_matrix_configurations = {                       \
-    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 16, 16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT16, INTEL_CMAT_FLOAT32, INTEL_CMAT_FLOAT32 }, \
-    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 16, 32, INTEL_CMAT_SINT8, INTEL_CMAT_SINT8, INTEL_CMAT_SINT32, INTEL_CMAT_SINT32 },       \
-    { INTEL_CMAT_SCOPE_SUBGROUP, 8, 16, 32, INTEL_CMAT_UINT8, INTEL_CMAT_UINT8, INTEL_CMAT_UINT32, INTEL_CMAT_UINT32 },       \
-   }
+   .has_flat_ccs = true
 
+/* Note, do not enable PAT 10 or 12 on BMG, according to
+ * Wa_18038669374 we should not not use any MOCS/PAT settings
+ * that has "Compressible UC policy"
+ *
+ * (both 10 and 12 map to different compressed L3UC entries)
+ */
 #define XE2_PAT_ENTRIES                                         \
    /* BSpec 71582 (r59285) */                                   \
    .pat = {                                                     \
diff --git a/src/intel/dev/intel_device_info.py b/src/intel/dev/intel_device_info.py
index 65b99e41065..582c2dd02a6 100644
--- a/src/intel/dev/intel_device_info.py
+++ b/src/intel/dev/intel_device_info.py
@@ -169,7 +169,8 @@ Enum("intel_cooperative_matrix_component_type",
       "INTEL_CMAT_SINT32",
       "INTEL_CMAT_SINT8",
       "INTEL_CMAT_UINT32",
-      "INTEL_CMAT_UINT8"])
+      "INTEL_CMAT_UINT8",
+      "INTEL_CMAT_BFLOAT16"])
 
 Enum("intel_engine_class",
      ["INTEL_ENGINE_CLASS_RENDER",
diff --git a/src/intel/dev/mesa_defs.json b/src/intel/dev/mesa_defs.json
index 9557b22656e..d9dc3dd04c4 100644
--- a/src/intel/dev/mesa_defs.json
+++ b/src/intel/dev/mesa_defs.json
@@ -5223,20 +5223,6 @@
   },
   "18040903259": {
     "mesa_platforms": {
-      "INTEL_PLATFORM_BMG": {
-        "ids": [
-          14024277838,
-          14024889744
-        ],
-        "steppings": "all"
-      },
-      "INTEL_PLATFORM_LNL": {
-        "ids": [
-          14024277843,
-          14024897109
-        ],
-        "steppings": "all"
-      },
       "INTEL_PLATFORM_PTL": {
         "ids": [
           14024662665,
@@ -5773,24 +5759,6 @@
           14021567687
         ],
         "steppings": "all"
-      },
-      "INTEL_PLATFORM_ARL_U": {
-        "ids": [
-          14021559313
-        ],
-        "steppings": "all"
-      },
-      "INTEL_PLATFORM_MTL_H": {
-        "ids": [
-          14021562306
-        ],
-        "steppings": "all"
-      },
-      "INTEL_PLATFORM_MTL_U": {
-        "ids": [
-          14021559313
-        ],
-        "steppings": "all"
       }
     }
   },
diff --git a/src/intel/executor/executor_main.c b/src/intel/executor/executor_main.c
index b1bdbf0fc03..29354c98e90 100644
--- a/src/intel/executor/executor_main.c
+++ b/src/intel/executor/executor_main.c
@@ -41,121 +41,184 @@ enum {
 
 const char usage_line[] = "usage: executor [-d DEVICE] FILENAME";
 
+static void
+open_manual()
+{
+   FILE *f = NULL;
+
+   /* This fd will be set as stdin for executing man. */
+   int fd = memfd_create("executor.1", 0);
+   if (fd != -1)
+      f = fdopen(fd, "w");
+
+   if (!f) {
+      /* Fallback to just printing the content out. */
+      f = stderr;
+   }
+
+   static const char *contents[] = {
+      ".TH executor 1 2025-03-28",
+      "",
+      ".SH NAME",
+      "",
+      "executor - executes assembly for Intel GPUs",
+      "",
+      ".SH SYNOPSIS",
+      "",
+      "executor [-d DEVICE] FILENAME",
+      "",
+      "executor -d list",
+      "",
+      ".SH DESCRIPTION",
+      "",
+      "Runs a Lua script that can perform data manipulation",
+      "and dispatch execution of compute shaders, written in the same",
+      "assembly format used by the brw_asm assembler or when dumping",
+      "shaders in debug mode.",
+      "",
+      "The goal is to have a tool to experiment directly with certain",
+      "assembly instructions and the shared units without having to",
+      "instrument the drivers.",
+      "",
+      "The program will pick the first available device unless -d is",
+      "passed with either the index or a substring of the device to use.",
+      "Use \"-d list\" to list available devices.",
+      "",
+      ".SH SCRIPTING ENVIRONMENT",
+      "",
+      "In addition to the regular Lua standard library the following variables and",
+      "functions are available",
+      "",
+      "- execute({src=STR, data=ARRAY}) -> ARRAY",
+      "  Takes a table as argument.  The 'src' in the table contains the shader to be",
+      "  executed.  The 'data' argument will be used to fill the data buffer with 32-bit",
+      "  values.  The function returns an ARRAY with the contents of the data buffer",
+      "  after the shader completes.",
+      "",
+      "- dump(ARRAY, COUNT)",
+      "  Pretty print the COUNT first elements of an array of 32-bit values.",
+      "",
+      "- check_ver(V, ...), check_verx10(V, ...)",
+      "  Exit if the Gfx version being executed isn't in the arguments list.",
+      "",
+      "- ver, verx10",
+      "  Variables containing the Gfx version being executed.",
+      "",
+      ".SH ASSEMBLY MACROS",
+      "",
+      "In addition to regular instructions, the follow macros will generate",
+      "assembly code based on the Gfx version being executed.  Unlike in regular",
+      "instructions, REGs don't use regions and can't be immediates.",
+      "",
+      "- @eot",
+      "  Send an EOT message.",
+      "",
+      "- @mov REG IMM",
+      "  Like a regular MOV but accepts numbers in both decimal and",
+      "  floating-point.",
+      "",
+      "- @id REG",
+      "  Write a local invocation index into REG.",
+      "",
+      "- @read DST_REG OFFSET_REG",
+      "  Read 32-bit values from the memory buffer at OFFSET_REG into DST_REG.",
+      "",
+      "- @write OFFSET_REG SRC_REG",
+      "  Write 32-bit values from SRC_REG to the memory buffer at OFFSET_REG.",
+      "",
+      "- @syncnop",
+      "  Produce a coarse grained sync.nop (when applicable) to ensure data from",
+      "  macros above are read/written.",
+      "",
+      ".SH GPU EXECUTION",
+      "",
+      "Compute shaders are dispatched with SIMD8 for Gfx9-125 and SIMD16",
+      "for Xe2+.  Only a single thread is dispatched.  A data buffer is used to",
+      "pipe data into the shader and out of it, it is bound to the graphics",
+      "address 0x30000000.",
+      "",
+      "The Gfx versions have differences in their assembly and shared units, so",
+      "other than very simple examples, scripts for this program will be either",
+      "specific to a version or provide shader variants for multiple versions.",
+      "",
+      ".SH ENVIRONMENT VARIABLES",
+      "",
+      "The following INTEL_DEBUG values (comma separated) are used:",
+      "",
+      " - bat             Dumps the batch buffer.",
+      " - color           Uses colors for the batch buffer dump.",
+      " - cs              Dumps the source after macro processing",
+      "                   the final assembly.",
+      "",
+      ".SH EXAMPLE",
+      "",
+      "The script",
+      "",
+      "  local r = execute {",
+      "    data={ [42] = 0x100 },",
+      "    src=[[",
+      "      @mov     g1      42",
+      "      @read    g2      g1",
+      "",
+      "      @id      g3",
+      "",
+      "      add(8)   g4<1>UD  g2<8,8,1>UD  g3<8,8,1>UD  { align1 @1 1Q };",
+      "",
+      "      @write   g3       g4",
+      "      @eot",
+      "    ]]",
+      "  }",
+      "",
+      "  dump(r, 4)",
+      "",
+      "Will produce the output",
+      "",
+      "   [0x00000000] 0x00000100 0x00000101 0x00000102 0x00000103",
+      "",
+      "More examples can be found in the examples/ directory in the source code.",
+      "",
+   };
+
+   for (int i = 0; i < ARRAY_SIZE(contents); i++) {
+      fputs(contents[i], f);
+      putc('\n', f);
+   }
+
+   fflush(f);
+
+   if (f != stderr) {
+      /* Inject the temporary as stdin for man. */
+      lseek(fd, 0, SEEK_SET);
+      dup2(fd, STDIN_FILENO);
+      fclose(f);
+
+      execlp("man", "man", "-l", "-", (char *)NULL);
+   } else {
+      exit(0);
+   }
+}
+
 static void
 print_help()
 {
    printf(
-      "Executes shaders written for Intel GPUs\n"
       "%s\n"
       "\n"
-      "The input is a Lua script that can perform data manipulation\n"
-      "and dispatch execution of compute shaders, written in assembly,\n"
-      "the same format used by the brw_asm assembler or when dumping\n"
-      "shaders in debug mode.\n"
-      "\n"
-      "The goal is to have a tool to experiment directly with certain\n"
-      "assembly instructions and the shared units without having to\n"
-      "instrument the drivers.\n"
-      "\n"
-      "The program will pick the first available device unless -d is\n"
-      "passed with either the index or a substring of the device to use.\n"
-      "Use \"-d list\" to list available devices.\n"
-      "\n"
-      "EXECUTION CONTEXT\n"
-      "\n"
-      "By default compute shaders are used with SIMD8 for Gfx9-125 and SIMD16\n"
-      "for Xe2+.  Only a single thread is dispatched.  A data buffer is used to\n"
-      "pipe data into the shader and out of it, it is bound to the graphics\n"
-      "address 0x%08x.\n"
-      "\n"
-      "The Gfx versions have differences in their assembly and shared units, so\n"
-      "other than very simple examples, scripts for this program will be either\n"
-      "specific to a version or provide shader variants for multiple versions.\n"
-      "\n"
-      "ASSEMBLY MACROS\n"
-      "\n"
-      "In addition to regular instructions, the follow macros will generate\n"
-      "assembly code based on the Gfx version being executed.  Unlike in regular\n"
-      "instructions, REGs don't use regions and can't be immediates.\n"
-      "\n"
-      "- @eot\n"
-      "  Send an EOT message.\n"
+      "SCRIPTING ENVIRONMENT:\n"
+      "- execute({src=STR, data=ARRAY}) -> ARRAY\n"
+      "- dump(ARRAY, COUNT)\n"
+      "- check_ver(V, ...), check_verx10(V, ...), ver, verx10\n"
       "\n"
+      "ASSEMBLY MACROS:\n"
+      "- @eot, @syncnop\n"
       "- @mov REG IMM\n"
-      "  Like a regular MOV but accepts numbers in both decimal and\n"
-      "  floating-point.\n"
-      "\n"
       "- @id REG\n"
-      "  Write a local invocation index into REG.\n"
-      "\n"
       "- @read DST_REG OFFSET_REG\n"
-      "  Read 32-bit values from the memory buffer at OFFSET_REG into DST_REG.\n"
-      "\n"
       "- @write OFFSET_REG SRC_REG\n"
-      "  Write 32-bit values from SRC_REG to the memory buffer at OFFSET_REG.\n"
-      "\n"
-      "- @syncnop\n"
-      "  Produce a coarse grained sync.nop (when applicable) to ensure data from\n"
-      "  macros above are read/written.\n"
-      "\n"
-      "LUA ENVIRONMENT\n"
-      "\n"
-      "In addition to the regular Lua standard library the following variables and.\n"
-      "functions are available.\n"
-      "\n"
-      "- execute({src=STR, data=ARRAY}) -> ARRAY\n"
-      "  Takes a table as argument.  The 'src' in the table contains the shader to be\n"
-      "  executed.  The 'data' argument will be used to fill the data buffer with 32-bit\n"
-      "  values.  The function returns an ARRAY with the contents of the data buffer\n"
-      "  after the shader completes.\n"
-      "\n"
-      "- dump(ARRAY, COUNT)\n"
-      "  Pretty print the COUNT first elements of an array of 32-bit values.\n"
-      "\n"
-      "- check_ver(V, ...), check_verx10(V, ...)\n"
-      "  Exit if the Gfx version being executed isn't in the arguments list.\n"
-      "\n"
-      "- ver, verx10\n"
-      "  Variables containing the Gfx version being executed.\n"
-      "\n"
-      "This program was compiled with %s.\n"
       "\n"
-      "ENVIRONMENT VARIABLES\n"
-      "\n"
-      "The following INTEL_DEBUG values (comma separated) are used:\n"
-      "\n"
-      " - bat             Dumps the batch buffer.\n"
-      " - color           Uses colors for the batch buffer dump.\n"
-      " - cs              Dumps the source after macro processing\n"
-      "                   the final assembly.\n"
-      "\n"
-      "EXAMPLE\n"
-      "\n"
-      "The following script\n"
-      "\n"
-      "  local r = execute {\n"
-      "    data={ [42] = 0x100 },\n"
-      "    src=[[\n"
-      "      @mov     g1      42\n"
-      "      @read    g2      g1\n"
-      "\n"
-      "      @id      g3\n"
-      "\n"
-      "      add(8)   g4<1>UD  g2<8,8,1>UD  g3<8,8,1>UD  { align1 @1 1Q };\n"
-      "\n"
-      "      @write   g3       g4\n"
-      "      @eot\n"
-      "    ]]\n"
-      "  }\n"
-      "\n"
-      "  dump(r, 4)\n"
-      "\n"
-      "Will produce the following output\n"
-      "\n"
-      "   [0x00000000] 0x00000100 0x00000101 0x00000102 0x00000103\n"
-      "\n"
-      "More examples can be found in the examples/ directory in the source code.\n"
-      "\n", usage_line, EXECUTOR_BO_DATA_ADDR, LUA_RELEASE);
+      "Use \'executor -d list\' to list available devices.\n"
+      "For more details, use \'executor --help\' to open manual.\n",
+      usage_line);
 }
 
 static struct {
@@ -853,7 +916,7 @@ main(int argc, char *argv[])
    const char *device_pattern = NULL;
 
    static const struct option long_options[] = {
-       {"help",   no_argument,       0, 'h'},
+       {"help",   no_argument,       0, 'H'},
        {"device", required_argument, 0, 'd'},
        {},
    };
@@ -870,6 +933,9 @@ main(int argc, char *argv[])
       case 'h':
          print_help();
          return 0;
+      case 'H':
+         open_manual();
+         return 0;
       default:
          fprintf(stderr, "%s\n", usage_line);
          return 1;
diff --git a/src/intel/genxml/gen300.xml b/src/intel/genxml/gen300.xml
index 2808ada0a16..663b82b9919 100644
--- a/src/intel/genxml/gen300.xml
+++ b/src/intel/genxml/gen300.xml
@@ -291,6 +291,42 @@
     <field name="Allow Low Quality LOD Calculation" start="120" end="120" type="bool" />
     <field name="Low Quality Filter" start="122" end="122" type="bool" />
   </struct>
+  <instruction name="3DSTATE_BTD" bias="2" length="6" engine="render|compute">
+    <field name="DWord Length" start="0" end="7" type="uint" default="4" />
+    <field name="3D Command Sub Opcode" start="16" end="23" type="uint" default="6" />
+    <field name="3D Command Opcode" start="24" end="26" type="uint" default="1" />
+    <field name="Command SubType" start="27" end="28" type="uint" default="0" />
+    <field name="Command Type" start="29" end="31" type="uint" default="3" />
+    <field name="Dispatch Timeout Counter" start="32" end="34" type="uint">
+      <value name="64 clocks" value="0" />
+      <value name="128 clocks" value="1" />
+      <value name="192 clocks" value="2" />
+      <value name="256 clocks" value="3" />
+      <value name="512 clocks" value="4" />
+      <value name="1024 clocks" value="5" />
+      <value name="2048 clocks" value="6" />
+      <value name="4096 clocks" value="7" />
+    </field>
+    <field name="Controls the maximum number of outstanding Ray Queries per SS" start="39" end="40" type="uint" prefix="RAYS_QUERIES_OUTSTANDING">
+      <value name="128" value="0" />
+      <value name="256" value="1" />
+      <value name="512" value="2" />
+      <value name="1024" value="3" />
+    </field>
+    <field name="RT Mem Structures 64b Mode Enable" start="62" end="62" type="bool" />
+    <field name="BTD Mid thread preemption" start="63" end="63" type="bool" />
+    <field name="Per DSS Memory Backed Buffer Size" start="64" end="66" type="uint" default="6">
+      <value name="2KB" value="0" />
+      <value name="4KB" value="1" />
+      <value name="8KB" value="2" />
+      <value name="16KB" value="3" />
+      <value name="32KB" value="4" />
+      <value name="64KB" value="5" />
+      <value name="128KB" value="6" />
+    </field>
+    <field name="Memory Backed Buffer Base Pointer" start="74" end="127" type="address" />
+    <field name="Scratch Space Buffer" start="138" end="159" type="uint" />
+  </instruction>
   <instruction name="3DSTATE_COARSE_PIXEL" bias="2" length="2" engine="render">
     <field name="DWord Length" start="0" end="15" type="uint" default="0" />
     <field name="3D Command Sub Opcode" start="16" end="23" type="uint" default="137" />
diff --git a/src/intel/genxml/gen300_rt.xml b/src/intel/genxml/gen300_rt.xml
index 73811e49ce8..18a7ec6edf7 100644
--- a/src/intel/genxml/gen300_rt.xml
+++ b/src/intel/genxml/gen300_rt.xml
@@ -17,22 +17,25 @@
     <field name="Kernel Start Pointer" start="6" end="31" type="offset" />
     <field name="Registers Per Thread" start="59" end="62" type="uint" />
   </struct>
-  <struct name="RT_DISPATCH_GLOBALS" length="20">
+  <struct name="RT_DISPATCH_GLOBALS" length="21">
     <field name="Mem Base Address" start="0" end="63" type="address" />
     <field name="Call Stack Handler" start="64" end="127" type="CALL_STACK_HANDLER" />
     <field name="Async RT Stack Size" start="128" end="159" type="uint" />
     <field name="Num DSS RT Stacks" start="160" end="175" type="uint" />
     <field name="Max BVH Levels" start="192" end="194" type="uint" />
+    <field name="Hit Group Stride" start="195" end="207" type="uint" />
+    <field name="Miss Group Stride" start="208" end="220" type="uint" />
     <field name="Flags" start="224" end="224" type="uint">
       <value name="RT_DEPTH_TEST_LESS_EQUAL" value="1" />
     </field>
-    <field name="Hit Group Table" start="256" end="319" type="RT_SHADER_TABLE" />
-    <field name="Miss Group Table" start="320" end="383" type="RT_SHADER_TABLE" />
+    <field name="Hit Group Table" start="256" end="319" type="address" />
+    <field name="Miss Group Table" start="320" end="383" type="address" />
     <field name="SW Stack Size" start="384" end="415" type="uint" />
     <field name="Launch Width" start="416" end="447" type="uint" />
     <field name="Launch Height" start="448" end="479" type="uint" />
     <field name="Launch Depth" start="480" end="511" type="uint" />
-    <field name="Callable Group Table" start="512" end="575" type="RT_SHADER_TABLE" />
-    <field name="Resume Shader Table" start="576" end="639" type="address" />
+    <field name="Callable Group Table" start="512" end="575" type="address" />
+    <field name="Callable Group Stride" start="576" end="588" type="uint" />
+    <field name="Resume Shader Table" start="608" end="671" type="address" />
   </struct>
 </genxml>
diff --git a/src/intel/perf/intel_perf_query_layout.c b/src/intel/perf/intel_perf_query_layout.c
index 22eba082433..83b61b57f50 100644
--- a/src/intel/perf/intel_perf_query_layout.c
+++ b/src/intel/perf/intel_perf_query_layout.c
@@ -93,7 +93,7 @@ main(int argc, char *argv[])
    }
 
    /* Force metric loading. */
-   intel_debug |= DEBUG_NO_OACONFIG;
+   BITSET_SET(intel_debug, DEBUG_NO_OACONFIG);
 
    struct intel_perf_config *perf_cfg = intel_perf_new(NULL);
    intel_perf_init_metrics(perf_cfg, &devinfo, -1, true, true);
diff --git a/src/intel/tools/aubinator.c b/src/intel/tools/aubinator.c
index b8e43ff23e7..b7eb7193509 100644
--- a/src/intel/tools/aubinator.c
+++ b/src/intel/tools/aubinator.c
@@ -61,7 +61,6 @@ uint16_t pci_id = 0;
 char *input_file = NULL, *xml_path = NULL;
 struct intel_device_info devinfo;
 struct intel_batch_decode_ctx batch_ctx;
-struct intel_isa_info isa_info = {};
 struct aub_mem mem;
 
 FILE *outfile;
@@ -97,7 +96,7 @@ aubinator_init(void *user_data, int aub_pci_id, const char *app_name)
       batch_flags |= INTEL_BATCH_DECODE_OFFSETS;
    batch_flags |= INTEL_BATCH_DECODE_FLOATS;
 
-   intel_decoder_init(&batch_ctx, &isa_info, &devinfo, outfile,
+   intel_decoder_init(&batch_ctx, &devinfo, outfile,
                       batch_flags, xml_path, NULL, NULL, NULL);
 
    /* Check for valid spec instance, if wrong xml_path is passed then spec
diff --git a/src/intel/tools/aubinator_error_decode.c b/src/intel/tools/aubinator_error_decode.c
index f7e78e3ac53..2dd9dca5475 100644
--- a/src/intel/tools/aubinator_error_decode.c
+++ b/src/intel/tools/aubinator_error_decode.c
@@ -585,8 +585,7 @@ read_i915_data_file(FILE *file, enum intel_batch_decode_flags batch_flags)
    }
 
    struct intel_batch_decode_ctx batch_ctx;
-   struct intel_isa_info isa_info = {};
-   intel_decoder_init(&batch_ctx, &isa_info, &devinfo, stdout,
+   intel_decoder_init(&batch_ctx, &devinfo, stdout,
                       batch_flags, xml_path, get_intel_batch_bo,
                       NULL, NULL);
    batch_ctx.acthd = acthd;
diff --git a/src/intel/tools/intel_tools.c b/src/intel/tools/intel_tools.c
index b63aec48ab5..a697cba1fcb 100644
--- a/src/intel/tools/intel_tools.c
+++ b/src/intel/tools/intel_tools.c
@@ -42,7 +42,6 @@ intel_disassemble(const struct intel_device_info *devinfo,
 
 void
 intel_decoder_init(struct intel_batch_decode_ctx *ctx,
-                   struct intel_isa_info *isa_info,
                    const struct intel_device_info *devinfo,
                    FILE *fp, enum intel_batch_decode_flags flags,
                    const char *xml_path,
@@ -51,15 +50,15 @@ intel_decoder_init(struct intel_batch_decode_ctx *ctx,
                    void *user_data)
 {
    if (devinfo->ver >= 9) {
-      struct brw_isa_info *isa = &isa_info->brw_isa;
-      brw_init_isa_info(isa, devinfo);
-      intel_batch_decode_ctx_init_brw(ctx, isa, devinfo, fp,
+      struct brw_isa_info isa;
+      brw_init_isa_info(&isa, devinfo);
+      intel_batch_decode_ctx_init_brw(ctx, &isa, devinfo, fp,
                                       flags, xml_path, get_bo, get_state_size, user_data);
    } else {
 #ifdef INTEL_USE_ELK
-      struct elk_isa_info *isa = &isa_info->elk_isa;
-      elk_init_isa_info(isa, devinfo);
-      intel_batch_decode_ctx_init_elk(ctx, isa, devinfo, fp,
+      struct elk_isa_info isa;
+      elk_init_isa_info(&isa, devinfo);
+      intel_batch_decode_ctx_init_elk(ctx, &isa, devinfo, fp,
                                       flags, xml_path, get_bo, get_state_size, user_data);
 #else
       not_supported(devinfo);
diff --git a/src/intel/tools/intel_tools.h b/src/intel/tools/intel_tools.h
index 13d14e4e3e9..3d33160ab44 100644
--- a/src/intel/tools/intel_tools.h
+++ b/src/intel/tools/intel_tools.h
@@ -9,33 +9,18 @@
 
 #include "intel/decoder/intel_decoder.h"
 
-#include "compiler/brw_isa_info.h"
-#ifdef INTEL_USE_ELK
-#include "compiler/elk/elk_isa_info.h"
-#endif
-
 #ifdef __cplusplus
 extern "C" {
 #endif
 
 struct intel_device_info;
 
-struct intel_isa_info {
-   union {
-      struct brw_isa_info brw_isa;
-#ifdef INTEL_USE_ELK
-      struct elk_isa_info elk_isa;
-#endif
-   };
-};
-
 /* Helpers to abstract some BRW/ELK differences. */
 
 void intel_disassemble(const struct intel_device_info *devinfo,
                        const void *assembly, int start, FILE *out);
 
 void intel_decoder_init(struct intel_batch_decode_ctx *ctx,
-                        struct intel_isa_info *isa_info,
                         const struct intel_device_info *devinfo,
                         FILE *fp, enum intel_batch_decode_flags flags,
                         const char *xml_path,
diff --git a/src/intel/vulkan/anv_batch_chain.c b/src/intel/vulkan/anv_batch_chain.c
index b6c297c1e8a..7cceba7e7ba 100644
--- a/src/intel/vulkan/anv_batch_chain.c
+++ b/src/intel/vulkan/anv_batch_chain.c
@@ -1264,7 +1264,7 @@ anv_cmd_buffer_exec_batch_debug(struct anv_queue *queue,
                                 struct anv_query_pool *perf_query_pool,
                                 uint32_t perf_query_pass)
 {
-   if (!INTEL_DEBUG(DEBUG_BATCH | DEBUG_BATCH_STATS))
+   if (!INTEL_DEBUG(DEBUG_BATCH) && !INTEL_DEBUG(DEBUG_BATCH_STATS))
       return;
 
    struct anv_device *device = queue->device;
diff --git a/src/intel/vulkan/anv_device.c b/src/intel/vulkan/anv_device.c
index 0fb86e9d846..e28a4ffec6e 100644
--- a/src/intel/vulkan/anv_device.c
+++ b/src/intel/vulkan/anv_device.c
@@ -384,7 +384,7 @@ VkResult anv_CreateDevice(
    if (result != VK_SUCCESS)
       goto fail_alloc;
 
-   if (INTEL_DEBUG(DEBUG_BATCH | DEBUG_BATCH_STATS)) {
+   if (INTEL_DEBUG(DEBUG_BATCH) || INTEL_DEBUG(DEBUG_BATCH_STATS)) {
       for (unsigned i = 0; i < physical_device->queue.family_count; i++) {
          struct intel_batch_decode_ctx *decoder = &device->decoder[i];
 
@@ -1296,7 +1296,7 @@ void anv_DestroyDevice(
 
    anv_device_destroy_context_or_vm(device);
 
-   if (INTEL_DEBUG(DEBUG_BATCH | DEBUG_BATCH_STATS)) {
+   if (INTEL_DEBUG(DEBUG_BATCH) || INTEL_DEBUG(DEBUG_BATCH_STATS)) {
       for (unsigned i = 0; i < pdevice->queue.family_count; i++) {
          if (INTEL_DEBUG(DEBUG_BATCH_STATS))
             intel_batch_print_stats(&device->decoder[i]);
diff --git a/src/intel/vulkan/anv_physical_device.c b/src/intel/vulkan/anv_physical_device.c
index ae6d2eaed70..c8472d3a2c7 100644
--- a/src/intel/vulkan/anv_physical_device.c
+++ b/src/intel/vulkan/anv_physical_device.c
@@ -123,6 +123,21 @@ get_device_descriptor_limits(const struct anv_physical_device *device,
    limits->max_resources = MIN2(limits->max_resources, limits->max_samplers);
 }
 
+
+static const bool
+anv_device_has_bfloat16_cooperative_matrix(const struct anv_physical_device *pdevice)
+{
+   const struct intel_device_info *devinfo = &pdevice->info;
+
+   for (int i = 0; i < ARRAY_SIZE(devinfo->cooperative_matrix_configurations); i++) {
+      const struct intel_cooperative_matrix_configuration *cfg =
+         &devinfo->cooperative_matrix_configurations[i];
+      if (cfg->a == INTEL_CMAT_BFLOAT16 || cfg->b == INTEL_CMAT_BFLOAT16)
+         return true;
+   }
+   return false;
+}
+
 static void
 get_device_extensions(const struct anv_physical_device *device,
                       struct vk_device_extension_table *ext)
@@ -147,6 +162,7 @@ get_device_extensions(const struct anv_physical_device *device,
       .KHR_create_renderpass2                = true,
       .KHR_dedicated_allocation              = true,
       .KHR_deferred_host_operations          = true,
+      .KHR_depth_clamp_zero_one              = true,
       .KHR_depth_stencil_resolve             = true,
       .KHR_descriptor_update_template        = true,
       .KHR_device_group                      = true,
@@ -282,6 +298,7 @@ get_device_extensions(const struct anv_physical_device *device,
       .EXT_extended_dynamic_state            = true,
       .EXT_extended_dynamic_state2           = true,
       .EXT_extended_dynamic_state3           = true,
+      .EXT_external_memory_acquire_unmodified = true,
       .EXT_external_memory_dma_buf           = true,
       .EXT_external_memory_host              = true,
       .EXT_fragment_shader_interlock         = true,
@@ -376,6 +393,7 @@ get_device_extensions(const struct anv_physical_device *device,
       .MESA_image_alignment_control          = true,
       .NV_compute_shader_derivatives         = true,
       .VALVE_mutable_descriptor_type         = true,
+      .KHR_shader_bfloat16                   = device->info.has_bfloat16,
    };
 }
 
@@ -580,7 +598,7 @@ get_features(const struct anv_physical_device *pdevice,
       .customBorderColorWithoutFormat =
          pdevice->instance->custom_border_colors_without_format,
 
-      /* VK_EXT_depth_clamp_zero_one */
+      /* VK_KHR_depth_clamp_zero_one */
       .depthClampZeroOne = true,
 
       /* VK_EXT_depth_clip_enable */
@@ -933,6 +951,12 @@ get_features(const struct anv_physical_device *pdevice,
 
       /* VK_KHR_maintenance8 */
       .maintenance8 = true,
+
+      /* VK_KHR_shader_bfloat16 */
+      .shaderBFloat16Type = pdevice->info.has_bfloat16,
+      .shaderBFloat16CooperativeMatrix =
+         anv_device_has_bfloat16_cooperative_matrix(pdevice),
+      .shaderBFloat16DotProduct = pdevice->info.has_bfloat16,
    };
 
    /* The new DOOM and Wolfenstein games require depthBounds without
@@ -1496,8 +1520,15 @@ get_properties(const struct anv_physical_device *pdevice,
       /* TODO */
       props->shaderGroupHandleSize = 32;
       props->maxRayRecursionDepth = 31;
-      /* MemRay::hitGroupSRStride is 16 bits */
-      props->maxShaderGroupStride = UINT16_MAX;
+      if (pdevice->info.ver >= 30) {
+         /* RTDispatchGlobals::missShaderStride is 13-bit wide. The maximum
+          * here is a 13-bit wide max value.
+          */
+         props->maxShaderGroupStride = (1U << 13) - 1;
+      } else {
+         /* MemRay::hitGroupSRStride is 16 bits */
+         props->maxShaderGroupStride = UINT16_MAX;
+      }
       /* MemRay::hitGroupSRBasePtr requires 16B alignment */
       props->shaderGroupBaseAlignment = 16;
       props->shaderGroupHandleAlignment = 16;
@@ -3110,12 +3141,13 @@ static VkComponentTypeKHR
 convert_component_type(enum intel_cooperative_matrix_component_type t)
 {
    switch (t) {
-   case INTEL_CMAT_FLOAT16: return VK_COMPONENT_TYPE_FLOAT16_KHR;
-   case INTEL_CMAT_FLOAT32: return VK_COMPONENT_TYPE_FLOAT32_KHR;
-   case INTEL_CMAT_SINT32:  return VK_COMPONENT_TYPE_SINT32_KHR;
-   case INTEL_CMAT_SINT8:   return VK_COMPONENT_TYPE_SINT8_KHR;
-   case INTEL_CMAT_UINT32:  return VK_COMPONENT_TYPE_UINT32_KHR;
-   case INTEL_CMAT_UINT8:   return VK_COMPONENT_TYPE_UINT8_KHR;
+   case INTEL_CMAT_FLOAT16:  return VK_COMPONENT_TYPE_FLOAT16_KHR;
+   case INTEL_CMAT_FLOAT32:  return VK_COMPONENT_TYPE_FLOAT32_KHR;
+   case INTEL_CMAT_SINT32:   return VK_COMPONENT_TYPE_SINT32_KHR;
+   case INTEL_CMAT_SINT8:    return VK_COMPONENT_TYPE_SINT8_KHR;
+   case INTEL_CMAT_UINT32:   return VK_COMPONENT_TYPE_UINT32_KHR;
+   case INTEL_CMAT_UINT8:    return VK_COMPONENT_TYPE_UINT8_KHR;
+   case INTEL_CMAT_BFLOAT16: return VK_COMPONENT_TYPE_BFLOAT16_KHR;
    }
    unreachable("invalid cooperative matrix component type in configuration");
 }
diff --git a/src/intel/vulkan/anv_pipeline.c b/src/intel/vulkan/anv_pipeline.c
index 0ab0cd87e19..997559b75af 100644
--- a/src/intel/vulkan/anv_pipeline.c
+++ b/src/intel/vulkan/anv_pipeline.c
@@ -456,6 +456,15 @@ rp_color_mask(const struct vk_render_pass_state *rp)
          color_mask |= BITFIELD_BIT(i);
    }
 
+   /* If there is depth/stencil attachment, even if the fragment shader
+    * doesn't write the depth/stencil output, we need a valid render target so
+    * that the compiler doesn't use the null-rt which would cull the
+    * depth/stencil output.
+    */
+   if (rp->depth_attachment_format != VK_FORMAT_UNDEFINED ||
+       rp->stencil_attachment_format != VK_FORMAT_UNDEFINED)
+      color_mask |= 1;
+
    return color_mask;
 }
 
@@ -969,8 +978,7 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
                });
    }
 
-   if (nir->info.stage == MESA_SHADER_MESH ||
-         nir->info.stage == MESA_SHADER_TASK) {
+   if (gl_shader_stage_is_mesh(nir->info.stage)) {
       nir_lower_compute_system_values_options options = {
             .lower_workgroup_id_to_index = true,
             /* nir_lower_idiv generates expensive code */
@@ -1118,10 +1126,8 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
               pipeline->layout.type);
 
    if (gl_shader_stage_uses_workgroup(nir->info.stage)) {
-      if (!nir->info.shared_memory_explicit_layout) {
-         NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
-                  nir_var_mem_shared, shared_type_info);
-      }
+      NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
+               nir_var_mem_shared, shared_type_info);
 
       NIR_PASS(_, nir, nir_lower_explicit_io,
                nir_var_mem_shared, nir_address_format_32bit_offset);
@@ -1472,13 +1478,23 @@ anv_pipeline_link_fs(const struct brw_compiler *compiler,
                      const struct vk_render_pass_state *rp)
 {
    /* Initially the valid outputs value is set to all possible render targets
-    * valid (see populate_wm_prog_key()), because we're not looking at the
-    * shader code yet. Here we look at the output written to get a correct
-    * number of render target outputs.
+    * valid (see populate_wm_prog_key()), before we look at the shader
+    * variables. Here we look at the output variables of the shader an compute
+    * a correct number of render target outputs.
     */
-   const uint64_t rt_mask =
-      stage->nir->info.outputs_written >> FRAG_RESULT_DATA0;
-   stage->key.wm.color_outputs_valid = rt_mask & rp_color_mask(rp);
+   stage->key.wm.color_outputs_valid = 0;
+   nir_foreach_shader_out_variable_safe(var, stage->nir) {
+      if (var->data.location < FRAG_RESULT_DATA0)
+         continue;
+
+      const unsigned rt = var->data.location - FRAG_RESULT_DATA0;
+      const unsigned array_len =
+         glsl_type_is_array(var->type) ? glsl_get_length(var->type) : 1;
+      assert(rt + array_len <= MAX_RTS);
+
+      stage->key.wm.color_outputs_valid |= BITFIELD_RANGE(rt, array_len);
+   }
+   stage->key.wm.color_outputs_valid &= rp_color_mask(rp);
    stage->key.wm.nr_color_regions =
       util_last_bit(stage->key.wm.color_outputs_valid);
 
@@ -1508,9 +1524,6 @@ anv_pipeline_link_fs(const struct brw_compiler *compiler,
                  compiler->devinfo, stage->nir,
                  stage->key.wm.multisample_fbo != INTEL_NEVER,
                  stage->key.wm.alpha_to_coverage != INTEL_NEVER)) {
-      /* Ensure the shader doesn't discard the writes */
-      stage->key.wm.color_outputs_valid = 0x1;
-      stage->key.wm.nr_color_regions = 1;
       /* Setup a null render target */
       rt_bindings[0] = (struct anv_pipeline_binding) {
          .set = ANV_DESCRIPTOR_SET_COLOR_ATTACHMENTS,
@@ -3361,6 +3374,11 @@ compile_upload_rt_shader(struct anv_ray_tracing_pipeline *pipeline,
       pipeline->base.device->physical->compiler;
    const struct intel_device_info *devinfo = compiler->devinfo;
 
+   struct brw_nir_lower_shader_calls_state lowering_state = {
+      .devinfo = devinfo,
+      .key = &stage->key.bs,
+   };
+
    nir_shader **resume_shaders = NULL;
    uint32_t num_resume_shaders = 0;
    if (nir->info.stage != MESA_SHADER_COMPUTE) {
@@ -3373,16 +3391,14 @@ compile_upload_rt_shader(struct anv_ray_tracing_pipeline *pipeline,
          .should_remat_callback = should_remat_cb,
       };
 
-      NIR_PASS(_, nir, brw_nir_lower_rt_intrinsics_pre_trace);
-
       NIR_PASS(_, nir, nir_lower_shader_calls, &opts,
                &resume_shaders, &num_resume_shaders, mem_ctx);
-      NIR_PASS(_, nir, brw_nir_lower_shader_calls, &stage->key.bs);
+      NIR_PASS(_, nir, brw_nir_lower_shader_calls, &lowering_state);
       NIR_PASS_V(nir, brw_nir_lower_rt_intrinsics, &stage->key.base, devinfo);
    }
 
    for (unsigned i = 0; i < num_resume_shaders; i++) {
-      NIR_PASS(_,resume_shaders[i], brw_nir_lower_shader_calls, &stage->key.bs);
+      NIR_PASS(_,resume_shaders[i], brw_nir_lower_shader_calls, &lowering_state);
       NIR_PASS_V(resume_shaders[i], brw_nir_lower_rt_intrinsics, &stage->key.base, devinfo);
    }
 
@@ -3717,7 +3733,7 @@ anv_pipeline_compile_ray_tracing(struct anv_ray_tracing_pipeline *pipeline,
       nir_shader *nir = nir_shader_clone(tmp_stage_ctx, stages[i].nir);
       switch (stages[i].stage) {
       case MESA_SHADER_RAYGEN:
-         brw_nir_lower_raygen(nir);
+         brw_nir_lower_raygen(nir, devinfo);
          break;
 
       case MESA_SHADER_ANY_HIT:
@@ -3725,18 +3741,18 @@ anv_pipeline_compile_ray_tracing(struct anv_ray_tracing_pipeline *pipeline,
          break;
 
       case MESA_SHADER_CLOSEST_HIT:
-         brw_nir_lower_closest_hit(nir);
+         brw_nir_lower_closest_hit(nir, devinfo);
          break;
 
       case MESA_SHADER_MISS:
-         brw_nir_lower_miss(nir);
+         brw_nir_lower_miss(nir, devinfo);
          break;
 
       case MESA_SHADER_INTERSECTION:
          unreachable("These are handled later");
 
       case MESA_SHADER_CALLABLE:
-         brw_nir_lower_callable(nir);
+         brw_nir_lower_callable(nir, devinfo);
          break;
 
       default:
diff --git a/src/intel/vulkan/anv_pipeline_cache.c b/src/intel/vulkan/anv_pipeline_cache.c
index a3dd2e35ddf..2620bfdcf64 100644
--- a/src/intel/vulkan/anv_pipeline_cache.c
+++ b/src/intel/vulkan/anv_pipeline_cache.c
@@ -250,6 +250,8 @@ anv_shader_bin_create(struct anv_device *device,
                                  &anv_shader_bin_ops, obj_key_data, key_size);
 
    shader->stage = stage;
+   if(INTEL_DEBUG(DEBUG_SHOW_SHADER_STAGE))
+      fprintf(stderr, "Stage: %s\n", gl_shader_stage_name(shader->stage));
 
    shader->kernel =
       anv_state_pool_alloc(&device->instruction_state_pool, kernel_size, 64);
diff --git a/src/intel/vulkan/anv_private.h b/src/intel/vulkan/anv_private.h
index 95223d01bdd..2471d1c3329 100644
--- a/src/intel/vulkan/anv_private.h
+++ b/src/intel/vulkan/anv_private.h
@@ -270,14 +270,7 @@ struct intel_perf_query_result;
 #define ANV_TRTT_L1_NULL_TILE_VAL 0
 #define ANV_TRTT_L1_INVALID_TILE_VAL 1
 
-/* The binding table entry id disabled, the shader can write to it and the
- * driver should use a null surface state so that writes are discarded.
- */
 #define ANV_COLOR_OUTPUT_DISABLED (0xff)
-/* The binding table entry id unused, the shader does not write to it and the
- * driver can leave whatever surface state was used before. Transitioning
- * to/from this entry does not require render target cache flush.
- */
 #define ANV_COLOR_OUTPUT_UNUSED   (0xfe)
 
 static inline uint32_t
@@ -2370,7 +2363,7 @@ anv_queue_post_submit(struct anv_queue *queue, VkResult submit_result)
 
 #if ANV_SUPPORT_RT && !ANV_SUPPORT_RT_GRL
    /* The recorded bvh is dumped to files upon command buffer completion */
-   if (INTEL_DEBUG(DEBUG_BVH_ANY))
+   if (INTEL_DEBUG_BVH_ANY)
       anv_dump_bvh_to_files(queue->device);
 #endif
 
@@ -5634,9 +5627,12 @@ anv_image_is_externally_shared(const struct anv_image *image)
 static inline bool
 anv_image_has_private_binding(const struct anv_image *image)
 {
-   const struct anv_image_binding private_binding =
-      image->bindings[ANV_IMAGE_MEMORY_BINDING_PRIVATE];
-   return private_binding.memory_range.size != 0;
+   if (image->bindings[ANV_IMAGE_MEMORY_BINDING_PRIVATE].memory_range.size > 0) {
+      assert(anv_image_is_externally_shared(image));
+      return true;
+   } else {
+      return false;
+   }
 }
 
 static inline bool
diff --git a/src/intel/vulkan/anv_queue.c b/src/intel/vulkan/anv_queue.c
index 227462695d2..2ce93f42fc0 100644
--- a/src/intel/vulkan/anv_queue.c
+++ b/src/intel/vulkan/anv_queue.c
@@ -94,7 +94,9 @@ anv_queue_init(struct anv_device *device, struct anv_queue *queue,
    /* Add a debug fence to wait on submissions if we're using the synchronized
     * submission feature, shader-print feature, or BVH dump.
     */
-   if (INTEL_DEBUG(DEBUG_SYNC | DEBUG_SHADER_PRINT | DEBUG_BVH_ANY)) {
+   if (INTEL_DEBUG(DEBUG_SYNC) ||
+       INTEL_DEBUG(DEBUG_SHADER_PRINT) ||
+       INTEL_DEBUG_BVH_ANY) {
       result = vk_sync_create(&device->vk,
                               &device->physical->sync_syncobj_type,
                               0, 0, &queue->sync);
diff --git a/src/intel/vulkan/bvh/anv_bvh.h b/src/intel/vulkan/bvh/anv_bvh.h
index c4efeac5b6e..de629e8e572 100644
--- a/src/intel/vulkan/bvh/anv_bvh.h
+++ b/src/intel/vulkan/bvh/anv_bvh.h
@@ -74,7 +74,13 @@ struct anv_accel_struct_header {
 
    uint64_t self_ptr;
 
-   uint32_t padding[42];
+   /* A boolean indicating if the bvh is built with 64b_rt data structures.
+    * This is for INTEL_DEBUG=bvh_* to make the decision how to decode the
+    * dump.
+    */
+   uint32_t enable_64b_rt;
+
+   uint32_t padding[41];
 };
 
 /* Mixed internal node with type per child */
@@ -211,24 +217,46 @@ struct anv_internal_node {
 #define ANV_INSTANCE_ALL_AABB                               0x40
 
 struct instance_leaf_part0 {
-   /* shader index (24-bits) for software instancing
+   /* Xe1/2:
+    * shader index (24-bits) for software instancing
     * geometry mask (8-bits) used for ray masking
+    *
+    * Xe3+:
+    * instanceContribution: 24
+    * geometry mask (8-bits): 8
     */
-   uint32_t shader_index_and_geom_mask;
+   uint32_t DW0;
 
-   /* instance contribution to hit group index (24-bits)
+
+   /* Xe1/2:
+    * instance contribution to hit group index (24-bits)
     * Padding (5-bits)
     * DisableOpacityCull (1-bit)
     * OpaqueGeometry (1-bit)
     * Padding (1-bit)
+    *
+    * Xe3+:
+    * insFlags: 8
+    * ComparisonMode: 1
+    * ComparisonValue: 7
+    * pad0: 8
+    * subType: 4
+    * pad1: 1
+    * DisableOpacityCull: 1
+    * OpaqueGeometry: 1
+    * IgnoreRayMultiplier: 1
     */
-   uint32_t instance_contribution_and_geom_flags;
+   uint32_t DW1;
 
-   /* 48 bit start node of the instanced object
+   /* Xe1/2:
+    * 48 bit start node of the instanced object
     * instFlags (8-bits)
     * Padding (16-bits)
+    *
+    * Xe3+:
+    * 64 bit start node pointer
     */
-   uint64_t start_node_ptr_and_inst_flags;
+   uint64_t QW_startNodePtr;
 
    /* 1st row of Worl2Obj transform */
    float    world2obj_vx_x;
diff --git a/src/intel/vulkan/bvh/copy.comp b/src/intel/vulkan/bvh/copy.comp
index 65856b3e85d..17867445b1a 100644
--- a/src/intel/vulkan/bvh/copy.comp
+++ b/src/intel/vulkan/bvh/copy.comp
@@ -136,11 +136,15 @@ main(void)
             DEREF(instance_leaf).part1.bvh_ptr = blas_ptr;
 
             /* set the startNodePtr to blas_ptr + ANV_HEADER_SIZE */
-            uint64_t mask = 0x0000fffffffffffful;
             uint64_t new_startNodePtr = blas_ptr + ANV_RT_BVH_HEADER_SIZE;
+#if GFX_VERx10 >= 300
+            DEREF(instance_leaf).part0.QW_startNodePtr = new_startNodePtr;
+#else
+            uint64_t mask = 0x0000fffffffffffful;
             /* clear bits and set */
-            DEREF(instance_leaf).part0.start_node_ptr_and_inst_flags =
-               (DEREF(instance_leaf).part0.start_node_ptr_and_inst_flags & ~mask) | (new_startNodePtr & mask);
+            DEREF(instance_leaf).part0.QW_startNodePtr =
+               (DEREF(instance_leaf).part0.QW_startNodePtr & ~mask) | (new_startNodePtr & mask);
+#endif
          }
       }
    }
diff --git a/src/intel/vulkan/bvh/encode.comp b/src/intel/vulkan/bvh/encode.comp
index 884edeb970b..29f13276081 100644
--- a/src/intel/vulkan/bvh/encode.comp
+++ b/src/intel/vulkan/bvh/encode.comp
@@ -29,7 +29,7 @@ layout(push_constant) uniform CONSTS {
    encode_args args;
 };
 
-uint64_t
+uint32_t
 get_instance_flag(uint32_t src)
 {
    uint32_t flags = src & 0xff;
@@ -129,32 +129,48 @@ encode_leaf_node(uint32_t type, uint64_t src_node, uint64_t dst_node, REF(anv_ac
       uint64_t start_node_ptr = uint64_t(src.base_ptr) + DEREF(blas_header).rootNodeOffset;
 
       uint32_t sbt_offset_and_flags = src.sbt_offset_and_flags;
+      uint32_t instance_flags = DEREF(blas_header).instance_flags;
+      if (((sbt_offset_and_flags >> 24) & (VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR |
+                                           VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR)) != 0) {
+         instance_flags &= ~(VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR |
+                             VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR);
+         instance_flags |= (sbt_offset_and_flags >> 24) & (VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR |
+                                                           VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR);
+      }
+
+#if GFX_VERx10 >= 300
+      DEREF(dst_instance).part0.QW_startNodePtr = start_node_ptr;
+      uint32_t instance_contribution_and_geom_mask = 0;
+      instance_contribution_and_geom_mask |= src.sbt_offset_and_flags & 0xffffff;
+      instance_contribution_and_geom_mask |= (src.custom_instance_and_mask & 0xff000000);
+      DEREF(dst_instance).part0.DW0 = instance_contribution_and_geom_mask;
+
+      uint32_t inst_flags_and_the_rest = 0;
+      inst_flags_and_the_rest |= get_instance_flag(instance_flags | (src.sbt_offset_and_flags >> 24));
+      inst_flags_and_the_rest |= (1 << 29);
+      inst_flags_and_the_rest |=
+         ((get_instance_flag(src.sbt_offset_and_flags >> 24) & ANV_INSTANCE_FLAG_FORCE_OPAQUE) != 0 ?
+          ANV_GEOMETRY_FLAG_OPAQUE : 0) << 30;
 
+      DEREF(dst_instance).part0.DW1 = inst_flags_and_the_rest;
+
+#else
       uint32_t shader_index_and_geom_mask = 0;
       shader_index_and_geom_mask |= (src.custom_instance_and_mask & 0xff000000);
-      DEREF(dst_instance).part0.shader_index_and_geom_mask = shader_index_and_geom_mask;
+      DEREF(dst_instance).part0.DW0 = shader_index_and_geom_mask;
 
       uint32_t instance_contribution_and_geom_flags = 0;
       instance_contribution_and_geom_flags |= src.sbt_offset_and_flags & 0xffffff;
       instance_contribution_and_geom_flags |= (1 << 29);
       instance_contribution_and_geom_flags |=
-         (get_instance_flag(src.sbt_offset_and_flags >> 24) == ANV_INSTANCE_FLAG_FORCE_OPAQUE ?
+         ((get_instance_flag(src.sbt_offset_and_flags >> 24) & ANV_INSTANCE_FLAG_FORCE_OPAQUE) != 0 ?
           ANV_GEOMETRY_FLAG_OPAQUE : 0) << 30;
-      DEREF(dst_instance).part0.instance_contribution_and_geom_flags =
-         instance_contribution_and_geom_flags;
-
-      uint32_t instance_flags = DEREF(blas_header).instance_flags;
-      if (((sbt_offset_and_flags >> 24) & (VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR |
-                                           VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR)) != 0) {
-         instance_flags &= ~(VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR |
-                             VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR);
-         instance_flags |= (sbt_offset_and_flags >> 24) & (VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_KHR |
-                                                           VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_KHR);
-      }
+      DEREF(dst_instance).part0.DW1 = instance_contribution_and_geom_flags;
 
-      DEREF(dst_instance).part0.start_node_ptr_and_inst_flags =
+      DEREF(dst_instance).part0.QW_startNodePtr =
          (start_node_ptr & ((1ul << 48) - 1)) |
-         (get_instance_flag(instance_flags | (src.sbt_offset_and_flags >> 24)) << 48);
+         (uint64_t(get_instance_flag(instance_flags | (src.sbt_offset_and_flags >> 24))) << 48);
+#endif
 
       mat4 transform = mat4(src.otw_matrix);
 
diff --git a/src/intel/vulkan/bvh/header.comp b/src/intel/vulkan/bvh/header.comp
index fee5d70ec47..baf0b66e029 100644
--- a/src/intel/vulkan/bvh/header.comp
+++ b/src/intel/vulkan/bvh/header.comp
@@ -47,4 +47,9 @@ main(void)
    DEREF(args.dst).copy_dispatch_size[0] = DIV_ROUND_UP(compacted_size, 8 * 128);
    DEREF(args.dst).copy_dispatch_size[1] = 1;
    DEREF(args.dst).copy_dispatch_size[2] = 1;
+#if GFX_VERx10 >= 300
+   DEREF(args.dst).enable_64b_rt = 1;
+#else
+   DEREF(args.dst).enable_64b_rt = 0;
+#endif
 }
diff --git a/src/intel/vulkan/bvh/interpret.py b/src/intel/vulkan/bvh/interpret.py
index 77a0909efeb..ee6cc493115 100644
--- a/src/intel/vulkan/bvh/interpret.py
+++ b/src/intel/vulkan/bvh/interpret.py
@@ -22,6 +22,7 @@ def get_header_properties(header):
         'size': header.size,
         'instance_count': header.instance_count,
         'self_ptr': header.self_ptr,
+        'enable_64b_rt': header.enable_64b_rt,
         'padding': f"{len(header.padding)} uint32_t paddings",
     }
 
@@ -118,20 +119,38 @@ def get_internal_node_properties(node):
         'actual_coords': actual_coords
     }
 
-def get_instance_leaf_properties(node):
+def get_instance_leaf_properties(node, enable_64b_rt):
+    if enable_64b_rt:
+        part0 = {
+            'instanceContribution': node.part0.DW0 & 0xFFFFFF,
+            'geomMask': (node.part0.DW0 >> 24) & 0xFF,
+            'insFlags': node.part0.DW1 & 0xFF,
+            'ComparisonMode': (node.part0.DW1 >> 8) & 0x1,
+            'ComparisonValue': (node.part0.DW1 >> 9) & 0x7F,
+            'pad0': (node.part0.DW1 >> 16) & 0xFF,
+            'subType': (node.part0.DW1 >> 24) & 0xF,
+            'pad1': (node.part0.DW1 >> 28) & 0x1,
+            'DisableOpacityCull': (node.part0.DW1 >> 29) & 0x1,
+            'OpaqueGeometry': (node.part0.DW1 >> 30) & 0x1,
+            'IgnoreRayMultiplier': (node.part0.DW1 >> 31) & 0x1,
+            'startNodePtr': node.part0.QW_startNodePtr,
+        }
+    else:
+        part0 = {
+            'shaderIndex': node.part0.DW0 & 0xFFFFFF,
+            'geomMask': (node.part0.DW0 >> 24) & 0xFF,
+            'instanceContribution': node.part0.DW1 & 0xFFFFFF,
+            'pad0': (node.part0.DW1 >> 24) & 0x1F,
+            'DisableOpacityCull': (node.part0.DW1 >> 29) & 0x1,
+            'OpaqueGeometry': (node.part0.DW1 >> 30) & 0x1,
+            'pad1': (node.part0.DW1 >> 31) & 0x1,
+            'startNodePtr': node.part0.QW_startNodePtr & 0xFFFFFFFFFFFF,
+            'instFlags': (node.part0.QW_startNodePtr >> 48) & 0xFF,
+        }
+
     return {
         'part0': {
-            'shaderIndex': node.part0.shader_index_and_geom_mask & 0xFFFFFF,
-            'geomMask': (node.part0.shader_index_and_geom_mask >> 24) & 0xFF,
-            'instanceContribution': node.part0.instance_contribution_and_geom_flags & 0xFFFFFF,
-            'pad0': (node.part0.instance_contribution_and_geom_flags >> 24) & 0x1F,
-            'DisableOpacityCull': (node.part0.instance_contribution_and_geom_flags >> 29) & 0x1,
-            'OpaqueGeometry': (node.part0.instance_contribution_and_geom_flags >> 30) & 0x1,
-            'pad1': (node.part0.instance_contribution_and_geom_flags >> 31) & 0x1,
-            'startNodePtr': node.part0.start_node_ptr_and_inst_flags & 0xFFFFFFFFFFFF,
-            'instFlags': (node.part0.start_node_ptr_and_inst_flags >> 48) & 0xFF,
-            'ComparisonMode': (node.part0.start_node_ptr_and_inst_flags >> 56) & 0x1,
-            'ComparisonValue': (node.part0.start_node_ptr_and_inst_flags >> 57) & 0x7F,
+            **part0,
             'world2obj_vx': [node.part0.world2obj_vx_x, node.part0.world2obj_vx_y, node.part0.world2obj_vx_z],
             'world2obj_vy': [node.part0.world2obj_vy_x, node.part0.world2obj_vy_y, node.part0.world2obj_vy_z],
             'world2obj_vz': [node.part0.world2obj_vz_x, node.part0.world2obj_vz_y, node.part0.world2obj_vz_z],
@@ -180,7 +199,8 @@ class AnvAccelStructHeader(ctypes.Structure):
         ('size', ctypes.c_uint64),
         ('instance_count', ctypes.c_uint64),
         ('self_ptr', ctypes.c_uint64),
-        ('padding', ctypes.c_uint32 * 42),
+        ('enable_64b_rt', ctypes.c_uint32),
+        ('padding', ctypes.c_uint32 * 41),
     )
 
 class ChildData(ctypes.Structure):
@@ -230,9 +250,9 @@ class AnvProceduralLeafNode(ctypes.Structure):
 
 class InstanceLeafPart0(ctypes.Structure):
     _fields_ = (
-        ('shader_index_and_geom_mask', ctypes.c_uint32),
-        ('instance_contribution_and_geom_flags', ctypes.c_uint32),
-        ('start_node_ptr_and_inst_flags', ctypes.c_uint64),
+        ('DW0', ctypes.c_uint32),
+        ('DW1', ctypes.c_uint32),
+        ('QW_startNodePtr', ctypes.c_uint64),
         ('world2obj_vx_x', ctypes.c_float),
         ('world2obj_vx_y', ctypes.c_float),
         ('world2obj_vx_z', ctypes.c_float),
@@ -274,6 +294,7 @@ class AnvInstanceLeaf(ctypes.Structure):
 
 class BVHInterpreter:
     def __init__(self, data):
+        self.enable_64b_rt = False;
         self.data = data
         self.nodes = []
         self.relationships = {}
@@ -282,7 +303,10 @@ class BVHInterpreter:
     def interpret_structure(self, offset, structure):
         size = ctypes.sizeof(structure)
         if(offset + size > len(self.data)):
-            raise ValueError("Not enought data to interpret this structure.")
+            raise ValueError(
+                f"Not enough data to interpret structure: {structure.__name__}, "
+                f"required {size} bytes but only {len(self.data) - offset} bytes available."
+            )
         buffer = self.data[offset:offset + size]
         return structure.from_buffer_copy(buffer)
 
@@ -290,6 +314,7 @@ class BVHInterpreter:
         offset = 0
         # Interpret the header
         header = self.interpret_structure(offset, AnvAccelStructHeader)
+        self.enable_64b_rt = header.enable_64b_rt
         offset += header.rootNodeOffset
 
         # Interpret the rootNode
@@ -324,7 +349,7 @@ class BVHInterpreter:
             node_properties = get_internal_node_properties(node)
         elif structure == AnvInstanceLeaf:
             node_type_str = "AnvInstanceLeaf"
-            node_properties = get_instance_leaf_properties(node)
+            node_properties = get_instance_leaf_properties(node, self.enable_64b_rt)
         elif structure == AnvQuadLeafNode:
             node_type_str = "AnvQuadLeafNode"
             node_properties = get_quad_leaf_properties(node)
diff --git a/src/intel/vulkan/bvh/meson.build b/src/intel/vulkan/bvh/meson.build
index 8dbb5281c5b..0b7e4d5ec85 100644
--- a/src/intel/vulkan/bvh/meson.build
+++ b/src/intel/vulkan/bvh/meson.build
@@ -4,21 +4,16 @@
 
 # source file, output name, defines
 bvh_shaders = [
-  [
-    'encode.comp',
-    'encode',
-    [],
-  ],
-  [
-    'header.comp',
-    'header',
-    [],
-  ],
-  [
-    'copy.comp',
-    'copy',
-    []
-  ],
+  'encode.comp',
+  'header.comp',
+  'copy.comp',
+]
+
+# A mapping: [filename version, GFX_VERx10 define version]
+gfx_versions = [
+  ['125', '125'],
+  ['20', '200'],
+  ['30', '300']
 ]
 
 anv_bvh_include_dir = dir_source_root + '/src/intel/vulkan/bvh'
@@ -29,21 +24,28 @@ anv_bvh_includes = files(
   'anv_bvh.h',
 )
 
-foreach s : bvh_shaders
-  command = [
-    prog_glslang, '-V', '-I' + vk_bvh_include_dir, '-I' + anv_bvh_include_dir, '--target-env', 'spirv1.5', '-x', '-o', '@OUTPUT@', '@INPUT@'
-  ]
-  command += glslang_quiet
+foreach shader : bvh_shaders
+  foreach gfx: gfx_versions
+    file_name_ver = gfx[0]
+    define_ver = gfx[1]
+    command = [
+      prog_glslang, '-V', '-I' + vk_bvh_include_dir, '-I' + anv_bvh_include_dir,
+      '--target-env', 'spirv1.5', '-x', '-o', '@OUTPUT@', '@INPUT@',
+      '-DGFX_VERx10=' + define_ver # so that we can use this macro inside shaders
+    ]
+    command += glslang_quiet
 
-  foreach define : s[2]
-    command += '-D' + define
-  endforeach
+    shader_name = shader.split('.')[0]
+    output_name = 'gfx' + file_name_ver + '_' + shader_name + '.spv.h'
+    # By doing this, encode.comp with DGFX_VERx10=300 will be compiled to gfx30_encode.spv.h
+    # So the genX(encode).spv.h in genX_acceleration_structure.c can find the right file
 
-  bvh_spv += custom_target(
-    s[1] + '.spv.h',
-    input : s[0],
-    output : s[1] + '.spv.h',
-    command : command,
-    depend_files: [vk_bvh_includes, anv_bvh_includes],
-  )
+    bvh_spv += custom_target(
+      output_name,
+      input : shader,
+      output : output_name,
+      command : command,
+      depend_files: [vk_bvh_includes, anv_bvh_includes],
+    )
+   endforeach
 endforeach
diff --git a/src/intel/vulkan/genX_acceleration_structure.c b/src/intel/vulkan/genX_acceleration_structure.c
index 4c3a68fcef5..7e43ef6ab38 100644
--- a/src/intel/vulkan/genX_acceleration_structure.c
+++ b/src/intel/vulkan/genX_acceleration_structure.c
@@ -229,16 +229,23 @@ debug_record_as_to_bvh_dump(struct anv_cmd_buffer *cmd_buffer,
    }
 }
 
+#define STRINGIFY_HELPER(x) #x
+#define STRINGIFY(x) STRINGIFY_HELPER(x)
+
+#define ENCODE_SPV_PATH STRINGIFY(bvh/genX(encode).spv.h)
+#define HEADER_SPV_PATH STRINGIFY(bvh/genX(header).spv.h)
+#define COPY_SPV_PATH STRINGIFY(bvh/genX(copy).spv.h)
+
 static const uint32_t encode_spv[] = {
-#include "bvh/encode.spv.h"
+#include ENCODE_SPV_PATH
 };
 
 static const uint32_t header_spv[] = {
-#include "bvh/header.spv.h"
+#include HEADER_SPV_PATH
 };
 
 static const uint32_t copy_spv[] = {
-#include "bvh/copy.spv.h"
+#include COPY_SPV_PATH
 };
 
 static VkResult
@@ -350,7 +357,7 @@ anv_get_as_size(VkDevice device,
 }
 
 static uint32_t
-anv_get_encode_key(VkAccelerationStructureTypeKHR type,
+anv_get_encode_key(struct vk_device *device, VkAccelerationStructureTypeKHR type,
                    VkBuildAccelerationStructureFlagBitsKHR flags)
 {
    return 0;
@@ -437,7 +444,7 @@ anv_encode_as(VkCommandBuffer commandBuffer,
 }
 
 static uint32_t
-anv_get_header_key(VkAccelerationStructureTypeKHR type,
+anv_get_header_key(struct vk_device *device, VkAccelerationStructureTypeKHR type,
                    VkBuildAccelerationStructureFlagBitsKHR flags)
 {
    return (flags & VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_COMPACTION_BIT_KHR) ?
@@ -551,6 +558,12 @@ anv_init_header(VkCommandBuffer commandBuffer,
 
       header.size = header.compacted_size;
 
+#if GFX_VERx10 >= 300
+      header.enable_64b_rt = 1;
+#else
+      header.enable_64b_rt = 0;
+#endif
+
       size_t header_size = sizeof(struct anv_accel_struct_header) - base;
       assert(base % sizeof(uint32_t) == 0);
       assert(header_size % sizeof(uint32_t) == 0);
@@ -560,7 +573,7 @@ anv_init_header(VkCommandBuffer commandBuffer,
       anv_cmd_buffer_update_addr(cmd_buffer, addr, header_size, header_ptr);
    }
 
-   if (INTEL_DEBUG(DEBUG_BVH_ANY)) {
+   if (INTEL_DEBUG_BVH_ANY) {
       genx_batch_emit_pipe_control(&cmd_buffer->batch, cmd_buffer->device->info,
                                    cmd_buffer->state.current_pipeline,
                                    ANV_PIPE_END_OF_PIPE_SYNC_BIT |
diff --git a/src/intel/vulkan/genX_cmd_buffer.c b/src/intel/vulkan/genX_cmd_buffer.c
index 36bc9cbf591..81ef4cd1518 100644
--- a/src/intel/vulkan/genX_cmd_buffer.c
+++ b/src/intel/vulkan/genX_cmd_buffer.c
@@ -1019,6 +1019,13 @@ genX(set_fast_clear_state)(struct anv_cmd_buffer *cmd_buffer,
    }
 }
 
+static bool ATTRIBUTE_CONST
+queue_family_is_external(uint32_t index)
+{
+      return index == VK_QUEUE_FAMILY_FOREIGN_EXT ||
+             index == VK_QUEUE_FAMILY_EXTERNAL;
+}
+
 /**
  * @brief Transitions a color buffer from one layout to another.
  *
@@ -1029,6 +1036,9 @@ genX(set_fast_clear_state)(struct anv_cmd_buffer *cmd_buffer,
  * @param layer_count VK_REMAINING_ARRAY_LAYERS isn't supported. For 3D images,
  *                    this represents the maximum layers to transition at each
  *                    specified miplevel.
+ * @param acquire_unmodified True if
+ *    VkExternalMemoryAcquireUnmodifiedEXT::acquireUnmodifiedMemory is set and
+ *    relevant.
  */
 static void
 transition_color_buffer(struct anv_cmd_buffer *cmd_buffer,
@@ -1040,7 +1050,8 @@ transition_color_buffer(struct anv_cmd_buffer *cmd_buffer,
                         VkImageLayout final_layout,
                         uint32_t src_queue_family,
                         uint32_t dst_queue_family,
-                        bool will_full_fast_clear)
+                        bool will_full_fast_clear,
+                        bool acquire_unmodified)
 {
    struct anv_device *device = cmd_buffer->device;
    const struct intel_device_info *devinfo = device->info;
@@ -1067,13 +1078,8 @@ transition_color_buffer(struct anv_cmd_buffer *cmd_buffer,
       ? isl_drm_modifier_get_info(image->vk.drm_format_mod)
       : NULL;
 
-   const bool src_queue_external =
-      src_queue_family == VK_QUEUE_FAMILY_FOREIGN_EXT ||
-      src_queue_family == VK_QUEUE_FAMILY_EXTERNAL;
-
-   const bool dst_queue_external =
-      dst_queue_family == VK_QUEUE_FAMILY_FOREIGN_EXT ||
-      dst_queue_family == VK_QUEUE_FAMILY_EXTERNAL;
+   const bool src_queue_external = queue_family_is_external(src_queue_family);
+   const bool dst_queue_external = queue_family_is_external(dst_queue_family);
 
    /* If the queues are external, consider the first queue family flags
     * (should be the most capable)
@@ -1090,18 +1096,16 @@ transition_color_buffer(struct anv_cmd_buffer *cmd_buffer,
    /* Simultaneous acquire and release on external queues is illegal. */
    assert(!src_queue_external || !dst_queue_external);
 
-   /* Ownership transition on an external queue requires special action if the
-    * image has a DRM format modifier because we store image data in
-    * a driver-private bo which is inaccessible to the external queue.
+   /* Ownership transition on an external queue requires special action if we
+    * store any image data in a driver-private bo that is inaccessible to the
+    * external queue.
     */
    const bool private_binding_acquire =
       src_queue_external &&
-      anv_image_is_externally_shared(image) &&
       anv_image_has_private_binding(image);
 
    const bool private_binding_release =
       dst_queue_external &&
-      anv_image_is_externally_shared(image) &&
       anv_image_has_private_binding(image);
 
    if (initial_layout == final_layout &&
@@ -1225,8 +1229,7 @@ transition_color_buffer(struct anv_cmd_buffer *cmd_buffer,
 
          must_init_aux_surface = false;
       }
-
-   } else if (private_binding_acquire) {
+   } else if (private_binding_acquire && !acquire_unmodified) {
       /* The fast clear state lives in a driver-private bo, and therefore the
        * external/foreign queue is unaware of it.
        *
@@ -1259,6 +1262,19 @@ transition_color_buffer(struct anv_cmd_buffer *cmd_buffer,
           */
          must_init_aux_surface = false;
       }
+   } else if (private_binding_acquire && acquire_unmodified) {
+      /* The Vulkan 1.3.302 spec ensures we have previously initialized the
+       * image memory, and therefore initialized the fast clear state and aux
+       * surface, because initial_layout_undefined is false and
+       * acquireUnmodifiedMemory is true.
+       *
+       * Since the time of our most recent image ownership release and up
+       * until the current ownership re-acquisition, the externally-shared
+       * image memory has remained unmodified. Therefore the fast clear state
+       * and aux surface are valid and consistent with the image content.
+       */
+      must_init_fast_clear_state = false;
+      must_init_aux_surface = false;
    }
 
    if (must_init_fast_clear_state) {
@@ -4271,6 +4287,25 @@ cmd_buffer_has_pending_copy_query(struct anv_cmd_buffer *cmd_buffer)
            ANV_QUERY_WRITES_DATA_FLUSH) != 0;
 }
 
+static bool
+img_barrier_has_acquire_unmodified(const VkImageMemoryBarrier2 *img_barrier)
+{
+   /* The Vulkan 1.3.302 spec says:
+    *
+    *    This struct [VkExternalMemoryAcquireUnmodifiedEXT] is ignored if the
+    *    memory barrier's srcQueueFamilyIndex is not a special queue family
+    *    reserved for external memory ownership transfers.
+    */
+   if (!queue_family_is_external(img_barrier->srcQueueFamilyIndex))
+      return false;
+
+   const VkExternalMemoryAcquireUnmodifiedEXT *unmodified_info =
+      vk_find_struct_const(img_barrier->pNext,
+                           EXTERNAL_MEMORY_ACQUIRE_UNMODIFIED_EXT);
+
+   return unmodified_info && unmodified_info->acquireUnmodifiedMemory;
+}
+
 static void
 cmd_buffer_accumulate_barrier_bits(struct anv_cmd_buffer *cmd_buffer,
                                    uint32_t n_dep_infos,
@@ -4464,6 +4499,8 @@ cmd_buffer_accumulate_barrier_bits(struct anv_cmd_buffer *cmd_buffer,
          }
 
          if (range->aspectMask & VK_IMAGE_ASPECT_ANY_COLOR_BIT_ANV) {
+            bool acquire_unmodified =
+               img_barrier_has_acquire_unmodified(img_barrier);
             VkImageAspectFlags color_aspects =
                vk_image_expand_aspect_mask(&image->vk, range->aspectMask);
             anv_foreach_image_aspect_bit(aspect_bit, image, color_aspects) {
@@ -4473,7 +4510,8 @@ cmd_buffer_accumulate_barrier_bits(struct anv_cmd_buffer *cmd_buffer,
                                        old_layout, new_layout,
                                        img_barrier->srcQueueFamilyIndex,
                                        img_barrier->dstQueueFamilyIndex,
-                                       false /* will_full_fast_clear */);
+                                       false /* will_full_fast_clear */,
+                                       acquire_unmodified);
             }
          }
 #if GFX_VER < 20
@@ -5439,7 +5477,8 @@ void genX(CmdBeginRendering)(
                                           initial_layout, att->imageLayout,
                                           VK_QUEUE_FAMILY_IGNORED,
                                           VK_QUEUE_FAMILY_IGNORED,
-                                          fast_clear);
+                                          fast_clear,
+                                          false /* acquire_unmodified */);
                }
             } else {
                transition_color_buffer(cmd_buffer, iview->image,
@@ -5450,7 +5489,8 @@ void genX(CmdBeginRendering)(
                                        initial_layout, att->imageLayout,
                                        VK_QUEUE_FAMILY_IGNORED,
                                        VK_QUEUE_FAMILY_IGNORED,
-                                       fast_clear);
+                                       fast_clear,
+                                       false /* acquire_unmodified */);
             }
          }
 
diff --git a/src/intel/vulkan/genX_cmd_compute.c b/src/intel/vulkan/genX_cmd_compute.c
index 650b7acdc00..d8ea87bbfbf 100644
--- a/src/intel/vulkan/genX_cmd_compute.c
+++ b/src/intel/vulkan/genX_cmd_compute.c
@@ -1057,13 +1057,28 @@ cmd_buffer_emit_rt_dispatch_globals(struct anv_cmd_buffer *cmd_buffer,
       .NumDSSRTStacks     = rt->scratch.layout.stack_ids_per_dss,
       .MaxBVHLevels       = BRW_RT_MAX_BVH_LEVELS,
       .Flags              = RT_DEPTH_TEST_LESS_EQUAL,
+#if GFX_VER >= 30
+      .HitGroupStride     = params->hit_sbt->stride,
+      .MissGroupStride    = params->miss_sbt->stride,
+      .HitGroupTable      =
+         anv_address_from_u64(params->hit_sbt->deviceAddress),
+      .MissGroupTable     =
+         anv_address_from_u64(params->miss_sbt->deviceAddress),
+#else
       .HitGroupTable      = vk_sdar_to_shader_table(params->hit_sbt),
       .MissGroupTable     = vk_sdar_to_shader_table(params->miss_sbt),
+#endif
       .SWStackSize        = rt->scratch.layout.sw_stack_size / 64,
       .LaunchWidth        = params->launch_size[0],
       .LaunchHeight       = params->launch_size[1],
       .LaunchDepth        = params->launch_size[2],
+#if GFX_VER >= 30
+      .CallableGroupTable =
+         anv_address_from_u64(params->callable_sbt->deviceAddress),
+      .CallableGroupStride = params->callable_sbt->stride,
+#else
       .CallableGroupTable = vk_sdar_to_shader_table(params->callable_sbt),
+#endif
    };
    GENX(RT_DISPATCH_GLOBALS_pack)(NULL, rtdg_state.map, &rtdg);
 
@@ -1349,6 +1364,10 @@ cmd_buffer_trace_rays(struct anv_cmd_buffer *cmd_buffer,
 #if INTEL_NEEDS_WA_14017794102 || INTEL_NEEDS_WA_14023061436
       btd.BTDMidthreadpreemption = false;
 #endif
+
+#if GFX_VER >= 30
+      btd.RTMemStructures64bModeEnable = true;
+#endif
    }
 
    genX(cmd_buffer_ensure_cfe_state)(cmd_buffer, pipeline->base.scratch_size);
diff --git a/src/intel/vulkan/genX_gfx_state.c b/src/intel/vulkan/genX_gfx_state.c
index cd8c585bc67..fb8ec99f270 100644
--- a/src/intel/vulkan/genX_gfx_state.c
+++ b/src/intel/vulkan/genX_gfx_state.c
@@ -890,16 +890,27 @@ update_ps_extra_has_uav(struct anv_gfx_dynamic_state *hw_state,
 {
    const struct brw_wm_prog_data *wm_prog_data = get_wm_prog_data(pipeline);
 
-   /* Force fragment shader execution if occlusion queries are active to
-    * ensure PS_DEPTH_COUNT is correct. Otherwise a fragment shader with
-    * discard and no render target setup could be increment PS_DEPTH_COUNT if
-    * the HW internally decides to not run the shader because it has already
-    * established that depth-test is passing.
+#if GFX_VERx10 >= 125
+   SET_STAGE(PS_EXTRA, ps_extra.PixelShaderHasUAV,
+                       wm_prog_data && wm_prog_data->has_side_effects,
+                       FRAGMENT);
+#else
+   /* Prior to Gfx12.5 the HW seems to avoid spawning fragment shaders even if
+    * 3DSTATE_PS_EXTRA::PixelShaderKillsPixel=true when
+    * 3DSTATE_PS_BLEND::HasWriteableRT=false. This is causing problems with
+    * occlusion queries with 0 attachments. There are no CTS tests exercising
+    * this but zink+anv fails a bunch of tests like piglit
+    * arb_framebuffer_no_attachments-query.
+    *
+    * Here we choose to tweak the PixelShaderHasUAV to make sure the fragment
+    * shaders are run properly.
     */
    SET_STAGE(PS_EXTRA, ps_extra.PixelShaderHasUAV,
                        wm_prog_data && (wm_prog_data->has_side_effects ||
-                                        gfx->n_occlusion_queries > 0),
+                                        (gfx->color_att_count == 0 &&
+                                         gfx->n_occlusion_queries > 0)),
                        FRAGMENT);
+#endif
 }
 
 ALWAYS_INLINE static void
diff --git a/src/intel/vulkan/genX_init_state.c b/src/intel/vulkan/genX_init_state.c
index bb757a82090..b8df464dd01 100644
--- a/src/intel/vulkan/genX_init_state.c
+++ b/src/intel/vulkan/genX_init_state.c
@@ -367,6 +367,10 @@ init_common_queue_state(struct anv_queue *queue, struct anv_batch *batch)
 #if INTEL_NEEDS_WA_14017794102 || INTEL_NEEDS_WA_14023061436
          btd.BTDMidthreadpreemption = false;
 #endif
+
+#if GFX_VER >= 30
+         btd.RTMemStructures64bModeEnable = true;
+#endif
       }
    }
 #endif
diff --git a/src/intel/vulkan_hasvk/anv_pipeline.c b/src/intel/vulkan_hasvk/anv_pipeline.c
index 8e485934ce9..d9ce1e7fe17 100644
--- a/src/intel/vulkan_hasvk/anv_pipeline.c
+++ b/src/intel/vulkan_hasvk/anv_pipeline.c
@@ -555,10 +555,8 @@ anv_pipeline_lower_nir(struct anv_pipeline *pipeline,
               prog_data, &stage->bind_map, mem_ctx);
 
    if (gl_shader_stage_uses_workgroup(nir->info.stage)) {
-      if (!nir->info.shared_memory_explicit_layout) {
-         NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
-                  nir_var_mem_shared, shared_type_info);
-      }
+      NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
+               nir_var_mem_shared, shared_type_info);
 
       NIR_PASS(_, nir, nir_lower_explicit_io,
                nir_var_mem_shared, nir_address_format_32bit_offset);
diff --git a/src/loader/loader.c b/src/loader/loader.c
index 98bd9121220..5ec26b80b96 100644
--- a/src/loader/loader.c
+++ b/src/loader/loader.c
@@ -858,7 +858,7 @@ loader_open_driver_lib(const char *driver_name,
       len = next - p;
       snprintf(path, sizeof(path), "%.*s/%s%s.so", len,
                p, driver_name, lib_suffix);
-      driver = dlopen(path, RTLD_NOW | RTLD_GLOBAL);
+      driver = dlopen(path, RTLD_NOW | RTLD_LOCAL);
       if (driver == NULL) {
          dl_error = dlerror();
          log_(_LOADER_DEBUG, "MESA-LOADER: failed to open %s: %s\n",
diff --git a/src/mesa/main/consts_exts.h b/src/mesa/main/consts_exts.h
index 7a561ecd83a..1a9be719da1 100644
--- a/src/mesa/main/consts_exts.h
+++ b/src/mesa/main/consts_exts.h
@@ -926,9 +926,6 @@ struct gl_constants
    /** Override GL_MAP_UNSYNCHRONIZED_BIT */
    bool ForceMapBufferSynchronized;
 
-   /** Override GL_DEPTH_COMPONENT type from unsigned short to unsigned int */
-   bool ForceDepthComponentTypeInt;
-
    /** GL_ARB_get_program_binary */
    GLuint NumProgramBinaryFormats;
 
diff --git a/src/mesa/main/uniform_query.cpp b/src/mesa/main/uniform_query.cpp
index 895de8acdb0..cb3d79a91da 100644
--- a/src/mesa/main/uniform_query.cpp
+++ b/src/mesa/main/uniform_query.cpp
@@ -989,6 +989,7 @@ associate_uniform_storage(struct gl_context *ctx,
             FALLTHROUGH;
          case GLSL_TYPE_FLOAT:
          case GLSL_TYPE_FLOAT16:
+         case GLSL_TYPE_BFLOAT16:
             format = uniform_native;
             columns = storage->type->matrix_columns;
             break;
diff --git a/src/mesa/state_tracker/st_extensions.c b/src/mesa/state_tracker/st_extensions.c
index 92ead66e516..775f00caa4b 100644
--- a/src/mesa/state_tracker/st_extensions.c
+++ b/src/mesa/state_tracker/st_extensions.c
@@ -1196,8 +1196,6 @@ void st_init_extensions(struct pipe_screen *screen,
 
    consts->ForceMapBufferSynchronized = options->force_gl_map_buffer_synchronized;
 
-   consts->ForceDepthComponentTypeInt = options->force_gl_depth_component_type_int;
-
    consts->PrimitiveRestartFixedIndex =
       screen->caps.primitive_restart_fixed_index;
 
diff --git a/src/mesa/state_tracker/st_format.c b/src/mesa/state_tracker/st_format.c
index 4c6e1fa26ca..b040c0c4f17 100644
--- a/src/mesa/state_tracker/st_format.c
+++ b/src/mesa/state_tracker/st_format.c
@@ -1328,11 +1328,6 @@ st_ChooseTextureFormat(struct gl_context *ctx, GLenum target,
    bool is_renderbuffer = false;
    enum pipe_texture_target pTarget;
 
-   if (ctx->Const.ForceDepthComponentTypeInt &&
-       internalFormat == GL_DEPTH_COMPONENT &&
-       type == GL_UNSIGNED_SHORT)
-      type = GL_UNSIGNED_INT;
-
    if (target == GL_RENDERBUFFER) {
       pTarget = PIPE_TEXTURE_2D;
       is_renderbuffer = true;
diff --git a/src/microsoft/ci/gitlab-ci-inc.yml b/src/microsoft/ci/gitlab-ci-inc.yml
index a7a6873e20a..e1448afc2c7 100644
--- a/src/microsoft/ci/gitlab-ci-inc.yml
+++ b/src/microsoft/ci/gitlab-ci-inc.yml
@@ -73,7 +73,7 @@
       when: on_success
 
 .dozen-manual-rules:
-  stage: layered-backends-postmerge
+  stage: layered-backends-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
diff --git a/src/microsoft/compiler/dxil_nir_tess.c b/src/microsoft/compiler/dxil_nir_tess.c
index 6c2adec4297..96ef792dcbb 100644
--- a/src/microsoft/compiler/dxil_nir_tess.c
+++ b/src/microsoft/compiler/dxil_nir_tess.c
@@ -48,9 +48,13 @@ remove_hs_intrinsics(nir_function_impl *impl)
          if (instr->type != nir_instr_type_intrinsic)
             continue;
          nir_intrinsic_instr *intr = nir_instr_as_intrinsic(instr);
-         if (intr->intrinsic != nir_intrinsic_store_output &&
-             !is_memory_barrier_tcs_patch(intr))
+         if (intr->intrinsic == nir_intrinsic_load_output) {
+            nir_builder b = nir_builder_at(nir_before_instr(&intr->instr));
+            nir_def_rewrite_uses(&intr->def, nir_undef(&b, intr->def.num_components, intr->def.bit_size));
+         } else if (intr->intrinsic != nir_intrinsic_store_output &&
+             !is_memory_barrier_tcs_patch(intr)) {
             continue;
+         }
          nir_instr_remove(instr);
       }
    }
diff --git a/src/nouveau/ci/gitlab-ci-inc.yml b/src/nouveau/ci/gitlab-ci-inc.yml
index 93737b914af..8bbb7843a29 100644
--- a/src/nouveau/ci/gitlab-ci-inc.yml
+++ b/src/nouveau/ci/gitlab-ci-inc.yml
@@ -26,7 +26,7 @@
       when: on_success
 
 .nvk-valve-manual-rules:
-  stage: nouveau-postmerge
+  stage: nouveau-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
diff --git a/src/nouveau/ci/nvk-ga106-vkd3d-fails.txt b/src/nouveau/ci/nvk-ga106-vkd3d-fails.txt
index c3210dd77ab..6db30ba9593 100644
--- a/src/nouveau/ci/nvk-ga106-vkd3d-fails.txt
+++ b/src/nouveau/ci/nvk-ga106-vkd3d-fails.txt
@@ -1,6 +1,3 @@
-# src/nouveau/vulkan/nvk_cmd_draw.c:1900: nvk_flush_ms_state: Assertion `dyn->ms.rasterization_samples == 0 || dyn->ms.rasterization_samples == render->samples' failed.
-test_multisample_rendering,Crash
-
 # nouveau 0000:2d:00.0: gsp: mmu fault queued
 # nouveau 0000:2d:00.0: gsp: rc engn:00000001 chid:24 type:31 scope:1 part:233
 # nouveau 0000:2d:00.0: fifo:c00000:0003:0018:[d3d12[1056]] errored - disabling channel
diff --git a/src/nouveau/compiler/meson.build b/src/nouveau/compiler/meson.build
index 142a75bdaa6..55f92c2b5b2 100644
--- a/src/nouveau/compiler/meson.build
+++ b/src/nouveau/compiler/meson.build
@@ -141,8 +141,9 @@ if with_tests and get_option('b_sanitize') == 'none'
     'nak',
     _libnak_rs,
     args : [
-      # Don't run HW tests by default
+      # Don't run HW or nvdisasm tests by default
       '--skip', 'hw_tests::',
+      '--skip', 'nvdisasm_tests::',
     ],
     suite : ['nouveau'],
     dependencies : [
diff --git a/src/nouveau/compiler/nak/api.rs b/src/nouveau/compiler/nak/api.rs
index 1251c382a2a..fe8ea3fb2ad 100644
--- a/src/nouveau/compiler/nak/api.rs
+++ b/src/nouveau/compiler/nak/api.rs
@@ -120,7 +120,6 @@ fn nir_options(dev: &nv_device_info) -> nir_shader_compiler_options {
     op.lower_fsqrt = dev.sm < 52;
     op.lower_bitfield_extract = dev.sm >= 70;
     op.lower_bitfield_insert = true;
-    op.lower_pack_64_4x16 = true;
     op.lower_pack_half_2x16 = true;
     op.lower_pack_unorm_2x16 = true;
     op.lower_pack_snorm_2x16 = true;
@@ -157,6 +156,9 @@ fn nir_options(dev: &nv_device_info) -> nir_shader_compiler_options {
         | nir_lower_shift64
         | nir_lower_imul_2x32_64
         | nir_lower_conv64);
+    if dev.sm < 32 {
+        op.lower_int64_options |= nir_lower_shift64;
+    }
     op.lower_ldexp = true;
     op.lower_fmod = true;
     op.lower_ffract = true;
diff --git a/src/nouveau/compiler/nak/assign_regs.rs b/src/nouveau/compiler/nak/assign_regs.rs
index d736fdd09ba..619a55cb441 100644
--- a/src/nouveau/compiler/nak/assign_regs.rs
+++ b/src/nouveau/compiler/nak/assign_regs.rs
@@ -965,7 +965,7 @@ impl AssignRegsBlock {
     }
 
     fn try_coalesce(&mut self, ssa: SSAValue, src: &Src) -> bool {
-        debug_assert!(src.is_unmodified());
+        debug_assert!(src.src_mod.is_none());
         let SrcRef::Reg(src_reg) = src.src_ref else {
             return false;
         };
@@ -1018,7 +1018,7 @@ impl AssignRegsBlock {
             }
             Op::PhiSrcs(phi) => {
                 for (id, src) in phi.srcs.iter() {
-                    assert!(src.is_unmodified());
+                    assert!(src.src_mod.is_none());
                     if let Some(ssa) = src_ssa_ref(src) {
                         assert!(ssa.comps() == 1);
                         let reg = self.get_scalar(ssa[0]);
diff --git a/src/nouveau/compiler/nak/builder.rs b/src/nouveau/compiler/nak/builder.rs
index c45d0312a65..94b2909745a 100644
--- a/src/nouveau/compiler/nak/builder.rs
+++ b/src/nouveau/compiler/nak/builder.rs
@@ -145,7 +145,7 @@ pub trait SSABuilder: Builder {
 
     fn shl64(&mut self, x: Src, shift: Src) -> SSARef {
         let x = x.as_ssa().unwrap();
-        debug_assert!(shift.is_unmodified());
+        debug_assert!(shift.src_mod.is_none());
 
         let dst = self.alloc_ssa(RegFile::GPR, 2);
         if self.sm() >= 70 {
@@ -214,7 +214,7 @@ pub trait SSABuilder: Builder {
 
     fn shr64(&mut self, x: Src, shift: Src, signed: bool) -> SSARef {
         let x = x.as_ssa().unwrap();
-        debug_assert!(shift.is_unmodified());
+        debug_assert!(shift.src_mod.is_none());
 
         let dst = self.alloc_ssa(RegFile::GPR, 2);
         self.push_op(OpShf {
@@ -630,8 +630,8 @@ pub trait SSABuilder: Builder {
 
     fn lea64(&mut self, a: Src, b: Src, shift: u8) -> SSARef {
         assert!(self.sm() >= 70);
-        assert!(a.is_unmodified());
-        assert!(b.is_unmodified());
+        assert!(a.src_mod.is_none());
+        assert!(b.src_mod.is_none());
 
         let a = a.as_ssa().unwrap();
         let b = b.as_ssa().unwrap();
diff --git a/src/nouveau/compiler/nak/calc_instr_deps.rs b/src/nouveau/compiler/nak/calc_instr_deps.rs
index 21243d024ba..cc684cfefbf 100644
--- a/src/nouveau/compiler/nak/calc_instr_deps.rs
+++ b/src/nouveau/compiler/nak/calc_instr_deps.rs
@@ -452,12 +452,11 @@ fn calc_delays(f: &mut Function, sm: &dyn ShaderModel) -> u32 {
         if instr.deps.delay > MAX_INSTR_DELAY {
             let mut delay = instr.deps.delay - MAX_INSTR_DELAY;
             instr.deps.set_delay(MAX_INSTR_DELAY);
-            let mut instrs = vec![instr];
+            let instrs = vec![instr];
             while delay > 0 {
                 let mut nop = Instr::new_boxed(OpNop { label: None });
                 nop.deps.set_delay(delay.min(MAX_INSTR_DELAY));
                 delay -= nop.deps.delay;
-                instrs.push(nop);
             }
             MappedInstrs::Many(instrs)
         } else if matches!(instr.op, Op::SrcBar(_)) {
diff --git a/src/nouveau/compiler/nak/const_tracker.rs b/src/nouveau/compiler/nak/const_tracker.rs
index a110f6a8a3a..629a89b0ee7 100644
--- a/src/nouveau/compiler/nak/const_tracker.rs
+++ b/src/nouveau/compiler/nak/const_tracker.rs
@@ -33,7 +33,7 @@ impl ConstTracker {
         debug_assert!(dst.comps() == 1);
         let dst = dst[0];
 
-        debug_assert!(op.src.is_unmodified());
+        debug_assert!(op.src.src_mod.is_none());
         let is_const = match &op.src.src_ref {
             SrcRef::Zero | SrcRef::True | SrcRef::False | SrcRef::Imm32(_) => {
                 true
diff --git a/src/nouveau/compiler/nak/from_nir.rs b/src/nouveau/compiler/nak/from_nir.rs
index 11e5533689a..9e209665a38 100644
--- a/src/nouveau/compiler/nak/from_nir.rs
+++ b/src/nouveau/compiler/nak/from_nir.rs
@@ -1959,6 +1959,13 @@ impl<'a> ShaderFromNir<'a> {
                 di += 1;
             }
         }
+
+        if self.sm.sm() < 50 {
+            // TODO: texbar should be created by calc_instr_deps() and
+            // should be less conservative than textures_left=0.
+            // See the old pass: NVC0LegalizePostRA::insertTextureBarriers
+            b.push_op(OpTexDepBar { textures_left: 0 });
+        }
         self.set_ssa(tex.def.as_def(), nir_dst);
     }
 
@@ -2286,31 +2293,48 @@ impl<'a> ShaderFromNir<'a> {
 
                 assert!(intrin.def.bit_size() == 32);
                 let ftype = FloatType::F32;
-                let scratch = b.alloc_ssa(RegFile::GPR, 1);
-
-                b.push_op(OpShfl {
-                    dst: scratch[0].into(),
-                    in_bounds: Dst::None,
-                    src: self.get_src(&srcs[0]),
-                    lane: 1_u32.into(),
-                    c: (0x3_u32 | 0x1c_u32 << 8).into(),
-                    op: ShflOp::Bfly,
-                });
 
                 let dst = b.alloc_ssa(RegFile::GPR, 1);
 
-                b.push_op(OpFSwzAdd {
-                    dst: dst[0].into(),
-                    srcs: [scratch[0].into(), self.get_src(&srcs[0])],
-                    ops: [
-                        FSwzAddOp::SubLeft,
-                        FSwzAddOp::SubRight,
-                        FSwzAddOp::SubLeft,
-                        FSwzAddOp::SubRight,
-                    ],
-                    rnd_mode: self.float_ctl[ftype].rnd_mode,
-                    ftz: self.float_ctl[ftype].ftz,
-                });
+                if self.sm.sm() >= 50 {
+                    let scratch = b.alloc_ssa(RegFile::GPR, 1);
+
+                    b.push_op(OpShfl {
+                        dst: scratch[0].into(),
+                        in_bounds: Dst::None,
+                        src: self.get_src(&srcs[0]),
+                        lane: 1_u32.into(),
+                        c: (0x3_u32 | 0x1c_u32 << 8).into(),
+                        op: ShflOp::Bfly,
+                    });
+
+                    b.push_op(OpFSwzAdd {
+                        dst: dst[0].into(),
+                        srcs: [scratch[0].into(), self.get_src(&srcs[0])],
+                        ops: [
+                            FSwzAddOp::SubLeft,
+                            FSwzAddOp::SubRight,
+                            FSwzAddOp::SubLeft,
+                            FSwzAddOp::SubRight,
+                        ],
+                        rnd_mode: self.float_ctl[ftype].rnd_mode,
+                        ftz: self.float_ctl[ftype].ftz,
+                    });
+                } else {
+                    b.push_op(OpFSwz {
+                        dst: dst[0].into(),
+                        srcs: [self.get_src(&srcs[0]), self.get_src(&srcs[0])],
+                        ops: [
+                            FSwzAddOp::SubLeft,
+                            FSwzAddOp::SubRight,
+                            FSwzAddOp::SubLeft,
+                            FSwzAddOp::SubRight,
+                        ],
+                        rnd_mode: self.float_ctl[ftype].rnd_mode,
+                        ftz: self.float_ctl[ftype].ftz,
+                        shuffle: FSwzShuffle::SwapHorizontal,
+                    });
+                }
 
                 self.set_dst(&intrin.def, dst);
             }
@@ -2321,31 +2345,47 @@ impl<'a> ShaderFromNir<'a> {
 
                 assert!(intrin.def.bit_size() == 32);
                 let ftype = FloatType::F32;
-                let scratch = b.alloc_ssa(RegFile::GPR, 1);
+                let dst = b.alloc_ssa(RegFile::GPR, 1);
 
-                b.push_op(OpShfl {
-                    dst: scratch[0].into(),
-                    in_bounds: Dst::None,
-                    src: self.get_src(&srcs[0]),
-                    lane: 2_u32.into(),
-                    c: (0x3_u32 | 0x1c_u32 << 8).into(),
-                    op: ShflOp::Bfly,
-                });
+                if self.sm.sm() >= 50 {
+                    let scratch = b.alloc_ssa(RegFile::GPR, 1);
 
-                let dst = b.alloc_ssa(RegFile::GPR, 1);
+                    b.push_op(OpShfl {
+                        dst: scratch[0].into(),
+                        in_bounds: Dst::None,
+                        src: self.get_src(&srcs[0]),
+                        lane: 2_u32.into(),
+                        c: (0x3_u32 | 0x1c_u32 << 8).into(),
+                        op: ShflOp::Bfly,
+                    });
 
-                b.push_op(OpFSwzAdd {
-                    dst: dst[0].into(),
-                    srcs: [scratch[0].into(), self.get_src(&srcs[0])],
-                    ops: [
-                        FSwzAddOp::SubLeft,
-                        FSwzAddOp::SubLeft,
-                        FSwzAddOp::SubRight,
-                        FSwzAddOp::SubRight,
-                    ],
-                    rnd_mode: self.float_ctl[ftype].rnd_mode,
-                    ftz: self.float_ctl[ftype].ftz,
-                });
+                    b.push_op(OpFSwzAdd {
+                        dst: dst[0].into(),
+                        srcs: [scratch[0].into(), self.get_src(&srcs[0])],
+                        ops: [
+                            FSwzAddOp::SubLeft,
+                            FSwzAddOp::SubLeft,
+                            FSwzAddOp::SubRight,
+                            FSwzAddOp::SubRight,
+                        ],
+                        rnd_mode: self.float_ctl[ftype].rnd_mode,
+                        ftz: self.float_ctl[ftype].ftz,
+                    });
+                } else {
+                    b.push_op(OpFSwz {
+                        dst: dst[0].into(),
+                        srcs: [self.get_src(&srcs[0]), self.get_src(&srcs[0])],
+                        ops: [
+                            FSwzAddOp::SubLeft,
+                            FSwzAddOp::SubLeft,
+                            FSwzAddOp::SubRight,
+                            FSwzAddOp::SubRight,
+                        ],
+                        rnd_mode: self.float_ctl[ftype].rnd_mode,
+                        ftz: self.float_ctl[ftype].ftz,
+                        shuffle: FSwzShuffle::SwapVertical,
+                    });
+                }
 
                 self.set_dst(&intrin.def, dst);
             }
@@ -2942,7 +2982,9 @@ impl<'a> ShaderFromNir<'a> {
                 );
                 let comps = intrin.def.bit_size / 32;
                 let dst = b.alloc_ssa(RegFile::GPR, comps);
-                if idx == NAK_SV_CLOCK || idx == NAK_SV_CLOCK + 1 {
+                if self.sm.sm() >= 50
+                    && (idx == NAK_SV_CLOCK || idx == NAK_SV_CLOCK + 1)
+                {
                     debug_assert!(idx + comps <= NAK_SV_CLOCK + 2);
                     b.push_op(OpCS2R {
                         dst: dst.into(),
diff --git a/src/nouveau/compiler/nak/hw_tests.rs b/src/nouveau/compiler/nak/hw_tests.rs
index 8481cd79384..8f2a8cba441 100644
--- a/src/nouveau/compiler/nak/hw_tests.rs
+++ b/src/nouveau/compiler/nak/hw_tests.rs
@@ -918,6 +918,9 @@ fn test_op_popc() {
 #[test]
 fn test_op_shf() {
     let sm = &RunSingleton::get().sm;
+    if sm.sm() < 32 {
+        return;
+    }
 
     let types = [IntType::U32, IntType::I32, IntType::U64, IntType::I64];
 
@@ -1249,6 +1252,10 @@ fn test_isetp64() {
 #[test]
 fn test_shl64() {
     let run = RunSingleton::get();
+    if run.sm.sm() < 32 {
+        return;
+    }
+
     let invocations = 100;
 
     let mut b = TestShaderBuilder::new(run.sm.as_ref());
@@ -1283,6 +1290,10 @@ fn test_shl64() {
 #[test]
 fn test_shr64() {
     let run = RunSingleton::get();
+    if run.sm.sm() < 32 {
+        return;
+    }
+
     let invocations = 100;
 
     let cases = [true, false];
diff --git a/src/nouveau/compiler/nak/ir.rs b/src/nouveau/compiler/nak/ir.rs
index cfa419c6fe3..ae05ff6345f 100644
--- a/src/nouveau/compiler/nak/ir.rs
+++ b/src/nouveau/compiler/nak/ir.rs
@@ -1094,10 +1094,6 @@ impl Src {
         b.into()
     }
 
-    pub fn is_unmodified(&self) -> bool {
-        self.src_mod.is_none() && self.src_swizzle.is_none()
-    }
-
     pub fn fabs(&self) -> Src {
         Src {
             src_ref: self.src_ref,
@@ -1135,7 +1131,7 @@ impl Src {
             return *self;
         };
 
-        if self.is_unmodified() {
+        if self.src_mod.is_none() && self.src_swizzle.is_none() {
             return *self;
         }
 
@@ -1193,7 +1189,7 @@ impl Src {
                 _ => panic!("Not a bitwise source modifier"),
             },
             _ => {
-                assert!(self.is_unmodified());
+                assert!(self.src_mod.is_none());
                 u
             }
         };
@@ -1206,7 +1202,7 @@ impl Src {
     }
 
     pub fn as_ssa(&self) -> Option<&SSARef> {
-        if self.is_unmodified() {
+        if self.src_mod.is_none() {
             self.src_ref.as_ssa()
         } else {
             None
@@ -1230,7 +1226,7 @@ impl Src {
     }
 
     pub fn as_u32(&self) -> Option<u32> {
-        if self.is_unmodified() {
+        if self.src_mod.is_none() {
             self.src_ref.as_u32()
         } else {
             None
@@ -1240,7 +1236,7 @@ impl Src {
     pub fn as_imm_not_i20(&self) -> Option<u32> {
         match self.src_ref {
             SrcRef::Imm32(i) => {
-                assert!(self.is_unmodified());
+                assert!(self.src_mod.is_none());
                 let top = i & 0xfff80000;
                 if top == 0 || top == 0xfff80000 {
                     None
@@ -1255,7 +1251,7 @@ impl Src {
     pub fn as_imm_not_f20(&self) -> Option<u32> {
         match self.src_ref {
             SrcRef::Imm32(i) => {
-                assert!(self.is_unmodified());
+                assert!(self.src_mod.is_none());
                 if (i & 0xfff) == 0 {
                     None
                 } else {
@@ -1313,6 +1309,7 @@ impl Src {
 
     pub fn is_fneg_zero(&self, src_type: SrcType) -> bool {
         match self.fold_imm(src_type).src_ref {
+            SrcRef::Zero => self.src_mod == SrcMod::FNeg,
             SrcRef::Imm32(0x00008000) => src_type == SrcType::F16,
             SrcRef::Imm32(0x80000000) => src_type == SrcType::F32,
             SrcRef::Imm32(0x80008000) => src_type == SrcType::F16v2,
@@ -1324,14 +1321,14 @@ impl Src {
     pub fn supports_type(&self, src_type: &SrcType) -> bool {
         match src_type {
             SrcType::SSA => {
-                if !self.is_unmodified() {
+                if !self.src_mod.is_none() {
                     return false;
                 }
 
                 matches!(self.src_ref, SrcRef::SSA(_) | SrcRef::Reg(_))
             }
             SrcType::GPR => {
-                if !self.is_unmodified() {
+                if !self.src_mod.is_none() {
                     return false;
                 }
 
@@ -1340,7 +1337,7 @@ impl Src {
                     SrcRef::Zero | SrcRef::SSA(_) | SrcRef::Reg(_)
                 )
             }
-            SrcType::ALU => self.is_unmodified() && self.src_ref.is_alu(),
+            SrcType::ALU => self.src_mod.is_none() && self.src_ref.is_alu(),
             SrcType::F16 | SrcType::F32 | SrcType::F64 | SrcType::F16v2 => {
                 match self.src_mod {
                     SrcMod::None
@@ -1376,8 +1373,8 @@ impl Src {
 
                 self.src_ref.is_predicate()
             }
-            SrcType::Carry => self.is_unmodified() && self.src_ref.is_carry(),
-            SrcType::Bar => self.is_unmodified() && self.src_ref.is_barrier(),
+            SrcType::Carry => self.src_mod.is_none() && self.src_ref.is_carry(),
+            SrcType::Bar => self.src_mod.is_none() && self.src_ref.is_barrier(),
         }
     }
 }
@@ -2107,6 +2104,18 @@ pub enum TexLodMode {
     BiasClamp,
 }
 
+impl TexLodMode {
+    pub fn is_explicit_lod(&self) -> bool {
+        match self {
+            TexLodMode::Auto
+            | TexLodMode::Bias
+            | TexLodMode::Clamp
+            | TexLodMode::BiasClamp => false,
+            TexLodMode::Zero | TexLodMode::Lod => true,
+        }
+    }
+}
+
 impl fmt::Display for TexLodMode {
     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
         match self {
@@ -2526,6 +2535,15 @@ impl AtomType {
             AtomType::U64 | AtomType::I64 | AtomType::F64 => 64,
         }
     }
+
+    pub fn is_float(&self) -> bool {
+        match self {
+            AtomType::F16x2 | AtomType::F32 | AtomType::F64 => true,
+            AtomType::U32 | AtomType::I32 | AtomType::U64 | AtomType::I64 => {
+                false
+            }
+        }
+    }
 }
 
 impl fmt::Display for AtomType {
@@ -2872,6 +2890,80 @@ impl DisplayOp for OpFSwzAdd {
 }
 impl_display_for_op!(OpFSwzAdd);
 
+/// Describes where the second src is taken before doing the ops
+#[allow(dead_code)]
+#[derive(Clone, Copy, Eq, PartialEq)]
+pub enum FSwzShuffle {
+    Quad0,
+    Quad1,
+    Quad2,
+    Quad3,
+    // swap [0, 1] and [2, 3]
+    SwapHorizontal,
+    // swap [0, 2] and [1, 3]
+    SwapVertical,
+}
+
+impl fmt::Display for FSwzShuffle {
+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+        match self {
+            FSwzShuffle::Quad0 => write!(f, ".0000"),
+            FSwzShuffle::Quad1 => write!(f, ".1111"),
+            FSwzShuffle::Quad2 => write!(f, ".2222"),
+            FSwzShuffle::Quad3 => write!(f, ".3333"),
+            FSwzShuffle::SwapHorizontal => write!(f, ".1032"),
+            FSwzShuffle::SwapVertical => write!(f, ".2301"),
+        }
+    }
+}
+
+/// Op only present in Kepler and older
+/// It first does a shuffle on the second src and then applies
+/// src0 op src1, each thread on a quad might do a different operation.
+///
+/// This is used to encode ddx/ddy
+/// ex: ddx
+///   src1 = shuffle swap horizontal src1
+///   ops = [sub, subr, sub, subr]
+#[repr(C)]
+#[derive(SrcsAsSlice, DstsAsSlice)]
+pub struct OpFSwz {
+    #[dst_type(F32)]
+    pub dst: Dst,
+
+    #[src_type(GPR)]
+    pub srcs: [Src; 2],
+
+    pub rnd_mode: FRndMode,
+    pub ftz: bool,
+    pub shuffle: FSwzShuffle,
+
+    pub ops: [FSwzAddOp; 4],
+}
+
+impl DisplayOp for OpFSwz {
+    fn fmt_op(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+        write!(f, "fswz{}", self.shuffle)?;
+        if self.rnd_mode != FRndMode::NearestEven {
+            write!(f, "{}", self.rnd_mode)?;
+        }
+        if self.ftz {
+            write!(f, ".ftz")?;
+        }
+        write!(
+            f,
+            " {} {} [{}, {}, {}, {}]",
+            self.srcs[0],
+            self.srcs[1],
+            self.ops[0],
+            self.ops[1],
+            self.ops[2],
+            self.ops[3],
+        )
+    }
+}
+impl_display_for_op!(OpFSwz);
+
 pub enum RroOp {
     SinCos,
     Exp2,
@@ -5819,6 +5911,25 @@ impl DisplayOp for OpBar {
 }
 impl_display_for_op!(OpBar);
 
+/// Instruction only used on Kepler(A|B).
+/// Kepler has explicit dependency tracking for texture loads.
+/// When a texture load is executed, it is put on some kind of FIFO queue
+/// for later execution.
+/// Before the results of a texture are used we need to wait on the queue,
+/// texdepbar waits until the queue has at most `textures_left` elements.
+#[repr(C)]
+#[derive(SrcsAsSlice, DstsAsSlice)]
+pub struct OpTexDepBar {
+    pub textures_left: i8,
+}
+
+impl DisplayOp for OpTexDepBar {
+    fn fmt_op(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+        write!(f, "texdepbar {}", self.textures_left)
+    }
+}
+impl_display_for_op!(OpTexDepBar);
+
 #[repr(C)]
 #[derive(SrcsAsSlice, DstsAsSlice)]
 pub struct OpCS2R {
@@ -6456,6 +6567,7 @@ pub enum Op {
     FSet(OpFSet),
     FSetP(OpFSetP),
     FSwzAdd(OpFSwzAdd),
+    FSwz(OpFSwz),
     DAdd(OpDAdd),
     DFma(OpDFma),
     DMnMx(OpDMnMx),
@@ -6538,6 +6650,7 @@ pub enum Op {
     Exit(OpExit),
     WarpSync(OpWarpSync),
     Bar(OpBar),
+    TexDepBar(OpTexDepBar),
     CS2R(OpCS2R),
     Isberd(OpIsberd),
     Kill(OpKill),
@@ -6573,6 +6686,24 @@ impl Op {
         }
     }
 
+    pub fn is_fp64(&self) -> bool {
+        match self {
+            Op::MuFu(op) => matches!(op.op, MuFuOp::Rcp64H | MuFuOp::Rsq64H),
+            Op::DAdd(_)
+            | Op::DFma(_)
+            | Op::DMnMx(_)
+            | Op::DMul(_)
+            | Op::DSetP(_) => true,
+            Op::F2F(op) => op.src_type.bits() == 64 || op.dst_type.bits() == 64,
+            Op::F2I(op) => op.src_type.bits() == 64 || op.dst_type.bits() == 64,
+            Op::I2F(op) => op.src_type.bits() == 64 || op.dst_type.bits() == 64,
+            Op::FRnd(op) => {
+                op.src_type.bits() == 64 || op.dst_type.bits() == 64
+            }
+            _ => false,
+        }
+    }
+
     pub fn has_fixed_latency(&self, sm: u8) -> bool {
         match self {
             // Float ALU
@@ -6589,6 +6720,7 @@ impl Op {
             | Op::HSet2(_)
             | Op::HSetP2(_)
             | Op::HMnMx2(_)
+            | Op::FSwz(_)
             | Op::FSwzAdd(_) => true,
 
             // Multi-function unit is variable latency
@@ -6687,6 +6819,7 @@ impl Op {
 
             // Miscellaneous ops
             Op::Bar(_)
+            | Op::TexDepBar(_)
             | Op::CS2R(_)
             | Op::Isberd(_)
             | Op::Kill(_)
@@ -7077,6 +7210,7 @@ impl Instr {
             | Op::Exit(_)
             | Op::WarpSync(_)
             | Op::Bar(_)
+            | Op::TexDepBar(_)
             | Op::RegOut(_)
             | Op::Out(_)
             | Op::OutFinal(_)
@@ -7769,6 +7903,7 @@ impl Shader<'_> {
         let mut num_instrs = 0;
         let mut uses_global_mem = false;
         let mut writes_global_mem = false;
+        let mut uses_fp64 = false;
 
         self.for_each_instr(&mut |instr| {
             num_instrs += 1;
@@ -7780,11 +7915,16 @@ impl Shader<'_> {
             if !writes_global_mem {
                 writes_global_mem = instr.writes_global_mem();
             }
+
+            if !uses_fp64 {
+                uses_fp64 = instr.op.is_fp64();
+            }
         });
 
         self.info.num_instrs = num_instrs;
         self.info.uses_global_mem = uses_global_mem;
         self.info.writes_global_mem = writes_global_mem;
+        self.info.uses_fp64 = uses_fp64;
 
         self.info.max_warps_per_sm = max_warps_per_sm(
             self.info.num_gprs as u32 + self.sm.hw_reserved_gprs(),
diff --git a/src/nouveau/compiler/nak/lib.rs b/src/nouveau/compiler/nak/lib.rs
index 0101dbe3013..fb6237f4a26 100644
--- a/src/nouveau/compiler/nak/lib.rs
+++ b/src/nouveau/compiler/nak/lib.rs
@@ -43,3 +43,6 @@ mod hw_tests;
 
 #[cfg(test)]
 mod hw_runner;
+
+#[cfg(test)]
+mod nvdisasm_tests;
diff --git a/src/nouveau/compiler/nak/lower_copy_swap.rs b/src/nouveau/compiler/nak/lower_copy_swap.rs
index 0e3edd49b0d..0b4c2b4b027 100644
--- a/src/nouveau/compiler/nak/lower_copy_swap.rs
+++ b/src/nouveau/compiler/nak/lower_copy_swap.rs
@@ -24,7 +24,7 @@ impl LowerCopySwap {
     fn lower_copy(&mut self, b: &mut impl Builder, copy: OpCopy) {
         let dst_reg = copy.dst.as_reg().unwrap();
         assert!(dst_reg.comps() == 1);
-        assert!(copy.src.is_unmodified());
+        assert!(copy.src.src_mod.is_none());
         assert!(copy.src.is_uniform() || !dst_reg.is_uniform());
 
         match dst_reg.file() {
@@ -177,7 +177,7 @@ impl LowerCopySwap {
     }
 
     fn lower_r2ur(&mut self, b: &mut impl Builder, r2ur: OpR2UR) {
-        assert!(r2ur.src.is_unmodified());
+        assert!(r2ur.src.src_mod.is_none());
         if r2ur.src.is_uniform() {
             let copy = OpCopy {
                 dst: r2ur.dst,
@@ -214,9 +214,9 @@ impl LowerCopySwap {
         assert!(x.file() == y.file());
         assert!(x.file() != RegFile::Mem);
         assert!(x.comps() == 1 && y.comps() == 1);
-        assert!(swap.srcs[0].is_unmodified());
+        assert!(swap.srcs[0].src_mod.is_none());
         assert!(*swap.srcs[0].src_ref.as_reg().unwrap() == y);
-        assert!(swap.srcs[1].is_unmodified());
+        assert!(swap.srcs[1].src_mod.is_none());
         assert!(*swap.srcs[1].src_ref.as_reg().unwrap() == x);
 
         if x == y {
diff --git a/src/nouveau/compiler/nak/lower_par_copies.rs b/src/nouveau/compiler/nak/lower_par_copies.rs
index 40a534ed524..d51e8248031 100644
--- a/src/nouveau/compiler/nak/lower_par_copies.rs
+++ b/src/nouveau/compiler/nak/lower_par_copies.rs
@@ -110,7 +110,7 @@ fn lower_par_copy(pc: OpParCopy, sm: &dyn ShaderModel) -> MappedInstrs {
     }
 
     for (dst_idx, (_, src)) in pc.dsts_srcs.iter().enumerate() {
-        assert!(src.is_unmodified());
+        assert!(src.src_mod.is_none());
         let src = src.src_ref;
 
         let src_idx = if let SrcRef::Reg(reg) = src {
diff --git a/src/nouveau/compiler/nak/nvdisasm_tests.rs b/src/nouveau/compiler/nak/nvdisasm_tests.rs
new file mode 100644
index 00000000000..96de8d5ad43
--- /dev/null
+++ b/src/nouveau/compiler/nak/nvdisasm_tests.rs
@@ -0,0 +1,594 @@
+// Copyright Â© 2025 Valve Corporation
+// SPDX-License-Identifier: MIT
+
+use crate::ir::*;
+use crate::sm70::ShaderModel70;
+use compiler::cfg::CFGBuilder;
+
+use std::io::Write;
+use std::mem;
+use std::process;
+use std::process::Command;
+use std::slice;
+use std::sync::atomic::AtomicUsize;
+
+static FILE_NUM: AtomicUsize = AtomicUsize::new(0);
+
+fn run_nvdisasm(s: &Shader) -> String {
+    let code = s.sm.encode_shader(s);
+    // println!("{code:x?}");
+
+    let slice_u8: &[u8] = unsafe {
+        slice::from_raw_parts(
+            code.as_ptr() as *const u8,
+            code.len() * mem::size_of::<u32>(),
+        )
+    };
+
+    let tmp_file = format!(
+        "/tmp/nak_dis_{}_{}",
+        process::id(),
+        FILE_NUM.fetch_add(1, std::sync::atomic::Ordering::Relaxed)
+    );
+    std::fs::write(&tmp_file, slice_u8).expect("Failed to write file");
+
+    let out = Command::new("nvdisasm")
+        .arg("-b")
+        .arg(format!("SM{}", s.sm.sm()))
+        .arg("--print-raw")
+        .arg(&tmp_file)
+        .output()
+        .expect("failed to execute process");
+
+    std::io::stderr().write_all(&out.stderr).expect("IO error");
+    assert!(out.status.success());
+    let stdout = std::str::from_utf8(&out.stdout).unwrap();
+    std::fs::remove_file(tmp_file).unwrap();
+    stdout.into()
+}
+
+fn disassemble_instrs(instrs: Vec<Box<Instr>>, sm: u8) -> Vec<String> {
+    let mut label_alloc = LabelAllocator::new();
+    let block = BasicBlock {
+        label: label_alloc.alloc(),
+        uniform: true,
+        instrs,
+    };
+
+    let mut cfg = CFGBuilder::new();
+    cfg.add_node(0, block);
+
+    let f = Function {
+        ssa_alloc: SSAValueAllocator::new(),
+        phi_alloc: PhiAllocator::new(),
+        blocks: cfg.as_cfg(),
+    };
+
+    let cs_info = ComputeShaderInfo {
+        local_size: [32, 1, 1],
+        smem_size: 0,
+    };
+    let info = ShaderInfo {
+        max_warps_per_sm: 0,
+        num_gprs: 0,
+        num_control_barriers: 0,
+        num_instrs: 0,
+        num_static_cycles: 0,
+        num_spills_to_mem: 0,
+        num_fills_from_mem: 0,
+        num_spills_to_reg: 0,
+        num_fills_from_reg: 0,
+        slm_size: 0,
+        max_crs_depth: 0,
+        uses_global_mem: true,
+        writes_global_mem: true,
+        uses_fp64: false,
+        stage: ShaderStageInfo::Compute(cs_info),
+        io: ShaderIoInfo::None,
+    };
+
+    let sm: Box<dyn ShaderModel> = Box::new(ShaderModel70::new(sm));
+    let s = Shader {
+        sm: &*sm,
+        info: info,
+        functions: vec![f],
+    };
+    let out = run_nvdisasm(&s);
+    let out: Vec<String> = out
+        .lines()
+        .map(|line| {
+            let mut line: String = line
+                .trim_start_matches(|c| -> bool {
+                    match c {
+                        '/' | '*' => true,
+                        'a'..='f' => true, // Actual instructions are uppercase
+                        _ => c.is_numeric() || c.is_whitespace(),
+                    }
+                })
+                .trim()
+                .into();
+            line.make_ascii_lowercase();
+            line
+        })
+        .collect();
+
+    out
+}
+
+struct DisasmCheck {
+    instrs: Vec<Box<Instr>>,
+    expected: Vec<String>,
+}
+
+impl DisasmCheck {
+    fn new() -> Self {
+        DisasmCheck {
+            instrs: Vec::new(),
+            expected: Vec::new(),
+        }
+    }
+
+    fn push(&mut self, instr: impl Into<Instr>, expected: impl Into<String>) {
+        self.instrs.push(Box::new(instr.into()));
+        self.expected.push(expected.into());
+    }
+
+    fn check(mut self, sm: u8) {
+        assert!(self.expected.len() > 0);
+        let actual = disassemble_instrs(std::mem::take(&mut self.instrs), sm);
+        assert_eq!(actual.len(), self.expected.len());
+
+        let mut any_different = false;
+        for (a, e) in actual
+            .into_iter()
+            .zip(std::mem::take(&mut self.expected).into_iter())
+        {
+            if a != e {
+                if !any_different {
+                    eprintln!("Error: Difference on SM{sm}");
+                    any_different = true;
+                }
+                eprintln!("actual: {a}");
+                eprintln!("expect: {e}\n");
+            }
+        }
+        if any_different {
+            panic!("Differences found");
+        }
+    }
+}
+
+const SM_LIST: [u8; 8] = [70, 75, 80, 86, 89, 90, 100, 120];
+
+#[test]
+pub fn test_nop() {
+    for sm in SM_LIST {
+        let mut c = DisasmCheck::new();
+        c.push(OpNop { label: None }, "nop;");
+        c.check(sm);
+    }
+}
+
+#[test]
+pub fn test_ld_st_atom() {
+    let r0 = RegRef::new(RegFile::GPR, 0, 1);
+    let r1 = RegRef::new(RegFile::GPR, 1, 1);
+    let r2 = RegRef::new(RegFile::GPR, 2, 1);
+    let r3 = RegRef::new(RegFile::GPR, 3, 1);
+
+    let order = MemOrder::Strong(MemScope::CTA);
+
+    let atom_types = [
+        (AtomType::F16x2, ".f16x2.rn"),
+        (AtomType::U32, ""),
+        (AtomType::I32, ".s32"),
+        (AtomType::F32, ".f32.ftz.rn"),
+        (AtomType::U64, ".64"),
+        (AtomType::I64, ".s64"),
+        (AtomType::F64, ".f64.rn"),
+    ];
+
+    let spaces = [
+        MemSpace::Global(MemAddrType::A64),
+        MemSpace::Shared,
+        MemSpace::Local,
+    ];
+
+    for sm in SM_LIST {
+        let mut c = DisasmCheck::new();
+        for space in spaces {
+            for (addr_offset, addr_offset_str) in [(0x12, "0x12"), (-1, "-0x1")]
+            {
+                let cta = if sm >= 80 { "sm" } else { "cta" };
+
+                let pri = match space {
+                    MemSpace::Global(_) => MemEvictionPriority::First,
+                    MemSpace::Shared => MemEvictionPriority::Normal,
+                    MemSpace::Local => MemEvictionPriority::Normal,
+                };
+                let access = MemAccess {
+                    mem_type: MemType::B32,
+                    space,
+                    order: order,
+                    eviction_priority: pri,
+                };
+
+                let instr = OpLd {
+                    dst: Dst::Reg(r0),
+                    addr: SrcRef::Reg(r1).into(),
+                    offset: addr_offset,
+                    access: access.clone(),
+                };
+                let expected = match space {
+                    MemSpace::Global(_) => {
+                        format!(
+                            "ldg.e.ef.strong.{cta} r0, [r1+{addr_offset_str}];"
+                        )
+                    }
+                    MemSpace::Shared => {
+                        format!("lds r0, [r1+{addr_offset_str}];")
+                    }
+                    MemSpace::Local => {
+                        format!("ldl r0, [r1+{addr_offset_str}];")
+                    }
+                };
+                c.push(instr, expected);
+
+                let instr = OpSt {
+                    addr: SrcRef::Reg(r1).into(),
+                    data: SrcRef::Reg(r2).into(),
+                    offset: addr_offset,
+                    access: access.clone(),
+                };
+                let expected = match space {
+                    MemSpace::Global(_) => {
+                        format!(
+                            "stg.e.ef.strong.{cta} [r1+{addr_offset_str}], r2;"
+                        )
+                    }
+                    MemSpace::Shared => {
+                        format!("sts [r1+{addr_offset_str}], r2;")
+                    }
+                    MemSpace::Local => {
+                        format!("stl [r1+{addr_offset_str}], r2;")
+                    }
+                };
+                c.push(instr, expected);
+
+                for (atom_type, atom_type_str) in atom_types {
+                    for use_dst in [true, false] {
+                        let instr = OpAtom {
+                            dst: if use_dst { Dst::Reg(r0) } else { Dst::None },
+                            addr: SrcRef::Reg(r1).into(),
+                            data: SrcRef::Reg(r2).into(),
+                            atom_op: AtomOp::Add,
+                            cmpr: SrcRef::Reg(r3).into(),
+                            atom_type,
+
+                            addr_offset,
+
+                            mem_space: space,
+                            mem_order: order,
+                            mem_eviction_priority: pri,
+                        };
+
+                        let expected = match space {
+                            MemSpace::Global(_) => {
+                                let op = if use_dst {
+                                    "atomg"
+                                } else if sm >= 90 {
+                                    "redg"
+                                } else {
+                                    "red"
+                                };
+                                let dst = if use_dst { "pt, r0, " } else { "" };
+                                format!("{op}.e.add.ef{atom_type_str}.strong.{cta} {dst}[r1+{addr_offset_str}], r2;")
+                            }
+                            MemSpace::Shared => {
+                                if atom_type.is_float() {
+                                    continue;
+                                }
+                                if atom_type.bits() == 64 {
+                                    continue;
+                                }
+                                let dst = if use_dst { "r0" } else { "rz" };
+                                format!("atoms.add{atom_type_str} {dst}, [r1+{addr_offset_str}], r2;")
+                            }
+                            MemSpace::Local => continue,
+                        };
+
+                        c.push(instr, expected);
+                    }
+                }
+            }
+        }
+        c.check(sm);
+    }
+}
+
+#[test]
+pub fn test_texture() {
+    let r0 = RegRef::new(RegFile::GPR, 0, 1);
+    let r1 = RegRef::new(RegFile::GPR, 1, 1);
+    let r2 = RegRef::new(RegFile::GPR, 2, 1);
+    let r3 = RegRef::new(RegFile::GPR, 3, 1);
+    let p0 = RegRef::new(RegFile::Pred, 0, 1);
+
+    let lod_modes = [
+        TexLodMode::Auto,
+        TexLodMode::Zero,
+        TexLodMode::Lod,
+        TexLodMode::Bias,
+        TexLodMode::Clamp,
+        TexLodMode::BiasClamp,
+    ];
+
+    let tld4_offset_modes = [
+        Tld4OffsetMode::None,
+        Tld4OffsetMode::AddOffI,
+        Tld4OffsetMode::PerPx,
+    ];
+
+    let tex_queries = [
+        TexQuery::Dimension,
+        TexQuery::TextureType,
+        TexQuery::SamplerPos,
+    ];
+
+    for sm in SM_LIST {
+        let mut c = DisasmCheck::new();
+        for lod_mode in lod_modes {
+            let lod_mode_str = if lod_mode == TexLodMode::Auto {
+                String::new()
+            } else {
+                format!(".{lod_mode}")
+            };
+            if lod_mode == TexLodMode::BiasClamp && sm >= 100 {
+                continue;
+            }
+
+            let instr = OpTex {
+                dsts: [Dst::Reg(r0), Dst::Reg(r2)],
+                fault: Dst::Reg(p0),
+
+                tex: TexRef::Bindless,
+
+                srcs: [SrcRef::Reg(r1).into(), SrcRef::Reg(r3).into()],
+
+                dim: TexDim::_2D,
+                lod_mode,
+                z_cmpr: false,
+                offset: false,
+                mem_eviction_priority: MemEvictionPriority::First,
+                nodep: true,
+                channel_mask: ChannelMask::for_comps(3),
+            };
+            c.push(
+                instr,
+                format!(
+                    "tex.b{lod_mode_str}.ef.nodep p0, r2, r0, r1, r3, 2d, 0x7;"
+                ),
+            );
+
+            if lod_mode.is_explicit_lod() {
+                let instr = OpTld {
+                    dsts: [Dst::Reg(r0), Dst::Reg(r2)],
+                    fault: Dst::Reg(p0),
+
+                    tex: TexRef::Bindless,
+
+                    srcs: [SrcRef::Reg(r1).into(), SrcRef::Reg(r3).into()],
+
+                    dim: TexDim::_2D,
+                    is_ms: false,
+                    lod_mode,
+                    offset: false,
+                    mem_eviction_priority: MemEvictionPriority::First,
+                    nodep: true,
+                    channel_mask: ChannelMask::for_comps(3),
+                };
+                c.push(
+                    instr,
+                    format!("tld.b{lod_mode_str}.ef.nodep p0, r2, r0, r1, r3, 2d, 0x7;"),
+                );
+            }
+        }
+
+        for offset_mode in tld4_offset_modes {
+            let offset_mode_str = if offset_mode == Tld4OffsetMode::None {
+                String::new()
+            } else {
+                format!(".{offset_mode}")
+            };
+
+            let instr = OpTld4 {
+                dsts: [Dst::Reg(r0), Dst::Reg(r2)],
+                fault: Dst::Reg(p0),
+
+                tex: TexRef::Bindless,
+
+                srcs: [SrcRef::Reg(r1).into(), SrcRef::Reg(r3).into()],
+
+                dim: TexDim::_2D,
+                comp: 1,
+                offset_mode,
+                z_cmpr: false,
+                mem_eviction_priority: MemEvictionPriority::First,
+                nodep: true,
+                channel_mask: ChannelMask::for_comps(3),
+            };
+            c.push(
+                instr,
+                format!("tld4.g.b{offset_mode_str}.ef.nodep p0, r2, r0, r1, r3, 2d, 0x7;"),
+            );
+        }
+
+        let instr = OpTmml {
+            dsts: [Dst::Reg(r0), Dst::Reg(r2)],
+
+            tex: TexRef::Bindless,
+
+            srcs: [SrcRef::Reg(r1).into(), SrcRef::Reg(r3).into()],
+
+            dim: TexDim::_2D,
+            nodep: true,
+            channel_mask: ChannelMask::for_comps(3),
+        };
+        c.push(instr, format!("tmml.b.lod.nodep r2, r0, r1, r3, 2d, 0x7;"));
+
+        let instr = OpTxd {
+            dsts: [Dst::Reg(r0), Dst::Reg(r2)],
+            fault: Dst::Reg(p0),
+
+            tex: TexRef::Bindless,
+
+            srcs: [SrcRef::Reg(r1).into(), SrcRef::Reg(r3).into()],
+
+            dim: TexDim::_2D,
+            offset: false,
+            mem_eviction_priority: MemEvictionPriority::First,
+            nodep: true,
+            channel_mask: ChannelMask::for_comps(3),
+        };
+        c.push(
+            instr,
+            format!("txd.b.ef.nodep p0, r2, r0, r1, r3, 2d, 0x7;"),
+        );
+
+        for tex_query in tex_queries {
+            let instr = OpTxq {
+                dsts: [Dst::Reg(r0), Dst::Reg(r2)],
+
+                tex: TexRef::Bindless,
+
+                src: SrcRef::Reg(r1).into(),
+
+                query: tex_query,
+                nodep: true,
+                channel_mask: ChannelMask::for_comps(3),
+            };
+            c.push(
+                instr,
+                format!("txq.b.nodep r2, r0, r1, tex_header_{tex_query}, 0x7;"),
+            );
+        }
+
+        c.check(sm);
+    }
+}
+
+#[test]
+pub fn test_lea() {
+    let r0 = RegRef::new(RegFile::GPR, 0, 1);
+    let r1 = RegRef::new(RegFile::GPR, 1, 1);
+    let r2 = RegRef::new(RegFile::GPR, 2, 1);
+    let r3 = RegRef::new(RegFile::GPR, 3, 1);
+    let p0 = RegRef::new(RegFile::Pred, 0, 1);
+
+    let src_mods = [
+        (SrcMod::None, SrcMod::None),
+        (SrcMod::INeg, SrcMod::None),
+        (SrcMod::None, SrcMod::INeg),
+    ];
+
+    for sm in SM_LIST {
+        let mut c = DisasmCheck::new();
+
+        for (intermediate_mod, b_mod) in src_mods {
+            for shift in 0..32 {
+                let intermediate_mod_str = match intermediate_mod {
+                    SrcMod::None => "",
+                    SrcMod::INeg => "-",
+                    _ => unreachable!(),
+                };
+
+                let mut instr = OpLea {
+                    dst: Dst::Reg(r0),
+                    overflow: Dst::Reg(p0),
+
+                    a: SrcRef::Reg(r1).into(),
+                    b: SrcRef::Reg(r2).into(),
+
+                    a_high: 0.into(),
+
+                    shift,
+                    dst_high: false,
+                    intermediate_mod,
+                };
+                instr.b.src_mod = b_mod;
+                let disasm = format!(
+                    "lea r0, p0, {0}r1, {1}, 0x{2:x};",
+                    intermediate_mod_str, instr.b, shift
+                );
+                c.push(instr, disasm);
+
+                let mut instr = OpLea {
+                    dst: Dst::Reg(r0),
+                    overflow: Dst::Reg(p0),
+
+                    a: SrcRef::Reg(r1).into(),
+                    b: SrcRef::Reg(r2).into(),
+
+                    a_high: SrcRef::Reg(r3).into(),
+
+                    shift,
+                    dst_high: true,
+                    intermediate_mod,
+                };
+                instr.b.src_mod = b_mod;
+                let disasm = format!(
+                    "lea.hi r0, p0, {0}r1, {1}, r3, 0x{2:x};",
+                    intermediate_mod_str, instr.b, shift
+                );
+                c.push(instr, disasm);
+            }
+        }
+
+        c.check(sm);
+    }
+}
+
+#[test]
+pub fn test_hfma2() {
+    let r0 = RegRef::new(RegFile::GPR, 0, 1);
+    let r1 = RegRef::new(RegFile::GPR, 1, 1);
+    let r2 = RegRef::new(RegFile::GPR, 2, 1);
+    let r3 = RegRef::new(RegFile::GPR, 3, 1);
+
+    let src_mods = [SrcMod::None, SrcMod::FAbs, SrcMod::FNeg, SrcMod::FNegAbs];
+
+    for sm in SM_LIST {
+        let mut c = DisasmCheck::new();
+
+        for a_mod in src_mods {
+            for b_mod in src_mods {
+                for c_mod in src_mods {
+                    let mut instr = OpHFma2 {
+                        dst: Dst::Reg(r0),
+
+                        srcs: [
+                            SrcRef::Reg(r1).into(),
+                            SrcRef::Reg(r2).into(),
+                            SrcRef::Reg(r3).into(),
+                        ],
+
+                        saturate: false,
+                        ftz: false,
+                        dnz: false,
+                        f32: false,
+                    };
+                    instr.srcs[0].src_mod = a_mod;
+                    instr.srcs[1].src_mod = b_mod;
+                    instr.srcs[2].src_mod = c_mod;
+                    let disasm = format!(
+                        "hfma2 r0, {}, {}, {};",
+                        instr.srcs[0], instr.srcs[1], instr.srcs[2],
+                    );
+                    c.push(instr, disasm);
+                }
+            }
+        }
+
+        c.check(sm);
+    }
+}
diff --git a/src/nouveau/compiler/nak/opt_bar_prop.rs b/src/nouveau/compiler/nak/opt_bar_prop.rs
index 5f2dfeb7052..bdb9741ab03 100644
--- a/src/nouveau/compiler/nak/opt_bar_prop.rs
+++ b/src/nouveau/compiler/nak/opt_bar_prop.rs
@@ -182,7 +182,7 @@ impl BarPropPass {
                     }
                     Op::BMov(op) => {
                         assert!(!op.clear);
-                        assert!(op.src.is_unmodified());
+                        assert!(op.src.src_mod.is_none());
                         let dst = op.dst.as_ssa().unwrap();
                         let src = op.src.as_ssa().unwrap();
                         assert!(dst.comps() == 1 && src.comps() == 1);
diff --git a/src/nouveau/compiler/nak/opt_copy_prop.rs b/src/nouveau/compiler/nak/opt_copy_prop.rs
index c7bd0169cdf..965b7610f44 100644
--- a/src/nouveau/compiler/nak/opt_copy_prop.rs
+++ b/src/nouveau/compiler/nak/opt_copy_prop.rs
@@ -195,7 +195,7 @@ impl CopyPropPass {
                 continue;
             };
 
-            if entry.src.is_unmodified() {
+            if entry.src.src_mod.is_none() {
                 if let SrcRef::SSA(entry_ssa) = entry.src.src_ref {
                     assert!(entry_ssa.comps() == 1);
                     *c_ssa = entry_ssa[0];
@@ -208,7 +208,7 @@ impl CopyPropPass {
     }
 
     fn prop_to_ssa_src(&self, src: &mut Src) {
-        assert!(src.is_unmodified());
+        assert!(src.src_mod.is_none());
         if let SrcRef::SSA(src_ssa) = &mut src.src_ref {
             loop {
                 if !self.prop_to_ssa_ref(src_ssa) {
@@ -274,7 +274,8 @@ impl CopyPropPass {
                     }
 
                     // If there are modifiers, the source types have to match
-                    if !entry.src.is_unmodified() && entry.src_type != src_type
+                    if !entry.src.src_mod.is_none()
+                        && entry.src_type != src_type
                     {
                         return;
                     }
@@ -393,7 +394,7 @@ impl CopyPropPass {
             // source modifiers as needed when propagating the high bits.
             let lo_entry_or_none = self.get_copy(&src_ssa[0]);
             if let Some(CopyPropEntry::Copy(lo_entry)) = lo_entry_or_none {
-                if lo_entry.src.is_unmodified() {
+                if lo_entry.src.src_mod.is_none() {
                     if let SrcRef::SSA(lo_entry_ssa) = lo_entry.src.src_ref {
                         src_ssa[0] = lo_entry_ssa[0];
                         continue;
@@ -403,7 +404,7 @@ impl CopyPropPass {
 
             let hi_entry_or_none = self.get_copy(&src_ssa[1]);
             if let Some(CopyPropEntry::Copy(hi_entry)) = hi_entry_or_none {
-                if hi_entry.src.is_unmodified()
+                if hi_entry.src.src_mod.is_none()
                     || hi_entry.src_type == SrcType::F64
                 {
                     if let SrcRef::SSA(hi_entry_ssa) = hi_entry.src.src_ref {
@@ -422,11 +423,11 @@ impl CopyPropPass {
                 return;
             };
 
-            if !lo_entry.src.is_unmodified() {
+            if !lo_entry.src.src_mod.is_none() {
                 return;
             }
 
-            if !hi_entry.src.is_unmodified()
+            if !hi_entry.src.src_mod.is_none()
                 && hi_entry.src_type != SrcType::F64
             {
                 return;
@@ -688,7 +689,7 @@ impl CopyPropPass {
                 }
             }
             Op::R2UR(r2ur) => {
-                assert!(r2ur.src.is_unmodified());
+                assert!(r2ur.src.src_mod.is_none());
                 if r2ur.src.is_uniform() {
                     let dst = r2ur.dst.as_ssa().unwrap();
                     assert!(dst.comps() == 1);
diff --git a/src/nouveau/compiler/nak/opt_instr_sched_common.rs b/src/nouveau/compiler/nak/opt_instr_sched_common.rs
index ef54bc7c38a..83513930516 100644
--- a/src/nouveau/compiler/nak/opt_instr_sched_common.rs
+++ b/src/nouveau/compiler/nak/opt_instr_sched_common.rs
@@ -96,6 +96,7 @@ pub fn side_effect_type(op: &Op) -> SideEffect {
         | Op::HSet2(_)
         | Op::HSetP2(_)
         | Op::HMnMx2(_)
+        | Op::FSwz(_)
         | Op::FSwzAdd(_) => SideEffect::None,
 
         // Multi-function unit
@@ -193,9 +194,12 @@ pub fn side_effect_type(op: &Op) -> SideEffect {
         Op::Out(_) | Op::OutFinal(_) => SideEffect::Barrier,
 
         // Miscellaneous ops
-        Op::Bar(_) | Op::CS2R(_) | Op::Isberd(_) | Op::Kill(_) | Op::S2R(_) => {
-            SideEffect::Barrier
-        }
+        Op::Bar(_)
+        | Op::TexDepBar(_)
+        | Op::CS2R(_)
+        | Op::Isberd(_)
+        | Op::Kill(_)
+        | Op::S2R(_) => SideEffect::Barrier,
         Op::PixLd(_) | Op::Nop(_) | Op::Vote(_) => SideEffect::None,
 
         // Virtual ops
@@ -282,6 +286,7 @@ pub fn estimate_variable_latency(sm: u8, op: &Op) -> u32 {
 
         // Miscellaneous ops
         Op::Bar(_)
+        | Op::TexDepBar(_)
         | Op::CS2R(_)
         | Op::Isberd(_)
         | Op::Kill(_)
diff --git a/src/nouveau/compiler/nak/opt_lop.rs b/src/nouveau/compiler/nak/opt_lop.rs
index 3fbd68a7924..9ace08bd3bd 100644
--- a/src/nouveau/compiler/nak/opt_lop.rs
+++ b/src/nouveau/compiler/nak/opt_lop.rs
@@ -18,7 +18,7 @@ struct LopPass {
 }
 
 fn src_as_bool(src: &Src) -> Option<bool> {
-    assert!(src.is_unmodified());
+    assert!(src.src_mod.is_none());
     match src.src_ref {
         SrcRef::Zero | SrcRef::False | SrcRef::Imm32(0) => Some(false),
         SrcRef::True | SrcRef::Imm32(u32::MAX) => Some(true),
@@ -104,7 +104,7 @@ impl LopPass {
         src_idx: usize,
     ) {
         loop {
-            assert!(srcs[src_idx].is_unmodified());
+            assert!(srcs[src_idx].src_mod.is_none());
             let ssa = match srcs[src_idx].src_ref {
                 SrcRef::SSA(vec) => {
                     assert!(vec.comps() == 1);
@@ -197,7 +197,7 @@ impl LopPass {
         self.dedup_srcs(&mut op.op, &op.srcs);
 
         for (i, src) in op.srcs.iter_mut().enumerate() {
-            assert!(src.is_unmodified());
+            assert!(src.src_mod.is_none());
 
             if let Some(b) = src_as_bool(src) {
                 op.op.fix_src(i, b);
diff --git a/src/nouveau/compiler/nak/opt_prmt.rs b/src/nouveau/compiler/nak/opt_prmt.rs
index 80f5b1e9206..66e6651a659 100644
--- a/src/nouveau/compiler/nak/opt_prmt.rs
+++ b/src/nouveau/compiler/nak/opt_prmt.rs
@@ -103,8 +103,8 @@ impl PrmtPass {
             return;
         };
 
-        debug_assert!(op.srcs[0].is_unmodified());
-        debug_assert!(op.srcs[1].is_unmodified());
+        debug_assert!(op.srcs[0].src_mod.is_none());
+        debug_assert!(op.srcs[1].src_mod.is_none());
         let srcs = [op.srcs[0].src_ref, op.srcs[1].src_ref];
 
         self.ssa_prmt.insert(dst_ssa, PrmtEntry { sel, srcs });
@@ -115,7 +115,7 @@ impl PrmtPass {
     }
 
     fn get_prmt_for_src(&self, src: &Src) -> Option<&PrmtEntry> {
-        debug_assert!(src.is_unmodified());
+        debug_assert!(src.src_mod.is_none());
         if let SrcRef::SSA(vec) = &src.src_ref {
             debug_assert!(vec.comps() == 1);
             self.get_prmt(&vec[0])
@@ -218,7 +218,7 @@ impl PrmtPass {
 
                 new_sel[i] = PrmtSelByte::new(srcs.imm_src, byte_idx, false);
             } else {
-                debug_assert!(src.is_unmodified());
+                debug_assert!(src.src_mod.is_none());
                 let Some(src_idx) = srcs.try_add_src(src.src_ref) else {
                     return false;
                 };
diff --git a/src/nouveau/compiler/nak/sm20.rs b/src/nouveau/compiler/nak/sm20.rs
index ec2ccb426a7..89c1082ac1e 100644
--- a/src/nouveau/compiler/nak/sm20.rs
+++ b/src/nouveau/compiler/nak/sm20.rs
@@ -2,9 +2,15 @@
 // SPDX-License-Identifier: MIT
 
 use crate::ir::*;
-use crate::legalize::LegalizeBuilder;
-use bitview::{BitMutView, BitMutViewable, BitView, BitViewable, SetFieldU64};
+use crate::legalize::{
+    src_is_reg, swap_srcs_if_not_reg, LegalizeBuildHelpers, LegalizeBuilder,
+};
+use bitview::{
+    BitMutView, BitMutViewable, BitView, BitViewable, SetBit, SetField,
+    SetFieldU64,
+};
 
+use std::fmt;
 use std::{collections::HashMap, ops::Range};
 
 pub struct ShaderModel20 {
@@ -25,7 +31,7 @@ impl ShaderModel for ShaderModel20 {
 
     fn num_regs(&self, file: RegFile) -> u32 {
         match file {
-            RegFile::GPR => 255,
+            RegFile::GPR => 63,
             RegFile::UGPR => 0,
             RegFile::Pred => 7,
             RegFile::UPred => 0,
@@ -53,24 +59,8 @@ impl ShaderModel for ShaderModel20 {
         false
     }
 
-    fn exec_latency(&self, op: &Op) -> u32 {
-        // TODO
-        match op {
-            Op::CCtl(_)
-            | Op::MemBar(_)
-            | Op::Bra(_)
-            | Op::SSy(_)
-            | Op::Sync(_)
-            | Op::Brk(_)
-            | Op::PBk(_)
-            | Op::Cont(_)
-            | Op::PCnt(_)
-            | Op::Exit(_)
-            | Op::Bar(_)
-            | Op::Kill(_)
-            | Op::OutFinal(_) => 13,
-            _ => 1,
-        }
+    fn exec_latency(&self, _op: &Op) -> u32 {
+        1
     }
 
     fn raw_latency(
@@ -131,19 +121,78 @@ impl ShaderModel for ShaderModel20 {
     }
 }
 
+fn zero_reg() -> RegRef {
+    RegRef::new(RegFile::GPR, 63, 1)
+}
+
+fn true_reg() -> RegRef {
+    RegRef::new(RegFile::Pred, 7, 1)
+}
+
+enum AluSrc {
+    None,
+    Reg(RegRef),
+    Imm(u32),
+    CBuf(CBufRef),
+}
+
+impl AluSrc {
+    fn from_src(src: Option<&Src>) -> AluSrc {
+        if let Some(src) = src {
+            assert!(src.src_swizzle.is_none());
+            // do not assert src_mod, can be encoded by opcode.
+
+            match src.src_ref {
+                SrcRef::Zero => AluSrc::Reg(zero_reg()),
+                SrcRef::Reg(r) => AluSrc::Reg(r),
+                SrcRef::Imm32(x) => AluSrc::Imm(x),
+                SrcRef::CBuf(x) => AluSrc::CBuf(x),
+                _ => panic!("Unhandled ALU src type"),
+            }
+        } else {
+            AluSrc::None
+        }
+    }
+}
+
+#[repr(u8)]
+#[derive(Clone, Copy, Eq, Hash, PartialEq)]
+enum SM20Unit {
+    Float = 0,
+    Double = 1,
+    Imm32 = 2,
+    Int = 3,
+    Move = 4,
+    Mem = 5,
+    Tex = 6,
+    Exec = 7,
+}
+
+impl fmt::Display for SM20Unit {
+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+        match self {
+            SM20Unit::Float => write!(f, "float"),
+            SM20Unit::Double => write!(f, "double"),
+            SM20Unit::Imm32 => write!(f, "imm32"),
+            SM20Unit::Int => write!(f, "int"),
+            SM20Unit::Move => write!(f, "move"),
+            SM20Unit::Mem => write!(f, "mem"),
+            SM20Unit::Tex => write!(f, "tex"),
+            SM20Unit::Exec => write!(f, "exec"),
+        }
+    }
+}
+
 trait SM20Op {
     fn legalize(&mut self, b: &mut LegalizeBuilder);
-    #[allow(dead_code)]
     fn encode(&self, e: &mut SM20Encoder<'_>);
 }
 
-#[allow(dead_code)]
 struct SM20Encoder<'a> {
     sm: &'a ShaderModel20,
     ip: usize,
     labels: &'a HashMap<Label, usize>,
     inst: [u32; 2],
-    sched: u8,
 }
 
 impl BitViewable for SM20Encoder<'_> {
@@ -167,23 +216,2541 @@ impl SetFieldU64 for SM20Encoder<'_> {
         BitMutView::new(&mut self.inst).set_field_u64(range, val);
     }
 }
-macro_rules! as_sm20_op_match {
-    ($op: expr) => {
-        match $op {
-            _ => panic!("Unhandled instruction {}", $op),
+
+impl SM20Encoder<'_> {
+    fn set_opcode(&mut self, unit: SM20Unit, opcode: u8) {
+        self.set_field(0..3, unit as u8);
+        self.set_field(58..64, opcode);
+    }
+
+    fn set_pred_reg(&mut self, range: Range<usize>, reg: RegRef) {
+        assert!(range.len() == 3);
+        assert!(reg.file() == RegFile::Pred);
+        assert!(reg.base_idx() <= 7);
+        assert!(reg.comps() == 1);
+        self.set_field(range, reg.base_idx());
+    }
+
+    fn set_pred_src(&mut self, range: Range<usize>, src: Src) {
+        let (not, reg) = match src.src_ref {
+            SrcRef::True => (false, true_reg()),
+            SrcRef::False => (true, true_reg()),
+            SrcRef::Reg(reg) => (false, reg),
+            _ => panic!("Not a register"),
+        };
+        self.set_pred_reg(range.start..(range.end - 1), reg);
+        self.set_bit(range.end - 1, not ^ src.src_mod.is_bnot());
+    }
+
+    fn set_pred_dst(&mut self, range: Range<usize>, dst: Dst) {
+        let reg = match dst {
+            Dst::None => true_reg(),
+            Dst::Reg(reg) => reg,
+            _ => panic!("Dst is not pred {dst}"),
+        };
+        self.set_pred_reg(range, reg);
+    }
+
+    fn set_pred_dst2(
+        &mut self,
+        range1: Range<usize>,
+        range2: Range<usize>,
+        dst: Dst,
+    ) {
+        assert!(range1.len() == 2);
+        assert!(range2.len() == 1);
+        let reg = match dst {
+            Dst::None => true_reg(),
+            Dst::Reg(reg) => reg,
+            _ => panic!("Dst is not pred {dst}"),
+        };
+        assert!(reg.file() == RegFile::Pred);
+        assert!(reg.base_idx() <= 7);
+        assert!(reg.comps() == 1);
+        self.set_field(range1, reg.base_idx() & 0x3);
+        self.set_field(range2, reg.base_idx() >> 2);
+    }
+
+    fn set_pred(&mut self, pred: &Pred) {
+        // predicates are 4 bits starting at 18, last one denotes inversion
+        assert!(!pred.is_false());
+        self.set_pred_reg(
+            10..13,
+            match pred.pred_ref {
+                PredRef::None => true_reg(),
+                PredRef::Reg(reg) => reg,
+                PredRef::SSA(_) => panic!("SSA values must be lowered"),
+            },
+        );
+        self.set_bit(13, pred.pred_inv);
+    }
+
+    fn set_reg(&mut self, range: Range<usize>, reg: RegRef) {
+        assert!(range.len() == 6);
+        assert!(reg.file() == RegFile::GPR);
+        self.set_field(range, reg.base_idx());
+    }
+
+    fn set_reg_src_ref(&mut self, range: Range<usize>, src_ref: &SrcRef) {
+        match src_ref {
+            SrcRef::Zero => self.set_reg(range, zero_reg()),
+            SrcRef::Reg(reg) => self.set_reg(range, *reg),
+            _ => panic!("Not a register"),
         }
-    };
+    }
+
+    fn set_reg_src(&mut self, range: Range<usize>, src: Src) {
+        assert!(src.src_swizzle.is_none());
+        self.set_reg_src_ref(range, &src.src_ref);
+    }
+
+    fn set_dst(&mut self, range: Range<usize>, dst: Dst) {
+        let reg = match dst {
+            Dst::None => zero_reg(),
+            Dst::Reg(reg) => reg,
+            _ => panic!("Invalid dst {dst}"),
+        };
+        self.set_reg(range, reg);
+    }
+
+    fn set_carry_in(&mut self, bit: usize, src: Src) {
+        assert!(src.src_mod.is_none());
+        match src.src_ref {
+            SrcRef::Zero => self.set_bit(bit, false),
+            SrcRef::Reg(reg) => {
+                assert!(reg == RegRef::new(RegFile::Carry, 0, 1));
+                self.set_bit(bit, true);
+            }
+            _ => panic!("Invalid carry in: {src}"),
+        }
+    }
+
+    fn set_carry_out(&mut self, bit: usize, dst: Dst) {
+        match dst {
+            Dst::None => self.set_bit(bit, false),
+            Dst::Reg(reg) => {
+                assert!(reg == RegRef::new(RegFile::Carry, 0, 1));
+                self.set_bit(bit, true);
+            }
+            _ => panic!("Invalid carry out: {dst}"),
+        }
+    }
+
+    fn set_src_imm_i20(
+        &mut self,
+        range: Range<usize>,
+        sign_bit: usize,
+        i: u32,
+    ) {
+        assert!(range.len() == 19);
+        assert!((i & 0xfff80000) == 0 || (i & 0xfff80000) == 0xfff80000);
+
+        self.set_field(range, i & 0x7ffff);
+        self.set_field(sign_bit..sign_bit + 1, (i & 0x80000) >> 19);
+    }
+
+    fn set_src_imm_f20(
+        &mut self,
+        range: Range<usize>,
+        sign_bit: usize,
+        f: u32,
+    ) {
+        assert!(range.len() == 19);
+        assert!((f & 0x00000fff) == 0);
+
+        self.set_field(range, (f >> 12) & 0x7ffff);
+        self.set_field(sign_bit..sign_bit + 1, f >> 31);
+    }
+
+    fn encode_form_a(
+        &mut self,
+        unit: SM20Unit,
+        opcode: u8,
+        dst: Option<&Dst>,
+        src0: Option<&Src>,
+        src1: Option<&Src>,
+        src2: Option<&Src>,
+    ) {
+        self.set_opcode(unit, opcode);
+        if let Some(&dst) = dst {
+            self.set_dst(14..20, dst);
+        }
+
+        if let AluSrc::Reg(reg0) = AluSrc::from_src(src0) {
+            self.set_reg(20..26, reg0);
+        } else {
+            panic!("Unsupported src0");
+        }
+
+        match AluSrc::from_src(src1) {
+            AluSrc::None => panic!("Unsupported src1"),
+            AluSrc::Reg(reg1) => match AluSrc::from_src(src2) {
+                AluSrc::None => {
+                    self.set_reg(26..32, reg1);
+                }
+                AluSrc::Reg(reg2) => {
+                    self.set_reg(26..32, reg1);
+                    self.set_reg(49..55, reg2);
+                }
+                AluSrc::Imm(_) => {
+                    panic!("Immediates are only allowed in src1");
+                }
+                AluSrc::CBuf(cb) => {
+                    let CBuf::Binding(idx) = cb.buf else {
+                        panic!("Must be a bound constant buffer");
+                    };
+                    self.set_field(26..42, cb.offset);
+                    self.set_field(42..46, idx);
+                    self.set_field(46..48, 2_u8);
+                    self.set_reg(49..55, reg1);
+                }
+            },
+            AluSrc::Imm(imm32) => {
+                match unit {
+                    SM20Unit::Float | SM20Unit::Double => {
+                        self.set_src_imm_f20(26..45, 45, imm32);
+                    }
+                    SM20Unit::Int | SM20Unit::Move | SM20Unit::Tex => {
+                        self.set_src_imm_i20(26..45, 45, imm32);
+                    }
+                    _ => panic!("Unknown unit for immediate: {unit}"),
+                }
+                self.set_field(46..48, 3_u8);
+                if let Some(src2) = src2 {
+                    self.set_reg_src_ref(49..55, &src2.src_ref);
+                }
+            }
+            AluSrc::CBuf(cb) => {
+                let CBuf::Binding(idx) = cb.buf else {
+                    panic!("Must be a bound constant buffer");
+                };
+                self.set_field(26..42, cb.offset);
+                self.set_field(42..46, idx);
+                self.set_field(46..48, 1_u8);
+                if let Some(src2) = src2 {
+                    self.set_reg_src_ref(49..55, &src2.src_ref);
+                }
+            }
+        }
+    }
+
+    fn encode_form_a_imm32(
+        &mut self,
+        opcode: u8,
+        dst: Option<&Dst>,
+        src0: Option<&Src>,
+        imm_src1: u32,
+    ) {
+        self.set_opcode(SM20Unit::Imm32, opcode);
+        if let Some(&dst) = dst {
+            self.set_dst(14..20, dst);
+        }
+
+        if let AluSrc::Reg(reg0) = AluSrc::from_src(src0) {
+            self.set_reg(20..26, reg0);
+        } else {
+            panic!("Unsupported src0");
+        }
+
+        self.set_field(26..58, imm_src1);
+    }
+
+    fn encode_form_b(
+        &mut self,
+        unit: SM20Unit,
+        opcode: u8,
+        dst: Dst,
+        src: Src,
+    ) {
+        self.set_opcode(unit, opcode);
+        self.set_dst(14..20, dst);
+
+        match AluSrc::from_src(Some(&src)) {
+            AluSrc::None => panic!("src is always Some"),
+            AluSrc::Reg(reg) => {
+                self.set_reg(26..32, reg);
+            }
+            AluSrc::Imm(imm32) => {
+                match unit {
+                    SM20Unit::Float | SM20Unit::Double => {
+                        self.set_src_imm_f20(26..45, 45, imm32);
+                    }
+                    SM20Unit::Int | SM20Unit::Move | SM20Unit::Tex => {
+                        self.set_src_imm_i20(26..45, 45, imm32);
+                    }
+                    _ => panic!("Unknown unit for immediate: {unit}"),
+                }
+                self.set_field(46..48, 3_u8);
+            }
+            AluSrc::CBuf(cb) => {
+                let CBuf::Binding(idx) = cb.buf else {
+                    panic!("Must be a bound constant buffer");
+                };
+                self.set_field(26..42, cb.offset);
+                self.set_field(42..46, idx);
+                self.set_field(46..48, 1_u8);
+            }
+        }
+    }
+
+    fn encode_form_b_imm32(&mut self, opcode: u8, dst: Dst, imm_src: u32) {
+        self.set_opcode(SM20Unit::Imm32, opcode);
+        self.set_dst(14..20, dst);
+        self.set_field(26..58, imm_src);
+    }
+
+    fn set_rnd_mode(&mut self, range: Range<usize>, rnd_mode: FRndMode) {
+        self.set_field(
+            range,
+            match rnd_mode {
+                FRndMode::NearestEven => 0_u8,
+                FRndMode::NegInf => 1_u8,
+                FRndMode::PosInf => 2_u8,
+                FRndMode::Zero => 3_u8,
+            },
+        );
+    }
+
+    fn set_float_cmp_op(&mut self, range: Range<usize>, op: FloatCmpOp) {
+        assert!(range.len() == 4);
+        self.set_field(
+            range,
+            match op {
+                FloatCmpOp::OrdLt => 0x01_u8,
+                FloatCmpOp::OrdEq => 0x02_u8,
+                FloatCmpOp::OrdLe => 0x03_u8,
+                FloatCmpOp::OrdGt => 0x04_u8,
+                FloatCmpOp::OrdNe => 0x05_u8,
+                FloatCmpOp::OrdGe => 0x06_u8,
+                FloatCmpOp::UnordLt => 0x09_u8,
+                FloatCmpOp::UnordEq => 0x0a_u8,
+                FloatCmpOp::UnordLe => 0x0b_u8,
+                FloatCmpOp::UnordGt => 0x0c_u8,
+                FloatCmpOp::UnordNe => 0x0d_u8,
+                FloatCmpOp::UnordGe => 0x0e_u8,
+                FloatCmpOp::IsNum => 0x07_u8,
+                FloatCmpOp::IsNan => 0x08_u8,
+            },
+        );
+    }
 }
 
-#[allow(dead_code)]
-fn as_sm20_op(op: &Op) -> &dyn SM20Op {
-    as_sm20_op_match!(op)
+impl SM20Op for OpFAdd {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F32);
+        if src1.as_imm_not_f20().is_some()
+            && (self.saturate || self.rnd_mode == FRndMode::NearestEven)
+        {
+            b.copy_alu_src(src1, GPR, SrcType::F32);
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        if let Some(imm32) = self.srcs[1].as_imm_not_f20() {
+            // Technically the modifier bits for these do work but legalization
+            // should fold any modifiers on immediates for us.
+            assert!(self.srcs[1].src_mod.is_none());
+            e.encode_form_a_imm32(
+                0xa,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                imm32,
+            );
+            assert!(self.saturate);
+            assert!(self.rnd_mode == FRndMode::NearestEven);
+        } else {
+            e.encode_form_a(
+                SM20Unit::Float,
+                0x14,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                Some(&self.srcs[1]),
+                None,
+            );
+            e.set_bit(49, self.saturate);
+            e.set_rnd_mode(55..57, self.rnd_mode);
+        }
+        e.set_bit(5, self.ftz);
+        e.set_bit(6, self.srcs[1].src_mod.has_fabs());
+        e.set_bit(7, self.srcs[0].src_mod.has_fabs());
+        e.set_bit(8, self.srcs[1].src_mod.has_fneg());
+        e.set_bit(9, self.srcs[0].src_mod.has_fneg());
+    }
 }
 
-fn as_sm20_op_mut(op: &mut Op) -> &mut dyn SM20Op {
-    as_sm20_op_match!(op)
+impl SM20Op for OpFFma {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1, src2] = &mut self.srcs;
+        b.copy_alu_src_if_fabs(src0, GPR, SrcType::F32);
+        b.copy_alu_src_if_fabs(src1, GPR, SrcType::F32);
+        b.copy_alu_src_if_fabs(src2, GPR, SrcType::F32);
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F32);
+        if src1.as_imm_not_f20().is_some()
+            && (self.saturate
+                || self.rnd_mode != FRndMode::NearestEven
+                || self.dst.as_reg().is_none()
+                || self.dst.as_reg() != src2.src_ref.as_reg())
+        {
+            b.copy_alu_src(src1, GPR, SrcType::F32);
+        }
+        if src_is_reg(src1, GPR) {
+            b.copy_alu_src_if_imm(src2, GPR, SrcType::F32);
+        } else {
+            b.copy_alu_src_if_not_reg(src2, GPR, SrcType::F32);
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(!self.srcs[0].src_mod.has_fabs());
+        assert!(!self.srcs[1].src_mod.has_fabs());
+        assert!(!self.srcs[2].src_mod.has_fabs());
+
+        if let Some(imm32) = self.srcs[1].as_imm_not_f20() {
+            // Long immediates are only allowed if src2 == dst.
+            assert!(self.dst.as_reg().is_some());
+            assert!(self.dst.as_reg() == self.srcs[2].src_ref.as_reg());
+
+            // Technically the modifier bits for these do work but legalization
+            // should fold any modifiers on immediates for us.
+            assert!(self.srcs[1].src_mod.is_none());
+
+            e.encode_form_a_imm32(
+                0x8,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                imm32,
+            );
+            assert!(self.rnd_mode == FRndMode::NearestEven);
+        } else {
+            e.encode_form_a(
+                SM20Unit::Float,
+                0xc,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                Some(&self.srcs[1]),
+                Some(&self.srcs[2]),
+            );
+            e.set_rnd_mode(55..57, self.rnd_mode);
+        }
+
+        e.set_bit(5, self.saturate);
+        e.set_bit(6, self.ftz);
+        e.set_bit(7, self.dnz);
+
+        e.set_bit(8, self.srcs[2].src_mod.has_fneg());
+        let neg0 = self.srcs[0].src_mod.has_fneg();
+        let neg1 = self.srcs[1].src_mod.has_fneg();
+        e.set_bit(9, neg0 ^ neg1);
+    }
+}
+
+impl SM20Op for OpFMnMx {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F32);
+        b.copy_alu_src_if_f20_overflow(src1, GPR, SrcType::F32);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Float,
+            0x2,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+        e.set_bit(5, self.ftz);
+        e.set_bit(6, self.srcs[1].src_mod.has_fabs());
+        e.set_bit(7, self.srcs[0].src_mod.has_fabs());
+        e.set_bit(8, self.srcs[1].src_mod.has_fneg());
+        e.set_bit(9, self.srcs[0].src_mod.has_fneg());
+        e.set_pred_src(49..53, self.min);
+    }
+}
+
+impl SM20Op for OpFMul {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        b.copy_alu_src_if_fabs(src0, GPR, SrcType::F32);
+        b.copy_alu_src_if_fabs(src1, GPR, SrcType::F32);
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F32);
+        if src1.as_imm_not_f20().is_some()
+            && self.rnd_mode != FRndMode::NearestEven
+        {
+            b.copy_alu_src(src1, GPR, SrcType::F32);
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(!self.srcs[0].src_mod.has_fabs());
+        assert!(!self.srcs[1].src_mod.has_fabs());
+
+        if let Some(mut imm32) = self.srcs[1].as_imm_not_f20() {
+            // Technically the modifier bits for these do work but legalization
+            // should fold any modifiers on immediates for us.
+            assert!(self.srcs[1].src_mod.is_none());
+
+            // We don't, however, have a modifier for src0.  Just flip the
+            // immediate in that case.
+            if self.srcs[0].src_mod.has_fneg() {
+                imm32 ^= 0x80000000;
+            }
+            e.encode_form_a_imm32(
+                0xc,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                imm32,
+            );
+            assert!(self.rnd_mode == FRndMode::NearestEven);
+        } else {
+            e.encode_form_a(
+                SM20Unit::Float,
+                0x16,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                Some(&self.srcs[1]),
+                None,
+            );
+            e.set_rnd_mode(55..57, self.rnd_mode);
+            let neg0 = self.srcs[0].src_mod.has_fneg();
+            let neg1 = self.srcs[1].src_mod.has_fneg();
+            e.set_bit(25, neg0 ^ neg1);
+        }
+
+        e.set_bit(5, self.saturate);
+        e.set_bit(6, self.ftz);
+        e.set_bit(7, self.dnz);
+    }
+}
+
+impl SM20Op for OpRro {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_f20_overflow(&mut self.src, GPR, SrcType::F32);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_b(SM20Unit::Float, 0x18, self.dst, self.src);
+        e.set_field(
+            5..6,
+            match self.op {
+                RroOp::SinCos => 0u8,
+                RroOp::Exp2 => 1u8,
+            },
+        );
+        e.set_bit(6, self.src.src_mod.has_fabs());
+        e.set_bit(8, self.src.src_mod.has_fneg());
+    }
+}
+
+impl SM20Op for OpMuFu {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_not_reg(&mut self.src, GPR, SrcType::F32);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Float, 0x32);
+
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src_ref(20..26, &self.src.src_ref);
+
+        e.set_bit(5, false); // .sat
+        e.set_bit(6, self.src.src_mod.has_fabs());
+        e.set_bit(8, self.src.src_mod.has_fneg());
+        e.set_field(
+            26..30,
+            match self.op {
+                MuFuOp::Cos => 0_u8,
+                MuFuOp::Sin => 1_u8,
+                MuFuOp::Exp2 => 2_u8,
+                MuFuOp::Log2 => 3_u8,
+                MuFuOp::Rcp => 4_u8,
+                MuFuOp::Rsq => 5_u8,
+                MuFuOp::Rcp64H => 6_u8,
+                MuFuOp::Rsq64H => 7_u8,
+                _ => panic!("mufu{} not supported on SM20", self.op),
+            },
+        );
+    }
+}
+
+impl SM20Op for OpFSet {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        if swap_srcs_if_not_reg(src0, src1, GPR) {
+            self.cmp_op = self.cmp_op.flip();
+        }
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F32);
+        b.copy_alu_src_if_f20_overflow(src1, GPR, SrcType::F32);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Float,
+            0x6,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+
+        e.set_bit(5, self.ftz);
+        e.set_bit(6, self.srcs[1].src_mod.has_fabs());
+        e.set_bit(7, self.srcs[0].src_mod.has_fabs());
+        e.set_bit(8, self.srcs[1].src_mod.has_fneg());
+        e.set_bit(9, self.srcs[0].src_mod.has_fneg());
+        e.set_float_cmp_op(55..59, self.cmp_op);
+    }
+}
+
+impl SM20Op for OpFSetP {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        if swap_srcs_if_not_reg(src0, src1, GPR) {
+            self.cmp_op = self.cmp_op.flip();
+        }
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F32);
+        b.copy_alu_src_if_f20_overflow(src1, GPR, SrcType::F32);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Float,
+            0x8,
+            None,
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+
+        e.set_bit(6, self.srcs[1].src_mod.has_fabs());
+        e.set_bit(7, self.srcs[0].src_mod.has_fabs());
+        e.set_bit(8, self.srcs[1].src_mod.has_fneg());
+        e.set_bit(9, self.srcs[0].src_mod.has_fneg());
+        e.set_pred_dst(14..17, Dst::None);
+        e.set_pred_dst(17..20, self.dst);
+        e.set_pred_src(49..53, self.accum);
+        e.set_pred_set_op(53..55, self.set_op);
+        e.set_float_cmp_op(55..59, self.cmp_op);
+        e.set_bit(59, self.ftz);
+    }
+}
+
+impl SM20Op for OpFSwz {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_not_reg(&mut self.srcs[0], GPR, SrcType::GPR);
+        b.copy_alu_src_if_not_reg(&mut self.srcs[1], GPR, SrcType::GPR);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Float, 0x12);
+
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src(20..26, self.srcs[0]);
+        e.set_reg_src(26..32, self.srcs[1]);
+
+        e.set_bit(5, self.ftz);
+        e.set_field(
+            6..9,
+            match self.shuffle {
+                FSwzShuffle::Quad0 => 0_u8,
+                FSwzShuffle::Quad1 => 1_u8,
+                FSwzShuffle::Quad2 => 2_u8,
+                FSwzShuffle::Quad3 => 3_u8,
+                FSwzShuffle::SwapHorizontal => 4_u8,
+                FSwzShuffle::SwapVertical => 5_u8,
+            },
+        );
+        e.set_bit(9, false); // .ndv
+
+        for (i, op) in self.ops.iter().enumerate() {
+            e.set_field(
+                32 + i * 2..32 + (i + 1) * 2,
+                match op {
+                    FSwzAddOp::Add => 0u8,
+                    FSwzAddOp::SubLeft => 1u8,
+                    FSwzAddOp::SubRight => 2u8,
+                    FSwzAddOp::MoveLeft => 3u8,
+                },
+            );
+        }
+
+        e.set_rnd_mode(55..57, self.rnd_mode);
+    }
+}
+
+impl SM20Op for OpDAdd {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F64);
+        b.copy_alu_src_if_f20_overflow(src1, GPR, SrcType::F64);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Double,
+            0x12,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+        e.set_bit(6, self.srcs[1].src_mod.has_fabs());
+        e.set_bit(7, self.srcs[0].src_mod.has_fabs());
+        e.set_bit(8, self.srcs[1].src_mod.has_fneg());
+        e.set_bit(9, self.srcs[0].src_mod.has_fneg());
+        e.set_rnd_mode(55..57, self.rnd_mode);
+    }
+}
+
+impl SM20Op for OpDFma {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1, src2] = &mut self.srcs;
+        b.copy_alu_src_if_fabs(src0, GPR, SrcType::F64);
+        b.copy_alu_src_if_fabs(src1, GPR, SrcType::F64);
+        b.copy_alu_src_if_fabs(src2, GPR, SrcType::F64);
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F64);
+        b.copy_alu_src_if_f20_overflow(src1, GPR, SrcType::F64);
+        if src_is_reg(src1, GPR) {
+            b.copy_alu_src_if_imm(src2, GPR, SrcType::F64);
+        } else {
+            b.copy_alu_src_if_not_reg(src2, GPR, SrcType::F64);
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(!self.srcs[0].src_mod.has_fabs());
+        assert!(!self.srcs[1].src_mod.has_fabs());
+        assert!(!self.srcs[2].src_mod.has_fabs());
+
+        e.encode_form_a(
+            SM20Unit::Double,
+            0x8,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            Some(&self.srcs[2]),
+        );
+        e.set_bit(8, self.srcs[2].src_mod.has_fneg());
+        let neg0 = self.srcs[0].src_mod.has_fneg();
+        let neg1 = self.srcs[1].src_mod.has_fneg();
+        e.set_bit(9, neg0 ^ neg1);
+        e.set_rnd_mode(55..57, self.rnd_mode);
+    }
+}
+
+impl SM20Op for OpDMnMx {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F64);
+        b.copy_alu_src_if_f20_overflow(src1, GPR, SrcType::F64);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Double,
+            0x2,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+        e.set_bit(6, self.srcs[1].src_mod.has_fabs());
+        e.set_bit(7, self.srcs[0].src_mod.has_fabs());
+        e.set_bit(8, self.srcs[1].src_mod.has_fneg());
+        e.set_bit(9, self.srcs[0].src_mod.has_fneg());
+        e.set_pred_src(49..53, self.min);
+    }
+}
+
+impl SM20Op for OpDMul {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F64);
+        b.copy_alu_src_if_f20_overflow(src1, GPR, SrcType::F64);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(!self.srcs[0].src_mod.has_fabs());
+        assert!(!self.srcs[1].src_mod.has_fabs());
+
+        e.encode_form_a(
+            SM20Unit::Double,
+            0x14,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+        let neg0 = self.srcs[0].src_mod.has_fneg();
+        let neg1 = self.srcs[1].src_mod.has_fneg();
+        e.set_bit(9, neg0 ^ neg1);
+        e.set_rnd_mode(55..57, self.rnd_mode);
+    }
+}
+
+impl SM20Op for OpDSetP {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::F64);
+        b.copy_alu_src_if_f20_overflow(src1, GPR, SrcType::F64);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Double,
+            0x6,
+            None,
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+        e.set_bit(6, self.srcs[1].src_mod.has_fabs());
+        e.set_bit(7, self.srcs[0].src_mod.has_fabs());
+        e.set_bit(8, self.srcs[1].src_mod.has_fneg());
+        e.set_bit(9, self.srcs[0].src_mod.has_fneg());
+        e.set_pred_dst(14..17, Dst::None);
+        e.set_pred_dst(17..20, self.dst);
+        e.set_pred_src(49..53, self.accum);
+        e.set_pred_set_op(53..55, self.set_op);
+        e.set_float_cmp_op(55..59, self.cmp_op);
+    }
+}
+
+impl SM20Op for OpBfe {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_not_reg(&mut self.base, GPR, SrcType::ALU);
+        if let SrcRef::Imm32(imm32) = &mut self.range.src_ref {
+            // Only the bottom 16 bits of the immediate matter
+            *imm32 &= 0xffff;
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Int,
+            0x1c,
+            Some(&self.dst),
+            Some(&self.base),
+            Some(&self.range),
+            None,
+        );
+        e.set_bit(5, self.signed);
+        e.set_bit(8, self.reverse);
+    }
 }
 
-fn encode_sm20_shader(_sm: &ShaderModel20, _s: &Shader<'_>) -> Vec<u32> {
-    todo!("Implement SM20 encoding");
+impl SM20Op for OpFlo {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_i20_overflow(&mut self.src, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_b(SM20Unit::Int, 0x1e, self.dst, self.src);
+        e.set_bit(5, self.signed);
+        e.set_bit(6, self.return_shift_amount);
+        e.set_bit(8, self.src.src_mod.is_bnot());
+    }
+}
+
+impl SM20Op for OpIAdd2 {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        if src0.src_mod.is_ineg() && src1.src_mod.is_ineg() {
+            assert!(self.carry_out.is_none());
+            b.copy_alu_src_and_lower_ineg(src0, GPR, SrcType::I32);
+        }
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::I32);
+        if !self.carry_out.is_none() {
+            b.copy_alu_src_if_ineg_imm(src1, GPR, SrcType::I32);
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(
+            self.srcs[0].src_mod.is_none() || self.srcs[1].src_mod.is_none()
+        );
+
+        if let Some(imm32) = self.srcs[1].as_imm_not_i20() {
+            e.encode_form_a_imm32(
+                0x2,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                imm32,
+            );
+            e.set_carry_out(58, self.carry_out);
+        } else {
+            e.encode_form_a(
+                SM20Unit::Int,
+                0x12,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                Some(&self.srcs[1]),
+                None,
+            );
+            e.set_carry_out(48, self.carry_out);
+        }
+
+        e.set_bit(5, false); // saturate
+        e.set_bit(8, self.srcs[1].src_mod.is_ineg());
+        e.set_bit(9, self.srcs[0].src_mod.is_ineg());
+    }
+}
+
+impl SM20Op for OpIAdd2X {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::B32);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(
+            self.srcs[0].src_mod.is_none() || self.srcs[1].src_mod.is_none()
+        );
+
+        if let Some(imm32) = self.srcs[1].as_imm_not_i20() {
+            e.encode_form_a_imm32(
+                0x2,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                imm32,
+            );
+            e.set_carry_out(58, self.carry_out);
+        } else {
+            e.encode_form_a(
+                SM20Unit::Int,
+                0x12,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                Some(&self.srcs[1]),
+                None,
+            );
+            e.set_carry_out(48, self.carry_out);
+        }
+
+        e.set_bit(5, false); // saturate
+        e.set_carry_in(6, self.carry_in);
+        e.set_bit(8, self.srcs[1].src_mod.is_bnot());
+        e.set_bit(9, self.srcs[0].src_mod.is_bnot());
+    }
+}
+
+impl SM20Op for OpIMad {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1, src2] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::ALU);
+        b.copy_alu_src_if_i20_overflow(src1, GPR, SrcType::ALU);
+
+        let neg_ab = src0.src_mod.is_ineg() ^ src1.src_mod.is_ineg();
+        let neg_c = src2.src_mod.is_ineg();
+        if neg_ab && neg_c {
+            b.copy_alu_src_and_lower_ineg(src2, GPR, SrcType::ALU);
+        }
+        if src_is_reg(src1, GPR) {
+            b.copy_alu_src_if_imm(src2, GPR, SrcType::ALU);
+        } else {
+            b.copy_alu_src_if_not_reg(src2, GPR, SrcType::ALU);
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Int,
+            0x8,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            Some(&self.srcs[2]),
+        );
+
+        e.set_bit(5, self.signed);
+        e.set_bit(7, self.signed);
+
+        let neg_ab =
+            self.srcs[0].src_mod.is_ineg() ^ self.srcs[1].src_mod.is_ineg();
+        let neg_c = self.srcs[2].src_mod.is_ineg();
+        assert!(!neg_ab || !neg_c);
+        e.set_bit(8, neg_c);
+        e.set_bit(9, neg_ab);
+
+        e.set_bit(24, false); // saturate
+    }
+}
+
+impl SM20Op for OpIMul {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        if swap_srcs_if_not_reg(src0, src1, GPR) {
+            self.signed.swap(0, 1);
+        }
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(self.srcs[0].src_mod.is_none());
+        assert!(self.srcs[1].src_mod.is_none());
+
+        if let Some(imm32) = self.srcs[1].as_imm_not_i20() {
+            e.encode_form_a_imm32(
+                0x4,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                imm32,
+            );
+        } else {
+            e.encode_form_a(
+                SM20Unit::Int,
+                0x14,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                Some(&self.srcs[1]),
+                None,
+            );
+        }
+
+        e.set_bit(5, self.signed[0]);
+        e.set_bit(6, self.high);
+        e.set_bit(7, self.signed[1]);
+    }
+}
+
+impl SM20Encoder<'_> {
+    fn set_pred_set_op(&mut self, range: Range<usize>, op: PredSetOp) {
+        assert!(range.len() == 2);
+        self.set_field(
+            range,
+            match op {
+                PredSetOp::And => 0_u8,
+                PredSetOp::Or => 1_u8,
+                PredSetOp::Xor => 2_u8,
+            },
+        );
+    }
+
+    fn set_int_cmp_op(&mut self, range: Range<usize>, op: IntCmpOp) {
+        assert!(range.len() == 3);
+        self.set_field(
+            range,
+            match op {
+                IntCmpOp::False => 0_u8,
+                IntCmpOp::True => 7_u8,
+                IntCmpOp::Eq => 2_u8,
+                IntCmpOp::Ne => 5_u8,
+                IntCmpOp::Lt => 1_u8,
+                IntCmpOp::Le => 3_u8,
+                IntCmpOp::Gt => 4_u8,
+                IntCmpOp::Ge => 6_u8,
+            },
+        );
+    }
+}
+
+impl SM20Op for OpIMnMx {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        swap_srcs_if_not_reg(src0, src1, GPR);
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::ALU);
+        b.copy_alu_src_if_i20_overflow(src1, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(self.srcs[1].src_mod.is_none());
+        assert!(self.srcs[0].src_mod.is_none());
+
+        e.encode_form_a(
+            SM20Unit::Int,
+            0x2,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+        e.set_field(
+            5..6,
+            match self.cmp_type {
+                IntCmpType::U32 => 0_u8,
+                IntCmpType::I32 => 1_u8,
+            },
+        );
+        e.set_pred_src(49..53, self.min);
+    }
+}
+
+impl SM20Op for OpISetP {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        if swap_srcs_if_not_reg(src0, src1, GPR) {
+            self.cmp_op = self.cmp_op.flip();
+        }
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::ALU);
+        b.copy_alu_src_if_i20_overflow(src1, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(self.srcs[1].src_mod.is_none());
+        assert!(self.srcs[0].src_mod.is_none());
+
+        e.encode_form_a(
+            SM20Unit::Int,
+            0x6,
+            None,
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+
+        e.set_bit(5, self.cmp_type.is_signed());
+        e.set_bit(6, self.ex);
+        e.set_pred_dst(14..17, Dst::None);
+        e.set_pred_dst(17..20, self.dst);
+        e.set_pred_src(49..53, self.accum);
+        e.set_pred_set_op(53..55, self.set_op);
+        e.set_int_cmp_op(55..58, self.cmp_op);
+    }
+}
+
+impl SM20Op for OpLop2 {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        match self.op {
+            LogicOp2::PassB => {
+                *src0 = 0.into();
+                b.copy_alu_src_if_i20_overflow(src1, GPR, SrcType::ALU);
+            }
+            LogicOp2::And | LogicOp2::Or | LogicOp2::Xor => {
+                swap_srcs_if_not_reg(src0, src1, GPR);
+                b.copy_alu_src_if_not_reg(src0, GPR, SrcType::ALU);
+            }
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        if let Some(imm32) = self.srcs[1].as_imm_not_i20() {
+            e.encode_form_a_imm32(
+                0xe,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                imm32,
+            );
+            assert!(self.op != LogicOp2::PassB);
+        } else {
+            e.encode_form_a(
+                SM20Unit::Int,
+                0x1a,
+                Some(&self.dst),
+                Some(&self.srcs[0]),
+                Some(&self.srcs[1]),
+                None,
+            );
+        }
+        e.set_bit(5, false); // carry
+        e.set_field(
+            6..8,
+            match self.op {
+                LogicOp2::And => 0_u8,
+                LogicOp2::Or => 1_u8,
+                LogicOp2::Xor => 2_u8,
+                LogicOp2::PassB => 3_u8,
+            },
+        );
+        e.set_bit(8, self.srcs[1].src_mod.is_bnot());
+        e.set_bit(9, self.srcs[0].src_mod.is_bnot());
+    }
+}
+
+impl SM20Op for OpPopC {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        // popc on Fermi takes two sources and ANDs them and counts the
+        // intersecting bits.  Pass it !rZ as the second source.
+        let mask = Src::from(0).bnot();
+        e.encode_form_a(
+            SM20Unit::Move,
+            0x15,
+            Some(&self.dst),
+            Some(&mask),
+            Some(&self.src),
+            None,
+        );
+        e.set_bit(8, self.src.src_mod.is_bnot());
+        e.set_bit(9, mask.src_mod.is_bnot());
+    }
+}
+
+impl SM20Op for OpShl {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_not_reg(&mut self.src, GPR, SrcType::GPR);
+        if let SrcRef::Imm32(imm32) = &mut self.shift.src_ref {
+            if self.wrap {
+                *imm32 = *imm32 & 0x1f;
+            } else {
+                *imm32 = (*imm32).min(32);
+            }
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Int,
+            0x18,
+            Some(&self.dst),
+            Some(&self.src),
+            Some(&self.shift),
+            None,
+        );
+        e.set_bit(9, self.wrap);
+    }
+}
+
+impl SM20Op for OpShr {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_not_reg(&mut self.src, GPR, SrcType::GPR);
+        if let SrcRef::Imm32(imm32) = &mut self.shift.src_ref {
+            if self.wrap {
+                *imm32 = *imm32 & 0x1f;
+            } else {
+                *imm32 = (*imm32).min(32);
+            }
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Int,
+            0x16,
+            Some(&self.dst),
+            Some(&self.src),
+            Some(&self.shift),
+            None,
+        );
+        e.set_bit(5, self.signed);
+        e.set_bit(9, self.wrap);
+    }
+}
+
+impl SM20Op for OpF2F {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_f20_overflow(&mut self.src, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_b(SM20Unit::Move, 0x4, self.dst, self.src);
+        e.set_bit(5, false); // .sat
+        e.set_bit(6, self.src.src_mod.has_fabs());
+        e.set_bit(7, self.integer_rnd);
+        e.set_bit(8, self.src.src_mod.has_fneg());
+        e.set_field(20..22, (self.dst_type.bits() / 8).ilog2());
+        e.set_field(23..25, (self.src_type.bits() / 8).ilog2());
+        e.set_rnd_mode(49..51, self.rnd_mode);
+        e.set_bit(55, self.ftz);
+        e.set_bit(56, self.high);
+    }
+}
+
+impl SM20Op for OpF2I {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_f20_overflow(&mut self.src, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_b(SM20Unit::Move, 0x5, self.dst, self.src);
+        e.set_bit(6, self.src.src_mod.has_fabs());
+        e.set_bit(7, self.dst_type.is_signed());
+        e.set_bit(8, self.src.src_mod.has_fneg());
+        e.set_field(20..22, (self.dst_type.bits() / 8).ilog2());
+        e.set_field(23..25, (self.src_type.bits() / 8).ilog2());
+        e.set_rnd_mode(49..51, self.rnd_mode);
+        e.set_bit(55, self.ftz);
+        e.set_bit(56, false); // .high
+    }
+}
+
+impl SM20Op for OpI2F {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_i20_overflow(&mut self.src, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(self.src.src_mod.is_none());
+        e.encode_form_b(SM20Unit::Move, 0x6, self.dst, self.src);
+        e.set_bit(6, false); // .abs
+        e.set_bit(8, false); // .neg
+        e.set_bit(9, self.src_type.is_signed());
+        e.set_field(20..22, (self.dst_type.bits() / 8).ilog2());
+        e.set_field(23..25, (self.src_type.bits() / 8).ilog2());
+        e.set_rnd_mode(49..51, self.rnd_mode);
+        e.set_field(55..57, 0_u8); // 1: .h0, 2: .h1
+    }
+}
+
+impl SM20Op for OpI2I {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_i20_overflow(&mut self.src, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(self.src.src_mod.is_none());
+        e.encode_form_b(SM20Unit::Move, 0x7, self.dst, self.src);
+        e.set_bit(5, self.saturate);
+        e.set_bit(6, self.abs);
+        e.set_bit(7, self.dst_type.is_signed());
+        e.set_bit(8, self.neg);
+        e.set_bit(9, self.src_type.is_signed());
+        e.set_field(20..22, (self.dst_type.bits() / 8).ilog2());
+        e.set_field(23..25, (self.src_type.bits() / 8).ilog2());
+        e.set_field(55..57, 0_u8); // 1: .h0, 2: .h1
+    }
+}
+
+impl SM20Op for OpMov {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        if let Some(imm32) = self.src.as_imm_not_i20() {
+            e.encode_form_b_imm32(0x6, self.dst, imm32);
+        } else {
+            e.encode_form_b(SM20Unit::Move, 0xa, self.dst, self.src);
+        }
+        e.set_field(5..9, self.quad_lanes);
+    }
+}
+
+impl SM20Op for OpPrmt {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::ALU);
+        b.copy_alu_src_if_not_reg(src1, GPR, SrcType::ALU);
+        if let SrcRef::Imm32(imm32) = &mut self.sel.src_ref {
+            // Only the bottom 16 bits matter anyway
+            *imm32 = *imm32 & 0xffff;
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Move,
+            0x9,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.sel),
+            Some(&self.srcs[1]),
+        );
+        e.set_field(
+            5..8,
+            match self.mode {
+                PrmtMode::Index => 0_u8,
+                PrmtMode::Forward4Extract => 1_u8,
+                PrmtMode::Backward4Extract => 2_u8,
+                PrmtMode::Replicate8 => 3_u8,
+                PrmtMode::EdgeClampLeft => 4_u8,
+                PrmtMode::EdgeClampRight => 5_u8,
+                PrmtMode::Replicate16 => 6_u8,
+            },
+        );
+    }
+}
+
+impl SM20Op for OpSel {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        let [src0, src1] = &mut self.srcs;
+        if swap_srcs_if_not_reg(src0, src1, GPR) {
+            self.cond = self.cond.bnot();
+        }
+        b.copy_alu_src_if_not_reg(src0, GPR, SrcType::ALU);
+        b.copy_alu_src_if_i20_overflow(src1, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Move,
+            0x8,
+            Some(&self.dst),
+            Some(&self.srcs[0]),
+            Some(&self.srcs[1]),
+            None,
+        );
+        e.set_pred_src(49..53, self.cond);
+    }
+}
+
+impl SM20Op for OpShfl {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        if matches!(self.lane.src_ref, SrcRef::CBuf(_)) {
+            b.copy_alu_src(&mut self.lane, GPR, SrcType::ALU);
+        }
+        if matches!(self.c.src_ref, SrcRef::CBuf(_)) {
+            b.copy_alu_src(&mut self.c, GPR, SrcType::ALU);
+        }
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Mem, 0x22);
+        e.set_pred_dst2(8..10, 58..59, self.in_bounds);
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src(20..26, self.src);
+
+        if let Some(u) = self.lane.as_u32() {
+            e.set_field(26..32, u & 0x1f);
+            e.set_bit(5, true);
+        } else {
+            e.set_reg_src(26..32, self.lane);
+            e.set_bit(5, false);
+        }
+
+        if let Some(u) = self.c.as_u32() {
+            e.set_field(42..55, u & 0x1fff);
+            e.set_bit(6, true);
+        } else {
+            e.set_reg_src(49..55, self.c);
+            e.set_bit(6, false);
+        }
+
+        e.set_field(
+            55..57,
+            match self.op {
+                ShflOp::Idx => 0_u8,
+                ShflOp::Up => 1_u8,
+                ShflOp::Down => 2_u8,
+                ShflOp::Bfly => 3_u8,
+            },
+        );
+    }
+}
+
+impl SM20Op for OpPSetP {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Move, 0x3);
+
+        e.set_pred_dst(14..17, self.dsts[1]);
+        e.set_pred_dst(17..20, self.dsts[0]);
+        e.set_pred_src(20..24, self.srcs[0]);
+        e.set_pred_src(26..30, self.srcs[1]);
+        e.set_pred_set_op(30..32, self.ops[0]);
+        e.set_pred_src(49..53, self.srcs[2]);
+        e.set_pred_set_op(53..55, self.ops[1]);
+    }
+}
+
+impl SM20Encoder<'_> {
+    fn set_tex_dim(&mut self, range: Range<usize>, dim: TexDim) {
+        assert!(range.len() == 3);
+        self.set_field(
+            range,
+            match dim {
+                TexDim::_1D => 0_u8,
+                TexDim::Array1D => 1_u8,
+                TexDim::_2D => 2_u8,
+                TexDim::Array2D => 3_u8,
+                TexDim::_3D => 4_u8,
+                TexDim::Cube => 6_u8,
+                TexDim::ArrayCube => 7_u8,
+            },
+        );
+    }
+
+    fn set_tex_lod_mode(&mut self, range: Range<usize>, lod_mode: TexLodMode) {
+        assert!(range.len() == 2);
+        self.set_field(
+            range,
+            match lod_mode {
+                TexLodMode::Auto => 0_u8,
+                TexLodMode::Zero => 1_u8,
+                TexLodMode::Bias => 2_u8,
+                TexLodMode::Lod => 3_u8,
+                _ => panic!("Unknown LOD mode"),
+            },
+        );
+    }
+
+    fn set_tex_channel_mask(
+        &mut self,
+        range: Range<usize>,
+        channel_mask: ChannelMask,
+    ) {
+        self.set_field(range, channel_mask.to_bits());
+    }
+}
+
+fn legalize_tex_instr(op: &mut impl SrcsAsSlice, _b: &mut LegalizeBuilder) {
+    // Texture instructions have one or two sources.  When they have two, the
+    // second one is optional and we can set rZ instead.
+    let srcs = op.srcs_as_mut_slice();
+    assert!(matches!(&srcs[0].src_ref, SrcRef::SSA(_)));
+    if srcs.len() > 1 {
+        debug_assert!(srcs.len() == 2);
+        assert!(matches!(&srcs[1].src_ref, SrcRef::SSA(_) | SrcRef::Zero));
+    }
+}
+
+impl SM20Op for OpTex {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_tex_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x20);
+
+        match self.tex {
+            TexRef::Bound(idx) => {
+                e.set_field(32..40, idx);
+                e.set_bit(50, false); // .b
+            }
+            TexRef::CBuf { .. } => {
+                panic!("SM20 doesn't have CBuf textures");
+            }
+            TexRef::Bindless => {
+                assert!(e.sm.sm() >= 30);
+                e.set_field(32..40, 0xff_u8);
+                e.set_bit(50, true); // .b
+            }
+        }
+
+        e.set_field(7..9, 0x2_u8); // TODO: .p
+        e.set_bit(9, self.nodep);
+        e.set_dst(14..20, self.dsts[0]);
+        assert!(self.dsts[1].is_none());
+        assert!(self.fault.is_none());
+        e.set_reg_src(20..26, self.srcs[0]);
+        e.set_reg_src(26..32, self.srcs[1]);
+        e.set_tex_channel_mask(46..50, self.channel_mask);
+        e.set_tex_dim(51..54, self.dim);
+        e.set_bit(54, self.offset);
+        e.set_bit(56, self.z_cmpr);
+        e.set_tex_lod_mode(57..59, self.lod_mode);
+    }
+}
+
+impl SM20Op for OpTld {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_tex_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x24);
+
+        match self.tex {
+            TexRef::Bound(idx) => {
+                e.set_field(32..40, idx);
+                e.set_bit(50, false); // .b
+            }
+            TexRef::CBuf { .. } => {
+                panic!("SM20 doesn't have CBuf textures");
+            }
+            TexRef::Bindless => {
+                assert!(e.sm.sm() >= 30);
+                e.set_field(32..40, 0xff_u8);
+                e.set_bit(50, true); // .b
+            }
+        }
+
+        e.set_field(7..9, 0x2_u8); // TODO: .p
+        e.set_bit(9, self.nodep);
+        e.set_dst(14..20, self.dsts[0]);
+        assert!(self.dsts[1].is_none());
+        assert!(self.fault.is_none());
+        e.set_reg_src(20..26, self.srcs[0]);
+        e.set_reg_src(26..32, self.srcs[1]);
+        e.set_tex_channel_mask(46..50, self.channel_mask);
+        e.set_tex_dim(51..54, self.dim);
+        e.set_bit(54, self.offset);
+        e.set_bit(55, self.is_ms);
+        e.set_bit(56, false); // z_cmpr
+        e.set_field(
+            57..58,
+            match self.lod_mode {
+                TexLodMode::Zero => 0_u8,
+                TexLodMode::Lod => 1_u8,
+                _ => panic!("Tld does not support {}", self.lod_mode),
+            },
+        );
+    }
+}
+
+impl SM20Op for OpTld4 {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_tex_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x28);
+
+        match self.tex {
+            TexRef::Bound(idx) => {
+                e.set_field(32..40, idx);
+                e.set_bit(50, false); // .b
+            }
+            TexRef::CBuf { .. } => {
+                panic!("SM20 doesn't have CBuf textures");
+            }
+            TexRef::Bindless => {
+                assert!(e.sm.sm() >= 30);
+                e.set_field(32..40, 0xff_u8);
+                e.set_bit(50, true); // .b
+            }
+        }
+
+        e.set_field(5..7, self.comp);
+        e.set_field(7..9, 0x2_u8); // TODO: .p
+        e.set_bit(9, self.nodep);
+        e.set_dst(14..20, self.dsts[0]);
+        assert!(self.dsts[1].is_none());
+        assert!(self.fault.is_none());
+        e.set_reg_src(20..26, self.srcs[0]);
+        e.set_reg_src(26..32, self.srcs[1]);
+        e.set_bit(45, false); // .ndv
+        e.set_tex_channel_mask(46..50, self.channel_mask);
+        e.set_tex_dim(51..54, self.dim);
+        e.set_field(
+            54..56,
+            match self.offset_mode {
+                Tld4OffsetMode::None => 0_u8,
+                Tld4OffsetMode::AddOffI => 1_u8,
+                Tld4OffsetMode::PerPx => 2_u8,
+            },
+        );
+        e.set_bit(56, self.z_cmpr);
+    }
+}
+
+impl SM20Op for OpTmml {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_tex_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x2c);
+
+        match self.tex {
+            TexRef::Bound(idx) => {
+                e.set_field(32..40, idx);
+                e.set_bit(50, false); // .b
+            }
+            TexRef::CBuf { .. } => {
+                panic!("SM20 doesn't have CBuf textures");
+            }
+            TexRef::Bindless => {
+                assert!(e.sm.sm() >= 30);
+                e.set_field(32..40, 0xff_u8);
+                e.set_bit(50, true); // .b
+            }
+        }
+
+        e.set_field(7..9, 0x2_u8); // TODO: .p
+        e.set_bit(9, self.nodep);
+        e.set_dst(14..20, self.dsts[0]);
+        assert!(self.dsts[1].is_none());
+        e.set_reg_src(20..26, self.srcs[0]);
+        e.set_reg_src(26..32, self.srcs[1]);
+        e.set_tex_channel_mask(46..50, self.channel_mask);
+        e.set_tex_dim(51..54, self.dim);
+    }
+}
+
+impl SM20Op for OpTxd {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_tex_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x38);
+
+        match self.tex {
+            TexRef::Bound(idx) => {
+                e.set_field(32..40, idx);
+                e.set_bit(50, false); // .b
+            }
+            TexRef::CBuf { .. } => {
+                panic!("SM20 doesn't have CBuf textures");
+            }
+            TexRef::Bindless => {
+                assert!(e.sm.sm() >= 30);
+                e.set_field(32..40, 0xff_u8);
+                e.set_bit(50, true); // .b
+            }
+        }
+
+        e.set_field(7..9, 0x2_u8); // TODO: .p
+        e.set_bit(9, self.nodep);
+        e.set_dst(14..20, self.dsts[0]);
+        assert!(self.dsts[1].is_none());
+        e.set_reg_src(20..26, self.srcs[0]);
+        e.set_reg_src(26..32, self.srcs[1]);
+        e.set_tex_channel_mask(46..50, self.channel_mask);
+        e.set_tex_dim(51..54, self.dim);
+        e.set_bit(54, self.offset);
+    }
+}
+
+impl SM20Op for OpTxq {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_tex_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x30);
+
+        match self.tex {
+            TexRef::Bound(idx) => {
+                e.set_field(32..40, idx);
+                e.set_bit(50, false); // .b
+            }
+            TexRef::CBuf { .. } => {
+                panic!("SM20 doesn't have CBuf textures");
+            }
+            TexRef::Bindless => {
+                assert!(e.sm.sm() >= 30);
+                e.set_field(32..40, 0xff_u8);
+                e.set_bit(50, true); // .b
+            }
+        }
+
+        e.set_field(7..9, 0x2_u8); // TODO: .p
+        e.set_bit(9, self.nodep);
+        e.set_dst(14..20, self.dsts[0]);
+        assert!(self.dsts[1].is_none());
+        e.set_reg_src(20..26, self.src);
+        e.set_reg_src(26..32, 0.into());
+        e.set_tex_channel_mask(46..50, self.channel_mask);
+        e.set_field(
+            54..57,
+            match self.query {
+                TexQuery::Dimension => 0_u8,
+                TexQuery::TextureType => 1_u8,
+                TexQuery::SamplerPos => 2_u8,
+                // TexQuery::Filter => 0x3_u8,
+                // TexQuery::Lod => 0x4_u8,
+                // TexQuery::BorderColour => 0x5_u8,
+            },
+        );
+    }
+}
+
+impl SM20Encoder<'_> {
+    fn set_mem_type(&mut self, range: Range<usize>, mem_type: MemType) {
+        assert!(range.len() == 3);
+        self.set_field(
+            range,
+            match mem_type {
+                MemType::U8 => 0_u8,
+                MemType::I8 => 1_u8,
+                MemType::U16 => 2_u8,
+                MemType::I16 => 3_u8,
+                MemType::B32 => 4_u8,
+                MemType::B64 => 5_u8,
+                MemType::B128 => 6_u8,
+            },
+        );
+    }
+}
+
+/// Helper to legalize extended or external instructions
+///
+/// These are instructions which reach out external units such as load/store
+/// and texture ops.  They typically can't take anything but GPRs and are the
+/// only types of instructions that support vectors.
+///
+fn legalize_ext_instr(op: &mut impl SrcsAsSlice, _b: &mut LegalizeBuilder) {
+    let src_types = op.src_types();
+    for (i, src) in op.srcs_as_mut_slice().iter_mut().enumerate() {
+        match src_types[i] {
+            SrcType::SSA => {
+                assert!(src.as_ssa().is_some());
+            }
+            SrcType::GPR => {
+                assert!(src_is_reg(src, RegFile::GPR));
+            }
+            SrcType::ALU
+            | SrcType::F16
+            | SrcType::F16v2
+            | SrcType::F32
+            | SrcType::F64
+            | SrcType::I32
+            | SrcType::B32 => {
+                panic!("ALU srcs must be legalized explicitly");
+            }
+            SrcType::Pred => {
+                panic!("Predicates must be legalized explicitly");
+            }
+            SrcType::Carry => {
+                panic!("Carry values must be legalized explicitly");
+            }
+            SrcType::Bar => panic!("Barrier regs are Volta+"),
+        }
+    }
+}
+
+impl SM20Op for OpLd {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        match self.access.space {
+            MemSpace::Global(addr_type) => {
+                e.set_opcode(SM20Unit::Mem, 0x20);
+                e.set_field(26..58, self.offset);
+                e.set_bit(58, addr_type == MemAddrType::A64);
+            }
+            MemSpace::Local => {
+                e.set_opcode(SM20Unit::Mem, 0x30);
+                e.set_bit(56, false); // shared
+                e.set_field(26..50, self.offset);
+            }
+            MemSpace::Shared => {
+                e.set_opcode(SM20Unit::Mem, 0x30);
+                e.set_bit(56, true); // shared
+                e.set_field(26..50, self.offset);
+            }
+        }
+        e.set_mem_type(5..8, self.access.mem_type);
+        // 8..9: cache hints (.ca, .cg, .lu, .cv)
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src(20..26, self.addr);
+    }
+}
+
+impl SM20Op for OpLdc {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_not_reg(&mut self.offset, GPR, SrcType::GPR);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        assert!(self.cb.src_mod.is_none());
+        let SrcRef::CBuf(cb) = &self.cb.src_ref else {
+            panic!("Not a CBuf source");
+        };
+        let CBuf::Binding(cb_idx) = cb.buf else {
+            panic!("Must be a bound constant buffer");
+        };
+
+        e.set_opcode(SM20Unit::Tex, 0x5);
+
+        e.set_mem_type(5..8, self.mem_type);
+        e.set_field(
+            8..10,
+            match self.mode {
+                LdcMode::Indexed => 0_u8,
+                LdcMode::IndexedLinear => 1_u8,
+                LdcMode::IndexedSegmented => 2_u8,
+                LdcMode::IndexedSegmentedLinear => 3_u8,
+            },
+        );
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src(20..26, self.offset);
+        e.set_field(26..42, cb.offset);
+        e.set_field(42..47, cb_idx);
+    }
+}
+
+impl SM20Op for OpSt {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        match self.access.space {
+            MemSpace::Global(addr_type) => {
+                e.set_opcode(SM20Unit::Mem, 0x24);
+                e.set_field(26..58, self.offset);
+                e.set_bit(58, addr_type == MemAddrType::A64);
+            }
+            MemSpace::Local => {
+                e.set_opcode(SM20Unit::Mem, 0x32);
+                e.set_bit(56, false); // shared
+                e.set_field(26..50, self.offset);
+            }
+            MemSpace::Shared => {
+                e.set_opcode(SM20Unit::Mem, 0x32);
+                e.set_bit(56, true); // shared
+                e.set_field(26..50, self.offset);
+            }
+        }
+        e.set_mem_type(5..8, self.access.mem_type);
+        // 8..9: cache hints (.ca, .cg, .lu, .cv)
+        e.set_reg_src(14..20, self.data);
+        e.set_reg_src(20..26, self.addr);
+    }
+}
+
+fn atom_src_as_ssa(
+    b: &mut LegalizeBuilder,
+    src: Src,
+    atom_type: AtomType,
+) -> SSARef {
+    if let Some(ssa) = src.as_ssa() {
+        return *ssa;
+    }
+
+    let tmp;
+    if atom_type.bits() == 32 {
+        tmp = b.alloc_ssa(RegFile::GPR, 1);
+        b.copy_to(tmp.into(), 0.into());
+    } else {
+        debug_assert!(atom_type.bits() == 64);
+        tmp = b.alloc_ssa(RegFile::GPR, 2);
+        b.copy_to(tmp[0].into(), 0.into());
+        b.copy_to(tmp[1].into(), 0.into());
+    }
+    tmp
+}
+
+impl SM20Op for OpAtom {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        if self.atom_op == AtomOp::CmpExch(AtomCmpSrc::Separate) {
+            let cmpr = atom_src_as_ssa(b, self.cmpr, self.atom_type);
+            let data = atom_src_as_ssa(b, self.data, self.atom_type);
+
+            let mut cmpr_data = Vec::new();
+            cmpr_data.extend_from_slice(&cmpr);
+            cmpr_data.extend_from_slice(&data);
+            let cmpr_data = SSARef::try_from(cmpr_data).unwrap();
+
+            self.cmpr = 0.into();
+            self.data = cmpr_data.into();
+            self.atom_op = AtomOp::CmpExch(AtomCmpSrc::Packed);
+        }
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        let MemSpace::Global(addr_type) = self.mem_space else {
+            panic!("SM20 only supports global atomics");
+        };
+        assert!(addr_type == MemAddrType::A64);
+
+        if self.dst.is_none() {
+            e.set_opcode(SM20Unit::Mem, 0x1);
+        } else {
+            e.set_opcode(SM20Unit::Mem, 0x11);
+        }
+
+        let op = match self.atom_op {
+            AtomOp::Add => 0_u8,
+            AtomOp::Min => 1_u8,
+            AtomOp::Max => 2_u8,
+            AtomOp::Inc => 3_u8,
+            AtomOp::Dec => 4_u8,
+            AtomOp::And => 5_u8,
+            AtomOp::Or => 6_u8,
+            AtomOp::Xor => 7_u8,
+            AtomOp::Exch => 8_u8,
+            AtomOp::CmpExch(_) => 9_u8,
+        };
+        e.set_field(5..9, op);
+
+        let typ = match self.atom_type {
+            AtomType::F16x2 => panic!("Unsupported atomic type"),
+            // AtomType::U8 => 0x0_u8,
+            // AtomType::I8 => 0x1_u8,
+            // AtomType::U16 => 0x2_u8,
+            // AtomType::I16 => 0x3_u8,
+            AtomType::U32 => 0x4_u8,
+            AtomType::U64 => 0x5_u8,
+            //AtomType::U128 => 0x6_u8,
+            AtomType::I32 => 0x7_u8,
+            AtomType::I64 => 0x8_u8,
+            //AtomType::I128 => 0x9_u8,
+            //AtomType::F16 => 0xa_u8,
+            AtomType::F64 => 0xc_u8,
+            AtomType::F32 => 0xd_u8,
+        };
+        e.set_field(9..10, typ & 0x1);
+        e.set_field(59..62, typ >> 1);
+
+        e.set_reg_src(20..26, self.addr);
+        e.set_reg_src(14..20, self.data);
+
+        if self.dst.is_none() {
+            e.set_field(26..58, self.addr_offset);
+        } else {
+            e.set_dst(43..49, self.dst);
+            e.set_field(26..43, self.addr_offset & 0x1ffff);
+            e.set_field(55..58, self.addr_offset >> 17);
+        }
+
+        if let AtomOp::CmpExch(cmp_src) = self.atom_op {
+            // The hardware expects the first source to be packed and then the
+            // second source to be the top half of the first.
+            assert!(cmp_src == AtomCmpSrc::Packed);
+            let cmpr_data = self.data.src_ref.as_reg().unwrap();
+            assert!(cmpr_data.comps() % 2 == 0);
+            let data_comps = cmpr_data.comps() / 2;
+            let data_idx = cmpr_data.base_idx() + u32::from(data_comps);
+            let data = RegRef::new(cmpr_data.file(), data_idx, data_comps);
+
+            e.set_reg_src(49..55, data.into());
+        } else if !self.dst.is_none() {
+            e.set_reg_src(49..55, 0.into());
+        }
+    }
+}
+
+impl SM20Op for OpALd {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x1);
+        e.set_field(5..7, self.comps - 1);
+
+        if self.phys {
+            assert!(!self.patch);
+            assert!(self.offset.src_ref.as_reg().is_some());
+        } else if !self.patch {
+            assert!(self.offset.is_zero());
+        }
+        e.set_bit(8, self.patch);
+        e.set_bit(9, self.output);
+
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src(20..26, self.offset);
+        e.set_reg_src(26..32, self.vtx);
+        e.set_field(32..42, self.addr);
+    }
+}
+
+impl SM20Op for OpASt {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x2);
+        e.set_field(5..7, self.comps - 1);
+
+        e.set_bit(8, self.patch);
+        assert!(!self.phys);
+
+        e.set_reg_src(20..26, self.offset);
+        e.set_reg_src(26..32, self.data);
+        e.set_field(32..42, self.addr);
+        e.set_reg_src(49..55, self.vtx);
+    }
+}
+
+impl SM20Op for OpIpa {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Float, 0x30);
+
+        e.set_bit(5, false); // .sat
+        e.set_field(
+            6..8,
+            match self.freq {
+                InterpFreq::Pass => 0_u8,
+                InterpFreq::PassMulW => 1_u8,
+                InterpFreq::Constant => 2_u8,
+                InterpFreq::State => 3_u8,
+            },
+        );
+        e.set_field(
+            8..10,
+            match self.loc {
+                InterpLoc::Default => 0_u8,
+                InterpLoc::Centroid => 1_u8,
+                InterpLoc::Offset => 2_u8,
+            },
+        );
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src(20..26, 0.into()); // indirect
+        e.set_reg_src(26..32, self.inv_w);
+        e.set_reg_src(49..55, self.offset);
+        e.set_field(32..42, self.addr);
+    }
+}
+
+impl SM20Op for OpCCtl {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        let op = match self.mem_space {
+            MemSpace::Global(MemAddrType::A32) => 0x26,
+            MemSpace::Global(MemAddrType::A64) => 0x27,
+            MemSpace::Local => panic!("cctl does not support local"),
+            MemSpace::Shared => 0x34,
+        };
+        e.set_opcode(SM20Unit::Mem, op);
+
+        e.set_field(
+            5..10,
+            match self.op {
+                CCtlOp::Qry1 => 0_u8,
+                CCtlOp::PF1 => 1_u8,
+                CCtlOp::PF1_5 => 2_u8,
+                CCtlOp::PF2 => 3_u8,
+                CCtlOp::WB => 4_u8,
+                CCtlOp::IV => 5_u8,
+                CCtlOp::IVAll => 6_u8,
+                CCtlOp::RS => 7_u8,
+                CCtlOp::WBAll => 8_u8,
+                CCtlOp::RSLB => 9_u8,
+                CCtlOp::IVAllP | CCtlOp::WBAllP => {
+                    panic!("cctl{} is not supported on SM20", self.op);
+                }
+            },
+        );
+        e.set_dst(14..20, Dst::None);
+        e.set_reg_src(20..26, self.addr);
+        e.set_field(26..28, 0); // 1: .u, 2: .c: 3: .i
+
+        assert!(self.addr_offset % 4 == 0);
+        if matches!(self.mem_space, MemSpace::Global(_)) {
+            e.set_field(28..58, self.addr_offset / 4);
+        } else {
+            e.set_field(28..50, self.addr_offset / 4);
+        }
+    }
+}
+
+impl SM20Op for OpMemBar {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Mem, 0x38);
+        e.set_field(
+            5..7,
+            match self.scope {
+                MemScope::CTA => 0_u8,
+                MemScope::GPU => 1_u8,
+                MemScope::System => 2_u8,
+            },
+        );
+    }
+}
+
+impl SM20Encoder<'_> {
+    fn set_rel_offset(&mut self, range: Range<usize>, label: &Label) {
+        let ip = u32::try_from(self.ip).unwrap();
+        let ip = i32::try_from(ip).unwrap();
+
+        let target_ip = *self.labels.get(label).unwrap();
+        let target_ip = u32::try_from(target_ip).unwrap();
+        let target_ip = i32::try_from(target_ip).unwrap();
+
+        let rel_offset = target_ip - ip - 8;
+
+        self.set_field(range, rel_offset);
+    }
+}
+
+impl SM20Op for OpBra {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Exec, 0x10);
+        e.set_field(5..9, 0xf_u8); // flags
+        e.set_bit(15, false); // .u
+        e.set_bit(16, false); // .lmt
+        e.set_rel_offset(26..50, &self.target);
+    }
+}
+
+impl SM20Op for OpSSy {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Exec, 0x18);
+        e.set_rel_offset(26..50, &self.target);
+    }
+}
+
+impl SM20Op for OpSync {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        // SM20 doesn't have sync.  It's just nop.s
+        e.set_opcode(SM20Unit::Move, 0x10);
+        e.set_field(5..9, 0xf_u8); // flags
+        e.set_bit(4, true);
+    }
+}
+
+impl SM20Op for OpBrk {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Exec, 0x2a);
+        e.set_field(5..9, 0xf_u8); // flags
+    }
+}
+
+impl SM20Op for OpPBk {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Exec, 0x1a);
+        e.set_rel_offset(26..50, &self.target);
+    }
+}
+
+impl SM20Op for OpCont {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Exec, 0x2c);
+        e.set_field(5..9, 0xf_u8); // flags
+    }
+}
+
+impl SM20Op for OpPCnt {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Exec, 0x1c);
+        e.set_rel_offset(26..50, &self.target);
+    }
+}
+
+impl SM20Op for OpExit {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Exec, 0x20);
+        e.set_field(5..9, 0xf_u8); // flags
+    }
+}
+
+impl SM20Op for OpBar {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Move, 0x14);
+
+        e.set_field(5..7, 0_u8); // 0: .popc, 1: .and, 2: .or
+        e.set_field(7..9, 0_u8); // 0: .sync, 1: .arv, 2: .red
+        e.set_reg_src(20..26, 0.into());
+        e.set_reg_src(26..32, 0.into());
+        e.set_bit(46, false); // src1_is_imm
+        e.set_bit(47, false); // src0_is_imm
+        e.set_pred_src(49..53, true.into());
+        e.set_pred_dst(53..56, Dst::None);
+    }
+}
+
+impl SM20Op for OpTexDepBar {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x3c);
+        e.set_field(5..9, 0xf_u8); // flags
+        e.set_field(26..30, self.textures_left);
+    }
+}
+
+impl SM20Op for OpIsberd {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x0);
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src(20..26, self.idx);
+        e.set_field(26..42, 0_u16); // offset
+    }
+}
+
+impl SM20Op for OpKill {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Exec, 0x26);
+        e.set_field(5..9, 0xf_u8); // flags
+    }
+}
+
+impl SM20Op for OpNop {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Move, 0x10);
+        e.set_field(5..9, 0xf_u8); // flags
+    }
+}
+
+impl SM20Op for OpPixLd {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Tex, 0x4);
+        e.set_field(
+            5..8,
+            match &self.val {
+                PixVal::CovMask => 1_u8,
+                PixVal::Covered => 2_u8,
+                PixVal::Offset => 3_u8,
+                PixVal::CentroidOffset => 4_u8,
+                PixVal::MyIndex => 5_u8,
+                other => panic!("Unsupported PixVal: {other}"),
+            },
+        );
+        e.set_dst(14..20, self.dst);
+        e.set_reg_src(20..26, 0.into());
+        e.set_field(26..34, 0_u16); // offset
+        e.set_pred_dst(53..56, Dst::None);
+    }
+}
+
+impl SM20Op for OpS2R {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        legalize_ext_instr(self, b);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Move, 0xb);
+        e.set_dst(14..20, self.dst);
+        e.set_field(26..36, self.idx);
+    }
+}
+
+impl SM20Op for OpVote {
+    fn legalize(&mut self, _b: &mut LegalizeBuilder) {
+        // Nothing to do
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.set_opcode(SM20Unit::Move, 0x12);
+        e.set_field(
+            5..7,
+            match self.op {
+                VoteOp::All => 0_u8,
+                VoteOp::Any => 1_u8,
+                VoteOp::Eq => 2_u8,
+            },
+        );
+        e.set_dst(14..20, self.ballot);
+        e.set_pred_src(20..24, self.pred);
+        e.set_pred_dst(54..57, self.vote);
+    }
+}
+
+impl SM20Op for OpOut {
+    fn legalize(&mut self, b: &mut LegalizeBuilder) {
+        use RegFile::GPR;
+        b.copy_alu_src_if_not_reg(&mut self.handle, GPR, SrcType::ALU);
+        b.copy_alu_src_if_i20_overflow(&mut self.stream, GPR, SrcType::ALU);
+    }
+
+    fn encode(&self, e: &mut SM20Encoder<'_>) {
+        e.encode_form_a(
+            SM20Unit::Tex,
+            0x7,
+            Some(&self.dst),
+            Some(&self.handle),
+            Some(&self.stream),
+            None,
+        );
+        e.set_field(
+            5..7,
+            match self.out_type {
+                OutType::Emit => 1_u8,
+                OutType::Cut => 2_u8,
+                OutType::EmitThenCut => 3_u8,
+            },
+        );
+    }
+}
+
+macro_rules! as_sm20_op_match {
+    ($op: expr) => {
+        match $op {
+            Op::FAdd(op) => op,
+            Op::FFma(op) => op,
+            Op::FMnMx(op) => op,
+            Op::FMul(op) => op,
+            Op::Rro(op) => op,
+            Op::MuFu(op) => op,
+            Op::FSet(op) => op,
+            Op::FSetP(op) => op,
+            Op::FSwz(op) => op,
+            Op::DAdd(op) => op,
+            Op::DFma(op) => op,
+            Op::DMnMx(op) => op,
+            Op::DMul(op) => op,
+            Op::DSetP(op) => op,
+            Op::Bfe(op) => op,
+            Op::Flo(op) => op,
+            Op::IAdd2(op) => op,
+            Op::IAdd2X(op) => op,
+            Op::IMad(op) => op,
+            Op::IMul(op) => op,
+            Op::IMnMx(op) => op,
+            Op::ISetP(op) => op,
+            Op::Lop2(op) => op,
+            Op::PopC(op) => op,
+            Op::Shl(op) => op,
+            Op::Shr(op) => op,
+            Op::F2F(op) => op,
+            Op::F2I(op) => op,
+            Op::I2F(op) => op,
+            Op::I2I(op) => op,
+            Op::Mov(op) => op,
+            Op::Prmt(op) => op,
+            Op::Sel(op) => op,
+            Op::Shfl(op) => op,
+            Op::PSetP(op) => op,
+            Op::Tex(op) => op,
+            Op::Tld(op) => op,
+            Op::Tld4(op) => op,
+            Op::Tmml(op) => op,
+            Op::Txd(op) => op,
+            Op::Txq(op) => op,
+            Op::Ld(op) => op,
+            Op::Ldc(op) => op,
+            Op::St(op) => op,
+            Op::Atom(op) => op,
+            Op::ALd(op) => op,
+            Op::ASt(op) => op,
+            Op::Ipa(op) => op,
+            Op::CCtl(op) => op,
+            Op::MemBar(op) => op,
+            Op::Bra(op) => op,
+            Op::SSy(op) => op,
+            Op::Sync(op) => op,
+            Op::Brk(op) => op,
+            Op::PBk(op) => op,
+            Op::Cont(op) => op,
+            Op::PCnt(op) => op,
+            Op::Exit(op) => op,
+            Op::Bar(op) => op,
+            Op::TexDepBar(op) => op,
+            Op::Isberd(op) => op,
+            Op::Kill(op) => op,
+            Op::Nop(op) => op,
+            Op::PixLd(op) => op,
+            Op::S2R(op) => op,
+            Op::Vote(op) => op,
+            Op::Out(op) => op,
+            _ => panic!("Unhandled instruction {}", $op),
+        }
+    };
+}
+
+fn as_sm20_op(op: &Op) -> &dyn SM20Op {
+    as_sm20_op_match!(op)
+}
+
+fn as_sm20_op_mut(op: &mut Op) -> &mut dyn SM20Op {
+    as_sm20_op_match!(op)
+}
+
+fn encode_sm20_shader(sm: &ShaderModel20, s: &Shader<'_>) -> Vec<u32> {
+    assert!(s.functions.len() == 1);
+    let func = &s.functions[0];
+
+    let mut ip = 0_usize;
+    let mut labels = HashMap::new();
+    for b in &func.blocks {
+        // We ensure blocks will have groups of 7 instructions with a
+        // schedule instruction before each groups.  As we should never jump
+        // to a schedule instruction, we account for that here.
+        labels.insert(b.label, ip);
+        ip += b.instrs.len() * 8;
+    }
+
+    let mut encoded = Vec::new();
+    for b in &func.blocks {
+        for instr in &b.instrs {
+            let mut e = SM20Encoder {
+                sm: sm,
+                ip: encoded.len() * 4,
+                labels: &labels,
+                inst: [0_u32; 2],
+            };
+            as_sm20_op(&instr.op).encode(&mut e);
+            e.set_pred(&instr.pred);
+            encoded.extend(&e.inst[..]);
+        }
+    }
+
+    encoded
 }
diff --git a/src/nouveau/compiler/nak/sm50.rs b/src/nouveau/compiler/nak/sm50.rs
index 2bf2d4d412a..78556e59f37 100644
--- a/src/nouveau/compiler/nak/sm50.rs
+++ b/src/nouveau/compiler/nak/sm50.rs
@@ -266,7 +266,7 @@ impl SM50Encoder<'_> {
     }
 
     fn set_reg_src(&mut self, range: Range<usize>, src: Src) {
-        assert!(src.is_unmodified());
+        assert!(src.src_mod.is_none());
         self.set_reg_src_ref(range, src.src_ref);
     }
 
@@ -515,7 +515,7 @@ impl SM50Op for OpFAdd {
                 SrcRef::Imm32(imm32) => {
                     e.set_opcode(0x3858);
                     e.set_src_imm_f20(20..39, 56, *imm32);
-                    assert!(self.srcs[1].is_unmodified());
+                    assert!(self.srcs[1].src_mod.is_none());
                 }
                 SrcRef::CBuf(_) => {
                     e.set_opcode(0x4c58);
@@ -625,7 +625,7 @@ impl SM50Op for OpFMnMx {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3860);
                 e.set_src_imm_f20(20..39, 56, *imm32);
-                assert!(self.srcs[1].is_unmodified());
+                assert!(self.srcs[1].src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4c60);
@@ -725,7 +725,7 @@ impl SM50Op for OpRro {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3890);
                 e.set_src_imm_f20(20..39, 56, *imm32);
-                assert!(self.src.is_unmodified());
+                assert!(self.src.src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4c90);
@@ -850,7 +850,7 @@ impl SM50Op for OpFSet {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3000);
                 e.set_src_imm_f20(20..39, 56, *imm32);
-                assert!(self.srcs[1].is_unmodified());
+                assert!(self.srcs[1].src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4800);
@@ -888,7 +888,7 @@ impl SM50Op for OpFSetP {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x36b0);
                 e.set_src_imm_f20(20..39, 56, *imm32);
-                assert!(self.srcs[1].is_unmodified());
+                assert!(self.srcs[1].src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4bb0);
@@ -967,7 +967,7 @@ impl SM50Op for OpDAdd {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3870);
                 e.set_src_imm_f20(20..39, 56, *imm32);
-                assert!(self.srcs[1].is_unmodified());
+                assert!(self.srcs[1].src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4c70);
@@ -1066,7 +1066,7 @@ impl SM50Op for OpDMnMx {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3850);
                 e.set_src_imm_f20(20..39, 56, *imm32);
-                assert!(self.srcs[1].is_unmodified());
+                assert!(self.srcs[1].src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4c50);
@@ -1144,7 +1144,7 @@ impl SM50Op for OpDSetP {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3680);
                 e.set_src_imm_f20(20..39, 56, *imm32);
-                assert!(self.srcs[1].is_unmodified());
+                assert!(self.srcs[1].src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4b80);
@@ -1214,7 +1214,7 @@ impl SM50Op for OpFlo {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3830);
                 e.set_src_imm_i20(20..39, 56, *imm32);
-                assert!(self.src.is_unmodified());
+                assert!(self.src.src_mod.is_none());
             }
             SrcRef::CBuf(cb) => {
                 e.set_opcode(0x4c30);
@@ -1249,7 +1249,9 @@ impl SM50Op for OpIAdd2 {
     fn encode(&self, e: &mut SM50Encoder<'_>) {
         // Hardware requires at least one of these be unmodified.  Otherwise, it
         // encodes as iadd.po which isn't what we want.
-        assert!(self.srcs[0].is_unmodified() || self.srcs[1].is_unmodified());
+        assert!(
+            self.srcs[0].src_mod.is_none() || self.srcs[1].src_mod.is_none()
+        );
 
         let carry_out = match self.carry_out {
             Dst::Reg(reg) if reg.file() == RegFile::Carry => true,
@@ -1275,7 +1277,7 @@ impl SM50Op for OpIAdd2 {
                 SrcRef::Imm32(imm32) => {
                     e.set_opcode(0x3810);
                     e.set_src_imm_i20(20..39, 56, *imm32);
-                    assert!(self.srcs[1].is_unmodified());
+                    assert!(self.srcs[1].src_mod.is_none());
                 }
                 SrcRef::CBuf(_) => {
                     e.set_opcode(0x4c10);
@@ -1331,7 +1333,7 @@ impl SM50Op for OpIAdd2X {
                 SrcRef::Imm32(imm32) => {
                     e.set_opcode(0x3810);
                     e.set_src_imm_i20(20..39, 56, *imm32);
-                    assert!(self.srcs[1].is_unmodified());
+                    assert!(self.srcs[1].src_mod.is_none());
                 }
                 SrcRef::CBuf(_) => {
                     e.set_opcode(0x4c10);
@@ -1418,8 +1420,8 @@ impl SM50Op for OpIMul {
     }
 
     fn encode(&self, e: &mut SM50Encoder<'_>) {
-        assert!(self.srcs[0].is_unmodified());
-        assert!(self.srcs[1].is_unmodified());
+        assert!(self.srcs[0].src_mod.is_none());
+        assert!(self.srcs[1].src_mod.is_none());
 
         if let Some(i) = self.srcs[1].as_imm_not_i20() {
             e.set_opcode(0x1fc0);
@@ -1473,7 +1475,7 @@ impl SM50Op for OpIMnMx {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3820);
                 e.set_src_imm_i20(20..39, 56, *imm32);
-                assert!(self.srcs[1].is_unmodified());
+                assert!(self.srcs[1].src_mod.is_none());
             }
             SrcRef::CBuf(cb) => {
                 e.set_opcode(0x4c20);
@@ -1516,7 +1518,7 @@ impl SM50Op for OpISetP {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x3660);
                 e.set_src_imm_i20(20..39, 56, *imm32);
-                assert!(self.srcs[1].is_unmodified());
+                assert!(self.srcs[1].src_mod.is_none());
             }
             SrcRef::CBuf(cb) => {
                 e.set_opcode(0x4b60);
@@ -1591,7 +1593,7 @@ impl SM50Op for OpLop2 {
                 SrcRef::Imm32(imm32) => {
                     e.set_opcode(0x3840);
                     e.set_src_imm_i20(20..39, 56, *imm32);
-                    assert!(self.srcs[1].is_unmodified());
+                    assert!(self.srcs[1].src_mod.is_none());
                 }
                 SrcRef::CBuf(_) => {
                     e.set_opcode(0x4c40);
@@ -1664,7 +1666,7 @@ impl SM50Op for OpShf {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(if self.right { 0x38f8 } else { 0x36f8 });
                 e.set_src_imm_i20(20..39, 56, *imm32);
-                assert!(self.shift.is_unmodified());
+                assert!(self.shift.src_mod.is_none());
             }
             src => panic!("Invalid shf shift: {src}"),
         }
@@ -1773,7 +1775,7 @@ impl SM50Op for OpF2F {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x38a8);
                 e.set_src_imm_i20(20..39, 56, *imm32);
-                assert!(self.src.is_unmodified());
+                assert!(self.src.src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4ca8);
@@ -1815,7 +1817,7 @@ impl SM50Op for OpF2I {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x38b0);
                 e.set_src_imm_f20(20..39, 56, *imm32);
-                assert!(self.src.is_unmodified());
+                assert!(self.src.src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4cb0);
@@ -1856,7 +1858,7 @@ impl SM50Op for OpI2F {
             SrcRef::Imm32(imm32) => {
                 e.set_opcode(0x38b8);
                 e.set_src_imm_i20(20..39, 56, *imm32);
-                assert!(self.src.is_unmodified());
+                assert!(self.src.src_mod.is_none());
             }
             SrcRef::CBuf(_) => {
                 e.set_opcode(0x4cb8);
@@ -2597,7 +2599,7 @@ impl SM50Op for OpLdc {
     }
 
     fn encode(&self, e: &mut SM50Encoder<'_>) {
-        assert!(self.cb.is_unmodified());
+        assert!(self.cb.src_mod.is_none());
         let SrcRef::CBuf(cb) = &self.cb.src_ref else {
             panic!("Not a CBuf source");
         };
diff --git a/src/nouveau/compiler/nak/sm70_encode.rs b/src/nouveau/compiler/nak/sm70_encode.rs
index b87271f0fc0..bb1b65a1f5e 100644
--- a/src/nouveau/compiler/nak/sm70_encode.rs
+++ b/src/nouveau/compiler/nak/sm70_encode.rs
@@ -86,7 +86,7 @@ impl SM70Encoder<'_> {
     }
 
     fn set_reg_src(&mut self, range: Range<usize>, src: Src) {
-        assert!(src.is_unmodified());
+        assert!(src.src_mod.is_none());
         match src.src_ref {
             SrcRef::Zero => self.set_reg(range, self.zero_reg(RegFile::GPR)),
             SrcRef::Reg(reg) => self.set_reg(range, reg),
@@ -189,7 +189,7 @@ impl SM70Encoder<'_> {
     }
 
     fn set_bar_src(&mut self, range: Range<usize>, src: Src) {
-        assert!(src.is_unmodified());
+        assert!(src.src_mod.is_none());
         self.set_bar_reg(range, *src.src_ref.as_reg().unwrap());
     }
 
@@ -310,7 +310,7 @@ impl ALUSrc {
                 }
             }
             SrcRef::Imm32(i) => {
-                assert!(src.is_unmodified());
+                assert!(src.src_mod.is_none());
                 assert!(src.src_swizzle.is_none());
                 ALUSrc::Imm32(i)
             }
@@ -326,14 +326,6 @@ impl ALUSrc {
             _ => panic!("Invalid ALU source"),
         }
     }
-
-    pub fn has_src_mod(&self) -> bool {
-        match self {
-            ALUSrc::Reg(reg) | ALUSrc::UReg(reg) => reg.abs || reg.neg,
-            ALUSrc::CBuf(cb) => cb.abs || cb.neg,
-            _ => false,
-        }
-    }
 }
 
 impl SM70Encoder<'_> {
@@ -358,7 +350,6 @@ impl SM70Encoder<'_> {
         swizzle_range: Range<usize>,
         file: RegFile,
         is_fp16_alu: bool,
-        has_mod: bool,
         reg: &ALURegRef,
     ) {
         match file {
@@ -367,12 +358,8 @@ impl SM70Encoder<'_> {
             _ => panic!("Invalid ALU src register file"),
         }
 
-        if has_mod {
-            self.set_bit(abs_bit, reg.abs);
-            self.set_bit(neg_bit, reg.neg);
-        } else {
-            assert!(!reg.abs && !reg.neg);
-        }
+        self.set_bit(abs_bit, reg.abs);
+        self.set_bit(neg_bit, reg.neg);
 
         if is_fp16_alu {
             self.set_swizzle(swizzle_range, reg.swizzle);
@@ -392,7 +379,7 @@ impl SM70Encoder<'_> {
             ALUSrc::Reg(reg) => reg,
             _ => panic!("Invalid ALU src"),
         };
-        self.set_alu_reg(24..32, 73, 72, 74..76, file, is_fp16_alu, true, reg);
+        self.set_alu_reg(24..32, 73, 72, 74..76, file, is_fp16_alu, reg);
     }
 
     fn encode_alu_src2(
@@ -400,7 +387,6 @@ impl SM70Encoder<'_> {
         src: &ALUSrc,
         file: RegFile,
         is_fp16_alu: bool,
-        bit74_75_are_mod: bool,
     ) {
         let reg = match src {
             ALUSrc::None => return,
@@ -409,12 +395,11 @@ impl SM70Encoder<'_> {
         };
         self.set_alu_reg(
             64..72,
-            74,
-            75,
+            if is_fp16_alu { 83 } else { 74 },
+            if is_fp16_alu { 84 } else { 75 },
             81..83,
             file,
             is_fp16_alu,
-            bit74_75_are_mod,
             reg,
         );
     }
@@ -427,7 +412,6 @@ impl SM70Encoder<'_> {
             60..62,
             RegFile::GPR,
             is_fp16_alu,
-            true,
             reg,
         );
     }
@@ -479,25 +463,11 @@ impl SM70Encoder<'_> {
         let src1 = ALUSrc::from_src(self, src1, false);
         let src2 = ALUSrc::from_src(self, src2, false);
 
-        // Bits 74..76 are used both for the swizzle on src0 and for the source
-        // modifier for the register source of src1 and src2.  When both are
-        // registers, it's used for src2.  The hardware elects to always support
-        // a swizzle and not support source modifiers in that case.
-        let bit74_75_are_mod = !is_fp16_alu
-            || matches!(src1, ALUSrc::None)
-            || matches!(src2, ALUSrc::None);
-        debug_assert!(bit74_75_are_mod || !src2.has_src_mod());
-
         self.encode_alu_src0(&src0, RegFile::GPR, is_fp16_alu);
 
         let form = match &src2 {
             ALUSrc::None | ALUSrc::Reg(_) => {
-                self.encode_alu_src2(
-                    &src2,
-                    RegFile::GPR,
-                    is_fp16_alu,
-                    bit74_75_are_mod,
-                );
+                self.encode_alu_src2(&src2, RegFile::GPR, is_fp16_alu);
                 match &src1 {
                     ALUSrc::None => 1_u8, // form
                     ALUSrc::Reg(reg1) => {
@@ -520,33 +490,18 @@ impl SM70Encoder<'_> {
             }
             ALUSrc::UReg(reg2) => {
                 self.encode_alu_ureg(reg2, is_fp16_alu);
-                self.encode_alu_src2(
-                    &src1,
-                    RegFile::GPR,
-                    is_fp16_alu,
-                    bit74_75_are_mod,
-                );
+                self.encode_alu_src2(&src1, RegFile::GPR, is_fp16_alu);
                 7_u8 // form
             }
             ALUSrc::Imm32(imm2) => {
                 self.encode_alu_imm(imm2);
-                self.encode_alu_src2(
-                    &src1,
-                    RegFile::GPR,
-                    is_fp16_alu,
-                    bit74_75_are_mod,
-                );
+                self.encode_alu_src2(&src1, RegFile::GPR, is_fp16_alu);
                 2_u8 // form
             }
             ALUSrc::CBuf(cb2) => {
                 // TODO set_src_cx
                 self.encode_alu_cb(cb2, is_fp16_alu);
-                self.encode_alu_src2(
-                    &src1,
-                    RegFile::GPR,
-                    is_fp16_alu,
-                    bit74_75_are_mod,
-                );
+                self.encode_alu_src2(&src1, RegFile::GPR, is_fp16_alu);
                 3_u8 // form
             }
         };
@@ -599,7 +554,7 @@ impl SM70Encoder<'_> {
         self.encode_alu_src0(&src0, RegFile::UGPR, false);
         let form = match &src2 {
             ALUSrc::None | ALUSrc::Reg(_) => {
-                self.encode_alu_src2(&src2, RegFile::UGPR, false, true);
+                self.encode_alu_src2(&src2, RegFile::UGPR, false);
                 match &src1 {
                     ALUSrc::None => 1_u8, // form
                     ALUSrc::Reg(reg1) => {
@@ -617,7 +572,7 @@ impl SM70Encoder<'_> {
             ALUSrc::UReg(_) => panic!("UALU never has UReg"),
             ALUSrc::Imm32(imm2) => {
                 self.encode_alu_imm(imm2);
-                self.encode_alu_src2(&src1, RegFile::UGPR, false, true);
+                self.encode_alu_src2(&src1, RegFile::UGPR, false);
                 2_u8 // form
             }
             ALUSrc::CBuf(_) => panic!("UALU does not support cbufs"),
@@ -1112,19 +1067,9 @@ impl SM70Op for OpHFma2 {
         b.copy_alu_src_if_not_reg(src0, gpr, SrcType::F16v2);
         b.copy_alu_src_if_not_reg(src1, gpr, SrcType::F16v2);
         b.copy_alu_src_if_both_not_reg(src1, src2, gpr, SrcType::F16v2);
-
-        if !src1.is_unmodified() {
-            b.copy_alu_src_and_lower_fmod(src1, gpr, SrcType::F16v2);
-        }
-        if !src2.is_unmodified() {
-            b.copy_alu_src_and_lower_fmod(src2, gpr, SrcType::F16v2);
-        }
     }
 
     fn encode(&self, e: &mut SM70Encoder<'_>) {
-        assert!(self.srcs[1].is_unmodified());
-        assert!(self.srcs[2].is_unmodified());
-
         e.encode_fp16_alu(
             0x031,
             Some(&self.dst),
@@ -1361,7 +1306,7 @@ impl SM70Op for OpIAdd3 {
         let [src0, src1, src2] = &mut self.srcs;
         swap_srcs_if_not_reg(src0, src1, gpr);
         swap_srcs_if_not_reg(src2, src1, gpr);
-        if !src0.is_unmodified() && !src1.is_unmodified() {
+        if !src0.src_mod.is_none() && !src1.src_mod.is_none() {
             assert!(self.overflow[0].is_none());
             assert!(self.overflow[1].is_none());
             b.copy_alu_src_and_lower_ineg(src0, gpr, SrcType::I32);
@@ -1376,7 +1321,9 @@ impl SM70Op for OpIAdd3 {
 
     fn encode(&self, e: &mut SM70Encoder<'_>) {
         // Hardware requires at least one of these be unmodified
-        assert!(self.srcs[0].is_unmodified() || self.srcs[1].is_unmodified());
+        assert!(
+            self.srcs[0].src_mod.is_none() || self.srcs[1].src_mod.is_none()
+        );
 
         if self.is_uniform() {
             e.encode_ualu(
@@ -1410,7 +1357,7 @@ impl SM70Op for OpIAdd3X {
         let [src0, src1, src2] = &mut self.srcs;
         swap_srcs_if_not_reg(src0, src1, gpr);
         swap_srcs_if_not_reg(src2, src1, gpr);
-        if !src0.is_unmodified() && !src1.is_unmodified() {
+        if !src0.src_mod.is_none() && !src1.src_mod.is_none() {
             let val = b.alloc_ssa(gpr, 1);
             b.push_op(OpIAdd3X {
                 srcs: [Src::new_zero(), *src0, Src::new_zero()],
@@ -1430,7 +1377,9 @@ impl SM70Op for OpIAdd3X {
 
     fn encode(&self, e: &mut SM70Encoder<'_>) {
         // Hardware requires at least one of these be unmodified
-        assert!(self.srcs[0].is_unmodified() || self.srcs[1].is_unmodified());
+        assert!(
+            self.srcs[0].src_mod.is_none() || self.srcs[1].src_mod.is_none()
+        );
 
         if self.is_uniform() {
             e.encode_ualu(
@@ -2144,8 +2093,8 @@ impl SM70Op for OpShfl {
     }
 
     fn encode(&self, e: &mut SM70Encoder<'_>) {
-        assert!(self.lane.is_unmodified());
-        assert!(self.c.is_unmodified());
+        assert!(self.lane.src_mod.is_none());
+        assert!(self.c.src_mod.is_none());
 
         match &self.lane.src_ref {
             SrcRef::Zero | SrcRef::Reg(_) => match &self.c.src_ref {
@@ -2304,17 +2253,36 @@ impl SM70Encoder<'_> {
 
     fn set_tex_lod_mode(&mut self, range: Range<usize>, lod_mode: TexLodMode) {
         assert!(range.len() == 3);
-        self.set_field(
-            range,
-            match lod_mode {
-                TexLodMode::Auto => 0_u8,
-                TexLodMode::Zero => 1_u8,
-                TexLodMode::Bias => 2_u8,
-                TexLodMode::Lod => 3_u8,
-                TexLodMode::Clamp => 4_u8,
-                TexLodMode::BiasClamp => 5_u8,
-            },
-        );
+        if self.sm >= 100 {
+            self.set_field(
+                range,
+                match lod_mode {
+                    TexLodMode::Auto => 0_u8,
+                    TexLodMode::Bias => 1_u8,
+                    TexLodMode::Clamp => 2_u8,
+                    // ulb => 0x3
+                    // ulc => 0x4
+                    // lb.ulc => 0x5
+                    TexLodMode::BiasClamp => todo!(),
+
+                    TexLodMode::Zero => 0_u8,
+                    TexLodMode::Lod => 1_u8,
+                    // ull => 3
+                },
+            );
+        } else {
+            self.set_field(
+                range,
+                match lod_mode {
+                    TexLodMode::Auto => 0_u8,
+                    TexLodMode::Zero => 1_u8,
+                    TexLodMode::Bias => 2_u8,
+                    TexLodMode::Lod => 3_u8,
+                    TexLodMode::Clamp => 4_u8,
+                    TexLodMode::BiasClamp => 5_u8,
+                },
+            );
+        }
     }
 
     fn set_image_dim(&mut self, range: Range<usize>, dim: ImageDim) {
@@ -2382,12 +2350,18 @@ impl SM70Op for OpTex {
                 panic!("SM70+ doesn't have legacy bound textures");
             }
             TexRef::CBuf(cb) => {
+                assert!(e.sm < 100);
                 e.set_opcode(0xb60);
                 e.set_tex_cb_ref(40..59, cb);
             }
             TexRef::Bindless => {
-                e.set_opcode(0x361);
-                e.set_bit(59, true); // .B
+                if e.sm >= 100 {
+                    e.set_opcode(0xd61);
+                    e.set_bit(91, true);
+                } else {
+                    e.set_opcode(0x361);
+                    e.set_bit(59, true); // .B
+                }
             }
         }
 
@@ -2402,6 +2376,11 @@ impl SM70Op for OpTex {
         e.set_reg_src(24..32, self.srcs[0]);
         e.set_reg_src(32..40, self.srcs[1]);
 
+        if e.sm >= 100 {
+            e.set_field(48..56, 0xff_u8); // ureg
+            e.set_bit(59, self.lod_mode.is_explicit_lod());
+        }
+
         e.set_tex_dim(61..64, self.dim);
         e.set_tex_channel_mask(72..76, self.channel_mask);
         e.set_bit(76, self.offset);
@@ -2424,12 +2403,18 @@ impl SM70Op for OpTld {
                 panic!("SM70+ doesn't have legacy bound textures");
             }
             TexRef::CBuf(cb) => {
+                assert!(e.sm < 100);
                 e.set_opcode(0xb66);
                 e.set_tex_cb_ref(40..59, cb);
             }
             TexRef::Bindless => {
-                e.set_opcode(0x367);
-                e.set_bit(59, true); // .B
+                if e.sm >= 100 {
+                    e.set_opcode(0xd67);
+                    e.set_bit(91, true);
+                } else {
+                    e.set_opcode(0x367);
+                    e.set_bit(59, true); // .B
+                }
             }
         }
 
@@ -2444,17 +2429,18 @@ impl SM70Op for OpTld {
         e.set_reg_src(24..32, self.srcs[0]);
         e.set_reg_src(32..40, self.srcs[1]);
 
+        if e.sm >= 100 {
+            e.set_field(48..56, 0xff_u8); // ureg
+        }
+
         e.set_tex_dim(61..64, self.dim);
         e.set_tex_channel_mask(72..76, self.channel_mask);
         e.set_bit(76, self.offset);
         // bit 77: .CL
         e.set_bit(78, self.is_ms);
         // bits 79..81: .F16
-        assert!(
-            self.lod_mode == TexLodMode::Zero
-                || self.lod_mode == TexLodMode::Lod
-        );
         e.set_eviction_priority(&self.mem_eviction_priority);
+        assert!(self.lod_mode.is_explicit_lod());
         e.set_tex_lod_mode(87..90, self.lod_mode);
         e.set_bit(90, self.nodep);
     }
@@ -2471,12 +2457,18 @@ impl SM70Op for OpTld4 {
                 panic!("SM70+ doesn't have legacy bound textures");
             }
             TexRef::CBuf(cb) => {
+                assert!(e.sm < 100);
                 e.set_opcode(0xb63);
                 e.set_tex_cb_ref(40..59, cb);
             }
             TexRef::Bindless => {
-                e.set_opcode(0x364);
-                e.set_bit(59, true); // .B
+                if e.sm >= 100 {
+                    e.set_opcode(0xd64);
+                    e.set_bit(91, true);
+                } else {
+                    e.set_opcode(0x364);
+                    e.set_bit(59, true); // .B
+                }
             }
         }
 
@@ -2491,6 +2483,10 @@ impl SM70Op for OpTld4 {
         e.set_reg_src(24..32, self.srcs[0]);
         e.set_reg_src(32..40, self.srcs[1]);
 
+        if e.sm >= 100 {
+            e.set_field(48..56, 0xff_u8); // ureg
+        }
+
         e.set_tex_dim(61..64, self.dim);
         e.set_tex_channel_mask(72..76, self.channel_mask);
         e.set_field(
@@ -2520,6 +2516,7 @@ impl SM70Op for OpTmml {
                 panic!("SM70+ doesn't have legacy bound textures");
             }
             TexRef::CBuf(cb) => {
+                assert!(e.sm < 100);
                 e.set_opcode(0xb69);
                 e.set_tex_cb_ref(40..59, cb);
             }
@@ -2557,12 +2554,18 @@ impl SM70Op for OpTxd {
                 panic!("SM70+ doesn't have legacy bound textures");
             }
             TexRef::CBuf(cb) => {
+                assert!(e.sm < 100);
                 e.set_opcode(0xb6c);
                 e.set_tex_cb_ref(40..59, cb);
             }
             TexRef::Bindless => {
-                e.set_opcode(0x36d);
-                e.set_bit(59, true); // .B
+                if e.sm >= 100 {
+                    e.set_opcode(0xd6d);
+                    e.set_bit(91, true);
+                } else {
+                    e.set_opcode(0x36d);
+                    e.set_bit(59, true); // .B
+                }
             }
         }
 
@@ -2577,6 +2580,10 @@ impl SM70Op for OpTxd {
         e.set_reg_src(24..32, self.srcs[0]);
         e.set_reg_src(32..40, self.srcs[1]);
 
+        if e.sm >= 100 {
+            e.set_field(48..56, 0xff_u8); // ureg
+        }
+
         e.set_tex_dim(61..64, self.dim);
         e.set_tex_channel_mask(72..76, self.channel_mask);
         e.set_bit(76, self.offset);
@@ -2597,6 +2604,7 @@ impl SM70Op for OpTxq {
                 panic!("SM70+ doesn't have legacy bound textures");
             }
             TexRef::CBuf(cb) => {
+                assert!(e.sm < 100);
                 e.set_opcode(0xb6f);
                 e.set_tex_cb_ref(40..59, cb);
             }
@@ -2794,7 +2802,7 @@ impl SM70Op for OpSuAtom {
         e.set_eviction_priority(&self.mem_eviction_priority);
 
         e.set_bit(72, false); // .BA
-        e.set_atom_type(73..76, self.atom_type);
+        e.set_atom_type(self.atom_type);
     }
 }
 
@@ -2963,20 +2971,47 @@ impl SM70Encoder<'_> {
         );
     }
 
-    fn set_atom_type(&mut self, range: Range<usize>, atom_type: AtomType) {
-        assert!(range.len() == 3);
-        self.set_field(
-            range,
-            match atom_type {
-                AtomType::U32 => 0_u8,
-                AtomType::I32 => 1_u8,
-                AtomType::U64 => 2_u8,
-                AtomType::F32 => 3_u8,
-                AtomType::F16x2 => 4_u8,
-                AtomType::I64 => 5_u8,
-                AtomType::F64 => 6_u8,
-            },
-        );
+    fn set_atom_type(&mut self, atom_type: AtomType) {
+        if self.sm >= 90 {
+            // Float/int is differentiated by opcode
+            self.set_field(
+                73..77,
+                match atom_type {
+                    AtomType::F16x2 => 0_u8,
+                    // f16x4 => 1
+                    // f16x8 => 2
+                    // bf16x2 => 3
+                    // bf16x4 => 4
+                    // bf16x8 => 5
+                    AtomType::F32 => 9_u8, // .ftz
+                    // f32x2.ftz => 10
+                    // f32x4.ftz => 11
+                    // f32x1 => 12
+                    // f32x2 => 13
+                    // f32x4 => 14
+                    AtomType::F64 => 15_u8,
+
+                    AtomType::U32 => 0,
+                    AtomType::I32 => 1,
+                    AtomType::U64 => 2,
+                    AtomType::I64 => 3,
+                    // u128 => 4,
+                },
+            );
+        } else {
+            self.set_field(
+                73..76,
+                match atom_type {
+                    AtomType::U32 => 0_u8,
+                    AtomType::I32 => 1_u8,
+                    AtomType::U64 => 2_u8,
+                    AtomType::F32 => 3_u8,
+                    AtomType::F16x2 => 4_u8,
+                    AtomType::I64 => 5_u8,
+                    AtomType::F64 => 6_u8,
+                },
+            );
+        }
     }
 }
 
@@ -2989,7 +3024,11 @@ impl SM70Op for OpAtom {
         match self.mem_space {
             MemSpace::Global(_) => {
                 if self.dst.is_none() {
-                    e.set_opcode(0x98e);
+                    if e.sm >= 90 && self.atom_type.is_float() {
+                        e.set_opcode(0x9a6);
+                    } else {
+                        e.set_opcode(0x98e);
+                    }
 
                     e.set_reg_src(32..40, self.data);
                     e.set_atom_op(87..90, self.atom_op);
@@ -3000,7 +3039,11 @@ impl SM70Op for OpAtom {
                     e.set_reg_src(32..40, self.cmpr);
                     e.set_reg_src(64..72, self.data);
                 } else {
-                    e.set_opcode(0x3a8);
+                    if e.sm >= 90 && self.atom_type.is_float() {
+                        e.set_opcode(0x3a3);
+                    } else {
+                        e.set_opcode(0x3a8);
+                    }
 
                     e.set_reg_src(32..40, self.data);
                     e.set_atom_op(87..91, self.atom_op);
@@ -3036,6 +3079,10 @@ impl SM70Op for OpAtom {
                             || self.atom_op == AtomOp::Exch,
                         "64-bit Shared atomics only support CmpExch or Exch"
                     );
+                    assert!(
+                        !self.atom_type.is_float(),
+                        "Shared atomics don't support float"
+                    );
                     e.set_atom_op(87..91, self.atom_op);
                 }
 
@@ -3049,7 +3096,7 @@ impl SM70Op for OpAtom {
         e.set_dst(self.dst);
         e.set_reg_src(24..32, self.addr);
         e.set_field(40..64, self.addr_offset);
-        e.set_atom_type(73..76, self.atom_type);
+        e.set_atom_type(self.atom_type);
     }
 }
 
diff --git a/src/nouveau/compiler/nak/spill_values.rs b/src/nouveau/compiler/nak/spill_values.rs
index b425e909267..b75470f18e3 100644
--- a/src/nouveau/compiler/nak/spill_values.rs
+++ b/src/nouveau/compiler/nak/spill_values.rs
@@ -59,7 +59,7 @@ impl PhiSrcMap {
     }
 
     fn add_phi_src(&mut self, phi_idx: u32, src: Src) {
-        debug_assert!(src.is_unmodified());
+        debug_assert!(src.src_mod.is_none());
         let vec = src.src_ref.as_ssa().expect("Not an SSA source");
         debug_assert!(vec.comps() == 1);
         self.phi_src.insert(phi_idx, vec[0]);
@@ -735,7 +735,7 @@ fn spill_values<S: Spill>(
                         debug_assert!(dst_vec.comps() == 1);
                         let dst_ssa = &dst_vec[0];
 
-                        debug_assert!(src.is_unmodified());
+                        debug_assert!(src.src_mod.is_none());
                         let Some(src_vec) = src.src_ref.as_ssa() else {
                             continue;
                         };
@@ -980,7 +980,7 @@ fn spill_values<S: Spill>(
 
         if let Some(phi) = pb.phi_srcs_mut() {
             for (idx, src) in phi.srcs.iter_mut() {
-                debug_assert!(src.is_unmodified());
+                debug_assert!(src.src_mod.is_none());
                 let vec = src.src_ref.as_ssa().unwrap();
                 debug_assert!(vec.comps() == 1);
                 let ssa = &vec[0];
diff --git a/src/nouveau/compiler/nak/to_cssa.rs b/src/nouveau/compiler/nak/to_cssa.rs
index 81ba68cd4b7..a8a02875287 100644
--- a/src/nouveau/compiler/nak/to_cssa.rs
+++ b/src/nouveau/compiler/nak/to_cssa.rs
@@ -352,7 +352,7 @@ impl Function {
                         for (idx, src) in phi.srcs.iter_mut() {
                             let (ps, file) = cg.phi_set_file(idx);
 
-                            debug_assert!(src.is_unmodified());
+                            debug_assert!(src.src_mod.is_none());
                             if let SrcRef::SSA(vec) = &src.src_ref {
                                 debug_assert!(vec.comps() == 1);
                                 if vec[0].file() == file {
diff --git a/src/nouveau/compiler/nak_nir_lower_fs_inputs.c b/src/nouveau/compiler/nak_nir_lower_fs_inputs.c
index 3e7445cb25e..bdd32be9a17 100644
--- a/src/nouveau/compiler/nak_nir_lower_fs_inputs.c
+++ b/src/nouveau/compiler/nak_nir_lower_fs_inputs.c
@@ -77,7 +77,7 @@ interp_fs_input(nir_builder *b, unsigned num_components, uint32_t addr,
             comps[c] = nir_fmul(b, comps[c], inv_w);
       }
       return nir_vec(b, comps, num_components);
-   } else if (nak->sm >= 50) {
+   } else if (nak->sm >= 20) {
       struct nak_nir_ipa_flags flags = {
          .interp_mode = interp_mode,
          .interp_freq = NAK_INTERP_FREQ_PASS,
@@ -100,7 +100,7 @@ interp_fs_input(nir_builder *b, unsigned num_components, uint32_t addr,
       }
       return nir_vec(b, comps, num_components);
    } else {
-      unreachable("Figure out input interpolation on Kepler");
+      unreachable("Unsupported shader model");
    }
 }
 
diff --git a/src/nouveau/compiler/nak_nir_lower_tex.c b/src/nouveau/compiler/nak_nir_lower_tex.c
index da8b368392d..3e1d60a1820 100644
--- a/src/nouveau/compiler/nak_nir_lower_tex.c
+++ b/src/nouveau/compiler/nak_nir_lower_tex.c
@@ -9,6 +9,12 @@
 
 #include "util/u_math.h"
 
+static bool
+has_cbuf_tex(const struct nak_compiler *nak) {
+   /* TODO: Figure out how bound textures work on blackwell */
+   return nak->sm >= 70 && nak->sm < 100;
+}
+
 static bool
 tex_handle_as_cbuf(nir_def *tex_h, uint32_t *cbuf_out)
 {
@@ -73,7 +79,7 @@ lower_tex(nir_builder *b, nir_tex_instr *tex, const struct nak_compiler *nak)
    }
 
    enum nak_nir_tex_ref_type ref_type = NAK_NIR_TEX_REF_TYPE_BINDLESS;
-   if (nak->sm >= 70 && tex_handle_as_cbuf(tex_h, &tex->texture_index)) {
+   if (has_cbuf_tex(nak) && tex_handle_as_cbuf(tex_h, &tex->texture_index)) {
       ref_type = NAK_NIR_TEX_REF_TYPE_CBUF;
       tex_h = NULL;
    }
@@ -237,7 +243,7 @@ lower_tex(nir_builder *b, nir_tex_instr *tex, const struct nak_compiler *nak)
          tex->src[1].src_type = nir_tex_src_backend2;
          nir_src_rewrite(&tex->src[1].src, nir_vec(b, src1, src1_comps));
       }
-   } else if (nak->sm >= 32) {
+   } else if (nak->sm >= 30) {
       nir_def *src[8] = { NULL, };
       unsigned src_comps = 0;
 
@@ -362,7 +368,7 @@ lower_txq(nir_builder *b, nir_tex_instr *tex, const struct nak_compiler *nak)
    }
 
    enum nak_nir_tex_ref_type ref_type = NAK_NIR_TEX_REF_TYPE_BINDLESS;
-   if (nak->sm >= 70 && tex_handle_as_cbuf(tex_h, &tex->texture_index)) {
+   if (has_cbuf_tex(nak) && tex_handle_as_cbuf(tex_h, &tex->texture_index)) {
       ref_type = NAK_NIR_TEX_REF_TYPE_CBUF;
       tex_h = NULL;
    }
@@ -654,7 +660,7 @@ lower_image_txq(nir_builder *b, nir_intrinsic_instr *intrin,
 
    uint32_t texture_index = 0;
    enum nak_nir_tex_ref_type ref_type = NAK_NIR_TEX_REF_TYPE_BINDLESS;
-   if (nak->sm >= 70 && tex_handle_as_cbuf(img_h, &texture_index)) {
+   if (has_cbuf_tex(nak) && tex_handle_as_cbuf(img_h, &texture_index)) {
       ref_type = NAK_NIR_TEX_REF_TYPE_CBUF;
       img_h = NULL;
    }
diff --git a/src/nouveau/vulkan/nvk_cmd_meta.c b/src/nouveau/vulkan/nvk_cmd_meta.c
index be60f0068a1..f834c627c09 100644
--- a/src/nouveau/vulkan/nvk_cmd_meta.c
+++ b/src/nouveau/vulkan/nvk_cmd_meta.c
@@ -121,26 +121,6 @@ nvk_meta_begin(struct nvk_cmd_buffer *cmd,
                                        save->push);
 }
 
-static void
-nvk_meta_init_render(struct nvk_cmd_buffer *cmd,
-                     struct vk_meta_rendering_info *info)
-{
-   const struct nvk_rendering_state *render = &cmd->state.gfx.render;
-
-   *info = (struct vk_meta_rendering_info) {
-      .view_mask = render->view_mask,
-      .color_attachment_count = render->color_att_count,
-      .depth_attachment_format = render->depth_att.vk_format,
-      .stencil_attachment_format = render->stencil_att.vk_format,
-   };
-   for (uint32_t a = 0; a < render->color_att_count; a++) {
-      info->color_attachment_formats[a] = render->color_att[a].vk_format;
-      info->color_attachment_write_masks[a] =
-         VK_COLOR_COMPONENT_R_BIT | VK_COLOR_COMPONENT_G_BIT |
-         VK_COLOR_COMPONENT_B_BIT | VK_COLOR_COMPONENT_A_BIT;
-   }
-}
-
 static void
 nvk_meta_end(struct nvk_cmd_buffer *cmd,
              struct nvk_meta_save *save)
diff --git a/src/nouveau/vulkan/nvk_shader.c b/src/nouveau/vulkan/nvk_shader.c
index d38f4005ec4..c998aabfe75 100644
--- a/src/nouveau/vulkan/nvk_shader.c
+++ b/src/nouveau/vulkan/nvk_shader.c
@@ -458,11 +458,6 @@ nvk_lower_nir(struct nvk_device *dev, nir_shader *nir,
       NIR_PASS(_, nir, nir_lower_non_uniform_access, &opts);
    }
 
-   /* TODO: Kepler image lowering requires image params to be loaded from the
-    * descriptor set which we don't currently support.
-    */
-   assert(pdev->info.cls_eng3d >= MAXWELL_A || !nir_has_image_var(nir));
-
    struct nvk_cbuf_map *cbuf_map = NULL;
    if (use_nak(pdev, nir->info.stage) &&
        !(pdev->debug_flags & NVK_DEBUG_NO_CBUF)) {
@@ -499,10 +494,8 @@ nvk_lower_nir(struct nvk_device *dev, nir_shader *nir,
    NIR_PASS(_, nir, nir_shader_intrinsics_pass,
             lower_load_intrinsic, nir_metadata_none, NULL);
 
-   if (!nir->info.shared_memory_explicit_layout) {
-      NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
-               nir_var_mem_shared, shared_var_info);
-   }
+   NIR_PASS(_, nir, nir_lower_vars_to_explicit_types,
+            nir_var_mem_shared, shared_var_info);
    NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_shared,
             nir_address_format_32bit_offset);
 
@@ -968,12 +961,22 @@ nvk_compile_shader(struct nvk_device *dev,
                    const VkAllocationCallbacks* pAllocator,
                    struct vk_shader **shader_out)
 {
+   const struct nvk_physical_device *pdev = nvk_device_physical(dev);
    struct nvk_shader *shader;
    VkResult result;
 
    /* We consume the NIR, regardless of success or failure */
    nir_shader *nir = info->nir;
 
+   /* TODO: Kepler image lowering requires image params to be loaded from the
+    * descriptor set, which we don't currently support.
+    */
+   if (pdev->info.cls_eng3d < MAXWELL_A && nir_has_image_var(nir)) {
+      ralloc_free(nir);
+      return vk_errorf(dev, VK_ERROR_UNKNOWN,
+                       "Storage images are not supported on Kepler");
+   }
+
    shader = vk_shader_zalloc(&dev->vk, &nvk_shader_ops, info->stage,
                              pAllocator, sizeof(*shader));
    if (shader == NULL) {
diff --git a/src/panfrost/ci/gitlab-ci-inc.yml b/src/panfrost/ci/gitlab-ci-inc.yml
index 05a0c1571c4..841f79573e4 100644
--- a/src/panfrost/ci/gitlab-ci-inc.yml
+++ b/src/panfrost/ci/gitlab-ci-inc.yml
@@ -28,7 +28,7 @@
       when: on_success
 
 .panfrost-midgard-manual-rules:
-  stage: arm-postmerge
+  stage: arm-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -59,7 +59,7 @@
       when: on_success
 
 .panfrost-bifrost-gl-manual-rules:
-  stage: arm-postmerge
+  stage: arm-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -92,7 +92,7 @@
       when: on_success
 
 .panfrost-vk-manual-rules:
-  stage: arm-postmerge
+  stage: arm-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
@@ -125,7 +125,7 @@
       when: on_success
 
 .panfrost-valhall-gl-manual-rules:
-  stage: arm-postmerge
+  stage: arm-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
diff --git a/src/panfrost/ci/gitlab-ci.yml b/src/panfrost/ci/gitlab-ci.yml
index 10bc590da5d..13627a978e8 100644
--- a/src/panfrost/ci/gitlab-ci.yml
+++ b/src/panfrost/ci/gitlab-ci.yml
@@ -3,7 +3,7 @@ include:
 
 panfrost-t720-gles2:arm64:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-midgard-rules
     - .panfrost-test
     - .lava-sun50i-h6-pine-h64:arm64
@@ -12,14 +12,14 @@ panfrost-t720-gles2:arm64:
 # Keep the second t760 job manual.
 panfrost-t760-gles:arm32:
   extends:
-    - .lava-test-deqp:arm32
+    - .lava-arm32-test-gl
     - .panfrost-midgard-manual-rules
     - .panfrost-test
     - .lava-rk3288-veyron-jaq:arm32
 
 panfrost-t760-traces:arm32:
   extends:
-    - .lava-piglit-traces:arm32
+    - .lava-arm32-piglit-traces
     - .panfrost-midgard-manual-rules
     - .panfrost-test
     - .lava-rk3288-veyron-jaq:arm32
@@ -27,9 +27,10 @@ panfrost-t760-traces:arm32:
 
 panfrost-t860-cl:arm64:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-midgard-manual-rules
     - .panfrost-test
+    - .test-piglit
     - .lava-rk3399-gru-kevin:arm64
   rules:
     - !reference [.panfrost-midgard-manual-rules, rules]
@@ -41,7 +42,7 @@ panfrost-t860-cl:arm64:
 panfrost-t860-gl:arm64:
   parallel: 3
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-midgard-rules
     - .panfrost-test
     - .lava-rk3399-gru-kevin:arm64
@@ -51,7 +52,7 @@ panfrost-t860-gl:arm64:
 
 panfrost-t860-egl:arm64:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-midgard-rules
     - .panfrost-test
     - .lava-rk3399-gru-kevin:arm64
@@ -61,7 +62,7 @@ panfrost-t860-egl:arm64:
 
 panfrost-t860-traces:arm64:
   extends:
-    - .lava-piglit-traces:arm64
+    - .lava-arm64-piglit-traces
     - .panfrost-midgard-manual-rules
     - .panfrost-test
     - .lava-rk3399-gru-kevin:arm64
@@ -70,7 +71,7 @@ panfrost-t860-traces:arm64:
 panfrost-g52-gl:arm64:
   parallel: 4
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-bifrost-gl-rules
     - .panfrost-test
     - .lava-meson-g12b-a311d-khadas-vim3:arm64
@@ -82,7 +83,7 @@ panfrost-g52-gl:arm64:
 panfrost-g52-vk:arm64:
   parallel: 7
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-vk
     - .panfrost-test
     - .lava-mt8186-corsola-steelix-sku131072:arm64
     - .panfrost-vk-rules
@@ -108,9 +109,10 @@ panfrost-g52-vk-full:arm64:
 
 panfrost-g52-piglit:arm64:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-bifrost-gl-manual-rules
     - .panfrost-test
+    - .test-piglit
     - .lava-meson-g12b-a311d-khadas-vim3:arm64
   variables:
     HWCI_START_WESTON: 1
@@ -119,7 +121,7 @@ panfrost-g52-piglit:arm64:
 panfrost-g72-gl:arm64:
   parallel: 3
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-bifrost-gl-rules
     - .panfrost-test
     - .lava-mt8183-kukui-jacuzzi-juniper-sku16:arm64
@@ -128,7 +130,7 @@ panfrost-g72-gl:arm64:
 
 panfrost-g57-gl:arm64:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-bifrost-gl-rules
     - .panfrost-test
     - .lava-mt8195-cherry-tomato-r2:arm64
@@ -140,9 +142,10 @@ panfrost-g57-gl:arm64:
 
 panfrost-g57-piglit:arm64:
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-bifrost-gl-rules
     - .panfrost-test
+    - .test-piglit
     - .lava-mt8195-cherry-tomato-r2:arm64
   variables:
     HWCI_START_WESTON: 1
@@ -154,7 +157,7 @@ panfrost-g57-piglit:arm64:
 panfrost-g610-gl:arm64:
   parallel: 2
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-gl
     - .panfrost-valhall-gl-rules
     - .panfrost-test
     - .lava-rk3588-rock-5b:arm64
@@ -167,6 +170,7 @@ panfrost-g610-gl:arm64:
 .panfrost-g610-piglit:arm64:
   extends:
     - panfrost-g610-gl:arm64
+    - .test-piglit
     - .panfrost-valhall-gl-manual-rules
   variables:
     DEQP_SUITE: panfrost-g610-piglit
@@ -175,7 +179,7 @@ panfrost-g610-gl:arm64:
 panfrost-g610-vk:arm64:
   parallel: 5
   extends:
-    - .lava-test-deqp:arm64
+    - .lava-arm64-test-vk
     - .panfrost-test
     - .lava-rk3588-rock-5b:arm64
     - .panfrost-vk-rules
diff --git a/src/panfrost/ci/panfrost-g57-fails.txt b/src/panfrost/ci/panfrost-g57-fails.txt
index e2b5e98de42..c262fca7cc6 100644
--- a/src/panfrost/ci/panfrost-g57-fails.txt
+++ b/src/panfrost/ci/panfrost-g57-fails.txt
@@ -299,7 +299,7 @@ spec@ext_clear_texture@ext_clear_texture-base-formats,Fail
 spec@ext_disjoint_timer_query@simple,Fail
 spec@ext_image_dma_buf_import@ext_image_dma_buf_import-refcount-multithread,Crash
 spec@ext_timer_query@time-elapsed,Fail
-spec@ext_transform_feedback@max-varyings,Crash
+spec@ext_transform_feedback@max-varyings,Fail
 spec@ext_transform_feedback@max-varyings@max-varying-single-dimension-array,Fail
 spec@glsl-1.30@execution@tex-miplevel-selection texturegrad 1d,Fail
 spec@glsl-1.30@execution@tex-miplevel-selection texturegrad 1darray,Fail
diff --git a/src/panfrost/ci/panfrost-g610-fails.txt b/src/panfrost/ci/panfrost-g610-fails.txt
index 40db5c7b0b7..85018e02293 100644
--- a/src/panfrost/ci/panfrost-g610-fails.txt
+++ b/src/panfrost/ci/panfrost-g610-fails.txt
@@ -1,9 +1,6 @@
 # uprev Piglit in Mesa
 spec@ext_image_dma_buf_import@ext_image_dma_buf_import-refcount-multithread,Crash
 
-# CTS bug, tries to use vkCmdSetPatchControlPointsEXT when we don't have that
-dEQP-VK.pipeline.fast_linked_library.misc.interpolate_at_sample_no_sample_shading,Crash
-
 dEQP-VK.renderpass.multiple_subpasses_multiple_command_buffers.test,Fail
 
 dEQP-VK.glsl.loops.special.do_while_dynamic_iterations.dowhile_trap_vertex,Crash
diff --git a/src/panfrost/ci/panfrost-g720-fails.txt b/src/panfrost/ci/panfrost-g720-fails.txt
index b53fd5d6293..e2ddf9a46d9 100644
--- a/src/panfrost/ci/panfrost-g720-fails.txt
+++ b/src/panfrost/ci/panfrost-g720-fails.txt
@@ -1,9 +1,6 @@
 # uprev Piglit in Mesa
 spec@ext_image_dma_buf_import@ext_image_dma_buf_import-refcount-multithread,Crash
 
-# CTS bug, tries to use vkCmdSetPatchControlPointsEXT when we don't have that
-dEQP-VK.pipeline.fast_linked_library.misc.interpolate_at_sample_no_sample_shading,Crash
-
 dEQP-VK.glsl.loops.special.do_while_dynamic_iterations.dowhile_trap_vertex,Crash
 
 # Seems to be a precision issues because of floor fp16 being dropped since v11 (and the conversion done as a result)
diff --git a/src/panfrost/ci/panfrost-g725-fails.txt b/src/panfrost/ci/panfrost-g725-fails.txt
index 1f197a9a466..82d00f8aeee 100644
--- a/src/panfrost/ci/panfrost-g725-fails.txt
+++ b/src/panfrost/ci/panfrost-g725-fails.txt
@@ -1,9 +1,6 @@
 # uprev Piglit in Mesa
 spec@ext_image_dma_buf_import@ext_image_dma_buf_import-refcount-multithread,Crash
 
-# CTS bug, tries to use vkCmdSetPatchControlPointsEXT when we don't have that
-dEQP-VK.pipeline.fast_linked_library.misc.interpolate_at_sample_no_sample_shading,Crash
-
 # Seems to be a precision issues because of floor fp16 being dropped since v11 (and the conversion done as a result)
 dEQP-GLES3.functional.shaders.builtin_functions.common.fract.vec2_lowp_vertex,Fail
 dEQP-GLES31.functional.shaders.builtin_functions.common.fract.vec2_lowp_compute,Fail
diff --git a/src/panfrost/compiler/bifrost_compile.c b/src/panfrost/compiler/bifrost_compile.c
index 3e3bcce2527..794315d858e 100644
--- a/src/panfrost/compiler/bifrost_compile.c
+++ b/src/panfrost/compiler/bifrost_compile.c
@@ -1881,33 +1881,49 @@ static void
 bi_emit_derivative(bi_builder *b, bi_index dst, nir_intrinsic_instr *instr,
                    unsigned axis, bool coarse)
 {
+   assert(axis == 1 || axis == 2);
+
    bi_index left, right;
    bi_index s0 = bi_src_index(&instr->src[0]);
+
    unsigned sz = instr->def.bit_size;
 
    /* If all uses are fabs, the sign of the derivative doesn't matter. This is
     * inherently based on fine derivatives so we can't do it for coarse.
     */
-   if (nir_def_all_uses_ignore_sign_bit(&instr->def) && !coarse) {
+   if (coarse) {
+      left = bi_clper(b, s0, bi_imm_u8(0), BI_LANE_OP_NONE);
+      right = bi_clper(b, s0, bi_imm_u8(axis), BI_LANE_OP_NONE);
+   } else {
       left = s0;
       right = bi_clper(b, s0, bi_imm_u8(axis), BI_LANE_OP_XOR);
-   } else {
-      bi_index lane1, lane2;
-      if (coarse) {
-         lane1 = bi_imm_u32(0);
-         lane2 = bi_imm_u32(axis);
-      } else {
-         lane1 = bi_lshift_and_i32(b, bi_fau(BIR_FAU_LANE_ID, false),
-                                   bi_imm_u32(0x3 & ~axis), bi_imm_u8(0));
+   }
 
-         lane2 = bi_iadd_u32(b, lane1, bi_imm_u32(axis), false);
-      }
+   if (!coarse && !nir_def_all_uses_ignore_sign_bit(&instr->def)) {
+      /* If the user cares about the sign, we need to take into account the fact
+       * left/right (or top/bottom) might be inverted. Instead of using a couple
+       * CSEL, we just invert the sign bit with
+       *
+       *    sign_bit = XOR(sign_bit, axis_bit(lane_id)).
+       */
+      bi_index res = bi_fadd(b, sz, right, bi_neg(left));
+      bi_index lane = bi_fau(BIR_FAU_LANE_ID, false);
+      bi_index lane_shift = bi_imm_u8(sz - ffs(axis));
 
-      left = bi_clper(b, s0, bi_byte(lane1, 0), BI_LANE_OP_NONE);
-      right = bi_clper(b, s0, bi_byte(lane2, 0), BI_LANE_OP_NONE);
-   }
+      /* Clear the low bit before the shift if this is the Y-axis we want.
+       * We skip it on the X-axis, because the lshift-by-31 will get us a
+       * clean mask. */
+      if (axis == 2)
+         lane = bi_lshift_and_i32(b, lane, bi_imm_u32(2), bi_imm_u8(0));
 
-   bi_fadd_to(b, sz, dst, right, bi_neg(left));
+      if (sz == 16)
+         lane = bi_half(lane, false);
+
+      /* And here comes the final XOR on the sign bit. */
+      bi_lshift_xor_to(b, sz, dst, lane, res, lane_shift);
+   } else {
+      bi_fadd_to(b, sz, dst, right, bi_neg(left));
+   }
 }
 
 static enum bi_subgroup
@@ -2118,11 +2134,11 @@ bi_emit_intrinsic(bi_builder *b, nir_intrinsic_instr *instr)
       bi_emit_ld_tile(b, instr);
       break;
 
-   case nir_intrinsic_terminate_if:
+   case nir_intrinsic_demote_if:
       bi_discard_b32(b, bi_src_index(&instr->src[0]));
       break;
 
-   case nir_intrinsic_terminate:
+   case nir_intrinsic_demote:
       bi_discard_f32(b, bi_zero(), bi_zero(), BI_CMPF_EQ);
       break;
 
@@ -5700,6 +5716,18 @@ bifrost_preprocess_nir(nir_shader *nir, unsigned gpu_id)
 {
    MESA_TRACE_FUNC();
 
+   /* The DISCARD instruction just flags the thread as discarded, but the
+    * actual termination only happens when all threads in the quad are
+    * discarded, or when an instruction with a .discard flow is
+    * encountered (Valhall) or when a clause with a .terminate_discarded_thread
+    * is reached (Bifrost).
+    * We could do without nir_lower_terminate_to_demote(), but this allows
+    * for extra dead-code elimination when code sections are detected as
+    * being unused after a termination is crossed.
+    */
+   if (nir->info.stage == MESA_SHADER_FRAGMENT)
+      NIR_PASS(_, nir, nir_lower_terminate_to_demote);
+
    /* Ensure that halt are translated to returns and get ride of them */
    NIR_PASS(_, nir, nir_shader_instructions_pass, bi_lower_halt_to_return,
             nir_metadata_all, NULL);
@@ -5793,7 +5821,11 @@ bifrost_preprocess_nir(nir_shader *nir, unsigned gpu_id)
    NIR_PASS(_, nir, nir_lower_ssbo, &ssbo_opts);
 
    NIR_PASS(_, nir, pan_lower_sample_pos);
-   NIR_PASS(_, nir, pan_lower_helper_invocation);
+
+   if (nir->info.stage == MESA_SHADER_FRAGMENT) {
+      NIR_PASS(_, nir, nir_lower_is_helper_invocation);
+      NIR_PASS(_, nir, pan_lower_helper_invocation);
+   }
 
    /*
     * Lower subgroups ops before lowering int64: nir_lower_int64 doesn't know
diff --git a/src/panfrost/compiler/bifrost_compile.h b/src/panfrost/compiler/bifrost_compile.h
index beebf91e425..bbc2659ab2f 100644
--- a/src/panfrost/compiler/bifrost_compile.h
+++ b/src/panfrost/compiler/bifrost_compile.h
@@ -147,6 +147,7 @@ void bifrost_compile_shader_nir(nir_shader *nir,
       .scalarize_ddx = true,                                                   \
       .support_indirect_inputs = (uint8_t)BITFIELD_MASK(PIPE_SHADER_TYPES),    \
       .lower_hadd = arch >= 11,                                                \
+      .discard_is_demote = true,                                               \
    };
 
 DEFINE_OPTIONS(6);
diff --git a/src/panfrost/lib/genxml/decode_csf.c b/src/panfrost/lib/genxml/decode_csf.c
index c42edcc6054..185382d3d64 100644
--- a/src/panfrost/lib/genxml/decode_csf.c
+++ b/src/panfrost/lib/genxml/decode_csf.c
@@ -1669,7 +1669,7 @@ GENX(pandecode_interpret_cs)(struct pandecode_context *ctx, uint64_t queue,
 
    /* v10 has 96 registers. v12+ have 128. */
    struct queue_ctx qctx = {
-      .nr_regs = PAN_ARCH >= 12 ? 128 : 96,
+      .nr_regs = PAN_ARCH >= 12 ? 96 : 128,
       .regs = regs,
       .ip = cs,
       .end = cs + (size / 8),
@@ -2484,7 +2484,7 @@ GENX(pandecode_cs_trace)(struct pandecode_context *ctx, uint64_t trace,
 
       /* v10 has 96 registers. v12+ have 128. */
       struct queue_ctx qctx = {
-         .nr_regs = PAN_ARCH >= 12 ? 128 : 96,
+         .nr_regs = PAN_ARCH >= 12 ? 96 : 128,
          .regs = regs,
          .ip = instr,
          .end = instr + 1,
diff --git a/src/panfrost/lib/pan_props.h b/src/panfrost/lib/pan_props.h
index 9c18c255c09..c09a57fda0b 100644
--- a/src/panfrost/lib/pan_props.h
+++ b/src/panfrost/lib/pan_props.h
@@ -138,8 +138,8 @@ pan_arch(unsigned gpu_id)
 static inline unsigned
 panfrost_max_effective_tile_size(unsigned arch)
 {
-   /* XXX: On v12+, the max effective tile size is 64x64 but it is possible to
-    * overrun the internal depth buffer for now */
+   if (arch >= 12)
+      return 64 * 64;
 
    if (arch >= 10)
       return 32 * 32;
diff --git a/src/panfrost/lib/pan_shader.c b/src/panfrost/lib/pan_shader.c
index 24801086bdb..c8ad3881ccd 100644
--- a/src/panfrost/lib/pan_shader.c
+++ b/src/panfrost/lib/pan_shader.c
@@ -146,6 +146,10 @@ GENX(pan_shader_compile)(nir_shader *s, struct panfrost_compile_inputs *inputs,
 #if PAN_ARCH >= 9
       info->varyings.output_count =
          util_last_bit(s->info.outputs_written >> VARYING_SLOT_VAR0);
+
+      /* Store the mask of special varyings, in case we need to emit ADs later. */
+      info->varyings.fixed_varyings =
+         panfrost_get_fixed_varying_mask(s->info.outputs_written);
 #endif
       break;
    case MESA_SHADER_FRAGMENT:
@@ -195,6 +199,10 @@ GENX(pan_shader_compile)(nir_shader *s, struct panfrost_compile_inputs *inputs,
 #if PAN_ARCH >= 9
       info->varyings.input_count =
          util_last_bit(s->info.inputs_read >> VARYING_SLOT_VAR0);
+
+      /* Store the mask of special varyings, in case we need to emit ADs later. */
+      info->varyings.fixed_varyings =
+         panfrost_get_fixed_varying_mask(s->info.inputs_read);
 #endif
       break;
    default:
diff --git a/src/panfrost/lib/pan_shader.h b/src/panfrost/lib/pan_shader.h
index 4c58d264172..436aa099be0 100644
--- a/src/panfrost/lib/pan_shader.h
+++ b/src/panfrost/lib/pan_shader.h
@@ -37,6 +37,13 @@
 void bifrost_preprocess_nir(nir_shader *nir, unsigned gpu_id);
 void midgard_preprocess_nir(nir_shader *nir, unsigned gpu_id);
 
+static unsigned
+panfrost_get_fixed_varying_mask(unsigned varyings_used)
+{
+   return (varyings_used & BITFIELD_MASK(VARYING_SLOT_VAR0)) &
+      ~VARYING_BIT_POS & ~VARYING_BIT_PSIZ;
+}
+
 static inline void
 pan_shader_preprocess(nir_shader *nir, unsigned gpu_id)
 {
diff --git a/src/panfrost/meson.build b/src/panfrost/meson.build
index a8e00d2b82a..5a160067d6e 100644
--- a/src/panfrost/meson.build
+++ b/src/panfrost/meson.build
@@ -15,12 +15,9 @@ subdir('util')
 subdir('midgard')
 subdir('compiler')
 
-if with_gallium_panfrost or with_panfrost_vk or with_tools.contains('panfrost')
+if with_gallium_panfrost or with_panfrost_vk
    subdir('lib')
    subdir('clc')
-endif
-
-if with_gallium_panfrost or with_panfrost_vk
    subdir('libpan')
    subdir('perf')
 endif
diff --git a/src/panfrost/util/pan_ir.h b/src/panfrost/util/pan_ir.h
index b23748fa708..d041386e971 100644
--- a/src/panfrost/util/pan_ir.h
+++ b/src/panfrost/util/pan_ir.h
@@ -296,6 +296,9 @@ struct pan_shader_info {
 
       /* Bitfield of noperspective varyings, starting at VARYING_SLOT_VAR0 */
       uint32_t noperspective;
+
+      /* Bitfield of special varyings. */
+      uint32_t fixed_varyings;
    } varyings;
 
    /* UBOs to push to Register Mapped Uniforms (Midgard) or Fast Access
diff --git a/src/panfrost/vulkan/csf/panvk_vX_cmd_dispatch.c b/src/panfrost/vulkan/csf/panvk_vX_cmd_dispatch.c
index 2934bd999a1..547e640e288 100644
--- a/src/panfrost/vulkan/csf/panvk_vX_cmd_dispatch.c
+++ b/src/panfrost/vulkan/csf/panvk_vX_cmd_dispatch.c
@@ -209,14 +209,14 @@ cmd_dispatch(struct panvk_cmd_buffer *cmdbuf, struct panvk_dispatch_info *info)
       return;
 
    result = panvk_per_arch(cmd_prepare_push_uniforms)(
-      cmdbuf, cmdbuf->state.compute.shader);
+      cmdbuf, cmdbuf->state.compute.shader, 1);
    if (result != VK_SUCCESS)
       return;
 
    if (compute_state_dirty(cmdbuf, CS) ||
        compute_state_dirty(cmdbuf, DESC_STATE)) {
       result = panvk_per_arch(cmd_prepare_shader_res_table)(
-         cmdbuf, desc_state, shader, cs_desc_state);
+         cmdbuf, desc_state, shader, cs_desc_state, 1);
       if (result != VK_SUCCESS)
          return;
    }
diff --git a/src/panfrost/vulkan/csf/panvk_vX_cmd_draw.c b/src/panfrost/vulkan/csf/panvk_vX_cmd_draw.c
index 063d7a68d0f..49ce920bbe3 100644
--- a/src/panfrost/vulkan/csf/panvk_vX_cmd_draw.c
+++ b/src/panfrost/vulkan/csf/panvk_vX_cmd_draw.c
@@ -48,12 +48,14 @@ emit_vs_attrib(struct panvk_cmd_buffer *cmdbuf,
                uint32_t attrib_idx, uint32_t vb_desc_offset,
                struct mali_attribute_packed *desc)
 {
-   const struct vk_vertex_input_state *vi =
-      cmdbuf->vk.dynamic_graphics_state.vi;
+   const struct vk_dynamic_graphics_state *dyns =
+      &cmdbuf->vk.dynamic_graphics_state;
+   const struct vk_vertex_input_state *vi = dyns->vi;
    const struct vk_vertex_attribute_state *attrib_info =
       &vi->attributes[attrib_idx];
    const struct vk_vertex_binding_state *buf_info =
       &vi->bindings[attrib_info->binding];
+   const uint32_t stride = dyns->vi_binding_strides[attrib_info->binding];
    bool per_instance = buf_info->input_rate == VK_VERTEX_INPUT_RATE_INSTANCE;
    enum pipe_format f = vk_format_to_pipe_format(attrib_info->format);
    unsigned buf_idx = vb_desc_offset + attrib_info->binding;
@@ -61,15 +63,13 @@ emit_vs_attrib(struct panvk_cmd_buffer *cmdbuf,
    pan_pack(desc, ATTRIBUTE, cfg) {
       cfg.offset = attrib_info->offset;
 
-      if (per_instance) {
-         cfg.offset +=
-            cmdbuf->state.gfx.sysvals.vs.base_instance * buf_info->stride;
-      }
+      if (per_instance)
+         cfg.offset += cmdbuf->state.gfx.sysvals.vs.base_instance * stride;
 
       cfg.format = GENX(panfrost_format_from_pipe_format)(f)->hw;
       cfg.table = 0;
       cfg.buffer_index = buf_idx;
-      cfg.stride = buf_info->stride;
+      cfg.stride = stride;
       if (!per_instance) {
          /* Per-vertex */
          cfg.attribute_type = MALI_ATTRIBUTE_TYPE_1D;
@@ -110,24 +110,27 @@ vs_driver_set_is_dirty(struct panvk_cmd_buffer *cmdbuf)
 }
 
 static VkResult
-prepare_vs_driver_set(struct panvk_cmd_buffer *cmdbuf)
+prepare_vs_driver_set(struct panvk_cmd_buffer *cmdbuf,
+                      const struct panvk_draw_info *draw)
 {
    if (!vs_driver_set_is_dirty(cmdbuf))
       return VK_SUCCESS;
 
    struct panvk_shader_desc_state *vs_desc_state = &cmdbuf->state.gfx.vs.desc;
    const struct panvk_shader *vs = cmdbuf->state.gfx.vs.shader;
-   const struct vk_vertex_input_state *vi =
-      cmdbuf->vk.dynamic_graphics_state.vi;
+   const struct vk_dynamic_graphics_state *dyns =
+      &cmdbuf->vk.dynamic_graphics_state;
+   const struct vk_vertex_input_state *vi = dyns->vi;
    uint32_t vb_count = 0;
 
    cmdbuf->state.gfx.vi.attribs_changing_on_base_instance = 0;
    u_foreach_bit(i, vi->attributes_valid) {
       const struct vk_vertex_binding_state *binding =
          &vi->bindings[vi->attributes[i].binding];
+      const uint32_t stride =
+         dyns->vi_binding_strides[vi->attributes[i].binding];
 
-      if (binding->input_rate == VK_VERTEX_INPUT_RATE_INSTANCE &&
-          binding->stride != 0) {
+      if (binding->input_rate == VK_VERTEX_INPUT_RATE_INSTANCE && stride != 0) {
          cmdbuf->state.gfx.vi.attribs_changing_on_base_instance |=
             BITFIELD_BIT(i);
       }
@@ -137,45 +140,56 @@ prepare_vs_driver_set(struct panvk_cmd_buffer *cmdbuf)
 
    uint32_t vb_offset = vs->desc_info.dyn_bufs.count + MAX_VS_ATTRIBS + 1;
    uint32_t desc_count = vb_offset + vb_count;
+   uint32_t repeat_count = 1;
+
+   if (draw->indirect.draw_count > 1 &&
+       cmdbuf->state.gfx.vi.attribs_changing_on_base_instance != 0)
+      repeat_count = draw->indirect.draw_count;
+
    const struct panvk_descriptor_state *desc_state =
       &cmdbuf->state.gfx.desc_state;
    struct panfrost_ptr driver_set = panvk_cmd_alloc_dev_mem(
-      cmdbuf, desc, desc_count * PANVK_DESCRIPTOR_SIZE, PANVK_DESCRIPTOR_SIZE);
+      cmdbuf, desc, repeat_count * desc_count * PANVK_DESCRIPTOR_SIZE,
+      PANVK_DESCRIPTOR_SIZE);
    struct panvk_opaque_desc *descs = driver_set.cpu;
 
    if (!driver_set.gpu)
       return VK_ERROR_OUT_OF_DEVICE_MEMORY;
 
-   for (uint32_t i = 0; i < MAX_VS_ATTRIBS; i++) {
-      if (vi->attributes_valid & BITFIELD_BIT(i)) {
-         emit_vs_attrib(cmdbuf, i, vb_offset,
-                        (struct mali_attribute_packed *)(&descs[i]));
-      } else {
-         memset(&descs[i], 0, sizeof(descs[0]));
+   for (uint32_t r = 0; r < repeat_count; r++) {
+      for (uint32_t i = 0; i < MAX_VS_ATTRIBS; i++) {
+         if (vi->attributes_valid & BITFIELD_BIT(i)) {
+            emit_vs_attrib(cmdbuf, i, vb_offset,
+                           (struct mali_attribute_packed *)(&descs[i]));
+         } else {
+            memset(&descs[i], 0, sizeof(descs[0]));
+         }
       }
-   }
 
-   /* Dummy sampler always comes right after the vertex attribs. */
-   pan_cast_and_pack(&descs[MAX_VS_ATTRIBS], SAMPLER, cfg) {
-      cfg.clamp_integer_array_indices = false;
-   }
+      /* Dummy sampler always comes right after the vertex attribs. */
+      pan_cast_and_pack(&descs[MAX_VS_ATTRIBS], SAMPLER, cfg) {
+         cfg.clamp_integer_array_indices = false;
+      }
 
-   panvk_per_arch(cmd_fill_dyn_bufs)(
-      desc_state, vs,
-      (struct mali_buffer_packed *)(&descs[MAX_VS_ATTRIBS + 1]));
+      panvk_per_arch(cmd_fill_dyn_bufs)(
+         desc_state, vs,
+         (struct mali_buffer_packed *)(&descs[MAX_VS_ATTRIBS + 1]));
 
-   for (uint32_t i = 0; i < vb_count; i++) {
-      const struct panvk_attrib_buf *vb = &cmdbuf->state.gfx.vb.bufs[i];
+      for (uint32_t i = 0; i < vb_count; i++) {
+         const struct panvk_attrib_buf *vb = &cmdbuf->state.gfx.vb.bufs[i];
 
-      pan_cast_and_pack(&descs[vb_offset + i], BUFFER, cfg) {
-         if (vi->bindings_valid & BITFIELD_BIT(i)) {
-            cfg.address = vb->address;
-            cfg.size = vb->size;
-         } else {
-            cfg.address = 0;
-            cfg.size = 0;
+         pan_cast_and_pack(&descs[vb_offset + i], BUFFER, cfg) {
+            if (vi->bindings_valid & BITFIELD_BIT(i)) {
+               cfg.address = vb->address;
+               cfg.size = vb->size;
+            } else {
+               cfg.address = 0;
+               cfg.size = 0;
+            }
          }
       }
+
+      descs += desc_count;
    }
 
    vs_desc_state->driver_set.dev_addr = driver_set.gpu;
@@ -835,6 +849,10 @@ get_tiler_desc(struct panvk_cmd_buffer *cmdbuf)
 
    const struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
 
+   /* At this point, we should know sample count and the tile size should have
+    * been calculated */
+   assert(fbinfo->nr_samples > 0 && fbinfo->tile_size > 0);
+
    pan_pack(&tiler_tmpl, TILER_CONTEXT, cfg) {
       unsigned max_levels = tiler_features.max_levels;
       assert(max_levels >= 2);
@@ -1119,6 +1137,11 @@ get_fb_descs(struct panvk_cmd_buffer *cmdbuf)
 
    struct panvk_device *dev = to_panvk_device(cmdbuf->vk.base.device);
    struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
+
+   /* At this point, we should know sample count and the tile size should have
+    * been calculated */
+   assert(fbinfo->nr_samples > 0 && fbinfo->tile_size > 0);
+
    bool simul_use =
       cmdbuf->flags & VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT;
 
@@ -1305,6 +1328,8 @@ set_provoking_vertex_mode(struct panvk_cmd_buffer *cmdbuf)
 static VkResult
 get_render_ctx(struct panvk_cmd_buffer *cmdbuf)
 {
+   panvk_per_arch(cmd_select_tile_size)(cmdbuf);
+
    VkResult result = get_tiler_desc(cmdbuf);
    if (result != VK_SUCCESS)
       return result;
@@ -1313,7 +1338,7 @@ get_render_ctx(struct panvk_cmd_buffer *cmdbuf)
 }
 
 static VkResult
-prepare_vs(struct panvk_cmd_buffer *cmdbuf)
+prepare_vs(struct panvk_cmd_buffer *cmdbuf, const struct panvk_draw_info *draw)
 {
    struct panvk_descriptor_state *desc_state = &cmdbuf->state.gfx.desc_state;
    struct panvk_shader_desc_state *vs_desc_state = &cmdbuf->state.gfx.vs.desc;
@@ -1322,14 +1347,20 @@ prepare_vs(struct panvk_cmd_buffer *cmdbuf)
       panvk_get_cs_builder(cmdbuf, PANVK_SUBQUEUE_VERTEX_TILER);
    bool upd_res_table = false;
 
-   VkResult result = prepare_vs_driver_set(cmdbuf);
+   VkResult result = prepare_vs_driver_set(cmdbuf, draw);
    if (result != VK_SUCCESS)
       return result;
 
    if (gfx_state_dirty(cmdbuf, VS) || gfx_state_dirty(cmdbuf, DESC_STATE) ||
        vs_driver_set_is_dirty(cmdbuf)) {
-      result = panvk_per_arch(cmd_prepare_shader_res_table)(cmdbuf, desc_state,
-                                                            vs, vs_desc_state);
+      uint32_t repeat_count = 1;
+
+      if (draw->indirect.draw_count > 1 &&
+          cmdbuf->state.gfx.vi.attribs_changing_on_base_instance != 0)
+         repeat_count = draw->indirect.draw_count;
+
+      result = panvk_per_arch(cmd_prepare_shader_res_table)(
+         cmdbuf, desc_state, vs, vs_desc_state, repeat_count);
       if (result != VK_SUCCESS)
          return result;
 
@@ -1374,8 +1405,8 @@ prepare_fs(struct panvk_cmd_buffer *cmdbuf)
       if (result != VK_SUCCESS)
          return result;
 
-      result = panvk_per_arch(cmd_prepare_shader_res_table)(cmdbuf, desc_state,
-                                                            fs, fs_desc_state);
+      result = panvk_per_arch(cmd_prepare_shader_res_table)(
+         cmdbuf, desc_state, fs, fs_desc_state, 1);
       if (result != VK_SUCCESS)
          return result;
    }
@@ -1393,7 +1424,8 @@ prepare_fs(struct panvk_cmd_buffer *cmdbuf)
 }
 
 static VkResult
-prepare_push_uniforms(struct panvk_cmd_buffer *cmdbuf)
+prepare_push_uniforms(struct panvk_cmd_buffer *cmdbuf,
+                      const struct panvk_draw_info *draw)
 {
    struct cs_builder *b =
       panvk_get_cs_builder(cmdbuf, PANVK_SUBQUEUE_VERTEX_TILER);
@@ -1402,7 +1434,15 @@ prepare_push_uniforms(struct panvk_cmd_buffer *cmdbuf)
    VkResult result;
 
    if (gfx_state_dirty(cmdbuf, VS_PUSH_UNIFORMS)) {
-      result = panvk_per_arch(cmd_prepare_push_uniforms)(cmdbuf, vs);
+      uint32_t repeat_count = 1;
+
+      if (draw->indirect.draw_count > 1 &&
+          (shader_uses_sysval(vs, graphics, vs.first_vertex) ||
+           shader_uses_sysval(vs, graphics, vs.base_instance)))
+         repeat_count = draw->indirect.draw_count;
+
+      result =
+         panvk_per_arch(cmd_prepare_push_uniforms)(cmdbuf, vs, repeat_count);
       if (result != VK_SUCCESS)
          return result;
 
@@ -1417,7 +1457,7 @@ prepare_push_uniforms(struct panvk_cmd_buffer *cmdbuf)
       uint64_t fau_ptr = 0;
 
       if (fs) {
-         result = panvk_per_arch(cmd_prepare_push_uniforms)(cmdbuf, fs);
+         result = panvk_per_arch(cmd_prepare_push_uniforms)(cmdbuf, fs, 1);
          if (result != VK_SUCCESS)
             return result;
 
@@ -1780,15 +1820,11 @@ prepare_index_buffer(struct panvk_cmd_buffer *cmdbuf,
       panvk_get_cs_builder(cmdbuf, PANVK_SUBQUEUE_VERTEX_TILER);
 
    if (draw->index.size && gfx_state_dirty(cmdbuf, IB)) {
-      uint64_t ib_size =
-         panvk_buffer_range(cmdbuf->state.gfx.ib.buffer,
-                            cmdbuf->state.gfx.ib.offset, VK_WHOLE_SIZE);
-      assert(ib_size <= UINT32_MAX);
-      cs_move32_to(b, cs_sr_reg32(b, IDVS, INDEX_BUFFER_SIZE), ib_size);
+      cs_move32_to(b, cs_sr_reg32(b, IDVS, INDEX_BUFFER_SIZE),
+                   cmdbuf->state.gfx.ib.size);
 
       cs_move64_to(b, cs_sr_reg64(b, IDVS, INDEX_BUFFER),
-                   panvk_buffer_gpu_ptr(cmdbuf->state.gfx.ib.buffer,
-                                        cmdbuf->state.gfx.ib.offset));
+                   cmdbuf->state.gfx.ib.dev_addr);
    }
 }
 
@@ -1893,6 +1929,31 @@ prepare_draw(struct panvk_cmd_buffer *cmdbuf, struct panvk_draw_info *draw)
    if (result != VK_SUCCESS)
       return result;
 
+   if (!cmdbuf->vk.dynamic_graphics_state.rs.rasterizer_discard_enable) {
+      const struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
+      uint32_t *nr_samples = &cmdbuf->state.gfx.render.fb.nr_samples;
+      uint32_t rasterization_samples =
+         cmdbuf->vk.dynamic_graphics_state.ms.rasterization_samples;
+
+      /* If there's no attachment, we patch nr_samples to match
+       * rasterization_samples, otherwise, we make sure those two numbers match.
+       */
+      if (!cmdbuf->state.gfx.render.bound_attachments) {
+         assert(rasterization_samples > 0);
+         *nr_samples = rasterization_samples;
+      } else {
+         assert(rasterization_samples == *nr_samples);
+      }
+
+      /* In case we already emitted tiler/framebuffer descriptors, we ensure
+       * that the sample count didn't change
+       * XXX: This currently can happen in case we resume a render pass with no
+       * attachements and without any draw as the FBD is emitted when suspending.
+       */
+      assert(fbinfo->nr_samples == 0 ||
+             fbinfo->nr_samples == cmdbuf->state.gfx.render.fb.nr_samples);
+   }
+
    if (!inherits_render_ctx(cmdbuf)) {
       result = get_render_ctx(cmdbuf);
       if (result != VK_SUCCESS)
@@ -1927,11 +1988,11 @@ prepare_draw(struct panvk_cmd_buffer *cmdbuf, struct panvk_draw_info *draw)
 
    panvk_per_arch(cmd_prepare_draw_sysvals)(cmdbuf, draw);
 
-   result = prepare_push_uniforms(cmdbuf);
+   result = prepare_push_uniforms(cmdbuf, draw);
    if (result != VK_SUCCESS)
       return result;
 
-   result = prepare_vs(cmdbuf);
+   result = prepare_vs(cmdbuf, draw);
    if (result != VK_SUCCESS)
       return result;
 
@@ -1988,22 +2049,6 @@ panvk_cmd_draw(struct panvk_cmd_buffer *cmdbuf, struct panvk_draw_info *draw)
    cmdbuf->state.gfx.fs.required =
       fs_required(&cmdbuf->state.gfx, &cmdbuf->vk.dynamic_graphics_state);
 
-   if (!cmdbuf->vk.dynamic_graphics_state.rs.rasterizer_discard_enable) {
-      struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
-      uint32_t rasterization_samples =
-         cmdbuf->vk.dynamic_graphics_state.ms.rasterization_samples;
-
-      /* If there's no attachment, we patch nr_samples to match
-       * rasterization_samples, otherwise, we make sure those two numbers match.
-       */
-      if (!cmdbuf->state.gfx.render.bound_attachments) {
-         assert(rasterization_samples > 0);
-         fbinfo->nr_samples = rasterization_samples;
-      } else {
-         assert(rasterization_samples == fbinfo->nr_samples);
-      }
-   }
-
    result = prepare_draw(cmdbuf, draw);
    if (result != VK_SUCCESS)
       return;
@@ -2166,22 +2211,6 @@ panvk_cmd_draw_indirect(struct panvk_cmd_buffer *cmdbuf,
    cmdbuf->state.gfx.fs.required =
       fs_required(&cmdbuf->state.gfx, &cmdbuf->vk.dynamic_graphics_state);
 
-   if (!cmdbuf->vk.dynamic_graphics_state.rs.rasterizer_discard_enable) {
-      struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
-      uint32_t rasterization_samples =
-         cmdbuf->vk.dynamic_graphics_state.ms.rasterization_samples;
-
-      /* If there's no attachment, we patch nr_samples to match
-       * rasterization_samples, otherwise, we make sure those two numbers match.
-       */
-      if (!cmdbuf->state.gfx.render.bound_attachments) {
-         assert(rasterization_samples > 0);
-         fbinfo->nr_samples = rasterization_samples;
-      } else {
-         assert(rasterization_samples == fbinfo->nr_samples);
-      }
-   }
-
    /* Layered indirect draw (VK_EXT_shader_viewport_index_layer) needs
     * additional changes. We allow layer_count == 0 because that happens
     * when mixing dynamic rendering and secondary command buffers. Once
@@ -2195,9 +2224,6 @@ panvk_cmd_draw_indirect(struct panvk_cmd_buffer *cmdbuf,
    assert(cmdbuf->state.gfx.render.layer_count <= 1 ||
           cmdbuf->state.gfx.render.view_mask);
 
-   /* MultiDrawIndirect (.maxDrawIndirectCount) needs additional changes. */
-   assert(draw->indirect.draw_count == 1);
-
    /* Force a new push uniform block to be allocated */
    gfx_state_set_dirty(cmdbuf, VS_PUSH_UNIFORMS);
 
@@ -2205,123 +2231,177 @@ panvk_cmd_draw_indirect(struct panvk_cmd_buffer *cmdbuf,
    if (result != VK_SUCCESS)
       return;
 
+   struct panvk_shader_desc_state *vs_desc_state =
+      &cmdbuf->state.gfx.vs.desc;
+   const struct vk_dynamic_graphics_state *dyns =
+      &cmdbuf->vk.dynamic_graphics_state;
+   const struct vk_vertex_input_state *vi = dyns->vi;
+
+   struct mali_primitive_flags_packed flags_override =
+      get_tiler_flags_override(draw);
+
    uint32_t patch_attribs =
       cmdbuf->state.gfx.vi.attribs_changing_on_base_instance;
+   uint32_t vs_res_table_size =
+      (util_last_bit(vs->desc_info.used_set_mask) + 1) * pan_size(RESOURCE);
+   bool patch_faus = shader_uses_sysval(vs, graphics, vs.first_vertex) ||
+                     shader_uses_sysval(vs, graphics, vs.base_instance);
    struct cs_index draw_params_addr = cs_scratch_reg64(b, 0);
    struct cs_index vs_drv_set = cs_scratch_reg64(b, 2);
    struct cs_index attrib_offset = cs_scratch_reg32(b, 4);
    struct cs_index multiplicand = cs_scratch_reg32(b, 5);
+   struct cs_index draw_count = cs_scratch_reg32(b, 6);
+   struct cs_index max_draw_count = cs_scratch_reg32(b, 7);
+   struct cs_index draw_id = cs_scratch_reg32(b, 7);
+   struct cs_index vs_fau_addr = cs_scratch_reg64(b, 8);
+   struct cs_index tracing_scratch_regs = cs_scratch_reg_tuple(b, 10, 4);
+   uint32_t vs_fau_count = BITSET_COUNT(vs->fau.used_sysvals) +
+                           BITSET_COUNT(vs->fau.used_push_consts);
+
+   if (draw->indirect.count_buffer_dev_addr) {
+      cs_move32_to(b, max_draw_count, draw->indirect.draw_count);
+      cs_move64_to(b, draw_params_addr, draw->indirect.count_buffer_dev_addr);
+      cs_load32_to(b, draw_count, draw_params_addr, 0);
+
+      /* wait for draw_count to load from buffer */
+      cs_wait_slot(b, SB_ID(LS), false);
+      cs_umin32(b, draw_count, draw_count, max_draw_count);
+   } else {
+      cs_move32_to(b, draw_count, draw->indirect.draw_count);
+   }
+
+   if (patch_faus)
+      cs_move64_to(b, vs_fau_addr, cmdbuf->state.gfx.vs.push_uniforms);
 
    cs_move64_to(b, draw_params_addr, draw->indirect.buffer_dev_addr);
+   cs_move32_to(b, draw_id, 0);
 
-   cs_update_vt_ctx(b) {
-      cs_move32_to(b, cs_sr_reg32(b, IDVS, GLOBAL_ATTRIBUTE_OFFSET), 0);
-      /* Load SR33-37 from indirect buffer. */
-      unsigned reg_mask = draw->index.size ? 0b11111 : 0b11011;
-      cs_load_to(b, cs_sr_reg_tuple(b, IDVS, INDEX_COUNT, 5),
-                 draw_params_addr, reg_mask, 0);
-   }
+   cs_req_res(b, CS_IDVS_RES);
 
-   /* Wait for the SR33-37 indirect buffer load. */
-   cs_wait_slot(b, SB_ID(LS), false);
+   cs_while(b, MALI_CS_CONDITION_GREATER, draw_count) {
+      cs_update_vt_ctx(b) {
+         cs_move32_to(b, cs_sr_reg32(b, IDVS, GLOBAL_ATTRIBUTE_OFFSET), 0);
+         /* Load SR33-37 from indirect buffer. */
+         unsigned reg_mask = draw->index.size ? 0b11111 : 0b11011;
+         cs_load_to(b, cs_sr_reg_tuple(b, IDVS, INDEX_COUNT, 5),
+                    draw_params_addr, reg_mask, 0);
+      }
 
-   if (shader_uses_sysval(vs, graphics, vs.first_vertex) ||
-       shader_uses_sysval(vs, graphics, vs.base_instance)) {
-      struct cs_index fau_block_addr = cs_scratch_reg64(b, 2);
-      cs_move64_to(b, fau_block_addr, cmdbuf->state.gfx.vs.push_uniforms);
+      /* Wait for the SR33-37 indirect buffer load. */
+      cs_wait_slot(b, SB_ID(LS), false);
 
-      if (shader_uses_sysval(vs, graphics, vs.first_vertex)) {
-         cs_store32(b, cs_sr_reg32(b, IDVS, VERTEX_OFFSET), fau_block_addr,
-                    shader_remapped_sysval_offset(
-                       vs, sysval_offset(graphics, vs.first_vertex)));
-      }
+      if (patch_faus) {
+         if (shader_uses_sysval(vs, graphics, vs.first_vertex)) {
+            cs_store32(b, cs_sr_reg32(b, IDVS, VERTEX_OFFSET), vs_fau_addr,
+                       shader_remapped_sysval_offset(
+                          vs, sysval_offset(graphics, vs.first_vertex)));
+         }
 
-      if (shader_uses_sysval(vs, graphics, vs.base_instance)) {
-         cs_store32(b, cs_sr_reg32(b, IDVS, INSTANCE_OFFSET), fau_block_addr,
-                    shader_remapped_sysval_offset(
-                       vs, sysval_offset(graphics, vs.base_instance)));
+         if (shader_uses_sysval(vs, graphics, vs.base_instance)) {
+            cs_store32(b, cs_sr_reg32(b, IDVS, INSTANCE_OFFSET), vs_fau_addr,
+                       shader_remapped_sysval_offset(
+                          vs, sysval_offset(graphics, vs.base_instance)));
+         }
+
+         /* Wait for the store using SR-37 as src to finish, so we can
+          * overwrite it. */
+         cs_wait_slot(b, SB_ID(LS), false);
       }
 
-      /* Wait for the store using SR-37 as src to finish, so we can overwrite
-       * it. */
-      cs_wait_slot(b, SB_ID(LS), false);
-   }
+      if (patch_attribs != 0) {
+         cs_move64_to(b, vs_drv_set, vs_desc_state->driver_set.dev_addr);
 
-   if (patch_attribs != 0) {
-      struct panvk_shader_desc_state *vs_desc_state =
-         &cmdbuf->state.gfx.vs.desc;
-      const struct vk_vertex_input_state *vi =
-         cmdbuf->vk.dynamic_graphics_state.vi;
-
-      cs_move64_to(b, vs_drv_set, vs_desc_state->driver_set.dev_addr);
-
-      /* If firstInstance=0, skip the offset adjustment. */
-      cs_if(b, MALI_CS_CONDITION_NEQUAL,
-            cs_sr_reg32(b, IDVS, INSTANCE_OFFSET)) {
-         u_foreach_bit(i, patch_attribs) {
-            const struct vk_vertex_attribute_state *attrib_info =
-               &vi->attributes[i];
-            const struct vk_vertex_binding_state *binding =
-               &vi->bindings[attrib_info->binding];
-
-            cs_load32_to(b, attrib_offset, vs_drv_set,
-                         pan_size(ATTRIBUTE) * i + (2 * sizeof(uint32_t)));
-            cs_wait_slot(b, SB_ID(LS), false);
-
-            /* Emulated immediate multiply: we walk the bits in
-             * base_instance, and accumulate (stride << bit_pos) if the bit
-             * is present. This is sub-optimal, but it's simple :-). */
-            cs_add32(b, multiplicand, cs_sr_reg32(b, IDVS, INSTANCE_OFFSET), 0);
-            for (uint32_t i = 31; i > 0; i--) {
-               uint32_t add = binding->stride << i;
-
-               /* bit31 is the sign bit, so we don't need to subtract to
-                * check the presence of the bit. */
-               if (i < 31)
-                  cs_add32(b, multiplicand, multiplicand, -(1 << i));
-
-               if (add) {
-                  cs_if(b, MALI_CS_CONDITION_LESS, multiplicand)
-                     cs_add32(b, multiplicand, multiplicand, 1 << i);
-                  cs_else(b)
-                     cs_add32(b, attrib_offset, attrib_offset, add);
-               } else {
-                  cs_if(b, MALI_CS_CONDITION_LESS, multiplicand)
-                     cs_add32(b, multiplicand, multiplicand, 1 << i);
+         /* If firstInstance=0, skip the offset adjustment. */
+         cs_if(b, MALI_CS_CONDITION_NEQUAL,
+               cs_sr_reg32(b, IDVS, INSTANCE_OFFSET)) {
+            u_foreach_bit(i, patch_attribs) {
+               const struct vk_vertex_attribute_state *attrib_info =
+                  &vi->attributes[i];
+               const uint32_t stride =
+                  dyns->vi_binding_strides[attrib_info->binding];
+
+               cs_load32_to(b, attrib_offset, vs_drv_set,
+                            pan_size(ATTRIBUTE) * i + (2 * sizeof(uint32_t)));
+               cs_wait_slot(b, SB_ID(LS), false);
+
+               /* Emulated immediate multiply: we walk the bits in
+                * base_instance, and accumulate (stride << bit_pos) if the bit
+                * is present. This is sub-optimal, but it's simple :-). */
+               cs_add32(b, multiplicand,
+                        cs_sr_reg32(b, IDVS, INSTANCE_OFFSET), 0);
+               for (uint32_t i = 31; i > 0; i--) {
+                  uint32_t add = stride << i;
+
+                  /* bit31 is the sign bit, so we don't need to subtract to
+                   * check the presence of the bit. */
+                  if (i < 31)
+                     cs_add32(b, multiplicand, multiplicand, -(1 << i));
+
+                  if (add) {
+                     cs_if(b, MALI_CS_CONDITION_LESS, multiplicand)
+                        cs_add32(b, multiplicand, multiplicand, 1 << i);
+                     cs_else(b)
+                        cs_add32(b, attrib_offset, attrib_offset, add);
+                  } else {
+                     cs_if(b, MALI_CS_CONDITION_LESS, multiplicand)
+                        cs_add32(b, multiplicand, multiplicand, 1 << i);
+                  }
                }
-            }
 
-            cs_if(b, MALI_CS_CONDITION_NEQUAL, multiplicand)
-               cs_add32(b, attrib_offset, attrib_offset, binding->stride);
+               cs_if(b, MALI_CS_CONDITION_NEQUAL, multiplicand)
+                  cs_add32(b, attrib_offset, attrib_offset, stride);
 
-            cs_store32(b, attrib_offset, vs_drv_set,
-                       pan_size(ATTRIBUTE) * i + (2 * sizeof(uint32_t)));
-            cs_wait_slot(b, SB_ID(LS), false);
+               cs_store32(b, attrib_offset, vs_drv_set,
+                          pan_size(ATTRIBUTE) * i + (2 * sizeof(uint32_t)));
+               cs_wait_slot(b, SB_ID(LS), false);
+            }
          }
       }
-   }
 
-   /* NIR expects zero-based instance ID, but even if it did have an intrinsic to
-    * load the absolute instance ID, we'd want to keep it zero-based to work around
-    * Mali's limitation on non-zero firstInstance when a instance divisor is used.
-    */
-   cs_update_vt_ctx(b)
-      cs_move32_to(b, cs_sr_reg32(b, IDVS, INSTANCE_OFFSET), 0);
-
-   struct mali_primitive_flags_packed flags_override =
-      get_tiler_flags_override(draw);
+      /* NIR expects zero-based instance ID, but even if it did have an
+       * intrinsic to load the absolute instance ID, we'd want to keep it
+       * zero-based to work around Mali's limitation on non-zero firstInstance
+       * when a instance divisor is used.
+       */
+      cs_update_vt_ctx(b)
+         cs_move32_to(b, cs_sr_reg32(b, IDVS, INSTANCE_OFFSET), 0);
 
-   cs_req_res(b, CS_IDVS_RES);
 #if PAN_ARCH >= 12
-   cs_trace_run_idvs2(b, tracing_ctx, cs_scratch_reg_tuple(b, 0, 4),
-                     flags_override.opaque[0], false, true, cs_undef(),
-                     MALI_IDVS_SHADING_MODE_EARLY);
+      cs_trace_run_idvs2(b, tracing_ctx, tracing_scratch_regs,
+                        flags_override.opaque[0], false, true, draw_id,
+                        MALI_IDVS_SHADING_MODE_EARLY);
 #else
-   cs_trace_run_idvs(b, tracing_ctx, cs_scratch_reg_tuple(b, 0, 4),
-                     flags_override.opaque[0], false, true,
-                     cs_shader_res_sel(0, 0, 1, 0),
-                     cs_shader_res_sel(2, 2, 2, 0), cs_undef());
+      cs_trace_run_idvs(b, tracing_ctx, tracing_scratch_regs,
+                        flags_override.opaque[0], false, true,
+                        cs_shader_res_sel(0, 0, 1, 0),
+                        cs_shader_res_sel(2, 2, 2, 0), draw_id);
 #endif
+
+      cs_add32(b, draw_count, draw_count, -1);
+      cs_add32(b, draw_id, draw_id, 1);
+      cs_add64(b, draw_params_addr, draw_params_addr,
+               draw->indirect.stride);
+
+      if (patch_faus) {
+         cs_add64(b, vs_fau_addr, vs_fau_addr, vs_fau_count * sizeof(uint64_t));
+         cs_update_vt_ctx(b) {
+            cs_add64(b, cs_sr_reg64(b, IDVS, VERTEX_FAU),
+                     cs_sr_reg64(b, IDVS, VERTEX_FAU),
+                     vs_fau_count * sizeof(uint64_t));
+         }
+
+      }
+
+      if (patch_attribs != 0) {
+         cs_add64(b, vs_drv_set, vs_drv_set,
+                  vs_desc_state->driver_set.size);
+         cs_update_vt_ctx(b) {
+            cs_add64(b, cs_sr_reg64(b, IDVS, VERTEX_SRT),
+                     cs_sr_reg64(b, IDVS, VERTEX_SRT), vs_res_table_size);
+         }
+      }
+   }
+
    cs_req_res(b, 0);
 }
 
@@ -2366,6 +2446,61 @@ panvk_per_arch(CmdDrawIndexedIndirect)(VkCommandBuffer commandBuffer,
    panvk_cmd_draw_indirect(cmdbuf, &draw);
 }
 
+VKAPI_ATTR void VKAPI_CALL
+panvk_per_arch(CmdDrawIndirectCount)(VkCommandBuffer commandBuffer,
+                                     VkBuffer _buffer,
+                                     VkDeviceSize offset,
+                                     VkBuffer countBuffer,
+                                     VkDeviceSize countBufferOffset,
+                                     uint32_t maxDrawCount,
+                                     uint32_t stride)
+{
+   VK_FROM_HANDLE(panvk_cmd_buffer, cmdbuf, commandBuffer);
+   VK_FROM_HANDLE(panvk_buffer, buffer, _buffer);
+   VK_FROM_HANDLE(panvk_buffer, count_buffer, countBuffer);
+
+   if (maxDrawCount == 0)
+      return;
+
+   struct panvk_draw_info draw = {
+      .indirect.buffer_dev_addr = panvk_buffer_gpu_ptr(buffer, offset),
+      .indirect.count_buffer_dev_addr =
+         panvk_buffer_gpu_ptr(count_buffer, countBufferOffset),
+      .indirect.draw_count = maxDrawCount,
+      .indirect.stride = stride,
+   };
+
+   panvk_cmd_draw_indirect(cmdbuf, &draw);
+}
+
+VKAPI_ATTR void VKAPI_CALL
+panvk_per_arch(CmdDrawIndexedIndirectCount)(VkCommandBuffer commandBuffer,
+                                            VkBuffer _buffer,
+                                            VkDeviceSize offset,
+                                            VkBuffer countBuffer,
+                                            VkDeviceSize countBufferOffset,
+                                            uint32_t maxDrawCount,
+                                            uint32_t stride)
+{
+   VK_FROM_HANDLE(panvk_cmd_buffer, cmdbuf, commandBuffer);
+   VK_FROM_HANDLE(panvk_buffer, buffer, _buffer);
+   VK_FROM_HANDLE(panvk_buffer, count_buffer, countBuffer);
+
+   if (maxDrawCount == 0)
+      return;
+
+   struct panvk_draw_info draw = {
+      .index.size = cmdbuf->state.gfx.ib.index_size,
+      .indirect.buffer_dev_addr = panvk_buffer_gpu_ptr(buffer, offset),
+      .indirect.count_buffer_dev_addr =
+         panvk_buffer_gpu_ptr(count_buffer, countBufferOffset),
+      .indirect.draw_count = maxDrawCount,
+      .indirect.stride = stride,
+   };
+
+   panvk_cmd_draw_indirect(cmdbuf, &draw);
+}
+
 void
 panvk_per_arch(cmd_inherit_render_state)(
    struct panvk_cmd_buffer *cmdbuf,
@@ -2413,12 +2548,18 @@ panvk_per_arch(cmd_inherit_render_state)(
    cmdbuf->state.gfx.render.layer_count = inheritance_info->viewMask ?
       util_last_bit(inheritance_info->viewMask) :
       0;
+
+   /* If a draw was performed, the inherited sample count should match our current sample count */
+   assert(fbinfo->nr_samples == 0 || inheritance_info->rasterizationSamples == fbinfo->nr_samples);
    *fbinfo = (struct pan_fb_info){
       .tile_buf_budget = panfrost_query_optimal_tib_size(phys_dev->model),
       .z_tile_buf_budget = panfrost_query_optimal_z_tib_size(phys_dev->model),
+      .tile_size = fbinfo->tile_size,
+      .cbuf_allocation = fbinfo->cbuf_allocation,
       .nr_samples = inheritance_info->rasterizationSamples,
       .rt_count = inheritance_info->colorAttachmentCount,
    };
+   cmdbuf->state.gfx.render.fb.nr_samples = inheritance_info->rasterizationSamples;
 
    assert(inheritance_info->colorAttachmentCount <= ARRAY_SIZE(fbinfo->rts));
 
@@ -2894,6 +3035,10 @@ panvk_per_arch(CmdEndRendering)(VkCommandBuffer commandBuffer)
 
    if (!suspending) {
       struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
+
+      /* If no draw was performed, we should ensure sample count is valid and that we emit tile size */
+      panvk_per_arch(cmd_select_tile_size)(cmdbuf);
+
       bool clear = fbinfo->zs.clear.z | fbinfo->zs.clear.s;
       for (unsigned i = 0; i < fbinfo->rt_count; i++)
          clear |= fbinfo->rts[i].clear;
diff --git a/src/panfrost/vulkan/jm/panvk_vX_cmd_buffer.c b/src/panfrost/vulkan/jm/panvk_vX_cmd_buffer.c
index d521f88d79a..c6338d29f2f 100644
--- a/src/panfrost/vulkan/jm/panvk_vX_cmd_buffer.c
+++ b/src/panfrost/vulkan/jm/panvk_vX_cmd_buffer.c
@@ -137,6 +137,12 @@ panvk_per_arch(cmd_close_batch)(struct panvk_cmd_buffer *cmdbuf)
       GENX(pan_emit_tls)(&batch->tlsinfo, batch->tls.cpu);
 
    if (batch->fb.desc.cpu) {
+      panvk_per_arch(cmd_select_tile_size)(cmdbuf);
+
+      /* At this point, we should know sample count and the tile size should have
+       * been calculated */
+      assert(fbinfo->nr_samples > 0 && fbinfo->tile_size > 0);
+
       fbinfo->sample_positions = dev->sample_positions->addr.dev +
                                  panfrost_sample_positions_offset(
                                     pan_sample_pattern(fbinfo->nr_samples));
diff --git a/src/panfrost/vulkan/jm/panvk_vX_cmd_dispatch.c b/src/panfrost/vulkan/jm/panvk_vX_cmd_dispatch.c
index 7e5e050f248..adfdc0541a6 100644
--- a/src/panfrost/vulkan/jm/panvk_vX_cmd_dispatch.c
+++ b/src/panfrost/vulkan/jm/panvk_vX_cmd_dispatch.c
@@ -107,7 +107,7 @@ panvk_per_arch(CmdDispatchBase)(VkCommandBuffer commandBuffer,
    panvk_per_arch(cmd_prepare_dispatch_sysvals)(cmdbuf, &info);
 
    result = panvk_per_arch(cmd_prepare_push_uniforms)(
-      cmdbuf, cmdbuf->state.compute.shader);
+      cmdbuf, cmdbuf->state.compute.shader, 1);
    if (result != VK_SUCCESS)
       return;
 
diff --git a/src/panfrost/vulkan/jm/panvk_vX_cmd_draw.c b/src/panfrost/vulkan/jm/panvk_vX_cmd_draw.c
index 63a6e28dc96..213a7ec1aef 100644
--- a/src/panfrost/vulkan/jm/panvk_vX_cmd_draw.c
+++ b/src/panfrost/vulkan/jm/panvk_vX_cmd_draw.c
@@ -15,6 +15,7 @@
 #include "panvk_cmd_alloc.h"
 #include "panvk_cmd_buffer.h"
 #include "panvk_cmd_desc_state.h"
+#include "panvk_cmd_draw.h"
 #include "panvk_cmd_meta.h"
 #include "panvk_device.h"
 #include "panvk_entrypoints.h"
@@ -488,6 +489,7 @@ panvk_draw_prepare_varyings(struct panvk_cmd_buffer *cmdbuf,
 static void
 panvk_draw_emit_attrib_buf(const struct panvk_draw_data *draw,
                            const struct vk_vertex_binding_state *buf_info,
+                           uint32_t stride,
                            const struct panvk_attrib_buf *buf,
                            struct mali_attribute_buffer_packed *desc)
 {
@@ -501,7 +503,7 @@ panvk_draw_emit_attrib_buf(const struct panvk_draw_data *draw,
    if (draw->info.instance.count <= 1) {
       pan_pack(desc, ATTRIBUTE_BUFFER, cfg) {
          cfg.type = MALI_ATTRIBUTE_TYPE_1D;
-         cfg.stride = per_instance ? 0 : buf_info->stride;
+         cfg.stride = per_instance ? 0 : stride;
          cfg.pointer = addr;
          cfg.size = size;
       }
@@ -509,7 +511,7 @@ panvk_draw_emit_attrib_buf(const struct panvk_draw_data *draw,
       pan_pack(desc, ATTRIBUTE_BUFFER, cfg) {
          cfg.type = MALI_ATTRIBUTE_TYPE_1D_MODULUS;
          cfg.divisor = draw->padded_vertex_count;
-         cfg.stride = buf_info->stride;
+         cfg.stride = stride;
          cfg.pointer = addr;
          cfg.size = size;
       }
@@ -526,7 +528,7 @@ panvk_draw_emit_attrib_buf(const struct panvk_draw_data *draw,
    } else if (util_is_power_of_two_or_zero(divisor)) {
       pan_pack(desc, ATTRIBUTE_BUFFER, cfg) {
          cfg.type = MALI_ATTRIBUTE_TYPE_1D_POT_DIVISOR;
-         cfg.stride = buf_info->stride;
+         cfg.stride = stride;
          cfg.pointer = addr;
          cfg.size = size;
          cfg.divisor_r = __builtin_ctz(divisor);
@@ -537,7 +539,7 @@ panvk_draw_emit_attrib_buf(const struct panvk_draw_data *draw,
          panfrost_compute_magic_divisor(divisor, &divisor_r, &divisor_e);
       pan_pack(desc, ATTRIBUTE_BUFFER, cfg) {
          cfg.type = MALI_ATTRIBUTE_TYPE_1D_NPOT_DIVISOR;
-         cfg.stride = buf_info->stride;
+         cfg.stride = stride;
          cfg.pointer = addr;
          cfg.size = size;
          cfg.divisor_r = divisor_r;
@@ -585,8 +587,9 @@ panvk_draw_prepare_vs_attribs(struct panvk_cmd_buffer *cmdbuf,
                               struct panvk_draw_data *draw)
 {
    const struct panvk_shader *vs = cmdbuf->state.gfx.vs.shader;
-   const struct vk_vertex_input_state *vi =
-      cmdbuf->vk.dynamic_graphics_state.vi;
+   const struct vk_dynamic_graphics_state *dyns =
+      &cmdbuf->vk.dynamic_graphics_state;
+   const struct vk_vertex_input_state *vi = dyns->vi;
    unsigned num_imgs = vs->desc_info.others.count[PANVK_BIFROST_DESC_TABLE_IMG];
    unsigned num_vs_attribs = util_last_bit(vi->attributes_valid);
    unsigned num_vbs = util_last_bit(vi->bindings_valid);
@@ -616,6 +619,7 @@ panvk_draw_prepare_vs_attribs(struct panvk_cmd_buffer *cmdbuf,
    for (unsigned i = 0; i < num_vbs; i++) {
       if (vi->bindings_valid & BITFIELD_BIT(i)) {
          panvk_draw_emit_attrib_buf(draw, &vi->bindings[i],
+                                    dyns->vi_binding_strides[i],
                                     &cmdbuf->state.gfx.vb.bufs[i],
                                     &attrib_buf_descs[i * 2]);
       } else {
@@ -1181,7 +1185,8 @@ panvk_cmd_draw(struct panvk_cmd_buffer *cmdbuf, struct panvk_draw_data *draw)
    set_provoking_vertex_mode(cmdbuf);
 
    if (!rs->rasterizer_discard_enable) {
-      struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
+      const struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
+      uint32_t *nr_samples = &cmdbuf->state.gfx.render.fb.nr_samples;
       uint32_t rasterization_samples =
          cmdbuf->vk.dynamic_graphics_state.ms.rasterization_samples;
 
@@ -1190,16 +1195,26 @@ panvk_cmd_draw(struct panvk_cmd_buffer *cmdbuf, struct panvk_draw_data *draw)
        * make sure those two numbers match. */
       if (!batch->fb.desc.gpu && !cmdbuf->state.gfx.render.bound_attachments) {
          assert(rasterization_samples > 0);
-         fbinfo->nr_samples = rasterization_samples;
+         *nr_samples = rasterization_samples;
       } else {
-         assert(rasterization_samples == fbinfo->nr_samples);
+         assert(rasterization_samples == *nr_samples);
       }
 
+      /* In case we already emitted tiler/framebuffer descriptors, we ensure
+       * that the sample count didn't change
+       * XXX: This currently can happen in case we resume a render pass with no
+       * attachements and without any draw as the FBD is emitted when suspending.
+       */
+      assert(fbinfo->nr_samples == 0 ||
+             fbinfo->nr_samples == cmdbuf->state.gfx.render.fb.nr_samples);
+
       result = panvk_per_arch(cmd_alloc_fb_desc)(cmdbuf);
       if (result != VK_SUCCESS)
          return;
    }
 
+   panvk_per_arch(cmd_select_tile_size)(cmdbuf);
+
    result = panvk_per_arch(cmd_alloc_tls_desc)(cmdbuf, true);
    if (result != VK_SUCCESS)
       return;
@@ -1305,13 +1320,13 @@ panvk_cmd_draw(struct panvk_cmd_buffer *cmdbuf, struct panvk_draw_data *draw)
       }
 
       result = panvk_per_arch(cmd_prepare_push_uniforms)(
-         cmdbuf, cmdbuf->state.gfx.vs.shader);
+         cmdbuf, cmdbuf->state.gfx.vs.shader, 1);
       if (result != VK_SUCCESS)
          return;
 
       if (fs) {
          result = panvk_per_arch(cmd_prepare_push_uniforms)(
-            cmdbuf, cmdbuf->state.gfx.fs.shader);
+            cmdbuf, cmdbuf->state.gfx.fs.shader, 1);
          if (result != VK_SUCCESS)
             return;
       }
@@ -1409,14 +1424,9 @@ panvk_index_minmax_search(struct panvk_cmd_buffer *cmdbuf, uint32_t start,
    struct panvk_device *dev = to_panvk_device(cmdbuf->vk.base.device);
    struct panvk_instance *instance =
       to_panvk_instance(dev->vk.physical->instance);
-   void *ptr =
-      cmdbuf->state.gfx.ib.buffer->host_ptr + cmdbuf->state.gfx.ib.offset;
-
-   assert(PAN_ARCH < 9 && cmdbuf->state.gfx.ib.buffer->host_ptr);
+   void *ptr = cmdbuf->state.gfx.ib.host_addr;
 
-   assert(cmdbuf->state.gfx.ib.buffer);
-   assert(cmdbuf->state.gfx.ib.buffer->bo);
-   assert(cmdbuf->state.gfx.ib.buffer->host_ptr);
+   assert(PAN_ARCH < 9 && ptr);
 
    if (!(instance->debug_flags & PANVK_DEBUG_NO_KNOWN_WARN)) {
       mesa_logw("Crawling index buffers from the CPU isn't valid in Vulkan\n");
@@ -1487,8 +1497,7 @@ panvk_per_arch(CmdDrawIndexed)(VkCommandBuffer commandBuffer,
       .vertex_range = vertex_range,
       .padded_vertex_count =
          padded_vertex_count(cmdbuf, vertex_range, instanceCount),
-      .indices = panvk_buffer_gpu_ptr(cmdbuf->state.gfx.ib.buffer,
-                                      cmdbuf->state.gfx.ib.offset) +
+      .indices = cmdbuf->state.gfx.ib.dev_addr +
                  (firstIndex * cmdbuf->state.gfx.ib.index_size),
    };
 
diff --git a/src/panfrost/vulkan/panvk_cmd_desc_state.h b/src/panfrost/vulkan/panvk_cmd_desc_state.h
index 88e843ba906..78b335b25ee 100644
--- a/src/panfrost/vulkan/panvk_cmd_desc_state.h
+++ b/src/panfrost/vulkan/panvk_cmd_desc_state.h
@@ -76,7 +76,7 @@ VkResult panvk_per_arch(cmd_prepare_shader_res_table)(
    struct panvk_cmd_buffer *cmdbuf,
    const struct panvk_descriptor_state *desc_state,
    const struct panvk_shader *shader,
-   struct panvk_shader_desc_state *shader_desc_state);
+   struct panvk_shader_desc_state *shader_desc_state, uint32_t repeat_count);
 #endif
 
 VkResult panvk_per_arch(cmd_prepare_push_descs)(
diff --git a/src/panfrost/vulkan/panvk_cmd_draw.h b/src/panfrost/vulkan/panvk_cmd_draw.h
index f7fc384753b..2f0c53bdf51 100644
--- a/src/panfrost/vulkan/panvk_cmd_draw.h
+++ b/src/panfrost/vulkan/panvk_cmd_draw.h
@@ -64,6 +64,9 @@ struct panvk_rendering_state {
       struct pan_fb_info info;
       bool crc_valid[MAX_RTS];
 
+      /* nr_samples to be used before framebuffer / tiler descriptor are emitted */
+      uint32_t nr_samples;
+
 #if PAN_ARCH <= 7
       uint32_t bo_count;
       struct pan_kmod_bo *bos[MAX_RTS + 2];
@@ -154,8 +157,11 @@ struct panvk_cmd_graphics_state {
 
    /* Index buffer */
    struct {
-      struct panvk_buffer *buffer;
-      uint64_t offset;
+      uint64_t dev_addr;
+#if PAN_ARCH <= 7
+      void *host_addr;
+#endif
+      uint64_t size;
       uint8_t index_size;
    } ib;
 
@@ -323,6 +329,7 @@ panvk_per_arch(cmd_preload_render_area_border)(struct panvk_cmd_buffer *cmdbuf,
                                                const VkRenderingInfo *render_info);
 
 void panvk_per_arch(cmd_resolve_attachments)(struct panvk_cmd_buffer *cmdbuf);
+void panvk_per_arch(cmd_select_tile_size)(struct panvk_cmd_buffer *cmdbuf);
 
 struct panvk_draw_info {
    struct {
@@ -345,6 +352,7 @@ struct panvk_draw_info {
 
    struct {
       uint64_t buffer_dev_addr;
+      uint64_t count_buffer_dev_addr;
       uint32_t draw_count;
       uint32_t stride;
    } indirect;
diff --git a/src/panfrost/vulkan/panvk_cmd_push_constant.h b/src/panfrost/vulkan/panvk_cmd_push_constant.h
index 5c709e09f37..bf94369b734 100644
--- a/src/panfrost/vulkan/panvk_cmd_push_constant.h
+++ b/src/panfrost/vulkan/panvk_cmd_push_constant.h
@@ -21,6 +21,7 @@ struct panvk_push_constant_state {
 
 VkResult
 panvk_per_arch(cmd_prepare_push_uniforms)(struct panvk_cmd_buffer *cmdbuf,
-                                          const struct panvk_shader *shader);
+                                          const struct panvk_shader *shader,
+                                          uint32_t repeat_count);
 
 #endif
diff --git a/src/panfrost/vulkan/panvk_image.c b/src/panfrost/vulkan/panvk_image.c
index 8358fea2169..a14ff0e6c31 100644
--- a/src/panfrost/vulkan/panvk_image.c
+++ b/src/panfrost/vulkan/panvk_image.c
@@ -326,7 +326,7 @@ panvk_image_get_total_size(const struct panvk_image *image)
 }
 
 static bool
-is_disjoint(struct panvk_image *image)
+is_disjoint(const struct panvk_image *image)
 {
    assert((image->plane_count > 1 &&
            image->vk.format != VK_FORMAT_D32_SFLOAT_S8_UINT) ||
@@ -336,7 +336,7 @@ is_disjoint(struct panvk_image *image)
 }
 
 static void
-panvk_image_init(struct panvk_device *dev, struct panvk_image *image,
+panvk_image_init(struct panvk_image *image,
                  const VkImageCreateInfo *pCreateInfo)
 {
    /* Add any create/usage flags that might be needed for meta operations.
@@ -372,7 +372,7 @@ panvk_CreateImage(VkDevice device, const VkImageCreateInfo *pCreateInfo,
    if (!image)
       return panvk_error(device, VK_ERROR_OUT_OF_HOST_MEMORY);
 
-   panvk_image_init(dev, image, pCreateInfo);
+   panvk_image_init(image, pCreateInfo);
 
    /*
     * From the Vulkan spec:
@@ -405,19 +405,18 @@ panvk_DestroyImage(VkDevice _device, VkImage _image,
    vk_image_destroy(&device->vk, pAllocator, &image->vk);
 }
 
-VKAPI_ATTR void VKAPI_CALL
-panvk_GetImageSubresourceLayout(VkDevice _device, VkImage _image,
-                                const VkImageSubresource *pSubresource,
-                                VkSubresourceLayout *pLayout)
+static void
+get_image_subresource_layout(const struct panvk_image *image,
+                             const VkImageSubresource2 *subres2,
+                             VkSubresourceLayout2 *layout2)
 {
-   VK_FROM_HANDLE(panvk_image, image, _image);
-
-   unsigned plane =
-      panvk_plane_index(image->vk.format, pSubresource->aspectMask);
+   const VkImageSubresource *subres = &subres2->imageSubresource;
+   VkSubresourceLayout *layout = &layout2->subresourceLayout;
+   unsigned plane = panvk_plane_index(image->vk.format, subres->aspectMask);
    assert(plane < PANVK_MAX_PLANES);
 
    const struct pan_image_slice_layout *slice_layout =
-      &image->planes[plane].layout.slices[pSubresource->mipLevel];
+      &image->planes[plane].layout.slices[subres->mipLevel];
 
    uint64_t base_offset = 0;
    if (!is_disjoint(image)) {
@@ -425,13 +424,37 @@ panvk_GetImageSubresourceLayout(VkDevice _device, VkImage _image,
          base_offset += image->planes[plane_idx].layout.data_size;
    }
 
-   pLayout->offset = base_offset +
-      slice_layout->offset + (pSubresource->arrayLayer *
+   layout->offset = base_offset +
+      slice_layout->offset + (subres->arrayLayer *
                               image->planes[plane].layout.array_stride);
-   pLayout->size = slice_layout->size;
-   pLayout->rowPitch = slice_layout->row_stride;
-   pLayout->arrayPitch = image->planes[plane].layout.array_stride;
-   pLayout->depthPitch = slice_layout->surface_stride;
+   layout->size = slice_layout->size;
+   layout->rowPitch = slice_layout->row_stride;
+   layout->arrayPitch = image->planes[plane].layout.array_stride;
+   layout->depthPitch = slice_layout->surface_stride;
+}
+
+VKAPI_ATTR void VKAPI_CALL
+panvk_GetImageSubresourceLayout2(VkDevice device, VkImage image,
+                                 const VkImageSubresource2 *pSubresource,
+                                 VkSubresourceLayout2 *pLayout)
+{
+   VK_FROM_HANDLE(panvk_image, img, image);
+
+   get_image_subresource_layout(img, pSubresource, pLayout);
+}
+
+VKAPI_ATTR void VKAPI_CALL
+panvk_GetDeviceImageSubresourceLayoutKHR(
+   VkDevice device, const VkDeviceImageSubresourceInfoKHR *pInfo,
+   VkSubresourceLayout2KHR *pLayout)
+{
+   VK_FROM_HANDLE(panvk_device, dev, device);
+   struct panvk_image image = {0};
+
+   vk_image_init(&dev->vk, &image.vk, pInfo->pCreateInfo);
+   panvk_image_init(&image, pInfo->pCreateInfo);
+   get_image_subresource_layout(&image, pInfo->pSubresource, pLayout);
+   vk_image_finish(&image.vk);
 }
 
 VKAPI_ATTR void VKAPI_CALL
@@ -480,13 +503,14 @@ panvk_GetDeviceImageMemoryRequirements(VkDevice device,
 
    struct panvk_image image;
    vk_image_init(&dev->vk, &image.vk, pInfo->pCreateInfo);
-   panvk_image_init(dev, &image, pInfo->pCreateInfo);
+   panvk_image_init(&image, pInfo->pCreateInfo);
 
    VkImageMemoryRequirementsInfo2 info2 = {
       .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_REQUIREMENTS_INFO_2,
       .image = panvk_image_to_handle(&image),
    };
    panvk_GetImageMemoryRequirements2(device, &info2, pMemoryRequirements);
+   vk_image_finish(&image.vk);
 }
 
 VKAPI_ATTR void VKAPI_CALL
diff --git a/src/panfrost/vulkan/panvk_physical_device.c b/src/panfrost/vulkan/panvk_physical_device.c
index f2e878f7855..23753d667fa 100644
--- a/src/panfrost/vulkan/panvk_physical_device.c
+++ b/src/panfrost/vulkan/panvk_physical_device.c
@@ -210,6 +210,7 @@ get_device_extensions(const struct panvk_physical_device *device,
    const unsigned arch = pan_arch(device->kmod.props.gpu_prod_id);
 
    bool has_vk1_1 = arch >= 10;
+   bool has_vk1_2 = arch >= 10;
 
    *ext = (struct vk_device_extension_table){
       .KHR_8bit_storage = true,
@@ -222,6 +223,7 @@ get_device_extensions(const struct panvk_physical_device *device,
       .KHR_descriptor_update_template = true,
       .KHR_depth_stencil_resolve = true,
       .KHR_device_group = true,
+      .KHR_draw_indirect_count = arch >= 10,
       .KHR_driver_properties = true,
       .KHR_dynamic_rendering = true,
       .KHR_dynamic_rendering_local_read = true,
@@ -241,6 +243,8 @@ get_device_extensions(const struct panvk_physical_device *device,
       .KHR_maintenance1 = true,
       .KHR_maintenance2 = true,
       .KHR_maintenance3 = true,
+      .KHR_maintenance4 = has_vk1_1,
+      .KHR_maintenance5 = has_vk1_1,
       .KHR_map_memory2 = true,
       .KHR_multiview = arch >= 10,
       .KHR_pipeline_executable_properties = true,
@@ -255,13 +259,15 @@ get_device_extensions(const struct panvk_physical_device *device,
       .KHR_shader_float_controls = true,
       .KHR_shader_float_controls2 = has_vk1_1,
       .KHR_shader_float16_int8 = true,
+      .KHR_shader_integer_dot_product = true,
       .KHR_shader_maximal_reconvergence = has_vk1_1,
       .KHR_shader_non_semantic_info = true,
-      .KHR_shader_quad_control = false,
+      .KHR_shader_quad_control = has_vk1_2,
       .KHR_shader_relaxed_extended_instruction = true,
       .KHR_shader_subgroup_extended_types = has_vk1_1,
       .KHR_shader_subgroup_rotate = true,
       .KHR_shader_subgroup_uniform_control_flow = has_vk1_1,
+      .KHR_shader_terminate_invocation = true,
       .KHR_spirv_1_4 = arch >= 10,
       .KHR_storage_buffer_storage_class = true,
 #ifdef PANVK_USE_WSI_PLATFORM
@@ -277,10 +283,13 @@ get_device_extensions(const struct panvk_physical_device *device,
       .EXT_border_color_swizzle = true,
       .EXT_buffer_device_address = true,
       .EXT_custom_border_color = true,
+      .EXT_depth_bias_control = true,
       .EXT_depth_clip_enable = true,
 #ifdef VK_USE_PLATFORM_DISPLAY_KHR
       .EXT_display_control = true,
 #endif
+      .EXT_extended_dynamic_state = true,
+      .EXT_extended_dynamic_state2 = true,
       .EXT_external_memory_dma_buf = true,
       .EXT_global_priority = true,
       .EXT_global_priority_query = true,
@@ -303,8 +312,12 @@ get_device_extensions(const struct panvk_physical_device *device,
       .EXT_scalar_block_layout = true,
       .EXT_separate_stencil_usage = true,
       .EXT_shader_module_identifier = true,
+      .EXT_shader_demote_to_helper_invocation = true,
+      .EXT_shader_replicated_composites = true,
       .EXT_subgroup_size_control = has_vk1_1,
       .EXT_tooling_info = true,
+      .EXT_vertex_attribute_divisor = true,
+      .EXT_vertex_input_dynamic_state = true,
       .EXT_ycbcr_2plane_444_formats = arch >= 10,
       .EXT_ycbcr_image_arrays = arch >= 10,
       .GOOGLE_decorate_string = true,
@@ -367,6 +380,7 @@ get_features(const struct panvk_physical_device *device,
       .independentBlend = true,
       .sampleRateShading = true,
       .logicOp = true,
+      .multiDrawIndirect = arch >= 10,
       .wideLines = true,
       .largePoints = true,
       .occlusionQueryPrecise = true,
@@ -403,7 +417,7 @@ get_features(const struct panvk_physical_device *device,
 
       /* Vulkan 1.2 */
       .samplerMirrorClampToEdge = true,
-      .drawIndirectCount = false,
+      .drawIndirectCount = arch >= 10,
       .storageBuffer8BitAccess = true,
       .uniformAndStorageBuffer8BitAccess = true,
       .storagePushConstant8 = true,
@@ -456,10 +470,14 @@ get_features(const struct panvk_physical_device *device,
       .robustImageAccess = true,
       .inlineUniformBlock = false,
       .descriptorBindingInlineUniformBlockUpdateAfterBind = false,
+      .extendedDynamicState = true,
+      .extendedDynamicState2 = true,
+      .extendedDynamicState2LogicOp = true,
+      .extendedDynamicState2PatchControlPoints = false,
       .pipelineCreationCacheControl = true,
       .privateData = true,
-      .shaderDemoteToHelperInvocation = false,
-      .shaderTerminateInvocation = false,
+      .shaderDemoteToHelperInvocation = true,
+      .shaderTerminateInvocation = true,
       .subgroupSizeControl = true,
       .computeFullSubgroups = true,
       .synchronization2 = true,
@@ -467,8 +485,9 @@ get_features(const struct panvk_physical_device *device,
       .shaderZeroInitializeWorkgroupMemory = true,
       .dynamicRendering = true,
       .dynamicRenderingLocalRead = true,
-      .shaderIntegerDotProduct = false,
-      .maintenance4 = false,
+      .shaderIntegerDotProduct = true,
+      .maintenance4 = true,
+      .maintenance5 = true,
 
       /* Vulkan 1.4 */
       .shaderSubgroupRotate = true,
@@ -491,6 +510,15 @@ get_features(const struct panvk_physical_device *device,
       .vertexAttributeInstanceRateDivisor = true,
       .vertexAttributeInstanceRateZeroDivisor = true,
 
+      /* VK_EXT_vertex_input_dynamic_state */
+      .vertexInputDynamicState = true,
+
+      /* VK_EXT_depth_bias_control */
+      .depthBiasControl = true,
+      .leastRepresentableValueForceUnormRepresentation = false,
+      .floatRepresentation = false,
+      .depthBiasExact = true,
+
       /* VK_EXT_depth_clip_enable */
       .depthClipEnable = true,
 
@@ -526,7 +554,7 @@ get_features(const struct panvk_physical_device *device,
       .shaderFloatControls2 = true,
 
       /* VK_KHR_shader_quad_control */
-      .shaderQuadControl = false,
+      .shaderQuadControl = true,
 
       /* VK_KHR_shader_relaxed_extended_instruction */
       .shaderRelaxedExtendedInstruction = true,
@@ -543,11 +571,17 @@ get_features(const struct panvk_physical_device *device,
       /* VK_EXT_shader_module_identifier */
       .shaderModuleIdentifier = true,
 
+      /* VK_EXT_shader_replicated_composites */
+      .shaderReplicatedComposites = true,
+
       /* VK_EXT_ycbcr_2plane_444_formats */
       .ycbcr2plane444Formats = arch >= 10,
 
       /* VK_EXT_ycbcr_image_arrays */
       .ycbcrImageArrays = arch >= 10,
+
+      /* VK_KHR_push_descriptor */
+      .pushDescriptor = true,
    };
 }
 
@@ -791,8 +825,7 @@ get_device_properties(const struct panvk_instance *instance,
       .mipmapPrecisionBits = 8,
       /* Software limit. */
       .maxDrawIndexedIndexValue = UINT32_MAX,
-      /* Make it one for now. */
-      .maxDrawIndirectCount = 1,
+      .maxDrawIndirectCount = arch >= 10 ? UINT32_MAX : 1,
       .maxSamplerLodBias = (float)INT16_MAX / 256.0f,
       .maxSamplerAnisotropy = 16,
       .maxViewports = 1,
@@ -1008,7 +1041,7 @@ get_device_properties(const struct panvk_instance *instance,
       /* VK_KHR_vertex_attribute_divisor */
       /* We will have to restrict this a bit for multiview */
       .maxVertexAttribDivisor = UINT32_MAX,
-      .supportsNonZeroFirstInstance = false,
+      .supportsNonZeroFirstInstance = true,
 
       /* VK_KHR_push_descriptor */
       .maxPushDescriptors = MAX_PUSH_DESCRIPTORS,
diff --git a/src/panfrost/vulkan/panvk_vX_cmd_desc_state.c b/src/panfrost/vulkan/panvk_vX_cmd_desc_state.c
index 7c8c232b7c4..389c3d7c0c5 100644
--- a/src/panfrost/vulkan/panvk_vX_cmd_desc_state.c
+++ b/src/panfrost/vulkan/panvk_vX_cmd_desc_state.c
@@ -274,7 +274,7 @@ panvk_per_arch(cmd_prepare_shader_res_table)(
    struct panvk_cmd_buffer *cmdbuf,
    const struct panvk_descriptor_state *desc_state,
    const struct panvk_shader *shader,
-   struct panvk_shader_desc_state *shader_desc_state)
+   struct panvk_shader_desc_state *shader_desc_state, uint32_t repeat_count)
 {
    if (!shader) {
       shader_desc_state->res_table = 0;
@@ -284,34 +284,41 @@ panvk_per_arch(cmd_prepare_shader_res_table)(
    uint32_t first_unused_set = util_last_bit(shader->desc_info.used_set_mask);
    uint32_t res_count = 1 + first_unused_set;
    struct panfrost_ptr ptr =
-      panvk_cmd_alloc_desc_array(cmdbuf, res_count, RESOURCE);
+      panvk_cmd_alloc_desc_array(cmdbuf, res_count * repeat_count, RESOURCE);
    if (!ptr.gpu)
       return VK_ERROR_OUT_OF_DEVICE_MEMORY;
 
    struct mali_resource_packed *res_table = ptr.cpu;
 
-   /* First entry is the driver set table, where we store the vertex attributes,
-    * the dummy sampler, the dynamic buffers and the vertex buffers. */
-   pan_pack(&res_table[0], RESOURCE, cfg) {
-      cfg.address = shader_desc_state->driver_set.dev_addr;
-      cfg.size = shader_desc_state->driver_set.size;
-      cfg.contains_descriptors = cfg.size > 0;
-   }
+   for (uint32_t r = 0; r < repeat_count; r++) {
+      uint64_t drv_set_addr = shader_desc_state->driver_set.dev_addr +
+                              (r * shader_desc_state->driver_set.size);
+      /* First entry is the driver set table, where we store the vertex
+       * attributes, the dummy sampler, the dynamic buffers and the vertex
+       * buffers. */
+      pan_pack(&res_table[0], RESOURCE, cfg) {
+         cfg.address = drv_set_addr;
+         cfg.size = shader_desc_state->driver_set.size;
+         cfg.contains_descriptors = cfg.size > 0;
+      }
 
-   for (uint32_t i = 0; i < first_unused_set; i++) {
-      const struct panvk_descriptor_set *set = desc_state->sets[i];
-
-      pan_pack(&res_table[i + 1], RESOURCE, cfg) {
-         if (shader->desc_info.used_set_mask & BITFIELD_BIT(i)) {
-            cfg.address = set->descs.dev;
-            cfg.contains_descriptors = true;
-            cfg.size = set->desc_count * PANVK_DESCRIPTOR_SIZE;
-         } else {
-            cfg.address = 0;
-            cfg.contains_descriptors = false;
-            cfg.size = 0;
+      for (uint32_t i = 0; i < first_unused_set; i++) {
+         const struct panvk_descriptor_set *set = desc_state->sets[i];
+
+         pan_pack(&res_table[i + 1], RESOURCE, cfg) {
+            if (shader->desc_info.used_set_mask & BITFIELD_BIT(i)) {
+               cfg.address = set->descs.dev;
+               cfg.contains_descriptors = true;
+               cfg.size = set->desc_count * PANVK_DESCRIPTOR_SIZE;
+            } else {
+               cfg.address = 0;
+               cfg.contains_descriptors = false;
+               cfg.size = 0;
+            }
          }
       }
+
+      res_table += first_unused_set + 1;
    }
 
    shader_desc_state->res_table = ptr.gpu | res_count;
diff --git a/src/panfrost/vulkan/panvk_vX_cmd_draw.c b/src/panfrost/vulkan/panvk_vX_cmd_draw.c
index 171a99ec94b..57c63546a12 100644
--- a/src/panfrost/vulkan/panvk_vX_cmd_draw.c
+++ b/src/panfrost/vulkan/panvk_vX_cmd_draw.c
@@ -36,8 +36,9 @@ render_state_set_color_attachment(struct panvk_cmd_buffer *cmdbuf,
 
    fbinfo->rts[index].view = &iview->pview;
    fbinfo->rts[index].crc_valid = &state->render.fb.crc_valid[index];
-   fbinfo->nr_samples =
-      MAX2(fbinfo->nr_samples, pan_image_view_get_nr_samples(&iview->pview));
+   state->render.fb.nr_samples =
+      MAX2(state->render.fb.nr_samples,
+           pan_image_view_get_nr_samples(&iview->pview));
 
    if (att->loadOp == VK_ATTACHMENT_LOAD_OP_CLEAR) {
       enum pipe_format fmt = vk_format_to_pipe_format(iview->vk.format);
@@ -89,8 +90,9 @@ render_state_set_z_attachment(struct panvk_cmd_buffer *cmdbuf,
 
    state->render.zs_pview.planes[0] = &img->planes[0];
    state->render.zs_pview.planes[1] = NULL;
-   fbinfo->nr_samples =
-      MAX2(fbinfo->nr_samples, pan_image_view_get_nr_samples(&iview->pview));
+   state->render.fb.nr_samples =
+      MAX2(state->render.fb.nr_samples,
+           pan_image_view_get_nr_samples(&iview->pview));
    state->render.z_attachment.iview = iview;
 
    /* D24S8 is a single plane format where the depth/stencil are interleaved.
@@ -157,8 +159,9 @@ render_state_set_s_attachment(struct panvk_cmd_buffer *cmdbuf,
       state->render.s_pview.planes[1] = NULL;
    }
 
-   fbinfo->nr_samples =
-      MAX2(fbinfo->nr_samples, pan_image_view_get_nr_samples(&iview->pview));
+   state->render.fb.nr_samples =
+      MAX2(state->render.fb.nr_samples,
+           pan_image_view_get_nr_samples(&iview->pview));
    state->render.s_attachment.iview = iview;
 
    /* If the depth and stencil attachments point to the same image,
@@ -234,9 +237,10 @@ panvk_per_arch(cmd_init_render_state)(struct panvk_cmd_buffer *cmdbuf,
    *fbinfo = (struct pan_fb_info){
       .tile_buf_budget = panfrost_query_optimal_tib_size(phys_dev->model),
       .z_tile_buf_budget = panfrost_query_optimal_z_tib_size(phys_dev->model),
-      .nr_samples = 1,
+      .nr_samples = 0,
       .rt_count = pRenderingInfo->colorAttachmentCount,
    };
+   cmdbuf->state.gfx.render.fb.nr_samples = 1;
 
    assert(pRenderingInfo->colorAttachmentCount <= ARRAY_SIZE(fbinfo->rts));
 
@@ -295,15 +299,30 @@ panvk_per_arch(cmd_init_render_state)(struct panvk_cmd_buffer *cmdbuf,
    }
 
    assert(fbinfo->width && fbinfo->height);
+}
 
-   GENX(pan_select_tile_size)(fbinfo);
+void
+panvk_per_arch(cmd_select_tile_size)(struct panvk_cmd_buffer *cmdbuf)
+{
+   struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
+
+   /* In case we never emitted tiler/framebuffer descriptors, we emit the
+    * current sample count and compute tile size */
+   if (fbinfo->nr_samples == 0) {
+      fbinfo->nr_samples = cmdbuf->state.gfx.render.fb.nr_samples;
+      GENX(pan_select_tile_size)(fbinfo);
 
 #if PAN_ARCH != 6
-   if (fbinfo->cbuf_allocation > fbinfo->tile_buf_budget) {
-      vk_perf(VK_LOG_OBJS(&cmdbuf->vk.base),
-              "Using too much tile-memory, disabling pipelining");
-   }
+      if (fbinfo->cbuf_allocation > fbinfo->tile_buf_budget) {
+         vk_perf(VK_LOG_OBJS(&cmdbuf->vk.base),
+                 "Using too much tile-memory, disabling pipelining");
+      }
 #endif
+   } else {
+      /* In case we already emitted tiler/framebuffer descriptors, we ensure
+       * that the sample count didn't change (this should never happen) */
+      assert(fbinfo->nr_samples == cmdbuf->state.gfx.render.fb.nr_samples);
+   }
 }
 
 void
@@ -790,23 +809,30 @@ panvk_per_arch(cmd_prepare_draw_sysvals)(struct panvk_cmd_buffer *cmdbuf,
 }
 
 VKAPI_ATTR void VKAPI_CALL
-panvk_per_arch(CmdBindVertexBuffers)(VkCommandBuffer commandBuffer,
-                                     uint32_t firstBinding,
-                                     uint32_t bindingCount,
-                                     const VkBuffer *pBuffers,
-                                     const VkDeviceSize *pOffsets)
+panvk_per_arch(CmdBindVertexBuffers2)(VkCommandBuffer commandBuffer,
+                                      uint32_t firstBinding,
+                                      uint32_t bindingCount,
+                                      const VkBuffer *pBuffers,
+                                      const VkDeviceSize *pOffsets,
+                                      const VkDeviceSize *pSizes,
+                                      const VkDeviceSize *pStrides)
 {
    VK_FROM_HANDLE(panvk_cmd_buffer, cmdbuf, commandBuffer);
 
    assert(firstBinding + bindingCount <= MAX_VBS);
 
+   if (pStrides) {
+      vk_cmd_set_vertex_binding_strides(&cmdbuf->vk, firstBinding,
+                                        bindingCount, pStrides);
+   }
+
    for (uint32_t i = 0; i < bindingCount; i++) {
       VK_FROM_HANDLE(panvk_buffer, buffer, pBuffers[i]);
 
       cmdbuf->state.gfx.vb.bufs[firstBinding + i].address =
          panvk_buffer_gpu_ptr(buffer, pOffsets[i]);
-      cmdbuf->state.gfx.vb.bufs[firstBinding + i].size =
-         panvk_buffer_range(buffer, pOffsets[i], VK_WHOLE_SIZE);
+      cmdbuf->state.gfx.vb.bufs[firstBinding + i].size = panvk_buffer_range(
+         buffer, pOffsets[i], pSizes ? pSizes[i] : VK_WHOLE_SIZE);
    }
 
    cmdbuf->state.gfx.vb.count =
@@ -815,15 +841,20 @@ panvk_per_arch(CmdBindVertexBuffers)(VkCommandBuffer commandBuffer,
 }
 
 VKAPI_ATTR void VKAPI_CALL
-panvk_per_arch(CmdBindIndexBuffer)(VkCommandBuffer commandBuffer,
-                                   VkBuffer buffer, VkDeviceSize offset,
-                                   VkIndexType indexType)
+panvk_per_arch(CmdBindIndexBuffer2)(VkCommandBuffer commandBuffer,
+                                    VkBuffer buffer, VkDeviceSize offset,
+                                    VkDeviceSize size, VkIndexType indexType)
 {
    VK_FROM_HANDLE(panvk_cmd_buffer, cmdbuf, commandBuffer);
    VK_FROM_HANDLE(panvk_buffer, buf, buffer);
 
-   cmdbuf->state.gfx.ib.buffer = buf;
-   cmdbuf->state.gfx.ib.offset = offset;
+   cmdbuf->state.gfx.ib.size = panvk_buffer_range(buf, offset, size);
+   assert(cmdbuf->state.gfx.ib.size <= UINT32_MAX);
+   cmdbuf->state.gfx.ib.dev_addr = panvk_buffer_gpu_ptr(buf, offset);
+#if PAN_ARCH <= 7
+   cmdbuf->state.gfx.ib.host_addr =
+      buf && buf->host_ptr ? buf->host_ptr + offset : NULL;
+#endif
    cmdbuf->state.gfx.ib.index_size = vk_index_type_to_bytes(indexType);
    gfx_state_set_dirty(cmdbuf, IB);
 }
diff --git a/src/panfrost/vulkan/panvk_vX_cmd_meta.c b/src/panfrost/vulkan/panvk_vX_cmd_meta.c
index 25bb84d707e..6e5cc6c7cfe 100644
--- a/src/panfrost/vulkan/panvk_vX_cmd_meta.c
+++ b/src/panfrost/vulkan/panvk_vX_cmd_meta.c
@@ -192,13 +192,12 @@ panvk_per_arch(CmdClearAttachments)(VkCommandBuffer commandBuffer,
                                     const VkClearRect *pRects)
 {
    VK_FROM_HANDLE(panvk_cmd_buffer, cmdbuf, commandBuffer);
-   const struct pan_fb_info *fbinfo = &cmdbuf->state.gfx.render.fb.info;
    struct panvk_device *dev = to_panvk_device(cmdbuf->vk.base.device);
    struct panvk_cmd_meta_graphics_save_ctx save = {0};
    struct vk_meta_rendering_info render = {
       .view_mask = cmdbuf->state.gfx.render.view_mask,
-      .samples = fbinfo->nr_samples,
-      .color_attachment_count = fbinfo->rt_count,
+      .samples = cmdbuf->state.gfx.render.fb.nr_samples,
+      .color_attachment_count = cmdbuf->state.gfx.render.fb.info.rt_count,
       .depth_attachment_format = cmdbuf->state.gfx.render.z_attachment.fmt,
       .stencil_attachment_format = cmdbuf->state.gfx.render.s_attachment.fmt,
    };
diff --git a/src/panfrost/vulkan/panvk_vX_cmd_push_constant.c b/src/panfrost/vulkan/panvk_vX_cmd_push_constant.c
index cf33e065f79..3a6ce87bec8 100644
--- a/src/panfrost/vulkan/panvk_vX_cmd_push_constant.c
+++ b/src/panfrost/vulkan/panvk_vX_cmd_push_constant.c
@@ -9,7 +9,8 @@
 
 VkResult
 panvk_per_arch(cmd_prepare_push_uniforms)(struct panvk_cmd_buffer *cmdbuf,
-                                          const struct panvk_shader *shader)
+                                          const struct panvk_shader *shader,
+                                          uint32_t repeat_count)
 {
    uint64_t *push_ptr;
 
@@ -40,7 +41,7 @@ panvk_per_arch(cmd_prepare_push_uniforms)(struct panvk_cmd_buffer *cmdbuf,
    }
 
    struct panfrost_ptr push_uniforms = panvk_cmd_alloc_dev_mem(
-      cmdbuf, desc, shader->fau.total_count * sizeof(uint64_t),
+      cmdbuf, desc, shader->fau.total_count * sizeof(uint64_t) * repeat_count,
       sizeof(uint64_t));
 
    if (!push_uniforms.gpu)
@@ -61,13 +62,16 @@ panvk_per_arch(cmd_prepare_push_uniforms)(struct panvk_cmd_buffer *cmdbuf,
    uint64_t *faus = push_uniforms.cpu;
    uint32_t w, fau = 0;
 
-   /* After packing, the sysvals come first, followed by the user push constants.
-    * The ordering is encoded shader side, so don't re-order these loops. */
-   BITSET_FOREACH_SET(w, shader->fau.used_sysvals, MAX_SYSVAL_FAUS)
-      faus[fau++] = sysvals[w];
+   for (uint32_t i = 0; i < repeat_count; i++) {
+      /* After packing, the sysvals come first, followed by the user push
+       * constants. The ordering is encoded shader side, so don't re-order
+       * these loops. */
+      BITSET_FOREACH_SET(w, shader->fau.used_sysvals, MAX_SYSVAL_FAUS)
+         faus[fau++] = sysvals[w];
 
-   BITSET_FOREACH_SET(w, shader->fau.used_push_consts, MAX_PUSH_CONST_FAUS)
-      faus[fau++] = push_consts[w];
+      BITSET_FOREACH_SET(w, shader->fau.used_push_consts, MAX_PUSH_CONST_FAUS)
+         faus[fau++] = push_consts[w];
+   }
 
    *push_ptr = push_uniforms.gpu;
    return VK_SUCCESS;
diff --git a/src/panfrost/vulkan/panvk_vX_shader.c b/src/panfrost/vulkan/panvk_vX_shader.c
index 7be69ef53de..78243e122f3 100644
--- a/src/panfrost/vulkan/panvk_vX_shader.c
+++ b/src/panfrost/vulkan/panvk_vX_shader.c
@@ -119,6 +119,10 @@ panvk_lower_sysvals(nir_builder *b, nir_instr *instr, void *data)
 #endif
 
    case nir_intrinsic_load_draw_id:
+      /* Multidraw is supported on v10. */
+      if (PAN_ARCH >= 10)
+         return false;
+
       /* TODO: We only implement single-draw direct and indirect draws, so this
        * is sufficient. We'll revisit this when we get around to implementing
        * multidraw. */
@@ -791,10 +795,8 @@ panvk_lower_nir(struct panvk_device *dev, nir_shader *nir,
 #endif
 
    if (gl_shader_stage_uses_workgroup(stage)) {
-      if (!nir->info.shared_memory_explicit_layout) {
-         NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, nir_var_mem_shared,
-                  shared_type_info);
-      }
+      NIR_PASS(_, nir, nir_lower_vars_to_explicit_types, nir_var_mem_shared,
+               shared_type_info);
 
       NIR_PASS(_, nir, nir_lower_explicit_io, nir_var_mem_shared,
                nir_address_format_32bit_offset);
diff --git a/src/util/00-mesa-defaults.conf b/src/util/00-mesa-defaults.conf
index b84928817c5..253a1a1e8f4 100644
--- a/src/util/00-mesa-defaults.conf
+++ b/src/util/00-mesa-defaults.conf
@@ -185,10 +185,6 @@ TODO: document the other workarounds.
             <option name="allow_glsl_extension_directive_midshader" value="true" />
         </application>
 
-        <application name="TombRaider 4-5-6 Remastered" executable="tomb456.exe">
-            <option name="force_gl_depth_component_type_int" value="true" />
-        </application>
-
         <application name="Warsow (32-bit)" executable="warsow.i386">
             <option name="allow_glsl_extension_directive_midshader" value="true" />
         </application>
@@ -1058,6 +1054,9 @@ TODO: document the other workarounds.
         <application name="A Game About Digging A Hole" executable="DiggingGame.exe">
             <option name="force_vk_vendor" value="-1" />
         </application>
+        <application name="Jusant" executable="ASC-Win64-Shipping.exe">
+            <option name="force_vk_vendor" value="-1"/>
+        </application>
         <application name="DIRT 5" executable="DIRT5.exe">
             <option name="fp64_workaround_enabled" value="true" />
         </application>
@@ -1096,6 +1095,9 @@ TODO: document the other workarounds.
         <engine engine_name_match="vkd3d">
             <option name="compression_control_enabled" value="true" />
         </engine>
+        <engine engine_name_match="ANGLE">
+            <option name="custom_border_colors_without_format" value="true" />
+        </engine>
     </device>
     <device driver="dzn">
         <application name="DOOMEternal" executable="DOOMEternalx64vk.exe">
diff --git a/src/util/bfloat.h b/src/util/bfloat.h
new file mode 100644
index 00000000000..02f401917a2
--- /dev/null
+++ b/src/util/bfloat.h
@@ -0,0 +1,69 @@
+/*
+ * Copyright Â© 2025 Intel Corporation
+ * SPDX-License-Identifier: MIT
+ */
+
+#pragma once
+
+#include <assert.h>
+#include <math.h>
+#include <stdint.h>
+#include "u_math.h"
+
+/* When converting a Float NaN value to BFloat16 it is possible that the
+ * significand bits that make the value a NaN will be rounded/truncated off
+ * so ensure at least one significand bit is set.
+ */
+static inline uint16_t
+_mesa_float_nan_to_bfloat_bits(union fi x)
+{
+   assert(isnan(x.f));
+   return x.ui >> 16 | 1 << 6;
+}
+
+/* Round-towards-zero. */
+static inline uint16_t
+_mesa_float_to_bfloat16_bits_rtz(float f)
+{
+   union fi x;
+   x.f = f;
+
+   if (isnan(f))
+      _mesa_float_nan_to_bfloat_bits(x);
+
+   return x.ui >> 16;
+}
+
+/* Round-to-nearest-even. */
+static inline uint16_t
+_mesa_float_to_bfloat16_bits_rte(float f)
+{
+   union fi x;
+   x.f = f;
+
+   if (isnan(f))
+      _mesa_float_nan_to_bfloat_bits(x);
+
+   /* Use the tail part that is discarded to decide rounding,
+    * break the tie with the nearest even.
+    *
+    * Overflow of the significand value will turn to zero and
+    * increment the exponent.  If exponent reaches 0xff, the
+    * value will correctly end up as +/- Inf.
+    */
+   uint32_t result = x.ui >> 16;
+   const uint32_t tail = x.ui & 0xffff;
+   if (tail > 0x8000 || (tail == 0x8000 && (result & 1) == 1))
+      result++;
+
+   return result;
+}
+
+static inline float
+_mesa_bfloat16_bits_to_float(uint16_t bf)
+{
+   union fi x;
+   x.ui = bf << 16;
+
+   return x.f;
+}
diff --git a/src/util/bitscan.h b/src/util/bitscan.h
index 541bf79d076..21bdafd1e49 100644
--- a/src/util/bitscan.h
+++ b/src/util/bitscan.h
@@ -326,6 +326,8 @@ util_bitcount(unsigned n)
 {
 #if defined(HAVE___BUILTIN_POPCOUNT)
    return __builtin_popcount(n);
+#elif __OPENCL_VERSION__
+   return popcount(n);
 #else
    /* K&R classic bitcount.
     *
@@ -366,6 +368,8 @@ util_bitcount64(uint64_t n)
 {
 #ifdef HAVE___BUILTIN_POPCOUNTLL
    return __builtin_popcountll(n);
+#elif __OPENCL_VERSION__
+   return popcount(n);
 #else
    return util_bitcount((unsigned)n) + util_bitcount((unsigned)(n >> 32));
 #endif
diff --git a/src/util/bitset.h b/src/util/bitset.h
index 4fc4dbb6f3e..cf9e59a01cf 100644
--- a/src/util/bitset.h
+++ b/src/util/bitset.h
@@ -280,6 +280,20 @@ __bitclear_clear_range(BITSET_WORD *r, unsigned start, unsigned end)
 #define BITSET_CLEAR_RANGE(x, b, e) \
    __bitclear_clear_range(x, b, e)
 
+static inline unsigned
+__bitset_extract(const BITSET_WORD *r, unsigned start, unsigned count)
+{
+   unsigned shift = start % BITSET_WORDBITS;
+   unsigned lower = r[BITSET_BITWORD(start)] >> shift;
+   unsigned upper = shift ? r[BITSET_BITWORD(start) + 1] << (32 - shift) : 0;
+   unsigned total = lower | upper;
+
+   return count != 32 ? total & ((1u << count) - 1u) : total;
+}
+
+#define BITSET_EXTRACT(x, s, c) \
+   __bitset_extract(x, s, c)
+   
 static inline unsigned
 __bitset_prefix_sum(const BITSET_WORD *x, unsigned b, unsigned n)
 {
diff --git a/src/util/disk_cache.c b/src/util/disk_cache.c
index 9bcfde6907a..3dfde287dc0 100644
--- a/src/util/disk_cache.c
+++ b/src/util/disk_cache.c
@@ -223,17 +223,19 @@ disk_cache_create(const char *gpu_name, const char *driver_id,
    uint64_t max_size = 0;
    char *max_size_str;
 
-   if (debug_get_bool_option("MESA_DISK_CACHE_SINGLE_FILE", false))
+   if (debug_get_bool_option("MESA_DISK_CACHE_SINGLE_FILE", false)) {
       cache_type = DISK_CACHE_SINGLE_FILE;
-   else if (debug_get_bool_option("MESA_DISK_CACHE_MULTI_FILE", false))
-      cache_type = DISK_CACHE_MULTI_FILE;
-   else {
+   } else if (debug_get_bool_option("MESA_DISK_CACHE_DATABASE", false)) {
       cache_type = DISK_CACHE_DATABASE;
       /* Since switching the default cache to <mesa_shader_cache_db>, remove the
        * old cache folder if it hasn't been modified for more than 7 days.
        */
       if (!getenv("MESA_SHADER_CACHE_DIR") && !getenv("MESA_GLSL_CACHE_DIR") && disk_cache_enabled())
          disk_cache_delete_old_cache();
+   } else if (debug_get_bool_option("MESA_DISK_CACHE_MULTI_FILE", true)) {
+      cache_type = DISK_CACHE_MULTI_FILE;
+   } else {
+      return NULL;
    }
 
    max_size_str = getenv("MESA_SHADER_CACHE_MAX_SIZE");
diff --git a/src/util/driconf.h b/src/util/driconf.h
index d46947b3bac..5b0481912c8 100644
--- a/src/util/driconf.h
+++ b/src/util/driconf.h
@@ -291,9 +291,6 @@
 #define DRI_CONF_FORCE_GL_MAP_BUFFER_SYNCHRONIZED(def) \
    DRI_CONF_OPT_B(force_gl_map_buffer_synchronized, def, "Override GL_MAP_UNSYNCHRONIZED_BIT.")
 
-#define DRI_CONF_FORCE_GL_DEPTH_COMPONENT_TYPE_INT(def) \
-   DRI_CONF_OPT_B(force_gl_depth_component_type_int, def, "Override GL_DEPTH_COMPONENT type from unsigned short to unsigned int")
-
 #define DRI_CONF_TRANSCODE_ETC(def) \
    DRI_CONF_OPT_B(transcode_etc, def, "Transcode ETC formats to DXTC if unsupported")
 
diff --git a/src/util/tests/cache_test.cpp b/src/util/tests/cache_test.cpp
index f181178c809..d1772f3240f 100644
--- a/src/util/tests/cache_test.cpp
+++ b/src/util/tests/cache_test.cpp
@@ -819,7 +819,9 @@ TEST_F(Cache, Database)
 #ifndef ENABLE_SHADER_CACHE
    GTEST_SKIP() << "ENABLE_SHADER_CACHE not defined.";
 #else
+   setenv("MESA_DISK_CACHE_MULTI_FILE", "false", 1);
    setenv("MESA_DISK_CACHE_DATABASE_NUM_PARTS", "1", 1);
+   setenv("MESA_DISK_CACHE_DATABASE", "true", 1);
 
    test_disk_cache_create(mem_ctx, CACHE_DIR_NAME_DB, driver_id);
 
@@ -845,6 +847,7 @@ TEST_F(Cache, Database)
 
    test_put_big_sized_entry_to_empty_cache(driver_id);
 
+   setenv("MESA_DISK_CACHE_DATABASE", "false", 1);
    unsetenv("MESA_DISK_CACHE_DATABASE_NUM_PARTS");
 
    err = rmrf_local(CACHE_TEST_TMP);
@@ -872,6 +875,7 @@ TEST_F(Cache, Combined)
 #else
    setenv("MESA_DISK_CACHE_SINGLE_FILE", "true", 1);
    setenv("MESA_DISK_CACHE_MULTI_FILE", "true", 1);
+   setenv("MESA_DISK_CACHE_DATABASE", "false", 1);
 
 #ifdef SHADER_CACHE_DISABLE_BY_DEFAULT
    setenv("MESA_SHADER_CACHE_DISABLE", "false", 1);
@@ -942,6 +946,7 @@ TEST_F(Cache, Combined)
 
    setenv("MESA_DISK_CACHE_SINGLE_FILE", "false", 1);
    setenv("MESA_DISK_CACHE_MULTI_FILE", "false", 1);
+   setenv("MESA_DISK_CACHE_DATABASE", "true", 1);
 
    /* Create MESA-DB cache with enabled retrieval from the read-only
     * cache. */
@@ -1010,6 +1015,7 @@ TEST_F(Cache, Combined)
    disk_cache_destroy(cache_mesa_db);
 
    /* Create default multi-file cache. */
+   setenv("MESA_DISK_CACHE_DATABASE", "false", 1);
    setenv("MESA_DISK_CACHE_MULTI_FILE", "true", 1);
 
    /* Enable read-only cache. */
@@ -1068,7 +1074,9 @@ TEST_F(Cache, Combined)
 
    disk_cache_destroy(cache_multifile);
 
+   unsetenv("MESA_DISK_CACHE_SINGLE_FILE");
    unsetenv("MESA_DISK_CACHE_MULTI_FILE");
+   unsetenv("MESA_DISK_CACHE_DATABASE");
 
    int err = rmrf_local(CACHE_TEST_TMP);
    EXPECT_EQ(err, 0) << "Removing " CACHE_TEST_TMP " again";
@@ -1325,13 +1333,16 @@ TEST_F(Cache, DatabaseMultipartEviction)
 #ifndef ENABLE_SHADER_CACHE
    GTEST_SKIP() << "ENABLE_SHADER_CACHE not defined.";
 #else
+   setenv("MESA_DISK_CACHE_MULTI_FILE", "false", 1);
    setenv("MESA_DISK_CACHE_DATABASE_NUM_PARTS", "3", 1);
+   setenv("MESA_DISK_CACHE_DATABASE", "true", 1);
 
    test_disk_cache_create(mem_ctx, CACHE_DIR_NAME_DB, driver_id);
 
    test_multipart_eviction(driver_id);
 
    unsetenv("MESA_DISK_CACHE_DATABASE_NUM_PARTS");
+   unsetenv("MESA_DISK_CACHE_DATABASE");
 
    int err = rmrf_local(CACHE_TEST_TMP);
    EXPECT_EQ(err, 0) << "Removing " CACHE_TEST_TMP " again";
diff --git a/src/util/u_dynarray.h b/src/util/u_dynarray.h
index 16d81495994..5b95d7da773 100644
--- a/src/util/u_dynarray.h
+++ b/src/util/u_dynarray.h
@@ -135,6 +135,18 @@ util_dynarray_resize_bytes(struct util_dynarray *buf, unsigned nelts, size_t elt
    return p;
 }
 
+MUST_CHECK static inline void *
+util_dynarray_resize_bytes_zero(struct util_dynarray *buf, unsigned nelts, size_t eltsize)
+{
+   size_t size = buf->capacity;
+   void *ret = util_dynarray_resize_bytes(buf, nelts, eltsize);
+   if (ret) {
+      uint8_t *data = (uint8_t*)buf->data;
+      memset(data + size, 0, buf->capacity - size);
+   }
+   return ret;
+}
+
 static inline void
 util_dynarray_clone(struct util_dynarray *buf, void *mem_ctx,
                     struct util_dynarray *from_buf)
@@ -203,11 +215,13 @@ util_dynarray_append_dynarray(struct util_dynarray *buf,
 #define util_dynarray_append_array(buf, type, v, count) do {memcpy(util_dynarray_grow_bytes((buf), count, sizeof(type)), v, sizeof(type) * count);} while(0)
 /* Returns a pointer to the space of the first new element (in case of growth) or NULL on failure. */
 #define util_dynarray_resize(buf, type, nelts) util_dynarray_resize_bytes(buf, (nelts), sizeof(type))
+#define util_dynarray_resize_zero(buf, type, nelts) util_dynarray_resize_bytes_zero(buf, (nelts), sizeof(type))
 #define util_dynarray_grow(buf, type, ngrow) util_dynarray_grow_bytes(buf, (ngrow), sizeof(type))
 #define util_dynarray_top_ptr(buf, type) ((type*)((char*)(buf)->data + (buf)->size - sizeof(type)))
 #define util_dynarray_top(buf, type) *util_dynarray_top_ptr(buf, type)
 #define util_dynarray_pop_ptr(buf, type) ((type*)((char*)(buf)->data + ((buf)->size -= sizeof(type))))
 #define util_dynarray_pop(buf, type) *util_dynarray_pop_ptr(buf, type)
+#define util_dynarray_last_ptr(buf, type) ((type*)((char*)(buf)->data + ((buf)->size - sizeof(type))))
 #define util_dynarray_contains(buf, type) ((buf)->size >= sizeof(type))
 #define util_dynarray_element(buf, type, idx) ((type*)(buf)->data + (idx))
 #define util_dynarray_begin(buf) ((buf)->data)
@@ -243,4 +257,3 @@ util_dynarray_append_dynarray(struct util_dynarray *buf,
 #endif
 
 #endif /* U_DYNARRAY_H */
-
diff --git a/src/virtio/ci/gitlab-ci-inc.yml b/src/virtio/ci/gitlab-ci-inc.yml
index 4805c686fc5..1455413909e 100644
--- a/src/virtio/ci/gitlab-ci-inc.yml
+++ b/src/virtio/ci/gitlab-ci-inc.yml
@@ -8,7 +8,7 @@
       when: on_success
 
 .venus-manual-rules:
-  stage: layered-backends-postmerge
+  stage: layered-backends-nightly
   extends: .no-auto-retry
   rules:
     - !reference [.test, rules]
diff --git a/src/virtio/vdrm/vdrm_vpipe.c b/src/virtio/vdrm/vdrm_vpipe.c
index b9bacb45b30..cd5e872c585 100644
--- a/src/virtio/vdrm/vdrm_vpipe.c
+++ b/src/virtio/vdrm/vdrm_vpipe.c
@@ -774,10 +774,10 @@ init_shmem(struct vpipe_device *vtdev)
    return 0;
 }
 
-struct vdrm_device * vdrm_vpipe_connect(uint32_t context_type);
+struct vdrm_device * vdrm_vpipe_connect(int fd, uint32_t context_type);
 
 struct vdrm_device *
-vdrm_vpipe_connect(uint32_t context_type)
+vdrm_vpipe_connect(int fd, uint32_t context_type)
 {
    struct vpipe_device *vtdev;
    struct vdrm_device *vdev = NULL;
diff --git a/src/vulkan/runtime/bvh/vk_bvh.h b/src/vulkan/runtime/bvh/vk_bvh.h
index f393fa443d4..4052a7b8578 100644
--- a/src/vulkan/runtime/bvh/vk_bvh.h
+++ b/src/vulkan/runtime/bvh/vk_bvh.h
@@ -94,7 +94,14 @@ struct vk_ir_header {
    uint32_t dispatch_size_y;
    uint32_t dispatch_size_z;
    vk_global_sync_data sync_data;
+   /* Generic offset used by the driver during encoding
+    * to write HW nodes in a compact way.
+    */
    uint32_t dst_node_offset;
+   /* Same as dst_node_offset but only useful if the driver
+    * uses a separate memory section for leaf nodes.
+    */
+   uint32_t dst_leaf_node_offset;
 };
 
 struct vk_ir_node {
diff --git a/src/vulkan/runtime/vk_acceleration_structure.c b/src/vulkan/runtime/vk_acceleration_structure.c
index 9ac40993025..7881a52549f 100644
--- a/src/vulkan/runtime/vk_acceleration_structure.c
+++ b/src/vulkan/runtime/vk_acceleration_structure.c
@@ -147,7 +147,7 @@ struct scratch_layout {
 };
 
 static struct build_config
-build_config(uint32_t leaf_count,
+build_config(struct vk_device *device, uint32_t leaf_count,
              const VkAccelerationStructureBuildGeometryInfoKHR *build_info,
              const struct vk_acceleration_structure_build_ops *ops)
 {
@@ -176,7 +176,7 @@ build_config(uint32_t leaf_count,
    for (unsigned i = 0; i < ARRAY_SIZE(config.encode_key); i++) {
       if (!ops->get_encode_key[i])
          break;
-      config.encode_key[i] = ops->get_encode_key[i](leaf_count, build_info->flags);
+      config.encode_key[i] = ops->get_encode_key[i](device, leaf_count, build_info->flags);
    }
 
    return config;
@@ -218,7 +218,7 @@ get_scratch_layout(struct vk_device *device,
    uint32_t ploc_scratch_space = 0;
    uint32_t lbvh_node_space = 0;
 
-   struct build_config config = build_config(leaf_count, build_info,
+   struct build_config config = build_config(device, leaf_count, build_info,
                                              device->as_build_ops);
 
    if (config.internal_type == INTERNAL_BUILD_TYPE_PLOC)
@@ -1039,7 +1039,7 @@ vk_cmd_build_acceleration_structures(VkCommandBuffer commandBuffer,
 
       get_scratch_layout(device, leaf_node_count, pInfos + i, args, &bvh_states[i].scratch);
 
-      struct build_config config = build_config(leaf_node_count, pInfos + i,
+      struct build_config config = build_config(cmd_buffer->base.device, leaf_node_count, pInfos + i,
                                                 device->as_build_ops);
       bvh_states[i].config = config;
 
diff --git a/src/vulkan/runtime/vk_acceleration_structure.h b/src/vulkan/runtime/vk_acceleration_structure.h
index c14cd6ee3b5..31f9d1ba19b 100644
--- a/src/vulkan/runtime/vk_acceleration_structure.h
+++ b/src/vulkan/runtime/vk_acceleration_structure.h
@@ -76,7 +76,8 @@ struct vk_acceleration_structure_build_ops {
                                const VkAccelerationStructureBuildGeometryInfoKHR *pBuildInfo,
                                uint32_t leaf_count);
    VkDeviceSize (*get_update_scratch_size)(struct vk_device *device, uint32_t leaf_count);
-   uint32_t (*get_encode_key[MAX_ENCODE_PASSES])(VkAccelerationStructureTypeKHR type,
+   uint32_t (*get_encode_key[MAX_ENCODE_PASSES])(struct vk_device *device,
+                                                 VkAccelerationStructureTypeKHR type,
                                                  VkBuildAccelerationStructureFlagBitsKHR flags);
    VkResult (*encode_bind_pipeline[MAX_ENCODE_PASSES])(VkCommandBuffer cmd_buffer,
                                                        uint32_t key);
