From 85502947629fcdd72af703a86af57d293243ba07 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 13:36:15 +0200
Subject: [PATCH 01/26] compiler: add float8 glsl types

e4m3fn: 8bit floating point format with 4bit exponent, 3bit mantissa
        and no infinities (finite only)
e5m2:   8bit floating point format with 5bit exponent, 2bit mantissa
        and with infinities.
---
 src/compiler/builtin_types.py                 |  2 ++
 src/compiler/glsl/ast_to_hir.cpp              |  2 ++
 .../glsl/gl_nir_link_uniform_initializers.c   |  2 ++
 src/compiler/glsl/ir_clone.cpp                |  2 ++
 src/compiler/glsl_types.c                     | 26 +++++++++++++++++++
 src/compiler/glsl_types.h                     | 22 ++++++++++++++++
 src/compiler/nir/nir.c                        |  2 ++
 src/compiler/spirv/vtn_variables.c            |  4 +++
 src/intel/compiler/brw_nir.c                  |  2 ++
 src/intel/compiler/elk/elk_shader.cpp         |  2 ++
 src/intel/compiler/elk/elk_vec4_visitor.cpp   |  2 ++
 src/mesa/main/uniform_query.cpp               |  2 ++
 12 files changed, 70 insertions(+)

diff --git a/src/compiler/builtin_types.py b/src/compiler/builtin_types.py
index 99bb1709676..624ca2940e7 100644
--- a/src/compiler/builtin_types.py
+++ b/src/compiler/builtin_types.py
@@ -62,6 +62,8 @@ vector_type("int8_t",    "i8vec",  "GLSL_TYPE_INT8",    "GL_INT8", "_NV")
 vector_type("uint8_t",   "u8vec",  "GLSL_TYPE_UINT8",   "GL_UNSIGNED_INT8", "_NV")
 
 vector_type("bfloat16_t", "bf16vec", "GLSL_TYPE_BFLOAT16", None)
+vector_type("e4m3fn_t", "e4m3fnvec", "GLSL_TYPE_FLOAT_E4M3FN", None)
+vector_type("e5m2_t", "e5m2vec", "GLSL_TYPE_FLOAT_E5M2", None)
 
 simple_type("mat2",   "GL_FLOAT_MAT2",   "GLSL_TYPE_FLOAT", 2, 2)
 simple_type("mat3",   "GL_FLOAT_MAT3",   "GLSL_TYPE_FLOAT", 3, 3)
diff --git a/src/compiler/glsl/ast_to_hir.cpp b/src/compiler/glsl/ast_to_hir.cpp
index 537be820068..c8eee0f8b1a 100644
--- a/src/compiler/glsl/ast_to_hir.cpp
+++ b/src/compiler/glsl/ast_to_hir.cpp
@@ -1136,6 +1136,8 @@ do_comparison(void *mem_ctx, int operation, ir_rvalue *op0, ir_rvalue *op1)
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_BOOL:
diff --git a/src/compiler/glsl/gl_nir_link_uniform_initializers.c b/src/compiler/glsl/gl_nir_link_uniform_initializers.c
index 425b354cf29..272f45e6e9c 100644
--- a/src/compiler/glsl/gl_nir_link_uniform_initializers.c
+++ b/src/compiler/glsl/gl_nir_link_uniform_initializers.c
@@ -164,6 +164,8 @@ copy_constant_to_storage(union gl_constant_value *storage,
          case GLSL_TYPE_INT8:
          case GLSL_TYPE_FLOAT16:
          case GLSL_TYPE_BFLOAT16:
+         case GLSL_TYPE_FLOAT_E4M3FN:
+         case GLSL_TYPE_FLOAT_E5M2:
             /* All other types should have already been filtered by other
              * paths in the caller.
              */
diff --git a/src/compiler/glsl/ir_clone.cpp b/src/compiler/glsl/ir_clone.cpp
index 3c1977b6cc5..665b7b06204 100644
--- a/src/compiler/glsl/ir_clone.cpp
+++ b/src/compiler/glsl/ir_clone.cpp
@@ -339,6 +339,8 @@ ir_constant::clone(void *mem_ctx, struct hash_table *ht) const
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_BOOL:
    case GLSL_TYPE_UINT64:
diff --git a/src/compiler/glsl_types.c b/src/compiler/glsl_types.c
index 10fcd786fac..84d51c980e8 100644
--- a/src/compiler/glsl_types.c
+++ b/src/compiler/glsl_types.c
@@ -349,6 +349,10 @@ glsl_get_base_glsl_type(const glsl_type *t)
       return &glsl_type_builtin_double;
    case GLSL_TYPE_BFLOAT16:
       return &glsl_type_builtin_bfloat16_t;
+   case GLSL_TYPE_FLOAT_E4M3FN:
+      return &glsl_type_builtin_e4m3fn_t;
+   case GLSL_TYPE_FLOAT_E5M2:
+      return &glsl_type_builtin_e5m2_t;
    case GLSL_TYPE_BOOL:
       return &glsl_type_builtin_bool;
    case GLSL_TYPE_UINT64:
@@ -387,6 +391,8 @@ glsl_get_bare_type(const glsl_type *t)
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
@@ -597,6 +603,8 @@ glsl_ ## vname ## _type (unsigned components)    \
 VECN(components, float, vec)
 VECN(components, float16_t, f16vec)
 VECN(components, bfloat16_t, bf16vec)
+VECN(components, e4m3fn_t, e4m3fnvec)
+VECN(components, e5m2_t, e5m2vec)
 VECN(components, double, dvec)
 VECN(components, int, ivec)
 VECN(components, uint, uvec)
@@ -647,6 +655,10 @@ glsl_simple_explicit_type(unsigned base_type, unsigned rows, unsigned columns,
          return glsl_f16vec_type(rows);
       case GLSL_TYPE_BFLOAT16:
          return glsl_bf16vec_type(rows);
+      case GLSL_TYPE_FLOAT_E4M3FN:
+         return glsl_e4m3fnvec_type(rows);
+      case GLSL_TYPE_FLOAT_E5M2:
+         return glsl_e5m2vec_type(rows);
       case GLSL_TYPE_DOUBLE:
          return glsl_dvec_type(rows);
       case GLSL_TYPE_BOOL:
@@ -1749,6 +1761,8 @@ glsl_get_component_slots(const glsl_type *t)
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_BOOL:
       return glsl_get_components(t);
 
@@ -1802,6 +1816,8 @@ glsl_get_component_slots_aligned(const glsl_type *t, unsigned offset)
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_BOOL:
       return glsl_get_components(t);
 
@@ -2889,6 +2905,8 @@ glsl_count_vec4_slots(const glsl_type *t, bool is_gl_vertex_input, bool is_bindl
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_BOOL:
       return t->matrix_columns;
    case GLSL_TYPE_DOUBLE:
@@ -3094,6 +3112,8 @@ encode_type_to_blob(struct blob *blob, const glsl_type *type)
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_UINT8:
    case GLSL_TYPE_INT8:
@@ -3743,6 +3763,8 @@ glsl_get_natural_size_align_bytes(const glsl_type *type,
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
@@ -3803,6 +3825,8 @@ glsl_get_word_size_align_bytes(const glsl_type *type,
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
@@ -3863,6 +3887,8 @@ glsl_get_vec4_size_align_bytes(const glsl_type *type,
    case GLSL_TYPE_INT16:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_UINT:
    case GLSL_TYPE_INT:
    case GLSL_TYPE_FLOAT:
diff --git a/src/compiler/glsl_types.h b/src/compiler/glsl_types.h
index 4afba690abf..e154508439e 100644
--- a/src/compiler/glsl_types.h
+++ b/src/compiler/glsl_types.h
@@ -64,6 +64,8 @@ enum glsl_base_type {
    GLSL_TYPE_FLOAT,
    GLSL_TYPE_FLOAT16,
    GLSL_TYPE_BFLOAT16,
+   GLSL_TYPE_FLOAT_E4M3FN,
+   GLSL_TYPE_FLOAT_E5M2,
    GLSL_TYPE_DOUBLE,
    GLSL_TYPE_UINT8,
    GLSL_TYPE_INT8,
@@ -107,6 +109,8 @@ static unsigned glsl_base_type_bit_size(enum glsl_base_type type)
 
    case GLSL_TYPE_UINT8:
    case GLSL_TYPE_INT8:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
       return 8;
 
    case GLSL_TYPE_DOUBLE:
@@ -176,6 +180,8 @@ glsl_base_type_get_bit_size(const enum glsl_base_type base_type)
 
    case GLSL_TYPE_UINT8:
    case GLSL_TYPE_INT8:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
       return 8;
 
    case GLSL_TYPE_DOUBLE:
@@ -630,6 +636,18 @@ glsl_type_is_bfloat_16(const glsl_type *t)
    return t->base_type == GLSL_TYPE_BFLOAT16;
 }
 
+static inline bool
+glsl_type_is_e4m3fn(const glsl_type *t)
+{
+   return t->base_type == GLSL_TYPE_FLOAT_E4M3FN;
+}
+
+static inline bool
+glsl_type_is_e5m2(const glsl_type *t)
+{
+   return t->base_type == GLSL_TYPE_FLOAT_E5M2;
+}
+
 static inline bool
 glsl_type_is_int_16_32_64(const glsl_type *t)
 {
@@ -947,6 +965,8 @@ static inline const glsl_type *glsl_uint8_t_type(void) { return &glsl_type_built
 static inline const glsl_type *glsl_bool_type(void) { return &glsl_type_builtin_bool; }
 static inline const glsl_type *glsl_atomic_uint_type(void) { return &glsl_type_builtin_atomic_uint; }
 static inline const glsl_type *glsl_bfloat16_t_type(void) { return &glsl_type_builtin_bfloat16_t; }
+static inline const glsl_type *glsl_e4m3fn_t_type(void) { return &glsl_type_builtin_e4m3fn_t; }
+static inline const glsl_type *glsl_e5m2_t_type(void) { return &glsl_type_builtin_e5m2_t; }
 
 static inline const glsl_type *
 glsl_floatN_t_type(unsigned bit_size)
@@ -999,6 +1019,8 @@ glsl_uintN_t_type(unsigned bit_size)
 const glsl_type *glsl_vec_type(unsigned components);
 const glsl_type *glsl_f16vec_type(unsigned components);
 const glsl_type *glsl_bf16vec_type(unsigned components);
+const glsl_type *glsl_e4m3fnvec_type(unsigned components);
+const glsl_type *glsl_e5m2vec_type(unsigned components);
 const glsl_type *glsl_dvec_type(unsigned components);
 const glsl_type *glsl_ivec_type(unsigned components);
 const glsl_type *glsl_uvec_type(unsigned components);
diff --git a/src/compiler/nir/nir.c b/src/compiler/nir/nir.c
index feeb0f4d432..80f3dc5a80f 100644
--- a/src/compiler/nir/nir.c
+++ b/src/compiler/nir/nir.c
@@ -2905,6 +2905,8 @@ nir_get_nir_type_for_glsl_base_type(enum glsl_base_type base_type)
    case GLSL_TYPE_FLOAT:   return nir_type_float32;
    case GLSL_TYPE_FLOAT16: return nir_type_float16;
    case GLSL_TYPE_BFLOAT16: return nir_type_uint16;
+   case GLSL_TYPE_FLOAT_E4M3FN: return nir_type_uint8;
+   case GLSL_TYPE_FLOAT_E5M2: return nir_type_uint8;
    case GLSL_TYPE_DOUBLE:  return nir_type_float64;
       /* clang-format on */
 
diff --git a/src/compiler/spirv/vtn_variables.c b/src/compiler/spirv/vtn_variables.c
index baf359c9f9f..b4f60e27339 100644
--- a/src/compiler/spirv/vtn_variables.c
+++ b/src/compiler/spirv/vtn_variables.c
@@ -717,6 +717,8 @@ _vtn_variable_load_store(struct vtn_builder *b, bool load,
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_BOOL:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_COOPERATIVE_MATRIX:
@@ -811,6 +813,8 @@ _vtn_variable_copy(struct vtn_builder *b, struct vtn_pointer *dest,
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_BOOL:
       /* At this point, we have a scalar, vector, or matrix so we know that
diff --git a/src/intel/compiler/brw_nir.c b/src/intel/compiler/brw_nir.c
index 71f325b1006..bfa8ea5598a 100644
--- a/src/intel/compiler/brw_nir.c
+++ b/src/intel/compiler/brw_nir.c
@@ -43,6 +43,8 @@ type_size_xvec4(const struct glsl_type *type, bool as_vec4, bool bindless)
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_BOOL:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_UINT16:
diff --git a/src/intel/compiler/elk/elk_shader.cpp b/src/intel/compiler/elk/elk_shader.cpp
index 05c0a3b3032..63fa8cdf967 100644
--- a/src/intel/compiler/elk/elk_shader.cpp
+++ b/src/intel/compiler/elk/elk_shader.cpp
@@ -77,6 +77,8 @@ elk_type_for_base_type(const struct glsl_type *type)
    case GLSL_TYPE_ERROR:
    case GLSL_TYPE_COOPERATIVE_MATRIX:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
       unreachable("not reached");
    }
 
diff --git a/src/intel/compiler/elk/elk_vec4_visitor.cpp b/src/intel/compiler/elk/elk_vec4_visitor.cpp
index f5eb25be279..e5022cd037a 100644
--- a/src/intel/compiler/elk/elk_vec4_visitor.cpp
+++ b/src/intel/compiler/elk/elk_vec4_visitor.cpp
@@ -575,6 +575,8 @@ elk_type_size_xvec4(const struct glsl_type *type, bool as_vec4, bool bindless)
    case GLSL_TYPE_FLOAT:
    case GLSL_TYPE_FLOAT16:
    case GLSL_TYPE_BFLOAT16:
+   case GLSL_TYPE_FLOAT_E4M3FN:
+   case GLSL_TYPE_FLOAT_E5M2:
    case GLSL_TYPE_BOOL:
    case GLSL_TYPE_DOUBLE:
    case GLSL_TYPE_UINT16:
diff --git a/src/mesa/main/uniform_query.cpp b/src/mesa/main/uniform_query.cpp
index cb3d79a91da..296d023c9d1 100644
--- a/src/mesa/main/uniform_query.cpp
+++ b/src/mesa/main/uniform_query.cpp
@@ -1011,6 +1011,8 @@ associate_uniform_storage(struct gl_context *ctx,
          case GLSL_TYPE_ERROR:
          case GLSL_TYPE_INTERFACE:
          case GLSL_TYPE_COOPERATIVE_MATRIX:
+         case GLSL_TYPE_FLOAT_E4M3FN:
+         case GLSL_TYPE_FLOAT_E5M2:
             assert(!"Should not get here.");
             break;
          }
-- 
2.49.0


From 857d99a4984ff5f9973f45396046c9c13aa26df1 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Sat, 7 Jun 2025 20:01:05 +0200
Subject: [PATCH 02/26] util: add float8 conversion functions

---
 src/util/float8.c              | 192 +++++++++++
 src/util/float8.h              |  24 ++
 src/util/meson.build           |   2 +
 src/util/tests/float8_test.cpp | 612 +++++++++++++++++++++++++++++++++
 4 files changed, 830 insertions(+)
 create mode 100644 src/util/float8.c
 create mode 100644 src/util/float8.h
 create mode 100644 src/util/tests/float8_test.cpp

diff --git a/src/util/float8.c b/src/util/float8.c
new file mode 100644
index 00000000000..5b77deba0f9
--- /dev/null
+++ b/src/util/float8.c
@@ -0,0 +1,192 @@
+/*
+ * Copyright 2025 Valve Corporation
+ * SPDX-License-Identifier: MIT
+ */
+
+#include "float8.h"
+
+#include <assert.h>
+#include <math.h>
+#include "bitscan.h"
+#include "u_math.h"
+
+#define E4M3FN_NAN 0xff
+#define E4M3FN_MAX 0x7e
+
+#define E5M2_NAN 0xfe
+#define E5M2_MAX 0x7b
+#define E5M2_INF 0x7c
+
+
+uint8_t
+_mesa_float_to_e4m3fn(float val)
+{
+   /* This is a finite only format, out of range values (after rounding)
+    * are converted to NaN.
+    */
+   if (fabs(val) > 464.0f || isnan(val))
+      return E4M3FN_NAN;
+
+   bool s = fui(val) & 0x80000000;
+   int e = ((fui(val) >> 23) & 0xff) - 127 + 7;
+   uint32_t m = fui(val) & 0x7fffff;
+
+   uint8_t res = s ? 0x80 : 0;
+
+   /* Zero, underflow. */
+   if (e < -3)
+      return res;
+
+   bool is_denorm = e <= 0;
+
+   bool round_up = false;
+
+   if (is_denorm) {
+      unsigned offset = 1 - e;
+      round_up |= m & ((1 << offset) - 1);
+      m = (m | 0x800000) >> offset;
+   }
+
+   round_up |= m & 0x17ffff;
+
+   if ((m & 0x080000) && round_up) {
+      m += 0x100000;
+
+      if (m & 0x800000) {
+         m = 0;
+         e += 1;
+      }
+   }
+
+
+   if (!is_denorm)
+      res |= (e << 3);
+   res |= (m >> 20);
+
+   return res;
+}
+
+uint8_t
+_mesa_float_to_e4m3fn_sat(float val)
+{
+   if (val > 448.0f)
+      return E4M3FN_MAX;
+   else if (val < -448.0f)
+      return 0x80 | E4M3FN_MAX;
+   else
+      return _mesa_float_to_e4m3fn(val);
+}
+
+float
+_mesa_e4m3fn_to_float(uint8_t val)
+{
+   bool s = val & 0x80;
+   uint32_t e = (val >> 3) & 0xf;
+   uint32_t m = val & 0x7;
+
+   if (e == 0xf && m == 0x7)
+      return uif(0xffc00000);
+
+   uint32_t res = s ? 0x80000000 : 0;
+
+   if (e == 0 && m == 0) {
+      /* Zero. */
+   } else if (e == 0) {
+      /* Denorm. */
+      unsigned shift = (4 - util_last_bit(m));
+      res |= (127 - 6 - shift) << 23;
+      res |= ((m << shift) & 0x7) << (23 - 3);
+   } else {
+      res |= (e + (127 - 7)) << 23;
+      res |= m << (23 - 3);
+   }
+
+   return uif(res);
+}
+
+uint8_t
+_mesa_float_to_e5m2(float val)
+{
+   bool s = fui(val) & 0x80000000;
+   uint8_t res = s ? 0x80 : 0;
+   if (isnan(val))
+      return E5M2_NAN;
+   else if (fabs(val) >= 61440.0f)
+      return res | E5M2_INF;
+
+   int e = ((fui(val) >> 23) & 0xff) - 127 + 15;
+   uint32_t m = fui(val) & 0x7fffff;
+
+   /* Zero, underflow. */
+   if (e < -2)
+      return res;
+
+   bool is_denorm = e <= 0;
+
+   bool round_up = false;
+
+   if (is_denorm) {
+      unsigned offset = 1 - e;
+      round_up |= m & ((1 << offset) - 1);
+      m = (m | 0x800000) >> offset;
+   }
+
+   round_up |= m & 0x2fffff;
+
+   if ((m & 0x100000) && round_up) {
+      m += 0x200000;
+
+      if (m & 0x800000) {
+         m = 0;
+         e += 1;
+      }
+   }
+
+
+   if (!is_denorm)
+      res |= (e << 2);
+   res |= (m >> 21);
+
+   return res;
+}
+
+uint8_t
+_mesa_float_to_e5m2_sat(float val)
+{
+   if (val > 57344.0f)
+      return E5M2_MAX;
+   else if (val < -57344.0f)
+      return 0x80 | E5M2_MAX;
+   else
+      return _mesa_float_to_e5m2(val);
+}
+
+float
+_mesa_e5m2_to_float(uint8_t val)
+{
+   bool s = val & 0x80;
+   uint32_t e = (val >> 2) & 0x1f;
+   uint32_t m = val & 0x3;
+
+   if (e == 0x1f && m != 0)
+      return uif(0xffc00000);
+
+   uint32_t res = s ? 0x80000000 : 0;
+
+   if (e == 0x1f) {
+      /* Infinity. */
+      res |= 0x7f800000;
+   } else if (e == 0 && m == 0) {
+      /* Zero. */
+   } else if (e == 0) {
+      /* Denorm. */
+      unsigned shift = (3 - util_last_bit(m));
+      res |= (127 - 14 - shift) << 23;
+      res |= ((m << shift) & 0x3) << (23 - 2);
+   } else {
+      res |= (e + (127 - 15)) << 23;
+      res |= m << (23 - 2);
+   }
+
+   return uif(res);
+}
diff --git a/src/util/float8.h b/src/util/float8.h
new file mode 100644
index 00000000000..341794cda2e
--- /dev/null
+++ b/src/util/float8.h
@@ -0,0 +1,24 @@
+/*
+ * Copyright 2025 Valve Corporation
+ * SPDX-License-Identifier: MIT
+ */
+
+#pragma once
+
+#include <stdint.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+uint8_t _mesa_float_to_e4m3fn(float val);
+uint8_t _mesa_float_to_e4m3fn_sat(float val);
+float _mesa_e4m3fn_to_float(uint8_t val);
+
+uint8_t _mesa_float_to_e5m2(float val);
+uint8_t _mesa_float_to_e5m2_sat(float val);
+float _mesa_e5m2_to_float(uint8_t val);
+
+#ifdef __cplusplus
+} /* extern C */
+#endif
diff --git a/src/util/meson.build b/src/util/meson.build
index 0c774e6aeec..bf67bf16692 100644
--- a/src/util/meson.build
+++ b/src/util/meson.build
@@ -44,6 +44,7 @@ files_mesa_util = files(
   'enum_operators.h',
   'fast_idiv_by_const.c',
   'fast_idiv_by_const.h',
+  'float8.c',
   'format_r11g11b10f.h',
   'format_rgb9e5.h',
   'format_srgb.h',
@@ -391,6 +392,7 @@ if with_tests
     'tests/dag_test.cpp',
     'tests/fast_idiv_by_const_test.cpp',
     'tests/fast_urem_by_const_test.cpp',
+    'tests/float8_test.cpp',
     'tests/gc_alloc_tests.cpp',
     'tests/half_float_test.cpp',
     'tests/int_min_max.cpp',
diff --git a/src/util/tests/float8_test.cpp b/src/util/tests/float8_test.cpp
new file mode 100644
index 00000000000..92dc33d4a59
--- /dev/null
+++ b/src/util/tests/float8_test.cpp
@@ -0,0 +1,612 @@
+/*
+ * Copyright 2025 Valve Corporation
+ * SPDX-License-Identifier: MIT
+ */
+
+
+#include <math.h>
+#include <gtest/gtest.h>
+
+#include "util/float8.h"
+#include "u_math.h"
+
+/* Navi48 output. */
+static const uint32_t e4m3fn_lut[256] = {
+   0x0,        /* 0x0 */
+   0x3b000000, /* 0x1 */
+   0x3b800000, /* 0x2 */
+   0x3bc00000, /* 0x3 */
+   0x3c000000, /* 0x4 */
+   0x3c200000, /* 0x5 */
+   0x3c400000, /* 0x6 */
+   0x3c600000, /* 0x7 */
+   0x3c800000, /* 0x8 */
+   0x3c900000, /* 0x9 */
+   0x3ca00000, /* 0xa */
+   0x3cb00000, /* 0xb */
+   0x3cc00000, /* 0xc */
+   0x3cd00000, /* 0xd */
+   0x3ce00000, /* 0xe */
+   0x3cf00000, /* 0xf */
+   0x3d000000, /* 0x10 */
+   0x3d100000, /* 0x11 */
+   0x3d200000, /* 0x12 */
+   0x3d300000, /* 0x13 */
+   0x3d400000, /* 0x14 */
+   0x3d500000, /* 0x15 */
+   0x3d600000, /* 0x16 */
+   0x3d700000, /* 0x17 */
+   0x3d800000, /* 0x18 */
+   0x3d900000, /* 0x19 */
+   0x3da00000, /* 0x1a */
+   0x3db00000, /* 0x1b */
+   0x3dc00000, /* 0x1c */
+   0x3dd00000, /* 0x1d */
+   0x3de00000, /* 0x1e */
+   0x3df00000, /* 0x1f */
+   0x3e000000, /* 0x20 */
+   0x3e100000, /* 0x21 */
+   0x3e200000, /* 0x22 */
+   0x3e300000, /* 0x23 */
+   0x3e400000, /* 0x24 */
+   0x3e500000, /* 0x25 */
+   0x3e600000, /* 0x26 */
+   0x3e700000, /* 0x27 */
+   0x3e800000, /* 0x28 */
+   0x3e900000, /* 0x29 */
+   0x3ea00000, /* 0x2a */
+   0x3eb00000, /* 0x2b */
+   0x3ec00000, /* 0x2c */
+   0x3ed00000, /* 0x2d */
+   0x3ee00000, /* 0x2e */
+   0x3ef00000, /* 0x2f */
+   0x3f000000, /* 0x30 */
+   0x3f100000, /* 0x31 */
+   0x3f200000, /* 0x32 */
+   0x3f300000, /* 0x33 */
+   0x3f400000, /* 0x34 */
+   0x3f500000, /* 0x35 */
+   0x3f600000, /* 0x36 */
+   0x3f700000, /* 0x37 */
+   0x3f800000, /* 0x38 */
+   0x3f900000, /* 0x39 */
+   0x3fa00000, /* 0x3a */
+   0x3fb00000, /* 0x3b */
+   0x3fc00000, /* 0x3c */
+   0x3fd00000, /* 0x3d */
+   0x3fe00000, /* 0x3e */
+   0x3ff00000, /* 0x3f */
+   0x40000000, /* 0x40 */
+   0x40100000, /* 0x41 */
+   0x40200000, /* 0x42 */
+   0x40300000, /* 0x43 */
+   0x40400000, /* 0x44 */
+   0x40500000, /* 0x45 */
+   0x40600000, /* 0x46 */
+   0x40700000, /* 0x47 */
+   0x40800000, /* 0x48 */
+   0x40900000, /* 0x49 */
+   0x40a00000, /* 0x4a */
+   0x40b00000, /* 0x4b */
+   0x40c00000, /* 0x4c */
+   0x40d00000, /* 0x4d */
+   0x40e00000, /* 0x4e */
+   0x40f00000, /* 0x4f */
+   0x41000000, /* 0x50 */
+   0x41100000, /* 0x51 */
+   0x41200000, /* 0x52 */
+   0x41300000, /* 0x53 */
+   0x41400000, /* 0x54 */
+   0x41500000, /* 0x55 */
+   0x41600000, /* 0x56 */
+   0x41700000, /* 0x57 */
+   0x41800000, /* 0x58 */
+   0x41900000, /* 0x59 */
+   0x41a00000, /* 0x5a */
+   0x41b00000, /* 0x5b */
+   0x41c00000, /* 0x5c */
+   0x41d00000, /* 0x5d */
+   0x41e00000, /* 0x5e */
+   0x41f00000, /* 0x5f */
+   0x42000000, /* 0x60 */
+   0x42100000, /* 0x61 */
+   0x42200000, /* 0x62 */
+   0x42300000, /* 0x63 */
+   0x42400000, /* 0x64 */
+   0x42500000, /* 0x65 */
+   0x42600000, /* 0x66 */
+   0x42700000, /* 0x67 */
+   0x42800000, /* 0x68 */
+   0x42900000, /* 0x69 */
+   0x42a00000, /* 0x6a */
+   0x42b00000, /* 0x6b */
+   0x42c00000, /* 0x6c */
+   0x42d00000, /* 0x6d */
+   0x42e00000, /* 0x6e */
+   0x42f00000, /* 0x6f */
+   0x43000000, /* 0x70 */
+   0x43100000, /* 0x71 */
+   0x43200000, /* 0x72 */
+   0x43300000, /* 0x73 */
+   0x43400000, /* 0x74 */
+   0x43500000, /* 0x75 */
+   0x43600000, /* 0x76 */
+   0x43700000, /* 0x77 */
+   0x43800000, /* 0x78 */
+   0x43900000, /* 0x79 */
+   0x43a00000, /* 0x7a */
+   0x43b00000, /* 0x7b */
+   0x43c00000, /* 0x7c */
+   0x43d00000, /* 0x7d */
+   0x43e00000, /* 0x7e */
+   0xffc00000, /* 0x7f */
+   0x80000000, /* 0x80 */
+   0xbb000000, /* 0x81 */
+   0xbb800000, /* 0x82 */
+   0xbbc00000, /* 0x83 */
+   0xbc000000, /* 0x84 */
+   0xbc200000, /* 0x85 */
+   0xbc400000, /* 0x86 */
+   0xbc600000, /* 0x87 */
+   0xbc800000, /* 0x88 */
+   0xbc900000, /* 0x89 */
+   0xbca00000, /* 0x8a */
+   0xbcb00000, /* 0x8b */
+   0xbcc00000, /* 0x8c */
+   0xbcd00000, /* 0x8d */
+   0xbce00000, /* 0x8e */
+   0xbcf00000, /* 0x8f */
+   0xbd000000, /* 0x90 */
+   0xbd100000, /* 0x91 */
+   0xbd200000, /* 0x92 */
+   0xbd300000, /* 0x93 */
+   0xbd400000, /* 0x94 */
+   0xbd500000, /* 0x95 */
+   0xbd600000, /* 0x96 */
+   0xbd700000, /* 0x97 */
+   0xbd800000, /* 0x98 */
+   0xbd900000, /* 0x99 */
+   0xbda00000, /* 0x9a */
+   0xbdb00000, /* 0x9b */
+   0xbdc00000, /* 0x9c */
+   0xbdd00000, /* 0x9d */
+   0xbde00000, /* 0x9e */
+   0xbdf00000, /* 0x9f */
+   0xbe000000, /* 0xa0 */
+   0xbe100000, /* 0xa1 */
+   0xbe200000, /* 0xa2 */
+   0xbe300000, /* 0xa3 */
+   0xbe400000, /* 0xa4 */
+   0xbe500000, /* 0xa5 */
+   0xbe600000, /* 0xa6 */
+   0xbe700000, /* 0xa7 */
+   0xbe800000, /* 0xa8 */
+   0xbe900000, /* 0xa9 */
+   0xbea00000, /* 0xaa */
+   0xbeb00000, /* 0xab */
+   0xbec00000, /* 0xac */
+   0xbed00000, /* 0xad */
+   0xbee00000, /* 0xae */
+   0xbef00000, /* 0xaf */
+   0xbf000000, /* 0xb0 */
+   0xbf100000, /* 0xb1 */
+   0xbf200000, /* 0xb2 */
+   0xbf300000, /* 0xb3 */
+   0xbf400000, /* 0xb4 */
+   0xbf500000, /* 0xb5 */
+   0xbf600000, /* 0xb6 */
+   0xbf700000, /* 0xb7 */
+   0xbf800000, /* 0xb8 */
+   0xbf900000, /* 0xb9 */
+   0xbfa00000, /* 0xba */
+   0xbfb00000, /* 0xbb */
+   0xbfc00000, /* 0xbc */
+   0xbfd00000, /* 0xbd */
+   0xbfe00000, /* 0xbe */
+   0xbff00000, /* 0xbf */
+   0xc0000000, /* 0xc0 */
+   0xc0100000, /* 0xc1 */
+   0xc0200000, /* 0xc2 */
+   0xc0300000, /* 0xc3 */
+   0xc0400000, /* 0xc4 */
+   0xc0500000, /* 0xc5 */
+   0xc0600000, /* 0xc6 */
+   0xc0700000, /* 0xc7 */
+   0xc0800000, /* 0xc8 */
+   0xc0900000, /* 0xc9 */
+   0xc0a00000, /* 0xca */
+   0xc0b00000, /* 0xcb */
+   0xc0c00000, /* 0xcc */
+   0xc0d00000, /* 0xcd */
+   0xc0e00000, /* 0xce */
+   0xc0f00000, /* 0xcf */
+   0xc1000000, /* 0xd0 */
+   0xc1100000, /* 0xd1 */
+   0xc1200000, /* 0xd2 */
+   0xc1300000, /* 0xd3 */
+   0xc1400000, /* 0xd4 */
+   0xc1500000, /* 0xd5 */
+   0xc1600000, /* 0xd6 */
+   0xc1700000, /* 0xd7 */
+   0xc1800000, /* 0xd8 */
+   0xc1900000, /* 0xd9 */
+   0xc1a00000, /* 0xda */
+   0xc1b00000, /* 0xdb */
+   0xc1c00000, /* 0xdc */
+   0xc1d00000, /* 0xdd */
+   0xc1e00000, /* 0xde */
+   0xc1f00000, /* 0xdf */
+   0xc2000000, /* 0xe0 */
+   0xc2100000, /* 0xe1 */
+   0xc2200000, /* 0xe2 */
+   0xc2300000, /* 0xe3 */
+   0xc2400000, /* 0xe4 */
+   0xc2500000, /* 0xe5 */
+   0xc2600000, /* 0xe6 */
+   0xc2700000, /* 0xe7 */
+   0xc2800000, /* 0xe8 */
+   0xc2900000, /* 0xe9 */
+   0xc2a00000, /* 0xea */
+   0xc2b00000, /* 0xeb */
+   0xc2c00000, /* 0xec */
+   0xc2d00000, /* 0xed */
+   0xc2e00000, /* 0xee */
+   0xc2f00000, /* 0xef */
+   0xc3000000, /* 0xf0 */
+   0xc3100000, /* 0xf1 */
+   0xc3200000, /* 0xf2 */
+   0xc3300000, /* 0xf3 */
+   0xc3400000, /* 0xf4 */
+   0xc3500000, /* 0xf5 */
+   0xc3600000, /* 0xf6 */
+   0xc3700000, /* 0xf7 */
+   0xc3800000, /* 0xf8 */
+   0xc3900000, /* 0xf9 */
+   0xc3a00000, /* 0xfa */
+   0xc3b00000, /* 0xfb */
+   0xc3c00000, /* 0xfc */
+   0xc3d00000, /* 0xfd */
+   0xc3e00000, /* 0xfe */
+   0xffc00000, /* 0xff */
+};
+
+static const uint32_t e5m2_lut[256] = {
+   0x0,        /* 0x0 */
+   0x37800000, /* 0x1 */
+   0x38000000, /* 0x2 */
+   0x38400000, /* 0x3 */
+   0x38800000, /* 0x4 */
+   0x38a00000, /* 0x5 */
+   0x38c00000, /* 0x6 */
+   0x38e00000, /* 0x7 */
+   0x39000000, /* 0x8 */
+   0x39200000, /* 0x9 */
+   0x39400000, /* 0xa */
+   0x39600000, /* 0xb */
+   0x39800000, /* 0xc */
+   0x39a00000, /* 0xd */
+   0x39c00000, /* 0xe */
+   0x39e00000, /* 0xf */
+   0x3a000000, /* 0x10 */
+   0x3a200000, /* 0x11 */
+   0x3a400000, /* 0x12 */
+   0x3a600000, /* 0x13 */
+   0x3a800000, /* 0x14 */
+   0x3aa00000, /* 0x15 */
+   0x3ac00000, /* 0x16 */
+   0x3ae00000, /* 0x17 */
+   0x3b000000, /* 0x18 */
+   0x3b200000, /* 0x19 */
+   0x3b400000, /* 0x1a */
+   0x3b600000, /* 0x1b */
+   0x3b800000, /* 0x1c */
+   0x3ba00000, /* 0x1d */
+   0x3bc00000, /* 0x1e */
+   0x3be00000, /* 0x1f */
+   0x3c000000, /* 0x20 */
+   0x3c200000, /* 0x21 */
+   0x3c400000, /* 0x22 */
+   0x3c600000, /* 0x23 */
+   0x3c800000, /* 0x24 */
+   0x3ca00000, /* 0x25 */
+   0x3cc00000, /* 0x26 */
+   0x3ce00000, /* 0x27 */
+   0x3d000000, /* 0x28 */
+   0x3d200000, /* 0x29 */
+   0x3d400000, /* 0x2a */
+   0x3d600000, /* 0x2b */
+   0x3d800000, /* 0x2c */
+   0x3da00000, /* 0x2d */
+   0x3dc00000, /* 0x2e */
+   0x3de00000, /* 0x2f */
+   0x3e000000, /* 0x30 */
+   0x3e200000, /* 0x31 */
+   0x3e400000, /* 0x32 */
+   0x3e600000, /* 0x33 */
+   0x3e800000, /* 0x34 */
+   0x3ea00000, /* 0x35 */
+   0x3ec00000, /* 0x36 */
+   0x3ee00000, /* 0x37 */
+   0x3f000000, /* 0x38 */
+   0x3f200000, /* 0x39 */
+   0x3f400000, /* 0x3a */
+   0x3f600000, /* 0x3b */
+   0x3f800000, /* 0x3c */
+   0x3fa00000, /* 0x3d */
+   0x3fc00000, /* 0x3e */
+   0x3fe00000, /* 0x3f */
+   0x40000000, /* 0x40 */
+   0x40200000, /* 0x41 */
+   0x40400000, /* 0x42 */
+   0x40600000, /* 0x43 */
+   0x40800000, /* 0x44 */
+   0x40a00000, /* 0x45 */
+   0x40c00000, /* 0x46 */
+   0x40e00000, /* 0x47 */
+   0x41000000, /* 0x48 */
+   0x41200000, /* 0x49 */
+   0x41400000, /* 0x4a */
+   0x41600000, /* 0x4b */
+   0x41800000, /* 0x4c */
+   0x41a00000, /* 0x4d */
+   0x41c00000, /* 0x4e */
+   0x41e00000, /* 0x4f */
+   0x42000000, /* 0x50 */
+   0x42200000, /* 0x51 */
+   0x42400000, /* 0x52 */
+   0x42600000, /* 0x53 */
+   0x42800000, /* 0x54 */
+   0x42a00000, /* 0x55 */
+   0x42c00000, /* 0x56 */
+   0x42e00000, /* 0x57 */
+   0x43000000, /* 0x58 */
+   0x43200000, /* 0x59 */
+   0x43400000, /* 0x5a */
+   0x43600000, /* 0x5b */
+   0x43800000, /* 0x5c */
+   0x43a00000, /* 0x5d */
+   0x43c00000, /* 0x5e */
+   0x43e00000, /* 0x5f */
+   0x44000000, /* 0x60 */
+   0x44200000, /* 0x61 */
+   0x44400000, /* 0x62 */
+   0x44600000, /* 0x63 */
+   0x44800000, /* 0x64 */
+   0x44a00000, /* 0x65 */
+   0x44c00000, /* 0x66 */
+   0x44e00000, /* 0x67 */
+   0x45000000, /* 0x68 */
+   0x45200000, /* 0x69 */
+   0x45400000, /* 0x6a */
+   0x45600000, /* 0x6b */
+   0x45800000, /* 0x6c */
+   0x45a00000, /* 0x6d */
+   0x45c00000, /* 0x6e */
+   0x45e00000, /* 0x6f */
+   0x46000000, /* 0x70 */
+   0x46200000, /* 0x71 */
+   0x46400000, /* 0x72 */
+   0x46600000, /* 0x73 */
+   0x46800000, /* 0x74 */
+   0x46a00000, /* 0x75 */
+   0x46c00000, /* 0x76 */
+   0x46e00000, /* 0x77 */
+   0x47000000, /* 0x78 */
+   0x47200000, /* 0x79 */
+   0x47400000, /* 0x7a */
+   0x47600000, /* 0x7b */
+   0x7f800000, /* 0x7c */
+   0xffc00000, /* 0x7d */
+   0xffc00000, /* 0x7e */
+   0xffc00000, /* 0x7f */
+   0x80000000, /* 0x80 */
+   0xb7800000, /* 0x81 */
+   0xb8000000, /* 0x82 */
+   0xb8400000, /* 0x83 */
+   0xb8800000, /* 0x84 */
+   0xb8a00000, /* 0x85 */
+   0xb8c00000, /* 0x86 */
+   0xb8e00000, /* 0x87 */
+   0xb9000000, /* 0x88 */
+   0xb9200000, /* 0x89 */
+   0xb9400000, /* 0x8a */
+   0xb9600000, /* 0x8b */
+   0xb9800000, /* 0x8c */
+   0xb9a00000, /* 0x8d */
+   0xb9c00000, /* 0x8e */
+   0xb9e00000, /* 0x8f */
+   0xba000000, /* 0x90 */
+   0xba200000, /* 0x91 */
+   0xba400000, /* 0x92 */
+   0xba600000, /* 0x93 */
+   0xba800000, /* 0x94 */
+   0xbaa00000, /* 0x95 */
+   0xbac00000, /* 0x96 */
+   0xbae00000, /* 0x97 */
+   0xbb000000, /* 0x98 */
+   0xbb200000, /* 0x99 */
+   0xbb400000, /* 0x9a */
+   0xbb600000, /* 0x9b */
+   0xbb800000, /* 0x9c */
+   0xbba00000, /* 0x9d */
+   0xbbc00000, /* 0x9e */
+   0xbbe00000, /* 0x9f */
+   0xbc000000, /* 0xa0 */
+   0xbc200000, /* 0xa1 */
+   0xbc400000, /* 0xa2 */
+   0xbc600000, /* 0xa3 */
+   0xbc800000, /* 0xa4 */
+   0xbca00000, /* 0xa5 */
+   0xbcc00000, /* 0xa6 */
+   0xbce00000, /* 0xa7 */
+   0xbd000000, /* 0xa8 */
+   0xbd200000, /* 0xa9 */
+   0xbd400000, /* 0xaa */
+   0xbd600000, /* 0xab */
+   0xbd800000, /* 0xac */
+   0xbda00000, /* 0xad */
+   0xbdc00000, /* 0xae */
+   0xbde00000, /* 0xaf */
+   0xbe000000, /* 0xb0 */
+   0xbe200000, /* 0xb1 */
+   0xbe400000, /* 0xb2 */
+   0xbe600000, /* 0xb3 */
+   0xbe800000, /* 0xb4 */
+   0xbea00000, /* 0xb5 */
+   0xbec00000, /* 0xb6 */
+   0xbee00000, /* 0xb7 */
+   0xbf000000, /* 0xb8 */
+   0xbf200000, /* 0xb9 */
+   0xbf400000, /* 0xba */
+   0xbf600000, /* 0xbb */
+   0xbf800000, /* 0xbc */
+   0xbfa00000, /* 0xbd */
+   0xbfc00000, /* 0xbe */
+   0xbfe00000, /* 0xbf */
+   0xc0000000, /* 0xc0 */
+   0xc0200000, /* 0xc1 */
+   0xc0400000, /* 0xc2 */
+   0xc0600000, /* 0xc3 */
+   0xc0800000, /* 0xc4 */
+   0xc0a00000, /* 0xc5 */
+   0xc0c00000, /* 0xc6 */
+   0xc0e00000, /* 0xc7 */
+   0xc1000000, /* 0xc8 */
+   0xc1200000, /* 0xc9 */
+   0xc1400000, /* 0xca */
+   0xc1600000, /* 0xcb */
+   0xc1800000, /* 0xcc */
+   0xc1a00000, /* 0xcd */
+   0xc1c00000, /* 0xce */
+   0xc1e00000, /* 0xcf */
+   0xc2000000, /* 0xd0 */
+   0xc2200000, /* 0xd1 */
+   0xc2400000, /* 0xd2 */
+   0xc2600000, /* 0xd3 */
+   0xc2800000, /* 0xd4 */
+   0xc2a00000, /* 0xd5 */
+   0xc2c00000, /* 0xd6 */
+   0xc2e00000, /* 0xd7 */
+   0xc3000000, /* 0xd8 */
+   0xc3200000, /* 0xd9 */
+   0xc3400000, /* 0xda */
+   0xc3600000, /* 0xdb */
+   0xc3800000, /* 0xdc */
+   0xc3a00000, /* 0xdd */
+   0xc3c00000, /* 0xde */
+   0xc3e00000, /* 0xdf */
+   0xc4000000, /* 0xe0 */
+   0xc4200000, /* 0xe1 */
+   0xc4400000, /* 0xe2 */
+   0xc4600000, /* 0xe3 */
+   0xc4800000, /* 0xe4 */
+   0xc4a00000, /* 0xe5 */
+   0xc4c00000, /* 0xe6 */
+   0xc4e00000, /* 0xe7 */
+   0xc5000000, /* 0xe8 */
+   0xc5200000, /* 0xe9 */
+   0xc5400000, /* 0xea */
+   0xc5600000, /* 0xeb */
+   0xc5800000, /* 0xec */
+   0xc5a00000, /* 0xed */
+   0xc5c00000, /* 0xee */
+   0xc5e00000, /* 0xef */
+   0xc6000000, /* 0xf0 */
+   0xc6200000, /* 0xf1 */
+   0xc6400000, /* 0xf2 */
+   0xc6600000, /* 0xf3 */
+   0xc6800000, /* 0xf4 */
+   0xc6a00000, /* 0xf5 */
+   0xc6c00000, /* 0xf6 */
+   0xc6e00000, /* 0xf7 */
+   0xc7000000, /* 0xf8 */
+   0xc7200000, /* 0xf9 */
+   0xc7400000, /* 0xfa */
+   0xc7600000, /* 0xfb */
+   0xff800000, /* 0xfc */
+   0xffc00000, /* 0xfd */
+   0xffc00000, /* 0xfe */
+   0xffc00000, /* 0xff */
+};
+
+TEST(float8_test, e4m3fn_to_float)
+{
+   for (unsigned i = 0; i < 256; i++) {
+      EXPECT_EQ(fui(_mesa_e4m3fn_to_float(i)), e4m3fn_lut[i]);
+   }
+}
+
+TEST(float8_test, e5m2_to_float)
+{
+   for (unsigned i = 0; i < 256; i++) {
+      EXPECT_EQ(fui(_mesa_e5m2_to_float(i)), e5m2_lut[i]);
+   }
+}
+
+TEST(float8_test, float_to_e4m3fn_exact)
+{
+   for (unsigned i = 0; i < 256; i++) {
+      EXPECT_EQ(fui(_mesa_e4m3fn_to_float(_mesa_float_to_e4m3fn(uif(e4m3fn_lut[i])))), e4m3fn_lut[i]);
+   }
+}
+
+TEST(float8_test, float_to_e5m2_exact)
+{
+   for (unsigned i = 0; i < 256; i++) {
+      EXPECT_EQ(fui(_mesa_e5m2_to_float(_mesa_float_to_e5m2(uif(e5m2_lut[i])))), e5m2_lut[i]);
+   }
+}
+
+TEST(float8_test, float_to_e4m3fn_rtne)
+{
+   /* underflow border */
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x3A800000)), 0);
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x3A800001)), 1);
+
+   /* rounding up border, denorm */
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x3b3fffff)), 1);
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x3b400000)), 2);
+
+   /* rounding down border, denorm */
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x3ba00000)), 2);
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x3ba00001)), 3);
+
+   /* rounding up border, normal */
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x4017ffff)), 0x41);
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x40180000)), 0x42);
+
+   /* rounding down border, normal */
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x40080000)), 0x40);
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x40080001)), 0x41);
+
+   /* overflow border */
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x43e80000)), 0x7e);
+   EXPECT_EQ(_mesa_float_to_e4m3fn(uif(0x43e80001)), 0xff);
+}
+
+TEST(float8_test, float_to_e5m2_rtne)
+{
+   /* underflow border */
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x37000000)), 0);
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x37000001)), 1);
+
+   /* rounding up border, denorm */
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x37bfffff)), 1);
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x37c00000)), 2);
+
+   /* rounding down border, denorm */
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x38200000)), 2);
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x38200001)), 3);
+
+   /* rounding up border, normal */
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x402fffff)), 0x41);
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x40300000)), 0x42);
+
+   /* rounding down border, normal */
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x40100000)), 0x40);
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x40100001)), 0x41);
+
+   /* overflow border */
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x476fffff)), 0x7b);
+   EXPECT_EQ(_mesa_float_to_e5m2(uif(0x47700000)), 0x7c);
+}
-- 
2.49.0


From 94124d651e5f55354d3901901c55575c661a8e53 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 13:14:09 +0200
Subject: [PATCH 03/26] nir: add float8 conversion opcodes

---
 src/compiler/nir/nir_constant_expressions.py | 1 +
 src/compiler/nir/nir_opcodes.py              | 9 +++++++++
 2 files changed, 10 insertions(+)

diff --git a/src/compiler/nir/nir_constant_expressions.py b/src/compiler/nir/nir_constant_expressions.py
index d3c2c729399..794f79ec40c 100644
--- a/src/compiler/nir/nir_constant_expressions.py
+++ b/src/compiler/nir/nir_constant_expressions.py
@@ -61,6 +61,7 @@ template = """\
 #include "util/double.h"
 #include "util/softfloat.h"
 #include "util/bfloat.h"
+#include "util/float8.h"
 #include "util/bigmath.h"
 #include "util/format/format_utils.h"
 #include "util/format_r11g11b10f.h"
diff --git a/src/compiler/nir/nir_opcodes.py b/src/compiler/nir/nir_opcodes.py
index 071fd57b293..3ae903b8654 100644
--- a/src/compiler/nir/nir_opcodes.py
+++ b/src/compiler/nir/nir_opcodes.py
@@ -1765,3 +1765,12 @@ opcode("bfdot2_bfadd", 1, tint16, [2, 2, 1], [tint16, tint16, tint16],
 
    dst.x = _mesa_float_to_bfloat16_bits_rte(acc);
 """)
+
+
+unop_numeric_convert("e4m3fn2f", tfloat32, tuint8, "_mesa_e4m3fn_to_float(src0)")
+unop_numeric_convert("f2e4m3fn", tuint8, tfloat32, "_mesa_float_to_e4m3fn(src0)")
+unop_numeric_convert("f2e4m3fn_sat", tuint8, tfloat32, "_mesa_float_to_e4m3fn_sat(src0)")
+
+unop_numeric_convert("e5m22f", tfloat32, tuint8, "_mesa_e5m2_to_float(src0)")
+unop_numeric_convert("f2e5m2", tuint8, tfloat32, "_mesa_float_to_e5m2(src0)")
+unop_numeric_convert("f2e5m2_sat", tuint8, tfloat32, "_mesa_float_to_e5m2_sat(src0)")
-- 
2.49.0


From bec1400146e5212d7f3a8a959c8f5cfe508a887d Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Sat, 7 Jun 2025 20:22:21 +0200
Subject: [PATCH 04/26] spirv: vtn_has_decoration helper

---
 src/compiler/spirv/spirv_to_nir.c | 29 +++++++++++++++++++++++++++++
 src/compiler/spirv/vtn_private.h  |  3 +++
 2 files changed, 32 insertions(+)

diff --git a/src/compiler/spirv/spirv_to_nir.c b/src/compiler/spirv/spirv_to_nir.c
index 3b956feaf2f..ca1ff6ca7c4 100644
--- a/src/compiler/spirv/spirv_to_nir.c
+++ b/src/compiler/spirv/spirv_to_nir.c
@@ -1023,6 +1023,35 @@ vtn_foreach_decoration(struct vtn_builder *b, struct vtn_value *value,
    _foreach_decoration_helper(b, value, -1, value, cb, data);
 }
 
+struct has_decoration_data {
+   SpvDecoration decoration;
+   bool result;
+};
+
+static void
+has_decoration_cb(struct vtn_builder *b, UNUSED struct vtn_value *val,
+                  UNUSED int member, const struct vtn_decoration *dec,
+                  void *_data)
+{
+   struct has_decoration_data *data = (struct has_decoration_data *)_data;
+   if (dec->decoration == data->decoration)
+      data->result = true;
+}
+
+bool
+vtn_has_decoration(struct vtn_builder *b, struct vtn_value *value,
+                   SpvDecoration decoration)
+{
+   struct has_decoration_data data = {
+      .decoration = decoration,
+      .result = false,
+   };
+
+   vtn_foreach_decoration(b, value, has_decoration_cb, &data);
+
+   return data.result;
+}
+
 void
 vtn_foreach_execution_mode(struct vtn_builder *b, struct vtn_value *value,
                            vtn_execution_mode_foreach_cb cb, void *data)
diff --git a/src/compiler/spirv/vtn_private.h b/src/compiler/spirv/vtn_private.h
index 3b83618778c..83daa2ccf44 100644
--- a/src/compiler/spirv/vtn_private.h
+++ b/src/compiler/spirv/vtn_private.h
@@ -946,6 +946,9 @@ typedef void (*vtn_decoration_foreach_cb)(struct vtn_builder *,
 void vtn_foreach_decoration(struct vtn_builder *b, struct vtn_value *value,
                             vtn_decoration_foreach_cb cb, void *data);
 
+bool vtn_has_decoration(struct vtn_builder *b, struct vtn_value *value,
+                        SpvDecoration decoration);
+
 typedef void (*vtn_execution_mode_foreach_cb)(struct vtn_builder *,
                                               struct vtn_value *,
                                               const struct vtn_decoration *,
-- 
2.49.0


From 8944a0c60b7f3b5c04b9c94b2c155a5b2df13cd7 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Sat, 7 Jun 2025 20:26:38 +0200
Subject: [PATCH 05/26] spirv,nir: emit saturating float8 cmat convert

---
 src/compiler/nir/nir_intrinsics.py | 2 +-
 src/compiler/spirv/vtn_cmat.c      | 5 ++++-
 2 files changed, 5 insertions(+), 2 deletions(-)

diff --git a/src/compiler/nir/nir_intrinsics.py b/src/compiler/nir/nir_intrinsics.py
index f1ae876e321..25b7d3dd362 100644
--- a/src/compiler/nir/nir_intrinsics.py
+++ b/src/compiler/nir/nir_intrinsics.py
@@ -1352,7 +1352,7 @@ intrinsic("cmat_load", src_comp=[-1, -1, 1], indices=[MATRIX_LAYOUT])
 intrinsic("cmat_store", src_comp=[-1, -1, 1], indices=[MATRIX_LAYOUT])
 intrinsic("cmat_length", src_comp=[], dest_comp=1, indices=[CMAT_DESC], bit_sizes=[32])
 intrinsic("cmat_muladd", src_comp=[-1, -1, -1, -1], indices=[SATURATE, CMAT_SIGNED_MASK])
-intrinsic("cmat_convert", src_comp=[-1, -1], indices=[CMAT_SIGNED_MASK])
+intrinsic("cmat_convert", src_comp=[-1, -1], indices=[SATURATE, CMAT_SIGNED_MASK])
 intrinsic("cmat_unary_op", src_comp=[-1, -1], indices=[ALU_OP])
 intrinsic("cmat_binary_op", src_comp=[-1, -1, -1], indices=[ALU_OP])
 intrinsic("cmat_scalar_op", src_comp=[-1, -1, -1], indices=[ALU_OP])
diff --git a/src/compiler/spirv/vtn_cmat.c b/src/compiler/spirv/vtn_cmat.c
index 746c58e2eea..8a1935f0e3d 100644
--- a/src/compiler/spirv/vtn_cmat.c
+++ b/src/compiler/spirv/vtn_cmat.c
@@ -201,6 +201,7 @@ vtn_handle_cooperative_alu(struct vtn_builder *b, struct vtn_value *dest_val,
       case SpvOpFConvert: {
          struct vtn_type *dst_type = vtn_get_type(b, w[1]);
          nir_deref_instr *src = vtn_get_cmat_deref(b, w[3]);
+         struct vtn_value *dest_val = vtn_untyped_value(b, w[2]);
 
          /* The Convert operations define whether integers are interpreted
           * as signed or unsigned regardless of their original type.  So take
@@ -210,9 +211,11 @@ vtn_handle_cooperative_alu(struct vtn_builder *b, struct vtn_value *dest_val,
             (vtn_convert_op_src_type(opcode) == nir_type_int ? NIR_CMAT_A_SIGNED : 0) |
             (vtn_convert_op_dst_type(opcode) == nir_type_int ? NIR_CMAT_RESULT_SIGNED : 0);
 
+         const bool saturate = vtn_has_decoration(b, dest_val, SpvDecorationSaturatedToLargestFloat8NormalConversionEXT);
+
 
          nir_deref_instr *dst = vtn_create_cmat_temporary(b, dst_type->type, "cmat_convert");
-         nir_cmat_convert(&b->nb, &dst->def, &src->def, .cmat_signed_mask = signed_mask);
+         nir_cmat_convert(&b->nb, &dst->def, &src->def, .saturate = saturate, .cmat_signed_mask = signed_mask);
          vtn_push_var_ssa(b, w[2], dst->var);
 
          break;
-- 
2.49.0


From f7e26d51b63af7b394a2200543f90378140ee32f Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 13:40:24 +0200
Subject: [PATCH 06/26] spirv: support float8 conversions

---
 src/compiler/spirv/vtn_alu.c | 37 ++++++++++++++++++++++++++++++++++++
 1 file changed, 37 insertions(+)

diff --git a/src/compiler/spirv/vtn_alu.c b/src/compiler/spirv/vtn_alu.c
index 097bc5bf95c..1a4d89c9ed8 100644
--- a/src/compiler/spirv/vtn_alu.c
+++ b/src/compiler/spirv/vtn_alu.c
@@ -683,6 +683,7 @@ vtn_handle_convert(struct vtn_builder *b, SpvOp opcode,
     *
     * For now we are limiting exposure of bfloat16 in NIR, so apply the
     * extra conversions directly here.
+    * The same applies to E4M3 and E5M2.
     */
    if (glsl_type_is_bfloat_16(glsl_src_type)) {
       nir_def *src_as_float = nir_bf2f(&b->nb, src);
@@ -699,6 +700,42 @@ vtn_handle_convert(struct vtn_builder *b, SpvOp opcode,
          src_as_float = vtn_handle_convert(b, opcode, dest_val, glsl_float_type(),
                                            glsl_src_type, src);
       return nir_f2bf(&b->nb, src_as_float);
+   } else if (glsl_type_is_e4m3fn(glsl_src_type)) {
+      nir_def *src_as_float = nir_e4m3fn2f(&b->nb, src);
+      if (glsl_type_is_float(glsl_dest_type))
+         return src_as_float;
+      return vtn_handle_convert(b, opcode, dest_val, glsl_dest_type,
+                                glsl_float_type(), src_as_float);
+
+   } else if (glsl_type_is_e4m3fn(glsl_dest_type)) {
+      nir_def *src_as_float;
+      if (glsl_type_is_float(glsl_src_type))
+         src_as_float = src;
+      else
+         src_as_float = vtn_handle_convert(b, opcode, dest_val, glsl_float_type(),
+                                           glsl_src_type, src);
+      if (vtn_has_decoration(b, dest_val, SpvDecorationSaturatedToLargestFloat8NormalConversionEXT))
+         return nir_f2e4m3fn_sat(&b->nb, src_as_float);
+      else
+         return nir_f2e4m3fn(&b->nb, src_as_float);
+   } else if (glsl_type_is_e5m2(glsl_src_type)) {
+      nir_def *src_as_float = nir_e5m22f(&b->nb, src);
+      if (glsl_type_is_float(glsl_dest_type))
+         return src_as_float;
+      return vtn_handle_convert(b, opcode, dest_val, glsl_dest_type,
+                                glsl_float_type(), src_as_float);
+
+   } else if (glsl_type_is_e5m2(glsl_dest_type)) {
+      nir_def *src_as_float;
+      if (glsl_type_is_float(glsl_src_type))
+         src_as_float = src;
+      else
+         src_as_float = vtn_handle_convert(b, opcode, dest_val, glsl_float_type(),
+                                           glsl_src_type, src);
+      if (vtn_has_decoration(b, dest_val, SpvDecorationSaturatedToLargestFloat8NormalConversionEXT))
+         return nir_f2e5m2_sat(&b->nb, src_as_float);
+      else
+         return nir_f2e5m2(&b->nb, src_as_float);
    }
 
    /* Use bit_size from NIR source instead of from the original src type,
-- 
2.49.0


From 33ccf1c4234c8a50f7e23e18bed684785671bdd6 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 13:44:18 +0200
Subject: [PATCH 07/26] spirv: create float8 types

---
 src/compiler/spirv/spirv_to_nir.c | 12 ++++++++++++
 1 file changed, 12 insertions(+)

diff --git a/src/compiler/spirv/spirv_to_nir.c b/src/compiler/spirv/spirv_to_nir.c
index ca1ff6ca7c4..3b8c22410e0 100644
--- a/src/compiler/spirv/spirv_to_nir.c
+++ b/src/compiler/spirv/spirv_to_nir.c
@@ -1932,6 +1932,18 @@ vtn_handle_type(struct vtn_builder *b, SpvOp opcode,
          val->type->type = glsl_bfloatN_t_type(bit_size);
          break;
 
+      case SpvFPEncodingFloat8E4M3EXT:
+         vtn_fail_if(bit_size != 8,
+                     "Invalid E4M3 bit size: %u", bit_size);
+         val->type->type = glsl_e4m3fn_t_type();
+         break;
+
+      case SpvFPEncodingFloat8E5M2EXT:
+         vtn_fail_if(bit_size != 8,
+                     "Invalid E5M2 bit size: %u", bit_size);
+         val->type->type = glsl_e5m2_t_type();
+         break;
+
       default:
          vtn_fail("Unsupported OpTypeFloat encoding: %d", encoding);
       }
-- 
2.49.0


From 41fb3d45f2f182a6399e23bed587cc6d8800bab4 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Sun, 8 Jun 2025 14:04:56 +0200
Subject: [PATCH 08/26] spirv: support float8 spec constant op

---
 src/compiler/spirv/spirv_to_nir.c | 70 +++++++++++++++++++++----------
 1 file changed, 47 insertions(+), 23 deletions(-)

diff --git a/src/compiler/spirv/spirv_to_nir.c b/src/compiler/spirv/spirv_to_nir.c
index 3b8c22410e0..656ae5e0472 100644
--- a/src/compiler/spirv/spirv_to_nir.c
+++ b/src/compiler/spirv/spirv_to_nir.c
@@ -41,6 +41,7 @@
 #include "util/u_printf.h"
 #include "util/mesa-blake3.h"
 #include "util/bfloat.h"
+#include "util/float8.h"
 
 #include <stdio.h>
 
@@ -2735,15 +2736,10 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
       default: {
          bool swap;
 
-         const glsl_type *dst_type = val->type->type;
-         const glsl_type *src_type = dst_type;
-
-         const bool bfloat_dst = glsl_type_is_bfloat_16(dst_type);
-         bool bfloat_src = bfloat_dst;
-
-         if (bfloat_dst)
-            dst_type = glsl_float_type();
+         const glsl_type *org_dst_type = val->type->type;
+         const glsl_type *org_src_type = org_dst_type;
 
+         const bool saturate = vtn_has_decoration(b, val, SpvDecorationSaturatedToLargestFloat8NormalConversionEXT);
          unsigned num_components = glsl_get_vector_elements(val->type->type);
 
          vtn_assert(count <= 7);
@@ -2751,18 +2747,22 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
          switch (opcode) {
          case SpvOpSConvert:
          case SpvOpFConvert:
-         case SpvOpUConvert: {
+         case SpvOpUConvert:
             /* We have a different source type in a conversion. */
-            src_type = vtn_get_value_type(b, w[4])->type;
-            bfloat_src = glsl_type_is_bfloat_16(src_type);
-            if (bfloat_src)
-               src_type = glsl_float_type();
+            org_src_type = vtn_get_value_type(b, w[4])->type;
             break;
-         }
          default:
             break;
          };
 
+         const glsl_type *dst_type = org_dst_type;
+         if (glsl_type_is_bfloat_16(dst_type) || glsl_type_is_e4m3fn(dst_type) || glsl_type_is_e5m2(dst_type))
+            dst_type = glsl_float_type();
+
+         const glsl_type *src_type = org_src_type;
+         if (glsl_type_is_bfloat_16(src_type) || glsl_type_is_e4m3fn(src_type) || glsl_type_is_e5m2(src_type))
+            src_type = glsl_float_type();
+
          bool exact;
          nir_op op = vtn_nir_alu_op_for_spirv_opcode(b, opcode, &swap, &exact,
                                                      src_type, dst_type);
@@ -2772,7 +2772,7 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
           */
          assert(!exact);
 
-         unsigned bit_size = glsl_get_bit_size(src_type);
+         unsigned bit_size = glsl_get_bit_size(dst_type);
          nir_const_value src[3][NIR_MAX_VEC_COMPONENTS];
 
          for (unsigned i = 0; i < count - 4; i++) {
@@ -2782,8 +2782,15 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
             /* If this is an unsized source, pull the bit size from the
              * source; otherwise, we'll use the bit size from the destination.
              */
-            if (!nir_alu_type_get_type_size(nir_op_infos[op].input_types[i]))
-               bit_size = glsl_get_bit_size(src_val->type->type);
+            if (!nir_alu_type_get_type_size(nir_op_infos[op].input_types[i])) {
+               if (org_src_type != src_type) {
+                  /* Small float conversion. */
+                  assert(i == 0);
+                  bit_size = glsl_get_bit_size(src_type);
+               } else {
+                  bit_size = glsl_get_bit_size(src_val->type->type);
+               }
+            }
 
             unsigned src_comps = nir_op_infos[op].input_sizes[i] ?
                                  nir_op_infos[op].input_sizes[i] :
@@ -2792,8 +2799,12 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
             unsigned j = swap ? 1 - i : i;
             for (unsigned c = 0; c < src_comps; c++) {
                src[j][c] = src_val->constant->values[c];
-               if (bfloat_src)
+               if (glsl_type_is_bfloat_16(org_src_type))
                   src[j][c].f32 = _mesa_bfloat16_bits_to_float(src[j][c].u16);
+               else if (glsl_type_is_e4m3fn(org_src_type))
+                  src[j][c].f32 = _mesa_e4m3fn_to_float(src[j][c].u8);
+               else if (glsl_type_is_e5m2(org_src_type))
+                  src[j][c].f32 = _mesa_e5m2_to_float(src[j][c].u8);
             }
          }
 
@@ -2824,12 +2835,25 @@ vtn_handle_constant(struct vtn_builder *b, SpvOp opcode,
                                num_components, bit_size, srcs,
                                b->shader->info.float_controls_execution_mode);
 
-         if (bfloat_dst) {
-            for (int i = 0; i < num_components; i++) {
-               const uint16_t b =
-                  _mesa_float_to_bfloat16_bits_rte(val->constant->values[i].f32);
-               val->constant->values[i] = nir_const_value_for_raw_uint(b, 16);
+         for (int i = 0; i < num_components; i++) {
+            uint16_t conv;
+            if (glsl_type_is_bfloat_16(org_dst_type)) {
+               conv = _mesa_float_to_bfloat16_bits_rte(val->constant->values[i].f32);
+            } else if (glsl_type_is_e4m3fn(org_dst_type)) {
+               if (saturate)
+                  conv = _mesa_float_to_e4m3fn_sat(val->constant->values[i].f32);
+               else
+                  conv = _mesa_float_to_e4m3fn(val->constant->values[i].f32);
+            } else if (glsl_type_is_e5m2(org_dst_type)) {
+               if (saturate)
+                  conv = _mesa_float_to_e5m2_sat(val->constant->values[i].f32);
+               else
+                  conv = _mesa_float_to_e5m2(val->constant->values[i].f32);
+            } else {
+               continue;
             }
+
+            val->constant->values[i] = nir_const_value_for_raw_uint(conv, glsl_get_bit_size(org_dst_type));
          }
 
          break;
-- 
2.49.0


From 560493594e501d3ec2a99d9b5ba3d0ac34a26dcd Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Fri, 6 Jun 2025 17:57:14 +0200
Subject: [PATCH 09/26] spirv: support float8 capabilities

---
 src/compiler/spirv/spirv_to_nir.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/src/compiler/spirv/spirv_to_nir.c b/src/compiler/spirv/spirv_to_nir.c
index 656ae5e0472..64463de8695 100644
--- a/src/compiler/spirv/spirv_to_nir.c
+++ b/src/compiler/spirv/spirv_to_nir.c
@@ -79,6 +79,8 @@ static const struct spirv_capabilities implemented_capabilities = {
    .DotProductInputAll = true,
    .DrawParameters = true,
    .ExpectAssumeKHR = true,
+   .Float8EXT = true,
+   .Float8CooperativeMatrixEXT = true,
    .Float16 = true,
    .Float16Buffer = true,
    .Float64 = true,
-- 
2.49.0


From 755fdd0506780ee189f41f3d8c3c9ae993f2f9bc Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 14:04:18 +0200
Subject: [PATCH 10/26] aco: emit float8 wmma

---
 src/amd/compiler/aco_optimizer.cpp                 | 10 +++++++++-
 .../aco_select_nir_intrinsics.cpp                  | 14 ++++++++++++++
 2 files changed, 23 insertions(+), 1 deletion(-)

diff --git a/src/amd/compiler/aco_optimizer.cpp b/src/amd/compiler/aco_optimizer.cpp
index 114de22b508..d392b57e527 100644
--- a/src/amd/compiler/aco_optimizer.cpp
+++ b/src/amd/compiler/aco_optimizer.cpp
@@ -467,7 +467,11 @@ can_apply_sgprs(opt_ctx& ctx, aco_ptr<Instruction>& instr)
           instr->opcode != aco_opcode::v_wmma_f16_16x16x16_f16 &&
           instr->opcode != aco_opcode::v_wmma_bf16_16x16x16_bf16 &&
           instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu8 &&
-          instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu4;
+          instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu4 &&
+          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_fp8_fp8 &&
+          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_fp8_bf8 &&
+          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_bf8_fp8 &&
+          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_bf8_bf8;
 }
 
 /* only covers special cases */
@@ -529,6 +533,10 @@ alu_can_accept_constant(const aco_ptr<Instruction>& instr, unsigned operand)
    case aco_opcode::v_dot2_bf16_bf16: /* TODO */
    case aco_opcode::v_wmma_f32_16x16x16_f16:
    case aco_opcode::v_wmma_f32_16x16x16_bf16:
+   case aco_opcode::v_wmma_f32_16x16x16_fp8_fp8:
+   case aco_opcode::v_wmma_f32_16x16x16_fp8_bf8:
+   case aco_opcode::v_wmma_f32_16x16x16_bf8_fp8:
+   case aco_opcode::v_wmma_f32_16x16x16_bf8_bf8:
    case aco_opcode::v_wmma_f16_16x16x16_f16:
    case aco_opcode::v_wmma_bf16_16x16x16_bf16:
    case aco_opcode::v_wmma_i32_16x16x16_iu8:
diff --git a/src/amd/compiler/instruction_selection/aco_select_nir_intrinsics.cpp b/src/amd/compiler/instruction_selection/aco_select_nir_intrinsics.cpp
index 53c8e840814..e396741ac1f 100644
--- a/src/amd/compiler/instruction_selection/aco_select_nir_intrinsics.cpp
+++ b/src/amd/compiler/instruction_selection/aco_select_nir_intrinsics.cpp
@@ -3762,6 +3762,20 @@ visit_cmat_muladd(isel_context* ctx, nir_intrinsic_instr* instr)
       neg_lo[0] = type_a == GLSL_TYPE_INT8;
       neg_lo[1] = type_b == GLSL_TYPE_INT8;
       break;
+   case GLSL_TYPE_FLOAT_E4M3FN:
+      switch (type_b) {
+      case GLSL_TYPE_FLOAT_E4M3FN: opcode = aco_opcode::v_wmma_f32_16x16x16_fp8_fp8; break;
+      case GLSL_TYPE_FLOAT_E5M2: opcode = aco_opcode::v_wmma_f32_16x16x16_fp8_bf8; break;
+      default: unreachable("invalid cmat_muladd_amd type");
+      }
+      break;
+   case GLSL_TYPE_FLOAT_E5M2:
+      switch (type_b) {
+      case GLSL_TYPE_FLOAT_E4M3FN: opcode = aco_opcode::v_wmma_f32_16x16x16_bf8_fp8; break;
+      case GLSL_TYPE_FLOAT_E5M2: opcode = aco_opcode::v_wmma_f32_16x16x16_bf8_bf8; break;
+      default: unreachable("invalid cmat_muladd_amd type");
+      }
+      break;
    }
    default: unreachable("invalid cmat_muladd_amd type");
    }
-- 
2.49.0


From c7a837814568a3995e476d233603df07cc4fd324 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Fri, 6 Jun 2025 16:42:39 +0200
Subject: [PATCH 11/26] aco/lower_to_hw: support saturating  bf8/fp8
 conversions

Sadly amd only made this behavior controlable with global state.
We reuse the unsupported clamp bit for this purpose and change FP16_OVFL
for each instruction. Ideally we would only do it once for clauses
and after ilp scheduling, but this can be improved in the future.
---
 src/amd/compiler/aco_lower_to_hw_instr.cpp | 16 ++++++++++++++++
 1 file changed, 16 insertions(+)

diff --git a/src/amd/compiler/aco_lower_to_hw_instr.cpp b/src/amd/compiler/aco_lower_to_hw_instr.cpp
index c9a9fa9eb08..297170dde6a 100644
--- a/src/amd/compiler/aco_lower_to_hw_instr.cpp
+++ b/src/amd/compiler/aco_lower_to_hw_instr.cpp
@@ -2928,6 +2928,22 @@ lower_to_hw_instr(Program* program)
             ctx.instructions.emplace_back(std::move(instr));
 
             emit_set_mode(bld, block->fp_mode, set_round, false);
+         } else if ((instr->opcode == aco_opcode::v_cvt_pk_fp8_f32 ||
+                     instr->opcode == aco_opcode::v_cvt_pk_bf8_f32) &&
+                    instr->valu().clamp) {
+            /* FP8/BF8 uses FP16_OVFL(1) to clamp to max finite result. Temporarily set it for the
+             * instruction.
+             * "((size - 1) << 11 | (offset << 6) | register" (MODE is encoded as register 1, we
+             * want to set a single bit at offset 23)
+             */
+            bld.sopk(aco_opcode::s_setreg_imm32_b32, Operand::literal32(1),
+                     (0 << 11) | (23 << 6) | 1);
+
+            instr->valu().clamp = false;
+            ctx.instructions.emplace_back(std::move(instr));
+
+            bld.sopk(aco_opcode::s_setreg_imm32_b32, Operand::literal32(0),
+                     (0 << 11) | (23 << 6) | 1);
          } else if (instr->isMIMG() && instr->mimg().strict_wqm) {
             lower_image_sample(&ctx, instr);
             ctx.instructions.emplace_back(std::move(instr));
-- 
2.49.0


From 7a653e83c6b44cac9fcb68f918082355d2ad7961 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 14:17:47 +0200
Subject: [PATCH 12/26] aco: select fp32 to float8 conversions

---
 src/amd/compiler/aco_ir.cpp                   |  2 +
 .../instruction_selection/aco_isel_setup.cpp  |  4 ++
 .../aco_select_nir_alu.cpp                    | 41 +++++++++++++++++++
 3 files changed, 47 insertions(+)

diff --git a/src/amd/compiler/aco_ir.cpp b/src/amd/compiler/aco_ir.cpp
index 4451599a1ab..b889dc76947 100644
--- a/src/amd/compiler/aco_ir.cpp
+++ b/src/amd/compiler/aco_ir.cpp
@@ -583,6 +583,8 @@ can_use_opsel(amd_gfx_level gfx_level, aco_opcode op, int idx)
    case aco_opcode::v_interp_p10_rtz_f16_f32_inreg: return idx == 0 || idx == 2;
    case aco_opcode::v_interp_p2_f16_f32_inreg:
    case aco_opcode::v_interp_p2_rtz_f16_f32_inreg: return idx == -1 || idx == 0;
+   case aco_opcode::v_cvt_pk_fp8_f32:
+   case aco_opcode::v_cvt_pk_bf8_f32: return idx == -1;
    default:
       return gfx_level >= GFX11 && (get_gfx11_true16_mask(op) & BITFIELD_BIT(idx == -1 ? 3 : idx));
    }
diff --git a/src/amd/compiler/instruction_selection/aco_isel_setup.cpp b/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
index cc15635ddc0..5b4011c23a0 100644
--- a/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
+++ b/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
@@ -412,6 +412,10 @@ init_context(isel_context* ctx, nir_shader* shader)
                       regclasses[alu_instr->src[0].src.ssa->index].type() == RegType::vgpr)
                      type = RegType::vgpr;
                   break;
+               case nir_op_f2e4m3fn:
+               case nir_op_f2e4m3fn_sat:
+               case nir_op_f2e5m2:
+               case nir_op_f2e5m2_sat:
                case nir_op_fmulz:
                case nir_op_ffmaz:
                case nir_op_f2f64:
diff --git a/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp b/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
index 37302231cdd..37ef2f339bb 100644
--- a/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
+++ b/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
@@ -2553,6 +2553,47 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       bld.vop1(aco_opcode::v_cvt_f64_f32, Definition(dst), src);
       break;
    }
+   case nir_op_f2e4m3fn:
+   case nir_op_f2e4m3fn_sat:
+   case nir_op_f2e5m2:
+   case nir_op_f2e5m2_sat: {
+      Operand src[2];
+      if (instr->def.num_components == 2) {
+         Temp pk_src = get_ssa_temp(ctx, instr->src[0].src.ssa);
+         RegClass rc = RegClass(pk_src.regClass().type(), 1);
+         for (unsigned i = 0; i < 2; i++)
+            src[i] = Operand(emit_extract_vector(ctx, pk_src, instr->src[0].swizzle[i], rc));
+      } else {
+         assert(instr->def.num_components == 1);
+         src[0] = Operand(get_alu_src(ctx, instr->src[0]));
+         src[1] = Operand::c32(0);
+      }
+
+      /* Ideally we would want to use FP16_OVFL for the sat variants,
+       * but the ISA doc is wrong and Inf isn't clamped to max_float.
+       */
+      bool clamp = instr->op == nir_op_f2e4m3fn_sat || instr->op == nir_op_f2e5m2_sat;
+      if (clamp) {
+         Temp max_float = bld.copy(
+            bld.def(s1), Operand::c32(fui(instr->op == nir_op_f2e4m3fn_sat ? 448.0f : 57344.0f)));
+
+         for (unsigned i = 0; i < instr->def.num_components; i++) {
+            /* use minimum variant because it preserves NaN. */
+            Instruction* clamped = bld.vop3(aco_opcode::v_minimummaximum_f32, bld.def(v1), src[i],
+                                            max_float, max_float);
+            clamped->valu().neg[2] = true;
+            src[i] = Operand(clamped->definitions[0].getTemp());
+         }
+      }
+
+      aco_opcode opcode = instr->op == nir_op_f2e4m3fn || instr->op == nir_op_f2e4m3fn_sat
+                             ? aco_opcode::v_cvt_pk_fp8_f32
+                             : aco_opcode::v_cvt_pk_bf8_f32;
+      bld.vop3(opcode, Definition(dst), src[0], src[1])->valu();
+      if (instr->def.num_components == 2)
+         emit_split_vector(ctx, dst, 2);
+      break;
+   }
    case nir_op_i2f16: {
       Temp src = get_alu_src(ctx, instr->src[0]);
       const unsigned input_size = instr->src[0].src.ssa->bit_size;
-- 
2.49.0


From ce93d469b5c0259212b656d8b03c79bfda3299ab Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Tue, 10 Jun 2025 15:10:02 +0200
Subject: [PATCH 13/26] nir,aco: optimize FP16_OFVL pattern created by
 vkd3d-proton

---
 src/amd/common/nir/ac_nir.c                   |  1 +
 .../instruction_selection/aco_isel_setup.cpp  |  1 +
 .../aco_select_nir_alu.cpp                    |  7 ++++--
 src/compiler/nir/nir_opcodes.py               |  2 ++
 src/compiler/nir/nir_opt_algebraic.py         | 24 +++++++++++++++++++
 .../nir/nir_shader_compiler_options.h         |  3 +++
 6 files changed, 36 insertions(+), 2 deletions(-)

diff --git a/src/amd/common/nir/ac_nir.c b/src/amd/common/nir/ac_nir.c
index 2a58272f7ef..52911038ae0 100644
--- a/src/amd/common/nir/ac_nir.c
+++ b/src/amd/common/nir/ac_nir.c
@@ -88,6 +88,7 @@ void ac_nir_set_options(struct radeon_info *info, bool use_llvm,
    options->has_msad = true;
    options->has_shfr32 = true;
    options->has_mul24_relaxed = true;
+   options->has_f2e4m3fn_satfn = !use_llvm && info->gfx_level >= GFX12;
    options->lower_int64_options = nir_lower_imul64 | nir_lower_imul_high64 | nir_lower_imul_2x32_64 | nir_lower_divmod64 |
                                   nir_lower_minmax64 | nir_lower_iabs64 | nir_lower_iadd_sat64 | nir_lower_conv64 |
                                   nir_lower_bitfield_extract64;
diff --git a/src/amd/compiler/instruction_selection/aco_isel_setup.cpp b/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
index 5b4011c23a0..ff4889790bf 100644
--- a/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
+++ b/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
@@ -414,6 +414,7 @@ init_context(isel_context* ctx, nir_shader* shader)
                   break;
                case nir_op_f2e4m3fn:
                case nir_op_f2e4m3fn_sat:
+               case nir_op_f2e4m3fn_satfn:
                case nir_op_f2e5m2:
                case nir_op_f2e5m2_sat:
                case nir_op_fmulz:
diff --git a/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp b/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
index 37ef2f339bb..df23ad5649f 100644
--- a/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
+++ b/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
@@ -2555,6 +2555,7 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
    }
    case nir_op_f2e4m3fn:
    case nir_op_f2e4m3fn_sat:
+   case nir_op_f2e4m3fn_satfn:
    case nir_op_f2e5m2:
    case nir_op_f2e5m2_sat: {
       Operand src[2];
@@ -2586,10 +2587,12 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
          }
       }
 
-      aco_opcode opcode = instr->op == nir_op_f2e4m3fn || instr->op == nir_op_f2e4m3fn_sat
+      aco_opcode opcode = instr->op == nir_op_f2e4m3fn || instr->op == nir_op_f2e4m3fn_sat ||
+                                instr->op == nir_op_f2e4m3fn_satfn
                              ? aco_opcode::v_cvt_pk_fp8_f32
                              : aco_opcode::v_cvt_pk_bf8_f32;
-      bld.vop3(opcode, Definition(dst), src[0], src[1])->valu();
+      bld.vop3(opcode, Definition(dst), src[0], src[1])->valu().clamp =
+         instr->op == nir_op_f2e4m3fn_satfn;
       if (instr->def.num_components == 2)
          emit_split_vector(ctx, dst, 2);
       break;
diff --git a/src/compiler/nir/nir_opcodes.py b/src/compiler/nir/nir_opcodes.py
index 3ae903b8654..05a100201dd 100644
--- a/src/compiler/nir/nir_opcodes.py
+++ b/src/compiler/nir/nir_opcodes.py
@@ -1770,6 +1770,8 @@ opcode("bfdot2_bfadd", 1, tint16, [2, 2, 1], [tint16, tint16, tint16],
 unop_numeric_convert("e4m3fn2f", tfloat32, tuint8, "_mesa_e4m3fn_to_float(src0)")
 unop_numeric_convert("f2e4m3fn", tuint8, tfloat32, "_mesa_float_to_e4m3fn(src0)")
 unop_numeric_convert("f2e4m3fn_sat", tuint8, tfloat32, "_mesa_float_to_e4m3fn_sat(src0)")
+# AMD specific conversion that clamps finite values but not inf (GFX12 FP16_OVFL=1 behavior)
+unop_numeric_convert("f2e4m3fn_satfn", tuint8, tfloat32, "isinf(src0) ? 0x7f : _mesa_float_to_e4m3fn_sat(src0)")
 
 unop_numeric_convert("e5m22f", tfloat32, tuint8, "_mesa_e5m2_to_float(src0)")
 unop_numeric_convert("f2e5m2", tuint8, tfloat32, "_mesa_float_to_e5m2(src0)")
diff --git a/src/compiler/nir/nir_opt_algebraic.py b/src/compiler/nir/nir_opt_algebraic.py
index f6b360ccf01..e9744c7c6aa 100644
--- a/src/compiler/nir/nir_opt_algebraic.py
+++ b/src/compiler/nir/nir_opt_algebraic.py
@@ -3144,6 +3144,30 @@ optimizations += [
    (('iadd', ('msad_4x8', a, b, 0), c), ('msad_4x8', a, b, c)),
 ]
 
+# VKD3D-Proton patterns for FP16_OVFL=1 conversion to e4m3fn
+def vkd3d_proton_f2e4m3_ovfl(variant, x, nan):
+   if variant == 0:
+      cond = ('feq', ('fabs', x), float('inf'))
+   elif variant == 1:
+      cond = ('feq', f'{x}(is_not_negative)', float('inf'))
+   elif variant == 2:
+      cond = ('feq', f'{x}(is_not_positive)', -float('inf'))
+
+   return ('bcsel', cond, f'#{nan}(is_nan)', x)
+
+
+for var in range(3):
+   optimizations += [
+      (('f2e4m3fn_sat', vkd3d_proton_f2e4m3_ovfl(var, a, b)),
+       ('f2e4m3fn_satfn', a), 'options->has_f2e4m3fn_satfn'),
+   ]
+
+for var0, var1 in itertools.product(range(3), repeat=2):
+   optimizations += [
+      (('f2e4m3fn_sat', ('vec2', vkd3d_proton_f2e4m3_ovfl(var0, a, b),
+                                 vkd3d_proton_f2e4m3_ovfl(var1, c, d))),
+       ('f2e4m3fn_satfn', ('vec2', a, c)), 'options->has_f2e4m3fn_satfn'),
+   ]
 
 # "all_equal(eq(a, b), vec(~0))" is the same as "all_equal(a, b)"
 # "any_nequal(neq(a, b), vec(0))" is the same as "any_nequal(a, b)"
diff --git a/src/compiler/nir/nir_shader_compiler_options.h b/src/compiler/nir/nir_shader_compiler_options.h
index b1be138e135..e2815072bef 100644
--- a/src/compiler/nir/nir_shader_compiler_options.h
+++ b/src/compiler/nir/nir_shader_compiler_options.h
@@ -638,6 +638,9 @@ typedef struct nir_shader_compiler_options {
    /** Backend support msad_u4x8. */
    bool has_msad;
 
+   /** Backend supports f2e4m3fn_satfn */
+   bool has_f2e4m3fn_satfn;
+
    /**
     * Is this the Intel vec4 backend?
     *
-- 
2.49.0


From 34788c5102887a1da3e60fb6e11714ee1653b4e6 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Tue, 15 Apr 2025 15:50:35 +0200
Subject: [PATCH 14/26] aco/isel: fix get_alu_src with 8bit vec2 source

---
 src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp b/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
index df23ad5649f..9fb05170dbe 100644
--- a/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
+++ b/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
@@ -101,7 +101,7 @@ get_alu_src(struct isel_context* ctx, nir_alu_src src, unsigned size = 1)
          elems[i] = emit_extract_vector(ctx, vec, src.swizzle[i], elem_rc);
          vec_instr->operands[i] = Operand{elems[i]};
       }
-      Temp dst = ctx->program->allocateTmp(RegClass(vec.type(), elem_size * size / 4));
+      Temp dst = ctx->program->allocateTmp(RegClass::get(vec.type(), elem_size * size));
       vec_instr->definitions[0] = Definition(dst);
       ctx->block->instructions.emplace_back(std::move(vec_instr));
       ctx->allocated_vec.emplace(dst.id(), elems);
-- 
2.49.0


From 08e4fcaba5db150f7b52187730d2183892994160 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 14:26:16 +0200
Subject: [PATCH 15/26] aco: select float8 to fp32 conversions

---
 src/amd/compiler/aco_ir.cpp                   |  2 ++
 .../instruction_selection/aco_isel_setup.cpp  |  2 ++
 .../aco_select_nir_alu.cpp                    | 24 +++++++++++++++++++
 3 files changed, 28 insertions(+)

diff --git a/src/amd/compiler/aco_ir.cpp b/src/amd/compiler/aco_ir.cpp
index b889dc76947..8ae1dc9e3cf 100644
--- a/src/amd/compiler/aco_ir.cpp
+++ b/src/amd/compiler/aco_ir.cpp
@@ -716,6 +716,8 @@ get_gfx11_true16_mask(aco_opcode op)
    case aco_opcode::v_and_b16:
    case aco_opcode::v_or_b16:
    case aco_opcode::v_xor_b16: return 0x3 | 0x8;
+   case aco_opcode::v_cvt_pk_f32_fp8:
+   case aco_opcode::v_cvt_pk_f32_bf8:
    case aco_opcode::v_cvt_f32_f16:
    case aco_opcode::v_cvt_i32_i16:
    case aco_opcode::v_cvt_u32_u16: return 0x1;
diff --git a/src/amd/compiler/instruction_selection/aco_isel_setup.cpp b/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
index ff4889790bf..fba6bdd55ff 100644
--- a/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
+++ b/src/amd/compiler/instruction_selection/aco_isel_setup.cpp
@@ -417,6 +417,8 @@ init_context(isel_context* ctx, nir_shader* shader)
                case nir_op_f2e4m3fn_satfn:
                case nir_op_f2e5m2:
                case nir_op_f2e5m2_sat:
+               case nir_op_e4m3fn2f:
+               case nir_op_e5m22f:
                case nir_op_fmulz:
                case nir_op_ffmaz:
                case nir_op_f2f64:
diff --git a/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp b/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
index 9fb05170dbe..4e9f06cd6dd 100644
--- a/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
+++ b/src/amd/compiler/instruction_selection/aco_select_nir_alu.cpp
@@ -2597,6 +2597,30 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
          emit_split_vector(ctx, dst, 2);
       break;
    }
+   case nir_op_e4m3fn2f: {
+      if (instr->def.num_components == 2) {
+         Temp src = get_alu_src(ctx, instr->src[0], 2);
+         bld.vop1(aco_opcode::v_cvt_pk_f32_fp8, Definition(dst), src);
+         emit_split_vector(ctx, dst, 2);
+      } else {
+         Temp src = get_alu_src(ctx, instr->src[0]);
+         assert(instr->def.num_components == 1);
+         bld.vop1(aco_opcode::v_cvt_f32_fp8, Definition(dst), src);
+      }
+      break;
+   }
+   case nir_op_e5m22f: {
+      if (instr->def.num_components == 2) {
+         Temp src = get_alu_src(ctx, instr->src[0], 2);
+         bld.vop1(aco_opcode::v_cvt_pk_f32_bf8, Definition(dst), src);
+         emit_split_vector(ctx, dst, 2);
+      } else {
+         Temp src = get_alu_src(ctx, instr->src[0]);
+         assert(instr->def.num_components == 1);
+         bld.vop1(aco_opcode::v_cvt_f32_bf8, Definition(dst), src);
+      }
+      break;
+   }
    case nir_op_i2f16: {
       Temp src = get_alu_src(ctx, instr->src[0]);
       const unsigned input_size = instr->src[0].src.ssa->bit_size;
-- 
2.49.0


From 22cd834f781b202415bb8e882e484ebde92e061f Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 14:31:26 +0200
Subject: [PATCH 16/26] radv: vectorize float8 conversions

---
 src/amd/vulkan/radv_pipeline.c | 17 +++++++++++++++--
 1 file changed, 15 insertions(+), 2 deletions(-)

diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index d6f2acb2904..511495acb94 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -265,6 +265,20 @@ opt_vectorize_callback(const nir_instr *instr, const void *_)
       return 1;
 
    const nir_alu_instr *alu = nir_instr_as_alu(instr);
+
+   switch (alu->op) {
+   case nir_op_f2e4m3fn:
+   case nir_op_f2e4m3fn_sat:
+   case nir_op_f2e4m3fn_satfn:
+   case nir_op_f2e5m2:
+   case nir_op_f2e5m2_sat:
+   case nir_op_e4m3fn2f:
+   case nir_op_e5m22f:
+      return 2;
+   default:
+      break;
+   }
+
    const unsigned bit_size = alu->def.bit_size;
    if (bit_size != 16)
       return 1;
@@ -587,8 +601,7 @@ radv_postprocess_nir(struct radv_device *device, const struct radv_graphics_stat
          NIR_PASS(_, stage->nir, nir_opt_dce);
       }
 
-      if (!stage->key.optimisations_disabled &&
-          ((stage->nir->info.bit_sizes_int | stage->nir->info.bit_sizes_float) & 16)) {
+      if (!stage->key.optimisations_disabled) {
          NIR_PASS(_, stage->nir, nir_opt_vectorize, opt_vectorize_callback, device);
       }
    }
-- 
2.49.0


From a8429eedb2515a2d816165581810d92ecf060660 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 9 Apr 2025 17:48:51 +0200
Subject: [PATCH 17/26] radv/nir/lower_cmat: handle float8 conversions

---
 .../nir/radv_nir_lower_cooperative_matrix.c   | 27 ++++++++++++++++---
 1 file changed, 23 insertions(+), 4 deletions(-)

diff --git a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
index 9e12b0964da..45a26c0001e 100644
--- a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
+++ b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
@@ -182,17 +182,35 @@ radv_get_base_row(nir_builder *b, struct glsl_cmat_description desc, const lower
 }
 
 static nir_def *
-convert_base_type(nir_builder *b, nir_def *src, enum glsl_base_type src_type, enum glsl_base_type dst_type)
+convert_base_type(nir_builder *b, nir_def *src, enum glsl_base_type src_type, enum glsl_base_type dst_type, bool sat)
 {
    if (dst_type == src_type)
       return src;
 
    if (src_type == GLSL_TYPE_BFLOAT16) {
       src = nir_bf2f(b, src);
-      return convert_base_type(b, src, GLSL_TYPE_FLOAT, dst_type);
+      return convert_base_type(b, src, GLSL_TYPE_FLOAT, dst_type, sat);
    } else if (dst_type == GLSL_TYPE_BFLOAT16) {
-      src = convert_base_type(b, src, src_type, GLSL_TYPE_FLOAT);
+      src = convert_base_type(b, src, src_type, GLSL_TYPE_FLOAT, sat);
       return nir_f2bf(b, src);
+   } else if (src_type == GLSL_TYPE_FLOAT_E4M3FN) {
+      src = nir_e4m3fn2f(b, src);
+      return convert_base_type(b, src, GLSL_TYPE_FLOAT, dst_type, sat);
+   } else if (dst_type == GLSL_TYPE_FLOAT_E4M3FN) {
+      src = convert_base_type(b, src, src_type, GLSL_TYPE_FLOAT, sat);
+      if (sat)
+         return nir_f2e4m3fn_sat(b, src);
+      else
+         return nir_f2e4m3fn(b, src);
+   } else if (src_type == GLSL_TYPE_FLOAT_E5M2) {
+      src = nir_e5m22f(b, src);
+      return convert_base_type(b, src, GLSL_TYPE_FLOAT, dst_type, sat);
+   } else if (dst_type == GLSL_TYPE_FLOAT_E5M2) {
+      src = convert_base_type(b, src, src_type, GLSL_TYPE_FLOAT, sat);
+      if (sat)
+         return nir_f2e5m2_sat(b, src);
+      else
+         return nir_f2e5m2(b, src);
    }
 
    nir_op op = nir_type_conversion_op(nir_get_nir_type_for_glsl_base_type(src_type),
@@ -466,6 +484,7 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                nir_def *src = radv_nir_load_cmat(&b, &params, intr->src[1].ssa);
 
                const nir_cmat_signed cmat_signed_mask = nir_intrinsic_cmat_signed_mask(intr);
+               const bool sat = nir_intrinsic_saturate(intr);
 
                enum glsl_base_type dst_element_type = glsl_apply_signedness_to_base_type(
                   dst_desc.element_type, cmat_signed_mask & NIR_CMAT_RESULT_SIGNED);
@@ -484,7 +503,7 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                   src = nir_vec(&b, components, src->num_components / scale);
                }
 
-               nir_def *ret = convert_base_type(&b, src, src_element_type, dst_element_type);
+               nir_def *ret = convert_base_type(&b, src, src_element_type, dst_element_type, sat);
 
                if (dst_mul > src_mul) {
                   nir_def *components[NIR_MAX_VEC_COMPONENTS];
-- 
2.49.0


From a4e4d10b1e6e4c4a12287f6b301fb25413e85846 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Fri, 6 Jun 2025 18:03:53 +0200
Subject: [PATCH 18/26] radv: expose VK_EXT_shader_float8

---
 docs/features.txt                     |  1 +
 docs/relnotes/new_features.txt        |  1 +
 src/amd/vulkan/radv_physical_device.c | 29 +++++++++++++++++++++++++++
 3 files changed, 31 insertions(+)

diff --git a/docs/features.txt b/docs/features.txt
index 8e77638207f..fa684bc8fc2 100644
--- a/docs/features.txt
+++ b/docs/features.txt
@@ -651,6 +651,7 @@ Khronos extensions that are not part of any Vulkan version:
   VK_EXT_sample_locations                               DONE (anv, hasvk, hk, nvk, radv, tu/a650+, vn)
   VK_EXT_shader_atomic_float                            DONE (anv, hasvk, lvp, radv, vn)
   VK_EXT_shader_atomic_float2                           DONE (anv, lvp, radv, vn)
+  VK_EXT_shader_float8                                  DONE (radv/gfx12+)
   VK_EXT_shader_image_atomic_int64                      DONE (anv, nvk, radv, vn)
   VK_EXT_shader_object                                  DONE (lvp, hk, nvk, radv)
   VK_EXT_shader_replicated_composites                   DONE (anv, dzn, hasvk, lvp, nvk, panvk, radv, tu, vn)
diff --git a/docs/relnotes/new_features.txt b/docs/relnotes/new_features.txt
index 47b6f2793e8..b7b9b1e5aea 100644
--- a/docs/relnotes/new_features.txt
+++ b/docs/relnotes/new_features.txt
@@ -49,3 +49,4 @@ VK_KHR_unified_image_layouts on RADV (RDNA3+)
 VK_KHR_vulkan_memory_model on panvk
 VK_KHR_present_wait2
 VK_EXT_descriptor_indexing on panvk/v10+
+VK_KHR_shader_float8 on RADV (RDNA4+)
diff --git a/src/amd/vulkan/radv_physical_device.c b/src/amd/vulkan/radv_physical_device.c
index af24baf8b96..2729c1d56d3 100644
--- a/src/amd/vulkan/radv_physical_device.c
+++ b/src/amd/vulkan/radv_physical_device.c
@@ -706,6 +706,7 @@ radv_physical_device_get_supported_extensions(const struct radv_physical_device
       .EXT_shader_atomic_float = true,
       .EXT_shader_atomic_float2 = true,
       .EXT_shader_demote_to_helper_invocation = true,
+      .EXT_shader_float8 = pdev->info.gfx_level >= GFX12 && !pdev->use_llvm,
       .EXT_shader_image_atomic_int64 = true,
       .EXT_shader_module_identifier = true,
       .EXT_shader_object = !pdev->use_llvm && !(instance->debug_flags & RADV_DEBUG_NO_ESO),
@@ -1330,6 +1331,10 @@ radv_physical_device_get_features(const struct radv_physical_device *pdev, struc
       /* VK_KHR_unified_layouts */
       .unifiedImageLayouts = true,
       .unifiedImageLayoutsVideo = true,
+
+      /* VK_EXT_shader_float8 */
+      .shaderFloat8 = true,
+      .shaderFloat8CooperativeMatrix = radv_cooperative_matrix_enabled(pdev),
    };
 }
 
@@ -2893,6 +2898,30 @@ radv_GetPhysicalDeviceCooperativeMatrixPropertiesKHR(VkPhysicalDevice physicalDe
    VK_FROM_HANDLE(radv_physical_device, pdev, physicalDevice);
    VK_OUTARRAY_MAKE_TYPED(VkCooperativeMatrixPropertiesKHR, out, pProperties, pPropertyCount);
 
+   if (pdev->info.gfx_level >= GFX12) {
+      for (unsigned e5m2_a = 0; e5m2_a < 2; e5m2_a++) {
+         for (unsigned e5m2_b = 0; e5m2_b < 2; e5m2_b++) {
+            VkComponentTypeKHR a_type = e5m2_a ? VK_COMPONENT_TYPE_FLOAT8_E5M2_EXT : VK_COMPONENT_TYPE_FLOAT8_E4M3_EXT;
+            VkComponentTypeKHR b_type = e5m2_b ? VK_COMPONENT_TYPE_FLOAT8_E5M2_EXT : VK_COMPONENT_TYPE_FLOAT8_E4M3_EXT;
+
+            vk_outarray_append_typed(VkCooperativeMatrixPropertiesKHR, &out, p)
+            {
+               *p = (struct VkCooperativeMatrixPropertiesKHR){
+                  .sType = VK_STRUCTURE_TYPE_COOPERATIVE_MATRIX_PROPERTIES_KHR,
+                  .MSize = 16,
+                  .NSize = 16,
+                  .KSize = 16,
+                  .AType = a_type,
+                  .BType = b_type,
+                  .CType = VK_COMPONENT_TYPE_FLOAT32_KHR,
+                  .ResultType = VK_COMPONENT_TYPE_FLOAT32_KHR,
+                  .saturatingAccumulation = false,
+                  .scope = VK_SCOPE_SUBGROUP_KHR};
+            }
+         }
+      }
+   }
+
    for (unsigned bfloat = 0; bfloat < 2; bfloat++) {
       for (unsigned fp32 = 0; fp32 < 2; fp32++) {
          VkComponentTypeKHR ab_type = bfloat ? VK_COMPONENT_TYPE_BFLOAT16_KHR : VK_COMPONENT_TYPE_FLOAT16_KHR;
-- 
2.49.0


From c974069574e50e5f0c15b68b1149ed74f93b290a Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Tue, 17 Jun 2025 09:19:26 +0200
Subject: [PATCH 19/26] radv/nir/lower_cmat: use common matrix layout on gfx12

The GFX12 ISA doc describes other layouts for A/B, but they are identical
to the C layout with the exception of the order of the rows (columns for A).
And as long as these are swapped in the same way for both A and B, the muladd
result will be the same. So we use the C layout for all uses.

This will simplify conversions between uses, and allows A/B to use a single
memory access for load/store in wave32.

Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 .../nir/radv_nir_lower_cooperative_matrix.c   | 33 +++++--------------
 1 file changed, 9 insertions(+), 24 deletions(-)

diff --git a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
index 45a26c0001e..c31ca27db60 100644
--- a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
+++ b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
@@ -17,18 +17,6 @@
  * as below:
  *
  * Wave32:
- * A&B:
- *         0..15  | 16..31 (lanes)
- * v0 lo:  row 0  | row 4
- * v0 hi:  row 1  | row 5
- * v1 lo:  row 2  | row 6
- * v1 hi:  row 3  | row 7
- * v2 lo:  row 8  | row 12
- * v2 hi:  row 9  | row 13
- * v3 lo:  row 10 | row 14
- * v3 hi:  row 11 | row 15
- *
- * C:
  *         0..15  | 16..31 (lanes)
  * v0 lo:  row 0  | row 8
  * v0 hi:  row 1  | row 9
@@ -40,19 +28,16 @@
  * v3 hi:  row 7  | row 15
  *
  * Wave64:
- * A&B:
- *         0..15 | 16..31 | 32..47 | 48..63 (lanes)
- * v0 lo:  row 0 | row 4  | row 8  | row 12
- * v0 hi:  row 1 | row 5  | row 9  | row 13
- * v1 lo:  row 2 | row 6  | row 10 | row 14
- * v1 hi:  row 3 | row 7  | row 11 | row 15
- *
- * C:
  *         0..15 | 16..31 | 32..47 | 48..63 (lanes)
  * v0 lo:  row 0 | row 8  | row 4  | row 12
  * v0 hi:  row 1 | row 9  | row 5  | row 13
  * v1 lo:  row 2 | row 10 | row 6  | row 14
  * v1 hi:  row 3 | row 11 | row 7  | row 15
+ *
+ * Note that the GFX12 ISA doc describes other layouts for A/B, but they are identical
+ * to the C layout with the exception of the order of the rows (columns for A).
+ * And as long as these are swapped in the same way for both A and B, the muladd
+ * result will be the same. So we use the C layout for all uses.
  */
 
 typedef struct {
@@ -166,13 +151,13 @@ radv_get_base_row(nir_builder *b, struct glsl_cmat_description desc, const lower
    if (params->gfx_level >= GFX12) {
       base_row = nir_udiv_imm(b, local_idx, 16);
 
-      if (desc.use == GLSL_CMAT_USE_ACCUMULATOR && params->wave_size == 64) {
+      if (params->wave_size == 64) {
          /* Switch rows from lanes 16..31 to 32..47, offset right shift by -2
           * to get implicit * 4.
           */
          base_row = nir_ushr_imm(b, nir_bitfield_reverse(b, base_row), 30 - 2);
       } else {
-         base_row = nir_imul_imm(b, base_row, desc.use == GLSL_CMAT_USE_ACCUMULATOR && params->wave_size == 32 ? 8 : 4);
+         base_row = nir_imul_imm(b, base_row, 8);
       }
    } else {
       base_row = desc.use == GLSL_CMAT_USE_ACCUMULATOR ? nir_udiv_imm(b, local_idx, 16) : nir_imm_int(b, 0);
@@ -346,7 +331,7 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                   uint32_t row_iter;
 
                   if (gfx_level >= GFX12) {
-                     row_iter = desc.use != GLSL_CMAT_USE_ACCUMULATOR && wave_size == 32 ? i + (i & 4) : i;
+                     row_iter = i;
                   } else {
                      row_iter = i * lanes_per_iter / 16;
                   }
@@ -417,7 +402,7 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                   uint32_t row_iter;
 
                   if (gfx_level >= GFX12) {
-                     row_iter = desc.use != GLSL_CMAT_USE_ACCUMULATOR && wave_size == 32 ? i + (i & 4) : i;
+                     row_iter = i;
                   } else {
                      row_iter = i * lanes_per_iter / 16;
                   }
-- 
2.49.0


From 3d29c7b1a0745203d53a84ec0737af3444e69da3 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 23 Apr 2025 17:40:34 +0200
Subject: [PATCH 20/26] nir: add cmat_transpose

---
 src/compiler/nir/nir_intrinsics.py | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/compiler/nir/nir_intrinsics.py b/src/compiler/nir/nir_intrinsics.py
index 25b7d3dd362..411c093ede5 100644
--- a/src/compiler/nir/nir_intrinsics.py
+++ b/src/compiler/nir/nir_intrinsics.py
@@ -1360,6 +1360,7 @@ intrinsic("cmat_bitcast", src_comp=[-1, -1])
 intrinsic("cmat_extract", src_comp=[-1, 1], dest_comp=1)
 intrinsic("cmat_insert", src_comp=[-1, 1, -1, 1])
 intrinsic("cmat_copy", src_comp=[-1, -1])
+intrinsic("cmat_transpose", src_comp=[-1, -1])
 
 # IR3-specific version of most SSBO intrinsics. The only different
 # compare to the originals is that they add an extra source to hold
-- 
2.49.0


From 41828ea6ae4d2002cfb7f28ad29129ee9ec046ff Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 23 Apr 2025 17:41:15 +0200
Subject: [PATCH 21/26] spirv: implement CooperativeMatrixConversionsNV

---
 src/compiler/spirv/spirv_to_nir.c |  3 +++
 src/compiler/spirv/vtn_cmat.c     | 20 ++++++++++++++++++++
 2 files changed, 23 insertions(+)

diff --git a/src/compiler/spirv/spirv_to_nir.c b/src/compiler/spirv/spirv_to_nir.c
index 64463de8695..48b63b26d4a 100644
--- a/src/compiler/spirv/spirv_to_nir.c
+++ b/src/compiler/spirv/spirv_to_nir.c
@@ -67,6 +67,7 @@ static const struct spirv_capabilities implemented_capabilities = {
    .ComputeDerivativeGroupLinearKHR = true,
    .ComputeDerivativeGroupQuadsKHR = true,
    .CooperativeMatrixKHR = true,
+   .CooperativeMatrixConversionsNV = true,
    .CullDistance = true,
    .DemoteToHelperInvocation = true,
    .DenormFlushToZero = true,
@@ -6861,6 +6862,8 @@ vtn_handle_body_instruction(struct vtn_builder *b, SpvOp opcode,
    case SpvOpCooperativeMatrixStoreKHR:
    case SpvOpCooperativeMatrixLengthKHR:
    case SpvOpCooperativeMatrixMulAddKHR:
+   case SpvOpCooperativeMatrixConvertNV:
+   case SpvOpCooperativeMatrixTransposeNV:
       vtn_handle_cooperative_instruction(b, opcode, w, count);
       break;
 
diff --git a/src/compiler/spirv/vtn_cmat.c b/src/compiler/spirv/vtn_cmat.c
index 8a1935f0e3d..fffe936f5d2 100644
--- a/src/compiler/spirv/vtn_cmat.c
+++ b/src/compiler/spirv/vtn_cmat.c
@@ -179,6 +179,26 @@ vtn_handle_cooperative_instruction(struct vtn_builder *b, SpvOp opcode,
       break;
    }
 
+   case SpvOpCooperativeMatrixConvertNV: {
+      struct vtn_type *dst_type = vtn_get_type(b, w[1]);
+      nir_deref_instr *src = vtn_get_cmat_deref(b, w[3]);
+
+      nir_deref_instr *dst = vtn_create_cmat_temporary(b, dst_type->type, "cmat_convert_nv");
+      nir_cmat_convert(&b->nb, &dst->def, &src->def);
+      vtn_push_var_ssa(b, w[2], dst->var);
+      break;
+   }
+
+   case SpvOpCooperativeMatrixTransposeNV: {
+      struct vtn_type *dst_type = vtn_get_type(b, w[1]);
+      nir_deref_instr *src = vtn_get_cmat_deref(b, w[3]);
+
+      nir_deref_instr *dst = vtn_create_cmat_temporary(b, dst_type->type, "cmat_transpose_nv");
+      nir_cmat_transpose(&b->nb, &dst->def, &src->def);
+      vtn_push_var_ssa(b, w[2], dst->var);
+      break;
+   }
+
    default:
       unreachable("Unexpected opcode for cooperative matrix instruction");
    }
-- 
2.49.0


From bfe47dc00089265e398e3e0cb63cce853201e639 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Fri, 2 May 2025 14:01:54 +0200
Subject: [PATCH 22/26] radv/nir/lower_cmat: implement use
 conversions/transpose

This could potentially be improved using packed 32bit subgroup ops,
but what we actually care about (gfx12 ACC -> B) is free.
---
 .../nir/radv_nir_lower_cooperative_matrix.c   | 159 +++++++++++++++++-
 1 file changed, 154 insertions(+), 5 deletions(-)

diff --git a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
index c31ca27db60..20d5ee8386b 100644
--- a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
+++ b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
@@ -204,6 +204,128 @@ convert_base_type(nir_builder *b, nir_def *src, enum glsl_base_type src_type, en
    return nir_build_alu1(b, op, src);
 }
 
+static nir_def *
+convert_use(nir_builder *b, nir_def *src, enum glsl_cmat_use src_use, enum glsl_cmat_use dst_use,
+            const lower_cmat_params *params)
+{
+   if (src_use == dst_use)
+      return src;
+   if (params->gfx_level >= GFX12) {
+      if (src_use == GLSL_CMAT_USE_B && dst_use == GLSL_CMAT_USE_ACCUMULATOR)
+         return src;
+      if (src_use == GLSL_CMAT_USE_ACCUMULATOR && dst_use == GLSL_CMAT_USE_B)
+         return src;
+   }
+
+   if (src_use == GLSL_CMAT_USE_A && dst_use == GLSL_CMAT_USE_ACCUMULATOR) {
+      src = convert_use(b, src, GLSL_CMAT_USE_A, GLSL_CMAT_USE_B, params);
+      return convert_use(b, src, GLSL_CMAT_USE_B, GLSL_CMAT_USE_ACCUMULATOR, params);
+   } else if (src_use == GLSL_CMAT_USE_ACCUMULATOR && dst_use == GLSL_CMAT_USE_A) {
+      src = convert_use(b, src, GLSL_CMAT_USE_ACCUMULATOR, GLSL_CMAT_USE_B, params);
+      return convert_use(b, src, GLSL_CMAT_USE_B, GLSL_CMAT_USE_A, params);
+   }
+
+   nir_def *components[NIR_MAX_VEC_COMPONENTS] = {NULL};
+
+   unsigned num_comps = src->num_components;
+   for (unsigned i = 0; i < num_comps; i++)
+      components[i] = nir_channel(b, src, i);
+
+   if (src_use == GLSL_CMAT_USE_ACCUMULATOR && dst_use == GLSL_CMAT_USE_B) {
+      assert(params->gfx_level < GFX12);
+      nir_def *tmp[NIR_MAX_VEC_COMPONENTS];
+
+      if (params->wave_size == 64) {
+         nir_def *low_lanes = nir_inverse_ballot(b, 1, nir_imm_intN_t(b, UINT32_MAX, 64));
+         for (int i = 0; i < num_comps; i++) {
+            nir_def *comp = components[i];
+            nir_def *half_swap = nir_rotate(b, comp, nir_imm_int(b, 32), .cluster_size = 64);
+
+            tmp[i * 2] = nir_bcsel(b, low_lanes, comp, half_swap);
+            tmp[i * 2 + 1] = nir_bcsel(b, low_lanes, half_swap, comp);
+         }
+         num_comps *= 2;
+         memcpy(components, tmp, sizeof(components));
+      }
+
+      for (int i = 0; i < num_comps; i++) {
+         unsigned broadcast_low16 = 0xf;
+         unsigned broadcast_high16 = 0xf | (0x10 << 10);
+         tmp[i * 2] = nir_masked_swizzle_amd(b, components[i], .swizzle_mask = broadcast_low16, .fetch_inactive = 1);
+         tmp[i * 2 + 1] =
+            nir_masked_swizzle_amd(b, components[i], .swizzle_mask = broadcast_high16, .fetch_inactive = 1);
+      }
+
+      num_comps *= 2;
+      memcpy(components, tmp, sizeof(components));
+      assert(num_comps == 16);
+   } else if (src_use == GLSL_CMAT_USE_B && dst_use == GLSL_CMAT_USE_ACCUMULATOR) {
+      assert(params->gfx_level < GFX12);
+      assert(num_comps == 16);
+      for (unsigned keep32 = 0; keep32 < ((params->wave_size == 64) ? 2 : 1); keep32++) {
+         nir_def *ballot = nir_imm_intN_t(b, keep32 ? UINT32_MAX : 0xffff0000ffffull, params->wave_size);
+         nir_def *keep = nir_inverse_ballot(b, 1, ballot);
+         for (unsigned i = 0; i < num_comps; i++) {
+            components[i] = nir_bcsel(b, keep, components[i], components[i + 1]);
+         }
+         num_comps /= 2;
+      }
+   } else if ((src_use == GLSL_CMAT_USE_A && dst_use == GLSL_CMAT_USE_B) ||
+              (src_use == GLSL_CMAT_USE_B && dst_use == GLSL_CMAT_USE_A)) {
+      /* Transpose is a mess... */
+      for (unsigned x_mask = 1; x_mask < num_comps; x_mask *= 2) {
+         /* Use separate masks to always keep the masked_swizzle on the first source of v_cndmask. */
+         uint64_t mask = 0;
+         for (unsigned i = 0; i < 64; i += 2 * x_mask) {
+            mask |= BITFIELD64_MASK(x_mask) << i;
+         }
+
+         nir_def *even = nir_inverse_ballot(b, 1, nir_imm_intN_t(b, mask, params->wave_size));
+         nir_def *odd = nir_inverse_ballot(b, 1, nir_imm_intN_t(b, mask << x_mask, params->wave_size));
+
+         for (unsigned i = 0; i < num_comps; i += 2 * x_mask) {
+            for (unsigned j = 0; j < x_mask; j++) {
+               unsigned pos0 = i + j;
+               unsigned pos1 = pos0 + x_mask;
+               nir_def *comp0 = components[pos0];
+               nir_def *comp1 = components[pos1];
+
+               nir_def *comp0x =
+                  nir_masked_swizzle_amd(b, comp0, .swizzle_mask = 0x1f | (x_mask << 10), .fetch_inactive = 1);
+               nir_def *comp1x =
+                  nir_masked_swizzle_amd(b, comp1, .swizzle_mask = 0x1f | (x_mask << 10), .fetch_inactive = 1);
+
+               components[pos0] = nir_bcsel(b, even, comp0, comp1x);
+               components[pos1] = nir_bcsel(b, odd, comp1, comp0x);
+            }
+         }
+      }
+
+      assert(num_comps == 16 || params->gfx_level >= GFX12);
+
+      if (params->gfx_level >= GFX12) {
+         if (params->wave_size == 64) {
+            nir_def *cond = nir_inverse_ballot(b, 1, nir_imm_intN_t(b, 0xf0f0f0f00f0f0f0f, params->wave_size));
+            for (unsigned i = 0; i < num_comps; i++) {
+               nir_def *comp = components[i];
+               nir_def *compx = nir_rotate(b, comp, nir_imm_int(b, 32));
+               compx = nir_masked_swizzle_amd(b, compx, .swizzle_mask = 0x1f | (0x4 << 10), .fetch_inactive = 1);
+               components[i] = nir_bcsel(b, cond, comp, compx);
+            }
+         }
+
+         nir_def *cond = nir_inverse_ballot(b, 1, nir_imm_intN_t(b, 0xff0000ffff0000ff, params->wave_size));
+         for (unsigned i = 0; i < num_comps; i++) {
+            nir_def *comp = components[i];
+            nir_def *compx = nir_masked_swizzle_amd(b, comp, .swizzle_mask = 0x1f | (0x18 << 10), .fetch_inactive = 1);
+            components[i] = nir_bcsel(b, cond, comp, compx);
+         }
+      }
+   }
+
+   return nir_vec(b, components, num_comps);
+}
+
 bool
 radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_level, unsigned wave_size)
 {
@@ -461,6 +583,7 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                progress = true;
                break;
             }
+            case nir_intrinsic_cmat_transpose:
             case nir_intrinsic_cmat_convert: {
                nir_deref_instr *dst_deref = nir_instr_as_deref(intr->src[0].ssa->parent_instr);
                nir_deref_instr *src_deref = nir_instr_as_deref(intr->src[1].ssa->parent_instr);
@@ -468,13 +591,37 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                struct glsl_cmat_description src_desc = *glsl_get_cmat_description(src_deref->type);
                nir_def *src = radv_nir_load_cmat(&b, &params, intr->src[1].ssa);
 
-               const nir_cmat_signed cmat_signed_mask = nir_intrinsic_cmat_signed_mask(intr);
                const bool sat = nir_intrinsic_saturate(intr);
+               bool transpose = intr->intrinsic == nir_intrinsic_cmat_transpose;
+
+               enum glsl_cmat_use dst_use = dst_desc.use;
+               enum glsl_cmat_use src_use = src_desc.use;
+
+               enum glsl_base_type dst_element_type = dst_desc.element_type;
+               enum glsl_base_type src_element_type = src_desc.element_type;
+
+               if (transpose) {
+                  /* NV_cmat2 only support acc -> b transpose, but we can handle any transpose except acc -> acc. */
+                  if (dst_use == GLSL_CMAT_USE_A) {
+                     dst_use = GLSL_CMAT_USE_B;
+                  } else if (dst_use == GLSL_CMAT_USE_B) {
+                     dst_use = GLSL_CMAT_USE_A;
+                  } else if (dst_use == GLSL_CMAT_USE_ACCUMULATOR) {
+                     if (src_use == GLSL_CMAT_USE_A)
+                        src_use = GLSL_CMAT_USE_B;
+                     else if (src_use == GLSL_CMAT_USE_B)
+                        src_use = GLSL_CMAT_USE_A;
+                     else
+                        unreachable("unsupported transpose");
+                  }
+               } else {
+                  nir_cmat_signed cmat_signed_mask = nir_intrinsic_cmat_signed_mask(intr);
 
-               enum glsl_base_type dst_element_type = glsl_apply_signedness_to_base_type(
-                  dst_desc.element_type, cmat_signed_mask & NIR_CMAT_RESULT_SIGNED);
-               enum glsl_base_type src_element_type = glsl_apply_signedness_to_base_type(
-                  src_desc.element_type, cmat_signed_mask & NIR_CMAT_A_SIGNED);
+                  dst_element_type =
+                     glsl_apply_signedness_to_base_type(dst_element_type, cmat_signed_mask & NIR_CMAT_RESULT_SIGNED);
+                  src_element_type =
+                     glsl_apply_signedness_to_base_type(src_element_type, cmat_signed_mask & NIR_CMAT_A_SIGNED);
+               }
 
                unsigned dst_mul = radv_nir_cmat_length_mul(dst_desc, &params);
                unsigned src_mul = radv_nir_cmat_length_mul(src_desc, &params);
@@ -488,6 +635,8 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                   src = nir_vec(&b, components, src->num_components / scale);
                }
 
+               src = convert_use(&b, src, src_use, dst_use, &params);
+
                nir_def *ret = convert_base_type(&b, src, src_element_type, dst_element_type, sat);
 
                if (dst_mul > src_mul) {
-- 
2.49.0


From 1bf59661c15bd23f0325b3b713d6c733481e6363 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 23 Apr 2025 17:25:13 +0200
Subject: [PATCH 23/26] radv: advertise
 VK_NV_cooperative_matrix2/cooperativeMatrixConversions behind an env var

---
 src/amd/vulkan/radv_instance.c        |  3 +++
 src/amd/vulkan/radv_instance.h        |  1 +
 src/amd/vulkan/radv_physical_device.c | 24 ++++++++++++++++++++++++
 src/util/00-radv-defaults.conf        |  1 +
 src/util/driconf.h                    |  4 ++++
 5 files changed, 33 insertions(+)

diff --git a/src/amd/vulkan/radv_instance.c b/src/amd/vulkan/radv_instance.c
index a6bbeadb286..a658996bd12 100644
--- a/src/amd/vulkan/radv_instance.c
+++ b/src/amd/vulkan/radv_instance.c
@@ -195,6 +195,7 @@ static const driOptionDescription radv_dri_options[] = {
       DRI_CONF_RADV_EMULATE_RT(false)
       DRI_CONF_RADV_ENABLE_FLOAT16_GFX8(false)
       DRI_CONF_RADV_DISABLE_HIZ_HIS_GFX12(false)
+      DRI_CONF_RADV_COOPERATIVE_MATRIX2_NV(false)
    DRI_CONF_SECTION_END
 };
 // clang-format on
@@ -299,6 +300,8 @@ radv_init_dri_options(struct radv_instance *instance)
    instance->drirc.expose_float16_gfx8 = driQueryOptionb(&instance->drirc.options, "radv_enable_float16_gfx8");
 
    instance->drirc.disable_hiz_his_gfx12 = driQueryOptionb(&instance->drirc.options, "radv_disable_hiz_his_gfx12");
+
+   instance->drirc.cooperative_matrix2_nv = driQueryOptionb(&instance->drirc.options, "radv_cooperative_matrix2_nv");
 }
 
 static const struct vk_instance_extension_table radv_instance_extensions_supported = {
diff --git a/src/amd/vulkan/radv_instance.h b/src/amd/vulkan/radv_instance.h
index 42285001563..a12610c3428 100644
--- a/src/amd/vulkan/radv_instance.h
+++ b/src/amd/vulkan/radv_instance.h
@@ -74,6 +74,7 @@ struct radv_instance {
       bool emulate_rt;
       bool expose_float16_gfx8;
       bool disable_hiz_his_gfx12;
+      bool cooperative_matrix2_nv;
       char *app_layer;
       uint8_t override_graphics_shader_version;
       uint8_t override_compute_shader_version;
diff --git a/src/amd/vulkan/radv_physical_device.c b/src/amd/vulkan/radv_physical_device.c
index 2729c1d56d3..f440c541661 100644
--- a/src/amd/vulkan/radv_physical_device.c
+++ b/src/amd/vulkan/radv_physical_device.c
@@ -133,6 +133,17 @@ radv_cooperative_matrix_enabled(const struct radv_physical_device *pdev)
    return pdev->info.gfx_level >= GFX11 && !pdev->use_llvm;
 }
 
+static bool
+radv_cooperative_matrix2_nv_enabled(const struct radv_physical_device *pdev)
+{
+   if (!radv_cooperative_matrix_enabled(pdev))
+      return false;
+
+   const struct radv_instance *instance = radv_physical_device_instance(pdev);
+
+   return instance->drirc.cooperative_matrix2_nv;
+}
+
 bool
 radv_enable_rt(const struct radv_physical_device *pdev)
 {
@@ -754,6 +765,7 @@ radv_physical_device_get_supported_extensions(const struct radv_physical_device
       .INTEL_shader_integer_functions2 = true,
       .MESA_image_alignment_control = pdev->info.gfx_level >= GFX9,
       .NV_compute_shader_derivatives = true,
+      .NV_cooperative_matrix2 = radv_cooperative_matrix2_nv_enabled(pdev),
       .VALVE_mutable_descriptor_type = true,
    };
    *out_ext = ext;
@@ -1335,6 +1347,9 @@ radv_physical_device_get_features(const struct radv_physical_device *pdev, struc
       /* VK_EXT_shader_float8 */
       .shaderFloat8 = true,
       .shaderFloat8CooperativeMatrix = radv_cooperative_matrix_enabled(pdev),
+
+      /* VK_NV_cooperative_matrix2 */
+      .cooperativeMatrixConversions = true,
    };
 }
 
@@ -2973,3 +2988,12 @@ radv_GetPhysicalDeviceCooperativeMatrixPropertiesKHR(VkPhysicalDevice physicalDe
 
    return vk_outarray_status(&out);
 }
+
+VKAPI_ATTR VkResult VKAPI_CALL
+radv_GetPhysicalDeviceCooperativeMatrixFlexibleDimensionsPropertiesNV(
+   VkPhysicalDevice physicalDevice, uint32_t *pPropertyCount,
+   VkCooperativeMatrixFlexibleDimensionsPropertiesNV *pProperties)
+{
+   *pPropertyCount = 0;
+   return VK_SUCCESS;
+}
diff --git a/src/util/00-radv-defaults.conf b/src/util/00-radv-defaults.conf
index 75c7fb25a51..b82e8d4da4d 100644
--- a/src/util/00-radv-defaults.conf
+++ b/src/util/00-radv-defaults.conf
@@ -42,6 +42,7 @@ Application bugs worked around in this file:
             <option name="radv_zero_vram" value="true" />
             <option name="radv_disable_aniso_single_level" value="true" />
             <option name="radv_disable_trunc_coord" value="true" />
+            <option name="radv_cooperative_matrix2_nv" value="true" />
         </engine>
 
         <engine engine_name_match="DXVK">
diff --git a/src/util/driconf.h b/src/util/driconf.h
index 4031a17059e..8b36db732b3 100644
--- a/src/util/driconf.h
+++ b/src/util/driconf.h
@@ -788,6 +788,10 @@
    DRI_CONF_OPT_B(radv_disable_hiz_his_gfx12, def, \
                   "Disable HiZ/HiS on GFX12 (RDNA4) to workaround a hw bug that causes random GPU hangs")
 
+#define DRI_CONF_RADV_COOPERATIVE_MATRIX2_NV(def) \
+   DRI_CONF_OPT_B(radv_cooperative_matrix2_nv, def, \
+                  "Expose VK_NV_cooperative_matrix2 on supported hardware.")
+
 /**
  * \brief ANV specific configuration options
  */
-- 
2.49.0


From 9fddf99d785b95b67b94bba7272cb7aa687af70a Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Thu, 15 May 2025 12:14:20 +0200
Subject: [PATCH 24/26] radv/ci: test VK_NV_cooperative_matrix2

---
 src/amd/ci/gitlab-ci-inc.yml | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/amd/ci/gitlab-ci-inc.yml b/src/amd/ci/gitlab-ci-inc.yml
index a06445eebeb..27f927a904c 100644
--- a/src/amd/ci/gitlab-ci-inc.yml
+++ b/src/amd/ci/gitlab-ci-inc.yml
@@ -314,6 +314,7 @@
     # the code generator.
     ACO_DEBUG: validateir,validatera
     MESA_VK_IGNORE_CONFORMANCE_WARNING: 1
+    radv_cooperative_matrix2_nv: 'true'
     # Enable ETC2 emulation on non-native platforms (RENOIR,RDNA+, GFX6-8 dGPUs)
     vk_require_etc2: 'true'
     CI_TRON__B2C_SWAP_SIZE: '16g'
-- 
2.49.0


From 0fe773b338609cd73584fe59e4eb21cdaa104023 Mon Sep 17 00:00:00 2001
From: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Date: Tue, 17 Jun 2025 14:51:50 +0200
Subject: [PATCH 25/26] ac/pm4: determine spi_shader_pgm_lo_reg when
 PKT3_SET_SH_REG_PAIRS is used

---
 src/amd/common/ac_pm4.c | 16 ++++++++++++++++
 1 file changed, 16 insertions(+)

diff --git a/src/amd/common/ac_pm4.c b/src/amd/common/ac_pm4.c
index df9a6d9448c..cfb7541ebd2 100644
--- a/src/amd/common/ac_pm4.c
+++ b/src/amd/common/ac_pm4.c
@@ -204,6 +204,22 @@ ac_pm4_finalize(struct ac_pm4_state *state)
          }
       }
    }
+
+   if (state->debug_sqtt && state->last_opcode == PKT3_SET_SH_REG_PAIRS) {
+      /* Set reg_va_low_idx to where the shader address is stored in the pm4 state. */
+      unsigned reg_count = (PKT_COUNT_G(state->pm4[state->last_pm4]) + 1) / 2;
+
+      for (unsigned i = 0; i < reg_count; i++) {
+         unsigned reg_base_offset = SI_SH_REG_OFFSET + state->pm4[state->last_pm4 + 1 + 2 * i] * 4;
+         if (strstr(ac_get_register_name(state->info->gfx_level,
+                                         state->info->family, reg_base_offset),
+                    "SPI_SHADER_PGM_LO_")) {
+            state->spi_shader_pgm_lo_reg = reg_base_offset;
+
+            break;
+         }
+      }
+   }
 }
 
 void
-- 
2.49.0


From 47c705fe75ceacb987d0ab0a410ecd186ae62bc7 Mon Sep 17 00:00:00 2001
From: Georg Lehmann <dadschoorse@gmail.com>
Date: Wed, 18 Jun 2025 16:42:17 +0200
Subject: [PATCH 26/26] radv/nir/lower_cmat: set optimal align for matrix
 load/store

---
 .../nir/radv_nir_lower_cooperative_matrix.c   | 32 +++++++++++++++++++
 1 file changed, 32 insertions(+)

diff --git a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
index 20d5ee8386b..7e0ecf9be17 100644
--- a/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
+++ b/src/amd/vulkan/nir/radv_nir_lower_cooperative_matrix.c
@@ -447,6 +447,15 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                unsigned idx_bits = deref->def.bit_size;
                nir_def *base_row = radv_get_base_row(&b, desc, &params, local_idx);
 
+               unsigned align_mul = 0;
+               if (layout == GLSL_MATRIX_LAYOUT_COLUMN_MAJOR)
+                  align_mul = MIN2(16, radv_nir_cmat_bits(desc) * desc.rows / 8);
+
+               if (gfx_level >= GFX12)
+                  align_mul /= wave_size / 16;
+               else if (desc.use == GLSL_CMAT_USE_ACCUMULATOR)
+                  align_mul = 0;
+
                for (unsigned i = 0; i < length / mul; ++i) {
                   nir_def *col_offset = inner_idx;
                   nir_def *row_offset;
@@ -476,6 +485,13 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                                                     glsl_scalar_type(desc.element_type), radv_nir_cmat_bits(desc) / 8);
                   iter_deref = nir_build_deref_ptr_as_array(&b, iter_deref, row_offset);
 
+                  if (align_mul) {
+                     unsigned align_offset = row_iter * radv_nir_cmat_bits(desc) / 8 % align_mul;
+                     iter_deref = nir_build_deref_cast_with_alignment(
+                        &b, &iter_deref->def, deref->modes, glsl_scalar_type(desc.element_type),
+                        radv_nir_cmat_bits(desc) / 8, align_mul, align_offset);
+                  }
+
                   vars[i * mul] = nir_load_deref(&b, iter_deref);
                }
 
@@ -518,6 +534,15 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                unsigned idx_bits = deref->def.bit_size;
                nir_def *base_row = radv_get_base_row(&b, desc, &params, local_idx);
 
+               unsigned align_mul = 0;
+               if (layout == GLSL_MATRIX_LAYOUT_COLUMN_MAJOR)
+                  align_mul = MIN2(16, radv_nir_cmat_bits(desc) * desc.rows / 8);
+
+               if (gfx_level >= GFX12)
+                  align_mul /= wave_size / 16;
+               else if (desc.use == GLSL_CMAT_USE_ACCUMULATOR)
+                  align_mul = 0;
+
                for (unsigned i = 0; i < length / mul; ++i) {
                   nir_def *col_offset = inner_idx;
                   nir_def *row_offset;
@@ -547,6 +572,13 @@ radv_nir_lower_cooperative_matrix(nir_shader *shader, enum amd_gfx_level gfx_lev
                                                     glsl_scalar_type(desc.element_type), radv_nir_cmat_bits(desc) / 8);
                   iter_deref = nir_build_deref_ptr_as_array(&b, iter_deref, row_offset);
 
+                  if (align_mul) {
+                     unsigned align_offset = row_iter * radv_nir_cmat_bits(desc) / 8 % align_mul;
+                     iter_deref = nir_build_deref_cast_with_alignment(
+                        &b, &iter_deref->def, deref->modes, glsl_scalar_type(desc.element_type),
+                        radv_nir_cmat_bits(desc) / 8, align_mul, align_offset);
+                  }
+
                   nir_store_deref(&b, iter_deref, vars[i * mul], 1);
                }
 
-- 
2.49.0

